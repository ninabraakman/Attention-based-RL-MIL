{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T22:17:34.310872348Z",
     "start_time": "2023-07-14T22:17:34.302037929Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T22:17:34.988344683Z",
     "start_time": "2023-07-14T22:17:34.311262786Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from aggregate_results import agg_all_results, agg_mil_results, agg_rlmil_results, add_formatted_column, save_dataset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIL json result does not exist! runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_2/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_4/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_7/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_10/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_9/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_3/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20\n",
      "MIL json result does not exist! runs/classification/seed_5/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20\n",
      "runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_6/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_1/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/MaxMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/MeanMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_8/oulad_full/instances/tabular/label/bag_size_20/repset_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/repset_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/MeanMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/AttentionMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_2/oulad_aggregated/instances/tabular/label/bag_size_20/MaxMLP_22_16_22/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/classification/seed_2/oulad_full/instances/tabular/label/bag_size_20/AttentionMLP_20_16_20/neg_policy_only_loss_epsilon_greedy_reg_sum_sample_static\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m classification_results \u001b[38;5;241m=\u001b[39m \u001b[43magg_all_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mbag_embedded_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbag_embedding_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/aggregate_results.py:48\u001b[0m, in \u001b[0;36magg_all_results\u001b[0;34m(device, data_dir_path, models_dir_path, bag_embedded_column_name, task_type, config_vars)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magg_all_results\u001b[39m(device, data_dir_path, models_dir_path, bag_embedded_column_name,  task_type, config_vars\u001b[38;5;241m=\u001b[39m[]):\n\u001b[1;32m     46\u001b[0m     mil_results \u001b[38;5;241m=\u001b[39m agg_mil_results(device, data_dir_path, models_dir_path, \n\u001b[1;32m     47\u001b[0m                                   bag_embedded_column_name,  task_type, config_vars)\n\u001b[0;32m---> 48\u001b[0m     rlmil_results \u001b[38;5;241m=\u001b[39m \u001b[43magg_rlmil_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mbag_embedded_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([mil_results, rlmil_results])\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/aggregate_results.py:109\u001b[0m, in \u001b[0;36magg_rlmil_results\u001b[0;34m(device, data_dir_path, models_dir_path, bag_embedded_column_name, task_type, config_vars, in_seeds)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(root)\n\u001b[1;32m    108\u001b[0m set_seed(\u001b[38;5;28mint\u001b[39m(random_seed))\n\u001b[0;32m--> 109\u001b[0m metrics, csv_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_result_for_rlmil_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdata_embedded_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mbag_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbag_embedded_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    113\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrl-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding_model_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m: prefix,\n\u001b[1;32m    121\u001b[0m         })\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/aggregate_results.py:222\u001b[0m, in \u001b[0;36mgenerate_result_for_rlmil_model\u001b[0;34m(model_path, device, random_seed, data_dir_path, dataset, data_embedded_column_name, embedding_model_name, target_column_name, bag_size, bag_embedded_column_name, task_type)\u001b[0m\n\u001b[1;32m    220\u001b[0m random \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly_ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split, dataloader \u001b[38;5;129;01min\u001b[39;00m dataloaders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 222\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_from_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbag_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     metric, probs, labels, preds \u001b[38;5;241m=\u001b[39m policy_network\u001b[38;5;241m.\u001b[39mcompute_metrics_and_details(data)\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# dataloader_pool = policy_network.create_pool_data(dataloader=dataloader, bag_size=int(bag_size), pool_size=pool_size, random=random)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# avg_reward, loss, ensemble_reward = policy_network.expected_reward_loss(dataloader_pool)\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/models.py:663\u001b[0m, in \u001b[0;36mPolicyNetwork.select_from_dataloader\u001b[0;34m(self, dataloader, bag_size, random)\u001b[0m\n\u001b[1;32m    661\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# select batch_x\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m action_probs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m sample_action(action_probs, bag_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, random\u001b[38;5;241m=\u001b[39mrandom, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_algorithm)\n\u001b[1;32m    665\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m select_from_action(action, batch_x)\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/models.py:628\u001b[0m, in \u001b[0;36mPolicyNetwork.forward\u001b[0;34m(self, batch_x)\u001b[0m\n\u001b[1;32m    626\u001b[0m     batch_rep \u001b[38;5;241m=\u001b[39m batch_x\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 628\u001b[0m     batch_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# batch_size, bag_size, embedding_size = batch_rep.shape\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# batch_rep = batch_rep.view(batch_size * bag_size, embedding_size)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m exp_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(batch_rep)\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/models.py:41\u001b[0m, in \u001b[0;36mBaseNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_sizes:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# batch_size, bag_size, d = x.size()\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# x = x.view(batch_size * bag_size, d)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# x = x.view(batch_size, bag_size, -1)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "model_path = 'runs'\n",
    "bag_embedding_column_name = \"bag_embeddings\"\n",
    "\n",
    "task_type = 'classification'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classification_results = agg_all_results(device=device, data_dir_path=data_path, models_dir_path=model_path,\n",
    "                                      bag_embedded_column_name=bag_embedding_column_name, task_type=task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_results\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_results\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m classification_results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_results.shape)\n",
    "print(classification_results.head())\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classification_results \u001b[38;5;241m=\u001b[39m \u001b[43madd_formatted_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m classification_results\n",
      "File \u001b[0;32m/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/aggregate_results.py:345\u001b[0m, in \u001b[0;36madd_formatted_column\u001b[0;34m(df, metric, extra_groupby_cols)\u001b[0m\n\u001b[1;32m    343\u001b[0m mil_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    344\u001b[0m ensemble_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 345\u001b[0m rlmil_df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL-\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    347\u001b[0m groupby_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m extra_groupby_cols\n\u001b[1;32m    349\u001b[0m mil_df \u001b[38;5;241m=\u001b[39m mil_df\u001b[38;5;241m.\u001b[39mgroupby(groupby_cols)[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39magg([np\u001b[38;5;241m.\u001b[39mmean, np\u001b[38;5;241m.\u001b[39mstd])\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/projects/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "classification_results = add_formatted_column(classification_results, 'f1')\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['incas'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_table(classification_results, 'incas', 'f1', 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking base model path: runs\n",
      "Contents of runs: ['classification']\n",
      "\n",
      "Checking task-specific path: runs/classification\n",
      "Contents of runs/classification: ['seed_6', 'seed_1', 'seed_8', 'seed_2', 'seed_4', 'seed_0', 'seed_7', 'seed_10', 'seed_9', 'seed_3', 'seed_5']\n",
      "\n",
      "Checking specific seed path: runs/classification/seed_1\n",
      "Contents of runs/classification/seed_1: ['oulad_aggregated', 'oulad_full']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = 'data' # As you defined\n",
    "model_path = 'runs' # As you defined\n",
    "task_type = 'classification' # As you defined\n",
    "\n",
    "print(f\"Checking base model path: {model_path}\")\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Contents of {model_path}: {os.listdir(model_path)}\")\n",
    "else:\n",
    "    print(f\"ERROR: {model_path} does NOT exist or is not accessible.\")\n",
    "\n",
    "classification_path = os.path.join(model_path, task_type)\n",
    "print(f\"\\nChecking task-specific path: {classification_path}\")\n",
    "if os.path.exists(classification_path):\n",
    "    print(f\"Contents of {classification_path}: {os.listdir(classification_path)}\")\n",
    "else:\n",
    "    print(f\"ERROR: {classification_path} does NOT exist or is not accessible.\")\n",
    "\n",
    "# Check one specific seed directory, e.g., seed_1\n",
    "seed_1_path = os.path.join(classification_path, \"seed_1\")\n",
    "print(f\"\\nChecking specific seed path: {seed_1_path}\")\n",
    "if os.path.exists(seed_1_path):\n",
    "    print(f\"Contents of {seed_1_path}: {os.listdir(seed_1_path)}\")\n",
    "else:\n",
    "    print(f\"ERROR: {seed_1_path} does NOT exist or is not accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
