{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cc3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a83d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW FULL BAG at index 800 ===\n",
      "Bag ID    : ('BBB', '2013B', 185240)\n",
      "Label     : 0\n",
      "Num Items : 12\n",
      "\n",
      "Instances:\n",
      "  Instance 1: [('code_module', 'BBB')]\n",
      "  Instance 2: [('code_presentation', '2013B')]\n",
      "  Instance 3: [('gender', 'F')]\n",
      "  Instance 4: [('region', 'West Midlands Region')]\n",
      "  Instance 5: [('imd_band', '40-50%')]\n",
      "  Instance 6: [('age_band', '35-55')]\n",
      "  Instance 7: [('disability', 'N')]\n",
      "  Instance 8: [('highest_education', 'Lower Than A Level')]\n",
      "  Instance 9: [('module_presentation_length', 240)]\n",
      "  Instance 10: [('num_of_prev_attempts', 1)]\n",
      "  Instance 11: [('studied_credits', 120)]\n",
      "  Instance 12: [('date_registration', -87.0)]\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "INPUT_PATH   = \"data/oulad/oulad_full_raw.pkl\"\n",
    "BAG_INDEX    = 800   # change to view a different bag\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(INPUT_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_bags = data[\"raw_bags\"]\n",
    "labels   = data[\"labels\"]\n",
    "bag_ids  = data[\"bag_ids\"]\n",
    "\n",
    "# === DISPLAY ONE BAG ===\n",
    "idx = BAG_INDEX\n",
    "print(f\"\\n=== RAW FULL BAG at index {idx} ===\")\n",
    "print(f\"Bag ID    : {bag_ids[idx]}\")\n",
    "print(f\"Label     : {labels[idx]}\")\n",
    "print(f\"Num Items : {len(raw_bags[idx])}\\n\")\n",
    "print(\"Instances:\")\n",
    "for j, inst in enumerate(raw_bags[idx], start=1):\n",
    "    print(f\"  Instance {j}: {inst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c0900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENCODED FULL BAG at index 800 ===\n",
      "Bag ID    : ('BBB', '2013B', 185240)\n",
      "Label     : 0\n",
      "Num Items : 12\n",
      "\n",
      "Instances (vectors):\n",
      "  Instance 1: [2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 2: [0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 3: [0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 4: [ 0.0000  0.0000  0.0000 12.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000]\n",
      "  Instance 5: [0.0000 0.0000 0.0000 0.0000 5.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 6: [0.0000 0.0000 0.0000 0.0000 0.0000 2.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 7: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 8: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 3.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 9: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.1714 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 10: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.1667 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 11: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.1500 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000]\n",
      "  Instance 12: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.2437 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "INPUT_PATH   = \"data/oulad/oulad_full.pkl\"\n",
    "BAG_INDEX    = 800   # same index as above for comparison\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(INPUT_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "bags    = data[\"bags\"]\n",
    "labels  = data[\"labels\"]\n",
    "bag_ids = data[\"bag_ids\"]\n",
    "\n",
    "# === DISPLAY ONE BAG ===\n",
    "idx = BAG_INDEX\n",
    "print(f\"\\n=== ENCODED FULL BAG at index {idx} ===\")\n",
    "print(f\"Bag ID    : {bag_ids[idx]}\")\n",
    "print(f\"Label     : {labels[idx]}\")\n",
    "print(f\"Num Items : {bags[idx].shape[0]}\\n\")\n",
    "print(\"Instances (vectors):\")\n",
    "for j, vec in enumerate(bags[idx], start=1):\n",
    "    print(f\"  Instance {j}: {np.array2string(vec, precision=4, floatmode='fixed')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ac75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances per bag (full raw):\n",
      "mean       209.393769\n",
      "median     157.000000\n",
      "min         12.000000\n",
      "max       1302.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) Load full raw bags\n",
    "with open(\"data/oulad/oulad_full_raw.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_bags = data[\"raw_bags\"]\n",
    "\n",
    "# 2) Compute number of instances per bag\n",
    "lengths = [len(bag) for bag in raw_bags]\n",
    "\n",
    "# 3) Aggregate statistics\n",
    "stats = pd.Series(lengths).agg(['mean', 'median', 'min', 'max'])\n",
    "print(\"Instances per bag (full raw):\")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee80a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW BAG at index 800 ===\n",
      "Bag ID    : ('BBB', '2013B', 185240)\n",
      "Label     : 0\n",
      "Num Items : 12\n",
      "\n",
      "Instances:\n",
      "  Instance 1: [('code_module', 'BBB')]\n",
      "  Instance 2: [('code_presentation', '2013B')]\n",
      "  Instance 3: [('gender', 'F')]\n",
      "  Instance 4: [('region', 'West Midlands Region')]\n",
      "  Instance 5: [('imd_band', '40-50%')]\n",
      "  Instance 6: [('age_band', '35-55')]\n",
      "  Instance 7: [('disability', 'N')]\n",
      "  Instance 8: [('highest_education', 'Lower Than A Level')]\n",
      "  Instance 9: [('module_presentation_length', 240)]\n",
      "  Instance 10: [('num_of_prev_attempts', 1)]\n",
      "  Instance 11: [('studied_credits', 120)]\n",
      "  Instance 12: [('date_registration', -87.0)]\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "INPUT_PATH = \"data/oulad/oulad_aggregated_raw.pkl\"\n",
    "BAG_INDEX   = 800   # change this to inspect a different bag\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(INPUT_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_bags = data[\"raw_bags\"]\n",
    "labels   = data[\"labels\"]\n",
    "bag_ids  = data[\"bag_ids\"]\n",
    "\n",
    "# === DISPLAY ONE BAG ===\n",
    "idx = BAG_INDEX\n",
    "print(f\"\\n=== RAW BAG at index {idx} ===\")\n",
    "print(f\"Bag ID    : {bag_ids[idx]}\")\n",
    "print(f\"Label     : {labels[idx]}\")\n",
    "print(f\"Num Items : {len(raw_bags[idx])}\\n\")\n",
    "print(\"Instances:\")\n",
    "for j, inst in enumerate(raw_bags[idx], start=1):\n",
    "    print(f\"  Instance {j}: {inst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415ce30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENCODED BAG at index 800 ===\n",
      "Bag ID    : ('BBB', '2013B', 185240)\n",
      "Label     : 0\n",
      "Num Items : 12\n",
      "\n",
      "Instances (full vectors):\n",
      "  Instance 1: [2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 2: [0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 3: [0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 4: [ 0.0000  0.0000  0.0000 12.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000]\n",
      "  Instance 5: [0.0000 0.0000 0.0000 0.0000 5.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 6: [0.0000 0.0000 0.0000 0.0000 0.0000 2.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 7: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 8: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 3.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 9: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.1714 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 10: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.1667 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 11: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.1500 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000]\n",
      "  Instance 12: [0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      " 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.2437 0.0000\n",
      " 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "INPUT_PATH = \"data/oulad/oulad_aggregated.pkl\"\n",
    "BAG_INDEX   = 800   # same index as above to compare\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(INPUT_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "bags    = data[\"bags\"]\n",
    "labels  = data[\"labels\"]\n",
    "bag_ids = data[\"bag_ids\"]\n",
    "\n",
    "# === DISPLAY ONE BAG ===\n",
    "idx = BAG_INDEX\n",
    "print(f\"\\n=== ENCODED BAG at index {idx} ===\")\n",
    "print(f\"Bag ID    : {bag_ids[idx]}\")\n",
    "print(f\"Label     : {labels[idx]}\")\n",
    "print(f\"Num Items : {bags[idx].shape[0]}\\n\")\n",
    "print(\"Instances (full vectors):\")\n",
    "for j, vec in enumerate(bags[idx], start=1):\n",
    "    print(f\"  Instance {j}: {np.array2string(vec, precision=4, floatmode='fixed')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb69f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances per bag (full raw):\n",
      "mean      26.425545\n",
      "median    26.000000\n",
      "min       12.000000\n",
      "max       39.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) Load full raw bags\n",
    "with open(\"data/oulad/oulad_aggregated_raw.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_bags = data[\"raw_bags\"]\n",
    "\n",
    "# 2) Compute number of instances per bag\n",
    "lengths = [len(bag) for bag in raw_bags]\n",
    "\n",
    "# 3) Aggregate statistics\n",
    "stats = pd.Series(lengths).agg(['mean', 'median', 'min', 'max'])\n",
    "print(\"Instances per bag (full raw):\")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2ff0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dataset  feature_dim  max_instances\n",
      "0        full           20           1302\n",
      "1  aggregated           22             39\n"
     ]
    }
   ],
   "source": [
    "# Paths to encoded datasets\n",
    "datasets = {\n",
    "    \"full\":       \"data/oulad/oulad_full.pkl\",\n",
    "    \"aggregated\": \"data/oulad/oulad_aggregated.pkl\"\n",
    "}\n",
    "\n",
    "summary = []\n",
    "for name, path in datasets.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    bags = data[\"bags\"]\n",
    "    # feature dimension is the vector length of any instance\n",
    "    feature_dim   = bags[0].shape[1] if bags else 0\n",
    "    # maximum number of instances in any bag\n",
    "    max_instances = max(len(bag) for bag in bags) if bags else 0\n",
    "    summary.append({\n",
    "        \"dataset\":       name,\n",
    "        \"feature_dim\":   feature_dim,\n",
    "        \"max_instances\": max_instances\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bbe903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bag_idx', 'bag_id', 'bag_label', 'instance_idx', 'code_module',\n",
      "       'code_presentation', 'gender', 'region', 'imd_band', 'age_band',\n",
      "       'disability', 'highest_education', 'module_presentation_length',\n",
      "       'num_of_prev_attempts', 'studied_credits', 'date_registration',\n",
      "       'assessment_type', 'score', 'weight', 'date_submitted', 'is_banked',\n",
      "       'activity_type', 'sum_click', 'first_click_day', 'last_click_day',\n",
      "       'click_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# After loading raw_bags, labels, bag_ids:\n",
    "rows = []\n",
    "for bag_idx, instances in enumerate(raw_bags):\n",
    "    bag_label = labels[bag_idx]\n",
    "    bag_id    = bag_ids[bag_idx]\n",
    "    for instance_idx, inst in enumerate(instances):\n",
    "        # assume inst is a dict of categorical features\n",
    "        row = {\n",
    "            \"bag_idx\":   bag_idx,\n",
    "            \"bag_id\":    bag_id,\n",
    "            \"bag_label\": bag_label,\n",
    "            \"instance_idx\":  instance_idx,\n",
    "        }\n",
    "        # merge in all key/value pairs from the instance\n",
    "        # if your inst is not a dict, you could wrap it first\n",
    "        row.update(inst)\n",
    "        rows.append(row)\n",
    "\n",
    "meta_df = pd.DataFrame(rows)\n",
    "print(meta_df.columns)   # you'll see bag_idx, bag_label, inst_idx, plus all your inst-keys\n",
    "\n",
    "# Save\n",
    "meta_df.to_csv(\"instance_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8be73af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_idx</th>\n",
       "      <th>bag_idx</th>\n",
       "      <th>instance_idx</th>\n",
       "      <th>logit</th>\n",
       "      <th>prob</th>\n",
       "      <th>chosen</th>\n",
       "      <th>bag_id</th>\n",
       "      <th>bag_label</th>\n",
       "      <th>code_module</th>\n",
       "      <th>...</th>\n",
       "      <th>assessment_type</th>\n",
       "      <th>score</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_submitted</th>\n",
       "      <th>is_banked</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>sum_click</th>\n",
       "      <th>first_click_day</th>\n",
       "      <th>last_click_day</th>\n",
       "      <th>click_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091539</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>1</td>\n",
       "      <td>('AAA', '2013J', 11391)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054090</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0</td>\n",
       "      <td>('AAA', '2013J', 11391)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.209513</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>1</td>\n",
       "      <td>('AAA', '2013J', 11391)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.029570</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0</td>\n",
       "      <td>('AAA', '2013J', 11391)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>1</td>\n",
       "      <td>('AAA', '2013J', 11391)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch_idx  bag_idx  instance_idx     logit      prob  chosen  \\\n",
       "0      0          0        0             0  0.091539  0.008087       1   \n",
       "1      0          0        0             1 -0.054090  0.006043       0   \n",
       "2      0          0        0             2  0.209513  0.010239       1   \n",
       "3      0          0        0             3 -0.029570  0.006347       0   \n",
       "4      0          0        0             4  0.072425  0.007783       1   \n",
       "\n",
       "                    bag_id  bag_label code_module  ... assessment_type score  \\\n",
       "0  ('AAA', '2013J', 11391)        1.0         AAA  ...             NaN   NaN   \n",
       "1  ('AAA', '2013J', 11391)        1.0         NaN  ...             NaN   NaN   \n",
       "2  ('AAA', '2013J', 11391)        1.0         NaN  ...             NaN   NaN   \n",
       "3  ('AAA', '2013J', 11391)        1.0         NaN  ...             NaN   NaN   \n",
       "4  ('AAA', '2013J', 11391)        1.0         NaN  ...             NaN   NaN   \n",
       "\n",
       "  weight date_submitted is_banked activity_type sum_click  first_click_day  \\\n",
       "0    NaN            NaN       NaN           NaN       NaN              NaN   \n",
       "1    NaN            NaN       NaN           NaN       NaN              NaN   \n",
       "2    NaN            NaN       NaN           NaN       NaN              NaN   \n",
       "3    NaN            NaN       NaN           NaN       NaN              NaN   \n",
       "4    NaN            NaN       NaN           NaN       NaN              NaN   \n",
       "\n",
       "   last_click_day  click_days  \n",
       "0             NaN         NaN  \n",
       "1             NaN         NaN  \n",
       "2             NaN         NaN  \n",
       "3             NaN         NaN  \n",
       "4             NaN         NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_df = pd.read_csv(\"/projects/prjs1491/MasterThesisNinaBraakman/runs/classification/seed_4/oulad_aggregated_subset/instances/tabular/label/bag_size_20/MeanMLP_22_16_22/neg_policy_only_loss_attention_reg_sum_sample_static/attention_log.csv\")\n",
    "meta_df = pd.read_csv(\"instance_metadata.csv\")  # now with all your categorical fields\n",
    "\n",
    "full_df = attn_df.merge(meta_df, on=[\"bag_idx\",\"instance_idx\"], how=\"left\")\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04becd10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/oulad/oulad_full_raw.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m BAG_INDEX \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# adjust to your bag of interest\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# --- Load raw metadata ---\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mINPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     18\u001b[0m raw_bags \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_bags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/projects/prjs1491/MasterThesisNinaBraakman/ve/lib64/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/oulad/oulad_full_raw.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuration ---\n",
    "LOG_FILES = {\n",
    "    \"MaxMLP\": \"MaxMLP_attention_log.csv\",\n",
    "    \"MeanMLP\": \"MeanMLP_attention_log.csv\",\n",
    "    \"Repset\": \"Repset_attention_log.csv\",\n",
    "    \"AttentionMLP\": \"AttentionMLP_attention_log.csv\",\n",
    "}\n",
    "INPUT_PATH = \"/mnt/data/oulad/oulad_full_raw.pkl\"\n",
    "BAG_INDEX = 0  # adjust to your bag of interest\n",
    "\n",
    "# --- Load raw metadata ---\n",
    "with open(INPUT_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "raw_bags = data[\"raw_bags\"]\n",
    "\n",
    "# --- Read logs and merge with metadata ---\n",
    "dfs = {}\n",
    "for name, path in LOG_FILES.items():\n",
    "    df = pd.read_csv(path)\n",
    "    # filter to epoch=0, batch_idx=0, bag_idx=0 for simplicity, and our bag index\n",
    "    df = df[(df[\"epoch\"] == 0) & (df[\"batch_idx\"] == 0) & (df[\"bag_idx\"] == 0)]\n",
    "    # attach instance metadata\n",
    "    metadata = pd.DataFrame({\n",
    "        \"instance_idx\": list(range(len(raw_bags[BAG_INDEX]))),\n",
    "        \"instance\": raw_bags[BAG_INDEX]\n",
    "    })\n",
    "    df = pd.merge(df, metadata, on=\"instance_idx\", how=\"left\")\n",
    "    dfs[name] = df\n",
    "\n",
    "# --- Plotting attention probabilities and highlighting chosen ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (name, df) in enumerate(dfs.items(), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    bars = plt.bar(df[\"instance_idx\"], df[\"prob\"], alpha=0.6, label=\"prob\")\n",
    "    # highlight chosen\n",
    "    for bar, chosen in zip(bars, df[\"chosen\"]):\n",
    "        if chosen:\n",
    "            bar.set_edgecolor(\"red\")\n",
    "            bar.set_linewidth(2)\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Instance Index\")\n",
    "    plt.ylabel(\"Attention Probability\")\n",
    "    plt.ylim(0, df[\"prob\"].max() * 1.1)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Display merged table for one of the methods as example ---\n",
    "dfs[\"AttentionMLP\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7507a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from: data/seed_0/oulad_aggregated_subset/instances/tabular/test.pickle\n",
      "Shape of the first 'bag_embeddings' entry: (39, 22)\n",
      "Dtype of the first 'bag_embeddings' entry: float32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Path to one of your generated pickle files\n",
    "# Adjust if your SAVE_DIR is different in the main script\n",
    "# From your prepare_oulad_data.py, it would be something like:\n",
    "# \"data/seed_0/oulad_aggregated_subset/instances/tabular/train.pickle\"\n",
    "\n",
    "# file_path = \"data/seed_0/oulad_aggregated_subset/instances/tabular/train.pickle\" \n",
    "# file_path = \"data/seed_0/oulad_aggregated_subset/instances/tabular/val.pickle\" \n",
    "file_path = \"data/seed_0/oulad_aggregated_subset/instances/tabular/test.pickle\" \n",
    "\n",
    "try:\n",
    "    df = pd.read_pickle(file_path)\n",
    "    if not df.empty and \"bag_embeddings\" in df.columns:\n",
    "        print(f\"Loaded DataFrame from: {file_path}\")\n",
    "        first_bag_embedding = df[\"bag_embeddings\"].iloc[0]\n",
    "        print(f\"Shape of the first 'bag_embeddings' entry: {first_bag_embedding.shape}\")\n",
    "        print(f\"Dtype of the first 'bag_embeddings' entry: {first_bag_embedding.dtype}\")\n",
    "    else:\n",
    "        print(f\"DataFrame loaded from {file_path} is empty or missing 'bag_embeddings' column.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
