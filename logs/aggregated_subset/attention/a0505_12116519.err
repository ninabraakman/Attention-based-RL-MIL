wandb: Agent Starting Run: gnwbb7q7 with config:
wandb: 	actor_learning_rate: 0.00027264608922635637
wandb: 	attention_dropout_p: 0.26901409925287956
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4283030841296306
wandb: 	temperature: 5.510055932240151
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152538-gnwbb7q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gnwbb7q7
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂▅▅▆▆▇▁▂▇▅▇▁▆▅▂▆▆▇▇▅▇▇▆▇▆▆▃▆▆▇▄▆▆▆▂▂▇▂▅
wandb:      eval/avg_mil_loss ▇▂▂▂▂▂▂▁▂▁▆▂▂▁█▂▁▂▂▂▁▁▁▂▂▂▁█▂▂▃▂▂▂▂▂▂▆▆▁
wandb:       eval/ensemble_f1 ▆▅▆▆▆▇▇▆▂▇▆▇▆▂▅▆█▆▆▆▆▇█▆▇▆▆▆▆▆▆▆▇█▁▆█▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▄▄▂▆▇▆▆█▃▆▅▆█▅▇▅▇▄▅▆▆▅▁▄▅▄▇▆▆▃▅█▁▆▆▂▇
wandb:      train/ensemble_f1 ▅▆▃▄▅▄█▆▄▅▄▄▇▅▃▄▆▆█▅█▄▁▆▆▁▅▄▄▃▄█▂▃▆██▁▅▅
wandb:         train/mil_loss ▂▆▅▃▅▁▄█▃▂▃▃▃▂▄▄▆▄▄▄▁▄▃▄▄▂▂▂▄▂▇▆▄▅▂▂█▃▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▇▃▃▃▃▃▃█▃▃▃▃▃▃▃▁▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.20625
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.34511
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.87879
wandb:      test/avg_mil_loss 0.32671
wandb:       test/ensemble_f1 0.87879
wandb:           train/avg_f1 0.87625
wandb:      train/ensemble_f1 0.87625
wandb:         train/mil_loss 0.30323
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gnwbb7q7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152538-gnwbb7q7/logs
wandb: Agent Starting Run: o1b8s7rc with config:
wandb: 	actor_learning_rate: 8.799098767278328e-05
wandb: 	attention_dropout_p: 0.2694248415377351
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06508248167227637
wandb: 	temperature: 0.06957358642579958
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152701-o1b8s7rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o1b8s7rc
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇██▇▇▄▇█▅▂▇▇█▇▇▇█▇▁█▇▇▇▂▇█▇▇█▇▇█▇▇▇████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁█▁▂▆▁▁▁▁▂▄▁▁▁▁▁▁▁▁▁▄▁▁▁
wandb:       eval/ensemble_f1 █████▇████▇▇▇▇███▇▂█▇▇▇▇██▁▇▇▇▇▇▇██▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆█▄▃▇▆▇▇▇▃▁▇▆▆▂█▇▅▆▆▅▇▆▆▂▃▂▅▆▁▅▃▆▇▃▁▅▇▆
wandb:      train/ensemble_f1 ▆█▄▃▇▆▅▂▇▆▄▃▅▇▆▆▂▇▆▅▄█▅▇▆▂▆█▁▃▅▃▆▇▃█▇▃█▆
wandb:         train/mil_loss ▄▁▆▁▁▁▂▁▁▇▁▃▁▄▂▃▂▁▂▂▂▁▁█▅▅▂▂▃▁▂▁▂▁▂▁▂▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.3165
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.27435
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13909
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.80444
wandb:      train/ensemble_f1 0.80444
wandb:         train/mil_loss 0.24542
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o1b8s7rc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152701-o1b8s7rc/logs
wandb: Agent Starting Run: v1nyah48 with config:
wandb: 	actor_learning_rate: 5.1921495667151874e-06
wandb: 	attention_dropout_p: 0.3185850655588253
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27881366579416444
wandb: 	temperature: 8.746576509052666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152808-v1nyah48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v1nyah48
wandb: uploading history steps 104-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▁▃▅
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▇▆▇▄▆▆▁▅▇▆▅▅▅▁▄▅▆▆▅▁▅▆█▆▆▅▆▄█▅▅▄▄█▄▆▅▆▄▇
wandb:      eval/avg_mil_loss ▇▆▃▆▂▄▅▆█▅▅▅█▇▅▆▅▄▄▅▅▆▅▆▅▆▅▅▄▅▅▃▅▄▅▁▄▆▇▂
wandb:       eval/ensemble_f1 ▇▄▅▅▁▅▅▄▁▅▇▅▅▄▅▄▅▇▂█▄▂▄▄▅▂▂▂█▄█▁▅▄▅▄▅▂▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▁▄▄▆▅▅▇▅▆▆▇▆▆▄▅▄▅▇▆▂█▁▄▄▄▇▅▄▅▄▆▂█▄▇▄▅
wandb:      train/ensemble_f1 ▇▆▃▃▆▅▇▆▇▄▅▂▄▇▄▇▅▇█▅▁▆▅▄▇▄▃▅█▆▆▄▄▅▆▃█▃▄▄
wandb:         train/mil_loss ▅▆▂▆▆▃▄█▆▄▃▄▄▄▅▇▇▃▂▃▃▆▇▅▄▄▄▄▄▅▅█▄▄▃▇█▆▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.28716
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.21576
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.17085
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.88117
wandb:      train/ensemble_f1 0.88117
wandb:         train/mil_loss 0.29239
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v1nyah48
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152808-v1nyah48/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3hyiby4d with config:
wandb: 	actor_learning_rate: 0.0001013083318654338
wandb: 	attention_dropout_p: 0.399729040614712
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8474574687854953
wandb: 	temperature: 7.777207095938957
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152945-3hyiby4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hyiby4d
wandb: uploading history steps 99-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▇▁██
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇█▃▇▇██▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇█▇▇█▇▁▇█▇▃▇▇▇██▇
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▂▂▂▂▁▃▂▂▃▂▂▁▂▂▂▃▂▂▂▁▂▂▂▂▁█▂▁▂▃▂▂▁▂
wandb:       eval/ensemble_f1 ▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▆▆▇▇▄█▇▇▆█▇▇█▆▇▆▇▆▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▆▆▇▆▆▅▃▇▇▆▆███▆█▄▇▇▂▆▇▅▇▃▇▇▄▆▂▇▅▇▅▁▄▆
wandb:      train/ensemble_f1 ▅▅▆█▆▆▇▆█▅▇▇▇▆▃▄▃▇▆▇▁▇▄▄▂▆▄▇█▄▆█▃▆▇█▅▁█▅
wandb:         train/mil_loss █▅▁▂▅▄▃▂▃▃▃▂▇▂▃▃▂▅▃▃▃▃▄▃▂▄▃▃▃▄▁▃▂▂▄▁▃▂▂▄
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.31908
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.33972
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.77965
wandb:      test/avg_mil_loss 0.44879
wandb:       test/ensemble_f1 0.77965
wandb:           train/avg_f1 0.87735
wandb:      train/ensemble_f1 0.87735
wandb:         train/mil_loss 0.26352
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hyiby4d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152945-3hyiby4d/logs
wandb: Agent Starting Run: ivg3idu6 with config:
wandb: 	actor_learning_rate: 0.0008074450716248242
wandb: 	attention_dropout_p: 0.1530676683604253
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9688634046740966
wandb: 	temperature: 3.544942955227519
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153058-ivg3idu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivg3idu6
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 113-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ██▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▆▆▇▅▆▆▆▅▇▆▆▄▆█▆▇▆▇▆▆▆▅▇▃▇▄▇▆▇▄▄▇▁▆▅▄▆▇▆▆
wandb:      eval/avg_mil_loss ▂▂▂▂▂▃▆▂▂▁▅█▁▁▃▁▂▁▃▂▃▂▂▄▁▂▁▁▁▂▃▂▂▃▁▂▂▂▂▇
wandb:       eval/ensemble_f1 ▆▆▄▆▇▄▆▂▆▄▇▁▄▆▆▆▆▆█▅▆▄▆▇▆▆▇▃▁▇▇▇▇▄▆▄▅▆▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▅▂▆▄▄▅▁▆▁▄▄▅▆▇▄▇▄▇▄▅▃▆▄█▅▄▆▃▇▃▆▅▆▆▃▅▅▅
wandb:      train/ensemble_f1 ▇▃▃▆▆▂▃▅▃▅▆▁▇▁▅▄█▅▆▂▃▄▄▄▄▅▄▇▄▂▄▆█▃▆▅▄▄▂▇
wandb:         train/mil_loss ▂▃▅▁▃▄▃▃▂█▄▄▅▄▄▂▄▂▃▂▇▃▅▁▃▅▁▃▁▂▇▂▁▃▁▂▇▅▂▄
wandb:      train/policy_loss ▆▃▇▃▇█▃▇▃▄▄▆▆▄▃██▆▆▆▃▆▆▃▂▃▂▁▃▂▆▄▃▇▆▆▆▆▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.16033
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.71989
wandb:      eval/avg_mil_loss 1.20552
wandb:       eval/ensemble_f1 0.71989
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.33348
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.85975
wandb:      train/ensemble_f1 0.85975
wandb:         train/mil_loss 0.4129
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivg3idu6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153058-ivg3idu6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f4p8p9qu with config:
wandb: 	actor_learning_rate: 1.370867377630131e-06
wandb: 	attention_dropout_p: 0.44346534453473174
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 143
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7707114251830336
wandb: 	temperature: 1.369785693613088
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153237-f4p8p9qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4p8p9qu
wandb: uploading history steps 99-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▇█▇▇▇█▁▇▇▆▇▇▇▇█▇▇▅█▇▇█▁▇▆▇▇▇▇▁▂▇▇▇█▇▇▇
wandb:      eval/avg_mil_loss ▁▂▁▂▂▁█▂▁█▁▂▁▁▁▁▄▁▁▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇█▇▆▇▇▇▇▆▇▇▇▂▇█▇▇▅▇▇▆▇▁▇▆▇▇▇█▇█▇▇▇▆▇▇▇▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▆▂▆▅▄▄▇▆█▂▇▅▇▆▅▆▆▆▇▃▅▇▃▆▃▅▆▇▁▇▆█▄█▇▄▆
wandb:      train/ensemble_f1 ▃▁▄▇▄▆▅▅▅▇█▆▄▆█▆▅▇▄▆▆▄▅█▄▅▄▅▆▆▇▇▆▆▇██▇▇▃
wandb:         train/mil_loss ▄▇▁▄▇▁▁█▂▄▅▅▂▃▂▄▁▇▄▄▃▆▃▁▃▂▇▅▃▇▅▅▃▇▂▄▇▆▄▂
wandb:      train/policy_loss ▃█▃▃▃▃▃▆▃▁▄▄▆▃▃▆▄▁▃▆▃▄▃▃▄▃▃▃▃▆▃▆▄▆▃▃▃▆▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃▃▄▄▃▃▃▆▆▃▃▃▆▄▁▃▄▃▄▃▃▃▆▃▄▃▆▁▄▃▄▆▃▆▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.26847
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.20862
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.2326
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.85124
wandb:      train/ensemble_f1 0.85124
wandb:         train/mil_loss 0.30698
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4p8p9qu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153237-f4p8p9qu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jd1u3vzf with config:
wandb: 	actor_learning_rate: 2.022301627368479e-06
wandb: 	attention_dropout_p: 0.4588459749335027
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8160139705094552
wandb: 	temperature: 3.5061385545716894
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153356-jd1u3vzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jd1u3vzf
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▁▁█▇▁▆▇▁▂▇█▇▅▂▇▇▂▇▇█▅▇▇██▂▃██▄▇▆▇▂▄▇█▇
wandb:      eval/avg_mil_loss ▁▇▁█▁█▁██▄▁▇▁▁▁▁▃▇▁▁▄▃▄▂▁▃▁▁▂▁▁▁▁█▄▁▁▂▁▁
wandb:       eval/ensemble_f1 █▇███▇▂▇█▂▂███▇▅▂▇▇▂▆▅▇▇█▇█▂▇▂█▇▁▂▄▆█▇▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆█▃▇▇▇▇▆▇▃█▅▇▇▇▅▄▅█▅▇▆▇▄▆▇▅▅▅█▆▁▆▄▅█▇▆▁
wandb:      train/ensemble_f1 ▇▅▆▄▃▇▃▇▇▇▆▇▇▇▃▅▅▆█▇▅▂▂▇▅▇▄▆▇▅▆█▅▁▅▇█▄▇▁
wandb:         train/mil_loss ▂▂▃▄▂▅▄▇▂▄█▂▁▂▃▅▂▄▇▂▁▆▃▂▂█▃█▄▂▂▂▁▂▂▂▃▂▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.33018
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.3245
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.32999
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.64844
wandb:      train/ensemble_f1 0.64844
wandb:         train/mil_loss 0.49339
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jd1u3vzf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153356-jd1u3vzf/logs
wandb: Agent Starting Run: qy4vp90w with config:
wandb: 	actor_learning_rate: 1.810886472953826e-05
wandb: 	attention_dropout_p: 0.2617013252184583
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2802536483880472
wandb: 	temperature: 8.036685333599607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153502-qy4vp90w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qy4vp90w
wandb: uploading history steps 79-104
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇█
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆▆▇█
wandb:            eval/avg_f1 ▆▆▇▁▇▇█▇█▇▇▇▇▆▇▆█▆▆▇▇▁▇███▁▇█▁▆██▄▇█▆▆▁▇
wandb:      eval/avg_mil_loss ▂▁▂▁▁▂▂▂▁▁▁▁▁▇▁▇▁▁▁▆▁▂█▁▁▂▁▁▁▁▁▁▆▁▂█▂▁▂▁
wandb:       eval/ensemble_f1 ▆▇█▇██▂█▂▂▁███▇▇▇█▂█▇█▇█▂▂████▆▇█████▂█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▇▆▇▂▄▄▄▁▅▆▄▇▇▄█▄▅▂▄▇▁▃█▂█▇▅▅▅▄▁▅▇▄▁▄█
wandb:      train/ensemble_f1 ▅▆▇▇▅▇▄▇▆▅▃▇▇▁▅▄▇▂▅▂▆▂▄▁▆▁▂▅▅▅▇▂▂▅▇▄▃█▇▂
wandb:         train/mil_loss ▃▅▄▃▃▁▂▆▃▄▃▄▂▅▆▃█▃▃▆▅▃▄▅▂▃▄▂▃▃▃▁▅▁▅▄▁▄▄▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.31121
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.3346
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.80998
wandb:      test/avg_mil_loss 0.43008
wandb:       test/ensemble_f1 0.80998
wandb:           train/avg_f1 0.89936
wandb:      train/ensemble_f1 0.89936
wandb:         train/mil_loss 0.63015
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qy4vp90w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153502-qy4vp90w/logs
wandb: Agent Starting Run: fw0ekoqk with config:
wandb: 	actor_learning_rate: 2.7833747440284944e-06
wandb: 	attention_dropout_p: 0.43176525690703055
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35613808953040016
wandb: 	temperature: 4.011372610388564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153610-fw0ekoqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fw0ekoqk
wandb: uploading history steps 131-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▄▅█
wandb: best/eval_avg_mil_loss █▆▇▃█▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▄▅█
wandb:            eval/avg_f1 ▃▁▆▁█▆▃▆▆▃▃█▃▃▆█▃▆█▆█▃█▆▃▁█▃▃▃▃▆▃██▃▆█▁▆
wandb:      eval/avg_mil_loss ▅▇▅▃▆█▄▇▆▃██▁▇▆▅▃▃█▃█▄▃▄▃▄▄▅▄▇▄▅▁▃▇▆▅▂▅▄
wandb:       eval/ensemble_f1 ▃▆▁█▃▃▆▃█▃▆█▃▃▁▆▆▆▆▃█▃▄▁▃▆██▃██▆▃██▃▆▆▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▆▆▁▆▂▆█▅▄▅█▇▄▇▂▃▅▂▆▄▇▅▆▄▃▃▅▃▅▅▅▄▅▇▃▄▅
wandb:      train/ensemble_f1 ▁▃▇▅▁▆▅▃▃▆▆▇█▅▄█▂▇▃▂▅██▁▅▇▆▆▄▂▅▂▄▃▅▅▄▄▄█
wandb:         train/mil_loss ▂▄▃▆▃▂▃▆▅▄▄▄▄▄█▃▂▅▃▄▂▄▆▅▃▂▂▃▄▄▃▂▂▃▇▆▃▃▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.24598
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.29278
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12897
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.90572
wandb:      train/ensemble_f1 0.90572
wandb:         train/mil_loss 0.1916
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fw0ekoqk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153610-fw0ekoqk/logs
wandb: Agent Starting Run: 67nm0z54 with config:
wandb: 	actor_learning_rate: 8.020810578483325e-06
wandb: 	attention_dropout_p: 0.3688878611040985
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1070966947452483
wandb: 	temperature: 4.711218420653209
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153733-67nm0z54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/67nm0z54
wandb: uploading history steps 151-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▅▇█
wandb: best/eval_avg_mil_loss ██▃▅▆▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▅▇█
wandb:            eval/avg_f1 ██▇████▇█▇█▆██████▇██▆▇█▆█▇▇██▃▇▇▁▇████▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▁▁▁▂█▂▁▁▁█▁▁▁▁▁▁▁▆▂▁▁▁▁▂▁▁▃▁▁▁▆▁▂▁
wandb:       eval/ensemble_f1 ▆▇▇█▇▇██▆█▄▇▇█▇▁▇▇▁▇▇▇██▇▆▇█▇██▇▅█▇█▇█▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇█▇▃▃▁▂▅█▆▇█▆▅▅▅▇▄▆▆█▇▇▂▄▅▇▄▃▆▆█▆▆▆▇▆▃
wandb:      train/ensemble_f1 ▇▅▇▇▅▇▃▅▆▆▅▅▄▅▄▆▅▇▆▅▅▄▄▆█▅▆█▆█▂▂▅▁▄▆▃▅▃▆
wandb:         train/mil_loss ▃▄▂▃▂▂▁▆▂▇▃▄▇▁▅█▆▃▄▅▄▆▄▂▇▁▂▁▅▄▁▄▇▄▆▇▅▂▃▃
wandb:      train/policy_loss ▃▄█▃▁▄▃▃█▄▃▆▃▃▃▃▃▆▆█▄█▆▃▃▆▃▃█▃▆▃▃█▃▆▄▄▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▆▆▁▃▅▅▃▃▆▃▃▅▃▅▅▅▃▆▃▅▃▃▅▃▃▅▅▆▅▃█▃▅▆▅▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.26602
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 1.80034
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.19669
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.82401
wandb:      train/ensemble_f1 0.82401
wandb:         train/mil_loss 0.35168
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/67nm0z54
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153733-67nm0z54/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xafmgi1x with config:
wandb: 	actor_learning_rate: 2.950201728002942e-05
wandb: 	attention_dropout_p: 0.22965171404354195
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2926261926962761
wandb: 	temperature: 7.900194708602033
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153951-xafmgi1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xafmgi1x
wandb: uploading wandb-summary.json; uploading history steps 130-154, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇████
wandb: best/eval_avg_mil_loss █▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇████
wandb:            eval/avg_f1 ▂▃▂▃▂▁▇█▃▂████▃█▂▂▆▆█▂▂██▂█▃▂█▁█▇▂█▄▃█▇█
wandb:      eval/avg_mil_loss ▄▅▅█▁▅▇▇▆▁█▄▁▁▁▁▄▁▇▁▁▆▁▇▇▁▁▁▁▁▅▁▁▁▁▅▁▁▇▁
wandb:       eval/ensemble_f1 ▂▁▂█▃▂█▂▁▂▃▂██▃█▂████▁▁██▂▂████▁▂▂██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▂▄▇▁▄▂▄▄▄▂▅▄▆▆▅▄▃▃▅█▆▆▆█▅▇▂▄▆▇▇▅▄▆▇▃▂
wandb:      train/ensemble_f1 ▄▅▂▄▇█▆▂▅▆▄▄▂▆▅▅▄▁▆▆▅▄▄▃▃▂█▆▇█▄▇▁█▄▇▇█▆▂
wandb:         train/mil_loss ▂▁▄▁▅▂▄▁▅▆▃▅▃▄▂▆▃▄▃▄▃▁▅▄▄▄▃▅█▆▁▄▄▅▅▄█▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████████▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33456
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.31431
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.34034
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.80382
wandb:      train/ensemble_f1 0.80382
wandb:         train/mil_loss 0.74839
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xafmgi1x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153951-xafmgi1x/logs
wandb: Agent Starting Run: r7rb3wsl with config:
wandb: 	actor_learning_rate: 2.9464122828437856e-06
wandb: 	attention_dropout_p: 0.36715849684161195
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6631029610351233
wandb: 	temperature: 5.570717728015351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154124-r7rb3wsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r7rb3wsl
wandb: uploading history steps 129-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss ▆▆█▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 █▁▁██▂▇▆█▅▇▁▆▁▁▁▁▁▇▁▇█▂▃▄▁█▂▇▁▁▂▇▇▂▆▇▂▁▁
wandb:      eval/avg_mil_loss ▅▇▁▁▇▇▇▁▁▄▆▂▁▁▁▆██▇▇▁▆▁▅▁▁▁▁▇█▂▁▇▅▇▅▇▂▂▇
wandb:       eval/ensemble_f1 █▁▁▇█▂▂▂▁▁▆▇▇▁▁▆▁█▁▂▆▂▂▇▁▂▁██▂▇▁█▁▆▂▂▇▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▄▄▇▃▃▄▁▅▇█▃▇▃▆▆▇▃▆▁▄▃█▃▂▃▆▁▅▄▃▇▄▃▄▆▅▄
wandb:      train/ensemble_f1 ▅▂▁▃▇▅▅▂▂▄█▅▄▃▆▆▇▅▅▇▆▇▃▂▆▃▂▂▆▄▁▆▇▅▆▁▅▅█▇
wandb:         train/mil_loss ▇▁▁▆▂▇▅▅▄▁█▅▃▆▅▅▅▅▅▄▅▄▅▇▄█▆▅▄▇▅▅▇▅▃▆▂▇▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.28614
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.84878
wandb:      eval/avg_mil_loss 0.46587
wandb:       eval/ensemble_f1 0.84878
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.2534
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.6825
wandb:      train/ensemble_f1 0.6825
wandb:         train/mil_loss 0.78993
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r7rb3wsl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154124-r7rb3wsl/logs
wandb: Agent Starting Run: cqyrcefz with config:
wandb: 	actor_learning_rate: 1.2500933668868185e-06
wandb: 	attention_dropout_p: 0.4356511931232298
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.611197646892389
wandb: 	temperature: 1.111039170371536
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154253-cqyrcefz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cqyrcefz
wandb: uploading history steps 155-164, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁█▇▃██▁▇▇█▄█▇▂▇▇██▄█▂▅██▇▂█▄███▁▃█▁▇█▇██
wandb:      eval/avg_mil_loss ▁▁▅▁▁▁▁▁▁███▁▆▂▁▁▂▁▁█▁▂▁▁▁▁▁▁▁▁▂█▁▂▅▁▁▁▁
wandb:       eval/ensemble_f1 ███▁█▄▄██▁██▄██▂█▂▇██▁███▁███▇█▇▇██▇██▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▃▄▇▂▅▁▆▆▇█▃▅▁▇▅██▅▄▇▃▂▇▇▇▃▅▁▇▃▃▅▇▇▅▅▅
wandb:      train/ensemble_f1 ▄█▃██▆▇▃▄▂▁▇██▆▆█▇██▇▅▆█▃▄▆▅▆▄▆▇▆▅▃▆▇▆▆▃
wandb:         train/mil_loss ▃▂▂▇▁▃▁▄▂▄▁▁▂▇█▄▁▁▆▃▄▄▄▂▃▁▄▃▃▄▁▂▃▆▄▂▃▄▃▁
wandb:      train/policy_loss ████████████████████▁███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31405
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.30956
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.04597
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.84529
wandb:      train/ensemble_f1 0.84529
wandb:         train/mil_loss 0.58678
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cqyrcefz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154253-cqyrcefz/logs
wandb: Agent Starting Run: 71az8t54 with config:
wandb: 	actor_learning_rate: 2.239887148917692e-05
wandb: 	attention_dropout_p: 0.32473431837231004
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4433854145945252
wandb: 	temperature: 9.047941166420545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154436-71az8t54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71az8t54
wandb: uploading history steps 126-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▇
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▃▂████▁██▁██▂▄██▁█▇█▁█▂▃▂████▆█▂█▁████▂▆
wandb:      eval/avg_mil_loss ▁█▄▁▁▁█▆▁█▇▄▇▇▁▁▁▁▁▁▁▁▁▁▁▁██▂▇▁▁▄▁█▁▅▁▁▁
wandb:       eval/ensemble_f1 ▂▂▁█▄██▂█▁█▅█▂██▅▇██▂▁▇███████▂▂▇█▁███▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▃▇█▄▆▆▅▄▄▇▅▆▇▇▆█▆▆▇▁▃▇▄▆▂▆▆▆▆▇█▇▄▆▇▆██
wandb:      train/ensemble_f1 █▆▅▅▆▂▅▇▄█▅▇▆▅▆▆▆▆▅█▅▆▅▆▁▆▆█▂▆▄▂▆▆█▃▆█▇▇
wandb:         train/mil_loss ▆▄▁▄▂▄▅▁▅▃▄▄▄▂▂█▄▂▃▇▃▅▁▂▄▂▄▂▄▃▄▄▅▁▅▄▂▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.30119
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.31494
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.20313
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.87598
wandb:      train/ensemble_f1 0.87598
wandb:         train/mil_loss 0.91972
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71az8t54
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154436-71az8t54/logs
wandb: Agent Starting Run: ewscup7v with config:
wandb: 	actor_learning_rate: 4.9393886858177375e-06
wandb: 	attention_dropout_p: 0.4651596814196863
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9159250465671658
wandb: 	temperature: 1.310389134616966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154559-ewscup7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewscup7v
wandb: uploading history steps 104-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss ▇█▆▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 █████▄▇███▇▁██▇██████▁██▇███████▇███▇█▇█
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▁▄▂▁▂▂▂▂▁▁▂▁▂▂█▁▂▂▁▃▂▂▁▁▂▁▁▂█▄▁▂▁▂
wandb:       eval/ensemble_f1 ▇▇██▇▇▇▆▇█▇▇▇▇▆█▇▇▇▇▇▇▇▇▇▆▇███▇████▁██▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▂▅█▆▁▄▅▆▇▆▅▅▄▆▇▄▆▂▃▆▆█▆▆█▆▃▃▆█▃▆▇▇▇▂▇
wandb:      train/ensemble_f1 ▆▆▆▆▇▆▆▇▇▂▁▅▇▄▇▆▇▆▆▇▂▄▇▅▇▅▆▆▆▅▅▇▆▃█▇█▇▆▇
wandb:         train/mil_loss ▂▅▅▂▃▄▂▂▁▂▃▂▃▄▂█▁▆▇▅▃▃▂▂▃▆▄▃▂▂▁▂▂▃▂▁▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.18676
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.21121
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.36555
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.88335
wandb:      train/ensemble_f1 0.88335
wandb:         train/mil_loss 0.56156
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewscup7v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154559-ewscup7v/logs
wandb: Agent Starting Run: llyaw059 with config:
wandb: 	actor_learning_rate: 1.6911721886031623e-06
wandb: 	attention_dropout_p: 0.44300980406076046
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8164706448110323
wandb: 	temperature: 0.1432378041332094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154716-llyaw059
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/llyaw059
wandb: uploading history steps 104-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▇▆█▇█▇▇█▇▇▁█▆█▇▇▇▇██▃█▇▇▇▇▇▇▇█▃▇█▇█▄▇▃
wandb:      eval/avg_mil_loss ▂▁▁▁▁▂▁▂▆▂▁▂▁▂▁▂▆▁▄▁▁▁▂▁▂▂▂▁▁▁▂▁▂▂▁▁█▁▁▂
wandb:       eval/ensemble_f1 ▂█▇▇▇▇█▇▇█▇▇█▁▇█▇▇█▇█▃█▃▇▇▇█▇▇▁█▇▃█▄▆▇▇▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▇▆█▃▇▇▂▃▆▇▇▇▅▃▁▅▅▅▇▇▃█▇▃▃▂▄▄▆▄▂▇▇▆▃▇▅
wandb:      train/ensemble_f1 ▄▆▄▅▅▇▇▆▇▄▄▇█▅█▄▃█▇▃▇▇▇▄▄█▄▄▅▃▄▅▁▆▃█▇▃▆▆
wandb:         train/mil_loss ▁▁▅▂▃▆▅▁█▂▂▂▂▂▄▅▃▇▂▅▂█▁▃▂▁▅▂▂▄▂▂▂▁▅▆▄▂▁█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32247
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.66154
wandb:      eval/avg_mil_loss 0.98699
wandb:       eval/ensemble_f1 0.66154
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.19788
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.84862
wandb:      train/ensemble_f1 0.84862
wandb:         train/mil_loss 0.85235
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/llyaw059
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154716-llyaw059/logs
wandb: Agent Starting Run: tit65xjv with config:
wandb: 	actor_learning_rate: 8.198061867055814e-06
wandb: 	attention_dropout_p: 0.2983603669790571
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17136582114385035
wandb: 	temperature: 8.360570388118735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154829-tit65xjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tit65xjv
wandb: uploading history steps 104-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▂▁▂
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ████▅▇▇██▂▁█▅▇▇█▂▃█▇▁▇▅▄█▇▇▅██▇█▆▇███▇██
wandb:      eval/avg_mil_loss ▂▁▁▂▁▃▁▁▁▅▁▂▄▂▂█▅▂▁▆▂▁▁▃▁▄▂▁▁▅▅▁▄▆▂▂▃▁▁▂
wandb:       eval/ensemble_f1 ▇█▅█▁▇▇▇▁▄▅▇█▇▅▆▇▇█▇▄▇▇▇▇▇▇█▇▇▇█▆▇█▇▄▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆█▆▅▅▄▇▅▇▆▅▇▇▅▇▇▆▁▇▇▅▄▇▅▆▆▆▂▁▅█▄▃▆█▆█▇
wandb:      train/ensemble_f1 ▅▇█▆▇▅█▆▇█▆▇█▆▇▇▅▂▆▆▆█▅▇▇▂▅▆▆▁▇▇▇▅▂█▆▇█▇
wandb:         train/mil_loss ▄▄▁▂▅▇▂▇▆▃▂▄▅▁▇█▂▃▂▄▆▂▇▁▂▁▅▄▂▇▅▂▅▂▃▄▁▃▇▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.26875
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.32787
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13525
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.84931
wandb:      train/ensemble_f1 0.84931
wandb:         train/mil_loss 0.23912
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tit65xjv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154829-tit65xjv/logs
wandb: Agent Starting Run: kq9ssn13 with config:
wandb: 	actor_learning_rate: 9.978114575440066e-06
wandb: 	attention_dropout_p: 0.4875352938732223
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 95
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8096765487683253
wandb: 	temperature: 1.4004384336192532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154936-kq9ssn13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kq9ssn13
wandb: uploading history steps 78-96, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▇▄▄▇█▂▂▇▁▂▅▂▂▇▇▂▅▄▇▁▄▂▂▅▅▂▇▇▄▄▂▄▇▅▂▇▄▄▇
wandb:      eval/avg_mil_loss ▄▄▅▄▅▇▄▇▅▆▄▆▅▃▃▄▃▇▄▇▆▄█▇▅▇▅▄▅▄▆▆▆▆▁█▄▄▇▄
wandb:       eval/ensemble_f1 ▂▇▄▄▇▇▂▂▇▂▄▂▁▂▅▂▇█▄▄▁▅▁▇▂▂▄▇▅▄▄▄▄▄▄▂▇▅▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▆▇▅▅▆▆▂▆▁▆▆▅▅██▆▅▆▂▆▇▇▅▄█▆▇▅▆▆▄▅▇▅▆▄▅
wandb:      train/ensemble_f1 ▆▇▆▅▆▆▇▄▆▆▄▅▆▁▇▅▇▅▃█▅▅▇▃▇▆▂▆▆▇▇▅▄▄▆▇▅▇▅▄
wandb:         train/mil_loss ▃▃▄█▇▃▃▂▄▄▄▅▇▇▆▂▅▄▄▆▄▁▃▃▄▄▂▂▁▃▃▃▆▁▅▂▅▂▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.30397
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.30581
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11572
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89374
wandb:      train/ensemble_f1 0.89374
wandb:         train/mil_loss 0.25678
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kq9ssn13
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154936-kq9ssn13/logs
wandb: Agent Starting Run: k5s7h9fp with config:
wandb: 	actor_learning_rate: 1.264391104938722e-05
wandb: 	attention_dropout_p: 0.4505680113187747
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.867237481412014
wandb: 	temperature: 1.978603127976344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155039-k5s7h9fp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k5s7h9fp
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇▇▇█▇███▇▇▆▇█▇▇▇▇▇▇▇▇▇█▁▇▇▇▇▇██▃▇█▇▇▇
wandb:      eval/avg_mil_loss ▂█▁▁▁▁▂▁▁▁▁▁▁▁▆▂▁▁▁▁▂▁▁▁▂▂▁▁▁▂▂▁▂▁▁▂▁▇▂▁
wandb:       eval/ensemble_f1 █▇▇▇▇▇▇█▇▇▇▇▇▇██▇▇▇▂▇█▇▁▇▇▇█▃▇▇▇▇▃▇█▇██▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▁█▆▇▇▆██▅▅▆▆▇▆▆▇██▆▇▄▆▄▃▃▆▆▇█▆▇▅▇▄█▅▇▇
wandb:      train/ensemble_f1 ▇█▇▇▇▃▇█▇█▅█▆▅▆▆▆▇▆▅▇▆▆▆█▅▁▆█▃▆██▅▇█▇▇▇▇
wandb:         train/mil_loss ▂▅▅▆▂▅▄▅▂▁▂▆▂▂▃▂▅▂▁▁▂▅▁▁▂▁▂▂▃▂▆▂█▂▂▂▅▂▆▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.33377
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.29487
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.13896
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.87311
wandb:      train/ensemble_f1 0.87311
wandb:         train/mil_loss 0.31193
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k5s7h9fp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155039-k5s7h9fp/logs
wandb: Agent Starting Run: 3zwvo10c with config:
wandb: 	actor_learning_rate: 7.025030107157043e-06
wandb: 	attention_dropout_p: 0.482799093874122
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8623737819838952
wandb: 	temperature: 2.4227984235279454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155146-3zwvo10c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3zwvo10c
wandb: uploading history steps 148-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇███
wandb: best/eval_avg_mil_loss █▂▁▂▂▂
wandb:  best/eval_ensemble_f1 ▁▆▇███
wandb:            eval/avg_f1 ▇▄▇▇▇▇▃█▇▇▆▇▁▄▁▁▇██▇▂▁▇▃▂█▃▃▇▇██▆█▃▇▇█▇▄
wandb:      eval/avg_mil_loss ▁▅▂▁▁▄▅▁▁▇▅▅▁▁▂▁▂▁▁▅▁▅▃▃▁█▁▁▂▁▁▁▁▄▁▁▅▁▁▄
wandb:       eval/ensemble_f1 ▇▃▆▄▅██▂▆▇▃▁▅▃▃▃██▇▄▅███▇██▃▃▇▇▄▄▆█▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▄▇▆▅▆▅▅▅▅▁▅▂▂▅█▆▄▇▄▃▆▆▆▄▅▅▃▅█▃▅▄▃▅▇▆▆
wandb:      train/ensemble_f1 ▁▄▄▅▃▃▄▃▄▆▆▅▆▆█▅▃▆▁▃▆▄▅▄▇▁▂▃▂▂▇▆▁▂▇▆█▇▃▅
wandb:         train/mil_loss ▂▇▂▆▄▃▂▄▆▂▃▇▅▄▄▄▂▅▅▄▆█▂▁▁▂▄▅▂▃▃▄▂▄▅▅▄▅▄▃
wandb:      train/policy_loss ▁▁▆▃▃▃▁▃▃▃▃▃▆▃▁▁▃▁▃▃▁▁▁▃▁▁▁█▃▁▆█▁▁▆▁▃▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▆▁▆▄▄▃▄▄▃▄▄▄▄▄▃█▃▆▄▃▄▄▃▃▁▆▄▃█▃▃▆▃▃▃▆▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33679
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.69662
wandb:      eval/avg_mil_loss 0.86767
wandb:       eval/ensemble_f1 0.69662
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.18667
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.77732
wandb:      train/ensemble_f1 0.77732
wandb:         train/mil_loss 0.37773
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3zwvo10c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155146-3zwvo10c/logs
wandb: Agent Starting Run: wvtiir1e with config:
wandb: 	actor_learning_rate: 4.142714365297416e-06
wandb: 	attention_dropout_p: 0.4830181686285728
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8466698915554133
wandb: 	temperature: 0.8439070994679221
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155330-wvtiir1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvtiir1e
wandb: uploading history steps 78-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇█▂▇███▆▁▇▁███▁▂▇▇▂▁███▁▁█▇▂▇▇████▂██▅█
wandb:      eval/avg_mil_loss ▁█▁█▁▁▁▂██▇▁▁█▁█▇▁█▁▁▁▇█▂▁▂▁▂▁▁▁▁▁█▂▃▁▁▁
wandb:       eval/ensemble_f1 █▁▇▁██▁█▇▆▇▇█▇▇████▁▆██▇▆▆█▇██▇███▇▆█▇▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▁▂▅█▄█▇▂▅▅▇▇▁▆▁▄▅▂▄█▅▃▇▇██▃█▂▂▅█▄▇▅▇▇▂
wandb:      train/ensemble_f1 ▃▇▇▂▇▇▆▆▅█▅█▅▅█▅▅▃█▅▅██▇▄▃▅▃▆▅▇▆█▃█▅▇▇▇▁
wandb:         train/mil_loss ▁█▅▄▃▂▂▁▁▃▃▁▁▆▃▄▅▃█▁▃▆▁▃▁▁▁▃▂▇▄▂▆▃▂▄▂▁▇▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.31569
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.33619
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.15898
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.6148
wandb:      train/ensemble_f1 0.6148
wandb:         train/mil_loss 0.24245
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvtiir1e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155330-wvtiir1e/logs
wandb: Agent Starting Run: ejlfaga5 with config:
wandb: 	actor_learning_rate: 6.334911947826412e-05
wandb: 	attention_dropout_p: 0.2151420139718767
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04997189986706041
wandb: 	temperature: 0.09729601507419972
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155427-ejlfaga5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ejlfaga5
wandb: uploading history steps 104-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▁█████▇██████▇█▅█▃█▁██▁█▁▃█████▂███▁█▁
wandb:      eval/avg_mil_loss ▁▆▁▁▁▁▂█▁▁▁▁▁▁▁▁▁▁█▂▃▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▆█▇
wandb:       eval/ensemble_f1 ▇█████▇▇▁█▁██▂▇▃█████▁▁██▁█▂█▂▇▇█▂▂██▇▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃█▆▄█▆▆▆▄▆▃▁▅▆▆▃▇▆▆▆█▆▇▇█▆▆█▅▆▅█▆▅█▇▆▄
wandb:      train/ensemble_f1 ▅▅▆▅▇▅█▃▁▅▅█▄▃█▆▅▅█▆▄▄▇▃▅▇▆▅▅▅▆▇▇▇▇▃█▃▃█
wandb:         train/mil_loss ▇▅▇▇▂▇▆▆▇█▃▁▅▄▇█▂▁▁▃▅▃▁▃▃▃▅▄▄█▅▃▆▄▅▃▂▄▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.36076
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.57665
wandb:      eval/avg_mil_loss 1.59902
wandb:       eval/ensemble_f1 0.57665
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12256
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.73034
wandb:      train/ensemble_f1 0.73034
wandb:         train/mil_loss 0.25349
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ejlfaga5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155427-ejlfaga5/logs
wandb: Agent Starting Run: 8to7gvek with config:
wandb: 	actor_learning_rate: 1.3257645499579071e-06
wandb: 	attention_dropout_p: 0.34940892171835614
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 161
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7289509476039735
wandb: 	temperature: 7.03356674275784
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155534-8to7gvek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8to7gvek
wandb: uploading history steps 156-162, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▆█
wandb: best/eval_avg_mil_loss ▆▆█▁
wandb:  best/eval_ensemble_f1 ▁▁▆█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▁█▇▇▄▇▇▆▇▇█▇▁▆▄▄▁▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁█▁▁▁▁▁▄▁▁▁▃▁▁▁▁▃▁▁▆▁▁▁▁▁▁▁▁▁▃▁▁▁▁▄▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▁▆▇▆▇▇▇▇▇█▇█▇▇▃▇▇▇▇▇▃█▇▇▅▄▇▇▇▇▇▇▇▁▇▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▄▆▆▁▅▆▇▆▆▂▅▅▆▇▅▇▇▅▇▆▆█▄▄▇▅▆▇▇▇▇▅▆▅▅▅▇▇
wandb:      train/ensemble_f1 █▅▂▃▆▆▇▅▇▁▇▇▄▄▅▆▅▅▆▅▆▅▆▇▅▅▇▂▆▆▆▇▅▅▄▆▆▆▃▄
wandb:         train/mil_loss ▂▃▄█▇▂▃▁▅▁▃▆▃▆▂▂▆▆▂▂▂▆▆▂▂▅▃▂▆▂▃▅▃▁▇▅▂▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.20006
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.29182
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.1935
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.89625
wandb:      train/ensemble_f1 0.89625
wandb:         train/mil_loss 0.27505
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8to7gvek
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155534-8to7gvek/logs
wandb: Agent Starting Run: jejzn1st with config:
wandb: 	actor_learning_rate: 1.4123006209537308e-05
wandb: 	attention_dropout_p: 0.4187913451217872
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7856540982977551
wandb: 	temperature: 2.598083276374302
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155712-jejzn1st
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jejzn1st
wandb: uploading history steps 104-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss ▇▆█▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▆▆▄▄▅▁▄▇▄█▇▄▄▄▄▆▄▅█▆▄▇▅▇▃▅▄▃▅▄▆▅▅▄▄▃▄▄▅▅
wandb:      eval/avg_mil_loss ▂▃▁▁▂▃▂▂▄▁▃█▃▂▂▃▃▂▃▁▂▃▃▃▁▄▂▁▃▂▃▃▃▂▂▃▂▃▃▂
wandb:       eval/ensemble_f1 ▇▇▆▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▁▇▇▇▆██▇▇▇▇▆▇▆█▇▇▇▇▆▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▆▄▁▆▄█▄▇▃▅▆▇▄▄▇▁▄▄▇▇▃▃▄▂▇▆▃█▃▄▃▃▅▆▁▄▆
wandb:      train/ensemble_f1 ▅▅▆▇▆▇▆▄▆▆▅▂▇▅▅▆▆▆█▇▅▇▅▆▇▄▅▃▄▆▇▁▄▆▃▄▆▆▃▆
wandb:         train/mil_loss ▄▄▂▄▅▄▂▄▃▃▄▃█▂▃▄▃▃▃▃▃▂▄▅▄▃▁▁▅▁▂▁▄▃▄▄▂▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.20748
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.2997
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.81993
wandb:      test/avg_mil_loss 0.42667
wandb:       test/ensemble_f1 0.81993
wandb:           train/avg_f1 0.90223
wandb:      train/ensemble_f1 0.90223
wandb:         train/mil_loss 0.31738
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jejzn1st
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155712-jejzn1st/logs
wandb: Agent Starting Run: 3nojnb7w with config:
wandb: 	actor_learning_rate: 3.073612033435472e-05
wandb: 	attention_dropout_p: 0.1790503314802726
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2578679762898498
wandb: 	temperature: 9.281345376914448
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155819-3nojnb7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nojnb7w
wandb: uploading history steps 104-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▇█
wandb: best/eval_avg_mil_loss ▇█▁▁
wandb:  best/eval_ensemble_f1 ▁▁▇█
wandb:            eval/avg_f1 ▂▁▃▂▁▁▁▁▂▁▁█▃▁▇▁▆▂▂▂▁▂▂▁▅▂▂▂▄▄▂▂▂▄▂▁▂▁▂▁
wandb:      eval/avg_mil_loss ▇▆▅▇█▇▃▇▆▇▇▆▇█▇▇▇▇▇▇▄█▆▇▃▃▃▇▄▇▇▃▇▆▆▇▆▁▇▆
wandb:       eval/ensemble_f1 ▂▁▂▂▂▂▂▁▅▂▂▁▁▂▁▁▂▂▁▂▁▃▂▄▂▂▂▁▁▂▅▂▂▂▂▁▂█▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▄▂▁▅▆▃▅▅▅▁▅█▇▂▅▆▅▂▃▂▅▆▆▅▄▂▄▃▂▅▅▅▂▅▃▆▄▄
wandb:      train/ensemble_f1 ▂▁▂▆▅▅▂▂▂▃▂▂▄▅▃█▂▅▆▅▂▅▄▅▆▇▂▅▄▂▅▂▅▂▃▄▂▅▅▃
wandb:         train/mil_loss ▅▅▄▆▃█▂▆█▄▅▁▂▄▇▆▅▆▅▆▅▄▅▆▅▂▅▅▆▆▅▄▆▆▄▆▆▅▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.23961
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.00108
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.66018
wandb:      test/avg_mil_loss 0.78044
wandb:       test/ensemble_f1 0.66018
wandb:           train/avg_f1 0.58109
wandb:      train/ensemble_f1 0.58109
wandb:         train/mil_loss 1.30139
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nojnb7w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155819-3nojnb7w/logs
wandb: Agent Starting Run: tihfquhz with config:
wandb: 	actor_learning_rate: 3.0681794614635416e-05
wandb: 	attention_dropout_p: 0.15383834452874243
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8673605538387427
wandb: 	temperature: 4.076544440691679
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155932-tihfquhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tihfquhz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▇▇▁██▇█▂▁▇▇▇▁█▁█▇█▁▇▁█▇▇▇▁▂▇▇█▇██▂▂▅▅▇▇▁
wandb:      eval/avg_mil_loss ▁▁▇▂▂▆▇▆▂▂▁█▁▆▁▁▁▁▇▁▁▂█▁▂▁▁▁▂▁▆▇▇▁▁▇▁▁▆▆
wandb:       eval/ensemble_f1 ▇▇▁▇▂▇▇▅▂▆▆▂▆▆▇▂█▇▂▇▇▂▇▇▇▇▇▃▇▇▆▂▂▅▂▂▆▂▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▁▆▄▆▆▅▃▆▆▅▇▆▅▆█▅▇▅▃▁▆▄▅▅▄▂▃▇▆▄▆▇▇▅▄▇▆▂
wandb:      train/ensemble_f1 ▆█▅▄▇▇▄▆▅▄▆▇▅▅▆▆▅▆▇▅▇█▃▆▁▄▄▅▇▄▃▆▆▄▆█▅▄▆▄
wandb:         train/mil_loss ▅▃▁▄▅▂▆▁▅▁▄▆▇▅▅▆▇▅▂▅▁▃▅▂█▅▅▃▆▄▂▄▃▆▅▇▃▃▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94995
wandb: best/eval_avg_mil_loss 0.20759
wandb:  best/eval_ensemble_f1 0.94995
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 1.61346
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 0.83184
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.65934
wandb:      train/ensemble_f1 0.65934
wandb:         train/mil_loss 0.36147
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tihfquhz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155932-tihfquhz/logs
wandb: Agent Starting Run: 00mtslzp with config:
wandb: 	actor_learning_rate: 2.0645827736915447e-05
wandb: 	attention_dropout_p: 0.05873229513116601
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47763911407278425
wandb: 	temperature: 7.931243653406106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160024-00mtslzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00mtslzp
wandb: uploading history steps 50-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▂█▇▇▇██▇▇▇▇▇▇██▇▇▇▇▇▂▇▁████▂▇▁█▁█▇▇▇███▇
wandb:      eval/avg_mil_loss █▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂█▇▇█▇███▇▇█▇███▇▇█▇▁█▇██▂█▁███▁████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▄▅▇▄▃▄▄▇▂▆▆▇▃▃▇▃▆▇▆▂▆▆▂▆▅▄██▄▄▇▄▅▄▇▂▃▄
wandb:      train/ensemble_f1 ▆▅▄▅▇▃▄█▄▇▆▂▆▇▃▃▇▇▁▄▂▆▄▇▂▅▄▆▅▄█▂▄▄▄▅▆▄▇▄
wandb:         train/mil_loss ▅▃▂█▄▂▃█▆▄▂▃▂▂▁▂▂▂▃▁▃▁▁▅▁▁▅▃▄▁▄▁▁▅▂▁▃▃▃▂
wandb:      train/policy_loss ██▅▁▅▅▁▅▁█▅██▁▅▁▁▅▁█▅▅▅▁▅▅▅▅▁▅█▁▁▅▅▁▅▁▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃█▁▁▁▃▃▁▁▁▃▃▆▁▁▁▁▆▃▁▃▃▃▁█▃▆▃▁▃▃▁▆▁▁▁▃▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.27318
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32741
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.19126
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.83724
wandb:      train/ensemble_f1 0.83724
wandb:         train/mil_loss 0.57582
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00mtslzp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160024-00mtslzp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tjtqfli8 with config:
wandb: 	actor_learning_rate: 0.0002471446500010938
wandb: 	attention_dropout_p: 0.22146007839288817
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2191351504429561
wandb: 	temperature: 2.884753042061398
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160129-tjtqfli8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjtqfli8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▂▇▂▇▇▇▇▆▇▂▇▇▇▆██▇▇▂█▃▂▇▇▇▃▇▂▆▇▃▂██▁▃▇▇▇▇
wandb:      eval/avg_mil_loss ▅▂▁▂▁▂▁▁▁▂▂▁▁▁▂▁▁▁▆▂▁▁▂▁█▁▁▁▆▁▁▁▅▁▇▁▁▁▅▁
wandb:       eval/ensemble_f1 ▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆█▇▆▇▇▃▂▇▁▇▇▃▂▇▇▂▆▇▆▇▇▇▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄█▄▆▁▅▇█▄▄▅▆▂▇▄▄▇▄▄▅▇▆█▆█▅▄▆▄▅▇▇▂▆▃▇▆▇█
wandb:      train/ensemble_f1 ▁█▄▄▆▆▄▅▁▅▅▃▇▆▇▂▅█▃▇▄▅▄▇▅▄▅▄█▄▄▇█▆▇█▇▇▇▄
wandb:         train/mil_loss ▆▆▅▆▄▄▅▄▃█▁▃▆▃▆▆▃▂▄▂▃▄▁▁▃▁▃▂▅▃▂▂▄▃▃█▄▁▂▃
wandb:      train/policy_loss ▄▁▄▄▄▆▃▃▄▄█▃▄▄▃▄▄▆▃▃▃▁▄▃▃▃▃▃▃▃▃█▃▄▄▆▄▄▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▆▆▆▃▄▃▃▄▄▃▄█▄▆▃▃▃▁▃▄▃▃▃▃▃▃▃▃▄▄▃▆▃▄▄▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.20408
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32003
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.67159
wandb:      test/avg_mil_loss 1.17652
wandb:       test/ensemble_f1 0.67159
wandb:           train/avg_f1 0.89414
wandb:      train/ensemble_f1 0.89414
wandb:         train/mil_loss 1.00916
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjtqfli8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160129-tjtqfli8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xqdv5xb2 with config:
wandb: 	actor_learning_rate: 6.925660751962673e-05
wandb: 	attention_dropout_p: 0.2604061903967021
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8791834049487293
wandb: 	temperature: 7.820729321196707
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160309-xqdv5xb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xqdv5xb2
wandb: uploading history steps 104-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇███
wandb: best/eval_avg_mil_loss █▆▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▇███
wandb:            eval/avg_f1 ▁▃▇█▇▁▇██▇█▇█▇▇▇▇▇▇▇▇▂▅▁▇▁▇▇▁▇▇▇▇▁██▁▇▂█
wandb:      eval/avg_mil_loss ▆▁▁▁▂▁▇▅▁▂▆▁▁▁▁▁▁▁▁▂▁▁▂▄▂▂▂██▁▁▁█▂▁▇▁█▁▁
wandb:       eval/ensemble_f1 ▁██▃▇▇▇██▇█▇██████▂▇█▇▅▇▇▇█▆▁▇▁█▇█▇██▁▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▅██▆▆▆▆█▇▇▇██▅▇█▂▇▅▇█▃▇▅█▆▁██▅█▃▄▆█▅▆▃
wandb:      train/ensemble_f1 ▇▇▄█▇▅▅▇▅▆▇▇▇▇▇▇▇▅▇▅▇▁▇█▇▅▂▇▂▇█▇▄▅▇▆▇▅▅▂
wandb:         train/mil_loss ▂▅▅▁▇▄▃▆▆▄▄▁▅▂▅▃█▅▁▂▂▁▁▅▃▁▁▆▄▁▂▅▁▅▂▅▅▁▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████▁████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32865
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.32593
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.15695
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.70231
wandb:      train/ensemble_f1 0.70231
wandb:         train/mil_loss 0.77193
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xqdv5xb2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160309-xqdv5xb2/logs
wandb: Agent Starting Run: 2ub0ivch with config:
wandb: 	actor_learning_rate: 4.769788622458349e-06
wandb: 	attention_dropout_p: 0.08447656560799788
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7481252454140428
wandb: 	temperature: 4.56811033057237
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160426-2ub0ivch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ub0ivch
wandb: uploading history steps 98-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▂▇▂█▅▁▃▃▁▁▄▃▁▂▅▂▁█▅▁▂▃█▇▁▂█▂█▃▃▂▃▁▇▂█▁▃▁
wandb:      eval/avg_mil_loss ▁▃▅▁▅▆▇▄▁▅▂▆▆█▆▇▅▆▄▅▇▂▁█▁▂▁▇▇▁▆██▁▄▅█▁▇▄
wandb:       eval/ensemble_f1 ███▃▁█▃▁▂▂▁█▇▅▁▂▃▄▇▁▁▃█▁▂▃▃▁▇▂█▃▅▂▁▁▃▁▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▄▄▁▂▁▃▂▅▂█▃▂▅▂▄▄▂▄▅▄▁▂▅▄▁▄▃▄▆▅▄▇▃▃▂▂▃▆
wandb:      train/ensemble_f1 ▆▄▅▅▃▆▄▄▆▄▄▅▄▆▄▄█▅▃▄▄▃▆▃▇▅▅▃▅▅▁▄▅▅▆▇▅▄▅▄
wandb:         train/mil_loss ▇▆▄▂▅▄▅▆▃▅▅▁▄▄▅▅▆▆▄▆▁▄▄▃▄█▅▇▄▄▃▅▁▃▃▅█▃▅▄
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▄▄▆▄▄▄▆▃▆█▄▄▄▄▃▄▄▄▄▄▄▃▆▄█▃▄▄▄▆▄▆▄▄▁▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.23748
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.95095
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.32183
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.75404
wandb:      train/ensemble_f1 0.75404
wandb:         train/mil_loss 1.13187
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ub0ivch
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160426-2ub0ivch/logs
wandb: Agent Starting Run: e51orsxh with config:
wandb: 	actor_learning_rate: 2.76934334244927e-05
wandb: 	attention_dropout_p: 0.14158522568535398
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29170126072778757
wandb: 	temperature: 7.117047070453487
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160545-e51orsxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e51orsxh
wandb: uploading history steps 104-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄█
wandb: best/eval_avg_mil_loss ▆▅██▁
wandb:  best/eval_ensemble_f1 ▁▃▄▄█
wandb:            eval/avg_f1 ▇▇▇▇▇▇█▃▇█▇▇█▇▇██▇▇▃▇▇█▇▇▁▇▇█▁▃▇▇█▇▇▆▇▇▇
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▁▂▂▁▂▂▁▁▂▂▂▁▂▁█▅▂▁▂▂▂▁
wandb:       eval/ensemble_f1 ▆▇▇▇▆▇▁█▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▇▃▅▇██▆▆▇▆▇▅▇▅█▆▅▄█▂▃▅▆▅▄▆▄█▇▃▆▄▅▇█▇▇▄
wandb:      train/ensemble_f1 ▁▅▇▃▆▇▆█▃▇▆▆▇▆▆█▃▄▆█▅▆▆▄█▇▃▆▅▄▁▆▆▅▇▇▅▁▆▆
wandb:         train/mil_loss ▃▂▃▃▂▅▂▃▂▂▃▂▁▅▃▁▂▃▂▂▂▁▂▂▃▃▁▂▂▄▂▂▅▂▁▂█▂▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.23523
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.32236
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.13527
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.88749
wandb:      train/ensemble_f1 0.88749
wandb:         train/mil_loss 0.29617
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e51orsxh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160545-e51orsxh/logs
wandb: Agent Starting Run: fmlbu6ry with config:
wandb: 	actor_learning_rate: 0.0005314392092855867
wandb: 	attention_dropout_p: 0.3236839059237664
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22584544434901752
wandb: 	temperature: 8.60817143969803
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160702-fmlbu6ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmlbu6ry
wandb: uploading history steps 50-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss █▁▄▅
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▇▇▄▇██▇▇▇████▇▇▇▇▇█▇█▁▇▇▇▇▇█▁▇▇█▄▄▇▇█▇▇▁
wandb:      eval/avg_mil_loss ▁▁▁▄▁▁▁▁▁█▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▇
wandb:       eval/ensemble_f1 ▇▇▇▄▇██▇▇▇▁▁███▇▇▇▃██▁▇█▇▇▇▇█▁▇▇█▄▄▇▇▇▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▅█▆▆██▄▃▂▅▆▂▅▆▇▆▄▅▆▅▃▇▅▄▄▅▃▃▄▆▁▇▇▅▇▄▅
wandb:      train/ensemble_f1 ▅▃▅▅█▆▆██▄▃▂▆▂▄▆▆▄▄▅▅▃▇▆▅▅▄▅▃██▄▆▁▇▅▇▂▄▅
wandb:         train/mil_loss ▂▄▃▄▁▆▆▂▁▄▁▄▄▅▃▇▂▄▂▂▁▁▂▃▂▄▅▃▃▄▅▆█▃█▆▁▇▂▃
wandb:      train/policy_loss ▃▄▃▁▃▃▃██▃▃▁▁▃█▁▄▁▁▆▄▃▃▆▄▃▃▄▃▁▃▆▃▃▆█▄█▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▁▃▅▃█▃▆▃▁▁▃█▁▁▅▆█▅▃▆▅▃▃▅▃▁▁▃▆▃▆▃▆█▅█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.35219
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 1.66933
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12181
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.82112
wandb:      train/ensemble_f1 0.82112
wandb:         train/mil_loss 0.42006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmlbu6ry
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160702-fmlbu6ry/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4ipcvfkp with config:
wandb: 	actor_learning_rate: 1.6300502996349449e-06
wandb: 	attention_dropout_p: 0.06890659076150918
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 115
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07632549100876451
wandb: 	temperature: 9.946724133800451
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160757-4ipcvfkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ipcvfkp
wandb: uploading history steps 99-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▇▇█▂▇▇▇█▁▇███▇▄▇▇▇██▆▂▇▇▇█▁▇▂▇▇▇▇█▇▆▇▇█
wandb:      eval/avg_mil_loss ▁▂▁▁▁▂▂▂▂▁▁▂▁▅▂▂▁▂▂▁▁▁▁▂█▁▁▂▂▁▂▁▂▁▂▂▁▁▂▁
wandb:       eval/ensemble_f1 ▆▆▇███▁███▄▇▇███▂██▇▆▂▇▇▂█▇█▇▇▂▇███▇▇██▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▆█▅▅▅▇▇▅▅█▆▇▇▆▇▅▇▇▆▇▅▆▇▆█▆▅▅▅▅▅▇█▆▇█▁▄
wandb:      train/ensemble_f1 ▄▅▅▆▅▆▃▆▃▆▅▃▇▄▇▆▇▁▆▂▆▃▅▃█▇▆▄▇▇▃▄▃▆▄▆▃▄▅▇
wandb:         train/mil_loss ▃▃▂▂█▅▂▅▃▆▂▃▂▅▃▂▃▃▂▆▃▄▃▃▁▅▂▅▁█▃▂▂▃▃▅▅▄▅▁
wandb:      train/policy_loss █▆▆▆▁▃▆▃▆▃█▃▃▃▃▁▆▃█▆▃▆▃▁▃█▆██▁▁▁▆█▆▆▆▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▆▆▆▃▃▃▃▃▃▃▆▁█▆▃▃█▆▆▃▃█▃█▆▆▁▃▃▆▆▆▃▃█▆▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.33249
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.28409
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.87957
wandb:      test/avg_mil_loss 0.28175
wandb:       test/ensemble_f1 0.87957
wandb:           train/avg_f1 0.73788
wandb:      train/ensemble_f1 0.73788
wandb:         train/mil_loss 0.29189
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ipcvfkp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160757-4ipcvfkp/logs
wandb: Agent Starting Run: osaei4jz with config:
wandb: 	actor_learning_rate: 3.2419363200115343e-06
wandb: 	attention_dropout_p: 0.3846957712179461
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7966496124993689
wandb: 	temperature: 5.558419930370437
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160903-osaei4jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/osaei4jz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss ▄▁█
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 █▇█▇▇▂▃█▁▇▆▇▅██▁▁▇█▃▇▇███▇▇▅█▇█▃▁▃▂▇▇▁▇▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▅▁▁▁▁▁▁▁▁▁▄▁▃█▁▁▁▇▇▆▅▁
wandb:       eval/ensemble_f1 ▇███▇▇▇▃▇█▇▇▇▂▇▇▇█▁▇▇▇▇▇▇▇▇▇▇▇▃▅▁▇▇▇▃▃▂▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅█▇▅▂▅▇█▅▇▅█▆█▆▇▆▅█▂▆█▅▄▆▇█▅▇▅▇▅▇▅▅▆▇▅▄
wandb:      train/ensemble_f1 ▁██▇▇▆▇█▄▅▅▄▃▆█▇▄▂▆▅█▇▅▆█▄▆▅▄▇▇▅█▆█▃▇█▅▅
wandb:         train/mil_loss ▂▅▂▅▃▂▂▃▄▂▃▃▆▂▂▅▄▁▂▂▂▅▆▅▅▄▂▂▂▃█▅▆▅▇▅▅▂▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.32281
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.76566
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11933
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.78749
wandb:      train/ensemble_f1 0.78749
wandb:         train/mil_loss 0.38437
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/osaei4jz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160903-osaei4jz/logs
wandb: Agent Starting Run: o0ize8i7 with config:
wandb: 	actor_learning_rate: 0.0009779964625052076
wandb: 	attention_dropout_p: 0.27745265366323857
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7348556939231571
wandb: 	temperature: 8.039072970176628
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161011-o0ize8i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o0ize8i7
wandb: uploading history steps 99-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▇██
wandb: best/eval_avg_mil_loss ▅█▆█▇▁
wandb:  best/eval_ensemble_f1 ▁▂▂▇██
wandb:            eval/avg_f1 ▇█▃▇▇▇▇▇▁█▇▁▇▇█▁█▁███▂▇▇▇█▂█▂███▂▇█▇▇▂██
wandb:      eval/avg_mil_loss ▂▂▂█▁▁▁▁▁█▁█▁▁▇▂▁▂▁▁▇▂▁▇▇█▁▇▂▁▁▁▁▁▁▁▇▃▂▁
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇█▁▇▇▇█▁▁█▁█▇▇▇█▇▇▅▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▅▅▆▆▅▁▁▄▇▇▃▃▅█▅▄▄▄▄▃▅▇▆▇▅▄▅▇▆▅▄▅▆▆▇█▅▃
wandb:      train/ensemble_f1 ▅▆▇▆▂▅█▇█▄▄▅▆▁▅▅▅▅▄▇▅▄▆▇▆▄▅▅▅▆▆▅▆▆▆▆▇▄▃▅
wandb:         train/mil_loss ▂▄▇▁▁▁▄▁▄▁▄▇▇▄▃▁▂▄▁▁▅▇▃▃▃▅▃▇▃▄▅▅█▃▇▂▃▂▇▆
wandb:      train/policy_loss ▆▃▃▆▆▃▆█▆▃███▆▁▆█▆█▃▃█▃▆▆█▃▁▃▃███▃█▃▃▆█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▆▁▆▃██▇▆▆█▆▆█▁█▆▇▇▃█▃█▆▁▇▇▆██▆█▃████▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.19185
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.31919
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.34427
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.85073
wandb:      train/ensemble_f1 0.85073
wandb:         train/mil_loss 0.94122
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o0ize8i7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161011-o0ize8i7/logs
wandb: Agent Starting Run: 9rx8v7s0 with config:
wandb: 	actor_learning_rate: 1.4740956499916562e-06
wandb: 	attention_dropout_p: 0.2385280238504956
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23448837325853855
wandb: 	temperature: 6.535252593232369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161124-9rx8v7s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9rx8v7s0
wandb: uploading history steps 182-191, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇███
wandb: best/eval_avg_mil_loss █▁▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇▇███
wandb:            eval/avg_f1 ▆██▇█▇▁▁█▇▇███▆█▇▇██▇▇█▇▂▃██▇▇███▇█▇▂▇▂█
wandb:      eval/avg_mil_loss ▁▁▁▂▁▁▁▁▂█▁▁▁▁▂▁▂▁▆▁▁▁▁▁▂▁▂▂▁▁▂▂▁▂█▇▆▁▁▁
wandb:       eval/ensemble_f1 █▇▇▇▇▇▇▇▇▇▁▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▁▇▇▇▆▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▇▇█▃▆▅▇▇▆▅▆▆▅█▃▆▇▇▇▇▅▇▅▄█▁▇▆▅▁▆▇▇▇▆▇▆▄
wandb:      train/ensemble_f1 ▅▅█▂▄▇▃▃█▇▇█▆▆▅▇█▅▆▇▅█▅█▇▆▆█▅█▄▁▇▃▄█▅▅▅▂
wandb:         train/mil_loss ▂▃▂▂▃▂▄▃▅█▂▁▅▄▁▅▃▃▄▅▄▄▅▇▃▃▄▃▂▅▄▁▂▃▆▃▃█▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.19689
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.2507
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.70501
wandb:      test/avg_mil_loss 0.58118
wandb:       test/ensemble_f1 0.70501
wandb:           train/avg_f1 0.8367
wandb:      train/ensemble_f1 0.8367
wandb:         train/mil_loss 0.62295
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9rx8v7s0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161124-9rx8v7s0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: np21s9rz with config:
wandb: 	actor_learning_rate: 0.000450358876976465
wandb: 	attention_dropout_p: 0.01976488114689856
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6797252472887736
wandb: 	temperature: 8.07865544503994
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161329-np21s9rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np21s9rz
wandb: uploading history steps 52-76, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆██
wandb: best/eval_avg_mil_loss █▇▅▁▄
wandb:  best/eval_ensemble_f1 ▁▅▆██
wandb:            eval/avg_f1 ▇▇█▇▇▇█▇█▇▇▁█▇▇█▇▇▇▇██▇▇▇▇▇████▇▇▇▇█▁██▇
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▂▂▂▂▁▂▃▂▁▁▁▂▁▂▂▁▁▂▂▂▁▂▂▂▁▂▂▂█▁▂▁▂▂
wandb:       eval/ensemble_f1 ▇▇▇▇██▇██▇▇▇▇▁▇▇█▇█▇█▇▇▇▇█▇██▇▇█▇▇█▁▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▄▃▃▁▄▆▄▇▅█▆▅▄▅▄▂▆▂▅▃▆▅▆▄▆▅▅▇▅▅▆▆▃▆▅▄▆
wandb:      train/ensemble_f1 ▅▃▅▄▆▃▂▄▆▅▆▇▆▆█▆▅▅▅▅▃▆▆▆▆▄▆▁▆▄▄▂▇▆▆▆▄▅▄▆
wandb:         train/mil_loss ▂▂▅▃▄▃▅▇▆▄▄▇▅▆▄▂▃▇▅▄▄▅▄▇▅▄▅▁▅▂▂██▆▄▂▃▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.24074
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.29998
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.12531
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.89936
wandb:      train/ensemble_f1 0.89936
wandb:         train/mil_loss 0.3816
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np21s9rz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161329-np21s9rz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xyqeggx5 with config:
wandb: 	actor_learning_rate: 1.0068328544533853e-05
wandb: 	attention_dropout_p: 0.39403982328651865
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0661094739444309
wandb: 	temperature: 0.5559176774292596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161427-xyqeggx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xyqeggx5
wandb: uploading history steps 99-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▆▁█
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▇▇▇██▇█▇██▃▇▁▃▇▇▁▁▇▇▇▃▇▇▇██▂█▇█▇▃▃▃█▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▂▁▂▁▁▂▂▂▂▁▆▁▁██▂▁▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▂▁▂▁▂▂
wandb:       eval/ensemble_f1 ▇▇▇█▇▁▇▇█▇▃▇▇▇▁█▃▂▇▇▇▇▇▇███▇█▇██▇▇█▇▃▃▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▇▇▆▅▅▄▁▅▄▅▅▇▅▇▆▄▇▂█▆▆▆▅▅▆▅▇▇▃▂▃▄▆▄▅▅▆
wandb:      train/ensemble_f1 ▅▅▄▅▄▅▅▅▅▄▅▂▅▅▁▆▆▁▆▇▅▂█▆▆▇▅▅▆▇▃▂▆▆▃▇▆▄▅▆
wandb:         train/mil_loss ▅▁▅▅▅▅▄▅▆▄▆▄▆▅▃▂▃▁▃▃█▃▆▃▂▂▃▃▃▂▃▆▆▆▂▁▂▂▃▃
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▃▅▃▆▅█▅▁▆▃▁▅▆▆▆▅▃▃▃▃█▃▆▃▃▃▆▃█▃▅▆▃▃▅▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.34618
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 1.77946
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11414
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.79897
wandb:      train/ensemble_f1 0.79897
wandb:         train/mil_loss 0.5285
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xyqeggx5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161427-xyqeggx5/logs
wandb: Agent Starting Run: 8v3t2cpu with config:
wandb: 	actor_learning_rate: 4.9157922034811395e-06
wandb: 	attention_dropout_p: 0.45012302068677856
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5413937993496243
wandb: 	temperature: 3.10862292113392
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161538-8v3t2cpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8v3t2cpu
wandb: uploading history steps 148-168, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇███
wandb: best/eval_avg_mil_loss █▄▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▇███
wandb:            eval/avg_f1 ▄██▇█▇██▇█▇▇█▁▇███▁▂▇▇▁██▃▃▃▄██▇▁▇███▂▇▇
wandb:      eval/avg_mil_loss ▇▇▁▁▁▄▇▁▅▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁█▆▄▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂█▁█████████▁███████▇███▇▁█▂██▄█▇▇████▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▁▆▄▆▅▄▇▅▇▅▄▁▅█▅▇▇▇▆█▅▅▇▆▇▇█▇▄█▄▃▇▄▇▄▇
wandb:      train/ensemble_f1 ▆▃▆▃▆▆▆▄▃▃▄▇▁█▂▆▄▅▅▆▅█▅▇▃▆▆▃▇▇▄▃▄▇▄▇▅▇▆▇
wandb:         train/mil_loss ▅▁▁▄▇▁▃▂▂▂▃▂▂▄▃▂▂▆█▄▃▇▄█▄▂▂▄▄▁▅▁▅▄▄▃▃▂▄▇
wandb:      train/policy_loss ▁▃▆▁▃▁▃▃▁▃▃▃▃▆▃▃▃▃▁▃▆▁▃▃▁▆▃▃▃▃▁▁▃▁▃▁█▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆▁▁▃▃▃▁▃█▆▃▃▆▁▃▁▃▃▃▃▃█▃▃▃▃▃▃▃▃▁▁▁▆▁▃▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31659
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32388
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.3124
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.79151
wandb:      train/ensemble_f1 0.79151
wandb:         train/mil_loss 0.57499
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8v3t2cpu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161538-8v3t2cpu/logs
wandb: Agent Starting Run: 5qdm8d1z with config:
wandb: 	actor_learning_rate: 1.993171520029302e-06
wandb: 	attention_dropout_p: 0.3125687714763512
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02916448175344577
wandb: 	temperature: 1.521934633347498
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161726-5qdm8d1z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5qdm8d1z
wandb: uploading history steps 99-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▂▇█▇█████▁▂▇█▁█▂▃▂▇▁▂▆▂▇▇█▇▂▇▂▂▃▂█▄▇▃█
wandb:      eval/avg_mil_loss ▆▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▆▁▁▁▆▇▇▆▁▇▁▆▁▅▆▁▅▁▄█
wandb:       eval/ensemble_f1 ▂▂███▁▇▂██▇█▇▂▇▇▂█▇▃▂▇▃▁▃▂▇▆█▇▅█▇▂▃█▄▄▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▄▆▁▅▃▄▆▄▅▅▃▄▇▅▅▆▅▄▇█▄▆█▆▂▆▂▂▆▄▆▄▇▆▄▄▄▆
wandb:      train/ensemble_f1 ▅▆▃▃█▇▄▅▅▆▄▂▃▄▆▄▅▄▃▄▆▄▅▆▄▆▆▇▄▂▇▅▂▅▃▁▄▆▅▆
wandb:         train/mil_loss ▃▄▂▆▄▃▂▂▅▃▃▅▄█▂▅▃▂▄▃▃▂▁▄▂▃▂▅▂▂▄▂▄▃▂▃▄▃▁▄
wandb:      train/policy_loss ▆▆▅▆▆▆▅▅▆▅▅▁▃▆█▁▅▅▅▃▆▅▃▃▅▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▄▄▄█▄██▁▁▄▄█▄▁▁▄▄▄▄▄▄█▄▄▁▁▄▄▄▄▄▄▄▄▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.3348
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.32675
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.1142
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.82022
wandb:      train/ensemble_f1 0.82022
wandb:         train/mil_loss 0.74202
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5qdm8d1z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161726-5qdm8d1z/logs
wandb: Agent Starting Run: rlrvhvwj with config:
wandb: 	actor_learning_rate: 6.085728651444807e-05
wandb: 	attention_dropout_p: 0.06069609367494494
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0773403876999188
wandb: 	temperature: 1.2321791371903723
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161834-rlrvhvwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rlrvhvwj
wandb: uploading history steps 78-104
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▆█
wandb: best/eval_avg_mil_loss ▆▁███▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆▆█
wandb:            eval/avg_f1 ▅▄▄▄▆▄▇▄▅█▆▇█▁▅▄▇▇▇▄▄▆▄▄▇▇▆▇▇▇▆▄▅▇▅▇▃▅▂▆
wandb:      eval/avg_mil_loss ▆█▇▆▇▆▆▇▇▇▇▆▆▅▆▆▅▆▃██▁▆▄▅█▁█▆█▄▄▇█▇▇▄▆▇▄
wandb:       eval/ensemble_f1 ▄▄▆▃▇▄▆▆▆▆▆▁▄▆▆▆▄▆▄▆█▄█▄▆▆▅▇▆▆▅▅▆▆▅▄▆▅██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▇█▇▆▆▇▄▇▆▅▇▆▆▇▄▂▅▅▆▁▅▄▇▃█▆▅▇▆▄▇▆▄▄▄▅▂
wandb:      train/ensemble_f1 ▄██▄▅▅▄▆█▂▆▅▅▅▇▇▄▃▅▁▅▆▄▅▁▆▂▄█▇▅▃▇▆▅▆▁▅▅▅
wandb:         train/mil_loss ▂▂▁▂▂▂▂▂█▁▂▂▂▂▁▂▁▂▁▂▂▂▃▄▂▁▂▂▂▁▂▃▁▂▂▂▂▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.24656
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.3215
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.14195
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.80496
wandb:      train/ensemble_f1 0.80496
wandb:         train/mil_loss 0.36202
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rlrvhvwj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161834-rlrvhvwj/logs
wandb: Agent Starting Run: 0722p8hr with config:
wandb: 	actor_learning_rate: 0.0006383662863256387
wandb: 	attention_dropout_p: 0.42960712406390944
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10292823453696688
wandb: 	temperature: 9.964118546664
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161941-0722p8hr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0722p8hr
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▅▆█
wandb: best/eval_avg_mil_loss ▆▅█▆▇▁
wandb:  best/eval_ensemble_f1 ▁▂▅▅▆█
wandb:            eval/avg_f1 ▇▇▇▇▂██▇█▇██▂▇█▇█▇▄▇▇▄▂█▇▄▃██▇▇█▁█▇▇▇█▇█
wandb:      eval/avg_mil_loss ▂▁▁▁▁█▁▁▂▂▁▁▁▆▁▆▂▁▁▁▂▁▆▁▂▁▂▅▁▁▁▁▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇█▇█▃█▂█▁▇▃███▇▁█▇▄▇▂▇▇█▄▇▇▃▃▃▇▇▇▁███▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇█▇▁█▅▇▄▇█▇▇▇▄▇█▇▄▇▄▇▇▄█▅▆▅▅█▇▄▇▃▇▇▂▆▅▅
wandb:      train/ensemble_f1 ▇▃▆▇█▂▄▂▇▇█▁▇▄▇▆▅▇▅▃█▆▃▄█▇▆▆▇▆▄▆▇▄▇▇▆▆▇▃
wandb:         train/mil_loss ▅▅▂▄▄▂▂▄▁▃▇▅▁▁▅▁▁▄▇▂▂▄▂▁▂▅▁▅▅▅▁█▅▄▅▅█▃▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.18206
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.22671
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.66018
wandb:      test/avg_mil_loss 0.94042
wandb:       test/ensemble_f1 0.66018
wandb:           train/avg_f1 0.79874
wandb:      train/ensemble_f1 0.79874
wandb:         train/mil_loss 0.66349
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0722p8hr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161941-0722p8hr/logs
wandb: Agent Starting Run: ua5lkwx3 with config:
wandb: 	actor_learning_rate: 1.1176843328942955e-06
wandb: 	attention_dropout_p: 0.0032799618938698094
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8805437802524801
wandb: 	temperature: 1.8858311834043464
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162114-ua5lkwx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ua5lkwx3
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇▅▇▇█▇▇▇██▃▄▇██▄▇▇▁▇█▇▇▆▇▃█▇▁▇█▇█▇██▅
wandb:      eval/avg_mil_loss ▁▁▁▅▄▁▁▁▁▁█▁▁▁▁█▆▁▅▄▄▁▅▁▆▁▁▅▁▇▁▁▅▂▁▁▁▁▁▃
wandb:       eval/ensemble_f1 ▁█▄▇█▅▇▇▇▇▇▄█▅█▇▇▇▄▇▅█▁▇▁▆█▃█▃▁▁▇████▁▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▇▅▆▅▃▇▇▄▇▆█▇▄▅▆▂▅▅▅▄▅▇▇▅▅▇▄▇▇▄▄▁▆▇█▇▆▇
wandb:      train/ensemble_f1 ▇▃▅█▁▄▇▇▅▆▃▆▇▅▅▇▃▄▆▅▇▇▆▆▆▆▇▅▄▇▆▂▅▇█▇▇▆▃▆
wandb:         train/mil_loss █▂▇▃▃▁▆▄▅▂▄▂▅▂▂▂█▂▂▄▃▂▅▄▃▃▆▄▃▅▆▄▄▄▃▁▁▁▃▇
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.26942
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.32655
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.15609
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.85959
wandb:      train/ensemble_f1 0.85959
wandb:         train/mil_loss 0.35847
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ua5lkwx3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162114-ua5lkwx3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gdi6csde with config:
wandb: 	actor_learning_rate: 0.00010038999260963156
wandb: 	attention_dropout_p: 0.23691156974220595
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9392108970244226
wandb: 	temperature: 9.407486008463618
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162227-gdi6csde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdi6csde
wandb: uploading history steps 90-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 █▇▇▇▅▇▄▆▇▆▇▄▅▇▆▃▇▃▇█▂▇▇▇▇▄▇▆█▇▁▇▁▇▆▇▇▃▃▅
wandb:      eval/avg_mil_loss ▁▂▃▁▁▂█▁▂▂▁▂▄▁▂▃▅▁▁▁▁▁▁▁▁▁▃▂▁▁▅▁▁▂▂▁▁▄▁▁
wandb:       eval/ensemble_f1 ▅▇▅▇▇▇█▇▄▇▆▇▅▄▅▇▆▅▇▇█▄▄█▇█▇▇▁▇█▆█▇█▇█▇▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▃▂▅▁▆▅▂▄▇▅▆▅▅▄▄▂▅▄▃█▄▅▇▆▃▇▁▃▄▅▂▇▆▄▅▄▃
wandb:      train/ensemble_f1 ▃▅▂█▆▁▆▂▄▃▇▅▅▂▅▅▆▆▃▄▄▄▄▆▅▇▁▅▄▅▇█▆▅▆▅▄▁▄▃
wandb:         train/mil_loss ▃▃▃▃▅▁▃▂▆▇▃▂▂▄▆▅█▇▃▃▂▄▇▂▅▂▃█▄▂▅▃▄▃█▂▄▅▄▄
wandb:      train/policy_loss ▃▄▇▃▆▆▃▆▃▆▁▆▇▂▄▇▇▆▄▆▃▄▃▇▄▃▂▆▃▂▆▃▂▇█▆▃▆▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▁▄▆▁▄▃▄▃▃▆▃█▃▆▃▃█▆▃▃▁▄█▃▁▁▆██▁▆▃▆▄▆▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93978
wandb: best/eval_avg_mil_loss 0.18245
wandb:  best/eval_ensemble_f1 0.93978
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.20955
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.78998
wandb:      test/avg_mil_loss 1.42962
wandb:       test/ensemble_f1 0.78998
wandb:           train/avg_f1 0.81824
wandb:      train/ensemble_f1 0.81824
wandb:         train/mil_loss 0.48332
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdi6csde
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162227-gdi6csde/logs
wandb: Agent Starting Run: 2tkwt3y0 with config:
wandb: 	actor_learning_rate: 5.035925517748773e-05
wandb: 	attention_dropout_p: 0.33504553907874157
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13831541363679511
wandb: 	temperature: 8.519646047224954
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162344-2tkwt3y0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2tkwt3y0
wandb: uploading history steps 125-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▄▁▆
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▇███▅▂▁▇▁▁▇▇▃▇▇▆█▇▇██▇▁█▇▇▁██▁▇███▂▇▇█▃█
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▄▇▁▇▁▃▁▃▁▁▂▁▁▁▇▁▇▁▁▁▁▁▁▁▂█▅▁▁▆▁▁▂▁
wandb:       eval/ensemble_f1 ▇████▁▁▁▁▇██▇▇▇▁▇▇▇██▁▇▁███▇▁▁█▂██▇▃██▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▅▅▅▆▄▇▃▇▆▄▇▄▅▆▅▇▅▁▄▇▂▅█▅█▅▅▄▇▇▇▄▄▁▇▅▄
wandb:      train/ensemble_f1 ▆▆▆▆▄▅▃▆▇▆▄▄▁▃▅▅▄▄█▃█▅▆▆▆▄▃▃▄▇▅▄▄▆▆▆▇▅▅▆
wandb:         train/mil_loss ▁▂▄▄█▂▁▃▄▇▂▄▄▅▂▅▄▁▃▄▃▄▄▄▃▃▁▅▃▃▆▅▄▅▁▅▁▃▅▃
wandb:      train/policy_loss █▆▆█▆█▆▆▆██▆▃▆▆▆▆█▃▃▆▃▃▆█▃█▆▁▆▃▆▁▆█▃▆▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▃█▆▆▆█▆▆▃▆▆██▆▃▁▆▆▆▆██▃█▆█▆▃▆▃▃▆█▁▆█▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.34038
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.32819
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.30907
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.77452
wandb:      train/ensemble_f1 0.77452
wandb:         train/mil_loss 0.61888
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2tkwt3y0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162344-2tkwt3y0/logs
wandb: Agent Starting Run: x8n4r4qv with config:
wandb: 	actor_learning_rate: 0.00011842471546541133
wandb: 	attention_dropout_p: 0.31267047502099043
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6699563530030153
wandb: 	temperature: 1.8136396039260736
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162521-x8n4r4qv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x8n4r4qv
wandb: uploading history steps 53-69, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅█
wandb: best/eval_avg_mil_loss ██▃▅▁
wandb:  best/eval_ensemble_f1 ▁▄▅▅█
wandb:            eval/avg_f1 ▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▆▇▇▇▇▇▇▇▇▇▇█▇▇▇
wandb:      eval/avg_mil_loss ▂▂▁█▁▁▂▂▁▁▁▁▂▁▂▂▂▁▂▂▂▁▄▆▁▂▂▂▇▁▂▁▁▂▁▂▁▂▂▁
wandb:       eval/ensemble_f1 ▇▂▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇▄▂▇▇▁▇▇▇█▇▇▇▇█▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▇█▆██▆▇▇▅█▅▃█▇▆▇▇▅▇▇▆▇▅▇▁▇▆▆▆▇█▄▇▇▅▁▅▇
wandb:      train/ensemble_f1 ▇▆█▇██▄▆█▆▇▇█▆▅▇▇▇▇██▆▇▆▇▇▁▇▆▇█▅█▇▅▁▅▇▅▇
wandb:         train/mil_loss ▂▂▁▄▂▂▁▂▅▂▆▁▂▂▁▂▁▁▁▃▁▅▂▄▂▆▁▁▅▂▄▂█▁▂▄▂▁▇▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9399
wandb: best/eval_avg_mil_loss 0.17065
wandb:  best/eval_ensemble_f1 0.9399
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.29479
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.1114
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88484
wandb:      train/ensemble_f1 0.88484
wandb:         train/mil_loss 0.52864
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x8n4r4qv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162521-x8n4r4qv/logs
wandb: Agent Starting Run: 7qaxtw0e with config:
wandb: 	actor_learning_rate: 0.0002499340857535687
wandb: 	attention_dropout_p: 0.07387530025842226
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00206753983493535
wandb: 	temperature: 4.933659832961435
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162608-7qaxtw0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qaxtw0e
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▁▇▆██▇█▄█▇▇▁▄▇▇▁██▇█▇▆▄▅▇▁▆▃▄▃█▂▇▂█▁▇▇▁
wandb:      eval/avg_mil_loss ▇▂▄▁▄▁▁▁▁▁█▃▁█▁▁▇▁▁▁▅▄▃▃▄▁▁▁▁█▁▃▁▆▁▅▅▁▁█
wandb:       eval/ensemble_f1 ▃█▃▄▇▇▄████▇▁▁▄▃▇▇███▃▃█▆▇█▅▇▃▁▅▃▃▁▁▂▇▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▅███▇▁▅▇▅▇▅▆▆█▆▇▆▅▇█▇▆▅▆▅█▄█▃█▅▆▆▃▇▃▆▆
wandb:      train/ensemble_f1 █▅█▃▅█▆▃▅▇▆█▄▇▄▁▆▅▆▅█▄█▇▅▅█▅▃▅▆▅▇▇█▄█▂▃▃
wandb:         train/mil_loss ▅▅▂▃█▁▃▅▇▁▃▁▅▆▄▇▅▅▄▅▃▂▅▄▅▄▄▂▂▁▁▂▃▃▆▃▄▆▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.24854
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.86684
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.58822
wandb:      test/avg_mil_loss 1.51915
wandb:       test/ensemble_f1 0.58822
wandb:           train/avg_f1 0.75052
wandb:      train/ensemble_f1 0.75052
wandb:         train/mil_loss 0.45108
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qaxtw0e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162608-7qaxtw0e/logs
wandb: Agent Starting Run: dxyre5c1 with config:
wandb: 	actor_learning_rate: 8.926594905623106e-06
wandb: 	attention_dropout_p: 0.3289176738637824
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49496180381891675
wandb: 	temperature: 2.852081389402291
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162715-dxyre5c1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxyre5c1
wandb: uploading history steps 100-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ███▅▇▁▆█▇▃██▇▂█▂▅█▇▇▇▇▂█▂▇██▇█▂▇█▆█▇▇█▅█
wandb:      eval/avg_mil_loss ▁▁▂▄▄▁█▃▁▃▂▁▁▂▁▁▂▁█▂▁▁▁▅▁▅▁▁▁▃▇▆▁▁▂▂▁▃▁▁
wandb:       eval/ensemble_f1 ▂▁▇█▅▄▇▁▆▇▇▃███▇▇██▂█▇█▇▄▇▂▇█▃█▂███▇▇██▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▂▄█▆▃▆▄█▇▆▃▆▆▃▆▅▅▅▆▄▄▅▆▁▅▇▃▆█▆▅▂█▇▁█▅▄
wandb:      train/ensemble_f1 ▇▅█▂▆▄▆▆▃▇▆▃▆▂▂▅▆▅▄▅▄▆▄▅▆▄▃▇▆▅█▁▇▆▆▇▆▅▇▃
wandb:         train/mil_loss ▂▄▃▃▅▄▁▆▁▃▂▃▄▂▁▃▅▃▆▅▂█▂▄▁▃▅▂▁▄▃▃▅▃▁▅▄▄▄▆
wandb:      train/policy_loss █████████████████████████▁██████▄███████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.3389
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.83838
wandb:      eval/avg_mil_loss 0.36875
wandb:       eval/ensemble_f1 0.83838
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.19356
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.90078
wandb:      train/ensemble_f1 0.90078
wandb:         train/mil_loss 0.89165
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxyre5c1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162715-dxyre5c1/logs
wandb: Agent Starting Run: xza6w8o5 with config:
wandb: 	actor_learning_rate: 2.5608970234224926e-06
wandb: 	attention_dropout_p: 0.08188542979928604
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34161517717968015
wandb: 	temperature: 2.635123356626119
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162822-xza6w8o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xza6w8o5
wandb: uploading history steps 131-149, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss ▂█▁▆
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▇▇▇▁▇▇▇██▇▇▇▇▇▇█▂█▇▇▇▇▁▇▇▂▇▇█▇▇▇▂▇▇█▇█▇▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁█▆▁▁▁▁▁▁▁▆▁▁
wandb:       eval/ensemble_f1 █▇█▇▇▇▇▇▅▅▇█▇▇▇▇█▇▇▇▇▇▇▇▂██▇▇▁▇█▇▂▇▇██▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▇█▇▇▅▆▅▁▅▇▇█▄▇▁▇▄▇▆▅▄▅▆▅▅▇▅▇▄██▃▇█▇▆▇
wandb:      train/ensemble_f1 ██▁▇▅█▅▆▇▅▇▇█▅▇▇▄▄▅▅▆▇▆▇▇▇█▆▅█▄▇▄█▄▇▅▇█▅
wandb:         train/mil_loss ▁▂▄▂▄▁▆▂▅▂▄▁▅▂▅▁▂▅▅▁▂▂█▅▁▁▄▂▄▄▁▅▅▁▇▁▄▁▇▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.33983
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.35108
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.17413
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.87616
wandb:      train/ensemble_f1 0.87616
wandb:         train/mil_loss 0.96042
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xza6w8o5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162822-xza6w8o5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: eqic60x8 with config:
wandb: 	actor_learning_rate: 3.228428941249574e-06
wandb: 	attention_dropout_p: 0.1443670995259299
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7503646539993217
wandb: 	temperature: 1.1046135654984757
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163010-eqic60x8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/iqekye1m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eqic60x8
wandb: uploading history steps 105-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄█
wandb: best/eval_avg_mil_loss █▇▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄█
wandb:            eval/avg_f1 ▇▇▆▇█▇▇▇▃▆▁▆▇▅▅▇▇▇▅█▇▇▃▆▅▇▆▇▆▆▇▇▇▁▆▇▇▇▇▇
wandb:      eval/avg_mil_loss ▂▂▂█▁▃▂▂▅▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▅▂▂▂▂▃▂▂▂▄▂▂▂
wandb:       eval/ensemble_f1 ▇▇▇▃█▄█▇▇█▁▇▇▇▇█▇▇▇▇▇█▇▇█▆▇▇▆▇▇▇▃▇▇▇▂▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▆▅▇▃▅█▇█▇▃▃▇▆█▅▅█▆▁▇▆▆▅▆▁▇▃▇▄▆▇▄█▃▆▅▆
wandb:      train/ensemble_f1 ▂▂▅█▅▆▄▃█▇▄█▅▆▁▇█▄▇█▆▄▆▆▆▅▅▆▇▆▅▂▂▃▁▄▇▁▇▆
wandb:         train/mil_loss ▄▂▄▂▂▂▃▃▃▆▄▂█▁█▃▂▇▂▄▆█▂▂▇▂▂▄▃▄▇▃▂▂▇▅▂▅▂█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.20029
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.32933
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.12192
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.85265
wandb:      train/ensemble_f1 0.85265
wandb:         train/mil_loss 0.35375
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eqic60x8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163010-eqic60x8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 1aq9f83p with config:
wandb: 	actor_learning_rate: 1.452107532968459e-06
wandb: 	attention_dropout_p: 0.12166801435425025
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9953323255128328
wandb: 	temperature: 4.444237255626289
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163138-1aq9f83p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1aq9f83p
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 49-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▆
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▇▅█▂▇▅█▇▇▇▃▂▇▁█▃█▇▄██▇██▁▇▃▇█▆▇▇▇▃█▇▆███
wandb:      eval/avg_mil_loss ▂▃▆▆▂▃▆▂▃▁▂▂▅▂█▆▃▁▇▁▁▁▁▁▆▁▁▁▁▂▂▁▁▇▁▂▁▁▆▁
wandb:       eval/ensemble_f1 ▇▅▃██▇█▅▃▅▇▇▃▇▇█▄█▇█▁█▇▇█▇█▆█▇▃███▆▇██▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▇▄▁▇▃▄▇▅▃▅▅▅▄▇▄█▂▄▅█▇▅▅▅▇▄▇▅▇▃▂▅▁▇▇█▆▄
wandb:      train/ensemble_f1 ▃▆▅▄▇▃▄▇▇▆▅▅▄▄█▇▂▄▆▅▆▅▅▅▅▇▄▅▇▇▁█▅▁▅▇█▆▅▄
wandb:         train/mil_loss ▆█▃▅▆▆▅▂▄▂█▂▁▄▃▅▄▃▁▅▄▂▁▄▅▃▃▂▃▆▃▄▃▄▆▃▄▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30612
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.21883
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.15662
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.77226
wandb:      train/ensemble_f1 0.77226
wandb:         train/mil_loss 0.30336
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1aq9f83p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163138-1aq9f83p/logs
wandb: Agent Starting Run: d5kufd01 with config:
wandb: 	actor_learning_rate: 7.041315891632013e-06
wandb: 	attention_dropout_p: 0.4507060787030198
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7704933128740717
wandb: 	temperature: 5.925964489405412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163225-d5kufd01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d5kufd01
wandb: uploading history steps 102-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂██▂▄█▃▇▂▃▆█▇▂▁▁▂▃▅▂▃▁▃▃█▆██▇▁▇█▃█▃█▃█▃▇
wandb:      eval/avg_mil_loss ▁▆▁▅▁▄▅█▅▅▆▁▂▁▇▇▅▅▆▅▆▅▁▆▁▁▁▁▁█▆▅▇▁▅▅▇▇▁█
wandb:       eval/ensemble_f1 ▂█▂█▂█▃▇█▄▇▃▂▆█▇██▁▁▃▃▁▃█▄█▇█▇▃▅█▃▂▇██▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▇▂▄█▄▅▂▇▄▃▃▅▅▃▄▅█▅▇▅▅▄▇▄█▂▄▃▅▄▅▁▃▅█▂▂▃
wandb:      train/ensemble_f1 ▅▅▇▇█▄▃▅▆▁▇▄▄▄▅▇█▆█▃▆▄▅▄▅▃▄▇▇█▆▆█▅▅▃▄▆▃▃
wandb:         train/mil_loss ▇▄█▃▃▁▃▂▁▃▄▅▃▃▂▅▅▂▆▃▄▄▄▃▅▅▃▁▅▅▅▆▅▃▆▃▄▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.30647
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.81971
wandb:      eval/avg_mil_loss 0.42889
wandb:       eval/ensemble_f1 0.81971
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.09951
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.71297
wandb:      train/ensemble_f1 0.71297
wandb:         train/mil_loss 0.8107
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d5kufd01
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163225-d5kufd01/logs
wandb: Agent Starting Run: 3j1e3oio with config:
wandb: 	actor_learning_rate: 4.278252663441337e-06
wandb: 	attention_dropout_p: 0.24508959294654564
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2653872962352215
wandb: 	temperature: 3.400167726041249
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163332-3j1e3oio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3j1e3oio
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ▅▂▅█▄▄▄▁██▂▄▇▄▁▅▇▅▅▅▅▇▁█▅▄▁▅▄▁▅█▅▂▅▂█▁▅█
wandb:      eval/avg_mil_loss ▄▁▃▄▄█▁▁▅▅▁▃▅▃▄▄▅▅▁█▂▁▅▄█▅█▄▆▄▅▅▄▅▄▁▅▅▆▁
wandb:       eval/ensemble_f1 ▆▂█▄▁▅▁▇▁▂▄▃▇█▁▇▂▆▅▄▅█▁▂█▁▅▄▁▅▂▂▅▂▁▁▅▅▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▄▅▅▆▅▄▄▃▁▆▄▃▅▄▅▅▇▇▆▇▆▄▂▇▃█▄▅▂▅▄▇█▃▆▂▅
wandb:      train/ensemble_f1 ▄▅▄▁▆▄▆▅▇▄▃▁▅▃▄▆▅▄▅▇█▆▇▄▄▄▅█▄▄▅▂▄▄▂█▃▆▂▇
wandb:         train/mil_loss ▅▁▅▄▇▆▂▆▅▂▇▅▃▃▅▄▆▅▅▂▃▇▄▇▃▃▆▃▂▃▄▂▆▆▆▅█▆▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.25982
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.91987
wandb:      eval/avg_mil_loss 0.29485
wandb:       eval/ensemble_f1 0.91987
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.18841
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.75271
wandb:      train/ensemble_f1 0.75271
wandb:         train/mil_loss 1.55195
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3j1e3oio
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163332-3j1e3oio/logs
wandb: Agent Starting Run: il0c03si with config:
wandb: 	actor_learning_rate: 0.0008026728383407571
wandb: 	attention_dropout_p: 0.05078519728282449
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9896595907706563
wandb: 	temperature: 8.482228673739854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163424-il0c03si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/il0c03si
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇█
wandb: best/eval_avg_mil_loss █▅▅▁▆▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇█
wandb:            eval/avg_f1 ▇▁▇▁▇▇▇▇▇▇▂▇▇▇▇▇▃█▇█▆█▇▇█▇▇▇█▇▇▇▇██▇▇█▇▆
wandb:      eval/avg_mil_loss ▂▁▇▂▂▁▁▂▂▁▁▂▂▁▁▁█▂▂▁▁▁▁▁▂▁▁▁▂▂▁▂▁▂▁▁▁▂▁▂
wandb:       eval/ensemble_f1 ▆▇▆▆█▆▇▇▆▇▆▆▆▆▇▆▇▇▆▇▇▁▇▇▇▁▇▇▇▆▇▇█▇▁▇▆▇▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▅▁▇▆▄▄▆▄▇▄▆▇▂▃▆▂▆▅▇▇█▇▇█▂▇▇▆▄▂▅▆▆█▇▅█
wandb:      train/ensemble_f1 ▇▆█▆▆▆▆▇▇▇▅▇▇▄▇▁▇▆█▇▇▅█▅▇▆█▇▅█▆▄█▆▇█▇▆▇▅
wandb:         train/mil_loss ▇▃▅▁▂▂▃▂▄▃▃▃▃▆▆▃▃█▄▄▂▃█▅▁▄▂▂▂▄▂▂▃▃▃▆▅▁▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆█▃▃▁█▃▃▁▆▃▁▆▃▅▆█▆▆▅▃▁▁▃▆▅▃▃▃▃▅▁▃▃▃▃▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.19754
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.42808
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11641
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.79919
wandb:      train/ensemble_f1 0.79919
wandb:         train/mil_loss 0.27354
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/il0c03si
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163424-il0c03si/logs
wandb: Agent Starting Run: i54yd8aj with config:
wandb: 	actor_learning_rate: 9.731874144523864e-05
wandb: 	attention_dropout_p: 0.20043169182851123
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4682568616366184
wandb: 	temperature: 3.799523677268546
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163536-i54yd8aj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i54yd8aj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇▇████
wandb: best/eval_avg_mil_loss █▂▂▁▂▁▁▂▁
wandb:  best/eval_ensemble_f1 ▁▆▆▇▇████
wandb:            eval/avg_f1 ▇▃▇▅▅▅▄▇▄▁█▁▄▅▇▅▅▅▅▅▇▄▂▂█▇▇▅▅▅▆▄█▅█▁▅█▁▇
wandb:      eval/avg_mil_loss ▂▁▁█▄▁▅▁▆▅▆▆▅▄▁▂▂▁▅▂▂▁▅▂▁▁▃▂▂▂▁▃▁▃▁▃▁▁▅▁
wandb:       eval/ensemble_f1 ▄▅▁▅▄█▄▇▁▅▅▄▅▅▄▅▆▄▄▇▇▇█▇▅▅▅▇█▆█▇▅▇▄█▅▇▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▄▅▄▁▃▇▇▂▂▄▃▆▆▃▆▇▇▆▅▄▄▅▆▅▅▄▆▄▇▆▇█▆▇▅▆▄▇
wandb:      train/ensemble_f1 ▃█▂▅▄▄▄▆▇▄▅▄▅▆▁▃▄▇▅▇▅▄▃▅▃▆▆▆▄█▇▄▃▁▅█▄▆▂▇
wandb:         train/mil_loss ▅▄▅█▅▃█▃▇▅▇▄▅▅▃▄▆▅▆▂▅▅▅▅█▆▄▆▅▆▄▄▄▅▅▅▅▂▁▆
wandb:      train/policy_loss ▃▆▆█▆▄█▄█▆▆█▃▄▆▆▃▆▃▁▄█▄▆▃██▄▁▆▆▄▆▆▄▄▁▆▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▇▄▇▇█▅▂▅▄▅▄▄▇▇▇▄▇▂▄▂▄▅▅▄▇█▁▇▂▇▇▇▅▂▇▂▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.24784
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.33954
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.73737
wandb:      test/avg_mil_loss 0.72082
wandb:       test/ensemble_f1 0.73737
wandb:           train/avg_f1 0.80988
wandb:      train/ensemble_f1 0.80988
wandb:         train/mil_loss 0.87024
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i54yd8aj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163536-i54yd8aj/logs
wandb: Agent Starting Run: x9at1h11 with config:
wandb: 	actor_learning_rate: 3.397795790342486e-06
wandb: 	attention_dropout_p: 0.24484143742979836
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0840480531270903
wandb: 	temperature: 4.195396328072355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163659-x9at1h11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x9at1h11
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▃▃█▅▅▇▇▆▅▅▆▅▅▇▂▁▆▁▅▄▂▂▅▅▂▅▆▄▅▅▂▃▄▁▇▅▁▆▁
wandb:      eval/avg_mil_loss ▇▄▅▁▅▁▃▁▂▄▃▃▃▄▂▇█▂▆▄▆▃▃▄▂▅▃▆▆▄▇▁▅▇▂▁▃▇▂▇
wandb:       eval/ensemble_f1 ▁▅▃▃█▅▇▇▆▅▅▆▅▅▇▁▁▆▁▅▂▂▅▅▅▂▅▆▄▅▅▂▃█▄▆▇▅▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▆▄▃▅█▃▅▆▄▅▃▃▁▃▇▄▇▅▅▅▆▅█▅▃▅▇▄▅▇▇▅▆▆▄▅▇
wandb:      train/ensemble_f1 ▄▅▄▅▃▂█▂▇▄█▆▃▄▂▅▃▂▇▇▇▃▄▅▆▄█▄▁▆▃▄▆▆▄▅▃▄▂▅
wandb:         train/mil_loss ▅█▄▃▄▅▅▅▅▄▃▇▅▄▆▃▂▇▆▇▆▆▃▇▄▇▃▅▁▄▄▃█▆▄▄▅▃▄▄
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▁▇▇▇▇█▇▇▇▇▇▇▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▇▁▇▇▇▇▇█▇▇▇▇▇▇▇▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.21421
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.8223
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.05154
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.74807
wandb:      train/ensemble_f1 0.74807
wandb:         train/mil_loss 0.98444
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x9at1h11
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163659-x9at1h11/logs
wandb: Agent Starting Run: b7koawna with config:
wandb: 	actor_learning_rate: 2.887600784899009e-06
wandb: 	attention_dropout_p: 0.016741044520601434
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.453937442950054
wandb: 	temperature: 0.8631996671363584
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163740-b7koawna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b7koawna
wandb: uploading history steps 100-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss █▁▇█
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 █▇▅▇▇▇▇▇▅▇█▁▇▁▁██▅▇▇█▇▁▇▇█▇█▇▄██▇██▇█▂█▅
wandb:      eval/avg_mil_loss ▁▁▁▁▃▁▁▁█▅▁▂▇▁▂▂▁▂▁▁▁▃▁▅▂▁▁▅▁▁▁▁▁▁▁▁▁▇▅▄
wandb:       eval/ensemble_f1 ▆▇▇▇█▇▇▇▇█▁▇▁▅▇▇▇▅▁█▅▇▇▁▇▇█▁▇▁█▇▇█▇██▇█▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▅▅▅█▅▅▇▃▇█▄▁▆▅▇▆█▅▇▅▄▅▇▅▆▄▇▇▅▄▇▇▅▃▇▅█▇
wandb:      train/ensemble_f1 ▇▂▆▆▃▅▃▇▄▅▂▄▇▇▇▄▂▅▅▄▇▆▅▁▄█▆▃▅▅█▇▇▃▅▆▇▄▇█
wandb:         train/mil_loss ▂▂▆▆▁▂▃▂▄▁▃▃▄▂▃▁▄▃█▂▅▂▃▁▆▃▂▄▃▁▁▅▃▁▃█▃▂▅▅
wandb:      train/policy_loss ▁▁▄▄▄▃▆▃▄▃▄▃▃▁▄▄▃▁▃▆▄▆▄▆▃▄▆▆▄▆▃█▃▄▄█▄▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▅▃▃▅▃▃▆▃▃▃▁▅▃▅▃▁▆▅▃▆▅▅▅▁▃▅▆▃▃█▃▆▅▃██▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.29392
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30658
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.64862
wandb:      test/avg_mil_loss 1.01448
wandb:       test/ensemble_f1 0.64862
wandb:           train/avg_f1 0.86085
wandb:      train/ensemble_f1 0.86085
wandb:         train/mil_loss 0.77272
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b7koawna
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163740-b7koawna/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: muzxbxeb with config:
wandb: 	actor_learning_rate: 3.0151823801864404e-06
wandb: 	attention_dropout_p: 0.20147831227674973
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9505813483746846
wandb: 	temperature: 8.275353232638833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163933-muzxbxeb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/muzxbxeb
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 124-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▁▂▁
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ▇▂▁▂▇▂▂▇▂▃▇▃▆▃▇▂▁▂██▂█▃▇▂█▇▂▂▄▇▇█▇█▇█▇█▂
wandb:      eval/avg_mil_loss ▅▁█▄▁▅▇▁▇▆▁▂▂▁▁▁▁▆█▇▁▆▁▄▁▁▁▅▃▁▁▁▁▁█▁▆▁▁▇
wandb:       eval/ensemble_f1 ▇█▇▁▁▁▁▇▂▁▇▂▇▂▁▁▂▇▇▂▇▇▂▁▇▂▁▇▆▂▇▃▁▇▇▇█▇█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▁▆▆▅▅▄▆█▄▄▅▃▃▄▆▅▄█▄▅▄▄▃▇▅▆▆▆▆▄▇▄▅▅▄▅▄▂
wandb:      train/ensemble_f1 ▄▃▅▆▄▅▄▃▄▅█▆▄▂▅▄▅▂▄▃▆▆▆▅▅▃▆▄█▄▅▂▄▄▇▇▃▄▆▁
wandb:         train/mil_loss ▄▇▅▄▄▇▁▆▅▅▃▅█▅▁▂▅▂▂▆▃▅▂▄▂▃▅▄▂▅▃▁▄▃▄▁▃▃▇▄
wandb:      train/policy_loss ▄▃▄▄▄▆█▆▄▁▃█▄▄▆▁▄▆▃▄▄█▄▃▄▄▃▃▄▄▃▄▆█▄▅▃▆▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▅▃▅▆▅█▆▁▅▅▃▃▃▃▅▅▅▅▁▃▅▅█▆▅▆▅▅▃▅▃▆▃▆▆▅▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.199
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 1.96393
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.52674
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.6241
wandb:      train/ensemble_f1 0.6241
wandb:         train/mil_loss 0.83474
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/muzxbxeb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163933-muzxbxeb/logs
wandb: Agent Starting Run: swrtgk5d with config:
wandb: 	actor_learning_rate: 6.06127047656762e-06
wandb: 	attention_dropout_p: 0.455439869200004
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8104631258199855
wandb: 	temperature: 6.502910987428124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164101-swrtgk5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swrtgk5d
wandb: uploading history steps 113-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇▇█
wandb: best/eval_avg_mil_loss █▃▃▃▅▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇▇█
wandb:            eval/avg_f1 ▃▅▇▁▇▄▇▁▇▇▅▆▅▄▂▇▅▅▁▇▅▅▇▇▅▆▇█▃▇▇▇▅▇▇▇▆█▇▇
wandb:      eval/avg_mil_loss ▂▁▄▁▅▄█▁▄▁▁▃▂▃▃▁▁▂▄▅▅▂▄▁▂▄▁▁▁▃▁▁▂▅▂▁▂▁▃▄
wandb:       eval/ensemble_f1 ▇▇▆▅▁█▃▄█▇▃▆▅▄▆▅▅▅▇▇▁▇█▅▄▇▇▄▅▆▆▄▆▅▆▃▄▇▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▅▄▅▃▅▂▁▅▃▆▃▆▇▄▃▅▄▃▄▂▃▃▅▂▄▄▄▅▃█▅▁▃▄▅▄▆
wandb:      train/ensemble_f1 ▄▃▄▃▁▃▅▃▂▁▂▇▆▅▇▅▃▅▄▇▂▄▄▄▂▅▅▅▄▄▅▇▃█▃▇▃▄▃█
wandb:         train/mil_loss ▃▃▆▃▇▇▄▄▃▁▄▄▄▆▅▃▃▅▂▄▂▃▅▇▁▃▄▆▂█▂▄█▄▆▅▅▃▅▇
wandb:      train/policy_loss ▂▃▂▆▆▁▇▆▆▆▅▆▁▂█▅▇▇▇▆▅▆▆▃▆▅▂▃▇▃▂▂▆█▂▂▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.1752
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.27917
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.66018
wandb:      test/avg_mil_loss 1.34006
wandb:       test/ensemble_f1 0.66018
wandb:           train/avg_f1 0.86698
wandb:      train/ensemble_f1 0.86698
wandb:         train/mil_loss 0.74669
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swrtgk5d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164101-swrtgk5d/logs
wandb: Agent Starting Run: kvg09i8b with config:
wandb: 	actor_learning_rate: 1.3768038865477593e-05
wandb: 	attention_dropout_p: 0.1298165193495387
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3908450296307644
wandb: 	temperature: 2.61737506530567
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164224-kvg09i8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kvg09i8b
wandb: uploading history steps 159-164, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss ▆█▃▇▁
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▆▇▅▇▃▇▇▇▇▇▂▁▄▇▄▇▅▇█▆▆▇▄▅▅█▆▇▇▆▄▇▇▅▅▇▆▇▆▇
wandb:      eval/avg_mil_loss ▁▁▃▁▁▁▅▇▂█▁▃▁▄▁▂▁▄▁█▅▂▁▁▁▅▁▁▁▃▃▂▃▁▁▂▃▃▂▁
wandb:       eval/ensemble_f1 ▇▇█▇▅▇▇▇█▃▄▇▇▆▇▅▇▆▇▅▄▇▁▆█▄▆▇▆▇▇▅▄▇▇█▇▆▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▁▃▇▆▃▅▁▅▅▄▅▇▇▆▇▆▇▆▂▅▇▇▅▇▇▆▅█▇▆▇▆▅▅▄▅▇█
wandb:      train/ensemble_f1 ▅▁▅▇▅▇▃▄▄▇▆▇▆▇▂▆▅▅▄▆▅▆▅▄▆▆▅▄▅▅█▇▄▅▄▆▄▆▆█
wandb:         train/mil_loss ▂▄▄▃▂█▃▃▄▄▁▅▃▄▃▂▇▂▄▃▂▃▂▃▂▄▆▁▃▂▇▃▆█▃▄▅▄▂▂
wandb:      train/policy_loss ▄▇▄▂▇▄▇▇▂▇▇▁▄▇▇▇▂▄▄▂▄▂▇▂▅▄▇▄▄▇▂▇▄▇▄▂█▅▂▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▇▇▄▄▂▂▄▇▇▇▂▂▁▇▇▇▇▁▄▂▂▁▄▇▂▇▇▂▂▅▇▅▂▂▂▁█▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.22614
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.24289
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.78947
wandb:      test/avg_mil_loss 0.54472
wandb:       test/ensemble_f1 0.78947
wandb:           train/avg_f1 0.84992
wandb:      train/ensemble_f1 0.84992
wandb:         train/mil_loss 0.40676
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kvg09i8b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164224-kvg09i8b/logs
wandb: Agent Starting Run: a8b79u9n with config:
wandb: 	actor_learning_rate: 6.007300632049914e-05
wandb: 	attention_dropout_p: 0.09600550863903112
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.920866232784369
wandb: 	temperature: 4.813219386110614
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164417-a8b79u9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a8b79u9n
wandb: uploading history steps 114-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▂▂▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▅▄▇▅██▂▇█▂█▇▇▅▅▆▂▇▂▅▆▇▄▇▇▃▇▇▂▁▄▇▅▅▇▆▃▇▂▇
wandb:      eval/avg_mil_loss ▃▄▅▃█▄▆▁▁▁▁▅▃▂▁▄▇▄▁▂▄▅▁▇▁▃▁▁▁▃▅▁▅▃▂▆▄▃▂▂
wandb:       eval/ensemble_f1 ▄▅▇▅▆▆▁▁█▅▇█▅▇▂▅▁▆▄▇▇▇▄▄▄▁▁▃▅█▃█▄▅▁▇▄▅▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃█▅▆▆▆▆▅▇▅▅█▅▄▂▆▆▅▇▆▅▅▁▄▇▇▆▆▇▄█▇▆▄▆▆▅▄
wandb:      train/ensemble_f1 ▅▂▃▃▁▅▇▆█▄▂▆▃▄▅▄▄▄▃▅▃▅▃▃▄▆▅▄▁▆█▆▅▆▇▄▂▃▅▅
wandb:         train/mil_loss ▇▆▄▅▇▂▅█▄▅▃▃▆▃▇█▆▃▃█▇▇▆▆▄▇▇▃▂█▆▄▅█▅▂▁▅▂▇
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▆▄▁▆▁█▄█▃▄▃▄▆▃▆▆▆▄▁▄█▆▆▁██▆▆▆▆▆▃▁▆▃▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.20715
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.72867
wandb:      eval/avg_mil_loss 0.93532
wandb:       eval/ensemble_f1 0.72867
wandb:            test/avg_f1 0.68286
wandb:      test/avg_mil_loss 1.216
wandb:       test/ensemble_f1 0.68286
wandb:           train/avg_f1 0.78392
wandb:      train/ensemble_f1 0.78392
wandb:         train/mil_loss 0.895
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a8b79u9n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164417-a8b79u9n/logs
wandb: Agent Starting Run: 5c7f6a1g with config:
wandb: 	actor_learning_rate: 0.00045263536014836654
wandb: 	attention_dropout_p: 0.19973354022256656
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5445740845434794
wandb: 	temperature: 0.4651885532022826
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164550-5c7f6a1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5c7f6a1g
wandb: uploading history steps 50-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▇▁▇▇▇▇▇▇▇▇▇▇▇▇▆█▇▇▇█▇▇▇▇▇▆▇▇▇▇▇▇▁▇▇▂▇▇█
wandb:      eval/avg_mil_loss ▂▁▁▅▁▁▁▁▁▂▁▁▁▁▁▁▁▅▁█▁▁▁▄▁▁▁▁▁▁▁▁▁▇▁▁▂▁▁█
wandb:       eval/ensemble_f1 █▇▇▇▁█▇▇▇▇▇▇▇▇█▂▇▁▆█▇▄█▇▇▇▇▇▆▇▇▇▇▂▇▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▅▄▆▃▇▃▆▅▅▄▇▇▆▆▄▆▆▇▂▁▂▆▅▄▅▅▆▆█▅▃▆▄█▆▂▅
wandb:      train/ensemble_f1 ▄▅▆▁▆▂▆▄▇▃▅▆▇▅▇▆▄▆▆▃▃▂▂▇▅▄▅▅▁▆▅▃▅▄▆▅█▇▃▅
wandb:         train/mil_loss ▂▅▂▁▃▅▃▁▂▂▃▂▁▁▄▄▁█▂█▂▂▂▄▁▁▃▄▄▂▂▆▂▅▁▂▁▅▃▂
wandb:      train/policy_loss ▆▃█▆▃███▁▆▃▆▃▆▃▆█▃▁▃▃█▆▃▁▃▃▃█▃▃▆███▆▃██▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▃█▆▃████▃▃▆▆▃▃▆█▃▁▆▃█▆▃▁▃█▆▃█▃█▆▆▃█▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.32326
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.20491
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13297
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.8335
wandb:      train/ensemble_f1 0.8335
wandb:         train/mil_loss 0.29723
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5c7f6a1g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164550-5c7f6a1g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i48lgcde with config:
wandb: 	actor_learning_rate: 1.6644922050827714e-05
wandb: 	attention_dropout_p: 0.3998838410747263
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6166475425962733
wandb: 	temperature: 1.8030710290659713
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164642-i48lgcde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i48lgcde
wandb: uploading history steps 105-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss ▁█▄▂
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ██▇█▁█▇▇▇▆▇▇▃▁█▆▇▃▁█▆█▇▅▂█▆▆█▇▆▁▆▁▅▃▇██▇
wandb:      eval/avg_mil_loss ▁▁▁▄▁▁▁▁▁▁▁█▁▇▁▁▇▁▁▂▅▁▁▁▁▁▁▁▅▃▇▂▆▆▁▃▁▁▁▃
wandb:       eval/ensemble_f1 █▇██▇▇▆▆█▇▁▇▇█▅█▁▇▅█▁▆███▆█▅▁▆▆▂▁▁▂▇▇▁▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▁▇▃▅▁█▅▄▆▇▅▅▅▃▇▄▄▆▄▂▅▅▆▄▁▆▄▅▅█▅▅▅▅▇▆▅▂
wandb:      train/ensemble_f1 ▃▇▁▅▅▃▆▄▅▅▇▇▄▅▇█▅█▁▇▄▆▅▇▇█▅▅▅▆▅▆▇▅▃█▆▅▃▂
wandb:         train/mil_loss ▁▄▃▄▂▅▃▅▅▄▇▃▃█▄▆▅▁▅▂▁▃▄▃▆█▂▃▃▆▄▆▆▁▃▄▆▂▅▄
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30781
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 0.76842
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.2073
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.70154
wandb:      train/ensemble_f1 0.70154
wandb:         train/mil_loss 0.53778
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i48lgcde
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164642-i48lgcde/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lgnzli78 with config:
wandb: 	actor_learning_rate: 2.1807548701630872e-06
wandb: 	attention_dropout_p: 0.4284252726210888
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5450261239250688
wandb: 	temperature: 8.975196461545243
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164810-lgnzli78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lgnzli78
wandb: uploading history steps 105-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆██
wandb: best/eval_avg_mil_loss █▇▅▇▄▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆██
wandb:            eval/avg_f1 ▁▆▄▄▄▅▄█▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▆▅█▄▄█▄▃▄▄▄▄▃▅▆▅▇
wandb:      eval/avg_mil_loss █▅▇▆█▃▄▆▃▆▇▇▆▆▆▆▁█▆▆▅▅▇▅▇▆▁▅▇▆▅▇▇▅▂▇▆▆▅▅
wandb:       eval/ensemble_f1 ▆▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆█▇▇▇▇▆▅█▆▅▇█▇▆█▇▅▆▅▁▇▇██▆▅▄▆▇▆▇▆▇▇█▅▇▅
wandb:      train/ensemble_f1 ▆▅▅▅▇▅▃█▄▅▅▇▆▅▆▅▇▆▆▁▁▆▄▆▇▅▇▅▄▆▆▅▆▇▇▇▁▆▇▄
wandb:         train/mil_loss ▃▃▂▂▂▃█▃▃▂▄▂▃▄▇▂▃▃▄▂▃▄▂▂▃▃▄▃▂▃▃▇▁▂▁▃▂▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.1993
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.31163
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.1164
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.86874
wandb:      train/ensemble_f1 0.86874
wandb:         train/mil_loss 0.31909
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lgnzli78
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164810-lgnzli78/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qxq57mja with config:
wandb: 	actor_learning_rate: 0.0004429004768246973
wandb: 	attention_dropout_p: 0.334176945191379
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2388343757104523
wandb: 	temperature: 8.44294418532456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164928-qxq57mja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxq57mja
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▇█
wandb: best/eval_avg_mil_loss █▃▄▂▁
wandb:  best/eval_ensemble_f1 ▁▄▄▇█
wandb:            eval/avg_f1 ▇▇▁▂▃▇▅█▇▁▇█▇▇▆▁▁██▁██▁▅▃█▇▂▁██▇▇▂▇██▂▃█
wandb:      eval/avg_mil_loss ▂▁▁▆▆▁▁▁▁▆▁▁▁▁▇▂▇▇▄▁▄▄▁▁▁▂▂▁▁█▃▇▇▃▂▂▂▆▁▁
wandb:       eval/ensemble_f1 ▇▂█▇▂█▄▆███▂█▇▇▇▄▂▅██▄▇▇▂▄▇█▂▂▆▂█▆▂▂█▇█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▅▆▆▅▆▁▅▇▅█▄█▄▃▇▅▅▃▇▅▆▆▄█▇▄▅▆▄▅█▇▅▄▆▆▆
wandb:      train/ensemble_f1 ▇▅▃▇▄▆▁▅▅▇█▇▆▆▇▅▅▃█▆▆▄█▅▂▇▄▆▄▇▅▁▇▅▆▁▆▇▇▅
wandb:         train/mil_loss ▃▅▆▇▄█▁▄▅▂▄▂▄▄▃▅▃▆▆▃▄▄▄▁▆▅▅█▁▆▇▄▄▇▄▁▂▄▂▂
wandb:      train/policy_loss ▃▃█▃▄▆▄▃▃▃▃▆▄█▄▆▆▃▄▆▃▄▄▄▃▄▃▃▆▆▃▁▆▃▃▄█▃▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▃▁▁▆▃▆▁▃▆▆▃▁▁▁█▁▆▆▁▃▁▆▆▆▃█▁▃▃▆▁█▆▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.23522
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.27935
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.57924
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.83529
wandb:      train/ensemble_f1 0.83529
wandb:         train/mil_loss 0.59271
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxq57mja
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164928-qxq57mja/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: le8x72k0 with config:
wandb: 	actor_learning_rate: 7.27876813712533e-05
wandb: 	attention_dropout_p: 0.2835210121180627
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1849081367531732
wandb: 	temperature: 7.579084100922201
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165055-le8x72k0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/le8x72k0
wandb: uploading history steps 75-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▂█▇█▁▃▇▇█▁▂▂██▇▇▇▂▄▇▇██▁▂▂▂▁▁▃▇▂▇▇▆▇▂▄▇▇
wandb:      eval/avg_mil_loss ▇▂▃▁▂▁▁▁▇▁▇▄▁▁▁▃▁▁▇▃▂▇▃▇▁█▄▁▁▁▁▁▁▃▂▇▃▇▅▁
wandb:       eval/ensemble_f1 ▃█▁▅▄█▃▂▃▃▇▃███▇▇█▅▇▇▂▅▃▇▃▃█▂▃▇▇▇▂▇▃▃███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▅▄▆▅▆█▂▄▃▂▃▇▅▆▅▇▆▁▄▇▄▇▆▁▇▅▄▅▆▅▅▇▅▆▆▆▇▃
wandb:      train/ensemble_f1 ▇▄▅▄▄▂▃▂█▂▄▃▆▂▃▅▅▅▇▅▆▄▆▁▇▄▃▅▆▅▇▆▇▅▆▆▃▆▅▃
wandb:         train/mil_loss ▆█▄▂▆▃▃▃▃▄▃▁▄▆▄▂▅▃▃▃▅▃▆▂▂▅▂▂▂▃▃▄▁▄▁▃▄▃▃▂
wandb:      train/policy_loss ████████████████████████████████████▁███
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▃▅▄▁▄▄▆▃▄▄█▃▆▃▃▃▃▃▃▄▃▃▃▆▃▃█▄▄▄▆▄▅▆▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.19122
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 1.9275
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.3114
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.69124
wandb:      train/ensemble_f1 0.69124
wandb:         train/mil_loss 0.68248
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/le8x72k0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165055-le8x72k0/logs
wandb: Agent Starting Run: 12bqg2i8 with config:
wandb: 	actor_learning_rate: 7.2279215882116e-06
wandb: 	attention_dropout_p: 0.18702256290849517
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1101340374101647
wandb: 	temperature: 8.63061905123274
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165157-12bqg2i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12bqg2i8
wandb: uploading history steps 69-76, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 ▆▂█▂▃▅▃▂▃▂▃▂▂▆▅▂▅▆▅▃█▂▄▁▃▃▅▃▅▂▄▂▅▅▆▅▄▅▅▄
wandb:      eval/avg_mil_loss ▅▂▅▁▅▄▃▇▅▅▇█▁▇▇▄▃▄▅▇▇▄▄▃▆█▇▄▆▇█▅▄▅▄▅▂█▆▅
wandb:       eval/ensemble_f1 ▄▆▇▅▁▅▂▁▃▂▅▃▁▁█▁▅▅▅▂▆▅▂▁▃▄▂▄▃▃▄▅▅▃▅▇▄▆▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▆▁▆▅▄█▅▇▆▄▆▆▇▇▃▅▂▇▄▆▇▄▆▅▅▃▂▃▆▆▅▄▅▅▅▅▅
wandb:      train/ensemble_f1 ▃▅▁▆▅▃▅▄▃█▇▄▄▅▆▆▃▅▁▅▇▃▆▄▅▅▃▁▆▅▄▄▅▅▃▅▇▅█▅
wandb:         train/mil_loss ▁▁▅▄▂▇▅▂▂▃▂▃▃▁▃▃▄▃▄▆▃▃▁▅▃▁▂▄▄█▆▃▂▄▄▅▅▂▄▅
wandb:      train/policy_loss ▃██▆▆▅▆▃▆▅▅▅▅▆██▆▆▃▆█▅▅▅▅▃▁▆▅▃▁▆▅▆█▁▁▁█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆██▄▆▃▁▆▄▄▄█▄▆▃█▆▆▃█▄▄▄▄▄▃▆▄▁▃▄▄▁▁▃▃█▄█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.24202
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.6875
wandb:      eval/avg_mil_loss 1.08696
wandb:       eval/ensemble_f1 0.6875
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 1.6626
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.72087
wandb:      train/ensemble_f1 0.72087
wandb:         train/mil_loss 1.09113
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12bqg2i8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165157-12bqg2i8/logs
wandb: Agent Starting Run: atm4q4mw with config:
wandb: 	actor_learning_rate: 7.128839477107481e-05
wandb: 	attention_dropout_p: 0.18525891235835448
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26909451571969223
wandb: 	temperature: 6.348876667349482
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165255-atm4q4mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atm4q4mw
wandb: uploading history steps 105-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇█▇█▄▁▇█▇▇▇█▇▇▇▇█▇▇█▇█▇▇▁▇▇▇██▇█▇▇▇▇█▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▁▁▄█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▂▁▁▁▂█▁▂▁▁
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▁▇▇▇▇▇▇▇█▆▆▇▇▇██▇█▇▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▇██▇█▄▇▅▄▅▇▇█▄▇▅▇▁▇▇▇▇█▅▇▇▇▇▇▇█▇▃█▇██
wandb:      train/ensemble_f1 ▇▁██▄▇▅▇▅▇▅█▇▄█▇▁▇█▇█▇▇▅▇▄▅█▇▇▇▅▃█▇▄▇█▇▇
wandb:         train/mil_loss ▂▂▆▁▄▁▄█▆▁▁▂▂▃▅▄▁▁▂▁▂▃▂▁▂▁▂▂▂▁▁▁▁▁▁▅▅▄▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.2643
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.276
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12821
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.92424
wandb:      train/ensemble_f1 0.92424
wandb:         train/mil_loss 0.29434
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atm4q4mw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165255-atm4q4mw/logs
wandb: Agent Starting Run: fh96c1b8 with config:
wandb: 	actor_learning_rate: 0.0007055478444650448
wandb: 	attention_dropout_p: 0.39876136700869
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3111457199369856
wandb: 	temperature: 8.607969892671939
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165417-fh96c1b8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fh96c1b8
wandb: uploading history steps 131-157
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁██▆
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇▇█▇▆▆▇▇▇▇▇▇▇▇▁█▇█▇▇▇▇▆▇▇█▇▇▇▇▇▇▇▆▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▂▁▇▁▁▁▂▁▂▁▁▂▁▂▅▅▅▁▂▁▁▁▁▁▂▂█▂▁▁▁▂▁▁▁▁▂▁
wandb:       eval/ensemble_f1 ▇▇▇▇▇██▇█▇▇▇██▇▇█▃▇██▁▇█▆█▇▇▇█▇▇▆▁██▇█▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▆▇▇▇▃▅▃▇▃▇▇▅▆▇▆▅▇▇▇▇█▃▄▁▇█▆▆▇▇▃▇▄▃▄▇▆
wandb:      train/ensemble_f1 ▇▅▇▅▆▇▇▄▇▆▁▆▇▆▂▅▄▇▄▆▄█▂▃▅▇▇▆▇▆▇▅▅▂▄▆▅▆▆▆
wandb:         train/mil_loss ▃▂▁▅▃▁▇▂▁▅▂▂▁▁▂▂▆█▂▄▃▁▃▄▁▁▂▂▇▃▅▅▁▁▃▂▁▅▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.28988
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.28879
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.29729
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.89223
wandb:      train/ensemble_f1 0.89223
wandb:         train/mil_loss 0.26632
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fh96c1b8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165417-fh96c1b8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jsevn8v7 with config:
wandb: 	actor_learning_rate: 0.00013578428361549417
wandb: 	attention_dropout_p: 0.1606528409528184
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5061825338960145
wandb: 	temperature: 2.198096644969273
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165620-jsevn8v7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jsevn8v7
wandb: uploading history steps 50-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▇▇▃▇▂▁███▇█▇▂▂▂▇█▂▂█▂██▂▂▂▁███▆█▃▂▇██▂▂█
wandb:      eval/avg_mil_loss ▁▁▄▁▆▆▁▁▁▆▁▁██▆▁▆▅▁▁▁▁▇▁▇▁▁▁▆▇▁▆▅▁▁▅▅▂▁▅
wandb:       eval/ensemble_f1 ▇▇▃▇▂███▇▇▂▂▂▅▇▂▂█▇▂▂▂▇▂▁██▃▂▆▃▂▇██▄▂▂█▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▃▂▄▇▇▇▄▇▅▁▆▅▅▄▄▅▅▅▄▃▆▄▄▆▄▃▁▇▆▅▅▄▆▆▇▃█
wandb:      train/ensemble_f1 ▆▃▄▃▂▄▇▇▇▄▇▅▁▆▄▅▄▃▅▅▆▅▄▃▆▆▄▆▄▃▂▇▆▅▅▆▆▆▇█
wandb:         train/mil_loss ▄▄▄▂▄▆▆▆█▇▄▃▄▇▅▅▆▂▂█▂▂▅▄▅▄▁▂▃▄▃▄▄▆▅█▃▂▆▂
wandb:      train/policy_loss ▃▆▃▃▄▄▄▄▄█▄▄▄█▆▃▄▄▄▄▄▄▆▃▃▆▄▆▃▃▃▁▃▆▆▄▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▃▃▄▄▄▄▄█▄▄▄█▆▃▄▄▄▄▄▄▆▃▃▄▆▃▃▄▃▁▃▆▆▃▃▃▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30934
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 1.35921
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.19204
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.86749
wandb:      train/ensemble_f1 0.86749
wandb:         train/mil_loss 0.51914
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jsevn8v7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165620-jsevn8v7/logs
wandb: Agent Starting Run: 7c67eajs with config:
wandb: 	actor_learning_rate: 6.723700183361455e-05
wandb: 	attention_dropout_p: 0.0011256197993079753
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11152621924256356
wandb: 	temperature: 8.19275492579352
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165656-7c67eajs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7c67eajs
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇██▇▇██▇▇█▁██▇██▂█▇▇▇███▇▇▇█▁██▄▂█▇▂██▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▇▁▁▁▇▁▁▁▁▇▁▁▁▁▁▁▁▇▁▁▁▁█▁▁█▁▁▁▁▃█▁▁
wandb:       eval/ensemble_f1 ██▇█▇█▇▂▇██████▇█▇▂▇█▇██▇▇██▁██▇▇████▂█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▅▅▇▇▇▇▇▅▆▆▅▆▅▆▆▆▆██▇▇▇▆█▇▄▇▆▇▇▆▆▇▄▇▁█▇
wandb:      train/ensemble_f1 ▇▅▃▅▂▅▃▆▇█▆▇▇▆▅▅▅▇▁▂▄▇▃▆▇▇▄█▄▇▄▆▄▇▆▇▃▅▇▆
wandb:         train/mil_loss ▃▁▂▁▃▂▁▁▁▂▄▁▁▁▁▅▁▅▁▃▁▅▁▂▁▃▁▆▃▃▃▁█▁▃▆▂▂▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32697
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.28177
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.12103
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.85356
wandb:      train/ensemble_f1 0.85356
wandb:         train/mil_loss 0.33475
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7c67eajs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165656-7c67eajs/logs
wandb: Agent Starting Run: gvj974g3 with config:
wandb: 	actor_learning_rate: 1.189114929074478e-05
wandb: 	attention_dropout_p: 0.1101147155487639
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2875648480116745
wandb: 	temperature: 7.9332366923156785
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165803-gvj974g3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvj974g3
wandb: uploading history steps 105-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▆
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▇█▇▇█▆█▆██▇▂▇████▇▇████▁▇█▂██▃▄█▇█▃▇██▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▃▁▁▁▇▂▁▁▁▁█▂▁▁▁▁▅▆▇▁▅▁▁▃▁▄▁▅▁▁
wandb:       eval/ensemble_f1 █▇██▇██▆█▃███▆▇▇█▁█▆▆▇█████▁████▇█▇██▃▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▅▇▇▅▅▇▆▃█▄█▄█▅▇▅▇▅▄▃▄▄▇▃▃▇▄▇▅▆▇█▆▆▁▇▇
wandb:      train/ensemble_f1 ▇▆▇█▇▅▃▇▆▆▅▆▃▇█▅▅▄▅▇▆▄▆▅█▄█▇▇▇▆▇▁▇▂▇▆▇▇▇
wandb:         train/mil_loss ▆▅▂▁▂▆▇▃▁▄▂▅▅▅▃▃▅▇▆▂▇▃█▅▁▅▃▂▂▅▂▃▃▆▆▇▃▇▇▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.33878
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32897
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.61293
wandb:      test/avg_mil_loss 1.07342
wandb:       test/ensemble_f1 0.61293
wandb:           train/avg_f1 0.89498
wandb:      train/ensemble_f1 0.89498
wandb:         train/mil_loss 0.20247
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvj974g3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165803-gvj974g3/logs
wandb: Agent Starting Run: tfxs8mx7 with config:
wandb: 	actor_learning_rate: 6.75240613128714e-05
wandb: 	attention_dropout_p: 0.4905488438690379
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6224076802273633
wandb: 	temperature: 1.8749120028645696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165921-tfxs8mx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tfxs8mx7
wandb: uploading history steps 104-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▂▂▂███▂▅██▁▇█████▂█▃█▂█▂█▁█▂▂██▁███▂██
wandb:      eval/avg_mil_loss ▁▁▆▁▁▇▁█▁▁▁▁▁▅▁▁▁▁█▁▇▇▁▁▇▁▁▇▁▇▁▁▇▁█▁▄▁▆▁
wandb:       eval/ensemble_f1 ████████▂███▁▇██▂█▂█████▁▂███▂▃▂██▂██▂██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▄▇█▆▇▅██▆▁▇▆▄▄▆▇█▆▅▆▆▄▄▅▅▆▇▇▃▆▂▆█▆▆▆▆
wandb:      train/ensemble_f1 ▇▆▇▄▇▆▄▁▅▆█▇█▆▄▇▇█▄▆█▇▇▇▆▄▄▆▅▄▇▁▂▆▆█▆▆▄▄
wandb:         train/mil_loss ▃▆▆▅▃▅▅▄▄▃▃▄▃▅▃▄▅▅▃▃▅▄▅▃▃▁▃█▅▄▆▅▂▅▃▃▅▇▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32945
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.30353
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.16277
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.80208
wandb:      train/ensemble_f1 0.80208
wandb:         train/mil_loss 0.58936
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tfxs8mx7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165921-tfxs8mx7/logs
wandb: Agent Starting Run: hcwh3zg2 with config:
wandb: 	actor_learning_rate: 0.0001712667991685991
wandb: 	attention_dropout_p: 0.29169058943037884
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1992554343380607
wandb: 	temperature: 1.1452084509602125
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170029-hcwh3zg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcwh3zg2
wandb: uploading history steps 100-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▇▇▁▄▁██▇▆▆██▅▆▇▇▇███▆▆█▁█████▇█▇▇▃▃▇▇▇█
wandb:      eval/avg_mil_loss ▂▃▁▂█▂▂▁▃▃▃▁▁▁▂▄▁█▁▁▁▁▂▁▁▂▄▃▅▅▁█▁▆▂▁▂█▁█
wandb:       eval/ensemble_f1 █▃▅▃▂▁▅█▇▆▆▇▅▇▆██████▇▆▆▂██▁▅██▇▇▅▅█▇▅▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▅▆▇▆▄▆▇▆▆▆▇█▄▆▂▇▆▃▅▅▇▅▁▅▆▇▅▆▆▇▆▆▆█▄█▇
wandb:      train/ensemble_f1 ▁▅▃▇▃▆▆▃▄▄▆▅█▁▄▂▆▄▄▆▆▃▁▄▅▅▆▄▃▅▅▅▅▆▇▄▅▂▇▇
wandb:         train/mil_loss ▇▂▁▂▅█▇▂▂█▁▃▆▅▃▂▇▃▆▆▆▃▂▅▂▆▆▄▄▃▅▁▅▅▄▃▄▄▅▇
wandb:      train/policy_loss ▄▃▄▆▆▃▃▃▄▆▃▆▆▃▆▄▆▃▆▃▃▃▄█▆▃▃▁▄▆▃▃▆▃▆▃█▄▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▃▁▃▆▆▃▃▁▃▆▆▁▆▆█▁▁▁▃▆▆▁▃▆▁▆▁▁▁▆▆▃▁▁▃█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.2183
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.68056
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.16601
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.87833
wandb:      train/ensemble_f1 0.87833
wandb:         train/mil_loss 1.05073
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcwh3zg2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170029-hcwh3zg2/logs
wandb: Agent Starting Run: fo5ux8pa with config:
wandb: 	actor_learning_rate: 0.0003742573238901608
wandb: 	attention_dropout_p: 0.3798693877847082
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6405076458556236
wandb: 	temperature: 0.5156064240614899
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170146-fo5ux8pa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo5ux8pa
wandb: uploading history steps 100-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅█
wandb: best/eval_avg_mil_loss ▂█▃▁▄▇
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▇▇▇▇▂▇▇▇▇▇▇▇▇██▇▇█▇▁▇▇▇▇▇▇█▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▂▁▂▂▁▁▁▁▂▁▂▂▁▁▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂█▁▂▂▁▁▂▂▁▂▂
wandb:       eval/ensemble_f1 ▅▆▃▁▄▃▆▇▆▃▇▂▄▆▇▇▃▅▅▆██▄█▇▃▃▅▄▇▄▆▆▂▇▄▃▅▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▅▅▅█▆▆▇▄▄▇▁▂▄▃▄▅▅▄▂▃▄▂▄▆▅▂▂▆▄▃▅▇▅▃▄▄▅▃
wandb:      train/ensemble_f1 ▁▂▄▆█▅▆▄▄▃▁▄▆▄▄▅▄▅▂▆▅▄▄▂▂▄▃▁▂▃▇▅▃▂▅▄▆▅▁▁
wandb:         train/mil_loss ▂▂▁▃▂█▂▅▂▅▂▃▂▂▂▁▂▁▃▃▁▄▄▂▂▂▅▁▄▂▄▂▂▂▄▅▂▁▂▁
wandb:      train/policy_loss ▃▄▁▃█▃█▁▆▄▃▄▃▃▆▆▃▄▃▃▃▃▃▃▄▃▃▆▃▃█▄█▄▁▄▄▃█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▆▆█▃▃█▁█▆▃▄▄▆▆▆▆▄▁▃▃▃▃▃▃▁▃▃▄▃▃▃▃██▃█▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.34316
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.34922
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12182
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.85613
wandb:      train/ensemble_f1 0.85613
wandb:         train/mil_loss 0.33627
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo5ux8pa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170146-fo5ux8pa/logs
wandb: Agent Starting Run: sgupsw5f with config:
wandb: 	actor_learning_rate: 4.6844878114121226e-05
wandb: 	attention_dropout_p: 0.3153054173457364
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7926227259825339
wandb: 	temperature: 4.993424152760771
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170303-sgupsw5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sgupsw5f
wandb: uploading history steps 124-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▂▂▂▂▇▂▇▇▂▇█▁█▂▇▇▃▃▂▂▇███▂▂█▇▂▂▇▂▇▂▂▇▇▇▇
wandb:      eval/avg_mil_loss ▇█▁▁▂▁▁▅▁▁▁▇▁▃▆▇▇▄▁▄▁▅▇▆▇▇█▁▆▁▇▁▃▆▆▁▁▁▁▇
wandb:       eval/ensemble_f1 █▇▂▂▂▁█▇█▇▂█▄▄█▇▂▃▂▇▃▂▄▁▂▇██▇▂▂▇▇▇▂▇▇▇▂▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▄▃▄▇▆▇▇▆▇▄▆▁▆▂▂▆▅▅▅▅▆▅▅▃▃▅▄▆▅▄▄▃▂▅▆▇▅▆
wandb:      train/ensemble_f1 ▄▃▄▆▄▇▆▄▆▆▁▆▅▆▄▆▄▅▃▅▆▃▅▅▂█▅▆▃▄▆▆▅▅▄▆▆▅▆▆
wandb:         train/mil_loss ▅▃▅▅▆▇█▇▆▃▅▄▃▄▅▁▄▅▅▃▄▄▅▆▆▂▅▅▆▃▄▅▄▄▃▇▇▅▅▄
wandb:      train/policy_loss █▁█████████████████████████████████████▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▄▃▆▄▃▆▆▄▃▄█▃▄▄▃▄▆▃▆▄▆▃▄▃▄▄▆▄▁▄▃▃▄▃▄▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32638
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.50715
wandb:      eval/avg_mil_loss 1.95037
wandb:       eval/ensemble_f1 0.50715
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 1.61408
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.76485
wandb:      train/ensemble_f1 0.76485
wandb:         train/mil_loss 1.59725
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sgupsw5f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170303-sgupsw5f/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u3nqv3kp with config:
wandb: 	actor_learning_rate: 1.8550132017612693e-05
wandb: 	attention_dropout_p: 0.29341013004493466
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45597703451960303
wandb: 	temperature: 5.542633948486635
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170501-u3nqv3kp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u3nqv3kp
wandb: uploading history steps 147-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 █▇▇███▂▇▇▇█▇▂▇▇▂▇▇▇▇▇▇▇██▂█▇█▆▂▂██▁▇█▁▇▇
wandb:      eval/avg_mil_loss ▁▂▁▂▂▁▂▁▂▂▂▂█▁▁▁▁▁▂▂▁▁▂▁▁▂▁▁▂▁▂▂▂▁▂▁▄▆▁▂
wandb:       eval/ensemble_f1 ▁▇▇▇▂▅▇▅▇▇▁▇▁▇▁▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▁▇▁▇▇▇▇▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▆▅▄▆▄▆█▁▆▆▆▇▅▅█▅▇▃▄▇▃▂▄▆▅▅▅▃▃▅▅▅▅▁▄▂▃▄
wandb:      train/ensemble_f1 ▄▇▄▃▆▄▆▅▆▄▄▆▆█▇▇▆▄▅▄▅▅▅▁▆▅▆▇▂█▂▅▅▇▃▃▅█▅▆
wandb:         train/mil_loss ▆▃▅▃▂█▃▄▅▂▄▃▃▄▅▁▄▅▅▇▄▅▄▅▄▄▁▂▆▅▅▇▅▂▇▃▃▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.95994
wandb: best/eval_avg_mil_loss 0.17578
wandb:  best/eval_ensemble_f1 0.95994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32405
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12672
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.7798
wandb:      train/ensemble_f1 0.7798
wandb:         train/mil_loss 0.51821
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u3nqv3kp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170501-u3nqv3kp/logs
wandb: Agent Starting Run: 6f1d45fm with config:
wandb: 	actor_learning_rate: 0.0003759108867036843
wandb: 	attention_dropout_p: 0.346183589875948
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9172531009206006
wandb: 	temperature: 5.567519839846974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170643-6f1d45fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6f1d45fm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇███
wandb: best/eval_avg_mil_loss █▁▂▁▁
wandb:  best/eval_ensemble_f1 ▁▇███
wandb:            eval/avg_f1 ▇█▇▃███▂█▄▇█▃▄█▇█▂▂▇▂▇█▆▇▅▇▇█▂▇█▁▁█▇█▇▄▇
wandb:      eval/avg_mil_loss ▇▁▂▂▄▁▁▂▃▂▆▂▇▇▂▅▂▇█▅▁▁▇▅▂▂▂▃▁▆▆▁▇▂█▂▁▁▂▂
wandb:       eval/ensemble_f1 ▂█▄██▁▅█▄▃▃█▃█▃██▃▇█▂██▃▆▇█▅▃█▇▂█▂▂▆▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▇▁▆▇▆▂▂▃▅▄▇▇▇▃▃▆▆▅█▃▅▆█▄▃▇▄▁▄▄▆▇▅▆▇▇▇▆
wandb:      train/ensemble_f1 ▂▇▇▁▃▅▇▂▃▆▅▄▇▇▅▅▃▆▅▃▆▆▅█▅▆▅▅▄▆▇▄▂▁▅▆▇▇▆▆
wandb:         train/mil_loss ▄▄▇▄▆▄▆█▂▆▂▆▄▃▃▁▄▇▁▆▅▇▆▅▃█▂▇█▆▄▃▆▇█▆▃▆▃▄
wandb:      train/policy_loss ▆█▁▆▃█▆▃▆▆█▃█▆▆█▆▆▆▆█▆▃▆▆▆▁▁▃▃▆█▆█▆▆▃▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▃█▃▁█▆▆▆█▃▆▆█▃██▆▆▆▃█▃▆▆▁▃▆▁▆▃▃▆█▆▃▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.21007
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.33533
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.289
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.78031
wandb:      train/ensemble_f1 0.78031
wandb:         train/mil_loss 0.71232
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6f1d45fm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170643-6f1d45fm/logs
wandb: Agent Starting Run: z2xm85na with config:
wandb: 	actor_learning_rate: 3.972021559775909e-06
wandb: 	attention_dropout_p: 0.413849057491108
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 84
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.120510449465007
wandb: 	temperature: 8.24050522415497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170735-z2xm85na
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2xm85na
wandb: uploading history steps 75-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▅
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▇█▅███▁▃█▁█▁██████▁▄█▁████▂█▅█▃▅▇█▄▂▆▄██
wandb:      eval/avg_mil_loss ▁▄▁▁▁▆▁█▇▄▁▆▁▁▁▁▁▄▁▁▁█▁▂▁▃▁▃▄▄▁▄▁▁▅▁▁▁▁▅
wandb:       eval/ensemble_f1 ▇█▇▇█▂█▃▄▁████▇▇█▁▃▄▇▇▇▇▁▇▂▇▅█▃▅▇█▇█▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▅█▇▆▇▇▃▂▇▅▄▆▄▃▅▅▃▄▆▅▅▃▆▆▆▅█▇▄▄▅▃▅▃▇▁▅
wandb:      train/ensemble_f1 ▂▄▅▇▄█▅▇▅▇▁▃▇▅▆▄▄▆▄▂▄▅▆▆▄▅▇▅▇▆▅▅█▆▃▃▂▅▅▄
wandb:         train/mil_loss ▄▂▃▇▅▅▅▄▃▄▅▄▆▅▄▁▆▂▆▄▃▄▁▆▃▅▄▅▄▄▄▄▃▅▄▃▄█▃▆
wandb:      train/policy_loss ▃▃▃▃▃▃▅▁▅▃▃▁▃▅▅▆▃▅▃▅▅█▃▅▅▃▁▃▃▃▃▅▅▃▅▃▃▆▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▁▃▅▃▅▁▅▃▁▅▅▃▃▅▁▆█▅▅▅▅▅▃▃▃▃▃▃▃▅▅▆▃▃▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.31533
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.60114
wandb:      eval/avg_mil_loss 1.12818
wandb:       eval/ensemble_f1 0.60114
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 1.98389
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.80807
wandb:      train/ensemble_f1 0.80807
wandb:         train/mil_loss 0.79934
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2xm85na
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170735-z2xm85na/logs
wandb: Agent Starting Run: lixec2gw with config:
wandb: 	actor_learning_rate: 1.69375781797912e-05
wandb: 	attention_dropout_p: 0.4123643114591338
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1256187313006426
wandb: 	temperature: 5.670253284427254
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170833-lixec2gw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lixec2gw
wandb: uploading history steps 113-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss ▇▁█
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▇▇█▆█▇▆▁█▆▇▅▇▇▇▅█▇▄▇█▂▇▇▇▇▅▄█▅▇█▇▆▇▇▇▇▁▇
wandb:      eval/avg_mil_loss ▁▂▁▂▁▅▁▃▄▃▇▁▄▁█▂▁▄▁▁▁▄▁▁▄▄▁▃▁▃▁▄▁▂▁▃▄▁▁█
wandb:       eval/ensemble_f1 ▇▆█▆▄▇▄▅▄▆▇▆█▅▆▃▆▅▅▆▄▁▆▇▇▇▇▅▂▆▆▆▇▆▆▄█▄▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▆▂▅▆▂█▅▄▃▆▃▆▃▂▆▄▁▇▄▅▃▅▄▅▅▃▄▅▅▁▃▄▅▃▅▅▄
wandb:      train/ensemble_f1 ▇▅▂▆▃▆▅▇▄▆██▅▆▄▄▇▄▇▅▂▆▆▅▇▃▆▅▅▄▅▅▁▄▄▅▆▅▄▅
wandb:         train/mil_loss ▁▄▂▃▅▄▂▇▁▄▃▄▁▄▄█▃▂▄▁▄▅▆▅▃▄▄▃▃▂▄▃▃▂▂▃▁▄▁▅
wandb:      train/policy_loss ▁▅▂▅▂▅▅▂▅▂▅▂▁▅█▂▂▄▄▅▅▇▄▂▅▅▇▅▂▁▇▅▂▇▄█▂▅▇▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▂▆▆▆▄▆▆▆▇▁▃▇▃▇▄▆▂█▇▃▆▂▆▆▃▃█▆▆█▃▄▃▆▄▃▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.24143
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.84926
wandb:      eval/avg_mil_loss 0.24817
wandb:       eval/ensemble_f1 0.84926
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13484
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.85985
wandb:      train/ensemble_f1 0.85985
wandb:         train/mil_loss 0.65506
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lixec2gw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170833-lixec2gw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nqt829kt with config:
wandb: 	actor_learning_rate: 0.00010688973830758096
wandb: 	attention_dropout_p: 0.06923786358172657
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9210118617035066
wandb: 	temperature: 3.1970007757014773
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171018-nqt829kt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqt829kt
wandb: uploading history steps 50-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▇▁█▄▂█▇▇█▇▄█▇███▇█▇█▇█▇▇███▇█▇▂█▇▇▇▇█▇▇
wandb:      eval/avg_mil_loss █▂▂▇▁▂█▁▂▁▂▁▅▁▁▂▂▂▁▁▁▂▁▂▂▁▁▁▁▁▂▁▁▆▆▂▁▂▂▂
wandb:       eval/ensemble_f1 ▂▇▁███▂█▇███████████▇███████▃▇█▇█▂▂▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▃▆▄▅▄▆▆▄▇▇██▄▇▄▅▆▇▁▇▅▃█▄▄▆▄▂▃▄▅▅█▇▃▄▄▅
wandb:      train/ensemble_f1 ▅▂▃▆▄▆▅▄▅▄▄▆▆▇▁▇▅▆█▇▁▇▅▅▄█▄▆▆█▃▄▅▁█▇▃▄▄▅
wandb:         train/mil_loss ▄▂▁▄█▂▄▃▂▄█▁▃▇▄▆█▂▃▁▇▁▃▅▂▄▃▇▃▃▄▆▅▄▃▃▁▂▃▃
wandb:      train/policy_loss ▃▃▅▃▃▅▁▃▅▃▆▃▅▃▃▃▆▃▃▃▅▆▃▆▃█▃▅█▅▃▁▃▃▃▅▃▅▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▄▃▃▃▁▃▄█▄▆▃▄▄▃▆▃▃▃▃▃▄▆▆▄█▄▄▃▃▃▃▃▄▄▃▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.34866
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.34511
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12509
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.85511
wandb:      train/ensemble_f1 0.85511
wandb:         train/mil_loss 0.35538
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqt829kt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171018-nqt829kt/logs
wandb: Agent Starting Run: bwv6p9rd with config:
wandb: 	actor_learning_rate: 4.3174966749703745e-05
wandb: 	attention_dropout_p: 0.26844447450093534
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14073547669075548
wandb: 	temperature: 4.210233401084308
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171104-bwv6p9rd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bwv6p9rd
wandb: uploading history steps 131-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss █▁▃▅
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 █▇█▇██▂▇█▂▁▄▁▇▂▇▇▃▇▂▇▂▂▂▇▇▃█▇▇▇▇▂▇█▁▅█▂█
wandb:      eval/avg_mil_loss ▁▁▅▁▁▁▁▇▁▁█▇▁▁▁▁▁▁▁▅▁▁█▇▅▁▄▁▄▄▇▃█▁▁▇▁▁▇▁
wandb:       eval/ensemble_f1 ▇▂█▁▇▁▇▇▇▇▇▇█▇▂▄▁▇▂▂▇█▃▇▂▇▇▇▃▇▇▇▇▂▇█▇▁▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▄▇▆▆▁▄▆▆▄▆▇▅▆▄▄█▇▃▃▆▆▅▆▄▆▇▆▆▆▇█▆▅▆▇▆▆▆
wandb:      train/ensemble_f1 ▄▇▃▁▆▆▅▃▆▅▆▆█▆▄▃▃▆█▃▆▆▅▆▇▄▅▆▆▇▄██▃▇▅▅▅▄▇
wandb:         train/mil_loss ▁▆▃▃▅▁█▅▂▅▄▅▆▅▆▇▃▆▄▅▂█▆▄▆▃▆▁▄▃▄▃▂▃▂▄▁▅▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.3499
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.34375
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 2.26469
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.78465
wandb:      train/ensemble_f1 0.78465
wandb:         train/mil_loss 0.72004
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bwv6p9rd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171104-bwv6p9rd/logs
wandb: Agent Starting Run: fomme7pz with config:
wandb: 	actor_learning_rate: 2.102030464368455e-06
wandb: 	attention_dropout_p: 0.12247973653087824
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7819313898001133
wandb: 	temperature: 4.899069322708984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171226-fomme7pz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fomme7pz
wandb: uploading history steps 75-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss ▁██
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▇▄▅▆▃▇▆▇▇▁▆▇▇▇▆▂▆▆▇▆▆▅▇▆▆▆▇▆▅▇▆▆▅▆▅▆▄▆█▆
wandb:      eval/avg_mil_loss ▂▃▂▂▂▃▂▂▁▂▂▂▂▂▂▂▃▂▂▃█▂▂▂▂▁▃▂▂▂▂▂▃▃▃▂▂▂▂▂
wandb:       eval/ensemble_f1 ▇▇▇▇▇██▇███▇███▆██▇█▇██▇▇███▇▇▇▁████▇█▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▂▅▃▄▂▄▇▄▄▂▄▄▄█▁▃▇▅█▆▅▆▃▅▅▇▇▇▁▄▅▄▆▇▁▅▅
wandb:      train/ensemble_f1 ▅▅▅▆▆▅▅▇▆▅▄▄▅▇▆▅█▇▃▄▆▆▁▆▇▄▅▇▄▁▃▅▂▇▅▅▇▃▆▆
wandb:         train/mil_loss ▂▃▆█▂▅▄▃▇▃▅▃▅▄▂▄▄▄▃▂▇▄▃▄▄▄▄▄▃▁▄▂▁▃▃▃▃▄▄▅
wandb:      train/policy_loss ▁▁▃▃▆▆▆▃▆█▆█▁▁█▆▃▃█▃▃▃▁▆▃▃▆▁█▃▃▆▆▆▃▃▆█▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▆▆▃▆▃▆▆▆█▆▃▆█▃█▃▃▃█▃▃▁▁▁██▃▃▁▃▃▆▁▃▃▆█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.3328
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.33268
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.29538
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.85347
wandb:      train/ensemble_f1 0.85347
wandb:         train/mil_loss 0.3099
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fomme7pz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171226-fomme7pz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3xdbspb6 with config:
wandb: 	actor_learning_rate: 2.233706458477532e-05
wandb: 	attention_dropout_p: 0.26287398125503225
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 82
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9160467841352142
wandb: 	temperature: 6.199531515869755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171334-3xdbspb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3xdbspb6
wandb: uploading history steps 75-83, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇▇▇██▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▅▇▇▇▆▆▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▃▅▅▂▃▂▃▃▄▄▁▅▅▄▃▃▃▃▃▅▄█▄▄▅▃▅▂▄▂▂▃▇▃▄▃█▃▇▅
wandb:       eval/ensemble_f1 █▅▅▅▇▆▅▆█▆▆▆▇▆▇▆▆▅▇▅▆▆▇▇▆▆▆▅▅▅▆█▄▄▆▇▇▄▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▃▄▆▅▅▃▆▃▄▅▅▄█▅▃▇▅▃▅▄▅▅▆▂▃▃▃▄▂▃▂▁▄▄▃▅▁
wandb:      train/ensemble_f1 ▄▆▆▅▂▅▆▄▄▇▆█▆▅▄█▅▅▅▆▄▁▅▇▆▅▅▅▅▆▆▄▅▆▄▅▅▅▆▄
wandb:         train/mil_loss ▁▂▃▂▂▆▃▃▃▇█▂▂▁▂▇▃▁▂▂▂▃▂▁▃▃▂▇▃▁▂▁▄▂▂▃▃▇▅▂
wandb:      train/policy_loss ▃▃▃█▃▃▆█▃█▃▃▃███▆▁█▃█▃▆█▃████▆▃▁▃▆█▃▃▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃████▃█▆▃▃▃██▁▃█▆▃▃▁███▃█▆▃▆▆▃▆▃▃▁▃█▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.21982
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.30266
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11811
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.87875
wandb:      train/ensemble_f1 0.87875
wandb:         train/mil_loss 0.29145
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3xdbspb6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171334-3xdbspb6/logs
wandb: Agent Starting Run: 814wspb1 with config:
wandb: 	actor_learning_rate: 3.6156593049750583e-06
wandb: 	attention_dropout_p: 0.38520667100769634
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5386510583179978
wandb: 	temperature: 3.9919233891628094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171431-814wspb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/814wspb1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▂▅█▃█▅▇▂▄▁▇▄▁▇████▆▇█▇▇▇▅▇▇▅█▅▇█▇█▁▂█▇▇
wandb:      eval/avg_mil_loss ▆▁▆▂▁▁▁▃▆▃▁▄▂▆▁▁▁▁▁▂▂▁▁▁▁▁▂▃▂▁▁▁▂▁▄█▅▁▁▂
wandb:       eval/ensemble_f1 ▂▅▃██▇▂▄▇▁▅▁▇▂███▆▇▇▇▇▇█▅▆▇▅▇█▅▇█▇█▇▁▂▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▅▆▆▃▁▅▃▅▄▇▆██▄▅▄▇▅▇▇▄▄▄▃▇▇▅▆▂▅▆▅▇▇▄▄▅▆
wandb:      train/ensemble_f1 ▇▆▅▆▆▃▁▃▅▅▇▆██▄▅▄▇▅▅▄▄▄█▃▇▅▇▆▃▅▆▅▇▇▄▅▇▆█
wandb:         train/mil_loss ▂▅▅▅▅▁▂▃▂▆▄▇▃▄▅▂▃▃▁▃▃▁▅▃▃█▅▂▃▁▄▂▂▃▁▅▄▃█▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.27742
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.35052
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 1.51637
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.87875
wandb:      train/ensemble_f1 0.87875
wandb:         train/mil_loss 1.09514
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/814wspb1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171431-814wspb1/logs
wandb: Agent Starting Run: 9kge9p7q with config:
wandb: 	actor_learning_rate: 2.8474995122625702e-05
wandb: 	attention_dropout_p: 0.03536861187564372
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 162
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10804847725550426
wandb: 	temperature: 4.580142413449035
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171508-9kge9p7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kge9p7q
wandb: uploading history steps 156-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇█
wandb: best/eval_avg_mil_loss █▆▇▄▄▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇█
wandb:            eval/avg_f1 ▆▇█▇▄▃▇▇▇▄▇▁▇▇▁█▃▇▇▇▇█▇▇▁▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▂▁▁▄▁▁█▁█▂▂▁▁▂▂▁▂▁▁▁▁▂▁▁▁▁▃▁▁▁▁▁▁▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▇▃▇▇▇▁█▃▇▇█▁█▇▇▇▂█▃▇▇▇▇▁▇▇▇▇▇▇▇▇▇█▇▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆▇█▅▅▁▅▅▅▆█▇▄▇▃██▅▇▅▆▆▅▇█▇▃▄▇▅▅▆▂█▇▆▅▇
wandb:      train/ensemble_f1 ▅▆▆▁▇▇▇▇▇▃▃▇█▆▅▆█▆▄▅▅▅▄▇▅▇█▃▄▁███▇██▆▅▇▇
wandb:         train/mil_loss ▁▁▆▁▅▁▄▁█▃▁▇▅▆▁▂▃▄▁█▁▃▃█▆▁▁▂▂▂▄▄▁▅▁▄▅▁▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.21263
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.26028
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.13542
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.86729
wandb:      train/ensemble_f1 0.86729
wandb:         train/mil_loss 0.38603
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kge9p7q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171508-9kge9p7q/logs
wandb: Agent Starting Run: lqt9xvf1 with config:
wandb: 	actor_learning_rate: 0.0001640974737259397
wandb: 	attention_dropout_p: 0.14351591136946473
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9469637748665412
wandb: 	temperature: 5.239091712669995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171646-lqt9xvf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqt9xvf1
wandb: uploading history steps 53-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁████
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁████
wandb:            eval/avg_f1 ▁██▇█▇█▂█▇██▁▇█▇██▇█▇█▇▇████▇█████▇▇██▆▇
wandb:      eval/avg_mil_loss █▁▁▁▁▄▆▁▁▁█▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▃▁
wandb:       eval/ensemble_f1 ██████▄▂█████▁▇███████▇█▇███▇████▇██▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▇▃▁▇▇▇▁▂▆▆██▇▇▇▄▇█▇▃▅▇▆▇▇▇▃▇▇▆▇▆█▃▇▇▇▅
wandb:      train/ensemble_f1 ▇▄▃▄▇▇▂▃▃▆▇▇▆█▇▄▇▇▅▄█▁▇▄▅█▇▄▆▇▇▇▆█▄▇▇▇▇▆
wandb:         train/mil_loss ▆▁▂▂▁█▂▂▂▂▂▃▂▂▂▁▁▂▁▁▂▁▂▂▂▁▂▁▁▄▄▄▂▃▃▃▂▅▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.28794
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.31397
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12073
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.85675
wandb:      train/ensemble_f1 0.85675
wandb:         train/mil_loss 0.69835
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqt9xvf1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171646-lqt9xvf1/logs
wandb: Agent Starting Run: qgl65uhh with config:
wandb: 	actor_learning_rate: 1.057167634714175e-05
wandb: 	attention_dropout_p: 0.22376973094128444
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17442131025952512
wandb: 	temperature: 5.351966625868507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171727-qgl65uhh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qgl65uhh
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▅▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▃▁▆▂▃▁▅▂▂▇▁▂█▆▂▁▆▅▂▃▂▄▅▂▃▃▂▃▃▆▂▅█▇▄▆▇▂▄▆
wandb:      eval/avg_mil_loss █▃▆█▅▄▁█▇▇▄█▅█▁▆▄▆▆▆▆▇▄▄▃▄▆▃▃▇▃▅▆▃▇▅▄▆▆▇
wandb:       eval/ensemble_f1 ▇▇▆▃▂▆▃▃█▂▁▃▄▆▁▄▃▆▃▇▄▃▅▂▃▃▇▃██▃██▅▅▄▅▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▂▅▇▄▅▆▂▆▆▄▅▁▃▇▃▃▅▃▃▆▃▄▄▄▁▃▅▅▄▄█▇▃▆▅▃▅
wandb:      train/ensemble_f1 ▁▃▅▃▇▄▅▄▃▆▂▃█▃▄▇▄▆▆▃▅▆▅▆▅▄▆▃▄▅█▅▅▂▄▄▆▄▆▅
wandb:         train/mil_loss ▇▆▆▇▇▆▆▅█▄▂▆▅▆█▄▄▆▆▇▅▅▆█▆▆▄▇▅▆▄▆▅▆▇▇▄▄▁▆
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.25948
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 2.1755
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.54718
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.63866
wandb:      train/ensemble_f1 0.63866
wandb:         train/mil_loss 1.56214
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qgl65uhh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171727-qgl65uhh/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.231.4:57168->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 0pb3akmh with config:
wandb: 	actor_learning_rate: 1.353922504570547e-05
wandb: 	attention_dropout_p: 0.16556778969269847
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3933197321479376
wandb: 	temperature: 0.6048602688504612
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171906-0pb3akmh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0pb3akmh
wandb: uploading history steps 113-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▆▃▃█▃▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▇▇▇▆█▇█▆▅▆█▆▇█▅▇▆▇██▅█▅▆▄█▄▇▇▇▄█▆▁█▅█▇▅█
wandb:      eval/avg_mil_loss ▁▁▂▂▁▁▁▂▆▁▃▅▄▁▁▂█▁▁▁▇▂▄▂▁▂▁▁▁▁▁▁▁▁▁▂▁▅▂▁
wandb:       eval/ensemble_f1 ▇▄▆▇▇▅▆▇▆▇▇▅▅▅▅▆█▁▇▇█▅▆▆▇▅█▅▇▇█▄▇▅█▇▇▅▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▇▃▁▅▄▁▆▃▃▅▄▅▅▅▂▃▃▅▂▆▄▄▅▄▃█▃▂▄▄▄▇▅▃▅▅▃▅
wandb:      train/ensemble_f1 ▅▄▁▆▃▃▆█▄▃▄▃▆▅▂▅▇▆▅▆▁▇▄▅█▂▅▄▆▄█▇▅▂▄▇▄▅▂▃
wandb:         train/mil_loss ▁▃▆▃▃▄▁▄▄▃▃▃▂▃▆▄▂▂▅█▄▄▁▃▁▄▄▃▁▃▂▂▃▆▂▄▄▃▃▃
wandb:      train/policy_loss ▅▄▄▁▄▂▄▇▅▄▂▄▄▄▂▂▂▇▂▇▅▄▄▄▃█▇▄▇▇▅▅▂▂▁▇▄▅▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▁▇▄▂▅█▄▇▅▁▂▄▂▂▂▇▇▄▄▄▂▄▂█▇▂▄▂█▅▅▄▇▄▂▇▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.17002
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.29897
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.86894
wandb:      test/avg_mil_loss 0.48384
wandb:       test/ensemble_f1 0.86894
wandb:           train/avg_f1 0.84125
wandb:      train/ensemble_f1 0.84125
wandb:         train/mil_loss 0.38815
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0pb3akmh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171906-0pb3akmh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pqdqehmf with config:
wandb: 	actor_learning_rate: 3.666819491121674e-06
wandb: 	attention_dropout_p: 0.4109086226650672
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10781562283920287
wandb: 	temperature: 7.888264053081624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172051-pqdqehmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqdqehmf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 █▇▇▅▅▆▇▁▆▅▇▇▇▄▅▄▇▅▇▅▅▅▇▅▇▇▇█▂▂▅▇█▅▆▅▇▅██
wandb:      eval/avg_mil_loss ▁▁▁▅▁▁▁▃█▅▃▃▁▂▄▆▄▆▇▁▃▇▁▁▃▃▄▅▁▂▁▅▃▃▃▂▁▃▁▁
wandb:       eval/ensemble_f1 █▇▇██▅█▆▇█▄▂▅▇▇▃▅▄▃▇▇▁▅▇█▅▇█▁▅▅▆▅▅▇▆▅▇▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▅▆▃▄▆▆▁▅▁▄▅▇▅█▄▅▂▅▇▄▅▆▄▃▅▆▄▆▄▄▅▃▂▇▅▃█
wandb:      train/ensemble_f1 ▇▆▅▅▃▃▄▄▆▁▇▄▇▅█▅▄▃▇▄▆▄▅▆▄▃▆▅▆▄▅▃▃▂▇▄▇▃▅█
wandb:         train/mil_loss ▄▇▆▂▆▅▄▇▅▁▆▅▃▄▃▄▄▄▇▄▅▄▅▅█▄▅▄▅▇▅▄▇▆▂▅▆▆▄▃
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.2353
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.32054
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.26787
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.77225
wandb:      train/ensemble_f1 0.77225
wandb:         train/mil_loss 0.86125
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqdqehmf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172051-pqdqehmf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qt8qn4c3 with config:
wandb: 	actor_learning_rate: 5.777466711093539e-05
wandb: 	attention_dropout_p: 0.18617786634532144
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09414137952164248
wandb: 	temperature: 3.332184969884606
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172205-qt8qn4c3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qt8qn4c3
wandb: uploading history steps 113-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▆▅▆▄▆▆▆▄▄▅▁▅▆▆▃█▅▆▆▄▆▆▅▅▅▄▅▁▆▅▅▃▅▅▅▆▅▃▇▆
wandb:      eval/avg_mil_loss ▂▃▂▂▂▃▃▁▃▃▃▂█▆▁▂▃▃▃▃▂▃▄▃▂▂▂▁▃█▃▂▃▃▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▇█▄▅▇▆▁▅▇▇▇█▄▆▅▄▇▇▂▂▆▇█▆█▄▄▇▆▇▂▇▇▇▆▅▆▆▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▆▃▄▂▅█▄▅▄▅▄▅▇▆▂▅▆▂▄▆▆▃▇▄▄▆▅▅▅▅▆▃▇▆▄▅▅▃
wandb:      train/ensemble_f1 ▄▅▇█▃▂▅▆▄▅▅▄▄▅▆█▃▅▅▆▁█▆▇▆▆▄▇▆▃▅▆▆▅▆▆▅▇▆▅
wandb:         train/mil_loss ▃▆▁▄▃▆▅▃▅▃█▁▅▄▃▁▅█▃▁▄▅▄▆▆▆▆▅▃▃▃▇▄▂▄▆▂▄▄▇
wandb:      train/policy_loss ▁▆▃▁▁▆▆▆▆▇▆▄▇█▆▇▇▄▄███▂▆▂▂▄▄▆█▁▆▆▆█▆▃▃▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▃▁█▄▃▆▆█▆▆▄▄▇▆▆▄▇▄▆▄▄█▆▆▃▆▄▂▄▆▁▆▁▄█▃▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.1987
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.27092
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.19037
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.88247
wandb:      train/ensemble_f1 0.88247
wandb:         train/mil_loss 0.25551
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qt8qn4c3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172205-qt8qn4c3/logs
wandb: Agent Starting Run: 3gpermzc with config:
wandb: 	actor_learning_rate: 2.9793401178036088e-05
wandb: 	attention_dropout_p: 0.3449463765308584
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14026732082809468
wandb: 	temperature: 4.191655965955858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172334-3gpermzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3gpermzc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▇██
wandb: best/eval_avg_mil_loss █▆▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▅▇██
wandb:            eval/avg_f1 ▁▄▁▃▆▆█▅▆▅▇▆▅▇▆▅▂█▇▆▇▃▄▆▆▁▅█▆▃▇▅▂▅█▆▇▇▅▂
wandb:      eval/avg_mil_loss ▆▅▁▁▅█▂▂▅▂▃▄▃▇▂▁▇▃▃▃▆▃▆▄▃▄▅▇▄▁▂▆▆▅▄▂▂▄▄▃
wandb:       eval/ensemble_f1 ▁▅▁▃▄█▆▇▅▁▅▂▇▅▆▂▂▃▆▇▅▅▆▃▆▂█▆█▂▆▅▇▇▇▅▅▇█▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▆▁▆▅▅▆▄▅█▃▄▅▇▁█▄▆▅█▆▇▄▄▇█▅▇▅▇▄▇▇▇▄▃▇▇
wandb:      train/ensemble_f1 ▄▃▃▃▁▃▅▅▂█▃▇▆▃▇▄▅▆▆▇▅▅█▄▇▆▅▇▄▇▅▅▅▅▅▄▅▄▃▇
wandb:         train/mil_loss ▅▃▇▆▄▄▄▂▇▃▂▆▄▆▆▇▃▄▃▄▁▃▂▄▆▇▂▅▆▆▃▄▆█▅█▆▆▃▂
wandb:      train/policy_loss ▆▅▅▅▅▆▂▇█▅▁▆▇▃▂▅▅▃▃▆▃▂▇▃▂▃▅▇▅▃▆▇▇▅▆▇▂▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████▁█████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.18066
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.61556
wandb:      eval/avg_mil_loss 1.15328
wandb:       eval/ensemble_f1 0.61556
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 1.65184
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.80447
wandb:      train/ensemble_f1 0.80447
wandb:         train/mil_loss 0.52098
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3gpermzc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172334-3gpermzc/logs
wandb: Agent Starting Run: org7wzhl with config:
wandb: 	actor_learning_rate: 3.6926670317412366e-06
wandb: 	attention_dropout_p: 0.17029360542596944
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7766999712620253
wandb: 	temperature: 5.227271251283863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172457-org7wzhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/org7wzhl
wandb: uploading history steps 74-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂▂▄▁▁▁▂▁▂▁▆▂█▆▂▁▂▇▁▂▁▁▂█▁█▁▇█▁▂▂▇▂▂█▁▁▁
wandb:      eval/avg_mil_loss ▄█▃▇▇██▂▇▁▇▅▂▁▂▆▆▇▂▂▇▃▇▇▁▇▇█▇▆█▁▃▇▆▇▇▆█▇
wandb:       eval/ensemble_f1 ▁▄▅▁▁▁▁▂▂▁▆▂▂▃▆▂▂▂▂▂▂▇▁▂▁▂█▂▂▁▁▂▂▁▇▂█▇▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅█▆▆▄▃▃▄▅▅▄▃▂▂▄▆▄▃▆▇▃▃▅▂▁▅▃▅▁▆▃▃▄▅▃█▄▅
wandb:      train/ensemble_f1 ▃▃▂▃▅▁▂▅▃▃▃▂▄▂▃▄▃▃▂▃▅▂▃▂▁▄▂▄▄▁▂▂▃▂█▅▆▃▂▄
wandb:         train/mil_loss ▃▇▇▃▇▆▇▇▆▇▆▅▂▃█▅▄▆▆▄▅▅▇▃▅▇▂▅▇▆▇▁▃▆▄▄▅▆█▆
wandb:      train/policy_loss ▄▄█▄▁█▁▁▄▄▄▄▄█▄▁▄█▄█▄██▄█▆▄▄▁▄█▁█▄▄▄▄▄▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▃▃▃▁▃▃▃▃▃▃█▃▃▃▁▃▆▆▃▃▆▃▆▆▅▃▃▆▅▆▆▃▃▃▁▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30399
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.19859
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 2.14961
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.58123
wandb:      train/ensemble_f1 0.58123
wandb:         train/mil_loss 1.93772
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/org7wzhl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172457-org7wzhl/logs
wandb: Agent Starting Run: iq465i84 with config:
wandb: 	actor_learning_rate: 0.0006191231316154126
wandb: 	attention_dropout_p: 0.1708806590703404
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8656652583310512
wandb: 	temperature: 2.3932880692561143
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172559-iq465i84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq465i84
wandb: uploading history steps 124-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▇▇█
wandb: best/eval_avg_mil_loss ▅▃▁█▅▅
wandb:  best/eval_ensemble_f1 ▁▃▄▇▇█
wandb:            eval/avg_f1 ▂█████▂▅█▂▄█▇▂▄█▄▅██▁▂██▄██▄▄█▄▇███████▂
wandb:      eval/avg_mil_loss ▇▁▁▁▁▁▅▂█▁▁▆▁▁▄▁▆▂▁▁▄▁▆▄▁▆▁▂▁█▁▁▁▁▁▁▁▁▆▁
wandb:       eval/ensemble_f1 ▂▇█████▇█▇▇▇▁█▇▇▄▇▂▇▄▄▇▇█▂▁▃▄▇██▇▇▇▁███▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▅▅▇▅▇▆▃█▃▆▆▆█▇▆▇▇▇▆▇▅▆▇▅▇▂▅▆▇▄▄▇▅▃▁▆█
wandb:      train/ensemble_f1 ▅▅▅▆█▆▇▆▇█▆▇▅▅▅▅▃█▇▄▄▇▅█▆▆▁▅▆▁▅▅▃▇▄▇█▇▃▅
wandb:         train/mil_loss ▇▃▁▂▁▅▄▄▂▃█▃▂▄▄▄▇▃▂▂▃▄▂█▁▃▂▃▄▂▅▄▁▄▁▄▆▂▆▇
wandb:      train/policy_loss ▆█▆▃▆█▆█▆▃▆▆▆▆▃█▃▆▆▆▃▆▃▆█▁▃█▆▃▆▃▆▃█▃▃▃██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▃▆▆▁▆▃▆█▆█▃▆▆▆▃▆▆▆▃▃▃▆▃▃▆█▁▆▃▃▃█▃▃▆▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31347
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 1.92865
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.4458
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.82452
wandb:      train/ensemble_f1 0.82452
wandb:         train/mil_loss 0.78544
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq465i84
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172559-iq465i84/logs
wandb: Agent Starting Run: i75bi9ff with config:
wandb: 	actor_learning_rate: 2.091612126113383e-06
wandb: 	attention_dropout_p: 0.3502129184201878
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4776913872742834
wandb: 	temperature: 3.865895785738001
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172722-i75bi9ff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i75bi9ff
wandb: uploading history steps 45-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss ██▆▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▆▅▇▆▆▆▇▆▅▇▇▃▇▆▇▇▆▆▆▇▇▁▆▆▆▅▅▆▅█▆▅▆▆▇▇▅▆▇▆
wandb:      eval/avg_mil_loss ▂▄▂▃▂▃▂▃▃▂▂▂▃▃▂▂▃▂▂▂▂▂▂█▁▂▂▃▃▃▃▁▂▂▂▂▂▁▂▂
wandb:       eval/ensemble_f1 ▆▅█▆▇▇▇▆▅██▇█▆▇▇█▇▆▆█▆▆▇█▁▅▅▆▅▄▇▆█▇▇▅▆▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▃▄▂▃▃▃▄▇▅▅▁▃▃▃▃▄▄█▄▆▄▇▆▃▄▃▁▅▄▅▄▄▆▆▃▆▆
wandb:      train/ensemble_f1 ▂▅▅▄▄▄▁▃▄▅▄▄▄▅▅▄▅▃▄▄▃▄▅▇▄▆▇▆▆▄▅▅▅▅▄▅▆█▄▄
wandb:         train/mil_loss ▁▂▅▄▄▅▄▃▃▄▇▄▂▃█▆▇▂▁▃▄▃▂▆▂▆▅▂▃▂▆▆▆█▃▃▁▄▄▁
wandb:      train/policy_loss ▅▆▂▂▆▂▆▆▃▂▂█▃▂▆▂▂▆▃▇▆█▇▆▆▅▆▆▁▆▆▆█▃▂▆▇▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▂▆▃▆▆▆▃▂▂▂▆▆▂▃▃█▂▇▆█▇▆▅▆▆▁▆▂▆█▃▆▂▆▇▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.22958
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.28722
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.13289
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.90622
wandb:      train/ensemble_f1 0.90622
wandb:         train/mil_loss 0.25737
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i75bi9ff
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172722-i75bi9ff/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fi90sm43 with config:
wandb: 	actor_learning_rate: 3.332377943687833e-06
wandb: 	attention_dropout_p: 0.4782396582074996
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9041280348356177
wandb: 	temperature: 2.3742575768622376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172819-fi90sm43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fi90sm43
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss ▇█▅▁▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▇▆▆▇█▇▇▃▅▄▃▂▃▇█▂▇▂▃█▇▃▇▂▆▆▃▇██▃▇▄▅▅▆▄▁
wandb:      eval/avg_mil_loss ▁█▇▂▂▁▁▂▁▁▁▅▇▂▃▁▁▂▅▂▁▄▁▁▁▇█▁▇▁▁▁▂▄▃▁▁▁█▄
wandb:       eval/ensemble_f1 ▆▇▆▇▃▆▇█▇▂██▇▃▄█▂▂▇▆▆▆▇▇▃▁▅▆▂▆▆█▇█▆▇▂▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▄▄▆▃▆▆▅▆▅▆▅▅▆█▆▅▅▁▅▃▃▅▅▅▆▇▆▆▆▇▃▄▅▅▄▇▅▅
wandb:      train/ensemble_f1 ▆▄▇▆▆▄▅▂▅▅▄▅▆▅█▅▁▅▃▃▄▅▅▆▂▅▆▆▃▅▇▅▃▄▄▅▄▇▆▅
wandb:         train/mil_loss ▃▃▃▄▂▃▃▄▄▄▄▅▃▂▄▇▆▃▃▆▂▆▇▂▅▂▅▅█▆█▄▄▃▁▇▄▆▇▄
wandb:      train/policy_loss ██████████████████████████████████████▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▆█▃▆▄▂▆▇▁▆▆▆▃▆▆▂▃▇▆▆▇▆▆▇▆▆▁▃▆▇▆▆▆▄▄▂▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.21486
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.74383
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.71591
wandb:      test/avg_mil_loss 1.13237
wandb:       test/ensemble_f1 0.71591
wandb:           train/avg_f1 0.85993
wandb:      train/ensemble_f1 0.85993
wandb:         train/mil_loss 0.32756
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fi90sm43
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172819-fi90sm43/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mivooypb with config:
wandb: 	actor_learning_rate: 7.048754150053934e-06
wandb: 	attention_dropout_p: 0.4558991042183192
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7903805838728926
wandb: 	temperature: 0.2864569475480694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173007-mivooypb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mivooypb
wandb: uploading history steps 45-61, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss █▄▆▁
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▅▂▅▅▅▆▅▇▅▅▇▁▄▆▆▆▇▅▇▇▅▆▇█▆▄▅▆▅▄▅▅▆▅▅▆▇▅▆▇
wandb:      eval/avg_mil_loss ▃▁▄▇▂▄▃▃▃▂▃▂▃▂█▃▁▂▂▃▃▃▂▂▃▂▄▃▁▄▄▂▂▃▃▃▂▂▃▂
wandb:       eval/ensemble_f1 ▆█▅▂▆▇▇▄█▅▆▆▅█▁▅▄▇█▇███▆▇▇▇▄▆▇▄█▅▅▆▇▅▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▄▃▄▄█▅▇▁▅▆▄▂▅▃█▇▂▄▆▃▅▃▇▇▅▃▆▄▃▃▄▄▅▆▃▃▃
wandb:      train/ensemble_f1 ▄▄▃▄▅▄▄▄█▅▇▅▁▇▅▄▃▅█▇▄▅▆▅▃▅▇▇▅▃▄▃▃▄▄▅▆▃▃▅
wandb:         train/mil_loss ▃▆█▄▃▆▇█▄▄▃▆▅▄▇█▅▂▄▃▇▂▃▆▄▅▅▅▃▁▅▆▂▅▃▄▃▂▃▄
wandb:      train/policy_loss ▃▂▆▂▆▆▁▂▂▅▃▃▃▂▆▃▃▂▂▂▃▆▅▆▃█▆▃▃▂▂▆▂▆▆▂▁▂▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▂▆▂▆▃▆▁▂▅▂▃▃▃▃▃▂▂▃▅▅▆▂█▆▃▂▂▁▆▆▂▂▂▁▃▂▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.18866
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.23945
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.10749
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89918
wandb:      train/ensemble_f1 0.89918
wandb:         train/mil_loss 0.23803
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mivooypb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173007-mivooypb/logs
wandb: Agent Starting Run: 1xeilaut with config:
wandb: 	actor_learning_rate: 0.0007186230960608165
wandb: 	attention_dropout_p: 0.11425631565813148
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6057573465838155
wandb: 	temperature: 0.002252039844322651
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173054-1xeilaut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1xeilaut
wandb: uploading history steps 157-164, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▅▅█▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▅▄▄▅▆▆▂▅▆▄▆▆▆▅▆▆▅▆▅█▄▆▁▆▅▅▇▆█▄▆▆▆▆▆▂▂▆▆▅
wandb:      eval/avg_mil_loss ▄▃▄▄▄▆▄▄▅▄▅▅▃▄▄▃▃▂▆▃▄▂▄▁▄▆▄▆▅▄▃▃▄▃▃▄▄█▄▄
wandb:       eval/ensemble_f1 ▅▅▅▆▃▆▃▆▆▂▆▄▄▆▆▁▆▆▆▆█▅▆▆▇█▅▆█▇▆▇▆▆▆▆▆▅▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▇▆▄▆▅▅▅▁▆▆▆▇▆█▅▅▅▄▆▆▆▅█▆▄▇▄█▆▃▆▅▇▄██▆
wandb:      train/ensemble_f1 ▅▂▅▅▅▃▅▄▄▇▂▄▃▁▆▃▄▂▄▅▇▅▃▄▃▇▆▆▄▂▃▂▁▄█▆▃▂▅▅
wandb:         train/mil_loss ▂▄▃▃▄▃▃▃▅▄▄▆▂▂▆▂▅▃▂▁█▃▄▅▂▅▃▂▃▄▅▃▃▁▄▂▅▃▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.20534
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.27869
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.15342
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.90499
wandb:      train/ensemble_f1 0.90499
wandb:         train/mil_loss 0.24901
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1xeilaut
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173054-1xeilaut/logs
wandb: Agent Starting Run: hv3t3m2a with config:
wandb: 	actor_learning_rate: 0.0009434635137342204
wandb: 	attention_dropout_p: 0.3246056847172384
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8023258660424364
wandb: 	temperature: 8.628824383795473
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173233-hv3t3m2a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hv3t3m2a
wandb: uploading history steps 150-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▅▂▂▂▁▁▂█▇▂▄▂▃▂▅█▂▂▄█▁▁▁▂█▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂
wandb:      eval/avg_mil_loss ▅▁█▆███▆█▆▇█▃▁█▁▇▁██▃█▁▇█▇█▄▁▂▃▁▇▂▇▇▆▆▇▆
wandb:       eval/ensemble_f1 ▂▂▄▂▄▂▇▂▁▁▁▂█▇▇▂▃▂▃█▁▂▅▂▂█▂▂▁▂▄▂▂█▄▂█▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▇▄▃▂▂▇▄▅▆▄▂▄▅▇▄▄▇▄█▅▄▃▄█▃█▂▇▇▄▄▃▇▄▂▆▆▇
wandb:      train/ensemble_f1 ▂▅▃▄▁▃▃▄▅▃▄▂▅▃▅▅▂▄▅▅▃▄▄█▄▅▅▄▃█▆▅▆▁▆▇▄▁▆▇
wandb:         train/mil_loss █▅▃▄▆▇▇▆▅▄▅▇▅▇█▄▄▆▅▆▇▅█▄▇▃▁▇▆▅▅▃▆▅▆▅▆▅▆▅
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁█▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.3484
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 1.5769
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.13407
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.72268
wandb:      train/ensemble_f1 0.72268
wandb:         train/mil_loss 1.17743
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hv3t3m2a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173233-hv3t3m2a/logs
wandb: Agent Starting Run: akh1fzl9 with config:
wandb: 	actor_learning_rate: 2.3952725676803727e-06
wandb: 	attention_dropout_p: 0.04493580530824853
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04671020250683344
wandb: 	temperature: 5.120537230472565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173411-akh1fzl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zez9ea2r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akh1fzl9
wandb: uploading history steps 50-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▆█▇▇▇██▅▇▇▇▇▇▇▇▇█▆▅▇▇▇▅█▇▇▆▇█▁▅▇▇▇██▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▄▁▁▁▁▁█▁▁▁▁▁▁▁▄▁▁▁
wandb:       eval/ensemble_f1 ▂▇▆▆▆▇▆▇▁▆▆▆▆▆▇▆▆▆▆█▆▆▆▆▇▆▆▄▇▆▆▁▁▆▆▇▆▁▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▃▇▅▃▃▅▆▇▃▆▇▁▆▆█▄▃▇▆▇▅▅▆▆▇▅▅▄▆▆▇▆▆▇▇▅▃▆
wandb:      train/ensemble_f1 ▄▄▃▆▅▃▃▆▇▇▆▇▇▁▇▅▆▅▄▃▅▆▇▅▅█▅▆▅▄▆▆▇▆▇▅▄▁▃▆
wandb:         train/mil_loss ▂▂▄▂▂▄▂▃▁▆▂▃▆▆▂▄▃▁▂▂▆▁▂▄▃▂▂▂▂▂▅▂▂▁▄█▂▃▃▆
wandb:      train/policy_loss ▄▄▃▃▃▃▃▃▃▃▃█▃▃▄▃▃▃▄▃▄▄▄▃▃▃▃▁▃▃▃▁▆▄▃▃▄▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▃▃▃▆▃▁▃▃█▃▃▃▃▃▃▄▃▃▃▄▄▄▃▃▃▁▃▁▃▃▆▃▄▄▃▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.28107
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.29185
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11691
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88159
wandb:      train/ensemble_f1 0.88159
wandb:         train/mil_loss 0.51782
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akh1fzl9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173411-akh1fzl9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: pqhvfkco with config:
wandb: 	actor_learning_rate: 7.107987136475118e-06
wandb: 	attention_dropout_p: 0.011783979063523964
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1785087069840945
wandb: 	temperature: 5.481704013191519
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173507-pqhvfkco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqhvfkco
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 100-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ███▇███▃████▂████▃██▅█▃█▃▄██▃███▁█▂████▇
wandb:      eval/avg_mil_loss ▁▁▁▁▆▄▆█▁▁▁▁▁▁▅▅▁▁▄█▁▁█▂▁▆▁▁▁▁▁▆▁█▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▂██▃▇█▇██▁▆▇▂▂▂██▄▄█▂▂██▃█▇██▂▂▃██▁██▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▆▁▃▅▄▄██▆▇▆▆▆▂█▅▆▆▃▆▅▇▄▇▅▆▆▄█▅███▆█▅▆
wandb:      train/ensemble_f1 ▆▆█▁▆▆▆█▄▆▄█▆▄▆▅▄▄▅█▃▆▅▄▆▅▅▆▅██▆▄▅▅▆█▆▆▄
wandb:         train/mil_loss ▃▅▃▅▁▃▅▄▇▂▂█▁█▃▅▅▂▁▅▄▇▃▅▃▃▄▁▄▁▃▄▄█▆▆▄▃▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30733
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.28368
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.694
wandb:      test/avg_mil_loss 0.79615
wandb:       test/ensemble_f1 0.694
wandb:           train/avg_f1 0.68458
wandb:      train/ensemble_f1 0.68458
wandb:         train/mil_loss 0.50724
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqhvfkco
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173507-pqhvfkco/logs
wandb: Agent Starting Run: lk7fbq8b with config:
wandb: 	actor_learning_rate: 1.0228152528506077e-06
wandb: 	attention_dropout_p: 0.4045479275809317
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.531456644192086
wandb: 	temperature: 0.08095563272218387
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173619-lk7fbq8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lk7fbq8b
wandb: uploading history steps 74-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ▇█▃▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▇█▇██▂▂▂█▇▇▂▂▇█▇█▂▃▇▇█▃▃▇▃▇▇▇▇▇▁▇▂█▄█▇▅▇
wandb:      eval/avg_mil_loss ▁▁▂▂▁▁▂▁▁▂▁▁▇▁▁▁▁▁▁▂▁▁▁▁▂▅▁▁▁▁▇▁▁▁▅█▁▄▁▃
wandb:       eval/ensemble_f1 █▇▇███▂▂▇█▇▇▇▇▇▇▇█▂▇▇▇▇█▇▇▇▇▇▇▁▂▇█▇██▄█▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▅▄▇▆▃▆▃▇▁▃▅▁▄▅▅▄▅▅▂▄▅▃▄█▆▂▆▄▇▂▆▅▇▆▁▄▅
wandb:      train/ensemble_f1 ▄▅▄▅▅▇▆▅▃▄▆▆▅▃▂▃▄█▅▅▄▆▁▅▄▄▆▇▇▃▄▄▇▃▅▇▆▁▄▆
wandb:         train/mil_loss ▅▆▁▆▄▅▅▂▄▃▆▅▃▄▂▆▄▂▃▅▅█▄▅▃▁▃▄▇▄▅▃▅▅▃▁▂▁▄▇
wandb:      train/policy_loss ▃▁▁▁▆▁▁▁▁▆▆▃▁▃▃▃▃▁▁▁▆▆▁▃▃▆▃▁▃▆▁▁▆▃▁▃▃▃█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▁▁▃▃█▁▁▁▁▆▁▁▃▃▁▁▃▆▁▃▁▁▃▃▃▃▃▁▆▁▁▁▁▃▁█▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.18106
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.30871
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.1284
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.8694
wandb:      train/ensemble_f1 0.8694
wandb:         train/mil_loss 0.37782
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lk7fbq8b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173619-lk7fbq8b/logs
wandb: Agent Starting Run: iigy5klh with config:
wandb: 	actor_learning_rate: 2.1959757464879424e-06
wandb: 	attention_dropout_p: 0.3798906260460781
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8512505214146461
wandb: 	temperature: 7.990232543817739
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173721-iigy5klh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iigy5klh
wandb: uploading history steps 99-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇█▇▇▇▄▆▇▇▇▆▇▇██▇▇▇▇▁▇▆▇▇▇██▇▇▇▇▇▇█▂▂█▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▂▁▃▂▁▁▁▂▁▂▂▂▁▁▁▂▂▁█▁▁▃▁▂▂▁▁▁▁▁▁▁▁▁▂▁▂
wandb:       eval/ensemble_f1 █▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇▆▇▇█▇▆█▇▇▇▇▇█▇▇█▇▁█▇█▆▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▄▇▂▅▆█▆▇▅▆▄▇▅▆█▆▄▁▆▆▆▇▄▅█▅▇▇▅▆▅▆▄▆▆▃▇
wandb:      train/ensemble_f1 ▆▅▁█▇▆▃▇▇▄▂▇▆▆▆█▅▃▄▇▄▆▄▆▆▄▅▇▃▆▅▇▁▆▆▅▆▇▆▅
wandb:         train/mil_loss ▂▆▅▄▄▂▅▄▄▃▂▄▅▄▄▄▃▁▃▁▃▂█▃▂▂▆▅▃▃▂▃▄▄▁▃▄▂▅▅
wandb:      train/policy_loss ▆▁▃▅▆▁▆▆▃▅▅▁▅█▅▆▆▃▁▅▆▃▆▆▃▅▅▆▃▅▁▆▆▆▆▆▃▁▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▃▃▆█▆█▃▁▆███▁▃▃▃█▃█▃▆▃▃█▁▆█▃█▁████▆███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.19161
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.3746
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.16996
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.87875
wandb:      train/ensemble_f1 0.87875
wandb:         train/mil_loss 0.38894
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iigy5klh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173721-iigy5klh/logs
wandb: Agent Starting Run: 66fp00fh with config:
wandb: 	actor_learning_rate: 0.0005491953946722533
wandb: 	attention_dropout_p: 0.4271813053091898
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9694267497011504
wandb: 	temperature: 6.477624782982345
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173829-66fp00fh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66fp00fh
wandb: uploading history steps 78-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃██
wandb: best/eval_avg_mil_loss ▆▇▇█▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃██
wandb:            eval/avg_f1 ▂▁██▂▁▁▂█▂▂██▁▆▂▇█▇▃▃▂▂▇▂▂▂▂█▂▂▆▄▁▂▁▂▁▂█
wandb:      eval/avg_mil_loss ▆▇▇▇█▂██▇▁▇▂▁▇▇▃▁▅█▅▁▇▇▁█▁▅▁▁▄▇▇▁▁▄█▆█▅▅
wandb:       eval/ensemble_f1 ▂▇▂▁▄▄▂█▁█▂▂▂█▄▇▃▂▃▂▂▆▃▂█▂▂▂▂▆█▂▂▂▄▂▂▃█▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▄▄▆▄▅▄▄▅▄▄▇▅▆▄▅▅▅▅▅▁▆▅█▄▆▃▃▇▅▄▄▃▅▄▅▅▆
wandb:      train/ensemble_f1 ▄▅▄▄▄▇▁▄▃▅▃▄▇▄▅▇▄▅▅▄▆█▃▃▂▆▂▂▅▄▄▄▃▃▂▄▃▆▃▆
wandb:         train/mil_loss ▇▃▇▅▃█▇█▆▄▃▂▃▁▇▄▅▆▆▂▆▃▆▃▇▂▄▃▄▃▅▂▆▃▁▃▃▂▁▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.28315
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 1.99995
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.51668
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.79007
wandb:      train/ensemble_f1 0.79007
wandb:         train/mil_loss 0.66411
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66fp00fh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173829-66fp00fh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ph2tm0dq with config:
wandb: 	actor_learning_rate: 1.5077562345053747e-05
wandb: 	attention_dropout_p: 0.3428438271151309
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5156187933840569
wandb: 	temperature: 5.321125607350693
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173932-ph2tm0dq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph2tm0dq
wandb: uploading history steps 92-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 █▄▇▇▄▇▄▅▅▅▅▇▆▄▇▁██▅▂▇████▅▆▇▅█▅▅▇▅▆▇█▇▇▇
wandb:      eval/avg_mil_loss ▂▁▁▂▁▄▁▇▁▃▁▁▁▂▁▇▂▃▁▁▃█▁▁▁▃▄▇▆▆▆▃▁▃▂▁▆▁▁▁
wandb:       eval/ensemble_f1 ▇▇▅█▅▇▄█▇▅▇▇▄▇▁▇██▅▅▅▅▇▇▅█▇▅▄▇▅█▇▅▅▆▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▆▄▆▄▄▆▆▆▅▆▇█▅▄▆█▆▅█▄▆▆▆▆▅▇▃▄▄▅█▆▅▅▄█▁
wandb:      train/ensemble_f1 ▆▅▅▄▃▅▅▄▅▄▄▅▅▃▄▆▅▆▅▅▃█▆▄▄▅▇▇▃▃█▁▅▅▆▇▃▆▄▃
wandb:         train/mil_loss ▆▅▇▅▆▅▃▅▆▃▆█▅▃▇▅██▃▁▁▁▆▆▃▂▄▄▃▁▆▃█▅▁▂▃▃▇▄
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄▄▄▂▄█▅▁▇▄▇▇▂▇▅█▄▇▇▇▇▇▄▄▇▇▂▂█▇▅▄▇▄▇▄▄▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.23654
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.27592
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.17642
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.72337
wandb:      train/ensemble_f1 0.72337
wandb:         train/mil_loss 0.48712
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph2tm0dq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173932-ph2tm0dq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c5ft6ofp with config:
wandb: 	actor_learning_rate: 5.9170624198956855e-06
wandb: 	attention_dropout_p: 0.3966037086739386
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6204036978976087
wandb: 	temperature: 3.3728982880197913
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174058-c5ft6ofp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5ft6ofp
wandb: uploading history steps 124-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▇█
wandb: best/eval_avg_mil_loss █▃▂▃▁
wandb:  best/eval_ensemble_f1 ▁▅▆▇█
wandb:            eval/avg_f1 ▇▂▃▇█▆██▇▂▇█▂▂▅▂▆▇▆▁█▆▅▁▇██▂█▃▇████▇█▂██
wandb:      eval/avg_mil_loss ▁▂▄▁▁▆▁▁▁▁▁▁▁▁▃▂▁▁▁▁▁▁▁▆▁█▁▁▇▁▁▇▁▁▂▁▁▂▅▁
wandb:       eval/ensemble_f1 ▇█████▆▂▁█▃▇███▂▆▇▇██▇▁▇▇█▇█▁███▁▃█▂▇██▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▇▂▄▆▆▄▇▃▃▇▆▅▇▆▆▁█▃█▅█▇▇▇▇▇▅▃▆▅▇▃▄▄▅▇▆
wandb:      train/ensemble_f1 █▃▄▅▅▁▄▄▃▇▅▇▆▆▆▇▅▇▆▄▃▄▄▇▅▆▇▆▆▄▂▆▄▃▅▇▃▃▅▃
wandb:         train/mil_loss ▃▂▆▅▄▃▃▁▃▄▄▃▅▃▂▂█▁▃▄▄▅▅▅▆▄▄▁▃▅▅▄▃▃▆▃▆▁▅▁
wandb:      train/policy_loss ▄▃▃▄▃▃▄▃▄▄▃▄▄▆▃▁▃▄▃▆▃▃▃▄▃▃▄▆▃▃▃█▄▄▃▆▄█▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄█▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.27621
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.30656
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.1893
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.79075
wandb:      train/ensemble_f1 0.79075
wandb:         train/mil_loss 0.79571
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5ft6ofp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174058-c5ft6ofp/logs
wandb: Agent Starting Run: 2bqazki0 with config:
wandb: 	actor_learning_rate: 1.1736597380355444e-06
wandb: 	attention_dropout_p: 0.3936137806409359
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3167296271132678
wandb: 	temperature: 3.240484957731277
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174221-2bqazki0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2bqazki0
wandb: uploading history steps 91-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▅▇█▃█▅▅▄▇█▇▇▇▁█▅▇▅▇▅▇▅▇▅▇▇▆▆▇▇▅▄▅▇▅▇▇█▇▆
wandb:      eval/avg_mil_loss ▂▃▁▁▅▆▃▂▁█▅▁█▁▁▂▅▂▆█▇▄▂▅▆▁▁▃▂▅▂▂▆▂▁▂▂▆▃▂
wandb:       eval/ensemble_f1 ▆██▅▄▇▄█▇▅▇▇▄▇▅▅▅▇▁▅▅▇▅▄▇▄██▇▇▇▇▅▆▄▅█▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▂▅▄▅▆▅▃▅▂▂▃▆▆█▄▇▇▆▆▇▄▄▃▇▃▄▅▃▇▃█▆▅▄▆▅▁
wandb:      train/ensemble_f1 ▁▄▅▆▇▃▆▇▅▂▄▄█▄▅█▄▇▆▆▄▃▆▆▇▄▄▃▇▅▇▂▂█▄▅▅▅▄▅
wandb:         train/mil_loss ▂▁▄▂▄▇▇▅▂▆▂▆▃▆▂▅▅▅▁▂▂▃▃▃▂▁▅▆█▅▄▄█▄▇▆▅▅▆▃
wandb:      train/policy_loss ▄▂▅▂▇▅▄▄▅▇▅▄▄▅▁▄▄▂▁▇▅▅▅▄▇▅▅▄█▅▂▂▅▅▅▁▁▂▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▇▁▅▅▄▅▄▅▅▅▅▄▂▁▄▂▅▇▅▅▁▄▄▅▅█▄▅▄▅▂▅▂▁▅▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.23117
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.25739
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.78998
wandb:      test/avg_mil_loss 1.20662
wandb:       test/ensemble_f1 0.78998
wandb:           train/avg_f1 0.86418
wandb:      train/ensemble_f1 0.86418
wandb:         train/mil_loss 0.64312
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2bqazki0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174221-2bqazki0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vtafoyrw with config:
wandb: 	actor_learning_rate: 1.8549446896282291e-06
wandb: 	attention_dropout_p: 0.2133012687396239
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08939518506493549
wandb: 	temperature: 4.627800723578036
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174349-vtafoyrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vtafoyrw
wandb: uploading history steps 91-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▂▁▂▃▁▂▁▆▆▅▆▂▂▂▃▂█▃▂▆▂▅▂▁▃▂▂▁▅▃█▆▂▂▅▅▆▂▂▂
wandb:      eval/avg_mil_loss █▁█▅▇▃▆▃▄█▇▇▄▇▇█▆▇▆▅▁▇▅▄▄▅▇█▄▃▅▆▃▇▅▆▇▆██
wandb:       eval/ensemble_f1 ▂▂▁▁▁▂▅▂▂▁▁▂▂▃▅▁▂▂█▆▅█▅▅▁▅▂▅▂▅▅▂▂▃▅▂▂▅▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▆▄▄▃▄▃▅▄▅▅▂▃▅▄▇▆▅▄▂▇▄▃▄▂█▇▄▄▄▅▁▆▅▂▅▅█
wandb:      train/ensemble_f1 ▅▇▁▃▃▅▃▇▃▅▆▄▇▃▄▄▄▅▄▅▃▃▄▄▃▆▃█▅█▄▄▅▆▁▄▄▅▅▄
wandb:         train/mil_loss ▆▄▄▄▆▃▆▇▆▄▄▃▃▃▃▅▇██▇▃▆▁▄█▆▅▂▃▃▄▇▅▂▂▅▆▅▃▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅█▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.31142
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.29713
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.74937
wandb:      test/avg_mil_loss 1.52167
wandb:       test/ensemble_f1 0.74937
wandb:           train/avg_f1 0.75043
wandb:      train/ensemble_f1 0.75043
wandb:         train/mil_loss 1.39532
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vtafoyrw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174349-vtafoyrw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ld9d00um with config:
wandb: 	actor_learning_rate: 2.628338019171699e-06
wandb: 	attention_dropout_p: 0.3921996492893019
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41925847139312256
wandb: 	temperature: 2.7877216053679685
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174523-ld9d00um
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ld9d00um
wandb: uploading history steps 100-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▁▇▇▆█▇██▇▂▇▇▇▇█▆▇▇▇█▇▇▆▇▆▇▇▆█▆▇▆██▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▂▂▁▁▁▁▂▁▁▂▆▁▂▁▁▂▁▁▂▁▁▁▁▂▁▁▁█▂▁▁▁▁▁▁▂▁
wandb:       eval/ensemble_f1 ▃███▇▇███▇██▄█▇█▇██▇███▇▇████▇▁▇██▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▇▄▄▄█▆▆▆▇▂▇▄█▅█▂▅▆▄▂▅▄▅▃▇▆▁▇▇▄▇▆▆█▄▁▇
wandb:      train/ensemble_f1 ▅▆▆▆▅▄▄▃▅▅▃▃▅▃▄▂▄▂▄▅▃▅▄▂▅▆▅▆▄▃▇▆▂▆▅▁▃▅▅█
wandb:         train/mil_loss ▁▂▄▃▂▁▂▄▁▄▅▅▃▃▄▃▂▄▄▂▁▂▄▃▆▄▇▆▃▃▄▂▃▂▇▇▁█▂▂
wandb:      train/policy_loss ▅▆▃▅▃▅▃▃▃▃▅▃▅▅██▃▃▃▃▆▃█▁▃▃██▃▃▃▅▃▃▆▁▃▆▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▄▃▃▃▄▁▃▄▄▄▃▃▃▃▃▆█▁▃▃██▃▃▄▃▃▃█▃▃▆▃▃▄▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.29894
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.86999
wandb:      eval/avg_mil_loss 0.35266
wandb:       eval/ensemble_f1 0.86999
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.13264
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.8975
wandb:      train/ensemble_f1 0.8975
wandb:         train/mil_loss 0.24419
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ld9d00um
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174523-ld9d00um/logs
wandb: Agent Starting Run: gh5ku6kk with config:
wandb: 	actor_learning_rate: 1.1428447855944209e-06
wandb: 	attention_dropout_p: 0.3736228428097008
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4775214778296912
wandb: 	temperature: 2.8107173896824165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174638-gh5ku6kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gh5ku6kk
wandb: uploading history steps 125-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss ▆█▂▁▂
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▇██▇█▁▇▇▇█▇▇███▇▇██▇██▇▇▇█▇█████▂▇▇██▇█▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▄█▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▃▁▁▁▁▁█▁▁▁▁
wandb:       eval/ensemble_f1 ██▇██▃█████▁███████▅█████████▄█████████▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆█▅▄▄▆▃▅▇▃▅▅▂▄▅▂▆▁▅▄▇▅▁▃▁▇▇▄▄▁▅▄▃▇▇▆▆▆▆
wandb:      train/ensemble_f1 ▄▄▇▅▇█▆▇▆▃▇▇▇▆█▇▇▇▇▇▆▁▅▅▆▇▇▇▆█▆▇▆▇▇▇▆▇▃▆
wandb:         train/mil_loss ▂▁▁▆▂▂▂▅▂▃█▂▆▄▄▄▂▂▂▇▂▂▂▂▂▂▄▂▂▄▂▆▃▄▇▅▁▄▃▁
wandb:      train/policy_loss ▅▆▃▁▃█▃▅▁▃▃▁▁▃▃▃▁▃▁▃▃▃▃▅▃▃▅▃▆▃▃▃▃█▃▅▅▃▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▁▃▅▃▁▅▃▆▃▅▅▆▁▃▁█▁▃▃▃▃▅▅▃▅▅▁▅▃▃▅▃▃▃▃▅▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.26352
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.27606
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.90927
wandb:      test/avg_mil_loss 0.22008
wandb:       test/ensemble_f1 0.90927
wandb:           train/avg_f1 0.8998
wandb:      train/ensemble_f1 0.8998
wandb:         train/mil_loss 0.36124
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gh5ku6kk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174638-gh5ku6kk/logs
wandb: Agent Starting Run: f4i5bt8b with config:
wandb: 	actor_learning_rate: 1.1054038137375035e-06
wandb: 	attention_dropout_p: 0.4717543019022221
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7335593676819044
wandb: 	temperature: 0.6594174556147936
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174805-f4i5bt8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4i5bt8b
wandb: uploading history steps 99-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▇█▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃██▆▂▂▄▇▇▇▄▇██▃██▇█▃▁▇▃▇▂▂▂▄▆▇███▂█▇██▇▇
wandb:      eval/avg_mil_loss ▁▄▂▅▂▃▅▂▂▂▁▂▂▂▂▁▁▂▂▂▅▂▁▄▂▁▄▁▂▁▅▂▃▁▂▁▃▁▃█
wandb:       eval/ensemble_f1 ▇▃▆▄▇▇▂▄▇▇▇▄▇▃▇▇▇▁▇▇▇▂▇▆▇▆▇▇▇▇▇▂▇▇▇▇▆█▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▅▇▇▆█▅▇▄█▆▅▇█▆▅▅▇▆▄▆▆▇▆▆▆▆▁▅▆▅▆▅██▅▆▆▇
wandb:      train/ensemble_f1 ▇▆▄▄▇▆█▆▇▅▂▇▅▇█▇▆▄▆▇▃█▁▇▇▅▅▅▆▅▅▅▅▇▆▅▄▅▅▅
wandb:         train/mil_loss ▅▂▇▇▁▆▁▄▄▃▃▆▅▃▃▄▃▁█▄▅▆▄▂▆▂▇▇▄▅▇▅▆▃▃▁▃▃▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▃▃▃▃▃▁▆▁▁▁▁▃▃▁▁▁▁▁▁▁▃▁▃▁▃▁█▁▆▁▆▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▁▆▁▃▃▃▃▆▃▁▁▆▁▁▁▃▁▁▁▁▁▁▆▁▁▁▃▁▁▁█▁▆▃▁▁▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.20279
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.71062
wandb:      eval/avg_mil_loss 0.82726
wandb:       eval/ensemble_f1 0.71062
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.14211
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.82464
wandb:      train/ensemble_f1 0.82464
wandb:         train/mil_loss 0.75168
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4i5bt8b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174805-f4i5bt8b/logs
wandb: Agent Starting Run: e2ippaye with config:
wandb: 	actor_learning_rate: 4.681567245035807e-06
wandb: 	attention_dropout_p: 0.40893157888219506
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.871978178462864
wandb: 	temperature: 5.727407706004359
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174924-e2ippaye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2ippaye
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▄▅▇▅▄▄█▄▅▄▅▅▇█▄▄▂▅▄▅▄▂▄█▅▁▄▅▄▇▄▅▁█▅▇▂▄▄
wandb:      eval/avg_mil_loss ▇▄▄▅▃▄▅▁▅▁▅▃▅▅▅▄▆▄▄▄▆▅▅▅▄▅▅▄▂▆▇▆▃▇█▆▄▄▄▁
wandb:       eval/ensemble_f1 ▂▃▃▂▃▇▅▄▆▃▇▃▃▅▆▃▃▂▄▃▃▂▄▃▄▄▅▁▃▄█▃▅▃▅▄▁▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▁▆▅▄▃▇▃▅█▅▆▃█▅▆▂▇▄▄▇▅▄▅▃▆▅▄▄▅▄▇▆▇▁▇▆▄▇
wandb:      train/ensemble_f1 ▄▄▅▁▃▆▅█▄█▃▆▆▆▆▄▅▇▇▆▅▃▆▅▅▅▇▅▅▆▇▄▇█▅▃▆▆▄▇
wandb:         train/mil_loss ▃▁▃▅▂▃▄▂▃▃▄▃▆▄▁▃▄▆▅▂▃▂▄▄▄▄█▃▃▅▃▁▂▂▂▃▄▄▃▁
wandb:      train/policy_loss ▃▁█▅▁▆▃█▃▃▃▃▆▃▃▃▆▆▁▃▆▃▁▆▃▁▆▃▆▅▆▃▃▆▅▅▆▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃██▃▃▃█▆▃▃▆▃▃▃▆▆▃▆▃▁▆▆▁▆▃▆▃▆▃▆▁▃▃▄█▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.26761
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32188
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.40251
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.89
wandb:      train/ensemble_f1 0.89
wandb:         train/mil_loss 0.31416
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2ippaye
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174924-e2ippaye/logs
wandb: Agent Starting Run: 8twkyrdr with config:
wandb: 	actor_learning_rate: 3.993607354187329e-06
wandb: 	attention_dropout_p: 0.4207554358862422
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5045485213990585
wandb: 	temperature: 3.944264926671446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175031-8twkyrdr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8twkyrdr
wandb: uploading history steps 75-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▃▂▂█▇▂▂▂▇▇▂▇███▁▇▅▃▃▃▆▄▁▆▂▇▂▂▂▇▇▂▇▇▅▅▂▁▆
wandb:      eval/avg_mil_loss ▁▁▁▃██▆█▇▅▁▇▇▁█▁▁▂█▅▆▂▂█▆▁▆▂▁▁▂▁▁▁▇▁▃▆█▅
wandb:       eval/ensemble_f1 ▃▂█▇▇▁▁▂█▇▂█▇█▇▁▂▃▂▂▆▂▇▇▂▆▂▂▇▇▇▅▂▅▅▇▁▂▂▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▅▃▇▅▅▃▃█▃▆▆▅▄▄▄▅▆▂▄█▆▅▅▃▄▁▇█▄▅▅▅▄▂▃▂▄
wandb:      train/ensemble_f1 ▃▄▆▂▇▅▂▃▅▆▄▅▂▅▄▆▄▄▅▅▂█▇▅▃▄▃▆▆█▄▆▅▅▆▃▂▅▂▁
wandb:         train/mil_loss ▄█▅▅▆▄▃▅▄▂▂▄▆▆▂▄▆▄▄▃▃▃▄▆▃▇▇▅█▇▅▃▆▅▁▄█▅▂▇
wandb:      train/policy_loss ████████████████████████████████▁███████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▁█▁▃▆▁▁▃▃▃▁▁▃▁▃▃▆▃▆▁▃▃▁▃▃▃▆▃▆▁▆▁▁▆▃█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.25831
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.81935
wandb:      eval/avg_mil_loss 0.47642
wandb:       eval/ensemble_f1 0.81935
wandb:            test/avg_f1 0.82998
wandb:      test/avg_mil_loss 0.46474
wandb:       test/ensemble_f1 0.82998
wandb:           train/avg_f1 0.6938
wandb:      train/ensemble_f1 0.6938
wandb:         train/mil_loss 1.08507
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8twkyrdr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175031-8twkyrdr/logs
wandb: Agent Starting Run: amh8gi3s with config:
wandb: 	actor_learning_rate: 3.3438756111871015e-06
wandb: 	attention_dropout_p: 0.4007115833624245
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7476412091632532
wandb: 	temperature: 6.627094792485271
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175138-amh8gi3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/amh8gi3s
wandb: uploading history steps 100-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss ▇▁█▂▂
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▇▇▇█▇█▁▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▁█▁▇▇▁▇▇▄
wandb:      eval/avg_mil_loss ▁▁▇▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▇▁█▁▁▁▂▁▂▂▇▁▁▁▁▁▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▇▇▂▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▁▇▇█▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▅▄▃▁▇▆█▇▆▄▃▄▇█▅▅▆▆▇▇█▆▅▇▇▇▆▇▄▄▆▅▆▄▅▇▅
wandb:      train/ensemble_f1 █▃▅▄▄▆▆▅▅█▆▇▇▅▇█▄▇█▅▄▆▁▆▆▅▅▆▇▅▄▆▇▇█▂▅█▄▅
wandb:         train/mil_loss ▁▃▃▆▂▆▂▃▂▂▃▅▂▂▃▄▆▁▂▃▃▁▂▄▃▃▅▂▁▁▄▅▃▁█▃▃▄▂▂
wandb:      train/policy_loss ▃▃▄▃▄▄▃█▃▃▃▆▆▃▃▃██▃▄▃▃▁▆▃▃▆▃█▃▃▃▁▆▆▄▄▃▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▄▆▄▃▆▁█▃▃▄▆▃▄▃▆▃▄▃▄▄▃▃▆▃▄▃▃█▄▆▄▄▆▆▃▃▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.28216
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.99201
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.17381
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.85658
wandb:      train/ensemble_f1 0.85658
wandb:         train/mil_loss 0.2766
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/amh8gi3s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175138-amh8gi3s/logs
wandb: Agent Starting Run: ik8n8hpn with config:
wandb: 	actor_learning_rate: 3.422469108919504e-06
wandb: 	attention_dropout_p: 0.4274722618950627
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6546880205758472
wandb: 	temperature: 2.5708539365245664
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175301-ik8n8hpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ik8n8hpn
wandb: uploading history steps 75-80, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆█
wandb: best/eval_avg_mil_loss ▄▁▆██
wandb:  best/eval_ensemble_f1 ▁▁▃▆█
wandb:            eval/avg_f1 ██▆▃███▇▇▇▇█▆▇▇▇█▇█▇█▇▇██▂▇▇█▃█▁▂███▇█▇▇
wandb:      eval/avg_mil_loss ▂▃▁▁▁▁▁▂▂▁▁▂▂▂▁▁▁▁▁▂▂▁▁▁▂▂▁▁█▁▁▁▂▁▁██▁▁▂
wandb:       eval/ensemble_f1 █▆▁▃██▇███▇█▇█▇████▇▇██▇▂▇▃█▇██▇█▁██▇▂█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▇▁▇▆▆▇██▇▇▆▇▁▇▇▄▂▅▆█▇▆▇▆▇▅▆▅▇█▅▆█▇▅▄▇▇
wandb:      train/ensemble_f1 ▆▇▁▆▇▆▆▇▇▇▇▇▅▄▂▇█▄▅▇▆▅▆▇▅▇▇█▅▅▇▄▇▆▂▄▃▅▇█
wandb:         train/mil_loss ▂▃▁▂▂▂▁▃▆▄▇▃▂▂▃▂▄▂▁▃▁▂▂▁▅▁▂▂█▂▅▂▂▂▇▇▂▂▁▆
wandb:      train/policy_loss ▆▃▁▆▃█▃▃▆▃▁▃██▆▃▁▃▃▃▁▃▃▁▁▁▁▆█▆▁██▁▆▃▁▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▃▆▄███▄▄▁█▄█▄▄▃▄▄▄█▄▆▄▃▆██▃▆▆▆▆█▆▁▄█▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.34196
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.34684
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.36986
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.8887
wandb:      train/ensemble_f1 0.8887
wandb:         train/mil_loss 0.56295
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ik8n8hpn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175301-ik8n8hpn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qveyfggy with config:
wandb: 	actor_learning_rate: 2.3654068946081507e-06
wandb: 	attention_dropout_p: 0.37965668507517175
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9366842155407308
wandb: 	temperature: 6.009390572034912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175403-qveyfggy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qveyfggy
wandb: uploading history steps 124-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁█
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▃▁▁▇▁█▇█▇▁▂█▇▁▂██▁▁█▁▁▇███▂███▂▇▁██▂█▁▂
wandb:      eval/avg_mil_loss ▁▅▁▁█▇▁▁▆▆█▆▁▂▇▇▁▁█▁▁▁▂▅▁▆▂▆▆▁█▁▇▆▁▆▁▁▁▁
wandb:       eval/ensemble_f1 █▃█▂▂▂▂▇█▂▁█▂▂██▂███▂█▇▂█▇█▂▇█▂▂▂▄▂█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▃▁▃█▆▅▃▁▅▂▅▃█▅▅▄▆▆▄▃▄▅▄▇▃▆▁▁▇▅▇▅▆▅▄▅▆
wandb:      train/ensemble_f1 ▁▆▆▃▆▂▄▃▂▁▃▅▂▆▃▄▇▆▅▆▆▄▆▄▇▇▇▅▄▇▁▁▄▃█▆▄▆▅▆
wandb:         train/mil_loss ▆▄▃▄▆▅▄█▄▅▆▅▄▇▅▅▆▄▆▄▇▅▆▃▂▃▆▄▅▅▂█▅▅▁▅▄▅█▄
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.323
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.3024
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.1472
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.78603
wandb:      train/ensemble_f1 0.78603
wandb:         train/mil_loss 0.84089
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qveyfggy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175403-qveyfggy/logs
wandb: Agent Starting Run: ogz6vfo3 with config:
wandb: 	actor_learning_rate: 8.096669764376486e-06
wandb: 	attention_dropout_p: 0.33981455160866386
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9667597354946014
wandb: 	temperature: 5.760259399119376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175531-ogz6vfo3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ogz6vfo3
wandb: uploading history steps 99-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss ▆█▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▅███▇██▁███▃▁▂█▂▇█▁█▇▂█▃█▇█▇▃▂▄██▁▅▇███▇
wandb:      eval/avg_mil_loss ▁▁▂▂▁▂▂▇▅▅▁▇▁▁▆▁▁▁▁▁▁█▅▁▃▁▁▅▁▁▁▁█▅▄▇▁█▁▁
wandb:       eval/ensemble_f1 █▅███▅▆█▂▆▂▂▃██▂▃▅▇▁▄▄▇█▂█▁█▇▇█▅█▂█▇▁▆██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▅▄▆▅▅▆▇▆▅▇▅▅▅▄▆▇▅▅▁▇▃▇▄▆▁▄▆▅▆▆▅▆▆▆█▄▆▅
wandb:      train/ensemble_f1 ▆▆▄▅▇▄▆▄▅▇█▂█▅▄▅▃▅▅▆▆▆▆▅▄▃▅▆▁▇▇▇▅▆▅▇▅▇▇▆
wandb:         train/mil_loss █▅▅▆▅▇▄▅▇▅▃▄▄▄▃▂▅▆▁▅█▄▆▇▅▄▅█▃▆▁▆▅▄▆▅▅▂▆▅
wandb:      train/policy_loss ▆▆▆▃▆█▃▆▆▆▆████▆▆▇▆▃▆▆█▆▃▆▆█▆▃▆▃▃▃▆▁▆▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆██▁▆█▃▆▆█▃▃▆▆▆▆▁▆▃▃█▃▆▇▆▃▆▆▆▆▃▃▆▆▆▆▆▆▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.25751
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.33584
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.33535
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.76015
wandb:      train/ensemble_f1 0.76015
wandb:         train/mil_loss 0.85052
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ogz6vfo3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175531-ogz6vfo3/logs
wandb: Agent Starting Run: h16s2jzb with config:
wandb: 	actor_learning_rate: 1.3755587766007114e-05
wandb: 	attention_dropout_p: 0.39117148651756406
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8201556702674825
wandb: 	temperature: 5.1156252731295595
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175643-h16s2jzb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h16s2jzb
wandb: uploading history steps 99-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁██
wandb: best/eval_avg_mil_loss █▄▁▆
wandb:  best/eval_ensemble_f1 ▁▁██
wandb:            eval/avg_f1 █▆███▂▁█▇██▆█▇▃▃▄███▁█▇▂█▇▃▇████▇▄██▂▃█▆
wandb:      eval/avg_mil_loss ▁▂▁▄▆▁▁▇▆▁▁▁▁▁▇▁▇▁▅▁▁▁▁▆▁▁▁▂▅▁▃█▁▂▁▁▁▁▅▆
wandb:       eval/ensemble_f1 ██▂▁▁█▃███▂█▂▇█████▁█▂▁▇▃▇████▄▇█▇█▂█▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▇▇▅▄▁▅▆▆▃▆▆▄▂▇█▃▄▅▂▆▅▄▇▄▆▇▅█▅▆▆█▄▇▃▆█▄
wandb:      train/ensemble_f1 ▅▄▅▄▄▄▅▆▇▃▂▄▁▅▄▃▆▆▃▃▆▆▅▂▆█▃▅▅▅▅▇▇▃▅▄▃▅▅▄
wandb:         train/mil_loss ▄▅▂▅▆▂▁▅▃▃▂▆▂▆▂▃▄▂▃▁▃▂▂▅▄▄▃▆▂█▄▂▄▄▅▅▄▇▁▂
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▃▁▆▁▃▃▁▃▃▁▁▃▃▁▁▃▁▃▆▁▃▃▁▃▁▁▁▁▁▃▁▁█▁▃▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.28176
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.3691
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.19435
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.79731
wandb:      train/ensemble_f1 0.79731
wandb:         train/mil_loss 0.46246
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h16s2jzb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175643-h16s2jzb/logs
wandb: Agent Starting Run: cyqynmq4 with config:
wandb: 	actor_learning_rate: 7.005381881942328e-06
wandb: 	attention_dropout_p: 0.49927426534474567
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6330842032728788
wandb: 	temperature: 2.921567355649831
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175756-cyqynmq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cyqynmq4
wandb: uploading history steps 75-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▆▄▁█
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇▇███▂▃▇██▇▇▇▄█▇▇▇▇▇▇▂▁█▇▇█▁▇▇▃▇█▃█▇████
wandb:      eval/avg_mil_loss ▁▁▁▅▁▂▁▂▅▁▁▅▁▁▃▁▁▁▁▂▇▁█▁▁▂▁▇▂▇▁▅▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▇▆▇▃█▇█▇▇▄██▆▇▇▇▇▂▇▁▇██▁▇▃▄█▃███▇▂███▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▄▄█▃▁▇▅▆▄▇▂▇▄▄▄▁▇█▇▆▃▆▅▄▁▂▅▄▄▃▅▄▆▅▁▂▆
wandb:      train/ensemble_f1 ▃▅▃▄▅▅▄██▂▄█▇▆▆▃█▃▅▅▃▅▃▆▆▂▆▃▆▄▁▆▄▆▅▂▃▄▄▄
wandb:         train/mil_loss ▁▃▅▅▄▅▂▁▃▆█▃▃▅▅▄▄▁▂▄▄▄▄▃▂▃▃▃▆▃▃▁▂▆▄▄▅▄▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆█▃▆▃▆▃▃▆▃▆▁▆█▆▁██▃▆▆▃▃█▃▃▃▆▃▆▆▆▃▃▆▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.33999
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.32337
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.69183
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.85997
wandb:      train/ensemble_f1 0.85997
wandb:         train/mil_loss 0.58576
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cyqynmq4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175756-cyqynmq4/logs
wandb: Agent Starting Run: wh2b4rkr with config:
wandb: 	actor_learning_rate: 3.4089903844057184e-06
wandb: 	attention_dropout_p: 0.4617667200333856
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 161
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7836792280128555
wandb: 	temperature: 4.391667111279824
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175859-wh2b4rkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wh2b4rkr
wandb: uploading history steps 99-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇██
wandb: best/eval_avg_mil_loss █▃▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅▇██
wandb:            eval/avg_f1 ▃█▂▁▃██▂▂▃▂▄▃▃▃▄▂▂▂▂▂▃▃▇█▃▂█▇▇▂▃▁▂▇█▂█▄▃
wandb:      eval/avg_mil_loss ▁▇▅▁▁▇▁▆▄▁▅▆▁▁▁▆▆▇▁▆▇▆▁▂█▄▅▂▅▆▄▄▇████▁█▇
wandb:       eval/ensemble_f1 ▁▃█▁█▂▄▂▃▄██▂▃▂▂▃▃▃▇█▂▃██▇▃▇▂▂▂▁█▄▂██▂▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▅▄▅▆▅▅▆▂▅▄▂▄▅▄▃▇▄▄▅▄▁▁█▁▄▄▂▄▄▁▄▅▄█▆▆▄▆
wandb:      train/ensemble_f1 ▂▆▃▄▃▅▃▃▅▄▅▂▄▃▄█▅▁▆▇▄▅▁█▅▁▅▃▄▆▅▂▅▅▄▅▄▆▄▄
wandb:         train/mil_loss ▃▅▅▄▇▆▅▄▄▄▃▆▄▄▆▅▆▄▄▅▄▄▃▄▅▃▁▃▅█▄▄▄▆▅▃▃▃▁▇
wandb:      train/policy_loss █▄▃▃▃▃▃▆▃▃▁█▁▃▃▃▁▁▆▆▆▆█▃█▃▃▃▆▃▁▃▃▆▁▃▃▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▆▁▃▁▃▃▆▆▁█▃▁▃▃▆▄▁▁▁▃▃▆▆▁▃█▃▁▄▃▃▁▆▁▃▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.32144
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.57131
wandb:      eval/avg_mil_loss 1.4432
wandb:       eval/ensemble_f1 0.57131
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.70424
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.69192
wandb:      train/ensemble_f1 0.69192
wandb:         train/mil_loss 1.85315
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wh2b4rkr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175859-wh2b4rkr/logs
wandb: Agent Starting Run: 2ywkcgzq with config:
wandb: 	actor_learning_rate: 1.066537177984595e-05
wandb: 	attention_dropout_p: 0.23607450191518448
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8959015182898491
wandb: 	temperature: 7.615613952909643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180021-2ywkcgzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ywkcgzq
wandb: uploading history steps 123-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss ▆▁▄██
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▇▃▇▇█▃▇▁▇▇▇▇▅▆▂▇█▇▂▁▇▇█▅▆▁▇▅█▃▆▇▅▆▆▇▁▁█▇
wandb:      eval/avg_mil_loss ▁▂▂▁▃▃▇▄█▂▁▃▂▃▁▁▅▂▁▁▁█▃▅▅▇▁▄▁▄▁▂▁▁▂▆▄▁▁▁
wandb:       eval/ensemble_f1 █▄▇▁▇▁█▅█▂█▅▁█▃▆▅▂▅▂▇▃▅▃▆▇▁█▆█▂▆██▁█▆▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▇▂▃▇▄▅▃▂▃▆▄▆▃▇▁▃▆▄▆▅▇▄▅▆▄▂▆▃▂▆▅▇▅▃▅▅▂
wandb:      train/ensemble_f1 ▃▅▆▃▅▇▇▃▄▆▃▄▆▅▄▅▅▂▆▃▃▆▄▆▅▅▇▅█▄▇▇▅▅▄▆▃▁▁▃
wandb:         train/mil_loss ▆█▅▃▅▅▃▅▆▅▂▇▄▃▄▄▄▆▅▄▅▂▃▁▄▄▇▄▅▄█▆▅▄▄█▆▆▂▃
wandb:      train/policy_loss ▅▅▆▅▁▆▃▃▃▃▆▃▅▅▅▆▅▁▃▆▆▅▃▆▃▃▆▅▃▃▃▃▃▃▃█▅▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▆▃▄▆▆▄▃▃▆▄▃▆▆█▆▆▃▄▄▃▄▄▆▄▃▆▃▃▆▆▃▆█▆▃▆▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32985
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.28043
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.66628
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.73738
wandb:      train/ensemble_f1 0.73738
wandb:         train/mil_loss 0.53149
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ywkcgzq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180021-2ywkcgzq/logs
wandb: Agent Starting Run: h68eunag with config:
wandb: 	actor_learning_rate: 6.449447944617562e-06
wandb: 	attention_dropout_p: 0.307049375136036
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9756212444942438
wandb: 	temperature: 8.579484444917604
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180144-h68eunag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h68eunag
wandb: uploading history steps 90-97, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇██
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▅▇██
wandb:            eval/avg_f1 ▅▅█▅█▇▅▇▇▅▇▅▄▅▇▅▇▁▇█▇▇▂▇█▅▁▆▁▅▇▁▇▅▇▇▇▇▅▇
wandb:      eval/avg_mil_loss ▂▄▁▁▁▁▁▃▁▄▃▄▁▁▄▁▁▁▁▁▁▁█▃▃▃▁▁█▁▁▁▁▁▅▁▁▁▃▁
wandb:       eval/ensemble_f1 ▆▅▅▅█▅██▅▄▄▅███▇▅▇▂█▅█▅▅▅█▁█▅█▅██▅▆█▇▇▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▇▅▇▄▅▆▁▅█▆▆▃▇▆▆▆▁▃▃▆▅▄▄▇▅▅▅▃▂▆▆▅▄▆▄▃▅
wandb:      train/ensemble_f1 ▆▄▇█▇▅▆▇▆▅▆█▇▃▅▇▂▃█▆▇▅▅▄▇▅▄▅▅▆▇▁█▄▄█▃▄▇▆
wandb:         train/mil_loss ▁▇▇▄▄▂▆▂▆▅▁▁▇▆▆▆▅▄▄▆▆▄█▇▂▅▂▆▂▅▆▆█▄▄▇▅▆▄▂
wandb:      train/policy_loss ▃▅▃▇█▃▅▇▃▇▃▆▇▅▃▆▃▁▃▂▃▂▆▅▅▃▃▅▇▃▃▃▅█▃▃▆▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂█▅▄▇▂▁▅▇▄▅▇█▄▄▁▅▇▅▅▄▁▅▁▁▅▂▂▂▄▇▄▂▂▂▄▅▂█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.2121
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.26527
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.75962
wandb:      test/avg_mil_loss 1.43183
wandb:       test/ensemble_f1 0.75962
wandb:           train/avg_f1 0.81483
wandb:      train/ensemble_f1 0.81483
wandb:         train/mil_loss 0.49532
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h68eunag
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180144-h68eunag/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 34aslk83 with config:
wandb: 	actor_learning_rate: 9.60945651042219e-06
wandb: 	attention_dropout_p: 0.33062219795814396
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8591337210910628
wandb: 	temperature: 2.342650944307908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180302-34aslk83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/34aslk83
wandb: uploading history steps 74-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁████
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁████
wandb:            eval/avg_f1 ▁▂█▇▇▇▂████▇▃█▂█▃██▂▂▂▃█▄▄▃▂▂██▂█▃▂▂▂▄██
wandb:      eval/avg_mil_loss ▆▁▆▆▁▇▆▁▁▆▁█▆▁▁▁▁▇▁▁█▁▆█▆▁▃▂▇█▁▁▆▆▅▁▁▆▁▆
wandb:       eval/ensemble_f1 ▃▃▁▂▂▃█▇█▇▂███▂▇▃██▂▁█▂▁▂█▄▃▁██▃█▂▂███▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▄▅▄▆▅▁▅▅▆▅▆▂▆▆▂▅▄▁▅▁▄▄▃▅▅▅▃▄█▂▅▅▃▃▅▄▁
wandb:      train/ensemble_f1 ▄▃▃▃▂▄▄▄▄▄▅▃▅▆▂▂▅▂▅▄▅▄▁▄▄▅▄▆▄▅▄▅▅█▆▆▅▄▄▅
wandb:         train/mil_loss ▂▄▄▅▃▂▅▆▆▄▂▄▆▄█▄▇▂▅▄▂▅▅▄▅▃▁▄▅▄▄▆▃▃▅▃▆▃█▇
wandb:      train/policy_loss ▁▁▁▆▆▁▁▄▁▁█▁▄▄█▁▄▁▄▁▄▄▁▄▁█▄▁▁▄▆▄▄▁▄▁▄▄██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▁▆▃█▃▆▃▃▆▆▆▃▆▃▆▆▃▃▃▃▆▃█▃▆▃▃▆▆▃▃▃▆▃▆▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32993
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 1.79378
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.21424
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.77673
wandb:      train/ensemble_f1 0.77673
wandb:         train/mil_loss 1.27665
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/34aslk83
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180302-34aslk83/logs
wandb: Agent Starting Run: ms11f5sa with config:
wandb: 	actor_learning_rate: 5.829450630367692e-06
wandb: 	attention_dropout_p: 0.2777841842278374
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7658410734221984
wandb: 	temperature: 8.29531191611636
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180405-ms11f5sa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ms11f5sa
wandb: uploading history steps 122-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂███
wandb: best/eval_avg_mil_loss █▆▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂███
wandb:            eval/avg_f1 ▁██▃█▁▂▂▂▁████▂█▇▁█▇██▂█▁▄██▅▂██▂▁█▁▇██▂
wandb:      eval/avg_mil_loss ▆▂█▆▇▁▄▂▁▁██▂▁▆█▂▆▁▁▁▁▇▁█▆▁█▁▁▁▁▁▂███▂▇█
wandb:       eval/ensemble_f1 ▂▇█▇▂█▇▂█▁▃█▂▂█▂███▁██▂▂▄▇█▄▂█▅▂█▁▁▂██▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅█▅▁█▆▆▆▄▄▇▆▇▆▅▇▃▆▄▃▆▂▅▅▆▇▅▇▆▆▄▆▇▆▄▃▆▆▇
wandb:      train/ensemble_f1 ▂▅▇▆▄▆▅▅▅▇▃▇▂▁█▂▇▇▆▆▄▃▆▇▆▄▆▅▆▄▆▅▅▃▃▇▇▆▇█
wandb:         train/mil_loss ▄▅█▄▃▆▁▂▂▅▄▃▆▅▃█▄▇▃▅▅▄▄▄▁▃▃█▁▄▄▄▂▄▇▄▂▃▁▆
wandb:      train/policy_loss ▅▆▆▅▃▅▅▅▃▆▃█▆▃▅▅▅▆▅▅▆▅▅▅▅▅▁▃▅▃▅▅▅▃▆▆▅▅▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▆▅▆▆▅▃▃▅▁▅▃▃▅▃▅█▆▅▃▆▅▁▅▃▅▅▆▅▃▅▁▅▃▅▆▅▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.25729
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 2.03219
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.62795
wandb:      test/avg_mil_loss 0.72255
wandb:       test/ensemble_f1 0.62795
wandb:           train/avg_f1 0.74181
wandb:      train/ensemble_f1 0.74181
wandb:         train/mil_loss 0.47679
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ms11f5sa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180405-ms11f5sa/logs
wandb: Agent Starting Run: av25w128 with config:
wandb: 	actor_learning_rate: 6.224637922825339e-05
wandb: 	attention_dropout_p: 0.27927272880960435
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 69
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5356748401569515
wandb: 	temperature: 1.8582698123898111
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180533-av25w128
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/av25w128
wandb: uploading history steps 50-70, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▂█▂▂██▆▆▂▇▁▂▇▇▇▇▁█▇▇▇▇▁▂███▂██▇▇█▁▂▂▄▄▇
wandb:      eval/avg_mil_loss ▁▁█▁█▁▁▁█▄█▂▁▁█▁▁█▁▂▂▇▇█▁▁█▁▂▁▁▁▂█▆██▁▁▁
wandb:       eval/ensemble_f1 ███▂██▆▂▇▂▇▇▁▇▇▇▂▂█▇▇▇▃▂▂██▂▇▇██▇█▃▂▂▄██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▄▁▅▇▇▆▇▆▃█▅▇▅▄▄▄▆▄▆▇▇▄▅▇█▅█▃▂▅▇▅▆█▅█▅
wandb:      train/ensemble_f1 ▇▆▆▆▄▅▇▇▆▇▆▄▇█▅▇▄▄▇▆▇▅▆▇▅▇██▃▇▆▆▅▇██▇▁▄▅
wandb:         train/mil_loss ▆▄▃▆▄▂▃▄▄▄▄▄▂▄▄▃▄▃▄▆▄▂▃▄▇▄▆▃▅▆▁▆▃█▅▃▄▅▆▄
wandb:      train/policy_loss █████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.23339
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30412
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.88865
wandb:      test/avg_mil_loss 0.24819
wandb:       test/ensemble_f1 0.88865
wandb:           train/avg_f1 0.75154
wandb:      train/ensemble_f1 0.75154
wandb:         train/mil_loss 0.9245
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/av25w128
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180533-av25w128/logs
wandb: Agent Starting Run: 7l6oaxpt with config:
wandb: 	actor_learning_rate: 0.00014329138181432994
wandb: 	attention_dropout_p: 0.20862186781065756
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9760721517925832
wandb: 	temperature: 0.6322757308920468
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180620-7l6oaxpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7l6oaxpt
wandb: uploading history steps 52-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss ▁█▁▆
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ██▃▂█▃█▁▂█▃▄▅█▆▂█▂▂▇▂█▃▄▃▃▇▁▃█▃█▂▇██▂█▂▂
wandb:      eval/avg_mil_loss ▁▇▁▁▁▅█▁▁█▅█▁▅▇▁▂▅█▁▇▁█▂▇█▅▂▂▅▁▂▁▁▇▁▇▁▁█
wandb:       eval/ensemble_f1 █▇▂▇▂▂▂▇▁█▃▅▆▂▇▂▇█▇▂▂▄▇▇▃█▇█▇▂▇▇█▄▂▇▂█▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▅▅▅▆▃▂█▅▁▂▅█▂▅▂█▅▇█▃▅▅▇▃▃▆▆▇▅▅▂▄▂▃▅▂▅
wandb:      train/ensemble_f1 ▅▅▇▄█▄▂▄▅▅▂▁▅█▁▅▅▁█▁▆▆▄▅▄▄▅▅▅▇▇▅▄▁▁▂▇▅▁▄
wandb:         train/mil_loss ▄▅▇▄▂▄▇▇▄▆▄▄▂▃▃▆▄▃▂█▅▆▆█▄▇▂▃▁▂▇▇▁▃▅▅▃▆█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32674
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.06722
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.66018
wandb:      test/avg_mil_loss 1.18084
wandb:       test/ensemble_f1 0.66018
wandb:           train/avg_f1 0.65593
wandb:      train/ensemble_f1 0.65593
wandb:         train/mil_loss 1.15345
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7l6oaxpt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180620-7l6oaxpt/logs
wandb: Agent Starting Run: ivo3wmua with config:
wandb: 	actor_learning_rate: 0.0004729890334756114
wandb: 	attention_dropout_p: 0.011212145069257997
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5179189640254044
wandb: 	temperature: 4.411221411841373
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180711-ivo3wmua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivo3wmua
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁█▇▂▃▇▇▇▁█▁▁▅▁█▇▇▁▃▃▃▁▇▁▃▂▁▁▁▇▃▂▃▇▇▇▂█▂▄
wandb:      eval/avg_mil_loss ▁█▁▇█▁▁▁▁▁█▁▁▇▇▆▇▇▁▇▇▅█▃▆▁▇▇▅▁▁▆▁▅▆▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▄▁▇▇▇▇▁▁▁█▁▇▇▁█▃▂▃▂▃█▇▇▁▇▂▇▇▇▃▂▃▃▇▇▇▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▇▇▆▆▇▅▅▆▅▁▆▅▆▄█▅█▅▃▅▇▆▇▄▆▅▇▅▆▅▇▅▆▅▇▃▆
wandb:      train/ensemble_f1 ▆▄▃▅▅▅▂▅▄▂▃▅▄▇▇▁▅█▅▇▅▆▃▅▆▆█▅▃▇▅▃▃▄▅▄▄▆▁▅
wandb:         train/mil_loss ▆▄▃▅▃▇▅▆▄▅▃▇▅▃▅▁▄▇▃▅▄▅▇▅▃▃▅▂▅▁▁▃▂▃▁▅▄▄█▃
wandb:      train/policy_loss ▆█▃▁▆▆▃▃▃█▃▃▃▆▆█▃▆▆▃▆▃▃▆▆▆▃▆▃▆▁▃▆▆▃▃▆▃▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▆▃▆█▆▃▃▃▃▆▆▆▆▁▆▃▃▃▃▃█▆▆▃▆▁▃▆▆▆▃▆▃▃█▃▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.31592
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.67033
wandb:      eval/avg_mil_loss 0.95705
wandb:       eval/ensemble_f1 0.67033
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.27672
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.66703
wandb:      train/ensemble_f1 0.66703
wandb:         train/mil_loss 1.29992
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivo3wmua
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180711-ivo3wmua/logs
wandb: Agent Starting Run: v9yl93q1 with config:
wandb: 	actor_learning_rate: 1.744664477664802e-05
wandb: 	attention_dropout_p: 0.09108835173473444
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11761345229022356
wandb: 	temperature: 3.883170126745763
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180819-v9yl93q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v9yl93q1
wandb: uploading history steps 124-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁███
wandb: best/eval_avg_mil_loss █▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁███
wandb:            eval/avg_f1 █▂█▇▇▂▇██▂█▁▂▇█▂▃▂▅▃▂▂█▂█▂▇██▂▁▂█▂▁▂▂▇▂█
wandb:      eval/avg_mil_loss ▂▆▂▂▁▆█▆▁▆▁▁█▁▁▆▂▇▃▂▆▆▇▁▆▁▁▇▁▆▁▁▆▁▁▂▁▆▇▆
wandb:       eval/ensemble_f1 ▁▁▂▂▂▇▂█▂▇▂█▇▇▇█▂▂▂▂▂▂▂▇▇█▂▂██▂▁█▃▇▂▂█▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▅▄▁▇▆▆▄▅▇▅▄▄▆▆▆▅▃▅▇▄▆▅▄█▃▄▅▄▃▇▇▅▄█▅▄▆▃
wandb:      train/ensemble_f1 ▇▄▄▃█▆▄▅▇▆▇▆▅▅▅▄▄▅▄▇▆▅▇▅▃▅▃▆▆▅▃█▄▆▇▆▄▆▁▇
wandb:         train/mil_loss ▃▆▄▆▅▂▃▃▅▄▄▄▃▄▇▁▇█▇█▅▃▅▁▅▃▅▄▅▃▂▄▅▂▄▅▂▂▅▅
wandb:      train/policy_loss ▆▆▅▅▅▁▅▅▃▅▅▃▅█▅▃▅▅▅▆▃▅█▃▅▆▅▅▅▃▆▃▆▅▆▅▃▁▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▆█▆▆▆▆██▆▆▆▆▆▆██▃▆▁▆▃█▃▃▆▆▃▆▃▆█▆▆▃█▆▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32197
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.36002
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 1.47274
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.79841
wandb:      train/ensemble_f1 0.79841
wandb:         train/mil_loss 1.0816
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v9yl93q1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180819-v9yl93q1/logs
wandb: Agent Starting Run: 720a3yvu with config:
wandb: 	actor_learning_rate: 0.0001832910756624438
wandb: 	attention_dropout_p: 0.3681606548849905
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.989518133600218
wandb: 	temperature: 0.6373992688515173
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180952-720a3yvu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/720a3yvu
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂██▇██▇▇▇▂▂▇▃▇█▇▇▇▁█▇█▂▂▇▁█▂█▃▇▇█▇▇▇▇▁█
wandb:      eval/avg_mil_loss ▇█▁▇▂▁▂▁▁▁▁▂▇▁▁▁▇▂▁▁▂▁▂▇▇▁▂▁▁▁▂▇▁▁▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ▇▂█▇█▂▇▆▃▂█▇▇▂▂▇██▁▇▇▇▁▇██▁▇█▂▁▂▂▇▃▂▇█▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▄▅▄▆▅▆▃▅█▆▃▆▇▆▄▇▅▄▂▅▄▁▂▅▆▃▆▂▄▇▃▅▆▃▄▄▅
wandb:      train/ensemble_f1 ▄▄▆▄▇▄▂▄▃█▅▄▃▄▄▅▃▇▆▁▂▇▂▃▅▆▆▂▇▃▅▄▇▃▄▇▂▃▇▆
wandb:         train/mil_loss ▂▄▃▃▇▄▃▅▅▃▁▃▃▄▃▃▄▆▃▄▆▅█▇▄▂▄▇▁▂▄▅▄▃▅▇▅▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▃▁▁▃█▁▃▁▁▁▃█▃▃▁▆▁▁▃▆▆▆▁▁▃▁▁▁▁▆▁▁▃▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁█▃▃▃▁▁▃███▃▆▆▁▃▆▁▁▁▁▃▁█▁▁▁▁▃▁▁▁▁▁▃▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.3091
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30194
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.90845
wandb:      test/avg_mil_loss 0.18391
wandb:       test/ensemble_f1 0.90845
wandb:           train/avg_f1 0.79826
wandb:      train/ensemble_f1 0.79826
wandb:         train/mil_loss 0.60834
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/720a3yvu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180952-720a3yvu/logs
wandb: Agent Starting Run: 82545ic5 with config:
wandb: 	actor_learning_rate: 1.6029597817018157e-05
wandb: 	attention_dropout_p: 0.29282779061319986
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7978471843708468
wandb: 	temperature: 3.918459561515624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181100-82545ic5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82545ic5
wandb: uploading history steps 75-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇█▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ██▇▂▃▇▁▃▇▆▄██▄▇██▆▁█▇██▇▆▇▇▄▂█▃▆▃▂█▇▇▇▂▃
wandb:      eval/avg_mil_loss ▂▁▂▅▂▆▂▆▅▁▆▁█▂▅█▁▂▂▁▄▁▁▁▇▂█▂▆▁█▁▁▁▂▁▂▆▁▅
wandb:       eval/ensemble_f1 ██▇▇█▁▃▂▇▃███▃██▇██▃██▇▃▂██▂█▂▆▃▇█▄▃▆▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▅▆▅▇▄▅▄▅▅▃▄▃▄▅▃▁▃▄▆▆▇▄▄█▃▆▆▂▆▃▄▆█▅▆▁▄▄
wandb:      train/ensemble_f1 ▅▆▆▅▅▅▇█▅▆▆▅▅▄▅▃▄▄▅▆▇█▅▇▅▅▅▄▆▆▇▆▅▇▅▆▆▇▁▇
wandb:         train/mil_loss ▃▄▄▃▄▃▅▃▄▇▁▄▄▃▃▅▃▂▃▃▂▁█▄▃▃▃▃▆▄▄▄▂▄▆▄▄▃▃▁
wandb:      train/policy_loss ▃▅▅▅▆▅▅▅▆▅▅▅▅▃▆▆▅▃▁▆▆▆▁▃▆▅▁▃▆▃▆▅▅▆▃▆▃█▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆█▆███▃▁▆▆▃██▃█▆█▆▅█▆██▁▆▃▃▆▆█▃▆███▆▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.20684
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.61556
wandb:      eval/avg_mil_loss 1.16985
wandb:       eval/ensemble_f1 0.61556
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 1.52701
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.73454
wandb:      train/ensemble_f1 0.73454
wandb:         train/mil_loss 0.82252
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82545ic5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181100-82545ic5/logs
wandb: Agent Starting Run: 9ale45kq with config:
wandb: 	actor_learning_rate: 0.00021976038387092812
wandb: 	attention_dropout_p: 0.28827663668362713
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2252894561734452
wandb: 	temperature: 5.4008712124798315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181201-9ale45kq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ale45kq
wandb: uploading history steps 104-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▂▃█
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇▆▁▇█▆▇▆▆▆▇▇██▇▆▇▇▆▆▇▇▁▇▆▇▆▇▆▆▇▃▇█▇▅▆▆▆▇
wandb:      eval/avg_mil_loss ▁▂▂▁█▂▂▂▃▂▁▂▂▂▂▁▁▂▂▂▂▁▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▂▁▂
wandb:       eval/ensemble_f1 ▇▇▇▇█▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▆█▇▇▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▇▇▇▆▇▇▆▆▆▆▅█▇▆█▇▅▆▃▃▅▆▇▅▇▅▇▅▇▇▆▃▅▃█▇▁
wandb:      train/ensemble_f1 ▇▇▆▇▃▆▇▅█▅▆▇▇▃▇▆█▆▇▇▅█▆▃▅▆▅█▇█▇▅▇▇▇▃▇▇▇▁
wandb:         train/mil_loss ▂▅▅▂▂▅▂▃▂▅▂▂▃▁▂▂▂▂▂▃▃██▂▂▂▂▄▂▅▂▃▃▅▂▃▄▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.34525
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 1.2334
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.45282
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.78906
wandb:      train/ensemble_f1 0.78906
wandb:         train/mil_loss 0.22761
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ale45kq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181201-9ale45kq/logs
wandb: Agent Starting Run: iijwm91g with config:
wandb: 	actor_learning_rate: 3.394528394234305e-06
wandb: 	attention_dropout_p: 0.2690265045006772
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.589608181390023
wandb: 	temperature: 9.679846824658377
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181309-iijwm91g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iijwm91g
wandb: uploading history steps 53-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▄█▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ███▇▇██▁██▃▁█▁▇█▁▁▇▇▅▇▇▇▇▇▇▇▇▇▁█▇█▇█▇██▇
wandb:      eval/avg_mil_loss ▁▁▁▂▁▁▇▂▁▁▇▁▁▆▁▁▁█▁▇▁▁▂▁▁▁▁▂▁▁▆▂▇▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███▆▇▇██▁▁▁▇▅▅▇▇▇▁▁▇█▅▇▇▇▇▇▇▇▇▇▁█▇█▇█▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▅▇██▄▃██▆▁▅▇██▇▇█▇▆▇▇▇▆▅▆▅█▆▇▇▆▅█▇▇▅█▇
wandb:      train/ensemble_f1 ▇█▅▇▇▇████▁▅▇███▇██▇█▇▇▇▅▆▅█▆▁▇▇▇▆█▆▇▅█▇
wandb:         train/mil_loss ▆▂▂▆█▂▆▂▄▂▂▅▂▂▃▇▁▂▃▃▃▄▃▂▆▂▂▂▂▅▆▃▂▂▆▂▂▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.25352
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.34112
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.1221
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.73237
wandb:      train/ensemble_f1 0.73237
wandb:         train/mil_loss 0.29404
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iijwm91g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181309-iijwm91g/logs
wandb: Agent Starting Run: 351ggowe with config:
wandb: 	actor_learning_rate: 5.672410270342174e-05
wandb: 	attention_dropout_p: 0.1116306869183188
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9693067128255244
wandb: 	temperature: 9.611917490969764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181351-351ggowe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/351ggowe
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▃▁▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▁▅▅▂▄▁▆▆▂▅▄▅▂▁▅█▁▆▇▅▄▅▅▂▄▆▂▄▅▄▃▆▇▄▄█▅▇▂▆
wandb:      eval/avg_mil_loss ▃▆▁▇▄▂▃▄▃▁▄▃▄▅▂█▃▄▁▆▂▂▄▄▇▅▄▃▂▅▂▁▆▃▁▁▂█▃▁
wandb:       eval/ensemble_f1 ▁▁█▃▅▁▁█▃▁▅▅▅▆▃▅▆▆▄▇▃▆▆▇▅▄▄▆▂▄▆▅▇▇▂▅▆▇▄▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▅▁▆▃▁▁▅▆▆▅█▆▇▆▅▂▄▅▁▆▅▅▄▆▄▄▄▁▅▅▇▅▆▆▅▆▂█
wandb:      train/ensemble_f1 █▆▁▇▅▅▃▆▃▃▇▇▇▆▅▅▁▆█▄▅█▄▇▅▇▄▅▄▂▃█▇▄▇▇▆▂▁▅
wandb:         train/mil_loss ▄▃▅▅▅▃▅▃▇▃▁█▄▃▅▇▄▄▁▅▇▄▃▂▅▂▅▄▅▃▅▃▄▂▅▂▄▅▂▃
wandb:      train/policy_loss ▄▄▇▅▅▅▅▄▄▂▅▄▇▅▄▇▄▅▇▄▅▅▂▂▂▂▅▅▄▄█▂▂▂▄▁▄▄▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▆▅▆▆▆▃▇▂▁▅▃▅▆▅▅▇▅▃▇▆▇▆▃▇▆▁▃▅▃▃▁▆█▆▃▅▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.22943
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.2967
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.19861
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.7815
wandb:      train/ensemble_f1 0.7815
wandb:         train/mil_loss 0.76547
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/351ggowe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181351-351ggowe/logs
wandb: Agent Starting Run: edx56122 with config:
wandb: 	actor_learning_rate: 7.80187789194478e-06
wandb: 	attention_dropout_p: 0.3041360875988094
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8653587221692554
wandb: 	temperature: 8.688250462324337
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181514-edx56122
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/edx56122
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▁▃
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▆▇▇▂▅▅█▁▁█▂███▄▄▆█▆▅▃▅█▄▆▇▄▆█▅█▆▅▇▅▇▅▆▇▅
wandb:      eval/avg_mil_loss ▅▂▅▁▁▃▅▁▄▂▆▃▁█▁▆▁▁▄▁▁▃▄▂▆▃▁▁▆▁▁▇▁▅▆▅▁▁▂▁
wandb:       eval/ensemble_f1 ███▇▂▁▇▅█▁█▇▇▆▅█▇▅▂█▇▇▇▅▇▆▂▅▃▆▅▅▅▇▅▆▇▅▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▁▃▄▃▆▄▅▄▇▂▅▄▄█▃▃▄▅▄▃▄▇▄▄▇▅█▄▅▅▆▂▃▅█▄▅
wandb:      train/ensemble_f1 ▅▃▅▄▆▅▅▆▅▄▄▄▆▅▆▆▄▄▄▅▄▄▁▅▅▄▅▆▄▅▅▄▄▅▅▆▅▅▅█
wandb:         train/mil_loss ▄▆▇▃▄▂█▆▅▅▅▃▇▆▅▆▅▃▅▇▅▁▄▄▃▆▆▇▇▄▇▃▆▆▂▅▇▂▄▂
wandb:      train/policy_loss ▃█▆▃▅▆▇▆▅▆█▃▅▆▃▁▆▇▁▆▆▆▆▆▆▆▂▃▁▅▅▃▆▅▃▆▅▅▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.22955
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.83775
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.20264
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.78353
wandb:      train/ensemble_f1 0.78353
wandb:         train/mil_loss 0.84234
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/edx56122
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181514-edx56122/logs
wandb: Agent Starting Run: c787xbf2 with config:
wandb: 	actor_learning_rate: 1.365908436342161e-06
wandb: 	attention_dropout_p: 0.08340879052275463
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3987827013036733
wandb: 	temperature: 7.405158228715789
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181707-c787xbf2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c787xbf2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇▇█
wandb: best/eval_avg_mil_loss █▁▁▂▁
wandb:  best/eval_ensemble_f1 ▁▇▇▇█
wandb:            eval/avg_f1 ▂▇▇▃▂▇▂▇▇▇▇▇▇▇▂▂▇▇█▃▆▇▇▃▆▇▇▇▇█▇▇▇▁▇▇▇▂▇▇
wandb:      eval/avg_mil_loss ▇▁▂▂▅▂▁█▂▂▁▁▁█▁▂▂▂▂▁▂▂▁▂▁▁▁▂▁▂▇▁▁▁█▁█▁▁▁
wandb:       eval/ensemble_f1 ▂▇▃▂▂▇▇▇▇▇▇▂▂▇▇▇▇█▃▆▆▆▇▇▇▇▇▇▂▇▁▆▆▇▁▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▆▄█▆█▇▇▆▇▆▆▆▇▆▁█▆▆▇▇▇▅▅██▆▇▇█▄▅▆▆▇▅▄█▇
wandb:      train/ensemble_f1 ▇▇▆▇█▃█▇▆▇▆▇▆█▇█▇▅▁█▇▇▆▆█▇█▆▆█▆▆█▇▆▆▅▇█▇
wandb:         train/mil_loss ▄▂▁▄▅▂▁▁▁▂▇▁▁▇▄█▆▁▁▂▁▆▂▆▄▂▂█▂▄▇▆▄▂▁▆▇▂▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94995
wandb: best/eval_avg_mil_loss 0.16487
wandb:  best/eval_ensemble_f1 0.94995
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.25019
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.82985
wandb:      test/avg_mil_loss 0.40017
wandb:       test/ensemble_f1 0.82985
wandb:           train/avg_f1 0.85371
wandb:      train/ensemble_f1 0.85371
wandb:         train/mil_loss 0.21793
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c787xbf2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181707-c787xbf2/logs
wandb: Agent Starting Run: umanadnz with config:
wandb: 	actor_learning_rate: 0.00024958716680842515
wandb: 	attention_dropout_p: 0.10014296380659404
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5446990427496899
wandb: 	temperature: 5.89645802237426
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181810-umanadnz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/umanadnz
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▄
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▇█▅▆▃▆▇▆▆▅▃▃██▅▇▁▅█▃▂▆▁▅▅▄▄▄▅▅▅▃▆▅▆▆▇▃▇▅
wandb:      eval/avg_mil_loss ▁▂▄▄▆▂▃▆▁▁▁▃▄▆█▂▃▄▃▃█▄▇▁▅▃▃▁▆▄▁▃▄▃▄▅▁▂▁▅
wandb:       eval/ensemble_f1 ▇▄▅▅▆▅▆▅▆▂██▂▇▇▁▇▅▅▆▆▅▁▂▅▅▄▅▆▆█▄▅▅▅▆▃▇▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▄▂█▅▅▁▄▄▄▆█▅▅▃▄▄▅▅▆▃▆▃▇▂▆▅▄▄▆▅▇▄▂▄▃▄▄▂
wandb:      train/ensemble_f1 ▆▆▅▅▁▄▂█▅▄▇▆█▄▇▆▄▆▄▅▇▅▅▆▅▄▅▇▄▅▆▆▅▄▅▅▇▆▄▄
wandb:         train/mil_loss ▅▅▇▄▆▃▇▇▇▂▆▆▄▅█▃▂▂▄▄▆▄▂▄▆▃▃▃▂▃▅▃▆▇▇▆█▁▃▄
wandb:      train/policy_loss ▇▇█▁▇▄▅▅▂▂▄▇▄▇▅▂▇▄▄▄▇█▂▄▁▄▄▄▇█▄▅▄▇▅█▇▄▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▆█▃▃▄▁▁▃▃▆▆▄▆▃▃▄▆▃▃█▃▆▄▁▄▃▃█▆█▆▁▄▄▄▃▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.23897
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.7362
wandb:      eval/avg_mil_loss 1.22809
wandb:       eval/ensemble_f1 0.7362
wandb:            test/avg_f1 0.64862
wandb:      test/avg_mil_loss 1.62598
wandb:       test/ensemble_f1 0.64862
wandb:           train/avg_f1 0.71199
wandb:      train/ensemble_f1 0.71199
wandb:         train/mil_loss 0.73796
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/umanadnz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181810-umanadnz/logs
wandb: Agent Starting Run: 4betc3v4 with config:
wandb: 	actor_learning_rate: 1.700074030388358e-05
wandb: 	attention_dropout_p: 0.41609299109428177
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11250786645824208
wandb: 	temperature: 0.4828766105167037
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181943-4betc3v4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4betc3v4
wandb: uploading history steps 104-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▁▄
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇▃▇▁█▂▇▁██▇█▇▇▃▇▇▇█▃█▇▇▁▇█▂▁▇▃▇███▇▁▇▇▇▆
wandb:      eval/avg_mil_loss ▁▂▇▆▁▁▁▁▁▁▂▁▁▇▁▇▂▁▁▁▇▁▂▁▁▅██▁▁▁▁█▅▁▂▁▁▂▆
wandb:       eval/ensemble_f1 ▇▃█▇▁▁▁█████▇▇▇▁█▁██▇▇▇█▇█▇▂▇█▁██▇█▃█▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▅▄▇▇▅▇▄▅▅▁▂▆▄▄▅▆█▅▇▁▇▃▆▅▆▄▆▇▅▆▅▆▆▅▄▅▄
wandb:      train/ensemble_f1 ▇▇▄▄▂▅█▃▅▇▇▃▅▄▂▃▅▆▇█▆▇▄▆▆█▇█▅█▇▆▁▆▆█▆▇▅▆
wandb:         train/mil_loss ▃▆▆▁▃▁▃▆▁▄▃▇▆▁▁█▄▃▁▅▆▃▁▁▆▄▁█▁▅▄▃▁▂▂▄▃▃▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.32995
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.29138
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.15914
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.84835
wandb:      train/ensemble_f1 0.84835
wandb:         train/mil_loss 0.25495
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4betc3v4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181943-4betc3v4/logs
wandb: Agent Starting Run: n8ldhrpk with config:
wandb: 	actor_learning_rate: 2.012097366476575e-06
wandb: 	attention_dropout_p: 0.006705044647540792
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7879837582416085
wandb: 	temperature: 4.051172877796335
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182100-n8ldhrpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8ldhrpk
wandb: uploading history steps 52-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss █▂▁▂
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▆▇▅▁▇▅▁▅▇▁█▁█▁▇█▇█▇▇▇▂▂▂▄▇▇▂▇▇▇▇▇▇█▇▃▇▇▁
wandb:      eval/avg_mil_loss ▁▃▁▁▃▃▁▇▂▁▁█▁▁▁▁▁▁▁▁▄▇▁▅▁▇▁▁▁▁▃▁▇▁▁▁▁▁▁▅
wandb:       eval/ensemble_f1 ▆▅▇▂▇▂▅▇█▂▂▇█▇███▇▇█▂▃▇▃▄▇▃▇▁█▅▂▇▇▇█▄▇▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▁▅▅▆▄▅▃▅▅▅▃▆▄█▂▄▆▆▅▇▅▆▆▅█▃▅▃▄▇▄▄▆▅▅▅▇
wandb:      train/ensemble_f1 ▅▂▃▆▁▁▄▇▆▅▅▅█▃▇▆▇▄▆▂▃▆▅▆▆▅██▃▄█▅▄▆▆▅▅█▅▇
wandb:         train/mil_loss ▄▆▄▂▅▅▂▅▄▁▂▂▁▄▂▅▅▂▅▃▆▄▁▂▆▇▄▃▆▁▄█▅▅▅▇▅▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32783
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.53249
wandb:      eval/avg_mil_loss 1.43471
wandb:       eval/ensemble_f1 0.53249
wandb:            test/avg_f1 0.61293
wandb:      test/avg_mil_loss 1.23859
wandb:       test/ensemble_f1 0.61293
wandb:           train/avg_f1 0.84032
wandb:      train/ensemble_f1 0.84032
wandb:         train/mil_loss 0.42228
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8ldhrpk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182100-n8ldhrpk/logs
wandb: Agent Starting Run: 7nur0vuz with config:
wandb: 	actor_learning_rate: 5.205357806377419e-06
wandb: 	attention_dropout_p: 0.2475339927250086
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08049017651325308
wandb: 	temperature: 4.029315853290697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182141-7nur0vuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7nur0vuz
wandb: uploading history steps 136-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▆█▂▆▃██▇▇▄▂█▆▇▆▆▃▄▂▇▇▆▇▄▇▁▆▇▃▆▃▂▇▇▂▆▇▇█▁
wandb:      eval/avg_mil_loss ▂▂▅▂▂▇▄▂▂█▂▇▃▁▂▂▂▅▂▂▂▁▂▂▂▂▁▂▂▁▂▁▂▆▄▃▂▂▁▂
wandb:       eval/ensemble_f1 ▁▆▄█▁▇▇▆▅▂▇▆▇▂▃▇▆▂▆▇▇▂▇▇▇▁▅▇▆▇▇▇▇▂▇▁▇▇▇▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▆▁█▆▅▅▂▆▄▆▄▅▆▆▅▅▇▄▅▅▆▆▆▄▆▅▆▇▅▅▇▆▇▅▆▇▆
wandb:      train/ensemble_f1 ▆▅▆▁▆█▆▅█▄▅▆▆▇▂▆▅▆▆▇▅▇▄▇▆▅█▇▅▇▆█▅▆▇▇█▆▅▆
wandb:         train/mil_loss ▄▂▃▅▄▅▅▆▄▃▄▆▂▆▁▅▂▅▁▄▆▆▅▄▆█▃▃▂▅▆▇▂▁▇▃▁▁▇▄
wandb:      train/policy_loss ▇▇▇▇█▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▃▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.19922
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.7552
wandb:      eval/avg_mil_loss 1.23979
wandb:       eval/ensemble_f1 0.7552
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.35395
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.85978
wandb:      train/ensemble_f1 0.85978
wandb:         train/mil_loss 0.43109
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7nur0vuz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182141-7nur0vuz/logs
wandb: Agent Starting Run: y9ax2l08 with config:
wandb: 	actor_learning_rate: 3.10709998506566e-05
wandb: 	attention_dropout_p: 0.017345987340335267
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19597078786394595
wandb: 	temperature: 6.939644130895042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182330-y9ax2l08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9ax2l08
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▇▃█▁▆▁▆▆▆▆▇▇▆▆▆▇▆▇▃▆▇▇▂▆▆▆▇█▆▅▆▇▂▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▃▁▅▁▁▁▂▂▆▃▂▂▂▅▁▁▂▂▅▁▁▁▁▁█▁▁▂▁▂▁▃▂▂▁▂▁▁
wandb:       eval/ensemble_f1 █▇▇█▇▇▄▇▇▇▇█▆▇▇▇▇█▇▇██▇▇▇▄█▇▇▇▇▇▁▇█▇▇▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▄▅▅▅▇▆█▇▄▆█▁▆▅▇▂▇▄▇▄▄▇▃▃█▃▅▄▅▇▃█▆▅▅▃▂
wandb:      train/ensemble_f1 ▄▄▆▃▄▄▅▇▆▅▇▂█▅▇▅█▄▆▅▆▆▃▇▆▆▅▂▂▇▅▇▅▆▇▅▂▆▃▁
wandb:         train/mil_loss ▁▂▂▂▂▂▃▂▂▃▅▅▅▂▂▃▂▂▄▂▂▁▂▂▁▁▄▂▃▁▅▄▃▄▅█▁▂▄▃
wandb:      train/policy_loss ▃▃▂▆▃▃▃▃▆▃▆▂▆▆▆▇▃▃▂▇▃█▃▂▆▁▆▄▄▃▃▆▂▇▂▂▆▃▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▁▃▆▃▁▃▃▃▆▃█▁▆▃▃█▃▃█▃▁▁▅▁▁▆▁▆▆▃▁▃▃▁▃▁▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.17436
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.24721
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.17284
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.81114
wandb:      train/ensemble_f1 0.81114
wandb:         train/mil_loss 0.37516
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9ax2l08
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182330-y9ax2l08/logs
wandb: Agent Starting Run: zu23r326 with config:
wandb: 	actor_learning_rate: 0.0009218512119517808
wandb: 	attention_dropout_p: 0.012910232578449645
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9517681965261996
wandb: 	temperature: 9.481493583354917
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182442-zu23r326
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zu23r326
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▇█▇█▇█▇▃██▁▁██▇▇▁███▆███▇▇▇█▇▇█▁▇███▃█
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▃█▂▇▂▄▇▁▃▂█▁▂█▁▂▁▁▁▂▁▂▂▆▂█▁▂▁▁▇▂▁▄
wandb:       eval/ensemble_f1 ▇█▇▇▅▇▇▇▃▆▇▇▇▇▁▇▇▇▇▆▁▇▇▇▆▇▆▇▇▇▇▅▇▇▇▁▇▆▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▁▄▆▇▆▅▃▂▅▇▇▄▅▇▆▇▇▇▇▇▄▅▅▅▄█▇▅▅▄▂▅▇▅▂▅▄▇
wandb:      train/ensemble_f1 ▇▃▆▅▆▄▃▇▇▆▇▆█▅▅▇▁█▆▇▇▆█▅█▆▇█▆▄▇██▇▇▆▆█▆▇
wandb:         train/mil_loss ▆▂▅▁▅▇▅▅▄▃▆▄▅▂▆▂▂▃▄▆▂▄█▅▄▄▅▂▂▁▄▁▅▇▂▁▄▄▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.16789
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.25749
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.72832
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.86349
wandb:      train/ensemble_f1 0.86349
wandb:         train/mil_loss 0.36374
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zu23r326
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182442-zu23r326/logs
wandb: Agent Starting Run: t57olin6 with config:
wandb: 	actor_learning_rate: 3.940897866765872e-06
wandb: 	attention_dropout_p: 0.19713543318574028
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2540242598797269
wandb: 	temperature: 7.387673659596045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182550-t57olin6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t57olin6
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▇▇▇██▇█▅█▇▇█▇▇▇▇▇█▇▇▁▇█▇▁█▇▇▇▃▇███▇█▇▇▇█
wandb:      eval/avg_mil_loss ▂▁▁▁▁▃▂▁▁▁▂▁▁▁█▁▁▁▁▃▁▃▁▁▁▁▁▁▁▁▆▁▁▁▁▂▁▂▁▁
wandb:       eval/ensemble_f1 ▆▇███▇▅▇▇▇▇▇█▁▇▇▇█▇▅▁▇█▇██▆▇▇▇███▇▇▂▇▇▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▆▇▇▇▅▇█▄▂▄▅▇▁▆▄▆█▄█▃▇▅▇█▇▄▆▅▅█▅▇▇▅▆▇▅
wandb:      train/ensemble_f1 ▆▃▅▇▅▆▁▇▄██▂▇▂▅█▂▇▄▇▆▄▆▃▆▄█▃▇▇▆▇▃▆▅▇▆▆▄▃
wandb:         train/mil_loss ▃▅▂▂▄▇▅▄▁▁▅▃▂▅▆▅▄▂▂▂█▃▂▂▂▃▁▁▂▂▅▂▁▁▂▁▃▂▇▂
wandb:      train/policy_loss ▃▆▃▅▃██▃▆▃▃▃▃▃▅▁▃▃▆▃▆▃▃▅▃▁▅▃▅▆▅▅▆▃▆▅▅▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃█▃▆▆▃▃██▇▃▃▁▃▃▇▆▃▃▃▃▆▆▁▃▃██▃█▃▃▆▃▃▃▁▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.18915
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.29557
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.1356
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.83874
wandb:      train/ensemble_f1 0.83874
wandb:         train/mil_loss 0.57135
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t57olin6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182550-t57olin6/logs
wandb: Agent Starting Run: y44p8g3y with config:
wandb: 	actor_learning_rate: 0.00021631100216631976
wandb: 	attention_dropout_p: 0.26389740498479675
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8185532008003228
wandb: 	temperature: 1.5526078520305808
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182703-y44p8g3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y44p8g3y
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▇▇▁▇▇▇█▇▇▇██▇▆▇▇▇▇▇▇▇▇▇▇▇▁██▇▇▇▇▇▇█▇▇▇
wandb:      eval/avg_mil_loss ▆▁▂▆▂▂▁▁▁▂▂▁▂▂▂▂▁▅▂▂▂▁▁▂▁▁▂▁▁▁█▂▁▁▂▁▁▂▂▂
wandb:       eval/ensemble_f1 ▁▇▇▁▇█▇█▇▇█▇█▆▇▇▆▇▆▂▇▇█▇▆▇▇▇▇█▅▇▇▇█▇▇▇█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▁▄▆▆▇▆▃▆▆█▆▆▆▅▇▇▂▆▆█▇▆▆▇▇█▆▅▇▄▆▄▇▅▅▃▅
wandb:      train/ensemble_f1 ▃▆▆▆▇▆▆▂▆▁▆▆▃▅▁▆▅▆▄▅▇▄▇▃▆█▆▆▅▄▇▄▇█▄▅█▃▆▁
wandb:         train/mil_loss ▂▂▅▂▃█▁▂▂█▅▂▂▂▂▂▄▁▃▁▂▂▂▂▄▂▂▂▄▃▃▅▄▃▄▂▃▁▄▂
wandb:      train/policy_loss ▃▃▃▃▃▆▁▆▃▃▆▆█▃█▃▆▃▆▅▃▃▃▃▅▆▆▅▆▅▅▁▃▃▆▅▃▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▅▅▆▅▃▃▁▆▃▃▃▆█▆▃▃▃▃▆▅▆▃▃█▆▃▃▁▆▆▆▆▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32594
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.35258
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.17955
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.83243
wandb:      train/ensemble_f1 0.83243
wandb:         train/mil_loss 0.28041
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y44p8g3y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182703-y44p8g3y/logs
wandb: Agent Starting Run: 2mwwlnsu with config:
wandb: 	actor_learning_rate: 0.00020639559090986849
wandb: 	attention_dropout_p: 0.17904808936900812
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9627493602564589
wandb: 	temperature: 1.1426059797627908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182811-2mwwlnsu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mwwlnsu
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▇███
wandb: best/eval_avg_mil_loss █▆▂▂▁▂▁
wandb:  best/eval_ensemble_f1 ▁▂▆▇███
wandb:            eval/avg_f1 ▄▅▇▅▇▇▆▄▄▇▇▇▅▇▇▅▅▅▄██▇█▁▄▁▅█▅█▅█▇▅▅█▅▇▄▅
wandb:      eval/avg_mil_loss ▅▄▇▂▁▂▄▆▂▁▂▃▂▁▄▄▁▁▄▁▂█▂▅▅▂▄▂▂▃▄▄▁▄▃▄▆█▄▂
wandb:       eval/ensemble_f1 ▄▅▅▇▇▇▇▇▇▇█▇▅▄▅▆▇▅▇▅▅▇▇█▇▄▁▇▁▇▅█▅▇▇▅▄▇▄▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▃▂▆▆▄▄▇▆▆▅▆▆▃▃▄▄▅▂▁▅▅▆▆▇▅▁▇▆▄▃▃▄▆▆▅▆▆▂
wandb:      train/ensemble_f1 ▂▆▆▆▅▃▃▇▅▁█▇▆▇▄▆▅▅▅▆▆▁▇▇▅▅▆▅▃▅█▇▅▄▅▆▇▇▇▆
wandb:         train/mil_loss █▄▇▅▇▆▄▅▃▇▆▆▃▃▆▅▆▃▅▆▅▆█▆▆▂▅▆▄▆▃▇█▄█▁▅▄▃▂
wandb:      train/policy_loss ██████▁████████████████████▂████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▁████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.24386
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 1.22344
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.90845
wandb:      test/avg_mil_loss 0.29708
wandb:       test/ensemble_f1 0.90845
wandb:           train/avg_f1 0.81616
wandb:      train/ensemble_f1 0.81616
wandb:         train/mil_loss 0.404
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mwwlnsu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182811-2mwwlnsu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1g1mijry with config:
wandb: 	actor_learning_rate: 0.0009733076406337676
wandb: 	attention_dropout_p: 0.06365157735125188
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1470193948673768
wandb: 	temperature: 5.66199689838009
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182956-1g1mijry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1g1mijry
wandb: uploading history steps 52-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁█▂▂▁▂▇▁▅▇▇▇▇█▆▇▂█▇█▁███▇▇█▂▄█▇█▆▇▂▇▇█▃█
wandb:      eval/avg_mil_loss ▆▁▄▄▆▇▁▆▁█▇▁▂▁▂▂▁▁▇▁▁▁▅▁▁▁▄▅▁▇▁▁▂▁▄▂▁▁▄▁
wandb:       eval/ensemble_f1 ▁██▂▂▂▇▇▅▇▇▇▇█▆▇▇█▇▁▄█▇█▇▇█▂▄▇█▇▆▂▇▇█▃██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▇▆▅▄▂█▇▆▇▇▃▃██▆▆▇█▅▄▅▅▆▇▅▃▆▇▁▅▄▄█▅█▂▄▇
wandb:      train/ensemble_f1 ▇▅▆▆▅▇▅▅▄▇▃▇▅▇▇▇▆▇▅▄▃▄▇▅█▅▆█▇▄▇▁▅▅▃▅▅██▄
wandb:         train/mil_loss ▄▃▂▁▂▄▃▃▁▁▃▁▅█▃▄▄▂▃▃▃▅▂▃▄▄▄▆▆▄▃▃▄▃▅▂▅▁▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31256
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.32723
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.61293
wandb:      test/avg_mil_loss 1.38443
wandb:       test/ensemble_f1 0.61293
wandb:           train/avg_f1 0.89249
wandb:      train/ensemble_f1 0.89249
wandb:         train/mil_loss 0.24602
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1g1mijry
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182956-1g1mijry/logs
wandb: Agent Starting Run: kl8w9qfl with config:
wandb: 	actor_learning_rate: 1.7168554120111646e-06
wandb: 	attention_dropout_p: 0.3275300047556846
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07863314862467252
wandb: 	temperature: 3.334786629373707
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183041-kl8w9qfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl8w9qfl
wandb: uploading history steps 78-93, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇██
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇▇██
wandb:            eval/avg_f1 ▁▃█▂▇▂▆▇▂██▁█▃▂█▁█▇██▇▅▁█▇▇▂▆▁▇▁▁▃▂▅██▂▁
wandb:      eval/avg_mil_loss ▁▁▆█▅▆▁▁▁▁▂▆▁▄█▁▁█▆▁▁▄█▁▁▂▆█▁▁▂▇▁▇▁▄▁▁▁▆
wandb:       eval/ensemble_f1 ▂▇▇▁▁▇▇▂▇▂██▇█▄▁█▂▃▂▂██▇▇▂█▅▇▁█▃▇▇▂████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▂▇▄▄▇▆▅▆▇▆▁▅▆▆▅▅▆▅▄▂██▆▅▅▄▁▆█▇▆▇▃▄▄█▅▅
wandb:      train/ensemble_f1 ▁▁▆▄▆▇▅▆▁▆▆▅▅▆▅▅▆▄▆▅▇▇▆█▄▅▆▄▃▄▂▇▅█▆▇█▅▃▅
wandb:         train/mil_loss ▄▆▄▅▁▅▃▃▃█▂▇▅▆▅▅▆▄▂▄▆▆▁▄▂▁▅▅▃▅▄▆▄▇▁▁▆▄▂█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.34151
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.06454
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.18282
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.7173
wandb:      train/ensemble_f1 0.7173
wandb:         train/mil_loss 0.71851
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl8w9qfl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183041-kl8w9qfl/logs
wandb: Agent Starting Run: obvtff4t with config:
wandb: 	actor_learning_rate: 0.0007638278844283034
wandb: 	attention_dropout_p: 0.4491160424672268
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07384444675811086
wandb: 	temperature: 3.9457435247015527
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183143-obvtff4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/obvtff4t
wandb: uploading history steps 136-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▃▅█
wandb: best/eval_avg_mil_loss █▅▆▆▁▂
wandb:  best/eval_ensemble_f1 ▁▁▃▃▅█
wandb:            eval/avg_f1 ▆▂▁▆▂▆▂▇▇▆▄▇▆▅▆▃▆▇▆▇▅▄▇▇▇▆▂▅▆█▇▆▃▆▆▆▆▃▆▇
wandb:      eval/avg_mil_loss ▁▁▂▁▁▅▁▆▂▁▆▄▇▁▂▂▁▂▄▁▁▁▂▂▁▂▂▁▁▆▁▆▁▁█▃▅▂▂▄
wandb:       eval/ensemble_f1 ▄▇▇▂▄▇▃▇▃▇█▇▇█▇█▇▇▇▃███▃▆▁▇▇█▄▄▇█▇▇▃▇█▂▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▅▅▅▄▄▇▅▅▅█▁▇▄▁▂▂▅▆▄▆▄▅▄▆▃▅▆▅▃▅▃▂▅▃█▄▅
wandb:      train/ensemble_f1 ▅▆▅▅▆▅▅▆▆▆▆▆▇█▇▇▂▆▆▅▆▇▆▆▁█▆▄▆▆█▇▆▇▄▆▄▄▆▅
wandb:         train/mil_loss ▄▅▄█▁▆▅▆▄▃▃▄▂▃▂▄▅▅▆▂▅▄▂▃▄▁▇▇▇█▄▇▃▄▄▄▄▅▃▄
wandb:      train/policy_loss ▂▆▆▂▂▆█▁█▆▇▆▆▃▆▃▃▆▃▁█▃▆▆▁▆█▁▄▆▁█▆█▁▃▂▂▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▄▃▄▆█▁█▇▄▃▇▆▆▆▂▆▃▃▄▂▇▃▇▂▁▂▆▄▁█▆█▆▃▂▂▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.22693
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.80673
wandb:      eval/avg_mil_loss 0.5604
wandb:       eval/ensemble_f1 0.80673
wandb:            test/avg_f1 0.89854
wandb:      test/avg_mil_loss 0.19654
wandb:       test/ensemble_f1 0.89854
wandb:           train/avg_f1 0.86
wandb:      train/ensemble_f1 0.86
wandb:         train/mil_loss 0.38507
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/obvtff4t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183143-obvtff4t/logs
wandb: Agent Starting Run: zljpvd40 with config:
wandb: 	actor_learning_rate: 0.000956829979803926
wandb: 	attention_dropout_p: 0.2011173278251802
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4245562649826699
wandb: 	temperature: 9.62586431486973
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183321-zljpvd40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zljpvd40
wandb: uploading history steps 100-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss ▁█▂
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 █▂█▄▁█▃▂▃▃█▃▂▅██▂█▆▃██▂▁▃█▇▂▃█▂█▂█▆▁▅▃▃▃
wandb:      eval/avg_mil_loss ▆▇▇▁▇▆▂▇▅▁█▇▆▅▂▁▇▁▁▇▁▇▇▁▁▁▄▁▇▇▅▃█▅▁▃▁▆▁▁
wandb:       eval/ensemble_f1 █▂▁▂▂▃█▂▃▃▅██▃▃▅█▄▂▆███▂▃███▃███▄▂▃█▃▄▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▃▆▃▃▅▆▄▂▅▅▃▂▃▇▁▁▁▄▃▃▃▆▁▆▁▂▆▃▅▄▁▄▄█▅▅▂
wandb:      train/ensemble_f1 █▁▅▅▇▆▄▄▆▇▅▅▆▆▆▅▅▄▆▃▅▅▃▆▇▆▆█▄▄▅▅▇▅▅▆▅▆▆▅
wandb:         train/mil_loss ▃▆▆▂█▆▃▅▄▇▆▆▂▇▆▆▅▆▆▅▄▃▃▆▇▁▆▆▆▄▅▅▃▅▆▄▅▅▂▄
wandb:      train/policy_loss █▇▆▆▆▆▃▆▆▇▆▆▆▆███▆▆▆▆▃▃▆▆▆▆▃▇▆▃███▁▇▃▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▆█▆▆▆▆█▆▆▆▆█▁█▆▆▆▆▃▃▆▆▃▆▆▇▆█▃▆█▆▆▆█▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.27119
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.28988
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.6182
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.6806
wandb:      train/ensemble_f1 0.6806
wandb:         train/mil_loss 1.0929
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zljpvd40
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183321-zljpvd40/logs
wandb: Agent Starting Run: ebnxoqxb with config:
wandb: 	actor_learning_rate: 0.0004348741481660833
wandb: 	attention_dropout_p: 0.096550134055633
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5974545514491986
wandb: 	temperature: 2.936382190722715
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183439-ebnxoqxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebnxoqxb
wandb: uploading history steps 79-81, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▁▇
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 █▄▅██▂██▃▁█▄▇▇▁█▇▃▇█▆▆▁█▇█▅▄▂██▂█▆▅▁▇▂██
wandb:      eval/avg_mil_loss ▁▃▁▇▁▁▄█▁█▁▁▆▄▁▆▁▅▇▁▁▇▂▅▇▁▁▃▄▅▄▅▁▂▃▅▁▇▁▁
wandb:       eval/ensemble_f1 ▄▅█▃▂█▇█▁▇█▇▂▂▇█▄▂▇▃▂▆▂▃▁▃█▅█▄██▆▅▁▇▂███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆██▄▆▅▆▅▄▅▅▂▇▃▄▇▄▁▅▆▇▇▄▄▅▆▅▅▆▇▅▃▆▇▇▅▃▂
wandb:      train/ensemble_f1 ▃▅▄▅▆▃▇▄▄▅▃▃▃█▄▅▄▅▄▁▆▄▅▄▃▇▃▄▅▄▆▄▂▄▃▄▆▄▃▂
wandb:         train/mil_loss ▅▅▇▂▅▂▅▁▄▅▅▂▃▄▅▄▅▃▃▃▄▄▅▂▆▅▄▄▄▄▃▄▅█▄▄▆▂▅▅
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.3417
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30184
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11303
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.7664
wandb:      train/ensemble_f1 0.7664
wandb:         train/mil_loss 0.58297
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebnxoqxb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183439-ebnxoqxb/logs
wandb: Agent Starting Run: unbvilj8 with config:
wandb: 	actor_learning_rate: 0.00034666265805528954
wandb: 	attention_dropout_p: 0.49479925574097894
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4502218613139525
wandb: 	temperature: 8.752938594687064
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183531-unbvilj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/slt687s6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/unbvilj8
wandb: uploading history steps 104-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅█
wandb: best/eval_avg_mil_loss ▁▃▃█▆
wandb:  best/eval_ensemble_f1 ▁▄▅▅█
wandb:            eval/avg_f1 ██████████████████▅███▁█████████████████
wandb:      eval/avg_mil_loss ▂▁▂▁▁▂▁▂▁█▂▂▁▁▂▁▁▂▂▁▁▁▂▃▂█▃▂▁▁▂▄▁▁▁▁▂▁▂▁
wandb:       eval/ensemble_f1 ███▇████▇▇▇████▇▅▂▆█▁▇██▆▇██▇█▇▆█████▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▄▇▆▆▇▃▆▆▇▆▅▆▆▇▇▇▃▇▄▆▇▇█▆▇▆▆▇▇▇▇▇▆▇▇█▆▆
wandb:      train/ensemble_f1 ▇▇▂▄▂█▆▃▄▇▇▆█▅▇▆▆█▇▇▆▃▅▇▅█▅▆▆▆▇█▇▂▇▇▇▁▇▆
wandb:         train/mil_loss ▄▂▂▃▂▄▂▄▂▂▁▆▂▂▂▃▃▂▂▂▆▄▂▇▂▅▂▃▃▂▅▂▂▅▄▅▂█▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.30986
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.28128
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.64862
wandb:      test/avg_mil_loss 1.00283
wandb:       test/ensemble_f1 0.64862
wandb:           train/avg_f1 0.88499
wandb:      train/ensemble_f1 0.88499
wandb:         train/mil_loss 0.81049
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/unbvilj8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183531-unbvilj8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: tjkywjdk with config:
wandb: 	actor_learning_rate: 1.1248188800885336e-05
wandb: 	attention_dropout_p: 0.2223285798919734
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8869259376670403
wandb: 	temperature: 1.328045556804548
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183707-tjkywjdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjkywjdk
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 93-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▇█
wandb: best/eval_avg_mil_loss ▄▄█▂▄▁▄
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▇█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▆▆▇▆▇▇▆▁▇▇▁▇▆▇▇▇▇█▆█▂▇▁▇▇█▇▂▆▇█▆█▃
wandb:      eval/avg_mil_loss ▂▃▁▁▁▂▁▂▂▂▁▁▂▂▂▂█▂▂▁▂▇▁▂▂▁█▁█▂▂▂▁▂▁▂▁▂▂▆
wandb:       eval/ensemble_f1 ▇▇▄▇▃▇▇▇▇▆▆▇▇▇▇▆▁▇▇▇▆▁▆▆▇▇▇▆▇▇▁▇█▆▇▆▇▇█▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▆▆▆█▄▃█▃▇▇▃▅▆▁▆▂▆▆▆▆▇▇▇██▆▄▄▆▅▇▆▆▅▄▄▅
wandb:      train/ensemble_f1 ▄▆▅▆▆█▂▄█▂▄▆▇▇▇▆▅▇▁▃▆▄▆▃▄▇▃██▄▆▆██▆▃▄▅▅▅
wandb:         train/mil_loss ▃▄▁▄▅▃▄▅▃▂▅▃▂▃▂▃▂▅▄▅▃▂▃▄█▂▃▂▄▅▅▂▃▂▂▃▃▁▃▃
wandb:      train/policy_loss █████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.34651
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.63108
wandb:      eval/avg_mil_loss 1.14986
wandb:       eval/ensemble_f1 0.63108
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.37938
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.85504
wandb:      train/ensemble_f1 0.85504
wandb:         train/mil_loss 0.53448
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjkywjdk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183707-tjkywjdk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8fsnz1pc with config:
wandb: 	actor_learning_rate: 4.699464144146365e-05
wandb: 	attention_dropout_p: 0.373258993202699
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 191
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8225387484625317
wandb: 	temperature: 4.218517751133835
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183830-8fsnz1pc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fsnz1pc
wandb: uploading history steps 105-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▇█▇███▃▃▁█▇█▃▃█▆██▇▇▃██▇██▃▃▇████▃███▇▇█
wandb:      eval/avg_mil_loss ▁▂▁▁▁▁▁▁██▁▁▁▁▂▁▁▁▇▁▁█▁▁▁█▁▁▁▇▁▁▁▇▁▁▁▁▁▄
wandb:       eval/ensemble_f1 ██▃▃▃▁█▇▃▇██▃▃█▇▂▇▃▇▃██▇████▇███████▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▃▄▆▇▃▇▅▆▇▅▃▄▄▆▄▆▇▇▆▅▆▅▇▂█▁▅▆█▂█▄▅▇▄▆▆
wandb:      train/ensemble_f1 ▆▅▆▄▇▆▇▇▆▅▅▄▇▁▆▄▆▇▇▇▆▃▆█▆▆▅▁▆▇▇▇▇▅▅▆█▃█▄
wandb:         train/mil_loss ▅▁▄▁▃▃▃▆▃▄▄▃▅▄▁▃▃▁█▇▂▄▃▅▄▄▁▁▁▂▃▅▆▂▆▃▇▁▁▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.28193
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 1.9923
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 1.09942
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.68785
wandb:      train/ensemble_f1 0.68785
wandb:         train/mil_loss 1.08958
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fsnz1pc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183830-8fsnz1pc/logs
wandb: Agent Starting Run: futlwlq1 with config:
wandb: 	actor_learning_rate: 5.5760060485511715e-06
wandb: 	attention_dropout_p: 0.23755250179471815
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 69
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3586189654496126
wandb: 	temperature: 6.737864605721232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183938-futlwlq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/futlwlq1
wandb: uploading history steps 50-70, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆█
wandb: best/eval_avg_mil_loss █▂▃▃▁
wandb:  best/eval_ensemble_f1 ▁▅▅▆█
wandb:            eval/avg_f1 ▇▁▄▃▂███▁▂█▆██▆▇▇▁▂█▂█▂▃▇█▂▄██▆██▆██▂▂██
wandb:      eval/avg_mil_loss ▂█▃▁█▁▇▆▇▁▃▁▂▁▆▅▇▁▇▁█▄▁▅▁▁▁▁▅▁▂▁▂▁▁▆▁▁▇▂
wandb:       eval/ensemble_f1 ▁▂▂██▂█▂▆██▆▆▇▇▃▂█▁▂▂▂▃█████▂█▇█▆▂██▂▂▂▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▄▆█▃▆▃▆▅▅▄▆▄▄▆▄▆▆▅█▅▇▆▃▆▆▇▅▇▃█▁▄▆▅▅█▁
wandb:      train/ensemble_f1 ▃▃▄▆█▃▆▄▃▆▅▄▇▆▅▇▄█▄▆▄▆▇▅▇▆▃▆▆█▄▄▄▆▄▂▃▅▆▁
wandb:         train/mil_loss ▅▆▄▂▆▅▂▂▃▃▃▄▃▅▁▁▆▄▃▄▃▂▆▃█▃▄▄▃▆█▅▂▁▃▃▄▄▃▇
wandb:      train/policy_loss ▆▆▁▃▃▃▃▃█▃▁▁▁▃▃▁▁▁▁▁█▁▆▁█▁▁▁▁▁▃▃▃▃▆▆▃▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▁▃▃▃▆▃▃▃█▁▃▆▁▃▃▃▁▁▁▁▁▃█▃▆▁▁▃▁▁▁▃▃▆▁▆▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.24788
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.3039
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.59887
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.62466
wandb:      train/ensemble_f1 0.62466
wandb:         train/mil_loss 1.40337
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/futlwlq1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183938-futlwlq1/logs
wandb: Agent Starting Run: ecwemtzg with config:
wandb: 	actor_learning_rate: 1.8671676176897176e-06
wandb: 	attention_dropout_p: 0.14496611733163267
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35336632566776205
wandb: 	temperature: 8.814116187273628
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184025-ecwemtzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ecwemtzg
wandb: uploading history steps 104-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▂█▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 █▇█▇▇██▇█▇▇▇█▇▁█▇███▁██▇███▇▇███▇██▇▆█▇▇
wandb:      eval/avg_mil_loss ▁▁▂▂▅▂▂▂▁▁▂▁▂▂▂▁▂▂▁▂▁▂▂▂▂▇█▂▂▂▁▂▂▄▁▂█▂▃▂
wandb:       eval/ensemble_f1 ▅▆█▅▄▇▄▅▇▆▅▆▅▅▄▅▅▇▆▄▅▆▄▄▆█▆▆▄▆▆▆▆▄▅▄▆▅▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▇▄▄▆▆▆▇▁▆▆▇▇▃▇▄▄▇▂▇▇▄▅▇▄▆█▇▇▇▇█▆▆▅▆▇▇
wandb:      train/ensemble_f1 ▇▇▆▇█▆▄▆▆▇▇█▆▆▇▇▄▇█▇█▁█▇▅▇▄▇▆▄▇██▆▅▇▇▇▇▄
wandb:         train/mil_loss ▃▁▂▂▂▂▃▁▂▂▂▂▇▂▃▂▂▂▂█▃▁▂█▁▂▆▁▁▂▃▁▁▇▂▂▁▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.25899
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.25894
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.16282
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.90117
wandb:      train/ensemble_f1 0.90117
wandb:         train/mil_loss 0.41032
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ecwemtzg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184025-ecwemtzg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u1np1z25 with config:
wandb: 	actor_learning_rate: 1.4854759861956406e-06
wandb: 	attention_dropout_p: 0.022444384244272583
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4804814808747251
wandb: 	temperature: 8.073674233541158
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184139-u1np1z25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u1np1z25
wandb: uploading history steps 99-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▇▁▂
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▇█▄█▇▁█▇█████▂█▂▆█▇▃▄▃▂▄▁▁██▇▇▇▇▇▂▄▂▃▂▄█
wandb:      eval/avg_mil_loss ▁▁▁▆▄▁▇▇▇▇▅▂▇▁▃▁▆▇▁▄▇▄▄▅▁▇▁▁▁▁█▁▁▁▁▇▅▇▃█
wandb:       eval/ensemble_f1 ▇██▄██▁▂▇▂██▄▂█▃▆▁▂▇▃██▂▄▇██▂▇▇█▃▇▇▂▂▄█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▇▆▂▂▅▅▃▆█▂▃▃▆▇▆▄█▆▄▄▁▂▂▅▂▆▅▇▂▂▂▄▅▅▄▇▁▅
wandb:      train/ensemble_f1 ▆▃▆▅▃▄▆▅▃█▆▅▃▇▅▆▅▁▃▄▄▆▆▄▇▆▅▆▄▅▇▄▅▃▃▅▆▅▆▇
wandb:         train/mil_loss ▁▅▂▅▄▄▃▄▃▅▃▂█▃▄▃▅▃▃▂▃▃▅▄▃▂▅▂▁▄▂▂▃▄▄▂▄▃▃▇
wandb:      train/policy_loss ▅▅▅▅▁▅▅▅█▁▅▅▅▁▅▁▁▁▁▁▁▆▁██▁▁▁▅▅▁▅▅▅█▅▁▅▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▄▃█▃▄▃▆▃▆▄▃▄▃▁▃▃▄▃▃▅▃▃▃▃█▃▄▄▃▄▄▄▄▄▄▃▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.30264
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.3141
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.16788
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.77723
wandb:      train/ensemble_f1 0.77723
wandb:         train/mil_loss 0.81787
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u1np1z25
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184139-u1np1z25/logs
wandb: Agent Starting Run: dqwwfyw8 with config:
wandb: 	actor_learning_rate: 1.503816319894586e-06
wandb: 	attention_dropout_p: 0.012023414350434802
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01523006096566859
wandb: 	temperature: 9.754952298469409
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184302-dqwwfyw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dqwwfyw8
wandb: uploading history steps 53-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▁▃█
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ███▇██▂███▂█▂▂█▁▁███▅▂█▂███▂██▂▂▂▇▄█▇▂██
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▇▁▁▇█▃███▁▁▁▄▇▆▁▁▄▁▆▇▁█▆▇█▁▁▁█▁
wandb:       eval/ensemble_f1 ████▇▂█████▂▂██▂▆█▁▁████▅▂█▂██▂▂▂▂▇▁█▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▁▅▅▁█▄▁▇▇▆▅▄▆▄▅▄▄▄▅▂▇▅▅▅▂▇▁▅▇▆█▆▆▂▂▅▅█
wandb:      train/ensemble_f1 ▄▄▇▆▂▁▃▅▅▇▆▇▆▅▄▅▇▆▅▅▃▁▆▆▃▃▆█▅▆▅█▆▆▆▅▅▅▆█
wandb:         train/mil_loss ▅▁█▅▄▃▆▃▃▆▃▆▅▅▃▃▃▅▅▁▆▃▅▆▃▁▂▁▂▇▄▃▅▆▅▃▅▇▇▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.33626
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30032
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.17465
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.9125
wandb:      train/ensemble_f1 0.9125
wandb:         train/mil_loss 0.54269
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dqwwfyw8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184302-dqwwfyw8/logs
wandb: Agent Starting Run: 0o3n4qui with config:
wandb: 	actor_learning_rate: 2.152616844482946e-06
wandb: 	attention_dropout_p: 0.4079522591641548
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.022731341430393015
wandb: 	temperature: 8.675037554638624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184343-0o3n4qui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o3n4qui
wandb: uploading history steps 99-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▁▂█
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▃▁▅▅█▁▃▃▅▁▅▁▁▃▆▃▅▁▅▅█▃▆▅▅▆▃▃▆█▆▅▃▆▆▆▅▅▆▆
wandb:      eval/avg_mil_loss ▄▄▅▄▄▄▄▆▄▆▅▅▄▅▆▄▃▆▁▄▆▄▆▄▅▅▄▃▅█▄▄▄▆▄▅▄▅▄▅
wandb:       eval/ensemble_f1 ▅▃█▁▅▆▅▁▅▆▅▁▆█▁▃▅▁▅█▃▅▆▆▃▆▃▃██▅▅▃▃▃█▆▅█▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▅▃▆▃▄▃▄▂▅▅▄▄▃▃▄▅▄▆▆█▆▅▄▅▅▄▆▅▄▇▅▄▅▁▅▆▃
wandb:      train/ensemble_f1 ▅▆▃▄▇▇▆▃▅█▅▅▆▅▆▃▂▆▄█▆█▄▆▄▆▅▄▄▇▂▇▆▅▇▆▁▄▄▆
wandb:         train/mil_loss ▅▄▄▆▅▂▄▄▆▃▅▃▆▄▃▂▅▂▂▂▄▇▅▁▄▅▆█▂▅▅▃▃▂▁▅▆▆▂▆
wandb:      train/policy_loss ▃▃▁▃▃▄▃▃▃▃▃▄▃▄▃█▃▃▆▄▄▄▃▄▄▃▄▃▄▄▃▃▄▄▄▄▄▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▅▃▅▅▃▁▁█▅▃▅▅▆▅▃▅▅▃▃▅▃▅▃▅▁▃▅▅▅▅▃▃▅▁▃▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.28649
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.27718
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.23458
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.90118
wandb:      train/ensemble_f1 0.90118
wandb:         train/mil_loss 0.32613
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o3n4qui
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184343-0o3n4qui/logs
wandb: Agent Starting Run: aruxvwoj with config:
wandb: 	actor_learning_rate: 1.5812666395419205e-06
wandb: 	attention_dropout_p: 0.0071176038674174436
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.057796181004084235
wandb: 	temperature: 9.711209624719409
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184455-aruxvwoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aruxvwoj
wandb: uploading history steps 90-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅███
wandb: best/eval_avg_mil_loss █▄▆▅▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▅███
wandb:            eval/avg_f1 ▂▅▁▆▃▆▆▂▆▆▆▂▂█▂▂▅▂▅▆▆█▅▆▅▅▂▂▇▂▂▃▅▂▅▅▅▆▆▄
wandb:      eval/avg_mil_loss ▄█▆▂▆▃▇▆▁▁▆▂▄▄▇▇▄▄▃▃▄▁▆▆▁▅▂▆▇▁▅▇▃▅▃▄▂▄▇▅
wandb:       eval/ensemble_f1 ▅▅▂▁█▂▅▆▆▄█▅▂▂▅▄▅▂▅▆▅▂▃▄███▂▂▂█▄▂▆▅▆▆▆▂▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▃▄▂▅▂▄▂▁▄▂▂▄▄▅▂▁▄▃█▃▄▃▂▅▄▄▄▄▃▆▅▂▂▄▂▅▄▂
wandb:      train/ensemble_f1 ▁▄▃▂▅▃▃▃▅▂▁▂▃▃▄▂▅▃▆▄▂▃▇█▄▂▄▅▄▆▄▄▄▆▄▄▅▃▄▂
wandb:         train/mil_loss ▇▇▆▅▃▂▃▅▄▂▁▆▆▃▄▃▅▇▄▆▅▅▄▅▅▄▆▅▅▆▃▇▁▅▇▄▄█▆▂
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▅▄█▅▁▅▇▇▇▅█▅▄▇▅▅█▇█▇▇▄▇▅▅▅▅▇▅▄▅█▄█▅█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.32708
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.71717
wandb:      eval/avg_mil_loss 1.48084
wandb:       eval/ensemble_f1 0.71717
wandb:            test/avg_f1 0.6624
wandb:      test/avg_mil_loss 1.1247
wandb:       test/ensemble_f1 0.6624
wandb:           train/avg_f1 0.67398
wandb:      train/ensemble_f1 0.67398
wandb:         train/mil_loss 1.20402
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aruxvwoj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184455-aruxvwoj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tz9l220c with config:
wandb: 	actor_learning_rate: 1.909337551770474e-06
wandb: 	attention_dropout_p: 0.05902371186434818
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 82
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5396837573992235
wandb: 	temperature: 9.72349441210672
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184622-tz9l220c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tz9l220c
wandb: uploading history steps 78-83, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇██
wandb: best/eval_avg_mil_loss █▇▇▅▁
wandb:  best/eval_ensemble_f1 ▁▆▇██
wandb:            eval/avg_f1 ▇██▇▇▇██▂█▇▁█▁██▁▃▃▇█▇▇█▆▇▃█▇▁██▁███▇█▇█
wandb:      eval/avg_mil_loss ▂▂▂▇██▂▇▁█▁▁▂▄█▁██▄▁▁▆▁▁▂▆▂▁▂▂▁█▆▁▄▁▁▂▁▁
wandb:       eval/ensemble_f1 ▇▅█▇▇█▇█▇▂▇▇▇▁▂▁███▇▇▇▃█▇▇▇▇▃▇▁█▁▇█▆▆█▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▇▄██▇▇▄▅█▄▇▇▂▅▅▇▃▆▄▆▃▇▅▇▅█▇▁▇▄▄▅▇▅▂▆▅▂
wandb:      train/ensemble_f1 ▅▅▅██▅▁▅▆█▆▅▆▄▆▃▅▇▆▇▇▇█▇▆▇█▆▅▃█▅▆▃▇▃▇▇▂▃
wandb:         train/mil_loss ▂▃▆▁▄▃▄▅▁▁▅▇▁▂▂▄▁▁▄▁▅▂▄▇▅▄▃▂▃▆▃▂▄▂▁▅▂█▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.20183
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.20623
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.82985
wandb:      test/avg_mil_loss 0.39161
wandb:       test/ensemble_f1 0.82985
wandb:           train/avg_f1 0.67708
wandb:      train/ensemble_f1 0.67708
wandb:         train/mil_loss 0.31675
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tz9l220c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184622-tz9l220c/logs
wandb: Agent Starting Run: 53k5qmrf with config:
wandb: 	actor_learning_rate: 4.8334161452356604e-06
wandb: 	attention_dropout_p: 0.11169248506298946
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2788234677739013
wandb: 	temperature: 7.543742459432762
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184718-53k5qmrf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/53k5qmrf
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂███
wandb: best/eval_avg_mil_loss █▇▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂███
wandb:            eval/avg_f1 ▂▃█▁▂█▇█▂▂▂▄▃█▃▇▃██▂█▁▇▅▇▇▆▆▅▂▂▄█▇▃▃▅▇▃█
wandb:      eval/avg_mil_loss ▆▁▁█▁█▄▁▄▅▅▇▁▄▁▇▂▅▁▇▃▂▁▂▃▄▁▇▁▄▁▇▆▃▄▂▂▁▅▁
wandb:       eval/ensemble_f1 ▁▂▁▇█▂▇▄▂▄▇▁█▃█▄▅▂▃█▁▂█▂▇▇▅▇▃▇▅▂██▂█▁▇▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▄▂▆▆▃▄▇▄▆▇▆▆▂▅█▃▅▆▅▆▁▆▅▃█▅▄▅▆▄▆▃█▇▆█▇▅
wandb:      train/ensemble_f1 ▄▄▂▆██▄▆▇▅▃▅▂▅▅▃▆▆▆▁▆▆▆▃█▄▅▅▆▇▆▆▇▄▃▆▄▄▇▅
wandb:         train/mil_loss ▂▃▆▅█▅▃▆▃▅▆▃▆▃▆▂▇▄▄▃▃▅▆▂▄▃▄▄▁▄▄▃▅▄▃▃▆▄▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.22389
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.3642
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.15442
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.76285
wandb:      train/ensemble_f1 0.76285
wandb:         train/mil_loss 0.23948
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/53k5qmrf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184718-53k5qmrf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2cydy0fm with config:
wandb: 	actor_learning_rate: 8.147359655382609e-06
wandb: 	attention_dropout_p: 0.4572307122794088
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22279420095320435
wandb: 	temperature: 8.097148505730244
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184839-2cydy0fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2cydy0fm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss ▇▇█▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▇▇██▂▇▇▇▇▁▇▇▇██▇█▇▇▇▇▇▇▇▇▇▂▇▇█▇▇▇▇▇█▇▇▆█
wandb:      eval/avg_mil_loss ▁▂▁█▁▁▆▁▁▄▂▂█▁▁▂▂▁▁▂▁▂▂▂▂▂▁▁▁▁▂▁▂▁▁▂▂▂▁▁
wandb:       eval/ensemble_f1 ▇▇██▂▂▇▄▇▇▁▁▇▇▇█▇▇▇▇▇▇▇█▇▁█▇▁▇█▇▇▇█▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▄▇▅▇▅▇▆▄▆▁▇▆▇▇▇▆▇███▆▇▇▄██▇▃▆▇▅▆▃▇▆▇▇▇
wandb:      train/ensemble_f1 ▆▆██▇▇▇▄▇▅▇▆▅▂▆▁▇▆▇▇▇▇▆▆▇▃▇▇▃▃█▇▃▆▄▆▃▇▅▄
wandb:         train/mil_loss ▅▆▂▂▂▁▄▁▁▁▂▁▆▆▂▁▂▇▂▂▄▂▂▃▂▂▁▂▂▄▇█▁▆▂▅▃▄▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.20338
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.25636
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.14352
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.89113
wandb:      train/ensemble_f1 0.89113
wandb:         train/mil_loss 0.26269
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2cydy0fm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184839-2cydy0fm/logs
wandb: Agent Starting Run: zlgqs8ah with config:
wandb: 	actor_learning_rate: 1.181230641544056e-06
wandb: 	attention_dropout_p: 0.24771699275219844
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12708873687354627
wandb: 	temperature: 6.392416602757251
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184941-zlgqs8ah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zlgqs8ah
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇███
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇███
wandb:            eval/avg_f1 ▇▂▂▁▁█▃▂██▄▅▁▄▄▃▃▂▇█▅▃▂▃▂▂▇▄█▂█▅▃▂█▂▂▄▂▂
wandb:      eval/avg_mil_loss ▅█▄▆▁▁▆▄▇▅▁▃▃▄▃▃▆▅▁▁▁▇▇▁▇▇▁▃█▆▁▅▆▃██▇▃▄▆
wandb:       eval/ensemble_f1 ▃▄▇▂█▂█▃█▂▃▂▇▅▇▅▁▃▂▂▂▃▇▇▄▂▂▃█▂▂█▂▅▂▁▂█▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▆▅▅▄▄▃▃▄▅▂█▁▇▆▃▃▅▅▄▆▄▁▅▁▂▅▅▄▅▄▆▃▂▅▃▅▇▄
wandb:      train/ensemble_f1 ▂▄▆▆▃▃▇▇▂▆▆▆▄▄▅▄▄▄▂▄▂▁█▂▅▃▆▂▅▇▄▁▆▂▇▆▃▆▅▆
wandb:         train/mil_loss █▆▄▆▆▄▄▅▄▅▄▅█▅▆▆▇▄▇▇▃▇▄▁▅█▅▄▄▁▆▆▆▃█▄▇▆▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.32672
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 1.82417
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 1.81152
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.51662
wandb:      train/ensemble_f1 0.51662
wandb:         train/mil_loss 0.69882
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zlgqs8ah
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184941-zlgqs8ah/logs
wandb: Agent Starting Run: c5usn5jq with config:
wandb: 	actor_learning_rate: 1.3903041919490868e-06
wandb: 	attention_dropout_p: 0.09343685553284442
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6312922642404469
wandb: 	temperature: 6.916460304047644
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185048-c5usn5jq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5usn5jq
wandb: uploading history steps 104-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇███
wandb: best/eval_avg_mil_loss █▅▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▇███
wandb:            eval/avg_f1 ▁▁▇▃██▂▇▆▃█▇▇▇▇▇█▇▇▇█▃▇▇▇▇▅▂██▇▁██▇▂▇▇▂█
wandb:      eval/avg_mil_loss ██▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▇▁▁▅▁▇▁▇▅▁▁
wandb:       eval/ensemble_f1 ▁█▇▇▇▂▃▇▇▇▇█▃▇▃▃▇▃█▇▂█▇▇▇▂▇▇▇▇▅▂█▇▇▇▇▇▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▁▄▄▇▇▄▆▇▃▇▃▄▅▄▇▄▇█▅▆▇█▆▆▄▇▇▃▅▅▇█▆▆▃▇▇▂
wandb:      train/ensemble_f1 ▁▁▄▆▇▇▇▂▇▇▆▄▄▅▇▄▇▇▄▇▇▅▄▆▇▇▇▄▅▇▇▅▃▆▇▇▇▇▅█
wandb:         train/mil_loss ▅▅▂▁▁▂▂▄▂▄▂▇▃▄▅▁▂▂█▄▄▁▂▂▂▃▂▂▁▄▄▂▃▄▃▃▄▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████▁█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.34098
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.31549
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.57555
wandb:      test/avg_mil_loss 1.17136
wandb:       test/ensemble_f1 0.57555
wandb:           train/avg_f1 0.73435
wandb:      train/ensemble_f1 0.73435
wandb:         train/mil_loss 0.59214
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5usn5jq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185048-c5usn5jq/logs
wandb: Agent Starting Run: qw2ltd4a with config:
wandb: 	actor_learning_rate: 3.1340777827379824e-06
wandb: 	attention_dropout_p: 0.4004577508276517
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0641573589692479
wandb: 	temperature: 8.927259202939057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185155-qw2ltd4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qw2ltd4a
wandb: uploading history steps 104-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇████
wandb: best/eval_avg_mil_loss █▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇████
wandb:            eval/avg_f1 ▁▇█▇▇██▇▇▁█▇▁▁█▁▇▁▂▁▁▁▇▂██▇▂▁▇█▁█▁▇▁▇▇▂▇
wandb:      eval/avg_mil_loss ▁▇█▁▇▁▇█▁▇▁▁█▁▁▅▁▇▇▇█▆▁▁▇▁▇▁▁▁▁▁█▁▇█▆▁▁█
wandb:       eval/ensemble_f1 ▂▂▇▂▂▂▇▂▇▂▇█▇▂▃▂▂▁▇▂▂▃▇███▇▃██▂▇▇▃▂▇▇▂▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▄▄▄▄▆▅▆▆▄▃▇▄▁▄▆▆▆▆▆▄▅▆▅▆▆▁▄▄▆▅▅▄▆▅▄▄█▆
wandb:      train/ensemble_f1 █▆█▆▄▆▃▄▅██▄▄▇▇▁▅▇▆▆▇▂▂▆▄▂▃▇▄▂█▄▄█▆▄▇▆▄▆
wandb:         train/mil_loss ▆▆▅▆▄▆▆▄█▆▄▅▄▁▄▆▆▃▅▁▁▃▄▃▅▆▄▂▃▇▇▄▂▆▅█▇▆▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33299
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.31382
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.78723
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.64244
wandb:      train/ensemble_f1 0.64244
wandb:         train/mil_loss 1.1684
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qw2ltd4a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185155-qw2ltd4a/logs
wandb: Agent Starting Run: g3aint9e with config:
wandb: 	actor_learning_rate: 1.1703829755747248e-06
wandb: 	attention_dropout_p: 0.40622041656196795
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5131636402255703
wandb: 	temperature: 5.450710158890648
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185308-g3aint9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3aint9e
wandb: uploading history steps 104-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss ▄█▃█▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▇▃███▆▇█▆▇█▇▇██▇▁█▇▇▇▅▇▇▇▇▂▇▁▇▇█▃▂▇▇▆██▇
wandb:      eval/avg_mil_loss ▁▁▁▁▂▁▂▅▁█▁▁▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▅▁▂▁▂▁▁▁▁▁▂▂
wandb:       eval/ensemble_f1 ███▆▇▃▆██▁██▁▇▁██▇▇█▆█▇▇▇▇▁▃█▇█▃▇█▇▆█▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▆█▄▅▅▇▁▅▄▇▇▂▇▇▇▆▄█▄▄▄▇▇▄▂▄▅▅▆▆▆▆▄▅▅▅▂▅
wandb:      train/ensemble_f1 ▆▆▄▃▄▇▁▄▆▇▅▅▆▅▇▇▇▆▆█▆▆█▆▇▅▄▄▆▇█▄▆▅▇▅█▆▇▇
wandb:         train/mil_loss ▂▄▃▁▂▃▃▃█▅▃▂▂▃▇▃▂▄▅▅▂▂▁▂▆▃▃▂▆▂▂▂▂▅▆▄▂▁▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.22083
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.33575
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.1923
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.72872
wandb:      train/ensemble_f1 0.72872
wandb:         train/mil_loss 0.45544
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3aint9e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185308-g3aint9e/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n8m49mps with config:
wandb: 	actor_learning_rate: 1.9575335972323938e-05
wandb: 	attention_dropout_p: 0.48549670564858616
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06698350022523925
wandb: 	temperature: 8.875357789018349
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185435-n8m49mps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8m49mps
wandb: uploading history steps 90-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▄▆█
wandb:            eval/avg_f1 ▄▅▅▅▇▇▅█▆▅▇▇▄▁▇▇▇▅█▇▇▄▇▇▅█▇▇▄▆▄▇██▅▅▅▅▅▆
wandb:      eval/avg_mil_loss ▅▆▁▅▅▅▁▃▁▁▁▃▂▃▁▁▁▁▁▂█▁▂▆▅▁▂▅▃▅▁▁▁▁▅▇▂▆▂▂
wandb:       eval/ensemble_f1 ▅▅▅▇▂█▅█▁▇█▇▇▃▇▇▇▆▇▇▇▇▅▅▇▇▆▇▇▁█▄▇▇▇▄▇▅▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▇▇▅▅▆▃▆▅▄▄▃▇▆▃█▃▆▃▄▆▅▅▅▂▂▃█▄▇▆▅▄▇▄▂▄▆▆
wandb:      train/ensemble_f1 █▁▂▅▂▅▄▅▃▇▄▆▄▄▃█▆▆▄▇█▅▆▆▂▁▆▂▄▄█▆▅▄▆▄▃▄▆▄
wandb:         train/mil_loss ▄▄▇▆▃▂▃▂▄▃▅▄▄▃▂▃▃▁▆▁▄▄▅▃▅▃▃▃▅▂▅▂▂█▄▃▄▁▂▁
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.17927
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.82998
wandb:      eval/avg_mil_loss 0.4056
wandb:       eval/ensemble_f1 0.82998
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.123
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.85841
wandb:      train/ensemble_f1 0.85841
wandb:         train/mil_loss 0.46576
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8m49mps
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185435-n8m49mps/logs
wandb: Agent Starting Run: fxtdze6a with config:
wandb: 	actor_learning_rate: 0.00020919436668179927
wandb: 	attention_dropout_p: 0.46837115324009665
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30231796150229107
wandb: 	temperature: 7.890362342211245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185558-fxtdze6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fxtdze6a
wandb: uploading wandb-summary.json; uploading history steps 78-103, summary
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▇▇▇█▇▇█▇▇█▇▇▃▇▇▇▇█▇██▇▁█▇▇▇▇▇▇▆▇██▇██▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▂▁▁▁█▁▁▁▁▁▁▁▅▁▁▁▁▁▂▁▁▁▁▁▁▅▁▁▁▂▁▁▁█
wandb:       eval/ensemble_f1 ▇▇▇▇█▇█▇▇▇█▇▇▇▇▇▇▇▇▂██▇▇█▇▇▇▇▇██▁▆█▇▇▆▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▅▄▇▇▅▇▇▂▂▆▅▆▅▂▅▁▇▆▆▅▆▅█▇▅▅▄▅▁▅▁▃▅▆▆▁▆
wandb:      train/ensemble_f1 ▆▆▆▅▄▇▇█▆▇█▆█▄▅▆▇▄▆▄▇▇█▇▆▇▆▅▇▆▁▆▆▆▇▆▅▇▇▇
wandb:         train/mil_loss ▂▂▃▂▅▂▃█▂▂▄▆▄▂▁▃▆▂▂▁▁▂▆▂▅▂▂▂▂▁▁▅▃▂▂▁▁▄▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33344
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 1.64797
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.33569
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.88722
wandb:      train/ensemble_f1 0.88722
wandb:         train/mil_loss 0.22188
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fxtdze6a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185558-fxtdze6a/logs
wandb: Agent Starting Run: 0fj4bm6p with config:
wandb: 	actor_learning_rate: 4.2800164127400456e-05
wandb: 	attention_dropout_p: 0.2873404991573
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8090797278058636
wandb: 	temperature: 3.0515946080587764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185705-0fj4bm6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fj4bm6p
wandb: uploading history steps 113-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆█
wandb: best/eval_avg_mil_loss █▆█▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▆█
wandb:            eval/avg_f1 ▇▇▆▅▄▆▆█▇▇█▇▆██▇▄▆▇▇▇▆▇▇▇▇▇▇▇▁▂▇▇▇▇▆▂█▇▇
wandb:      eval/avg_mil_loss ▂▂▂▂▅▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂█▁▂▂▁▁
wandb:       eval/ensemble_f1 ▇▄▇▆▇▆▇████▆▇██▇█▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▃▇▁▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▁▂▆▂▃▃▆▄▅▂▂▅▄▄▂▅▇▅▃▅▃▆▇▄▆▆▆█▆▇▅▇▆▅▄██▇
wandb:      train/ensemble_f1 ▃▄▂▂▂▁▅▅▅▄▄▄▅▅▇▃▅▄▂▃▆▅▅▅▄▄▆▇▅▇▇▅▆▇▄███▆▇
wandb:         train/mil_loss ▅▆▂█▄▃▃▂▅▃▃▃▅▂▂▂▃▆▂▅█▂▂▄▂▁▄▁▂▆▄▂▂▁▃▂▂▂▂▂
wandb:      train/policy_loss ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄████████▁██▄██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.19708
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.91987
wandb:      eval/avg_mil_loss 0.19793
wandb:       eval/ensemble_f1 0.91987
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.30439
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.87875
wandb:      train/ensemble_f1 0.87875
wandb:         train/mil_loss 0.29074
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fj4bm6p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185705-0fj4bm6p/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e9d658e8 with config:
wandb: 	actor_learning_rate: 0.00023391412998486429
wandb: 	attention_dropout_p: 0.21831395091797243
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8328564919333218
wandb: 	temperature: 0.6019964979954573
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185843-e9d658e8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9d658e8
wandb: uploading history steps 50-74, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▇▂█▇▇▇▇▇▇▇▆▇▅▄▁▅█▇█▇▃█▃▇█▄▇▇▆▇███▆▇▅▃▇▇
wandb:      eval/avg_mil_loss ▁▅▁▇▁▁▁▁▄▁▁▁▁▁▁▁▁▄█▃▃▂▁▁▂▄▁▁▁▂▁▁▁▂▂▃▅▃▁▁
wandb:       eval/ensemble_f1 ▃▂█▅▁██▂███████▅▄▁█▅█▃▅▄▇▆███▅████▆█▄▅▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▆▆▅▅▄▆▆▅▄▇█▁▆▆▄▁▅▅▃▅▆▇▆▆▅▅█▃▆▄▇▇▆▆▇▅▄
wandb:      train/ensemble_f1 ▆▄▅▃▅▅▅▄▆▇▄▆▂▁▆▆▆▄▁▅▃▅▆▆▄▅▅█▆█▆▆▄▆▇▇▆▆▄▄
wandb:         train/mil_loss ▃▅▄▇▄▃▂▅▃▅▇▃▄▃▅▄▅█▄▄▁▆▃▃▄▃▆▇▂▄▄▃▆▂▃▆▄▄▆▄
wandb:      train/policy_loss ▆█▃▆▆▃▆▃▃▃▁█▆▁█▁▁▁▁▃▃▁▁▃▁▆▃█▃▆▁█▁▁▆█▁▆▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▆▆▃█▁█▁▃█▁▁█▃▃▃▁▁▃▁▆█▃█▁▁▆▁██▃▆▁▁▆▆▃█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.20758
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.27179
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13056
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.80303
wandb:      train/ensemble_f1 0.80303
wandb:         train/mil_loss 0.50252
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9d658e8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185843-e9d658e8/logs
wandb: Agent Starting Run: 9tl83048 with config:
wandb: 	actor_learning_rate: 2.5390782423330572e-05
wandb: 	attention_dropout_p: 0.32110894132765394
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6836913257432178
wandb: 	temperature: 1.7251926580369892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185936-9tl83048
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9tl83048
wandb: uploading history steps 131-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁███
wandb: best/eval_avg_mil_loss █▁▁▇
wandb:  best/eval_ensemble_f1 ▁███
wandb:            eval/avg_f1 █▇▇█▁▇███▇▇▁▇██▇▁█▇███▆▇█▇▃▇█▇██▇▇▆█▂▇▇▇
wandb:      eval/avg_mil_loss ▁▂▃▁▂▂▂▂▃▃▅▂▂▂▁▂▂▂▂█▃▂▂▂▂▁▂▂▁▃▁▂▂▅▃▂▂▂▂▃
wandb:       eval/ensemble_f1 ▇▇█▇▇▆██▇██▃▇▇█▇█▇█▇▇▇▁▇█▇██▇██▆▆██▂████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁█▁▇▆▇█▆▄▅▆▆▂▆▆▇▇▇▄▃▅▄▅▆▃▇▅▅▇▆▇▇▆▇██▇▇█
wandb:      train/ensemble_f1 ▆▆▆▆▅▇▆▇▆▃▆▅▆▅▁█▅▅▆▆▇▇▃▆▄▇▇▃▇▅▆▇▅█▇▇▅▆▇▇
wandb:         train/mil_loss ▃▄▂▃▂▅▃▁█▄▃▃▄▂▄▄█▂▃█▃▄▃▃▆█▃▂▄▃▃▃▃▄▄█▂▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.30721
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.35637
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13885
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.88229
wandb:      train/ensemble_f1 0.88229
wandb:         train/mil_loss 0.31145
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9tl83048
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185936-9tl83048/logs
wandb: Agent Starting Run: t6cunj1t with config:
wandb: 	actor_learning_rate: 0.0006462219630111613
wandb: 	attention_dropout_p: 0.012731702057569128
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6122882382788517
wandb: 	temperature: 6.757712476823511
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190104-t6cunj1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t6cunj1t
wandb: uploading wandb-summary.json
wandb: uploading history steps 104-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆█▄▂▅█▁▂▂▂▅▇▄▁▁▂▇▂▃▁██▂▂▇█▂▁▃▃██▄▂██▂▇█
wandb:      eval/avg_mil_loss ▁▂▄▁▁▂▄▆▁▄██▇▅▆▂▅▇▁▁▇▁▄▇▄▁▁▅▇▇▁▇▅▇▁▇▅▁▂▁
wandb:       eval/ensemble_f1 ▇▃▇▂▁▂▃▇▄▄▃▁▁▂▄▅▂▃█▂▄▂▂▂▇██▂█▇▂▆▇▃█▇▂▁▂▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▅▅▅▂▆▅▆▆▃▄▇▁▆▆▅▄▃▃▆▅▆▂▅▄▆▄▆▃▇▂█▄▄▄▇▁
wandb:      train/ensemble_f1 ▇█▄▁▅▄▅▄▁▅▆▅▄▅▅▂▄▄▁▂▅█▅▃▅▅▂▄▁▃▅▃▃▄▅▅▃▄▆▆
wandb:         train/mil_loss ▅▄▃▂▅▄█▂▂▄▄▄▆▅▃▅▅█▂▄▅▅▄▆▄▁▂▄▃▄▃▂▁▆▅▂▆▂▄▄
wandb:      train/policy_loss █▁██████▄███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9399
wandb: best/eval_avg_mil_loss 0.18431
wandb:  best/eval_ensemble_f1 0.9399
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.24813
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.14024
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.55975
wandb:      train/ensemble_f1 0.55975
wandb:         train/mil_loss 0.90773
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t6cunj1t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190104-t6cunj1t/logs
wandb: Agent Starting Run: xxm7s9as with config:
wandb: 	actor_learning_rate: 0.0007296496159561975
wandb: 	attention_dropout_p: 0.012708202667725764
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35417662727761023
wandb: 	temperature: 4.8180310963880615
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190221-xxm7s9as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxm7s9as
wandb: uploading wandb-summary.json
wandb: uploading history steps 105-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▂▅▇▇█▇█▂██▅▃▇██▇▇▇██▂▇▁▂▂█▆▇█▃▁▆▆█▇▂▇▂
wandb:      eval/avg_mil_loss ▁▂▇▁▁▁▁██▁▂▂▁▁▁▂▁▁▁▅█▁█▁▁▁▃▁▁▂▇▁▃▁▁▇▁█▁▁
wandb:       eval/ensemble_f1 ██▇▂▇▇███▁▂▃█▇▆▇▂▂▂█▁▂▇▂█▄█▇█▇▃█▆▂▄█▂▇▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▆▄▂▇▄▂▇▅▆██▄█▄█▅▄▇▆▆▇▆▁▇▆▄▃█▇▃▅▆█▄▄▅▆
wandb:      train/ensemble_f1 ▄▇▆▅▄▅▆▄▂▆▄▄▄▇▇█▆█▄█▃▇▃▂▅█▅▆▁▆█▃▇▇▆▆▇▇▄▆
wandb:         train/mil_loss ▆▄▂▆▂▂▅▅▃▂▅▆▅▅▇▃▆▃▄▃▂▄▄▇▅▃▁▃▂█▁▂▆▅▂▃▆▆▁▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.33241
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.32968
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.87957
wandb:      test/avg_mil_loss 0.29597
wandb:       test/ensemble_f1 0.87957
wandb:           train/avg_f1 0.82357
wandb:      train/ensemble_f1 0.82357
wandb:         train/mil_loss 0.9866
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxm7s9as
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190221-xxm7s9as/logs
wandb: Agent Starting Run: 7rq2mzxd with config:
wandb: 	actor_learning_rate: 0.0001225647449189002
wandb: 	attention_dropout_p: 0.3742860904061951
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 82
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5076363397744916
wandb: 	temperature: 4.890462727109362
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190340-7rq2mzxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rq2mzxd
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄██
wandb: best/eval_avg_mil_loss █▃▆▁▃
wandb:  best/eval_ensemble_f1 ▁▁▄██
wandb:            eval/avg_f1 ██▇▇█▇█▇▅▇▁▇█▇█▁▇▇▁▇▁▇▇████▇█▇▇█▇█▇▆█▁██
wandb:      eval/avg_mil_loss ▂▁▁▁▁█▂▁▁▁▁▂▁▁▁▂▁▅▂▂▇▅▁▂▁▁▁▁▇▁▁▂▂▁▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ██▇█▁▇█▁▇██▂██▇▃▂▂▇▇▇▂▁▂█████▇▇▇▇█▇█▆▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▃▃▄█▄▅▅▅▇▅▃▇▂▅▅▆▅▆▄█▅▁▄▂▃▇▃▅▅▄█▃▅▇▆▄▄▆
wandb:      train/ensemble_f1 ▄▅▃▃▅▄█▃▆▁▅▅▆▄▅▇▇▃▇█▅▆█▅▇▆▁▃▃▇▃▂▅▄█▄▄▇▄▆
wandb:         train/mil_loss ▃▃▅▄▃▂▃▅▅▁▅▂▂▅▃▂▄▇▆▃▅▃▄▄▁▇▁▄▃▃▇▁▂▃▃▂▆▃█▅
wandb:      train/policy_loss █▆█▁▃▆▆█▃▆▃█▃▆▆█▆▆█▃▃▁▆▆▆▆▆▆█▃▃█▆▃▃▆▃▆██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▆▃▃▆█▆▃▆▆▃▆▆▆█▆▃█▁▆▆▆█▆▃▃▃█▁█▆▃█▃█▃▃▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.24319
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.3024
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.18332
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.84375
wandb:      train/ensemble_f1 0.84375
wandb:         train/mil_loss 0.9227
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rq2mzxd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190340-7rq2mzxd/logs
wandb: Agent Starting Run: iiyd8uqq with config:
wandb: 	actor_learning_rate: 7.635199747164327e-05
wandb: 	attention_dropout_p: 0.4644147891744113
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8196089386462171
wandb: 	temperature: 4.1117841457888735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190437-iiyd8uqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iiyd8uqq
wandb: uploading history steps 124-141, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃█
wandb: best/eval_avg_mil_loss ▄█▄▁
wandb:  best/eval_ensemble_f1 ▁▁▃█
wandb:            eval/avg_f1 ▇▇▇▇▇▁▂▇▇▇▇▇▇█▇█▇▇▇▃▇█▇▇▇█▇▇▄█▂▆▇▇▇▇█▇▂▆
wandb:      eval/avg_mil_loss ▂▂▃▂▁▂█▂▆▁▂▁▇▂▂▁▁▂▂▂▁▅▁▁▂▂▂▂▂▂▁▇▁█▂▁▁▂█▂
wandb:       eval/ensemble_f1 ▇▁▄▇▇▇▂▄▇▇▇▂█▇▇▃▇▄▇█▇▇▇▇▇▇▇▇▅█▂▇▇▇▁▇▂▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▄▆▄▄▆▁█▃▅▂▁▆▅▄▆▅▆▂▄▄▄▇▆▄▆▁▂▅▆▄▆▇▅▆▂▁▅▆
wandb:      train/ensemble_f1 ▇▅▇▆▅▆▅▅▄▃▄▅▇▆▁▆▆▇▆▆▃▆▄▇█▅▆███▇▇▄▆▇▇▇█▄▆
wandb:         train/mil_loss ▅▂▃▂▄▆▄▂▃▁▂▃▇▃▆▅▇▇▇▂█▃▅▄▅▄▄▃▇▂▁▅▃█▅▂▂▂▂▁
wandb:      train/policy_loss ▁▃▃▃▆▁▁▃▁▆▃▆▃▆▆▆▁▁▁█▃▁▃▆▁▁▃▆▁█▃▁▁▁▆▆█▆▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▃▃▄▆▄▃▄▃▆▄▆▆▄▆▆▆▄▄▄▃█▄▃▄▃▄▆▄▄▃▆█▆▁▃▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.20982
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.43246
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.16576
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.77202
wandb:      train/ensemble_f1 0.77202
wandb:         train/mil_loss 0.53281
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iiyd8uqq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190437-iiyd8uqq/logs
wandb: Agent Starting Run: ny6hygh6 with config:
wandb: 	actor_learning_rate: 1.6549726107846152e-05
wandb: 	attention_dropout_p: 0.06940039417099503
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.36702051536236147
wandb: 	temperature: 1.3761897427050218
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190609-ny6hygh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ny6hygh6
wandb: uploading history steps 114-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▄█
wandb: best/eval_avg_mil_loss ▅█▄▇▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▄█
wandb:            eval/avg_f1 ▄▁▄▂█▆▅▁▅▁▂▁▂▇▂▅▅▂▅▂▇▇▄█▂▅▅▇▅▅▃▂▅▅▅▆▇▅▂▃
wandb:      eval/avg_mil_loss ▅▃▅▅▂▁█▆▁▁▅▇▇▄▃▆▄▇▂▄▂▅▄▃▇▂▃▃▁▄▄▁▄▄▁▄▁▃▂▃
wandb:       eval/ensemble_f1 ▁▂▅▆█▁▅▂▂█▆▅▁▂▇▂▅▂▅▃▁▁▇▅▄▅▄▃▃▇▆▃▅▅▇▆▅▆▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄█▆▄▄▅▂▅▆▄▄▃▄▃▆▅▆▆▇▆▁▄▆▄▆▄▆▃▄▁▅▄▆▅█▄▃▃
wandb:      train/ensemble_f1 ▄▅▇▆▅▅▂▃▄▄▄▂▇▄▃█▇▄▇▅▁▆▇▇▆▄▃▅▆▅▅▁▇▄▅█▄▆▆▅
wandb:         train/mil_loss ▅▄▅▅▆▄▅▅▄▇▄▆█▇▅▃▇▄▆▅▄▅▄▄▆▇▅▃▁▆▃▄▁▆▅▃▆▅▅▅
wandb:      train/policy_loss ▂▅▂▄▅▂▅▇▂▄▅▅▂▂▄▅▂▅▅▁▂▇▅▂▂█▁▅▇▂▂▄▄▅▅▅▅▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▆▃▁█▆▃▄▆▆▃▃▄▃▆▆▃▆▆▆▃▆█▃▆▄▃▆▄▆▆█▃▄▃▃▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.30161
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.70833
wandb:      eval/avg_mil_loss 0.77992
wandb:       eval/ensemble_f1 0.70833
wandb:            test/avg_f1 0.7599
wandb:      test/avg_mil_loss 1.0262
wandb:       test/ensemble_f1 0.7599
wandb:           train/avg_f1 0.74546
wandb:      train/ensemble_f1 0.74546
wandb:         train/mil_loss 0.91678
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ny6hygh6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190609-ny6hygh6/logs
wandb: Agent Starting Run: xtlu6fwh with config:
wandb: 	actor_learning_rate: 1.9991153573730703e-06
wandb: 	attention_dropout_p: 0.18234901359324268
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26680334382587834
wandb: 	temperature: 2.5553886318827357
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190732-xtlu6fwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xtlu6fwh
wandb: uploading history steps 90-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▅▇▆▂▄▃▇▆▃▇▅█▅▆▆▃▆▅▆▇▆█▁▆▆▆▅▄▄█▄▆▅▆▆██▃
wandb:      eval/avg_mil_loss ▁▄▆▂▅▂▅▂▆▂▂▄▂█▂▆▄▃▃▂▂▄▂▅█▂▃▇▂▂▂▄▁▃▂▄▄▄▂▃
wandb:       eval/ensemble_f1 █▇▇▆▃▄▆▂▄▄▆▇▂▅▇▆▆▆▅▃▆▅▅▃▅██▆▅▄▆▇▇█▇▆▇▁█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▅▆▄▆▅▅▄▆█▅▅█▅▂▄▇▄▄▅▅▁▃▆▆▄▆▇█▆▄▄▄▂▆▆▄▆
wandb:      train/ensemble_f1 ▆▁▄▄▅▄▂█▄█▇▅▁▄▃▇▃▆▇▃▇▃▅▇▂▂▇▅▆▃▄▄▆▃▂▆▂▅▆▄
wandb:         train/mil_loss ▃▄▅▆▄▇▅▂▅▄▅▆▅▄▃▅▄▄▃▇▆▅▃▃▃▅▄▄▂█▄▇▆▅▃▅▃▅▄▁
wandb:      train/policy_loss ▇▄▇▂▄▁▄▅▄▄▄▅▄▄▅▇██▄█▇▇▇▇██▄▇██▇▇▇▄▄▄▇▂▄▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▁▃▄▄▄▆▄▃▄▃▃▃▄█▆▃██▆▄▁█▃▄▃▆▆█▆▆▆▄▆▃▆▆▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.19215
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.72115
wandb:      eval/avg_mil_loss 0.9955
wandb:       eval/ensemble_f1 0.72115
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.16783
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.83037
wandb:      train/ensemble_f1 0.83037
wandb:         train/mil_loss 0.47202
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xtlu6fwh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190732-xtlu6fwh/logs
wandb: Agent Starting Run: 3pyd9cfj with config:
wandb: 	actor_learning_rate: 1.7092745017092033e-05
wandb: 	attention_dropout_p: 0.4085038355372377
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9560373384080748
wandb: 	temperature: 7.522668628654894
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190854-3pyd9cfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3pyd9cfj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂██
wandb: best/eval_avg_mil_loss ███▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂██
wandb:            eval/avg_f1 ▂██▂█▄▇▃▂▂█▂▃▃▃█▂▃▂█▁▃██▃▂█▁█▃▄▄▂▂▃▂▆▇▂▃
wandb:      eval/avg_mil_loss ▇▇█▁▁▅▇▂▇▇▇▆▂▁▁▇█▆▇▁▁▇▁▁▇▇▁▇▇▄▁▆▇▆▄▇▁▇▁▇
wandb:       eval/ensemble_f1 ▂▃▃▂█▃▂▃▂▃▃█▂▂█▂▃▂██▃█▃█▃▃▂▂▂▃▂▃▂▃▄▂▂▁▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅█▆▄▂▂▆▄▅▂▆▅▂▂▂▁▂▁▁▇▄▆▄▃▁▂▅▇▁▂▂▂▃▂▄▃▄▆▂
wandb:      train/ensemble_f1 ▁▂▂▄▆▅▆▇▅▅▃▄▇▆▅▅▇▂▅▂█▁▃▃▁▄▇▆▅▃▇▄▂▂▂▂▃▄▆▆
wandb:         train/mil_loss ▆▅▃▆▄▁▃▂█▃▅▃▅▂▆▇▆▁▂▅▃▇▅▃▅▆▅▁▆▅▆▃▇▃█▄▁▁▇▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.30135
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.22914
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 1.44274
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.71693
wandb:      train/ensemble_f1 0.71693
wandb:         train/mil_loss 1.98929
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3pyd9cfj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190854-3pyd9cfj/logs
wandb: Agent Starting Run: pg22nyef with config:
wandb: 	actor_learning_rate: 0.00016830551747921548
wandb: 	attention_dropout_p: 0.4920781981168104
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45389693672524634
wandb: 	temperature: 1.60051501073468
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191002-pg22nyef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pg22nyef
wandb: uploading history steps 52-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇█▇▂▇▇▂▁▇▇█▇▇▇▂▇▇▇█▇▃▇▁▇▇█▇▇▇▁▇▇▁▇▇▇▇▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▆█▁▁▁▁▁▁▆▁▁▁▁▁▁▁█▁▁▁▁▁█▁▁▁▁█▁▁▁▁▁▆
wandb:       eval/ensemble_f1 █▇▇▇▇▇▇▂▁█▇▇█▇▇▇▇▇▇▇▇█▇▃▇▇▇▇█▇▁▇▁▇▇▁▁▁▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▇█▇▇█▇▁▇▇▇▅▂▇▃▄▇▇█▁▄▃▇▇▅▇▇▇▇█▆▇▄▇█▁▅▇▇
wandb:      train/ensemble_f1 █▅▇█▇██▅▇▃▅▇▆▇▇▆▄▅▇▇▅▅▁▇▇▅▅▇▇█▆▇▇▇▆▆▇▇▇▇
wandb:         train/mil_loss ▁▂▁▃▃▂▃▁▅▃▁▁▃█▄▂▅▁▄▇▄▂▁▂▁▁▃▃▁▃▁▁▃▃▁▃▃▆▁▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31893
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 1.39557
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.13663
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88776
wandb:      train/ensemble_f1 0.88776
wandb:         train/mil_loss 1.1022
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pg22nyef
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191002-pg22nyef/logs
wandb: Agent Starting Run: drtqotof with config:
wandb: 	actor_learning_rate: 0.0007594078954144196
wandb: 	attention_dropout_p: 0.27828146082630145
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7505755038677164
wandb: 	temperature: 9.796588792091294
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191049-drtqotof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drtqotof
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▅▁▅▅▅▅▅▁▅▅▂▅▅▅▁▅▅▅▅▁▅▆▅▅▅██▅▅█▅▁▅▆▆▁▁▅█
wandb:      eval/avg_mil_loss ▇▅▄▇▁█▁█▄▆▄▇▅▄▃█▄▄▄▃▅▅▃▃▄▃▇▅▆▄▅▃▄▁▁▃▁▅▇▄
wandb:       eval/ensemble_f1 ▂▅█▅▅█▅█▂▅▅▁▅▁▅▅▂▅▂▅▅▆▂▅▆██▅▅▅▂▅▂▅▅▂▂▂▆▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▂▅▃▆▆▄▃▃▄▆▆▆▅▁▄▅▃▄▇▂▆▅▁▄▄▇▂▆▇▆▅▇▄▄▄█▇▂
wandb:      train/ensemble_f1 ▆▅▇▂▅▁▇▇▄▄▃▇▄▆▃▅▅▇▆▆▅▆▅▆▇▂▇▂▁▃█▃▆▄▇▇▆█▅▁
wandb:         train/mil_loss ▃▁▄▇▄▄▅▇▅▆▄▄▄▁▅▄█▄▅▅▆▆█▁▇▆▃▃▄▇▄▂▃▂▅▂▅▇▅▆
wandb:      train/policy_loss ▂▂█▅▄▅█▅▅▅▅▇▄▁▂▁█▁▂▇▇▄▇▄▅▄▄█▄▇█▄▄▇▇▄▄▇▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.33588
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 1.78878
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.75962
wandb:      test/avg_mil_loss 1.15479
wandb:       test/ensemble_f1 0.75962
wandb:           train/avg_f1 0.67175
wandb:      train/ensemble_f1 0.67175
wandb:         train/mil_loss 1.12547
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drtqotof
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191049-drtqotof/logs
wandb: Agent Starting Run: 9kgnz81o with config:
wandb: 	actor_learning_rate: 4.1819321132782706e-05
wandb: 	attention_dropout_p: 0.4329268070449281
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6531070487968463
wandb: 	temperature: 6.164765105776059
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191206-9kgnz81o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kgnz81o
wandb: uploading history steps 79-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▇▁█▁▇▇▇▁▄█▇▆▁▁▃██▇█▁▁▇█▁▇█▃▇█▇▇██▇▂▇▇█▁
wandb:      eval/avg_mil_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▂▁▁▃▁▃▁▃▁▂▁▁▁▁▁▁▁▁▁▁▅
wandb:       eval/ensemble_f1 ▁▁▁▇█▇█▇▃▇▇▁▇█▁▄▆▁▁▃▇▃█▁██▁▅██▇▇▂██▂▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▅▇▅▅▅▄▇▄▆█▅▆▇▄▇█▇▆█▇▆▆▇▄█▄▃█▇▇▇▆▇▄▇▁▆▆
wandb:      train/ensemble_f1 ▆▆▅▄▇█▇▅▅█▆▅▁▄▆▇▆█▆▇▅▆▆▇▄▆▄█▇▅▆▇▇▄█▆▇▇▇▆
wandb:         train/mil_loss ▅▇▂▂▃▄▂▅▂▁▄▁▃▅▃▅▄▄█▄▅▂▃▃▃▆▂▁▂▆▃▂▄▂▂▃▄▁▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.31959
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.57835
wandb:      eval/avg_mil_loss 1.32791
wandb:       eval/ensemble_f1 0.57835
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.13282
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.8101
wandb:      train/ensemble_f1 0.8101
wandb:         train/mil_loss 0.63194
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kgnz81o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191206-9kgnz81o/logs
wandb: Agent Starting Run: ggo7be5u with config:
wandb: 	actor_learning_rate: 0.0003660003733881379
wandb: 	attention_dropout_p: 0.021999199016754956
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2988385454623993
wandb: 	temperature: 8.016795682384984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191308-ggo7be5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ggo7be5u
wandb: uploading history steps 136-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆████
wandb: best/eval_avg_mil_loss █▇▃▃▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆████
wandb:            eval/avg_f1 ▄▅▄▅▂▆▄▂▅▇▂▆▂▇▆▆▆▇▅▇▆▁▂▃▇▇▄▂▇▅▇▆▆▇▆▆▄▁█▇
wandb:      eval/avg_mil_loss ▆▆▃▁▄▁▄▅█▄▃▄▄▆▂▂▇▆▁▂▁▃▆▃▃▄▆▁▁▁▅▁▃▂▂▁▁▃▁▄
wandb:       eval/ensemble_f1 ▃█▄▅▆▄▅▇▅█▂▇▆▇▅▆▅▄▅▇▂▆▄█▄▅▅▆▇▆▅▆▇▃▆▁▅██▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▄█▅▄▂▃▂▃▄▃▅▄▆▅▁▃▁▃▅▅▄▃▄▃▄▂▁▂▄▃▅▄▂▃▄▆▄
wandb:      train/ensemble_f1 ▄▆▁█▅▄▃▃▃▄▆▃▆▄▅▃▂▆▃▃▆▆▆▄▅▄▇▅▅▄▅▄▅▅▃▄▅▄▆▄
wandb:         train/mil_loss ▆▄▅▅▄▅▅▅▅█▅▄▇▁▆▄▄▇▅▆▅▃▄▇▄▂▇▆▅▃▆▆▄▆▅▆█▆▃█
wandb:      train/policy_loss ▃▆▃▆▆▃█▃▆█▆▆▃▃▅▃▆▅▃▃▆▆█▆▅▆▁█▁▆▅▁▅▃▅▆▆▆█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▅▇▅▇▄█▅▇▇▇▇█▄▄▇▇▅▄▇▄▇▁▂▂▇█▅▅▄▇▄▄▅▇▄▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.24297
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.32153
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.15839
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.80122
wandb:      train/ensemble_f1 0.80122
wandb:         train/mil_loss 0.61118
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ggo7be5u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191308-ggo7be5u/logs
wandb: Agent Starting Run: g32bazu2 with config:
wandb: 	actor_learning_rate: 3.597866881895068e-05
wandb: 	attention_dropout_p: 0.08133026048313918
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4196657145785657
wandb: 	temperature: 2.268086632324157
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191456-g32bazu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g32bazu2
wandb: uploading history steps 46-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▃█▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 █▅▅▅▁▆█▆▆▅█▂▄▅▂▂▄▅▆▆▆▂▆█▃▆▆▃▂▅▆█▁▆▄▅█▅▂▂
wandb:      eval/avg_mil_loss ▁▄▅▅█▄▁▃▃▄▁▇▄▇▃▇▅▅▄▃▄▆▂▁▆▄▄▅▇▃▁▃▁█▃█▁▅▇▇
wandb:       eval/ensemble_f1 █▅▅▅▁▆█▆▆▅█▂▅▂▆▂▅▆▆▅▂▆█▃▃▆▃▂▅▅▆█▁▆▄▅█▅▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▆▂▂▄▇▅▃▄▃▇▄█▃▄▇▃▄▂▅▂▆▁█▃▄▄▄▅▇▂▃▆▆▅▂▃▃
wandb:      train/ensemble_f1 ▁▂▆▁▂▄▇▅▂▅▄▃▇▄█▃▄▇▃▄▂▅▂▆▁█▃▄▄▄▅▇▂▃▅▁▆▄▃▂
wandb:         train/mil_loss ▇▅▄▅▂▁▅▇▃▄▄▁▂▇▂▅▂▄▃▃▄▄▅▃▄▃▁▇█▃▃▄▂▆▅▆▄▂▆▇
wandb:      train/policy_loss ██████████████▁█████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▁██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.23137
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.53249
wandb:      eval/avg_mil_loss 1.9016
wandb:       eval/ensemble_f1 0.53249
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 2.21222
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.69776
wandb:      train/ensemble_f1 0.69776
wandb:         train/mil_loss 1.38446
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g32bazu2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191456-g32bazu2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 40z9i5x4 with config:
wandb: 	actor_learning_rate: 4.922776753112555e-06
wandb: 	attention_dropout_p: 0.0010974430481890396
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32303872413872126
wandb: 	temperature: 6.563120474868156
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191543-40z9i5x4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40z9i5x4
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▃▇▇▂█▅▇▇▁▇█▁▁███▇███▇▅▂█▇▇▇▇▃█▇▂▃█▇▃▇█▇
wandb:      eval/avg_mil_loss ▇▄▂▇▇▁▂▆▂▁▇▂▆▁▅▂▆▁▂▂▂█▇▁▂▆▆▂▂▅▁▂▇▂▂▁▄▅▂▂
wandb:       eval/ensemble_f1 █▂▃▇▇▂▇█▅▅▇▂▇█▁▃██▅▇▇█▇▇▅▂█▂▇▇█▂▇▂▇▃▇▇█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▁▃▆▇▅▄▄▅█▇▅▅▅▂▆▇▆▄▅▁▆▅▄▇▆▄▆▇▆▅▅▅█▃▁▇▆▁
wandb:      train/ensemble_f1 ▂▃▄▆▁▆▆▅▂▅█▆▅▅▅▅▇▆▄▅▇▂▄▄▂▆▆▆▆▄▅██▂▃▇▆▅█▆
wandb:         train/mil_loss ▃▅▃▆▆▅▆▁▄▃▂▅▃▂▄▃▂▂▆▂▅▄▄▅▅▄█▄▃▃▂▃▃▆▄▃▅▆▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.19507
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.87879
wandb:      eval/avg_mil_loss 0.28004
wandb:       eval/ensemble_f1 0.87879
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.20078
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.7402
wandb:      train/ensemble_f1 0.7402
wandb:         train/mil_loss 1.32929
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40z9i5x4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191543-40z9i5x4/logs
wandb: Agent Starting Run: bv2gm4jl with config:
wandb: 	actor_learning_rate: 1.6212445686678054e-06
wandb: 	attention_dropout_p: 0.43383384865374536
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6934027720926428
wandb: 	temperature: 6.588260033230515
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191629-bv2gm4jl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bv2gm4jl
wandb: uploading history steps 180-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇▇█
wandb: best/eval_avg_mil_loss █▄▁▂▁
wandb:  best/eval_ensemble_f1 ▁▂▇▇█
wandb:            eval/avg_f1 ▅▅▂█▃▂▅▄▃▅▄▅▁▂▂▂▆▃▅▆▂▂▃▄▅▅█▁▅▁▅▂█▃█▃▂▅▂▅
wandb:      eval/avg_mil_loss ▅▄▄▅▇▁▅▇▇▅▂▇▆▇▃▇▆▇▆▅▆▃▇▃▁▃▅▇▅▇█▂▁█▇▆█▂▆▆
wandb:       eval/ensemble_f1 ▅▁▅▁▁▅▅▃▅▁▂▂▅▅█▅▁▂▇▅▆▆▁▅▁▁▁▁█▁▁█▅▂▁▁▁█▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▅█▇▇▆▅▅▅▆▁▂▁▅▆▅▃▆▅▃▄▇▆▄▅▅▂▆▄▅▅▆▄▇▅▆▇▇
wandb:      train/ensemble_f1 ▂█▅▄▅▆▇▇▆▇▄▅▁▇▂▇▆▃▆▄▅▇▅▆▆█▅█▇▇▄▄▆▆▅▅▆▇▆█
wandb:         train/mil_loss ▅▁▆▄▆▃█▃▅▄▄▄▃▄▄▃▄▅▆▁▃▂▇▆▃▄▇▃▄▄▅▂▄▃▄▅▅▄▅▂
wandb:      train/policy_loss ▄▃▆█▄▃▄█▄▄▁█▄▆▃▆▄▆▄▄▄▄▆▄▄█▆▆▁▁▆▄▄▆▄▁▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▄▂▂▇▅▅▂▂█▄▅▄▂▄▅▅▄▄▄▂▄▇▄▅▁▂▄▂▅▂▁▅▅▅▅▅▅▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.25211
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.5864
wandb:      eval/avg_mil_loss 1.86381
wandb:       eval/ensemble_f1 0.5864
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 1.9767
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.74779
wandb:      train/ensemble_f1 0.74779
wandb:         train/mil_loss 1.06484
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bv2gm4jl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191629-bv2gm4jl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 93092wbk with config:
wandb: 	actor_learning_rate: 0.0003252542042313587
wandb: 	attention_dropout_p: 0.29202450475570485
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8639643344958937
wandb: 	temperature: 4.742908060224553
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191849-93092wbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93092wbk
wandb: uploading history steps 104-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇████
wandb: best/eval_avg_mil_loss █▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇▇████
wandb:            eval/avg_f1 ▇▃█▂▂▁██▇▇▇▇▅█▇▆▅▇█▃▅██▇▁▂▁█▁▇█▁▇▂█▇▂▁▁▅
wandb:      eval/avg_mil_loss ▄▁▁▇▁▆▃▁▁▂▁▃▁▁▁▁▁▄▃▃▇▁▃▁▂▁▁▁▂▅█▇▇▁▅▆▅▂▁▁
wandb:       eval/ensemble_f1 ▃▇▃▂▂▁███▇▅▃▇▅█▇▃▂▅███▁█▁██▁█▇▃▇██▂▇▇█▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▄▇▇█▆▆▇▄▆▅▇▅▆▆▄▆▅▆▄▆▅▅▄▆▄▄▇▁▄▅▇█▇█▄▅▃▆
wandb:      train/ensemble_f1 ▅▄█▃▆▆▆▇▆▅▂▆▄▅▆▆▆▄▅▆▅▃▄▅▅▆▇▇▇▁▆▅▆▄▆▅▅█▄▇
wandb:         train/mil_loss ▄▅▆▆▄▂▃▄▄▄▅▅▃▆▄▅▄▅▄▅▄▆▃▄▃█▇▃▃▄▄▂▆▆▁▃▄▆▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.30428
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.30124
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.625
wandb:      test/avg_mil_loss 1.01218
wandb:       test/ensemble_f1 0.625
wandb:           train/avg_f1 0.75154
wandb:      train/ensemble_f1 0.75154
wandb:         train/mil_loss 0.95587
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93092wbk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191849-93092wbk/logs
wandb: Agent Starting Run: xv35egnu with config:
wandb: 	actor_learning_rate: 7.087213062324258e-05
wandb: 	attention_dropout_p: 0.46104130330418136
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.819135814416524
wandb: 	temperature: 7.311836258378581
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192006-xv35egnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv35egnu
wandb: uploading history steps 104-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅█
wandb: best/eval_avg_mil_loss ▆▄▃▇█▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅█
wandb:            eval/avg_f1 ▇▇▇▇▇▆█▇▇▆▇▂▇▇▇▇▁█▁▇▄▂▇▇▇▆▇▁▂▁█▇▇▂▇▇▇▇▆▄
wandb:      eval/avg_mil_loss ▇▁▁▁▁▁▁▁▂▁▁▁▁▁▇▄▁▁▁▂▁▁█▆▆▆▁▇▁▁▅▁▇█▁▂▁▄▄▆
wandb:       eval/ensemble_f1 ▇▇▇▇▁▇▇▇▆▇▇▇▇█▄▇▇▇▆█▇▇▂▂▇▇▇▁▇▇▇▇▇▇▇▇▁▇▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▄▅▅▅▂▆▆█▆▆▆▃▆▄█▅▂█▆▄▂▆▆▄▆▄▅▆▇▅▁▅▇▇▇▇▂▇
wandb:      train/ensemble_f1 █▆▄▆▆█▆██▇█▆▄▄█▅▇▆█▆▆█▆▇▆▄▇▅▆▁▅▇█▇▇▄▇██▆
wandb:         train/mil_loss ▅▂▆▁▁▄▅▁▂▃▄▂█▃▄▃▁▁▂▅▃▅█▃▃▃▃▇▂▂▁█▁▅▂▄▅▅▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94995
wandb: best/eval_avg_mil_loss 0.19572
wandb:  best/eval_ensemble_f1 0.94995
wandb:            eval/avg_f1 0.53249
wandb:      eval/avg_mil_loss 1.54346
wandb:       eval/ensemble_f1 0.53249
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.14183
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.77494
wandb:      train/ensemble_f1 0.77494
wandb:         train/mil_loss 0.91185
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv35egnu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192006-xv35egnu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 06gp7xlv with config:
wandb: 	actor_learning_rate: 0.0003603816913222344
wandb: 	attention_dropout_p: 0.06617309745551214
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20083612208372825
wandb: 	temperature: 6.972458925880122
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192134-06gp7xlv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06gp7xlv
wandb: uploading history steps 136-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇▇▇▇██
wandb: best/eval_avg_mil_loss █▂▁▂▁▁▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇▇▇▇██
wandb:            eval/avg_f1 ▃▂▆█▇▅▇▄▄▅▅▇▄▁▄▄▅▆▇▇▇▃▆▇▅▇█▇▇▄▇▅▇▄▇▃▆█▄█
wandb:      eval/avg_mil_loss ▂▁█▇▅▆▁▁▁▂▆▃▅▇▂▁█▁▆▂▇▅▃▁▄▆▄▁▂▁▂▂▂▆▄▄▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▆█▁▄▇▅▅▇▅█▃▆█▇▇▇▇█▇▇█▅▅██▇▆█▇█▇█▇██▇█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▄▄▃▆▄▃▇▃▁▅▅▄▂▄▃▄▁▃▇▃▁▇▄▃▅▃▅▅▅▄▄▇▆▂▅█▆
wandb:      train/ensemble_f1 █▃▆█▄▁▄▆▄▁▂▇▅▁▆▆▇▄▅▃▅▆▇▅▅▃▂▆▅▂▆▄▅█▅▆▄▆▆▇
wandb:         train/mil_loss ▂▃▅▂▄▅▄▄▁▂▅▄▃▅▄▃▃▃▂▄▁▄▆▃▁▅▆▄▁▅▃▂▃▂▂▄▅▄█▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▃▆▃▃▃▄▃▃▁▆▁▆▃█▆▆▁▆▆▆▆▆▃▆▆▆▄▆▆▃▆█▃▃▆█▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.20931
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.83942
wandb:      eval/avg_mil_loss 0.34994
wandb:       eval/ensemble_f1 0.83942
wandb:            test/avg_f1 0.81993
wandb:      test/avg_mil_loss 0.28419
wandb:       test/ensemble_f1 0.81993
wandb:           train/avg_f1 0.88223
wandb:      train/ensemble_f1 0.88223
wandb:         train/mil_loss 0.34764
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06gp7xlv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192134-06gp7xlv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ddqtszfe with config:
wandb: 	actor_learning_rate: 1.3054415626309038e-06
wandb: 	attention_dropout_p: 0.050411492619827414
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3126377083298375
wandb: 	temperature: 7.569366680558974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192350-ddqtszfe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddqtszfe
wandb: uploading history steps 75-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁█▄▆
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁█▇▇▃▃▆▇█▇▇███▃▇▇▄██▇█▇█▇▇█▇██▅▇▆▂█▇▇▇▆▇
wandb:      eval/avg_mil_loss ▁█▂▂▂▂▁▆▂▂▁▂▂▁▅▁▆▁▆▁▂▁▂▁▁▂▂█▁▂▄▂▂▁▁▁▁▁▁▂
wandb:       eval/ensemble_f1 ▇▁█▇▇▇▇▃██▇▇▇▇▃▇██▇▇██▇▂▇▆▃▁█▅▆▇█▇▇▇▇▆█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▆▅▅▆▄▆▃▆▇▃▇▆▆▇▄▇▆▄██▇██▆▇▆▄█▆▁▆█▇▄▇▆▆▅
wandb:      train/ensemble_f1 ▄▇▄▄▃▁▅▇▃▇▅▇▇▆▅█▆▆▁▆▅▆▇▂█▇▆▇▇▂▅▆▅▇▇██▅▂▇
wandb:         train/mil_loss ▂▃▂▁▂▅▁▂▄▁▅▄▁▁▃▁▃▂▂▂▁▂▁▄█▄▄▃▂▂▁▃▄▂▁▁▃▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33058
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.35828
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.10004
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.87375
wandb:      train/ensemble_f1 0.87375
wandb:         train/mil_loss 0.76306
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddqtszfe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192350-ddqtszfe/logs
wandb: Agent Starting Run: g6widpa7 with config:
wandb: 	actor_learning_rate: 0.00013216597701843738
wandb: 	attention_dropout_p: 0.28052550460175835
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7892422844439707
wandb: 	temperature: 3.8471230374551713
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192448-g6widpa7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g6widpa7
wandb: uploading history steps 124-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss █▂▄▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 █▃▃▄██▄▇▇▇███▄▇▇▇█▇▂██▇▇▄▃▁▇▂▇████▂██▇█▂
wandb:      eval/avg_mil_loss ▁▅▅▆▁▂▁█▄▁▃▁▄▁█▁▁▁▄▁▁▁▆▁▁▁▁▅▃█▆▁▁▁▁▄▁▁▁▁
wandb:       eval/ensemble_f1 ▃▇▃▇▁▇▇▇█▄███▇▇▇▂█▃▇▇▂█▇▇▄▃▃▁▇▇▂▇█▇▂█▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▃▅▆▄▂▅▇▄█▄▅▄▅▇▇▅▅▇▆▅▄▆▆█▆▅▆▁▇▆▅▆▁▇▅▇▆▄
wandb:      train/ensemble_f1 ▂▇▃▃▇▆▃▇▆▃▅▅▄▅▆▆▆▅▅█▆▅▅▅▇▆▅▃▅▄▄▃▃▇▁▇▄▆█▃
wandb:         train/mil_loss ▂▁▃▃▁▅▁▅▇▅▄▁▆█▆▃▂▃▃▆▄▂▄▃▃▃▁▆▄▃▅█▆▂▃▇▅▄▇▃
wandb:      train/policy_loss ▆▆▃▃▃▃▃▁▆▆██▃▃▁▃▃█▁▆▆█▆▆█▆▆▃▆▃▆▆▃▆▆█▃▆▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▃▃▃▆▃▆▆▃▁█▆█▃█▆▁▆▆▃▆▃▁▃▁▆▆▆█▃▁▆▃█▁▆█▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.22769
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.28741
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.67159
wandb:      test/avg_mil_loss 1.25646
wandb:       test/ensemble_f1 0.67159
wandb:           train/avg_f1 0.74398
wandb:      train/ensemble_f1 0.74398
wandb:         train/mil_loss 0.40323
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g6widpa7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192448-g6widpa7/logs
wandb: Agent Starting Run: 1t2a2t3z with config:
wandb: 	actor_learning_rate: 5.088513582687913e-06
wandb: 	attention_dropout_p: 0.11359811790006225
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5984121086973813
wandb: 	temperature: 9.353804645290989
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192610-1t2a2t3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t2a2t3z
wandb: uploading history steps 104-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▇▇█▇▇▇▇▇▇▇▇▇██▆▆▇▇▇▇▇▇▄▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▁▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▅▁▁▁▁▁▁█▁▁▁▁▁█▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▇██▇▇▇▇▇▇▄▅█▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▇▇▄▇▄▇▃▇▆▄▆▄▇▇▇▇▆▄▂▇▇▆▃█▅▇▆▇▇█▄█▄▄▇▅▁
wandb:      train/ensemble_f1 ▆▇▆▅▃▃█▇▁▇▆▇▄▆▃▇▆▃██▇▇▆▅▂▆▁▅▆▇▆▇█▃▇▂▇█▇▄
wandb:         train/mil_loss ▁▂▂▂▂▅▂▃▂▄▄▂▂▂▁▂▂▂▂▂▂▂▃█▂▁▅▂▄▆▄▂▁▄▂▁▁▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.29237
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.31802
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.18903
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.7469
wandb:      train/ensemble_f1 0.7469
wandb:         train/mil_loss 0.30845
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t2a2t3z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192610-1t2a2t3z/logs
wandb: Agent Starting Run: 14ttyhk8 with config:
wandb: 	actor_learning_rate: 5.6698968421108655e-06
wandb: 	attention_dropout_p: 0.06942499157630966
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49766967782744786
wandb: 	temperature: 8.319102111392843
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192717-14ttyhk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14ttyhk8
wandb: uploading history steps 105-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss █▁▃▃
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▆▇▆█▆▆▁██▇█▇██▇▁████▁▇█▇██████▆███▂██▇▇█
wandb:      eval/avg_mil_loss ▆▃▄▃▂▂▃▁▂▂▄▂▂▂▂█▂▂▃▁▁▂▄▂▃▆█▁▂▂▃▂▂█▆▂▂▁▃▂
wandb:       eval/ensemble_f1 ▆▆▇▇▇▇▇▆▆▇▇▇▇▁█▆▇▆▇█▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▆▇▇▇█▁▆▇▇▇▆█▅▆▄█▆▄▇▅▇▇▇▄█▇▆█▇▇▇▇▇▄▆▇▆
wandb:      train/ensemble_f1 ▄▆▇▁██▇▆▄▆▆▇▄▆▅▆▅▆▇▅▅▇▆▇▁▃▅▇▆▇▁▆▅█▆▆▆▆▂▅
wandb:         train/mil_loss █▄▁▆▄▂▄▃▇▆▂▆▂▂▄▂▇▁▃▃▂▂▇▃▂▂▁▅▃▁▆▂▃▃▂▂▃▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32952
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.33888
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.17458
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.86746
wandb:      train/ensemble_f1 0.86746
wandb:         train/mil_loss 0.32221
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14ttyhk8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192717-14ttyhk8/logs
wandb: Agent Starting Run: 4o1eu4xp with config:
wandb: 	actor_learning_rate: 3.2768584761601183e-05
wandb: 	attention_dropout_p: 0.39428707347261394
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.750825666660998
wandb: 	temperature: 2.800782005356235
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192826-4o1eu4xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4o1eu4xp
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▁▇▇▇▇▇▇▇▆▇█▆▇▇▇▂▇▃▁▅█▇▇▇▇▇▇▇▇▇▂▇▇▃▇▇▅
wandb:      eval/avg_mil_loss ▁▁▁▅▁▆▁▄▁▁▁▁▂▁█▅▄▆▁▅▆█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄
wandb:       eval/ensemble_f1 █▇▇▁▇▇▇▇██▇▇▇█▂▇▇▇▇▂▅▇▇▇▇▂▇▇▁▇▇▇▇▇▇▇▇▂▇▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▇█▅▆▅▄▇▇▇▅▆▇▅▇█▆▄▁▆▄▇▃▁▅▆█▅▆▅▇▇▅▂▁▆▅▄▆
wandb:      train/ensemble_f1 ▇▇▇▇▇▇█▅▅▅█▇▆▅▆▅▅▃█▇▅▄▅▄▄▅▇▆▄▆▄█▅▇█▁▄▇▆▇
wandb:         train/mil_loss ▃▂▇▂▃█▄▃▁▂▁▂▁▂▁▃▃▁▃▃▂▁▃▄▃▆▁▂▁▆▁▅▂▃▁▄▃▂▁▂
wandb:      train/policy_loss ▃▆█▃▆▃▁▃▃▁▆▁▃▃▆▃▃▃▃▆▃▆▆▁▃▃▃▃▃▆▃▃▃▃█▁▃▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▅▅▃▁▃▁▃▅▁▃▅▆▃▆▃▆▃▆█▃▃▁▃▃▃▃▆▃▃▃▃▆▁▅▃▃▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.32918
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.74533
wandb:      eval/avg_mil_loss 0.93404
wandb:       eval/ensemble_f1 0.74533
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.33049
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.90161
wandb:      train/ensemble_f1 0.90161
wandb:         train/mil_loss 0.42076
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4o1eu4xp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192826-4o1eu4xp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lhefgdpt with config:
wandb: 	actor_learning_rate: 1.728001816974901e-05
wandb: 	attention_dropout_p: 0.11346326615899964
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5712871196593524
wandb: 	temperature: 8.129008449810474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192941-lhefgdpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhefgdpt
wandb: uploading history steps 53-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▇▇▇▁▇▇▇▇▇▇█▁▇▇▇▇▁▇▆▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁█▁▂█▁▁▁▁█▂▂▂▇▁▁▂▁▂▂▁▂▂▁▂▁▂▂▂▂▂▁▁▁▂▂▁▁
wandb:       eval/ensemble_f1 ▇▇▇▁▁▇▇▁▇█▁▇▇▇▇▇▁▇▆▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▆▆▆█▃▂▇▆▆▂▅█▃▇▆▇▇▇▄▆▆▇▇█▇█▇█▅▃▆▃▇▇▁█▇▃
wandb:      train/ensemble_f1 ▃▆▆▆▇▄█▅▄▇▇█▆▄▇▇█▇▆▇▇▇▇▇█▇▇▇▁█▇▇▅▅▇▇▇▃▇▅
wandb:         train/mil_loss ▂▂▂▁▇▂▃▂▁▂▂▂▂▂▃▂▇▂▅▂▃▂▂▂▂▇▂▂▂▂█▂▂▂▂▂▅▂▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.18945
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.25632
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.17855
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.8994
wandb:      train/ensemble_f1 0.8994
wandb:         train/mil_loss 0.30279
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhefgdpt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192941-lhefgdpt/logs
wandb: Agent Starting Run: 37ykrhmo with config:
wandb: 	actor_learning_rate: 3.5695077549823277e-06
wandb: 	attention_dropout_p: 0.0520347449800076
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.304815230769943
wandb: 	temperature: 9.343692916988608
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193034-37ykrhmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ykrhmo
wandb: uploading history steps 104-130, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▃█
wandb: best/eval_avg_mil_loss ▇▇█▇▅▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▃█
wandb:            eval/avg_f1 ▅▆▂▅▆▇▅▂▇▂▂▇▄▆▅▄▆▆▂▅▆▇▁▄▇▂▄▅▇▇▆▆▄▄▃▆█▆▄▅
wandb:      eval/avg_mil_loss ▆▇▅▅▄▄▇▇█▆▆▇▅▂▅▆▇▅▄▆▃▆▆▇▃▇▄▅▅▄▄▄▂▄▁▆▅▇▃▆
wandb:       eval/ensemble_f1 ▂▂▂▁▂▁▂▁▁▂▁▂▂▂▁▁▂█▂▁▂▂▂▂▂▁▂▂▁▂▂▃▂▂▂▂▃▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▃▅▄▁▄▄▄▄▅▄█▄▄▅▅▃▄▃▄▄▃▅▅▄▅▄▇▄▄▃▆▃▄▅▆▃▅
wandb:      train/ensemble_f1 ▇▂▃▁▃▅▃▂▃▃▄▂▄▄▅▃▃▄▁▂▄▄▃▅▄▃▂▄▅▄▃█▄▄▃▃▅▄▄▃
wandb:         train/mil_loss ▇▃██▄▅▁▅▆▄▆▅▇▆▄▅▄▂▄▅█▄▃▇▄▇▅█▆▇▁▇▇▆▅▃▅▃▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87825
wandb: best/eval_avg_mil_loss 0.3351
wandb:  best/eval_ensemble_f1 0.87825
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 2.02188
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.29917
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.53825
wandb:      train/ensemble_f1 0.53825
wandb:         train/mil_loss 1.93782
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ykrhmo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193034-37ykrhmo/logs
wandb: Agent Starting Run: bpr7w387 with config:
wandb: 	actor_learning_rate: 7.865965627344369e-05
wandb: 	attention_dropout_p: 0.3271640847030266
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2678992832796594
wandb: 	temperature: 2.6358999297932884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193156-bpr7w387
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bpr7w387
wandb: uploading config.yaml
wandb: uploading history steps 105-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆█
wandb: best/eval_avg_mil_loss █▁▁▇
wandb:  best/eval_ensemble_f1 ▁▄▆█
wandb:            eval/avg_f1 ▇█████▇██▆███▁██▁███▇█▇█▇█▇▇███████▇██▇▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▁▁▅▁▁▁▁▁█▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▇▇█████▁▆███████▂█▇▇████████▇██▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▇▅▆▂▆▆▆▄▆█▅▇▇▁██▅▃▆█▇▅▆▇▇▅▇▆▇▅▆▇▇▇▁▆█
wandb:      train/ensemble_f1 ▇▆▆▆█▇▇▂▇█▆▆█▆▇▇▂▃▇▇▇▆▇▇▇▁▆▇▃▇▇▇▃▇█▆▇▇▄█
wandb:         train/mil_loss ▂▅▃▂▁▂█▁▁▂▂▁▁▁▂▂▂▂▄▄▂▃▃▃▅▁▁▂▃▂▁▃▁▂▂▁▂▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.31012
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.25883
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.14656
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.91102
wandb:      train/ensemble_f1 0.91102
wandb:         train/mil_loss 0.30197
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bpr7w387
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193156-bpr7w387/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mzwxqzc6 with config:
wandb: 	actor_learning_rate: 7.669691271094599e-05
wandb: 	attention_dropout_p: 0.1774431916994491
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.021655085667319107
wandb: 	temperature: 1.2249445110486434
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193314-mzwxqzc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mzwxqzc6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss ▇██▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▇▇▇█▇▇▇▇▇▇▇▇▇▁▁▇▁█▇▂▇▇▇▇▇█▇███▇███▇▂▇▇▇█
wandb:      eval/avg_mil_loss ▁▁▂▁▁▂▆▂▂▁▁▁▂▂▆██▂▁▁█▂▁▁▂▁▂▁▁▁▆▁▅▁▁▅▂█▁▂
wandb:       eval/ensemble_f1 ▇▇█▇▇▆▇▇▇██▁▆█▇▁█▇▂▇▇▇▇▇▇▂██▇▃██▇▆▇█▇▇▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▅▃▂█▃█▅▃▆▁▂▄▅▄▄▄▇▆▄▄▃▄▇█▃▂▄█▄▅▁▃▃▃▅▇▅
wandb:      train/ensemble_f1 ▆▆▆▅▃▅▅▁█▃▃▃▆▁▄▄▄▄▄▄▆▆▆▇▇▂▄▅▆▇▄▃▅▁▄▂█▅▇▆
wandb:         train/mil_loss ▂▂▃▄▅▃▃▂▃▁█▄▃▅▂▂▁▁▄▄▄▃▃▃▄▇▄▄▄▅▅▃▆▄▃▄▃▂▄▅
wandb:      train/policy_loss ▃▃▆▁▁▁▁▁▅▁▁▃█▃▁▃▁▁▁▃▃▃▁▁▃▆▃▁▁▃▁█▃▃▁▃▆▃▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▁▁▃▆▃█▃▃▁▁▃▃▁▆▁▃▁▁▁▃▁▃▃▃▃▃▃▁▁▃█▁▁▁▁▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.26429
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.29096
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.73518
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.79732
wandb:      train/ensemble_f1 0.79732
wandb:         train/mil_loss 0.9233
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mzwxqzc6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193314-mzwxqzc6/logs
wandb: Agent Starting Run: lzxkeyuh with config:
wandb: 	actor_learning_rate: 2.8894312127550612e-06
wandb: 	attention_dropout_p: 0.049937367643544006
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37243874299772595
wandb: 	temperature: 2.1100396542091637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193406-lzxkeyuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lzxkeyuh
wandb: uploading history steps 149-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇██
wandb: best/eval_avg_mil_loss █▅▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▇██
wandb:            eval/avg_f1 ▃▂▂▂▂▇▂█▇█▃▇▅██▂▂▂▁▂▇▁▁▂▄█▂▁▄▂▂▂▇▁▁▃▂▂█▇
wandb:      eval/avg_mil_loss ▄▆▆▆▇▆▁▆▇▅▄▂▁▆▃█▄▄▁▇▂█▁▁▇▇▁▁▇▄▁▁▃█▁▃▇▅▁▂
wandb:       eval/ensemble_f1 ▂▃▇▂▂▇█▇▇▄▂▃█▇█▁▄▁▃█▂▂▃▄▁█▁█▃▂█▁▂█▃▂█▂█▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▇▇▆▅▆▅▇▄▄▃▄▅▁▃▄▆▄▂▅▃▄▇█▃▂▆▅▅▃▄▅▅▅▄▆▄▆▂
wandb:      train/ensemble_f1 ▇▅▅▇▆▅▅▆▆▅▂▃▄▆▆▁▅▆▅▄▇▇▃▆▃█▃▇▆▅▄▃▆▅▃▅▄▄▄▆
wandb:         train/mil_loss ▄▃▅▆▅▅▄▄▄▅▇▁▆▃█▇▄▄▄▃▃▄▄▇▅▆▃▆▄▄▄█▅▄▄▂▂▃▇▁
wandb:      train/policy_loss ▃▆█▆▃██▆▆▅▆▁█▆▆▆▆▆▁▆▆▁▆▃██▆▆▆█▆▆▃▆▃██▆▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅█▅▁█▁▅▅▅▁▁▅▅█▅▁▅▅▅▁▁▅▅▁██▅███▁▅▅▁▁▅▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.33498
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.57835
wandb:      eval/avg_mil_loss 1.48691
wandb:       eval/ensemble_f1 0.57835
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 1.85455
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.78787
wandb:      train/ensemble_f1 0.78787
wandb:         train/mil_loss 0.44046
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lzxkeyuh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193406-lzxkeyuh/logs
wandb: Agent Starting Run: on1ghmcg with config:
wandb: 	actor_learning_rate: 1.481114898296369e-06
wandb: 	attention_dropout_p: 0.17944733242389582
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6864048687115033
wandb: 	temperature: 0.8826172028703672
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193544-on1ghmcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/on1ghmcg
wandb: uploading history steps 112-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆█
wandb: best/eval_avg_mil_loss █▇▃▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆█
wandb:            eval/avg_f1 ▄▃▄▇▆▄▇█▁▅▃▆██▅▃▇▇▇▇▃▆▄▄▇▄▃▆▄▇▆▇▅▃▁▆▆▁▄▇
wandb:      eval/avg_mil_loss ▆▅▂▃▃▂▁█▂▂▃▆▆▂▃▄▂▃▇▁▁▂▄▁▂▂▁█▁▁▂▄▁▂▂▂▁▄▅▂
wandb:       eval/ensemble_f1 ▇▇▂▄▄▆▇▆▇▃▁▆█▃▆▄▄█▇▅▇▇▃▆▅▄▆▅▇▇▅█▅▆▅▇▂▃▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▄▂▅█▆▄▆▄▂▅▇▂▃▅▆▇▅▄▂▆▆▆▂▂▄▆▃▄▂▆▅▆█▅▅▅▂
wandb:      train/ensemble_f1 ▂▄▂▅▅▆▇▅▂▃▅▁▃▄▅▃▄▅▆▅▆▅▆▄▅▃▂▃▃▄▄▂▅█▆▇▅▅▁▅
wandb:         train/mil_loss ▅█▅█▅▄▄▆▃▁▅▂█▄▃▅▄▂▇▃▃▃▅▄▃▆▄▃▅▃▃▅▄▃▃▂▃▆▃▃
wandb:      train/policy_loss ▄▁▂▄▆▆█▆▆▂▁▂▂█▃▆▃▃▇▃▆▃▄▃▁▆▃▇▇▂▄▄▁▂▆▃▄▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.20736
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.30804
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.16529
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.82245
wandb:      train/ensemble_f1 0.82245
wandb:         train/mil_loss 0.49015
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/on1ghmcg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193544-on1ghmcg/logs
wandb: Agent Starting Run: b4qo8psd with config:
wandb: 	actor_learning_rate: 1.7867448172458795e-06
wandb: 	attention_dropout_p: 0.16032899787449906
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8162850530137223
wandb: 	temperature: 2.3768663440611437
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193712-b4qo8psd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b4qo8psd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▇█
wandb: best/eval_avg_mil_loss █▁▅▁▁
wandb:  best/eval_ensemble_f1 ▁▅▆▇█
wandb:            eval/avg_f1 ▃▅▄▄▆▅▁▅▄▃▃▄▄▄▂▆▃▁▄▅▅▄▅▆█▄▆▃▄▄▄▅▅▃▃▄▇▅▂▆
wandb:      eval/avg_mil_loss █▁▂▇▄▇▆▂▅▇▅▇▄▃▅▇▃▅▅█▃▃▅█▃▄▂▃▃▄▃▅▄▅▃▂▃▄▅▂
wandb:       eval/ensemble_f1 ▃▆▅▄▇▅▁▅▄▃▃▄▄▂▃▇▃▁▄▅▆▃▄▅▇▃▅▇▃▄▁▅▆▆▃▅▅█▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▄▄▃▇▆▅▆▅▄▆█▃▄▆▆▅▅▅▆▆▆▇▆▃▆▄█▆▄▇▆▅▇▅▁▇▇
wandb:      train/ensemble_f1 ▆▅▇▄▄▃▇▆▅▆▄▆█▃▄▆▆▅▆▅▅▆▆▆▇▃▆▄█▅▄▇▆▅▇▃▅▁▇▇
wandb:         train/mil_loss ▃▂▃▁▂▃▃▄▃▂▃▃▂▅▄▄▃▃▃▆▄▅▅▃▂▅▄▃▃█▃▃▄▄▄▂▃▃▃▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.20339
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.22313
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.17554
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.90344
wandb:      train/ensemble_f1 0.90344
wandb:         train/mil_loss 0.24673
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b4qo8psd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193712-b4qo8psd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d9m7jta3 with config:
wandb: 	actor_learning_rate: 0.0001479828300151425
wandb: 	attention_dropout_p: 0.4402436908898276
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13759533734093454
wandb: 	temperature: 4.376162164536449
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193758-d9m7jta3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/108xx98g
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d9m7jta3
wandb: uploading history steps 156-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▄▃▁▂▂
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▇▇▆▅▇▇▅▁▇▇▅▂▂▆▆▆▆▅▇▆▆▆▆▁▁▆▆▅▅▄█▅▆▁█▇▆▂▇▅
wandb:      eval/avg_mil_loss ▁▁▃▂▁▂▁▁▆▄█▂▁▁▁▂▂▁▁▄▁▄▁▂▁▅▂▁▄▂▄▃▁▁▁▂▁▁▂▂
wandb:       eval/ensemble_f1 ▅▆▆▆▇▂▇▄▁▇▆▆▆▅▅▅▅▅▅▃▅▆▃▇▅▅▅▁▇▆▆▄▅▂▆▆▂▇▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▇▁▅▇▄▇▇█▆▄▆▆▄▂▇▅▄▄█▆▇▆▆▆▆▅▇▆▆█▇▇▆▆▇▇▆
wandb:      train/ensemble_f1 ▇▅▁▆▅▅▂▆▇▄▆▆▆▅▇▂▁▁▂▇▇▆▃▃▅▇▅▅█▇▆▇▅▆▂▇▅▅▃▆
wandb:         train/mil_loss ▃▅▃▄▅▃▄▃▃▄▅▅▂▄▂▆▅▁▄▆▃▂▄▂▆▁▂▃▆▃▆█▄▂▄▇▄▄▃▁
wandb:      train/policy_loss ▃▆▆▆▃▃▆▅▆█▃▃▆▅▁▃▃█▃▅▆█▁▃▆▁▁▁▁█▆▅▆▆▆▆▃███
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆█▁▃▆▄▃▁▆▆▃▃▃▆█▃▂▃▂▆▂▃▂▃▂▂▄▇▆▂▇▂▃▆▄▆▄▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.20925
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.94999
wandb:      eval/avg_mil_loss 0.20925
wandb:       eval/ensemble_f1 0.94999
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11741
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.86497
wandb:      train/ensemble_f1 0.86497
wandb:         train/mil_loss 0.39423
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d9m7jta3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193758-d9m7jta3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
