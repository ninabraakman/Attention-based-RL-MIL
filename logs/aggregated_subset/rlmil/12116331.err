wandb: Agent Starting Run: i9hluc8o with config:
wandb: 	actor_learning_rate: 0.0003890044000714384
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.911054466751916
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3857309566238787
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145113-i9hluc8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9hluc8o
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▅▃▆▃▅▄▂▃▂▇▃▄▂▃▄▆▃▇▄▁▄▃▆▅█▆▆▅▄█▂▃▃▁▇▄▁▇
wandb:      train/ensemble_f1 ▃▆▆▇▅▅▄▅▄▄▆▇▁▅▇▇▇▄▂▅▃▆▅▇▃▆▅▅▅▄▃▆█▃▂▇▅▁▆▄
wandb:         train/mil_loss ▁▄▄▇▁▁▂▄▅▁▁▄▂▁▂▄▃▄▇▃▁▄▂▁▁█▁▂▄▂▄▅▄▄▁▄▂▅▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.0774
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.05564
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.43762
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.58331
wandb:      train/ensemble_f1 0.58331
wandb:         train/mil_loss 0.55031
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9hluc8o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145113-i9hluc8o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: msapkp3e with config:
wandb: 	actor_learning_rate: 0.00043048941898848675
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7878308965802021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4155096364172539
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145255-msapkp3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/msapkp3e
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▅▅▅▅▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▃▃▃▃▁▂▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 █████▅▅▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▅▄▆▆▆▆▅▄█▃▄▄▃▅▄▆▄▄▄▆▃▅▃▄▁▄▅▅▃▄▄▆▃▃▄▇▃▅
wandb:      train/ensemble_f1 ▇▅▇▅▆▃▆▅▆▄▄▃▅█▄▄▄▄▂▃▅▃▆▇▃▂▅▃▅▄▃▃▅▂▃▆▃▇▃▁
wandb:         train/mil_loss ▂▂▂▂▂▂▃▃▁▂▂▄▆▅▆▆▁▅▃▃▅▄▃▄▄▅▅▅▂▅▃▃▄▆▅▄▅▄▄█
wandb:      train/policy_loss ▂▂▂▂▃▃▃▁▁▅▅▃▃▃▃▃▃▃▃▃▆▅▅▆▄▄██▅▅▅▆▅▆▅▅▄▅▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.29452
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.30849
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.09155
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.88619
wandb:      train/ensemble_f1 0.88619
wandb:         train/mil_loss 0.28268
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/msapkp3e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145255-msapkp3e/logs
wandb: Agent Starting Run: 2cr37itc with config:
wandb: 	actor_learning_rate: 2.1207958318872447e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5422102000397767
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6661542615654519
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145412-2cr37itc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2cr37itc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▁▃▄▄▄▄▆▄▄▆▅▅▅▄▅▄▄▅▅▅▅▅▄█▆▇▇▅▅▅▆▇█▆▆▇▇
wandb:      train/ensemble_f1 ▁▂▃▁▃▃▃▂▄▄▄▃▃▃▃▃▃▂▂▂▄▅▄▄▅▆▅▅▆█▆▄▅▇▆▄▆▆▆▇
wandb:         train/mil_loss █▄▄▅▆▄▅▄▅▅▆▆▇▇▄▃▆▆▃▇▆▃▅▅▆▄▅▅▄▄▃▅▃▄▃▂▁▃▅▃
wandb:      train/policy_loss ▆▅▄▅▄▇▆▆▂▄▂▆▄▁▅▆▆▅█▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▆▇▇▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▅▄▅▆▆▄▂▇▆▇█▁▆▆▄▆▆▆▆▆▇▆▄██▅▄▇▆▇▅▆▅▆▇▇▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.29856
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.2881
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.30348
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.89459
wandb:      train/ensemble_f1 0.89459
wandb:         train/mil_loss 0.26809
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2cr37itc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145412-2cr37itc/logs
wandb: Agent Starting Run: 2d597ban with config:
wandb: 	actor_learning_rate: 0.00012603911539498658
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.83002801303214
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5111507067053297
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145636-2d597ban
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2d597ban
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▄▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▇▇▅▇█▄▅▅▅▃▃▆▄▅▇▂▃▄▂▇▆▅▅▃▂▃▃▂▃▁▆▅▃▆▅█▃
wandb:      train/ensemble_f1 ▇▅▃▃▅▇▃▅█▃▅▄▆▃▂▄▄▇▇▆▂▂▃▆▅▅▅▂▃▃▁▂▅▅▃▄▃▇▅▅
wandb:         train/mil_loss ▂▅▁▄▄▇▃▄▃▅▄▁▄█▄▄▃▃▂▁▃▂▆▁▁▇▃▄▁▄▃▃▃▂▂▁▄▁▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 1.84789
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.8314
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.13685
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.58528
wandb:      train/ensemble_f1 0.58528
wandb:         train/mil_loss 0.39015
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2d597ban
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145636-2d597ban/logs
wandb: Agent Starting Run: 4s8uvz75 with config:
wandb: 	actor_learning_rate: 0.007189228191540176
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7815021399539429
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8240570840831438
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145754-4s8uvz75
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4s8uvz75
wandb: uploading history steps 176-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▇▆▄▇▄▅▇▄▆▅▄▅▄▆▃▃█▅▄▁▅▇█▅▆▆▅▆▄▆▅▆█▆▅▄▆▄
wandb:      train/ensemble_f1 █▆▃▆▇▅▅▃▅▃▂▁▄▃▄▂█▃▂▅▅▂▃█▃▄▅▇▄▃▃▂▆▂▃▄▃▆▄▄
wandb:         train/mil_loss ▅▁▃▅▂▄▄▅▆▅▃▂▃▄▂▃▄▅▃▂▂▃▃▄▃▅▃▅▅▃▃▅▃▃█▃▂▁▄▃
wandb:      train/policy_loss ▃▄▄▅▁▃▂▃▅▁▃▁▄▂▃▁▅▁▇▇▆▆▅█▆▇▄██▇▅▆▄▅█▇▇▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▁▂▂▆▂▄▄▂▆▁▂▃▂▄▃▂▄▃▅▆▇▅▆▇█▇▅▅█▇▅█▇█▇▄▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.27688
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.28401
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.15241
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.88495
wandb:      train/ensemble_f1 0.88495
wandb:         train/mil_loss 0.22546
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4s8uvz75
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145754-4s8uvz75/logs
wandb: Agent Starting Run: dqb0t0w6 with config:
wandb: 	actor_learning_rate: 0.0060656478777636755
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5216388089657898
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.994670830506565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150009-dqb0t0w6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dqb0t0w6
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▁▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▃▄▃▁▆▂▃▃▄▅▆▁▆▃▆▄▅▃▆▆▃▇▆▇▅▄█▄▇▃▄▃▂▂▆▆▃
wandb:      train/ensemble_f1 ▂▄▂▄▄▄▄▅▁▇▁▅▆▄▆▆▃▅▅▄▃▄▂▅▇▄██▇▄▃▁▄▃▅▂▆▄▆▃
wandb:         train/mil_loss ▄▅▃▃▅▆▃██▄▄▂▄▇▇▄▅▄▅▁▄▄▆▄▃▆▇▅▃▄▅▄▄▃▅▅▃▄▅▂
wandb:      train/policy_loss ▅█▄▄▆▄▆▆▇▆▇█▅▄▇█▅▃▄▅▅▃▄▇▄▄▄█▄▅▄▅▆▆▃▃▄▃▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▆▆▆▆▄▃▅█▄▆▃▁▄▁▆▃▆▁▁▃▆█▅▃▆▃▃▆▃▃▁▁▄▆▆▃▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47246
wandb: best/eval_avg_mil_loss 2.10434
wandb:  best/eval_ensemble_f1 0.47246
wandb:            eval/avg_f1 0.47246
wandb:      eval/avg_mil_loss 2.06555
wandb:       eval/ensemble_f1 0.47246
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 2.52396
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.43407
wandb:      train/ensemble_f1 0.43407
wandb:         train/mil_loss 0.58864
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dqb0t0w6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150009-dqb0t0w6/logs
wandb: Agent Starting Run: 23zmi0iq with config:
wandb: 	actor_learning_rate: 0.0007380428367537689
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9660815058572032
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44529899356482416
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150126-23zmi0iq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/23zmi0iq
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▅▃▃▃▃▂▂▂▂▂▁▁▁▇▇▇▆▆████▇▇▇▇▇▇▇▆▆▆▆▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▆▃▅▅▄▂▃▄▄▂▅█▅▆▇▇▃▄▄▁▆██▃▅▇▅█▄▄▇▅▇▄▄▆▂▇
wandb:      train/ensemble_f1 ▅▁▆▅▄▄▄▂▆▇▇▅█▆▄▅▄▄▁▅▆▅▇▄▃▅▂▄▆▅▇▅▄▆▅▃▃▄▂▆
wandb:         train/mil_loss ▂▃▃█▆▂▂▆▆▇▇▂▆▃▂▇▃█▃▂▂▇▂▂▃▃▂▂▆▂▇▂▁▆▂▃▃▅▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 1.6097
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 1.60941
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 1.85964
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.53743
wandb:      train/ensemble_f1 0.53743
wandb:         train/mil_loss 0.28638
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/23zmi0iq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150126-23zmi0iq/logs
wandb: Agent Starting Run: zhtwgobj with config:
wandb: 	actor_learning_rate: 0.0010599649654999606
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6992285442138647
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05926593392505908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150243-zhtwgobj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zhtwgobj
wandb: uploading history steps 219-233, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▄▂▂▂▂▂▂▂▅▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██████▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▄▄▂▂▂▂▅▅▅████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▂▆▄▄▃▄▅▁▄▃▃▅▆▄▅▃▇▆▄▄▆█▆▃▆▃▆▅▃█▄▆▄▆▆▆▆
wandb:      train/ensemble_f1 ▃▄▃▃▄█▄▃▆▆▂▃▂▂▃▆▅▃▃▅▆▂▃▅▅▁▃▃▆▅▄▂▄▄▁▅▅▂▅▇
wandb:         train/mil_loss █▅▆▄▄▅▆▃▅▅▅▇▆▆▆▅▇▁▆▂▆▅▅▂▄▁▂▄▂▂▂▄▅▆▂▅▆▁▂▄
wandb:      train/policy_loss ▄▆▄▄▆▄▅▃▄▆▃▃▃▃▃▃▃▃▃▃▄▆█▃▆█▆▄▃▆▆▆█▆▃▆▄▁▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7756
wandb: best/eval_avg_mil_loss 0.59087
wandb:  best/eval_ensemble_f1 0.7756
wandb:            eval/avg_f1 0.76605
wandb:      eval/avg_mil_loss 0.5609
wandb:       eval/ensemble_f1 0.76605
wandb:            test/avg_f1 0.78947
wandb:      test/avg_mil_loss 0.59793
wandb:       test/ensemble_f1 0.78947
wandb:           train/avg_f1 0.83065
wandb:      train/ensemble_f1 0.83065
wandb:         train/mil_loss 0.35546
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zhtwgobj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150243-zhtwgobj/logs
wandb: Agent Starting Run: yl0bv2hn with config:
wandb: 	actor_learning_rate: 5.348006797259998e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18689273015350905
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5065437908281396
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150529-yl0bv2hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yl0bv2hn
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▃▃▃▃▃▃▃███▇▇████▇▇▇██▇▇▇▇▇▇▇▇▇▆▇▇▇▇▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▅▄▄▅▇▆▆▄▃▂▄▃▆▂▄▅▄▄█▁▂▄▁▄█▅▆▇▆▄▁▄▃▄▁▄▄
wandb:      train/ensemble_f1 ▅▄▃▄▃▄▅▃▄▃▃▂▁▁▅▄▂▂▄▄▅▅▆▅▃▂▄▆▂▇▅▅▄▅▅▄▄▆▂█
wandb:         train/mil_loss ▄▆▄▅▃▃▆▅▁▂▆▅▆▅▃▆▃▆▅▅▇▇▄▇▃▆█▅█▃▂▅▇▇▆▁▃▆▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.28369
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.28228
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.11569
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.93118
wandb:      train/ensemble_f1 0.93118
wandb:         train/mil_loss 0.22756
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yl0bv2hn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150529-yl0bv2hn/logs
wandb: Agent Starting Run: orsz4vr3 with config:
wandb: 	actor_learning_rate: 0.008374254637772235
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.028066052866659863
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12456984658113336
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150647-orsz4vr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orsz4vr3
wandb: uploading history steps 156-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████████████▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▃▄▅▂▃▃▂▅▅▃▄▁▅▄▇▄▄▃▅▃▃▅▅▅▄▅▅▆▅▅▄▅▅█▆▂▃
wandb:      train/ensemble_f1 ▄▃▄▂▁▆▅▃▆▅▆▆▄▄▅▂▄▇▁▅▅▆▃▆▄▃▆▅▂▄█▇▂▇▅▆█▆█▂
wandb:         train/mil_loss ▃▇▁▄▄▆█▃▃▂▂▅▃▂▁▂▃▂▆▅▃▄▇▃▃▃▆▃▄▂▅▄▁▂▃▃▃▂▁▂
wandb:      train/policy_loss ▇█▇█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▂▁▁▁▃▁▁▁▁▁▁▁▂▁▂▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.29838
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.27944
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.10411
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.90195
wandb:      train/ensemble_f1 0.90195
wandb:         train/mil_loss 0.21147
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orsz4vr3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150647-orsz4vr3/logs
wandb: Agent Starting Run: fnqq1ioc with config:
wandb: 	actor_learning_rate: 0.0009959698625045669
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8845966566083523
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09061278355599034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150851-fnqq1ioc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fnqq1ioc
wandb: uploading history steps 186-192, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▁▄█
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▁▁▅▅▅▅▅▅▅▅▅██████████████████
wandb:      eval/avg_mil_loss ▃▃▃▃▃▅▅▅▄▅▅▇▆█▇███▇▇▇▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄█▄▃▅▅▃▄▁▂▂▃▃▂▂▆▂▅▂▂▃▁▄▅▇▁▃▇▅▄▅▁▃▃▆▃▅▅
wandb:      train/ensemble_f1 ▅▆█▅▆▂▃▃▂▆▄▆▄▆▄▅▄▆▃▅▄▁▅▅▃▇▃▅▃█▃▁▂▆▆▆▄▄▅▆
wandb:         train/mil_loss ▄▃▅▃▁▄▂▂▁▃▃▄▇▅▂▄▂▄▆▃▂█▃▄▁▃▄▆▄▃▄▂▆▄▃█▂▂▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅██▂▅█▃▅██▃█▅█▅███▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74256
wandb: best/eval_avg_mil_loss 0.67299
wandb:  best/eval_ensemble_f1 0.74256
wandb:            eval/avg_f1 0.74256
wandb:      eval/avg_mil_loss 0.64979
wandb:       eval/ensemble_f1 0.74256
wandb:            test/avg_f1 0.79968
wandb:      test/avg_mil_loss 0.5474
wandb:       test/ensemble_f1 0.79968
wandb:           train/avg_f1 0.7796
wandb:      train/ensemble_f1 0.7796
wandb:         train/mil_loss 0.39667
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fnqq1ioc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150851-fnqq1ioc/logs
wandb: Agent Starting Run: 6f7vauzy with config:
wandb: 	actor_learning_rate: 0.005171539734624697
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09816041081512804
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8286823331131882
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151116-6f7vauzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6f7vauzy
wandb: uploading history steps 84-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▆▆▆▆▆▁▁▁▃▃▂▂▂▂▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 █████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▅▄▅▃▃▂▆▅▅▄▂▁▅▁▅▆▆▇▃▂▄▆█▅▄▅▄▅▄▅▅▆▅▅▃▄█▄
wandb:      train/ensemble_f1 ▅▅▁▇▂▆▅▅▄▃▂▆▅▆▅▄▃▄▆▁▆▂▇▃▄▅▆▅▄▅█▅▅▅▅▅▃▄▇▅
wandb:         train/mil_loss ▂▄▃▆▆▃▇▃▁▄▆█▄▄▆▃█▃▃▅▇▆▃▄▃▄▃▂▅▂▄▂▅▂▅█▂▄▃▅
wandb:      train/policy_loss ▇██▇▇█▇███▇█████▇▁▂▁▁▁▂▂▁▂▂▂▁▁▂▂▁▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇███▇▇█████▆█▇▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁▂▂▂▂▂▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85795
wandb: best/eval_avg_mil_loss 0.4078
wandb:  best/eval_ensemble_f1 0.85795
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.38668
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.77921
wandb:      test/avg_mil_loss 0.61868
wandb:       test/ensemble_f1 0.77921
wandb:           train/avg_f1 0.81344
wandb:      train/ensemble_f1 0.81344
wandb:         train/mil_loss 0.55464
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6f7vauzy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151116-6f7vauzy/logs
wandb: Agent Starting Run: 7hwbvvue with config:
wandb: 	actor_learning_rate: 0.001705587500568044
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5009222869860421
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7286714397585765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151235-7hwbvvue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hwbvvue
wandb: uploading history steps 83-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▂▄▇▃▅▂▆▅▄▂▄▄▆▄▆▇█▅▄▁▅▅▇█▆▅▃▅▄▃▃▂▂▆█▅▂
wandb:      train/ensemble_f1 ▆▃▂█▃▆▄▃▂▄▆▂▄▅▄▂▅▄▄▃▇▄▆▆▇▇▁▅▄▄█▃▅▇▃▇█▂▄▆
wandb:         train/mil_loss ▃▇▄▆█▅▆▅▅▄▃▆▆▄▅▆█▄▇█▅▄▃▆▅▅▂▃▁▇▅▃▅▆▅▆▆▅▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60114
wandb: best/eval_avg_mil_loss 0.92442
wandb:  best/eval_ensemble_f1 0.60114
wandb:            eval/avg_f1 0.60114
wandb:      eval/avg_mil_loss 0.8175
wandb:       eval/ensemble_f1 0.60114
wandb:            test/avg_f1 0.63689
wandb:      test/avg_mil_loss 1.01288
wandb:       test/ensemble_f1 0.63689
wandb:           train/avg_f1 0.64274
wandb:      train/ensemble_f1 0.64274
wandb:         train/mil_loss 0.47583
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hwbvvue
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151235-7hwbvvue/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6s3wcnsa with config:
wandb: 	actor_learning_rate: 0.0015518959502836523
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.050053042059668096
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7233975584526284
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151403-6s3wcnsa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s3wcnsa
wandb: uploading history steps 168-186, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃███████████████████
wandb:      eval/avg_mil_loss █▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▃▄▇▂▂▃▂▄▆▂▇▇▄▅▄▃▄▆▅▂▁▅▄▇▄▃▆▃▃▃▄█▇▅▆▅▆▆
wandb:      train/ensemble_f1 ▅▃▁▂▆▁▂▁▃▅▃▅▆▂▂▃▆▄▇▄▄█▅▄▄▆▄▃▄▂▆▇▂▅▅▇▅▇▅▁
wandb:         train/mil_loss ▆▆█▆▄▂▂▆▄▇▄▇▂▃▄▅▆▂▇▅▆▅▃▄▆▅▅▆▆▆▇▁▃▅▃▂▅▇▃▅
wandb:      train/policy_loss █████▃▁▁▃▁▃▁▁▃▁▁▅▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁▁▃▁▃▁▁▃▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53249
wandb: best/eval_avg_mil_loss 2.13082
wandb:  best/eval_ensemble_f1 0.53249
wandb:            eval/avg_f1 0.53249
wandb:      eval/avg_mil_loss 2.08037
wandb:       eval/ensemble_f1 0.53249
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.49441
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.52513
wandb:      train/ensemble_f1 0.52513
wandb:         train/mil_loss 1.89749
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s3wcnsa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151403-6s3wcnsa/logs
wandb: Agent Starting Run: v38m0oun with config:
wandb: 	actor_learning_rate: 1.0900500539116564e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5960544031786669
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3996066846857293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151623-v38m0oun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v38m0oun
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▆█▇▇▆▆▆▅▄▄▄▄▆▆▆▅▅▆█▇▇█▇▇▇▇▆▅▅▅▄▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▅▅▃▇▂▄▅▄▆▄▃▅▃▇▅▂▃▅▆▃▃▄▄▇▃▁▆▆▅▃▄▅▄▄█▇▅▆
wandb:      train/ensemble_f1 ▄▂▃▅▄▂▃▄▁▅▃▃▄▃▅▃▆▅▃▃▃▃▃▆▄▂▁▄▃▃▅▅▄▄▃▆█▄▇▅
wandb:         train/mil_loss ▂▄▁▁▄▁▄▄▁▄▄█▃▃▄▅▃▄▇▃▄▁▂▅▂▇▁▃▂▃▄▆▂▅▅▇▂▁▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.42696
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.40432
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 2.98895
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.3594
wandb:      train/ensemble_f1 0.3594
wandb:         train/mil_loss 1.58655
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v38m0oun
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151623-v38m0oun/logs
wandb: Agent Starting Run: go0eerlp with config:
wandb: 	actor_learning_rate: 0.0002004284111126316
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8168839592496439
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7674571079247172
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151740-go0eerlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go0eerlp
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▅▃▂▂▄▆▄▁▃▄▃▅▄▄▆▄▄▂▄▄▅▃▅▅▇█▇▂▇▆▄▁▅▆▂▂▂
wandb:      train/ensemble_f1 ▄▂▅▅▃▆▆▃▇▄▅█▇▆▁▄▄▆▂▇▄▆▄▅▃▄▄▄▃▂▅▅▅▅███▃▆▃
wandb:         train/mil_loss ▃▃▁▄▃▄▄▃▃▁▃▃▁▇▃▇▃▁▅▂▃▃▁▂▄▃▂▅▄▁▁▁▄▅▂▃▃█▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40229
wandb: best/eval_avg_mil_loss 2.42941
wandb:  best/eval_ensemble_f1 0.40229
wandb:            eval/avg_f1 0.40229
wandb:      eval/avg_mil_loss 2.38653
wandb:       eval/ensemble_f1 0.40229
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 2.92461
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.37107
wandb:      train/ensemble_f1 0.37107
wandb:         train/mil_loss 0.64038
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go0eerlp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151740-go0eerlp/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.54.24.4:42540->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: vtcgdjxl with config:
wandb: 	actor_learning_rate: 8.27806387547091e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7497451822112451
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28679374662469015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151925-vtcgdjxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vtcgdjxl
wandb: uploading history steps 108-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃█▆▇▄▃▅▄▆▅▄▆▃▄▆▂▅▅▁▂▇▆▄▄▁▃▅▅▃▃▅▇▅█▄▃▃▃
wandb:      train/ensemble_f1 ▆▃▆▇▇▄▆▆▅▄▆▆▇▄▄▁▇▅▆▂▄▄▅▇▄▆▇▅▂▃▄▂▃▃▄▄▅█▃▅
wandb:         train/mil_loss ▄▅▃▆▅▅▄▃▃▆▅▆▂▅▃▅▅▆▆▅▅▆▅▃▃▆▅▄▁▃▅▄▆▅▂▄▅▇█▃
wandb:      train/policy_loss ▆▃▅▄▆▅▄▅▄▄▆▆▆▆█▆█▆▃▄▃▃▅▃▅▁▆▃▅▅▆▄▆▁▃▁▄▁▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▃▄▃▅▅▄▄▅▇▄█▆▆▆▆▆▇▇▇▃▆▃▃▁▆▅▁▄▄▃▅▄▆▁▃▁▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.33328
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.34718
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11848
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89894
wandb:      train/ensemble_f1 0.89894
wandb:         train/mil_loss 0.27459
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vtcgdjxl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151925-vtcgdjxl/logs
wandb: Agent Starting Run: y6n4n4uv with config:
wandb: 	actor_learning_rate: 0.003010108984946272
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8404396916088879
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7005761462127873
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152102-y6n4n4uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6n4n4uv
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▇▄▄▅▄▅▂▂▃▅▂▄▇▄▁▅▄▂▅▆▄▄▄▄▂▄▄▇▄█▅▆▅▁▄▃▂
wandb:      train/ensemble_f1 ▆▅▇▅█▄▆▆▇▆▄▆▇▅▆▆▆▂▆▅▅▅▅▄▄▃█▃▆▇▅▅▁▅▁▄█▅▆▅
wandb:         train/mil_loss ▅▆▅▆▅▄▆▄▅▄▄▃▄▅▄▂▄▂▅▅▆▆▂▃▄▃▁▃▅▃▅█▃▆▃▅▃▄▆█
wandb:      train/policy_loss ▃▁▃▃▆▆▁▃▁▁▃▃▃▄▁▂▆▆▃▁█▆▁▃▃▁▁▁▁▃▂▃▆▃▁▃▁▁▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄█▄██▁▁▄▁▅▄▅▅▄█▅▁▁▁█▁▄█▁▂▁▄▁▂▄▅▄▅▅▄█▄█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.31662
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.33708
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.12586
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91649
wandb:      train/ensemble_f1 0.91649
wandb:         train/mil_loss 0.26897
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6n4n4uv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152102-y6n4n4uv/logs
wandb: Agent Starting Run: rm4r2i55 with config:
wandb: 	actor_learning_rate: 0.008229774883113104
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.30241315243195477
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7086147189316118
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152220-rm4r2i55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rm4r2i55
wandb: uploading history steps 129-150, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▆▆▇▇▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▄▅▆▆▅▅▆▄▄▃▃▅▄▁▄▄▆▄▄▃▃▅▃▅▃▅▄▆▂▄▃▃▄▃▅▅▃▅
wandb:      train/ensemble_f1 ▅▆▇▇▇▅▅▄▃▅▂▄▅▃▆▅▃▄▁▃▃█▂▅▇▆▅▂▅█▃▄▇▅▂▄▅█▄▂
wandb:         train/mil_loss ▂▅▄▃▄▆▃▃▅▅▄█▇▇▃▇▄▅▅▃▅▁█▄▇▄▇▇▄▄▇▄▆▇▄▇▃▃▄▅
wandb:      train/policy_loss ▇▃▇▃██▃▄██▇▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▁▃▆▄▄▃▅▄▆▃▃▆▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.03185
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.00027
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.38549
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.46963
wandb:      train/ensemble_f1 0.46963
wandb:         train/mil_loss 1.7772
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rm4r2i55
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152220-rm4r2i55/logs
wandb: Agent Starting Run: s0nkleh9 with config:
wandb: 	actor_learning_rate: 0.0003765398033075334
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9474903871422522
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6439753426185997
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152408-s0nkleh9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s0nkleh9
wandb: uploading history steps 192-205, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▃▃▃▃▃▃▃▃▃▁▅▅▅▅▅█████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █▇▇▇▆▆▅▅▅▃▂▂▂▂▂▁▁▃▃▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▅▅▅▅████▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▃▆▆▃▆▁▆▇▇▆▄▅▁▇▄▄▃▃▆█▃▅▅▆▅▆▆▇▅▄▆▇▃▄▆▅▃█
wandb:      train/ensemble_f1 ▄▇▅▆▆▇▂█▂▄▄▆▅▅▄▁▁▇▆▆▂▄▅▃▄▄▄▄▄▄▅▄▄▄▄▄▄▅▄▄
wandb:         train/mil_loss ▄▃█▂▂▃▄▃▃▃▅▂▄▄▄▃▃▃█▃▃▅▂▆▅▂▂▃▂▃▂▃▂▃▄▆▃▅▃▁
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63922
wandb: best/eval_avg_mil_loss 1.06885
wandb:  best/eval_ensemble_f1 0.63922
wandb:            eval/avg_f1 0.62667
wandb:      eval/avg_mil_loss 1.07624
wandb:       eval/ensemble_f1 0.62667
wandb:            test/avg_f1 0.694
wandb:      test/avg_mil_loss 1.0465
wandb:       test/ensemble_f1 0.694
wandb:           train/avg_f1 0.73043
wandb:      train/ensemble_f1 0.73043
wandb:         train/mil_loss 0.34946
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s0nkleh9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152408-s0nkleh9/logs
wandb: Agent Starting Run: dx9rff8r with config:
wandb: 	actor_learning_rate: 0.00018995271650559825
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1529522232396877
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5087379381663918
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152639-dx9rff8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dx9rff8r
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▃▃▆▅▃▆▆▅▆▃▆▄▄▁▄▄█▆▄▇▅▆▆▄▆▃▇▆▂▃▆▆▆▅█▅▇▅
wandb:      train/ensemble_f1 ▂▄▇▅▃▂▅▄▆▃▅▆▁▃▄▄▅▄▅▆▆▅▇▄▆▅█▆▅█▅▄▆▇▃▇▄▆▅▇
wandb:         train/mil_loss ▃▃▇▆▆▃▇▇▆▅▇▄▆▄▅▅▇▄█▄▇▇█▁▅▃▅▇▇▃▄▅█▃▇▄▅▃▂▁
wandb:      train/policy_loss ▆▆▂██▆█▄▇██▇▆▆▄▆█▆█▆▂▆▆▅██▆▆██▁█▇▆▆▆█▄▄▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▂█▄▆█▆█▄███▆▃█▄██▆▆▂██▃▆▅▆▄█▆█▆▁█▄▄▆▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 2.31404
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 2.26868
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.6894
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.51049
wandb:      train/ensemble_f1 0.51049
wandb:         train/mil_loss 1.46244
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dx9rff8r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152639-dx9rff8r/logs
wandb: Agent Starting Run: nfnuxy65 with config:
wandb: 	actor_learning_rate: 0.00022150776643122056
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6994912403774519
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9878040237644434
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152757-nfnuxy65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nfnuxy65
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▅▅▄▃▃▁▅▃▄▃▄▄▅▅▄█▄▆▆▄▅▆▃▆▅▅▂▄▅▅▅▄▄▄▄█▃
wandb:      train/ensemble_f1 ▄▅▄▅▁▅▅▃▃▄▄▄▄▄█▂▆▄▆▆▆▅▆▆▇▆▅▂▄▅▄▆▅▆▄▄▄▄▆▃
wandb:         train/mil_loss ▅▇▅▄▂▅▇▄▆▆▄▃▄▃▄▄▆▂▅▅▄▅▁▆▅▁▃▅█▅▄▄▁▃▄▄▅▅▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.50248
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.45316
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 3.05075
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.348
wandb:      train/ensemble_f1 0.348
wandb:         train/mil_loss 0.62353
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nfnuxy65
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152757-nfnuxy65/logs
wandb: Agent Starting Run: vowi4j03 with config:
wandb: 	actor_learning_rate: 0.0069266602689965874
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5008394572765692
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8813224480307286
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152914-vowi4j03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vowi4j03
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▆█▃▅▆▇▆▅▅▅▂▄▃▅▄▄▄▅▅▆▄▃▅▄▄▆▄▅▅▆▃▅▄▆▄▄▆▃
wandb:      train/ensemble_f1 ▁▆█▅▅▇▁▂▅▆▅▄▃▅▄▄▄▂▄▄▄▅▄▆▄▄▅▃▂▄▄▂▅▅▇▅▄▂▁▅
wandb:         train/mil_loss ▄▂▆▅▅▄▅▆▃▄▅▃▆▇▆▄▅▅▃▃▅▅▅▁▃▃▅▃▄▂▄▆▅▄█▂▃▄▄▃
wandb:      train/policy_loss ▇█▄▄▅▅▃▅▅█▆▄▅▅▇▇▅▇▄█▅▁▇▂▆▄▅▄▃▅▅▄▂▂▅▇▇▅▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▄▃▁▅▅▅▅▃▁▆▃▆▃▅▆█▅▆█▅▁▅▅▄▁▄█▆▅▆█▃▃▄▄▁█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78947
wandb: best/eval_avg_mil_loss 0.60683
wandb:  best/eval_ensemble_f1 0.78947
wandb:            eval/avg_f1 0.78947
wandb:      eval/avg_mil_loss 0.59792
wandb:       eval/ensemble_f1 0.78947
wandb:            test/avg_f1 0.85978
wandb:      test/avg_mil_loss 0.38962
wandb:       test/ensemble_f1 0.85978
wandb:           train/avg_f1 0.84552
wandb:      train/ensemble_f1 0.84552
wandb:         train/mil_loss 0.3091
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vowi4j03
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152914-vowi4j03/logs
wandb: Agent Starting Run: u7mwuc98 with config:
wandb: 	actor_learning_rate: 0.004414103591792328
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8846190688545355
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11543865634090932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153032-u7mwuc98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7mwuc98
wandb: uploading history steps 106-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▆▅▃▄▂▂▁▃▃▄▃▃▃▇▃▄▄▃▄▆▄▃▁▅█▄▄▄▄▄▆▄▅▅▃▆▅
wandb:      train/ensemble_f1 ▄▃▄▂▄▂▃▄▁▅▃▃▃▃▄▅▂▄▅▄▁▄▂█▅▅▅▅▄▄▄▅▇▃▅▆▃▆▅▄
wandb:         train/mil_loss ▄▂▃█▅▃▁▂▃▃▆▂▂▅▅▂▃▅█▁▂▆▄▅▂▂▂▆▅▃▇▂▇▄▃▄▃▁▃▂
wandb:      train/policy_loss ▇████▁▃▁▂▂▂▁▁▂▄▁▄▄▂▂▄▁▁▁▂▁▅▂▂▃▁▁▂▂▁▁▂▂▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇████▅█▇▃▄▂▁▁▄▁▁▁▂▁▄▄▁▂▁▁▂▂▁▁▁▃▃▄▁▂▂▂▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68337
wandb: best/eval_avg_mil_loss 0.88054
wandb:  best/eval_ensemble_f1 0.68337
wandb:            eval/avg_f1 0.68337
wandb:      eval/avg_mil_loss 0.85062
wandb:       eval/ensemble_f1 0.68337
wandb:            test/avg_f1 0.60067
wandb:      test/avg_mil_loss 1.36625
wandb:       test/ensemble_f1 0.60067
wandb:           train/avg_f1 0.69347
wandb:      train/ensemble_f1 0.69347
wandb:         train/mil_loss 0.27326
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7mwuc98
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153032-u7mwuc98/logs
wandb: Agent Starting Run: uaiuhsw1 with config:
wandb: 	actor_learning_rate: 0.003751163127332067
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11434709221708828
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11565984605238266
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153206-uaiuhsw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uaiuhsw1
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▄▃▄▃▃▅▄▅▅▂▃▄▃▃▃▅▆▂▄▃▃▃▄▅▄▄▅▃▁▃▃▅█▇▆▅▆
wandb:      train/ensemble_f1 ▁▄▃▃▂▃▄▁▃▄▁▄▃▁▃▂▃▃▁▄▂▂▅▄▄▃▃▄▄▅▄▃▂▃▂▅▃▅█▇
wandb:         train/mil_loss ▄▆▇▅▃▄▆▇▃▂▅▅▆▄▇█▇█▅▅▄▅▂▅▅▆▁▄▇▁▅▄▅▄▂▆▆▆▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.45129
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.38476
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 3.01437
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.36052
wandb:      train/ensemble_f1 0.36052
wandb:         train/mil_loss 2.50819
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uaiuhsw1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153206-uaiuhsw1/logs
wandb: Agent Starting Run: j7cxan6x with config:
wandb: 	actor_learning_rate: 0.008965739521088107
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03670356580501932
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5749186261627461
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153323-j7cxan6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j7cxan6x
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▆▄▆▇▁▅▇▄▄▃▃▆█▆▆▃▄▇▃▇▅▆▅▃▄▅▆▅▆▆▆▅▇▅▅▂▅█
wandb:      train/ensemble_f1 ▇▇▃▅▆▄▇▇▁▇▅▃▅▃█▄▁▆▃▆▅▃▅▃▅▇▆▆▅▅▆▆▆▅▇▅▂▅▂▅
wandb:         train/mil_loss ▃▁▅▇▅▃▃█▄▄▃▅▅▇▆▆▄▆▄▃▁▇▃▃▃▂▄▂▄▅▅▇▄▅▃▇▃▇▂▆
wandb:      train/policy_loss ▆███▁█████▁█▆██▁█▁████████████▆█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁█▆███▁█████▁█▁█▁██████████▁███▁▁██████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85949
wandb: best/eval_avg_mil_loss 0.4075
wandb:  best/eval_ensemble_f1 0.85949
wandb:            eval/avg_f1 0.85949
wandb:      eval/avg_mil_loss 0.3993
wandb:       eval/ensemble_f1 0.85949
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.15542
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.91371
wandb:      train/ensemble_f1 0.91371
wandb:         train/mil_loss 0.29359
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j7cxan6x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153323-j7cxan6x/logs
wandb: Agent Starting Run: kl47n6fw with config:
wandb: 	actor_learning_rate: 1.6860157610951096e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3166438815043111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.056482309814136045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153441-kl47n6fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl47n6fw
wandb: uploading history steps 231-240, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▂▂▂▂▂▂▂▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅███████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▂▄▂▂▃▃▂▁▄▃▃▄▃▅▂▅▃▄▅▆▄▄▅▄▃▆▅▄▄▅▄▆▆▇▇█▄
wandb:      train/ensemble_f1 ▄▃▂▂▅▄▂▃▅▅▃▃▄▂▆▆▃▆▃▄▄▁█▄▆▃▇▄▄▆▇▆▇▇▂▄▇▅▄▇
wandb:         train/mil_loss ▅▂▆▁▇▅▇▃▄▅▆▇▆▄▅▇▆▄▄▆▃▄▄▄▃█▂▃▄▁▆▅▅█▃▂▅▅▄▄
wandb:      train/policy_loss ▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▃▄▅▃▄▃▅▄▆▃▅▄▁▇▃▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄█▃▄▂▅▇▄▄▄▃▆▂▅▃▂▄▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42241
wandb: best/eval_avg_mil_loss 2.29834
wandb:  best/eval_ensemble_f1 0.42241
wandb:            eval/avg_f1 0.42241
wandb:      eval/avg_mil_loss 2.23368
wandb:       eval/ensemble_f1 0.42241
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 2.86534
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.4247
wandb:      train/ensemble_f1 0.4247
wandb:         train/mil_loss 1.93905
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl47n6fw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153441-kl47n6fw/logs
wandb: Agent Starting Run: ux6629x9 with config:
wandb: 	actor_learning_rate: 2.3942304238603544e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1673728146235095
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6826122149968334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153738-ux6629x9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux6629x9
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▃▄▄▃▃▃▅▂▄▅▂▅▃▅▅▅▄▆▁▂▃▄▄▆▃▅█▆▅▆▆▅▄▃▅▃▅
wandb:      train/ensemble_f1 ▄▃▃▁▅▃▂▃▆▅▁▃▃▄▃▄▃▅▆▅▄▅▃▄▅▅▅▄█▃▆▃▅▇▂▅▄▅▄▃
wandb:         train/mil_loss ▄▅█▄▅▅▃▅█▂▄▆▅▁▄▅▃▅▄▄▄▆▄▅▁▄▂▂▄▄▃▆▂▁▄▂▁▅▄▄
wandb:      train/policy_loss █▆▇▄▅▆▆▅▁▆▄▆▆▆▆▅▆▂█▆▆▅▁█▆▆▆▄▇▄▄▆▆▄▄▇█▄▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▇▆█▃▆▅█▃▆▆▆▆▃█▅█▅▆▁▆▃▆▁▅▆█▆▅▆▆▆██▆▁█▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.41168
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.37295
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.13603
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88567
wandb:      train/ensemble_f1 0.88567
wandb:         train/mil_loss 0.27602
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux6629x9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153738-ux6629x9/logs
wandb: Agent Starting Run: ojou7vhk with config:
wandb: 	actor_learning_rate: 1.822802677127808e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8678824369869738
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6045940874964755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153855-ojou7vhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ojou7vhk
wandb: uploading history steps 107-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅██▅▅▅▅▅▅▅▁▁▁▁▁▅▅▅▅▅▅▅▅▅███████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▃▄▄▄▄▆▆▇▇▇████▇▇▇▇▇▇▆▆▆▆▅████▇▇▇▇▇
wandb:       eval/ensemble_f1 ▅▅▅▅▅█▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▂▃▅▃▁▅▁▅▂▃▂▃▅▁▂▆▅▅▅▅▄▇▅▅█▄▃▆▆▅▆▅▆▄▄▂▆
wandb:      train/ensemble_f1 ▂▅▆▅▂▆▁▃▁█▄▂▅▅▁▁▃▅▆▅▄▂█▄▅▇▃▄▆▄▅█▆▅▆▇▇▆█▆
wandb:         train/mil_loss ▄▃▃▆▄▁▃▃▂▂▃▂▄▅▂▄▂▄▂▂▃█▆▃▆▃▃▂▃▃▄▃▂▆▂▃▂▃▄▄
wandb:      train/policy_loss ▅▄▆██▆▆▂▁▂▆▆▆▆▅▂▁▂▃▁▂▄▃▆▅▅█▃▂▁▃▂▁▂▂▁▁▃▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91948
wandb: best/eval_avg_mil_loss 0.26459
wandb:  best/eval_ensemble_f1 0.91948
wandb:            eval/avg_f1 0.91948
wandb:      eval/avg_mil_loss 0.2888
wandb:       eval/ensemble_f1 0.91948
wandb:            test/avg_f1 0.76887
wandb:      test/avg_mil_loss 0.47379
wandb:       test/ensemble_f1 0.76887
wandb:           train/avg_f1 0.83645
wandb:      train/ensemble_f1 0.83645
wandb:         train/mil_loss 0.24203
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ojou7vhk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153855-ojou7vhk/logs
wandb: Agent Starting Run: y6rwtm4u with config:
wandb: 	actor_learning_rate: 0.0007323090170627727
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4232319476370794
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7063935310475828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154023-y6rwtm4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6rwtm4u
wandb: uploading history steps 282-289, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss ██▇▅▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▂▂▂▂▁▂▃▄▄▄▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆▇▇██████▆▆▆▆▆▆▅
wandb:      eval/avg_mil_loss ▇▇█████▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▃▂▄▃▃▃
wandb:       eval/ensemble_f1 ▂▂▂▂▁▂▂▂▂▂▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▂▅▁▂▃▇▄▄▄▃▅▄▂▄▆▇▃▆▁▆▁▄▇▄▃█▄▆▅▅▃▇▄▆▅▅
wandb:      train/ensemble_f1 ▄▅▅▃▄▆▄▁▁▄▆▂▃▆▄▂▄▅▆▄▆▆▆▄▁▇▄▄▆█▄▄▆▂▄▅▅▆▄▅
wandb:         train/mil_loss █▆▆▆▃▃▂▃▇▄▅▇▁▆▄▂▃▇▂▅▄▃▄▆▁▆▁▄▁█▄▄▂▃▆▆▆▆▃▅
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▁▂▄▄▅▇█▄▆▄▄▄▆▇█▅█▆▆▅▅▅▅▁▆▅▅▆▃▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68337
wandb: best/eval_avg_mil_loss 0.9714
wandb:  best/eval_ensemble_f1 0.68337
wandb:            eval/avg_f1 0.6397
wandb:      eval/avg_mil_loss 0.98638
wandb:       eval/ensemble_f1 0.6397
wandb:            test/avg_f1 0.63958
wandb:      test/avg_mil_loss 0.99605
wandb:       test/ensemble_f1 0.63958
wandb:           train/avg_f1 0.65771
wandb:      train/ensemble_f1 0.65771
wandb:         train/mil_loss 0.67762
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6rwtm4u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154023-y6rwtm4u/logs
wandb: Agent Starting Run: wyb3odpb with config:
wandb: 	actor_learning_rate: 4.1093408735039326e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12999191528170873
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6646025362634466
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154350-wyb3odpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wyb3odpb
wandb: uploading history steps 131-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▃▃▇▅▄▃▁▃▅▅▃▂▃▆▄▂▃▅▃▇▂▁▂▃▅▅▇▂▃▁▃▄█▅▅▃▅
wandb:      train/ensemble_f1 ▅▃▂▂▂▅▃▃▂▂▅▄▇▂▃▂▂█▂▆▅▂▂▅▂▄▆▆▃▃▃▁▁▃▅▄▃▅▅▆
wandb:         train/mil_loss ▆▆▇▅▅▅▄▃▆▃▅▃▇▄▃▃▃▄▆▃▅▄▆▄▅▅▁▃▄▅▅▆█▃▃▆▃▂▆▅
wandb:      train/policy_loss ████▆▆██▆▆▄▆▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▄██▆▆███▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86841
wandb: best/eval_avg_mil_loss 0.30096
wandb:  best/eval_ensemble_f1 0.86841
wandb:            eval/avg_f1 0.86841
wandb:      eval/avg_mil_loss 0.28517
wandb:       eval/ensemble_f1 0.86841
wandb:            test/avg_f1 0.83994
wandb:      test/avg_mil_loss 0.42059
wandb:       test/ensemble_f1 0.83994
wandb:           train/avg_f1 0.85655
wandb:      train/ensemble_f1 0.85655
wandb:         train/mil_loss 0.40379
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wyb3odpb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154350-wyb3odpb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mtdquerw with config:
wandb: 	actor_learning_rate: 2.2046141972761393e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8175568590610021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.795670658061121
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154537-mtdquerw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mtdquerw
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb:       eval/ensemble_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▂▁▆▆▄▃▃▄▃▆▄▃▄▄▄▃▅▄▇▂█▇▅█▄▄▄▅▆▄▃▆▄▅▄▄▆
wandb:      train/ensemble_f1 ▆▂▃▃▄▃▆▃▃▃▆▄█▁▅▄▅▃▃▅▄▅▁▇▂▆▃▇▆▅▃▃▂▄▄▁▄▅▃▅
wandb:         train/mil_loss ▁▅▃▁█▆▃▇▄▅▅▁▃▃▄█▃█▆▇▆▃▅▇█▂▅▆▃▃▁▅▁▅▇▆▁▃▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 1.75567
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.72085
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.10961
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.57541
wandb:      train/ensemble_f1 0.57541
wandb:         train/mil_loss 0.53125
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mtdquerw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154537-mtdquerw/logs
wandb: Agent Starting Run: 4122npr1 with config:
wandb: 	actor_learning_rate: 0.0013102328851884702
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1349705690246168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04975915632545913
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154653-4122npr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4122npr1
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆███▇▇▇▇▆▆▅▄▄▄▃▃▃▃▂▂▆▅▅▅▅▄▄▄▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▄▃▅▅▄▂▅▆▄▃▁▄▅▇▄▄▄▆▅▃▁▇▄▅█▇▆▇▄▄▇▆▅▄▆▄▇█
wandb:      train/ensemble_f1 █▂▇▅▅▆▃▁▆▇▆▄▅▄▃▃▂▁█▅▆▇▂█▆▂▂▇▆▅█▄▆▇▅▄▅▅▄█
wandb:         train/mil_loss █▆▅▇▂▃▄▃▄▇▆▂▃▅▄▄▄▅▅█▇▇█▆▄▅▃▅▆▆▃▄▃▆▄▇▂▆▃▁
wandb:      train/policy_loss ████▄▆▆▆█▆▆▅▆▆▄█▁▆█▆███▆▆▄▄▆▆▆▆▆▆█▆█▄█▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▆██▄▆▆█▆▆█▆▆▄▁████▆▆▆▆▄▄▆▆▆▆▆▆▆█▆██▆▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49004
wandb: best/eval_avg_mil_loss 1.98356
wandb:  best/eval_ensemble_f1 0.49004
wandb:            eval/avg_f1 0.49004
wandb:      eval/avg_mil_loss 1.95431
wandb:       eval/ensemble_f1 0.49004
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.28418
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.53027
wandb:      train/ensemble_f1 0.53027
wandb:         train/mil_loss 1.52654
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4122npr1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154653-4122npr1/logs
wandb: Agent Starting Run: 1kjyd4tx with config:
wandb: 	actor_learning_rate: 0.0002569043568367185
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2528914019961428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8449366426621713
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154811-1kjyd4tx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kjyd4tx
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▄▁▅▅▄▆▄▆▆▅▅▃█▆▃▄▅▆▅▄▆▄▇▅▃▁▅▆▇▆▃▄▄▆▆█▆█
wandb:      train/ensemble_f1 ▇▄▄▁▅▅▄▅▄▅▅▃▆▃█▅▇▃▄▃▇▄▆▃▄▇▄▃▄▅██▇▇▆▇▇▅▆▆
wandb:         train/mil_loss ▃▆▅▆▂▅▅▃▅▇▆▃▆▄▃▄▅▄▄▁▅▄▄▅█▆▆▆▅▄▄▄▆▄▅▂▆▄▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 1.56273
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.53249
wandb:      eval/avg_mil_loss 1.48807
wandb:       eval/ensemble_f1 0.53249
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 1.6683
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.56086
wandb:      train/ensemble_f1 0.56086
wandb:         train/mil_loss 1.27673
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kjyd4tx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154811-1kjyd4tx/logs
wandb: Agent Starting Run: eujjwrs2 with config:
wandb: 	actor_learning_rate: 1.90236851355571e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.975708523638222
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4084760662107817
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154929-eujjwrs2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eujjwrs2
wandb: uploading history steps 109-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▆▆▆▆██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▁▁▃▃▃▃▃▃▃▃▃▃▃▆▃▃
wandb:      eval/avg_mil_loss ▂▁▁▁▁█▇▇▇▆▆▆▆▆▆▅▅▅▅▄▃▃▄▄▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃
wandb:       eval/ensemble_f1 ▄▄▄██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▁▁▃▃▃▃▃▃▃▃▃▃▅▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▄▂▃▂▄▃▇█▇▃▅▄▄▄▅▇▃▅█▁▇▄█▅▅▇█▅█▅▆▆▃▆▆▇▆
wandb:      train/ensemble_f1 ▆▄▂▄▂▃▄▇▅▃█▇▅▄▃▅▆▆▅▅▄▅▄▅▃█▁▄▅▃█▅▆▆▆▆▄▆▅▆
wandb:         train/mil_loss ▄▅▃▆▄▄▃▄▃▄▄▄▆▄▅▄▅▁▃▅▄▃▄▅▅▄▄▄▄▄▅▆▄▇█▅▅▂▄▂
wandb:      train/policy_loss ██████████████████████████████████████▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▁▃▆▆▆▆▆▆▆▆▆▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.32904
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.88
wandb:      eval/avg_mil_loss 0.33159
wandb:       eval/ensemble_f1 0.88
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.30222
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.86961
wandb:      train/ensemble_f1 0.86961
wandb:         train/mil_loss 0.27106
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eujjwrs2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154929-eujjwrs2/logs
wandb: Agent Starting Run: jej981n6 with config:
wandb: 	actor_learning_rate: 0.000156351114896489
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3060001096878633
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2211571577386977
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155051-jej981n6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jej981n6
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇███████████
wandb:       eval/ensemble_f1 ███▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▇▆▇▅▇▁▆▁▆▂▂▆█▅▄▃▃▄▅▅▆▂▃▄▁▁▄▃▆▆▅▄▂▄▄█▂▆
wandb:      train/ensemble_f1 █▇▆▄█▃▄▃▇▃▇▅▆▅▄▆▇▄▇▅▇▂▄▆▅▅▆▅▃▄▅▂▆▅▅▁▆▃▆▇
wandb:         train/mil_loss ▅▃▄▃▅▃▂▄█▄▃▃▃▃▂▄▃▄▁▃▁▆▂▅▄▆▃▅▅▅▂▂▆▄▃▃▅▂▂▃
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▂▂▅▅▅█▇▆▆▆▇▅▆█▄▇▆▃▆▅▆▅▆▇▆▆▇▆▇▅▆▆▆▅▅▇▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94995
wandb: best/eval_avg_mil_loss 0.18003
wandb:  best/eval_ensemble_f1 0.94995
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.2057
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.20608
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.88241
wandb:      train/ensemble_f1 0.88241
wandb:         train/mil_loss 0.27976
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jej981n6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155051-jej981n6/logs
wandb: Agent Starting Run: gvq1nrga with config:
wandb: 	actor_learning_rate: 0.00017777364142622783
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04684703477278051
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3764428489580769
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155209-gvq1nrga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvq1nrga
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▃▁▂▂▂▅▃▁▄▂▄▃▄▄▃▅▂▄▄▅▄▄▅▄▅▄▃▃▂█▄▆▄▄▃▅▄
wandb:      train/ensemble_f1 ▄▂▄▂▂▂▃▅▃▃▅▃▁▄▃▅▄▃▃▃▅▄▂▅▅▅▄▃▄▅▄▂█▆▄▃▄▄▅▄
wandb:         train/mil_loss ▄▂▆▇▁▆█▄▄▅▂▂▆▁▃▆▅▅▄▅▅▅▅▃▃▆▄▅▃▂▄▃▃▆▃▄▃▇▃▃
wandb:      train/policy_loss ▁▁▁▂▁▁▂▁▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁██▇████████▇██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▂▁▂▁▁▂▁▁▁▁▂▁▂▁████████▇██████▇███▇█▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.36919
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.33384
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.10926
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.9134
wandb:      train/ensemble_f1 0.9134
wandb:         train/mil_loss 0.24255
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvq1nrga
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155209-gvq1nrga/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nnuyhevn with config:
wandb: 	actor_learning_rate: 9.160656776433238e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6686139741531181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013693049739822882
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155332-nnuyhevn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nnuyhevn
wandb: uploading history steps 84-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▅▅▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ████████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▄▅▅▆▄▇▃█▄▃▅▃▄▄▄█▃▁▃▅▅▄▆▂▃▄█▃▆▄▇▇▅▅▇▇▄
wandb:      train/ensemble_f1 ▃▄▇▄▆▅▆▆▆▃▄▄▄▃▃▄▇▄▄█▇▄▅▁▆▄▅▅▃▆▆▅▅▃▅▆▅▇▄▅
wandb:         train/mil_loss ▆▆▄▄▄▅▂▅▃▇▁▃▄▆▅▃▄▆▅█▃▆▆▄▆▅▄▆▂▅▃▅▅▅▁▄▆▇▅█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.33201
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.34252
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.10347
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.91099
wandb:      train/ensemble_f1 0.91099
wandb:         train/mil_loss 0.26007
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nnuyhevn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155332-nnuyhevn/logs
wandb: Agent Starting Run: s73p61j5 with config:
wandb: 	actor_learning_rate: 0.000109417500024394
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6516259754348785
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07993201481222412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155450-s73p61j5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s73p61j5
wandb: uploading history steps 149-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅█████████████████████████
wandb:      eval/avg_mil_loss ██████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▂▆▁▂▄▃▃▂▄▃▃▄▄▄▃▄▅▃▅▄█▅▄▄▃▂▄▂▇▅▂▂▅▄▂▃▃▄
wandb:      train/ensemble_f1 ▃▅▂█▁▂▄▂▅▂▄▄▅▆▅▃▅▂▇▇█▇▅▅▃▅▄▅▆▄▆▅▅▄▆▇▂▇▇▅
wandb:         train/mil_loss ▄▃▃▃▅▅▂▅▃▅▃█▅▆▂▃▂▃▃▁▂▄▅▄▃▄▆▅▄▂▁▃▂▃▂▂▃▅▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▅▂▃▃▃▃▃▃▃▃▃▃▃▄▆▅▄▄▄█▆▁▄▃▆▆▂█▆▅█▆▆▄▄▆▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42241
wandb: best/eval_avg_mil_loss 2.35488
wandb:  best/eval_ensemble_f1 0.42241
wandb:            eval/avg_f1 0.42241
wandb:      eval/avg_mil_loss 2.2839
wandb:       eval/ensemble_f1 0.42241
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 2.8359
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.40991
wandb:      train/ensemble_f1 0.40991
wandb:         train/mil_loss 0.5639
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s73p61j5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155450-s73p61j5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ljs9pao9 with config:
wandb: 	actor_learning_rate: 3.779160194063015e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2577117711059389
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.793206820450122
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155700-ljs9pao9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ljs9pao9
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▂▅▄▇▃▄▅▇▇▆▂▃▄▇▅▅▃▇▄██▃▆▄▇▆▃▂█▅▇▇▁▆▃▃▆
wandb:      train/ensemble_f1 ▄▄▆▅▃▁▅▆▃▂▂▃▃▅▃▅▃▄▆▄▃▅▂▄▂▇▄▅▅█▆▅▅▃▇▁▃▇▄▄
wandb:         train/mil_loss ▅▃▃▃▄▃▃▇▅▅█▃▆▅▅▅▄▇▅▃▄▂▆▁▃▅▆▃▁▃▁▅▃▄▄▃▃▄▅▄
wandb:      train/policy_loss ▆▅▆▆▃█▆▆▆▃▆▆▁▆█▁▅▅█▅▃▃▃▅▅▆█▅▃▆▃▆▃▆█▁▁▁▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▄▅▆▆█▆█▆▃▆▅▆▁▅▄▆▅▅▃▆▅▅▃▅▅▃▃▅▆▅▃▆▃▆▅▆▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.40857
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.38258
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11653
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89231
wandb:      train/ensemble_f1 0.89231
wandb:         train/mil_loss 0.26072
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ljs9pao9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155700-ljs9pao9/logs
wandb: Agent Starting Run: uxyb6qch with config:
wandb: 	actor_learning_rate: 6.186238883597415e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5104281634675722
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.491962104390728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155817-uxyb6qch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uxyb6qch
wandb: uploading history steps 535-549, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▄▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▅▅▅▅▅▅▃▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▄▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇█████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▃▂▃▂▄▃▂▄▄▄▃▄▄▅▅▄▆▄▆▇▅▅▆▇▆▆▅▇▅▆▇▆▆█▆█▇
wandb:      train/ensemble_f1 ▁▂▂▃▃▃▃▃▃▅▃▅▆▅▆▅▅▆▇▆▅▇▇█▇▇█▇▆█▇▇▇▅▇█▆▇██
wandb:         train/mil_loss ▅█▅▄▅▃▂▇▅▃▃▂▂▂▄▃▄▅▄▃▃▂▅▆▁▅▅▅▄▅▃▆▃▂▃▁▃▄▁▄
wandb:      train/policy_loss ▄▄▃▃▃▁▃▃▃▃▃▃▃▃▃▄▄▁▄▅▃▃▃▂▁▂▂▁▃▃▅▁█▄▆▂▄▄▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆▂▃▃▂▂▃▄▄▅▆▃▃▂▃▆▄▂▂▃▂▁▄▄▄▄▄▆▆▃▂▃█▄▅▂▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81527
wandb: best/eval_avg_mil_loss 0.38969
wandb:  best/eval_ensemble_f1 0.81527
wandb:            eval/avg_f1 0.80563
wandb:      eval/avg_mil_loss 0.37433
wandb:       eval/ensemble_f1 0.80563
wandb:            test/avg_f1 0.8
wandb:      test/avg_mil_loss 0.39899
wandb:       test/ensemble_f1 0.8
wandb:           train/avg_f1 0.77305
wandb:      train/ensemble_f1 0.77305
wandb:         train/mil_loss 0.38568
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uxyb6qch
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155817-uxyb6qch/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tsafqyt2 with config:
wandb: 	actor_learning_rate: 0.00036199242296321865
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5235530729786744
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4614151350207949
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160500-tsafqyt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsafqyt2
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▄▆▄▅▅▂▄▅▁▄▁▂▄▄▅▅▁▅▄▄▅▄▃▅▅▂▃▄▄▂▅▂▄▃▅▂█▄
wandb:      train/ensemble_f1 ▅▄▄▆▃▄▆▄▅█▅▄▄▅▁▂▃█▃▁▇▄▄█▅▄▃▄▂▃▆▃▄▂▂▃▂▅▂▃
wandb:         train/mil_loss ▃▇█▃▅▇▃▁▆▂▃█▄▆▄▂▄▃▆▃▃▇▂▅▃▄▄▆▄▄▄▇█▄▃▅▄▅▃▆
wandb:      train/policy_loss ▄▄▇▄▆▄▅▄▄▅▇▄█▁▅▄▂▄▄▂▃▁▁▁▆▄▄▄▄▄▃▁▁▇▄▇▄▆▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▄▄▃▆▆▄▆▂▆▅▁▄▅▆▂▅▅▂▃▂▁▄▅▄▄▄▄▄▁▃▁▄██▅▅▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86988
wandb: best/eval_avg_mil_loss 0.33361
wandb:  best/eval_ensemble_f1 0.86988
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.33006
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.21979
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.87495
wandb:      train/ensemble_f1 0.87495
wandb:         train/mil_loss 0.30515
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsafqyt2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160500-tsafqyt2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ucewjt6u with config:
wandb: 	actor_learning_rate: 0.0001343382794481527
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9159594984532944
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.544928445261431
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160646-ucewjt6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucewjt6u
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▇▇▇▇█████
wandb:       eval/ensemble_f1 ████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▆▂▇▂▆▃▃▅▃▂▅▅▅▅▇▄█▂▅▅▅▃▅▄▃▄█▅▆▅▃▁▅▂▆▂▃▅
wandb:      train/ensemble_f1 ▅▆▂▆▅▁▆▃▅▇▄▇▄▆█▅█▄▇▃▆▅▆▇▄▅▅▄▆▅▅▅▄▅▅▂▆▃▄▆
wandb:         train/mil_loss ▁▆▃▆▃▅▅▄▄▆▅▃▄▄▅▆▃▅▆▄▄▃▅▅▄▆▄▄▁▅▂█▆▃▂▃▃▃▅▄
wandb:      train/policy_loss ▇▇▇█▇█▆▇▆██▆▇██▇██▇█▁▃▃▃▃▃▁▃▃▃▃▁▁▁▁▁▅▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇██████▆▇▇██▇▇▇████▇▇█▆▇▃▃▃▃▃▃▃▅▁▁▃▁▁▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.4564
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.47807
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.13756
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.89043
wandb:      train/ensemble_f1 0.89043
wandb:         train/mil_loss 0.22949
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucewjt6u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160646-ucewjt6u/logs
wandb: Agent Starting Run: 3r9xnrk3 with config:
wandb: 	actor_learning_rate: 0.0011825635325358706
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6215959193797609
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7787322036314763
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160804-3r9xnrk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3r9xnrk3
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▁▆▄▅▅▃▃▅▄▄▂▄▂▄▄▆▄▆▃▁▆▄▄▂▅▅▆▆▇▄▄▄▆▇▄█▆
wandb:      train/ensemble_f1 ▁▆▂▅▄▅▅▃▃▄▅▇▇▄▇▆▆▅▆▇▄▄▅▇▆▆▂▁▅▄▅▆▆▆█▅▇▇▄▇
wandb:         train/mil_loss ▅▃▇▆▆▃▄▄▄▅▅▂▃▇▂▃▃▆▇▇▄▅▄█▂▇▅▇▄▂▅▅▄▃▆▃▇▇▆▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 2.17472
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.13595
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.53649
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.48436
wandb:      train/ensemble_f1 0.48436
wandb:         train/mil_loss 0.2801
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3r9xnrk3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160804-3r9xnrk3/logs
wandb: Agent Starting Run: s4sa4v0d with config:
wandb: 	actor_learning_rate: 0.0004710286683701395
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6045333707566206
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22502087874673593
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160922-s4sa4v0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4sa4v0d
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▃▃▂▄▁▅▂▃▆▇▇▁▂▃▄▁▃▂▃▆▅█▆▅▄▅▄▃▆▆▅▃▄▄▅▃▅▆
wandb:      train/ensemble_f1 ▃▆▄▅▅▂▅▄▆▃▄▁█▅▇▄▆▄▅▅▄▄▄█▅▆▆▆▆▆▆▅▇▅▆█▅▆▄▇
wandb:         train/mil_loss █▂▂▆▆▄▂▃▄▄▄▆▃▅▃▃▂▁▃▂▄▄▃▃▁▃▄▃▂▄▅▃▄▃▂▃▅▅▃▄
wandb:      train/policy_loss ▄▄▆▅▅▄▆▅▄▇▃▇▄▄▁▆▅▅▃▄▃▂▄▄▄▄█▅▅▅▄▅▄▇█▄▇▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.23495
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.21853
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.29687
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.8925
wandb:      train/ensemble_f1 0.8925
wandb:         train/mil_loss 0.24457
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4sa4v0d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160922-s4sa4v0d/logs
wandb: Agent Starting Run: jwbex8s4 with config:
wandb: 	actor_learning_rate: 0.0004527050635750214
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7390827238477076
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5668192525158432
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161040-jwbex8s4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jwbex8s4
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▆▆▆▆▆▇▇▇▇▇▇▇███████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▆▄▆▆▄█▃▃▄▇▄▅▆▆▃▅▅▇▄▆▄▄▃▂▇▅▅▆▅█▂▄▁▇▆▆▄
wandb:      train/ensemble_f1 ▃▇▄▆▄▆▄█▂▃▁█▄▅▃▇▅▅▅▅▄▅▆▃▄▁▇▅▇▄▅▅▆▁▄▄▇▆▆▅
wandb:         train/mil_loss ▅▃▆▆▁▇▄▆▅▄▅▅▃▄▄▄▄▅▁▅▃▃▅█▅▇▁▆▇▂▂▆▅▄▃▄▂█▆▂
wandb:      train/policy_loss ▅▇▆▁▄▆▅▅█▅▇▅▇▄▅▇▅▂▇▄█▇▅▇▇▆▇▇▅▃▇▃▇▇▇▇▆▇▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▅▄▁▇▅▅▅▆▇▆▅▅▅▅▇█▅▇▂▇█▇▆▇▆▅▇▅▆▇▅▇▇▇▄▄▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.38434
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.40168
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.10057
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91601
wandb:      train/ensemble_f1 0.91601
wandb:         train/mil_loss 0.29171
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jwbex8s4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161040-jwbex8s4/logs
wandb: Agent Starting Run: 2frhphop with config:
wandb: 	actor_learning_rate: 4.444911088082383e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7477347034044294
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13145368933671375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161158-2frhphop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2frhphop
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▄▅▅▅▅▆▇▃▁▄▃▅▅▄▃▇▇▆▆▄█▆▇▆▅▅▇▃▂▅▃▄▅▅▅▇▅
wandb:      train/ensemble_f1 ▄▄▁▄▆▃▆▄▅▅▅▅▂▅▅▂▇▂▅▅▆▅▄▇▇▆▅▅▆▅▃▅█▆▄▄▅▆▃▇
wandb:         train/mil_loss ▄▃▅▂▃▂▂▄▂▅▃▄▁▃█▃▃▂▃▃▄▅▃▂▅▂▃▃▄▃▄▂▃▂▄▃▁▃▂▆
wandb:      train/policy_loss █▃█▆██▄█▅▆▅▂▆▃▄▃▅███▆▆▆▃▆█▆▄▅▅▆▁▆▄▃▄▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▆▆█▃▄▃██▄▄▄▆▄▄█▅██▁▄▆▅▃▄▅▆▆▆▆▃▆▄▆▆▆▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.45716
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.46521
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.14012
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.89936
wandb:      train/ensemble_f1 0.89936
wandb:         train/mil_loss 0.25171
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2frhphop
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161158-2frhphop/logs
wandb: Agent Starting Run: 5gh2llws with config:
wandb: 	actor_learning_rate: 0.0028656695335717783
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9288449837256758
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.236510138785168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161317-5gh2llws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5gh2llws
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆▃▃█▄▃▅▄▆▆▄▅▄▅▆▃█▄▆▅▃▅▅▅▇▅▃▄▂▅▅▅▇▄▁▄▃▄
wandb:      train/ensemble_f1 ▅▂▃▆▄▃▄▅▃▇▆█▆▅▅▃▄█▄▂▆▃▅▃▃▅▅▅▂▅▅▅▄▄▁▄▃▄▅▅
wandb:         train/mil_loss ▄▆▄▆▁▄▁▄▂▇▂█▄▃▅▆▄▄▂▃▂▂▄▂▅▇▆▃▂▄▂▃▄▂▅▃▆▁▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.30908
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.32949
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9184
wandb:      test/avg_mil_loss 0.17996
wandb:       test/ensemble_f1 0.9184
wandb:           train/avg_f1 0.88125
wandb:      train/ensemble_f1 0.88125
wandb:         train/mil_loss 0.27017
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5gh2llws
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161317-5gh2llws/logs
wandb: Agent Starting Run: 0019mr4k with config:
wandb: 	actor_learning_rate: 6.310291964085264e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7787862152557548
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3237850120106308
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161435-0019mr4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0019mr4k
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▅▅▃▅▃▅▇▂▆█▄▁▂▆▄▄▄▄▇▄▅▅▂█▅▅▅▆▃▄▁▅▄▆▁▂▅█
wandb:      train/ensemble_f1 ▇▅▃▆▄▅▂▆▃▄▆█▅▄▅▆▆▄▆▅▃▅▃▅▆▄▃▂▃▃▅▅▁▄▃▁▆▅▂▃
wandb:         train/mil_loss ▅▆▆▅▆▆▃▄█▃▇▄▄▇▄▅▃▇▅▆█▇▆▇▄▆▆▂█▃██▅▁▄▂▃▄▅▃
wandb:      train/policy_loss ▂▂▄▁▄▄▁▂▃▃▆▃▅▆▆▅▆▄█▅██▆▅▆▆█▅█▆▅▃▅▄█▄█▅▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.34468
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.36027
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.11728
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.91622
wandb:      train/ensemble_f1 0.91622
wandb:         train/mil_loss 0.22971
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0019mr4k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161435-0019mr4k/logs
wandb: Agent Starting Run: soiohniv with config:
wandb: 	actor_learning_rate: 0.00039288913911022784
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7344953218800897
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6714707944819442
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161552-soiohniv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7j39dl0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/soiohniv
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▇▅▄▅▆▄▆▆▅▁▃▆▄▅▄▄▅▆▄█▄▄▃▄▅▅▃▃▄▄▂▅▅▅▄▅▄
wandb:      train/ensemble_f1 ▃▅▆▃▃▄▄▂▇▆▆▁▇▅▅▆▄▄▅▅▆▅▆▄▄▄▄▂▅▃▄▄▄▄▃▅▄▄█▄
wandb:         train/mil_loss ▄▂▁▂▄▅▄█▂▄▄▁▃▅▄▆▂▅▄▂▆▄▄▃▁▃▅▆▅▁▂▂▆▄▂▃▄▄▆▄
wandb:      train/policy_loss ▃▄▃▁▃▃▁▃▁▅▅▁▃▅▅▅▅▅▃▃█▅▃▃▃▃▅▆▇▁▃▁▁▃▁▃▃▅▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▁▅▄▃▃▃▅▁▃▅▃▁▃▅▅▁▁▃▅█▅▃█▁▄▅▆▇▄▁▃▁▃▃▃▄▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 1.6911
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 1.66121
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 1.86117
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.58706
wandb:      train/ensemble_f1 0.58706
wandb:         train/mil_loss 0.63792
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/soiohniv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161552-soiohniv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 958esfck with config:
wandb: 	actor_learning_rate: 0.0017765601948816492
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7762491279506175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8927637159750889
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161726-958esfck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/958esfck
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃█▆▅▅▅▃▄▄▄▁▅▄▅▇▄▅▃▃▆▃▄▅▄▃▁▃▅▆▃▄▄▃▁▅▃▄▄
wandb:      train/ensemble_f1 ▆▄▅▇▆▇▆▆▂▂▅▄▅▄▆▃█▅▆▅▆▆▂▄▆█▇▄▅▅▄▄▆▃▂▅▅▁▅▅
wandb:         train/mil_loss ▆▃▄▆▆▅▅▆▆▄▄▁▃▅▄▇▆█▆▃▃▃▃▇▅▃▂▄▆▃▃▃▅▃▆▄▃▄▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.26544
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.27264
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.19279
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.88474
wandb:      train/ensemble_f1 0.88474
wandb:         train/mil_loss 0.28421
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/958esfck
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161726-958esfck/logs
wandb: Agent Starting Run: mq4ja5sk with config:
wandb: 	actor_learning_rate: 1.674701410774984e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08528305392391189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8762118097312945
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161844-mq4ja5sk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq4ja5sk
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███████▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄█▇▆▁▅▄▅█▄▅▄▆▄▆▅▆▆▆▅▄▅▆▇▄▂▅▆▇▁▇▆▄▅▄▅▆▆
wandb:      train/ensemble_f1 ▄▄▄▃▂▃▄▁█▅▅▄▆▅█▅▅▆▇▅▄▄▇▅▄▅▅▄▅▃▇▁▄▆▆▅▅▅▄▅
wandb:         train/mil_loss ▇▁▅▅▆▂▄▇▅▄▁▂▂▆▂█▇▆█▅▅▆▅▇▄▇▆█▆▅▆▄▆▆▆▂▇▆▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.94259
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.83038
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.31866
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3372
wandb:      train/ensemble_f1 0.3372
wandb:         train/mil_loss 2.78987
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq4ja5sk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161844-mq4ja5sk/logs
wandb: Agent Starting Run: pbe5fpb3 with config:
wandb: 	actor_learning_rate: 3.422561315087396e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3733487482801544
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1844997919773448
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162002-pbe5fpb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pbe5fpb3
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▆▅▄█▂▄▄▅▅▄▃▆▆▅▄▅▄▅▅▅▁▆▆▇▂▅▆▅▅▅▄▃▅█▃▅█
wandb:      train/ensemble_f1 ▄▇█▅▅▅▄▃▃▂▅▄▅▆▂▃▃▅▅▇▅▄▆▆▄▅▅▆▆▆▇▁▆▇▅▃▇▆▆▆
wandb:         train/mil_loss ▅▅█▆▃▃▄▁▄▃▆█▅▃▇▅▂▁▃▄▄▅▂▅▃▂▂▅█▅▂▄█▅▂▅▃▃▄▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.39155
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.36497
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.76806
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3293
wandb:      train/ensemble_f1 0.3293
wandb:         train/mil_loss 2.01494
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pbe5fpb3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162002-pbe5fpb3/logs
wandb: Agent Starting Run: kcbwyz7l with config:
wandb: 	actor_learning_rate: 0.002309932846889307
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7847519483934983
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7986934634534584
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162119-kcbwyz7l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kcbwyz7l
wandb: uploading history steps 154-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▃▃▃▃▃▃▃▁▆▆▆▆▆▆██████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▅▅▅▅▅▅▅██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▅▁▁▅▁▄▅▅▆▄▅▇▄▄▆▃▃▆▅▆▇▆▅▆▅▃▇▇██▇▆▇▃▄▇█▃
wandb:      train/ensemble_f1 ▃▅▆▄▅▅▆▂▁▄▅▅▄▅▄▅▄▅▁▆▅▆▆▆█▄▄▆▅▆▇▇▅▆▇▆▃▆▇▇
wandb:         train/mil_loss ▇▇▇▄▂▂▆▆▅▅▄▃▁▄▄▅▂▅▅▃▄▄▄▄▃▆▂▄▅▄█▄▂▂▂▂▂▂▁▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▁▁▃▁▃▁▂▃▃▇▅▇█▇▄▇▅█▇▇▇▆▇▇███▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.3083
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.2947
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.78981
wandb:      test/avg_mil_loss 0.46247
wandb:       test/ensemble_f1 0.78981
wandb:           train/avg_f1 0.84844
wandb:      train/ensemble_f1 0.84844
wandb:         train/mil_loss 0.27725
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kcbwyz7l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162119-kcbwyz7l/logs
wandb: Agent Starting Run: x6hmx147 with config:
wandb: 	actor_learning_rate: 0.007783198851410582
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.986814565012562
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8792911723784929
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162323-x6hmx147
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x6hmx147
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▃▄▄▅▅▃▁▆▄▇▄▃▃▄▃▄▄▆▄▄▄▁▁▆▃█▆▆█▅▄▆▇▃▅▄▅█
wandb:      train/ensemble_f1 ▃▄▄▄▁▅▄▄▄▄▃▃▅▅▁▆▃▄▃▅█▃▁▆▇▃▅▆█▄▄▆▅▃▆▆▄▄▆▄
wandb:         train/mil_loss █▂▁▂▂▂▂▂▂▂█▂▂▇▂▁▁▂▇▃▂▂▂▂▃▁▂▁▂▂▁▂█▇▂▂▁▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.48589
wandb: best/eval_avg_mil_loss 2.80243
wandb:  best/eval_ensemble_f1 0.48589
wandb:            eval/avg_f1 0.48589
wandb:      eval/avg_mil_loss 2.77031
wandb:       eval/ensemble_f1 0.48589
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 3.40004
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.47941
wandb:      train/ensemble_f1 0.47941
wandb:         train/mil_loss 0.2774
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x6hmx147
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162323-x6hmx147/logs
wandb: Agent Starting Run: zxriwqpi with config:
wandb: 	actor_learning_rate: 0.0009902834521195857
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.811177895723915
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8518079976562442
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162435-zxriwqpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxriwqpi
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████▆▅▁▁▁▁▁▁▁▁▁▃▆▆██▆▅▅▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▂▃▃▃▂▂▂▂▂▁▁▄▅▅▅▇▇▇▇▇▆▆▇▇▆▆▇▇▇▇████▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██████████████▆▅▅▅▅▁▁▁▁▁▁▃▆▆▆█▆▅▅▅▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▆▄▄▅▆▅▆▄█▆▂▂▄▃▄▄▂▃▄▂▄▃▂▁▃▂▂▃▁▃▂▂▅▃▃▂
wandb:      train/ensemble_f1 ▆▅▆▆▇▅▄▅█▄▆▄▆▄▁▄▂▄▅▆▃▂▁▄▂▂▁▂▅▃▂▄▂▂▃▂▃▅▁▁
wandb:         train/mil_loss ▃▃▄▃▅▃▃▃▆█▂█▂▂▅▅▃▄▁▃▅▂▃▇▆▂▇▁▃▃▄▃▂▂▁▃▁▁▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████▁██████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64349
wandb: best/eval_avg_mil_loss 0.48712
wandb:  best/eval_ensemble_f1 0.64349
wandb:            eval/avg_f1 0.60114
wandb:      eval/avg_mil_loss 0.51094
wandb:       eval/ensemble_f1 0.60114
wandb:            test/avg_f1 0.59539
wandb:      test/avg_mil_loss 0.57372
wandb:       test/ensemble_f1 0.59539
wandb:           train/avg_f1 0.616
wandb:      train/ensemble_f1 0.616
wandb:         train/mil_loss 0.41005
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxriwqpi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162435-zxriwqpi/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iny0zee9 with config:
wandb: 	actor_learning_rate: 0.001669256669901754
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6310074887325196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8658620323605823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162558-iny0zee9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iny0zee9
wandb: uploading history steps 91-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ▁▁▁██▅▄▄▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ███▂▁▂▃▃▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▇██▅▄▄▄▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▅▇▇▇▇▅▇██▅█▇▇▅▆▆▇▇▆▅█▇▇▇▆▇▆█▇▆█▆▇██▅▆
wandb:      train/ensemble_f1 ▂▁▃▄▃█▅▅▅▄▃▄▆▆▆▆▆▄▅▄▄▅▅▃▅▃▂▆▄▅▆▃▅▆▅▄▅▆▄▅
wandb:         train/mil_loss ▆▆▃▇▅▄▅▅▆▆▄▄▃▅▆▂▅▄▅▄▆▅▃▃▄▅▇█▁▅▄▃▃▇▄▂▂▆▆▄
wandb:      train/policy_loss ▁█▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▅█▁▁▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.29648
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.29222
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.30316
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.87494
wandb:      train/ensemble_f1 0.87494
wandb:         train/mil_loss 0.30256
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iny0zee9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162558-iny0zee9/logs
wandb: Agent Starting Run: aycug7vj with config:
wandb: 	actor_learning_rate: 0.003420292729120616
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5910942775860081
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.694952499737152
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162716-aycug7vj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aycug7vj
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▅▁▁▁▁▁▁▁▁▁▃▃▃▃▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▃▃▂▂▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▃▆▆▆▆██▇▇▇▇▇▇▇▇▇▇▆▆▆▆
wandb:       eval/ensemble_f1 ████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▁▁▁▁▁▁▁▁▃▃▃▃▃▃▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▇▇█▆▆▇▆▆▆▇█▆▅█▃▇▄▃▃▁▃▂▃▄▃▂▂▄▁▃▄▅▄▄▄▃▅
wandb:      train/ensemble_f1 ▅▄▅▆▇▆▇▆█▇▇▆▅▇▅▅▅▅▇▅▄▃▄▅▃▄▂▃▃▅▄▃▁▃▅▃▄▃▁▄
wandb:         train/mil_loss ▆▆▄▄▄▄▆█▆▄▅▃▅▄▆▅▅▆▆▅▇▆▄▄▅▃▅▆▅▁▄▆▅▂▄▅▂▆▆▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▆▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 0.61192
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 0.63928
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 0.63353
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.55098
wandb:      train/ensemble_f1 0.55098
wandb:         train/mil_loss 0.4361
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aycug7vj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162716-aycug7vj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b1b04fx6 with config:
wandb: 	actor_learning_rate: 0.0017522389607077474
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7226228794411845
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8263532649982884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162857-b1b04fx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b1b04fx6
wandb: uploading history steps 92-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅███████████████████████████▅▅▅▅▅▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ▅▅▅███████████████████████████▅▅▅▅▅▅▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▇▅▇▅▄▃▅▄▆▇▅▅▅▃▃▆▆▆▅▆▅▄▃▃▆▄▅▁▅▅▅▃▂▆█▃▄▅
wandb:      train/ensemble_f1 ▃▄▂▄█▄▃▃▆▅▅▃▃▅▇▄▃▄▂▃▆▄▄▄▄▂▅▃▄▅▇▅▄▆▄▁▅▃▄▅
wandb:         train/mil_loss ▅▆▆▂▄▄▂▄█▂▄▄▃▅▄▄▂▃▄▂▃▃▄▄▃▂▂▅▃▂▃▁▄▃▃▃▃▁▄▃
wandb:      train/policy_loss ███████████████████████████████████▁████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▁▅█▄▄▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.22069
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.2268
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.21457
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.88818
wandb:      train/ensemble_f1 0.88818
wandb:         train/mil_loss 0.27435
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b1b04fx6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162857-b1b04fx6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: quipgvfs with config:
wandb: 	actor_learning_rate: 0.005912180231213989
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4447184172695018
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9940874002512318
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163023-quipgvfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quipgvfs
wandb: uploading history steps 115-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁█████████████████████████████████▃▃
wandb:      eval/avg_mil_loss ██████▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁████████████████████████████▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▂▃▂▂▂▂▂▃▅▄▄▄▄▄▄▄▅▁▄▃▅▅▄▅▅▃▃█▃▅▅▄▅▅▅▄▄▅
wandb:      train/ensemble_f1 ▃▃▃▄▂▃▃▃▃▅▄▂▄▄▄▅▃▃▄▃▄▅▃▅▁▅▄▄▃▅▄▅▅█▅▃▅▅▅▅
wandb:         train/mil_loss ▇▁█▄▅▅▃▃▄▆▄▄▄▆▄▇▆▆▄▆▅▆▂▅▆▄▃▆▃▅▄▃▆▅▅▆▂▃▄█
wandb:      train/policy_loss ▄▂▇▁▇▄▇▄▆▂▇▂▅▄▄▅▄▃▄▆▄▃▇▅▄▅▂█▅▄▅▅▄▆▅▅▃▄▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▃▁▃▂▃▃▃▇▄▃▂▅▄▃▅▃▅▅▂▇▂▃▃▃▃▅▂▅▅▆▂▂█▄▅▇▂▂▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71788
wandb: best/eval_avg_mil_loss 0.77411
wandb:  best/eval_ensemble_f1 0.71788
wandb:            eval/avg_f1 0.70877
wandb:      eval/avg_mil_loss 0.74497
wandb:       eval/ensemble_f1 0.70877
wandb:            test/avg_f1 0.63958
wandb:      test/avg_mil_loss 1.36283
wandb:       test/ensemble_f1 0.63958
wandb:           train/avg_f1 0.69414
wandb:      train/ensemble_f1 0.69414
wandb:         train/mil_loss 1.08285
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quipgvfs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163023-quipgvfs/logs
wandb: Agent Starting Run: 6s56v2fa with config:
wandb: 	actor_learning_rate: 0.008738568977499871
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11013789817737664
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.001057659707290992
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163146-6s56v2fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s56v2fa
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃▃▄▅▅▁▆▄▄▄▆▃▆▅▅▄▅▄▅▆▃█▇▆▅▅▆▄█▅▆▆▆▅▆▇▅▆
wandb:      train/ensemble_f1 ▅▅▁▃▃▆▂▄▅▃▄▅▆▃▄█▄▆▄▃▇▃▂▆▅▆▆▅▃▅▄▅▅▆▆▁▆▃▆▄
wandb:         train/mil_loss ▅▃▇█▇▅▆▆▆▅▇▇▇▅▄▅▅▆▄▃▄▅█▃▅▂▅▂▅▆▆▅▆▇▆▂▄▃▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57924
wandb: best/eval_avg_mil_loss 1.01685
wandb:  best/eval_ensemble_f1 0.57924
wandb:            eval/avg_f1 0.57924
wandb:      eval/avg_mil_loss 0.96254
wandb:       eval/ensemble_f1 0.57924
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 1.67628
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.50089
wandb:      train/ensemble_f1 0.50089
wandb:         train/mil_loss 0.91147
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s56v2fa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163146-6s56v2fa/logs
wandb: Agent Starting Run: u06e5j4x with config:
wandb: 	actor_learning_rate: 0.00793072543980573
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.012547175066813245
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5802528330262758
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163258-u06e5j4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u06e5j4x
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:       eval/ensemble_f1 ████████████▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇█████▇█▇▇█▂▁▂▂▂▁▁▂▁▁▂▂▂▁▁▁▂▂▂▁▂▂▁▂▂▁▁▁
wandb:      train/ensemble_f1 ██████▇███▃▁▂▂▂▁▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁▂▂▁▂▂▂▁▂▂
wandb:         train/mil_loss ▂▂▂▂▁▁▂▁▅▇▇▇██▇█▆█▇▇▆▇▆▇▇▇█▆▆██▇█▇▇█▇█▆▇
wandb:      train/policy_loss ██████████▁█▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████████████▁███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88865
wandb: best/eval_avg_mil_loss 0.28542
wandb:  best/eval_ensemble_f1 0.88865
wandb:            eval/avg_f1 0.46728
wandb:      eval/avg_mil_loss 1.07696
wandb:       eval/ensemble_f1 0.46728
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.39646
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.47666
wandb:      train/ensemble_f1 0.47666
wandb:         train/mil_loss 1.11418
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u06e5j4x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163258-u06e5j4x/logs
wandb: Agent Starting Run: 59zrf8fd with config:
wandb: 	actor_learning_rate: 0.009213428947827227
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7683631352460945
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.004794275750504062
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163411-59zrf8fd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/59zrf8fd
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆███▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ██████████████████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▂▅█▄▁▄▆▆▃▆▄▇▄▇▇▆▇▄▇▄▁▂▃▄▁▅▆▅▄▇▅▆▄▅▅▃▇▃
wandb:      train/ensemble_f1 ▃▄▆▂▄▅▅▃▆▃▆▇▄▂▇▅▇▄▆▆▅▂▃▃▄▅▄▄▁▄█▅▅▇▅▇▇▄▅▅
wandb:         train/mil_loss ▅▄▃▂▅▅▄▅▃▃▃▂▅▄▃█▃█▃▅▂▇▄▃▂▄▅▂▆▂▂▅▂▁▆▁▄▄▆▆
wandb:      train/policy_loss ▇▄▇▇▄▅▇▅▇▆▇█▅▃▆▅▆▄▄▁▁▁▂▄▃▄▄▂▂▃▄▁▁▄▂▃▂▁▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91971
wandb: best/eval_avg_mil_loss 0.23568
wandb:  best/eval_ensemble_f1 0.91971
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.3246
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.87981
wandb:      test/avg_mil_loss 0.37338
wandb:       test/ensemble_f1 0.87981
wandb:           train/avg_f1 0.87361
wandb:      train/ensemble_f1 0.87361
wandb:         train/mil_loss 0.34266
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/59zrf8fd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163411-59zrf8fd/logs
wandb: Agent Starting Run: nyonwwn8 with config:
wandb: 	actor_learning_rate: 0.00476484828571056
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9688256807309796
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.019669429673824346
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163523-nyonwwn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyonwwn8
wandb: uploading history steps 274-281, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇▇█
wandb: best/eval_avg_mil_loss ▆▇█▄▁
wandb:  best/eval_ensemble_f1 ▁▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▇▇▇▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ▄▄▇▇█▅▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▁▁▆▆▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▁▃▁▂▂▄▅▃▂▄▅▄▃▂▁▃▄▃▃▃▅▅▃▆▇▄▆█▅█▆▅▆▄▇▆▇
wandb:      train/ensemble_f1 ▄▃▁▁▃▃▄▄▄▄▅▂▃▄▃▃▄▃▄▄▅▇▅▇▄▆▅▆▆▆▆▇▆▅▇▆▆▆█▆
wandb:         train/mil_loss ▆▅▃█▅▅▅▃▆▂▅▃▄▃▅▅▃▃▅▂▃▃▃▃▂▄▃▂▃▃▃▂▃▅▂▁▃▁▃▅
wandb:      train/policy_loss ▁▁▁▆▂▂▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃█████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.31117
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.30402
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.30441
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.8624
wandb:      train/ensemble_f1 0.8624
wandb:         train/mil_loss 0.31467
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyonwwn8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163523-nyonwwn8/logs
wandb: Agent Starting Run: e486heze with config:
wandb: 	actor_learning_rate: 0.003999373426704963
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8144281643813827
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20293375871082384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163834-e486heze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e486heze
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▄▄▄▄▄▄▃▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▁▆▅█▂▇▄▇▃▄▄▅▆▆▄▇▃▅▃▇▃▇▃▃▂▅▁▃▅▇▇▅▇▆▃▅▂▄
wandb:      train/ensemble_f1 ▇▆▅▆▅▆▇▃▆▄▂▇▆▅▅▄▄▅▅▆▇▅▅▄▅▄▄▄▆▃▆▄▁█▆▇▆▅▆▄
wandb:         train/mil_loss ▁▃▄▃▆▃▃▃▅▅▃▄▆▄▁▄▁▃▂▃▃▃▁▃▃▁▅▁▁▃▅█▃▁▂▅▂▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.27259
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.24197
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 2.73473
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.33333
wandb:      train/ensemble_f1 0.33333
wandb:         train/mil_loss 0.59722
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e486heze
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163834-e486heze/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: otp8l0fb with config:
wandb: 	actor_learning_rate: 0.001387354424990335
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6211501353852589
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9820780438775344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163957-otp8l0fb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/otp8l0fb
wandb: uploading history steps 154-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇██▄▅▅▅▅▆▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▅█▆▄▆▆▅▃▄▄▆▅▆▆▃█▇▄▃▇▇▆▅▄▆▅█▂▅▅▇▃▄▁▂█▂▅
wandb:      train/ensemble_f1 ▅▆▆▇█▃▄▄▃▅▅▅▆█▆▇▅▄▅▆▃▅▆▆▄▂▇▄▅▄▅▇▅▁▃▁▇▁▄▃
wandb:         train/mil_loss ▅▅█▄▃▅▁▆▃▃▆▂▃▄▄▆▃▇▂▄▄▄▃▄▄▄▅▂▂▆▄▄▂▃▃▂▆▄▂▅
wandb:      train/policy_loss ▄▇▆▇▄▃▅▆▄▇▅▆▅▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.29741
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.29942
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.20197
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.87719
wandb:      train/ensemble_f1 0.87719
wandb:         train/mil_loss 0.27089
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/otp8l0fb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163957-otp8l0fb/logs
wandb: Agent Starting Run: p0jiz3qc with config:
wandb: 	actor_learning_rate: 0.0002683600308601519
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7299612782115256
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9866279741344808
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164151-p0jiz3qc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0jiz3qc
wandb: uploading history steps 174-190, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇█████
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▆▅▄▄▅▄▄▆▁▂▃▅▂█▃▄▁▄▄▇▃▁▃▃▇▃▅▄▅▄▄█▆▃▅▃▂
wandb:      train/ensemble_f1 ▃▅▃▄▆▃▄▁▅▅▇▃▅▄▂▃▄▅▅▅▆▅█▃▂▆▅▄▆▅▅▃▄▇▄▆▄▆▃▃
wandb:         train/mil_loss ▄▆▅▆▄▄▄▄▇▄█▆▅▇▃▃▃▆▂▅▄▄▃▅▃█▅▆▂▄▄▂▄▁▁▄▃▅▂▃
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃██▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.21349
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.21977
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.22682
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.88988
wandb:      train/ensemble_f1 0.88988
wandb:         train/mil_loss 0.26874
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0jiz3qc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164151-p0jiz3qc/logs
wandb: Agent Starting Run: 6qvsy7v6 with config:
wandb: 	actor_learning_rate: 0.0003323572484620349
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5381632839294025
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.93268654455498
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164410-6qvsy7v6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6qvsy7v6
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆█▇▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▄▄▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▄▃▃▅▃▇▄▆▆▆▅▅▇▅▄▃▃▃▅▅▃▅▄▁▃▇▆▅▇▇▂▄▃▅▇█▇
wandb:      train/ensemble_f1 ▄▅▄▂▅▅▄█▄▅▄█▂▇▅▄▆▇█▅▄▃▅▃▆▅▆▃▁▇▄▆█▄▅▅▃▅▄█
wandb:         train/mil_loss ▇▄▄▅▃▆▅█▄▆█▄▂▃▅▂▄▃▆▁█▅▃▄▃▃▆▄▃▂▃▃▆▅▅▄▃▆▇▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.36054
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.31515
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.73583
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.35012
wandb:      train/ensemble_f1 0.35012
wandb:         train/mil_loss 0.93118
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6qvsy7v6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164410-6qvsy7v6/logs
wandb: Agent Starting Run: uicf2fv3 with config:
wandb: 	actor_learning_rate: 0.0003214042587934376
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8193885069238991
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.985315162393479
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164528-uicf2fv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uicf2fv3
wandb: uploading history steps 181-203, summary; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅█▅▅▅▅▅▅▅█████████▅▅▅▅▅
wandb:      eval/avg_mil_loss ███▇▇▆▆▅▅▅▅▅▅▅▄▃▃▃▃▄▄▃▃▂▂▂▂▂▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▆▇▃▄▅▄▃▂▁▄▂▂▂▃▄▄▃▁▃▄▁▃▂▃▅▄▆▄▅▄▃▆▆▅█▇▇
wandb:      train/ensemble_f1 ▁▃▅▄▆▇▅▅▄▅▅▃▄▃▅▅▆▄▄▃▅▅▅▄▇▅▇▆█▄▆██▇▆▇▆█▇▅
wandb:         train/mil_loss ▃▃▃▃▅█▃▅▇▅▄▁▃▅▃▅▅▃▃▃▃▁▂▄▄▃▂▂▄▂▅▃▃▃▄▁▂▄▁▃
wandb:      train/policy_loss ▇▆▇▆▆▇█▇▆▇▇▇▇▆▃▆▁▁▃▁▇▆█▁▁▅▃▃▁██▅▅▆▇▆▄▅▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.2952
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.28695
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.33599
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.8344
wandb:      train/ensemble_f1 0.8344
wandb:         train/mil_loss 0.29655
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uicf2fv3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164528-uicf2fv3/logs
wandb: Agent Starting Run: yiblx9v6 with config:
wandb: 	actor_learning_rate: 0.0017143255919042264
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6747333468520251
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9375818930646156
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164747-yiblx9v6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yiblx9v6
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ██████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▄▆▆▄▃▃▅▅▆▅▅▃▆▅▆▆▆▄▇▃▄▃▆▄▂▄▄▆▁▇▅▄▄▅▅█▅
wandb:      train/ensemble_f1 ▃▅▃▁▆▅▃▂▅▅▅▅▄▄▅▅▄▃▃▂▃▅▁▅▃▃▅▆▆▆▅▃▃▄▆▂█▄▄▅
wandb:         train/mil_loss ▂█▄▆▃▅▄▃▄▃▁▃▄▂▅▄▃▇▇▄▁▃▅▄▅▃▅▄▅▂▃▂▃▄▅▄█▅▃▁
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▅▃▆▇█▃▅▆▂▅▁▅▅▅▄▅▅▇▆▇▅▅▅▅▅▇▇▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.20694
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.21144
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.18305
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.90807
wandb:      train/ensemble_f1 0.90807
wandb:         train/mil_loss 0.24308
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yiblx9v6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164747-yiblx9v6/logs
wandb: Agent Starting Run: unypi4wu with config:
wandb: 	actor_learning_rate: 7.196451206493649e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9480190672350808
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9160031800522022
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164900-unypi4wu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/unypi4wu
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▄▄▃▂▅▂▇▄▁▄▂▄▇▅▆▇▇▆▄██▄▇▇▆▇▅▂▆▇▆▆▅▇▇▅▅▇
wandb:      train/ensemble_f1 ▅▅▅▄▆▇▁▄▃▅▃▁▃▄▆▃▆▆▇▆▅█▇▇▅▆▇▇▆▄▆▇▇▅▅▃▅█▃▇
wandb:         train/mil_loss ▄▁▄▄▃▅█▄▂▇▂▆▄▇▄▄▃▂▃▄▅▄▄▂▄▄▄▄▆▆▃▁▁▅▂▂▆▂▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅█▅██▇███▅███▅██████▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82609
wandb: best/eval_avg_mil_loss 0.38544
wandb:  best/eval_ensemble_f1 0.82609
wandb:            eval/avg_f1 0.8164
wandb:      eval/avg_mil_loss 0.36063
wandb:       eval/ensemble_f1 0.8164
wandb:            test/avg_f1 0.75962
wandb:      test/avg_mil_loss 0.46901
wandb:       test/ensemble_f1 0.75962
wandb:           train/avg_f1 0.7862
wandb:      train/ensemble_f1 0.7862
wandb:         train/mil_loss 0.29785
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/unypi4wu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164900-unypi4wu/logs
wandb: Agent Starting Run: 18yhvpe5 with config:
wandb: 	actor_learning_rate: 0.00012636080479215878
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8479256855887782
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9789575829267952
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165012-18yhvpe5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/18yhvpe5
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▆▆▆▆▇▇▇▇█
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▅▆▄▂▂▁▄▇▁▃▅▄█▇▆▅▂▄▅▇▃▆▅▁▃▅▅▂▄▂▄▄▆█▇▇▇▇
wandb:      train/ensemble_f1 ▁▇▅▁▇▃▆▄▁▂▂▅▄▄▃▇▄▅▆█▂▇▅▃▇▅▆▃▁▄▃▅▅▆▄▇▇▆▅▄
wandb:         train/mil_loss ▂▄▄▄▄▆▂▄▃▄▄▅▇▂▃▃▅▄▆▄▄▅▄▁▅▃▄▁▃▂█▃▂▆▅▄▄▄▆▄
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.20092
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.20226
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.24368
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.91875
wandb:      train/ensemble_f1 0.91875
wandb:         train/mil_loss 0.28648
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/18yhvpe5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165012-18yhvpe5/logs
wandb: Agent Starting Run: umctjis6 with config:
wandb: 	actor_learning_rate: 1.1472105225078072e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8738245574277211
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9445846871968404
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165125-umctjis6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/umctjis6
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████
wandb:      eval/avg_mil_loss ███████▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▅▄█▆▇▄▇▆▇▅▇▄▅▃▇█▅▇▂▅▇▆▇▅▅▅▇▆▇▅▇▆▅▆█▇▅█
wandb:      train/ensemble_f1 ▅▃▄█▇▃▅▅▇▆▄▇▃▃▅▅▅▇▂▇▆▁▄▃▃▅▅▆▆▄▂▅▇▇▅▆▅▇██
wandb:         train/mil_loss ▆▂▄▄▄▂▆▃▅▇▂█▃▄▅▇▄▄▃▅▃▂▃▆▄▆▂▅▄▅▄▁▄▃▂▃▁▄▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▅█▅▅▅▅▃█▅█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁███▅▅▅▅▃██▅█▅█▅▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.22841
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.21106
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.87957
wandb:      test/avg_mil_loss 0.30042
wandb:       test/ensemble_f1 0.87957
wandb:           train/avg_f1 0.88621
wandb:      train/ensemble_f1 0.88621
wandb:         train/mil_loss 0.28213
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/umctjis6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165125-umctjis6/logs
wandb: Agent Starting Run: 6el8hi2c with config:
wandb: 	actor_learning_rate: 4.0668902677906365e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8797964708863032
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9739258227449548
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165237-6el8hi2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6el8hi2c
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅████████████████▅▅▅
wandb:      eval/avg_mil_loss ▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂██
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▅▅████████████████▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▂▆▃▆▂▁▇▂▁▃▃▅▇▅▂▁▅▆▃▄▄▄▅▆▇▇▇▂▃▆▇▇▅██▇▆▃
wandb:      train/ensemble_f1 ▂▁▄▃▄▂▃▂▄▂▂▃▃▅▅▄▄▄▅▄▆▄▄▃▃▂▄▃█▅▅▃▅▅▂▅▁▄▄▄
wandb:         train/mil_loss ▅▅█▄▆▅▃▅▆▆▃▄▃▆▆▂▄▄▃▆▇▂▄▃▂▄▁▄▂▄▆▃▄▂▄▆▄▄▄▂
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.29352
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.30222
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.31153
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.86095
wandb:      train/ensemble_f1 0.86095
wandb:         train/mil_loss 0.25786
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6el8hi2c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165237-6el8hi2c/logs
wandb: Agent Starting Run: 1kboqbts with config:
wandb: 	actor_learning_rate: 1.8415056813420355e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9532457297718852
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7506573095004587
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165452-1kboqbts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kboqbts
wandb: uploading history steps 273-282, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▅▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▃▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▃▃▃▃▃▃▃▄▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▁▁▂▄▄▃▁▅▄▄▂▄▄▅▄▅▄▆▅▅▅▅▅█▆▄▆▄▇▇▄▅▅▆▅▅█
wandb:      train/ensemble_f1 ▃▁▄▂▂▄▃▄▄▅▄▃▅▃▄▄▃▃▄▅▅▃▅▄▆▅█▅▇▅▇▇▆▇▅▇▅▇▆▇
wandb:         train/mil_loss ▆▆▇▆▇▇▄▅▆█▆▇▁▇▇▅▆▅▃▆▄▄▄▄▆▇▅▇▄▆▅▇▅▅▃▄▄▄▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▅███▇▅██▇█▅▅▂▂▂▁▁▁▁▄▁▂▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.31842
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.30994
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.81993
wandb:      test/avg_mil_loss 0.34563
wandb:       test/ensemble_f1 0.81993
wandb:           train/avg_f1 0.84976
wandb:      train/ensemble_f1 0.84976
wandb:         train/mil_loss 0.27525
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kboqbts
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165452-1kboqbts/logs
wandb: Agent Starting Run: 6enmxi8k with config:
wandb: 	actor_learning_rate: 1.142674203483274e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9760136245410264
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9993130924477852
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165803-6enmxi8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6enmxi8k
wandb: uploading history steps 253-268, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss ▆█▅▄▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▇██████████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▇▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▃▆▁▆█▄▄▄▆▃▃▄▄▄▃▃▄▄▆▅▅▆▄▆▄▅▇▄▆▃▅▅▇▇▇▆▆
wandb:      train/ensemble_f1 ▁▄▄▅▃▃▂▅▅▄▃▄█▃▄▅▃▅▅▄▅▇▅▃▃▄▂▅▂█▄▅▅▇▄▅█▄▆█
wandb:         train/mil_loss █▇█▅▅▄▆▇▇▆▄▆▇▅▆▅▄▆▅▇▄▅▃▄▆▄▅▆▇▇▅▃▃▂▅▁▆▄▄▇
wandb:      train/policy_loss ▁▁▁▂▁▃▃▃▃▃▆▆▆▆▆▁▁▁▁▃████▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▂▃▃▃▅▆▆▆▆▆▆▆▆▁▁▁▁▁▃██▁▁▁▁▁▂▂▁▁▂▁▂▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.29155
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.28127
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.31838
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.86984
wandb:      train/ensemble_f1 0.86984
wandb:         train/mil_loss 0.3052
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6enmxi8k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165803-6enmxi8k/logs
wandb: Agent Starting Run: og42n7mt with config:
wandb: 	actor_learning_rate: 0.008691025684389087
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9719291151412623
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.020458371786256757
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170104-og42n7mt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/og42n7mt
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▂▂▄▄▃▃▃▃▂▃▃▃▂▂▁▁▂▁▁███▇▇▇▇▇▆▆▆▅▅██▇▇▇▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▄▆▇▃▆█▄▇▆▃▇▆▁▃▆▄▅▄▄▅▇▅▆▅▅█▄█▃█▃▆▇▅▂▃█
wandb:      train/ensemble_f1 ▃▄▄▃▇▃▅▇▆▃▇▆▆▆▇▄▅▄▄█▅▁▆▅▄▄▄▄▄▄█▇▂▅█▇▄▄▇▇
wandb:         train/mil_loss ▂▂▇▂▂█▁▂▂▂▆▂▂▃▂▂▃▂▂▂▂▂▁▁▆▂▁██▂▂▂▂▂▂▂█▂▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.58532
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.59541
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.09374
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3448
wandb:      train/ensemble_f1 0.3448
wandb:         train/mil_loss 0.30392
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/og42n7mt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170104-og42n7mt/logs
wandb: Agent Starting Run: dxta19ma with config:
wandb: 	actor_learning_rate: 0.0013131583211264976
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8338455121678259
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8659191232495248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170221-dxta19ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxta19ma
wandb: uploading history steps 370-378, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▃▃▄▄▆▄▃▄▆▃▄▁▃▅▃▂▄▄▃▃▃▄▆▄▄▂▆▆▄█▄▂▆▄▄▅▅
wandb:      train/ensemble_f1 ▂▆▄▃▁▄▅▇▆▅▅▃▄▅▄▇▂▃▅▆▄▄▄▂▄▂▄▆▄▇█▄▆▅▆▅▂▇▇▅
wandb:         train/mil_loss ▂▅▄▂▂▆▂▄▃▂▃▃▄▅▄▃▃▁▁▃▂█▁▄▃▁▃▃▂▁▂▄▂▂▁▂▁▃▁▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▅█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▁▅▅▃▂▁▃▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57143
wandb: best/eval_avg_mil_loss 0.83027
wandb:  best/eval_ensemble_f1 0.57143
wandb:            eval/avg_f1 0.57143
wandb:      eval/avg_mil_loss 0.80609
wandb:       eval/ensemble_f1 0.57143
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 1.4655
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.42809
wandb:      train/ensemble_f1 0.42809
wandb:         train/mil_loss 0.4667
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxta19ma
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170221-dxta19ma/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1o1zr8xz with config:
wandb: 	actor_learning_rate: 0.0012570602928402984
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5425023856017694
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8583164217103842
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170655-1o1zr8xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1o1zr8xz
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▄▄▃▂▂▂▁▁▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▂▄▄▆▅▅▃▃▇▄▁▄▄▆▆▅▄▆▅▆▃▆▆▇▅▄▇▂▆▆▂▂▆▆▄█▃
wandb:      train/ensemble_f1 ▅▅▄▃▆▂▆▄▄▅▂▆▄▆▄▆▄▁▆▇▅▇▇▇▆▇▃▇▄▆▅▃▅█▅▃▂▂▁▃
wandb:         train/mil_loss █▅▃▃▂▄▁▂▃▆▄▃▁▅▂▅▅▅▅▅▄▁▃▅▃▄▁▅▂▄▃▅▄▃▅▃▆▄▅▄
wandb:      train/policy_loss ██▄▇▃█▅▅▃▂▇█▅▂▂▄▅▅▇▂▅▆█▆▅▅▃▁█▁▅▅▂▆▂▅▆█▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▄▂▃▄▁▄▂▂▁▄▁▁▄▅▅█▇▄▂▁▄▂▄▄▄▄▄▃▄▄▅▄▅▂▄▂▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52153
wandb: best/eval_avg_mil_loss 1.55199
wandb:  best/eval_ensemble_f1 0.52153
wandb:            eval/avg_f1 0.52153
wandb:      eval/avg_mil_loss 1.51947
wandb:       eval/ensemble_f1 0.52153
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 2.22446
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.42079
wandb:      train/ensemble_f1 0.42079
wandb:         train/mil_loss 1.13124
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1o1zr8xz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170655-1o1zr8xz/logs
wandb: Agent Starting Run: l96xfdnu with config:
wandb: 	actor_learning_rate: 0.0009919254462051356
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6052029753269617
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.982344895393804
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170813-l96xfdnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l96xfdnu
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 █████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▂▄▃▅▆▃▄▆▄▅▆▃▄▂▁▅▁▅▅▂▃█▆▂▁▄▆▂█▅▇▆▃█▅▇▄▆
wandb:      train/ensemble_f1 ▄▅▃▃▆▃▂▄▅▅▃▆▆▄▄▁▆▆▅▄▂▇▆▆▇▃▄▂▄▆▄▃██▅▄▄▅▄█
wandb:         train/mil_loss ▄▅▆▅▃▃▃▁▆▃▅▁▂▃▃▂▇█▃▆▂▅▅▃▂▂▆▃▃▇▅▄▄▆▄▄▃▄▅▄
wandb:      train/policy_loss ▄▄▃▂▃▂▄▅▃▄▃▄▅▃▃▁▃▁█▄▅▁▃▆▁▅▅▁▃▄▃▃▁▃▅▇▁▁▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▂▅▃▄▂▃▄▄▅▃▁▃▁██▁▅▁▄▆▅▁▃▃▅▅▁▃▃▃▁▃▅▁▁▇▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.23515
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.24325
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.92738
wandb:      test/avg_mil_loss 0.2049
wandb:       test/ensemble_f1 0.92738
wandb:           train/avg_f1 0.92215
wandb:      train/ensemble_f1 0.92215
wandb:         train/mil_loss 0.28874
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l96xfdnu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170813-l96xfdnu/logs
wandb: Agent Starting Run: 1eje33oc with config:
wandb: 	actor_learning_rate: 0.00983666967471883
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.799794434835562
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32451450460018716
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170926-1eje33oc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1eje33oc
wandb: uploading history steps 135-158, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▂▃▂▃▄▃▁▇▃▄▃▆▅▅▄▆▃▅▁▄▅▆▆▇▅▃▄▆▆▅▆▃█▆▇▄▇
wandb:      train/ensemble_f1 ▃▁▄▂▃▂▃▃▃▂▃▄▁▃▂▄▄▂▄▃▆▄▇▃▃▆▄▇█▄▆█▅▇▆▃▅▅▇▇
wandb:         train/mil_loss ▅▄█▅▆▃▄▅▆▄▆▆▄▃▆▃▃██▆▁▃▅█▂▅▄▁▄▂▃▃▆▁▁▃▁▂▂█
wandb:      train/policy_loss ███████████████▆▄▁▁▇▇▁▁▄▁▁▄▆▆▁▄▆▄▄▄▄▁▆▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▃▆▃▃▅▃▁▃▁▃▃▃▃▃▁▃▃▁▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66079
wandb: best/eval_avg_mil_loss 0.76354
wandb:  best/eval_ensemble_f1 0.66079
wandb:            eval/avg_f1 0.66079
wandb:      eval/avg_mil_loss 0.72816
wandb:       eval/ensemble_f1 0.66079
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.21918
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.54806
wandb:      train/ensemble_f1 0.54806
wandb:         train/mil_loss 0.69292
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1eje33oc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170926-1eje33oc/logs
wandb: Agent Starting Run: ri3wq1hc with config:
wandb: 	actor_learning_rate: 0.00019668970521971124
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24319514149242985
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.381319613079828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171114-ri3wq1hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ri3wq1hc
wandb: uploading history steps 159-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅██████████▅▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▂▂▂▁▁▁▃▃▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇▇▇▇▃▇▅▅▅▅██████████████▅▅▅▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▅▂▃▃▂▄▃▆▄▅▂▄█▄▅▄▂▃▅▅▅▃▅▃▄▇▇▆▄▄▂▄▆▄▄▅▄▆
wandb:      train/ensemble_f1 ▄▄▆▂▃▄▁▃▄▂▂▂▃▂▆▃▅█▃▄▃▄▂▆▄▆▆▃▅▄▄▃▄▄▄▂▃▆▃▄
wandb:         train/mil_loss ▄▆▄▅█▅▃█▇▇▂▆▆▄▆▅▅▁▄▇▅▆▅█▅▅▄▃▇▇▂▅▅█▅▄▂▆▃▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▆▇█▇▆▇▆█▇▇▆▇▅▅▁▂▄▃▄▅▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▄▄▇▆▆▇▅█▇▆▆▇▇▇█▄▂▂▁▂▁▁▂▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65212
wandb: best/eval_avg_mil_loss 1.06718
wandb:  best/eval_ensemble_f1 0.65212
wandb:            eval/avg_f1 0.62393
wandb:      eval/avg_mil_loss 1.05479
wandb:       eval/ensemble_f1 0.62393
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 1.61128
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.63146
wandb:      train/ensemble_f1 0.63146
wandb:         train/mil_loss 1.15613
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ri3wq1hc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171114-ri3wq1hc/logs
wandb: Agent Starting Run: arkxq0bk with config:
wandb: 	actor_learning_rate: 0.0003528553417041068
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5762072814984777
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.779259963927772
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171314-arkxq0bk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/arkxq0bk
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▆▂▅█▅▅▇▄▆▂█▁▃▄▄▄▄▄▅▆▄▅▄▄▄█▆▃▆▃▃▅▆▅▃▆▅
wandb:      train/ensemble_f1 ▆▇▅▁▆▅█▆▆█▄▅█▇▅▅▅▆▄▄▄▄▅▇▅▆▅▅▆▄▄▅▅▆▆▇▃▅▄▅
wandb:         train/mil_loss ▅▁▆▂▃▁▁▂▂▃▂▂▃▇▃▆▄▆█▃▄▃▅▃▂▃▂▄▆▃▆▃▁▇▁▁▁▆▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.49209
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.42103
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.83932
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33775
wandb:      train/ensemble_f1 0.33775
wandb:         train/mil_loss 0.865
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/arkxq0bk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171314-arkxq0bk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0fwt6z3l with config:
wandb: 	actor_learning_rate: 0.0005485510322997615
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.616260503403453
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7596252518281138
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171504-0fwt6z3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fwt6z3l
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▅▅▅▅▅▄████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▄▂▆▆▂▃█▃▄▅▃▅▃▃▇▅▆▃▃▂▅▆▂▁▄▄▃▅▃▅▂▃▃▃▄▃▂
wandb:      train/ensemble_f1 ▆█▄▆▅▅▅▆▇▆▅▃▁▆▄▆▃▇█▆▆▅▄▄▃▂▅▃▁▅▆▅▄▆▆▃▃▂▄▄
wandb:         train/mil_loss ▇▃▂▅▃▄█▃▄▄▃▂▅▂▂▅▁▆▄▄▅▅▆▅▂▅▄▃▄▃▅▆▆▁▄▃█▃▇▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.7987
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.76112
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.37711
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33278
wandb:      train/ensemble_f1 0.33278
wandb:         train/mil_loss 1.69802
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fwt6z3l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171504-0fwt6z3l/logs
wandb: Agent Starting Run: fx4y3jan with config:
wandb: 	actor_learning_rate: 0.0005964589768210121
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8734271894943423
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09752193384345476
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171619-fx4y3jan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fx4y3jan
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▂▂▂▂▂▁▁▃▃▂▂▂▂▁▂▇▆▆▆▆▆▅▅▄▄▇▇▆▆▆███▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▆█▅▅▇▇▅▃▄▇▄▄▅▄▄▃▅▅▆▅▃▄▇▃▃▅▁▆▅▄▄▃▆▅▇▆▇▆
wandb:      train/ensemble_f1 ▃▁█▆▆▄▇▅▃▂▃▅▃▄▃▄▅▁▃▄▂▄▅▃▃▂▂▂▆▇▅▃▃▆▆▁▇▇▇▇
wandb:         train/mil_loss ▄▁█▁▆▁▃▄▁▁▁▄▃▃▄▁▄▄▁▂▄▆▁▂▁▃▃▃▂▂▂▄▆▂▄▁▂▂▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.77742
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.79991
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.3142
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34372
wandb:      train/ensemble_f1 0.34372
wandb:         train/mil_loss 0.52353
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fx4y3jan
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171619-fx4y3jan/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rcqv02xn with config:
wandb: 	actor_learning_rate: 0.009209793064816807
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.660629386889684
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6154520184390099
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171741-rcqv02xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rcqv02xn
wandb: uploading history steps 114-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▃▃▃▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▅▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▁▆▃▄▆▅▇▄▆█▇▃▇▇▅▅▇▅▇▆▇▆▇▆▄▇▇▆▅▇▄█▆▆▅▄▃▄
wandb:      train/ensemble_f1 ▄▄▅▄▁▆▆▅▅▅▆▇▇▆▆▆▆█▇▆▆▅█▄▅▆▆▅▆▆▅▅▆▆▇▆▆▃▆▅
wandb:         train/mil_loss ▃▃▇▅▅█▅▄▅▄▃▄▇▃▆▇▆▆▄▄▂▃▇▄▄▄▄▄▅▂▂▇▃▃▄▄▅▃▁▁
wandb:      train/policy_loss ▁▃▄▂▅▆▄▄▆▄▅▂▄▇██▇▆▄▃▄▄▇▆▅▇▇▆▆▆▇▆▆▅▅▄▃▅▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.17583
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.19377
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.27829
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.90498
wandb:      train/ensemble_f1 0.90498
wandb:         train/mil_loss 0.24188
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rcqv02xn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171741-rcqv02xn/logs
wandb: Agent Starting Run: d86yml53 with config:
wandb: 	actor_learning_rate: 6.605436796731607e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7158757044652493
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5342327488440071
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171904-d86yml53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d86yml53
wandb: uploading history steps 160-167, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:      eval/avg_mil_loss ▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▁▁▁▁▂▂▂▂▂▂▂▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▅▃▃▃▆▄▂▅▃▃▇▃▂▄▄▃▄▄█▆▄▄▅▅▂▄▆▃▅▅▁▆▃▄▄▁▂
wandb:      train/ensemble_f1 █▄▇▂▆▅▆▃▃▇▁▃▅▅▅▇▆▆█▇▅▆▃▅▅▆▃▅▄▄▄▅▆▃▄▅▅▃▆▆
wandb:         train/mil_loss ▇▆▅▇▂▆▆▃▄▃▆▇▄▄▁▇▃▇▂▇▃▄▃▇▃▆▄█▃▄▃▁▅▄█▆▃▆▄▆
wandb:      train/policy_loss ▃▅▄▁▃▃▅▂▃▃▁▂█▄▃▄▄█▅▄▅█▆▅█▆▆▆▅▇▇█▇█▄▅▄▅▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▁▁▄▄▃▄▂▃▂▁▂█▁▄▄█▇▅▆▅█▇▄▇▅█▄▅█▆▄█▅█▄▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.20773
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.20326
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.27164
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.90344
wandb:      train/ensemble_f1 0.90344
wandb:         train/mil_loss 0.29478
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d86yml53
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171904-d86yml53/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 87od13vb with config:
wandb: 	actor_learning_rate: 0.0002990017544790016
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08623790434095657
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22515241985013723
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172121-87od13vb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87od13vb
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████
wandb:       eval/ensemble_f1 █████████████████████████████▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▄▄▃▅▂▂▄▅▄▅▄▄▅▃▅▃▃▁▅▃▅▅▅▄▅▂▅█▅▃▄█▄▄▇▃█
wandb:      train/ensemble_f1 ▄▁▅▄▄▄▅▃▅▃▅▆▄▆▆▅▆█▄▆▆▆█▆▅▁▆▆▇▂▆█▅▅▅▅▆█▅▆
wandb:         train/mil_loss ▅▄▁▅▄▅▅▃▃▂▆▄▆▆▄▂▃▅█▆▃▂▆▁▅▂▃▃▅▅▄▂▃▂▃▅▃▁▄▅
wandb:      train/policy_loss ▂▃▁▂▂▃▂▁▁▂▂▂▃▃▂▁▂▃▁▁▁▁▂▂▁▂▁▁▁▁█▇███████▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▁▃▁▁▂▁▂▃▂▁▂▃▁▂▁▁▂▂▂▂▂▁▁▁▁▁▂▇██▇▇█████▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.21171
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.21868
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.27458
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.91982
wandb:      train/ensemble_f1 0.91982
wandb:         train/mil_loss 0.27289
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87od13vb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172121-87od13vb/logs
wandb: Agent Starting Run: v54k5ncl with config:
wandb: 	actor_learning_rate: 0.00040422929455628305
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6732010765263314
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0904227339670146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172234-v54k5ncl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v54k5ncl
wandb: uploading history steps 180-191, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▆█
wandb: best/eval_avg_mil_loss █▆▄▄▁
wandb:  best/eval_ensemble_f1 ▁▁▄▆█
wandb:            eval/avg_f1 ▃▃▃▃▃▁▃▃▃▃▆▆▆▆▆▆▆███████████████████████
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▄▆▆▆▆▆▆█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▄▅▃▆▄▆▄▄▆▇▅▄▅▆▆▅▅▅▆▆█▆▃▆▅▇▇▅▇▅▆▆█▇▅▆▆
wandb:      train/ensemble_f1 ▂▅▅▃▄▂▆▆▁▇▅▅▆▇▄▄▅▃▆▆▆▅▅▃▆▇█▄▅▇▃▅▇▅█▇▅▂▇▆
wandb:         train/mil_loss ▇▃▆▄▄▃▄▇▃▅▃▃█▃▂▆▅▆▄▆▃▆▅▅▄▄▂▂▄▃▃▁▂▂▄▁▂▅▃▄
wandb:      train/policy_loss ▆▄▅██▇▆▅▅▅▅▅▅▅▅▃▃▁▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇█▇▆▆▆▆▆▅▇▃▅▃▃▃▅▁▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82609
wandb: best/eval_avg_mil_loss 0.3616
wandb:  best/eval_ensemble_f1 0.82609
wandb:            eval/avg_f1 0.82609
wandb:      eval/avg_mil_loss 0.33462
wandb:       eval/ensemble_f1 0.82609
wandb:            test/avg_f1 0.78981
wandb:      test/avg_mil_loss 0.43773
wandb:       test/ensemble_f1 0.78981
wandb:           train/avg_f1 0.79435
wandb:      train/ensemble_f1 0.79435
wandb:         train/mil_loss 0.32381
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v54k5ncl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172234-v54k5ncl/logs
wandb: Agent Starting Run: dt9ln0be with config:
wandb: 	actor_learning_rate: 0.0021496337375112554
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.587287895035739
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23824912918261876
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172449-dt9ln0be
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dt9ln0be
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▄▄▄▃▃▃▂▁███▇▆▆▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▇▇▅▄▇▄▄▅▃▅▅▆▄█▃▅█▅▅▅▁▆▃▄▆▃▆▃▅▅▅▁▅▃▁▅▄
wandb:      train/ensemble_f1 ▆█▄▆▃▇▄▅▅▅▇▅▆▇▆▅▆▅▅▅▅▆▂▃▄▅▅▄▆▅▁▅▆▆▆▁▅▆▆▄
wandb:         train/mil_loss ▃▅▇▄▄▆▃█▅▆▃▃█▁▃▆▁▅▇▆▆▆▃▄▃▄▄▆▄▆▅▃▅▃▃▁▆▁▇▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.96789
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.94556
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.60589
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3283
wandb:      train/ensemble_f1 0.3283
wandb:         train/mil_loss 0.94234
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dt9ln0be
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172449-dt9ln0be/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0szvsqmw with config:
wandb: 	actor_learning_rate: 1.9976251491332252e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9612999245805102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9501164113363976
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172643-0szvsqmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0szvsqmw
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▂▄▃▆▆▂▃▃▁▅█▃▄▄▂▆▅▇▆▅▃▃▅▆▄▅▅▆▅▄▆▇▃▅▆▁▃▃
wandb:      train/ensemble_f1 ▆▅▄▆▄▆▆▃▆▂▂▇▆█▅▂▃▃▃▄▇▅▅▁▄▄▅▄▄▄▅▆▆▆▃▁▇▇▇▆
wandb:         train/mil_loss ▅▅▇▇▃▆▃▂▅▃▅▃▄▄▅▃▆▆▆▄▃█▃▃▁▄▃▇▆▄▂█▃▃▃▂▆▇▄▅
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▅█▄████▅▄▂▄▄▄▄▂▄▄▄▂▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▁▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.18334
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.18427
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.28257
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.88122
wandb:      train/ensemble_f1 0.88122
wandb:         train/mil_loss 0.30321
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0szvsqmw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172643-0szvsqmw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g4gsrdfd with config:
wandb: 	actor_learning_rate: 0.001801674859435536
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03723655337108078
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5405411325400942
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172826-g4gsrdfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g4gsrdfd
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▂▄▄▅▅▅▅█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▆▆▆▇█▆▄▆▇▅▆▅▄▆▆▅▅▅▆▇▅▄▆▅▇▅▂▅▅▅▅▅▁▃▇▅▆
wandb:      train/ensemble_f1 ▃▅▄▅▄▄▃▄▃▄▁▃▃▃▂▃▃▃▄▆▅▆▄▆▃▃▆▅▄▃▇▃▄▃▄▃█▄▂▄
wandb:         train/mil_loss ▃▆▇▆▆▆▅▇▇▆▃▅▆▆▆▁▅▇▅▅▃▃▆▇█▆▆▄▅▇▆▄▇▆▅▇▅▂▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.19621
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.26597
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.51886
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33333
wandb:      train/ensemble_f1 0.33333
wandb:         train/mil_loss 2.33611
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g4gsrdfd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172826-g4gsrdfd/logs
wandb: Agent Starting Run: y6euxddh with config:
wandb: 	actor_learning_rate: 0.009847252768862046
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9557449762770466
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4830955854445209
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172942-y6euxddh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6euxddh
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████████▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████████████████████████▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▄▂▅▃▃▇▃▁▃▃▄▄▄▅▆▄▇▂▁▂▃▅▄▅▄▅▂▄▄▃▅▆▄▅▆▆█
wandb:      train/ensemble_f1 ▄▄▅▄▂▄▁▄▃▄▅▄▃▆█▆▄▃▇▇▂▆▅▇▆▆▄▅▆▄▂▃▅▅▅▅▆▆▅▄
wandb:         train/mil_loss █▅▅▂▄▅▄▅▃▄▆▂▄▂▄▂▅▄▄▅▅▃▄▃▄▃▃▃▃▂▄▂▄▁▅▁▅▃▅▄
wandb:      train/policy_loss ███████████████████████████████▁████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▅████▇█▅██▅▅███████████████▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.19795
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.92
wandb:      eval/avg_mil_loss 0.19657
wandb:       eval/ensemble_f1 0.92
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.29549
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.85872
wandb:      train/ensemble_f1 0.85872
wandb:         train/mil_loss 0.31308
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6euxddh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172942-y6euxddh/logs
wandb: Agent Starting Run: dk66tw5r with config:
wandb: 	actor_learning_rate: 0.00992685705406117
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6707368986160371
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6634978994994482
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173059-dk66tw5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dk66tw5r
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████████████▁▁▁▁▁▁▁█
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▂▂▂▂▁▃▃
wandb:       eval/ensemble_f1 ██████████████████████████████████▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▅▃▂▇▁▄▆▄▅▆▃▁▄▅▄▆▄▂▆▃▆▆▂▂▁▄▅▅▆▄█▂▃▃▅▂▇
wandb:      train/ensemble_f1 ▆▅▄▃▇▃▇▆▄▅▇▃▄▂▃▁▄▄▅▄▃▇▄█▆▄▄▃▆█▅▅▅▅█▃▇▁▃▄
wandb:         train/mil_loss ▄▃▅▄▇▅▄▆▄▇▆▇▃▃▄▆▅▄▄▄██▃▄▄▂▃▁▃▅▆▄▂▄▃▃▅▃▁▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55524
wandb: best/eval_avg_mil_loss 1.07747
wandb:  best/eval_ensemble_f1 0.55524
wandb:            eval/avg_f1 0.55524
wandb:      eval/avg_mil_loss 1.04059
wandb:       eval/ensemble_f1 0.55524
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 1.40969
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.49777
wandb:      train/ensemble_f1 0.49777
wandb:         train/mil_loss 0.82199
wandb:      train/policy_loss 0.35481
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.35481
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dk66tw5r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173059-dk66tw5r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bxi869qb with config:
wandb: 	actor_learning_rate: 9.95989243448871e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39918303903613894
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6515960541765543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173231-bxi869qb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bxi869qb
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ██████████████████████████████▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▅▆▄▅▇▅▅▅▄▅▄▆▄▄▄▅▅▅▃▆█▄▆▆▄▁▅▄▅▃▅▅▄▅▆▅▅▃
wandb:      train/ensemble_f1 ▄▇▃▁▃▄▂▃▇▄▃▅▃▇▃▂█▃▅▅▅▇▄▅▂▅▂▂▁▄▄█▆▅▆▅▆▃▃▄
wandb:         train/mil_loss ▇▆▆▆▄▄▂▆▂▅▄▅▄▆▂▆▄▆▇▄▄▂▅▅▄▂▃▄▃▇▂▅▄▃█▃▁▄█▆
wandb:      train/policy_loss ▅▅▇▇▅▅▇▅▅▆▄▅▇█▆▅▄▅▆▆▅▆▂▇▃▄▂█▇▆▂▂▂▁▂▂▁▂▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▄▆▅▆█▅▅▅▇▅▇▅▅▅▅▄▇▃▇▄█▄▅▇█▅▃▄▇▁▂▄▂▁▃▁▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.26397
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.26768
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.92792
wandb:      test/avg_mil_loss 0.19221
wandb:       test/ensemble_f1 0.92792
wandb:           train/avg_f1 0.88867
wandb:      train/ensemble_f1 0.88867
wandb:         train/mil_loss 0.24145
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bxi869qb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173231-bxi869qb/logs
wandb: Agent Starting Run: 7k9p3yml with config:
wandb: 	actor_learning_rate: 4.064830566622522e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3047699864716421
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5722469314422616
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173345-7k9p3yml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7k9p3yml
wandb: uploading history steps 138-150, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅████████████████████████████
wandb:      eval/avg_mil_loss █▇▆▆▆▅▅▄▄▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▅▆▅▁▆▄▆▅▅▅▇▃▄▄▃▆▆▅▄▇▃▇██▆▆█▆▇▅▇▆▄▅▆▇▃
wandb:      train/ensemble_f1 ▂▃▂▅▂▇▁▅▃▄▅▃▄▂▂▅▂▅▅▃▆▁▆▇▆▇▄▅▄▆▄█▃▄▄▄▅▃▆▆
wandb:         train/mil_loss ▃█▅▄▇▂▂▄▆▂▅▃▄▂█▃█▆▁▃▃▅▄▄▄▃▆▁▄▄▃▄▅▂▄▄▂▇█▂
wandb:      train/policy_loss ▆▃▆▆▁▆▄▆▆▆██▅▁▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.25385
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.25419
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.23212
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.86243
wandb:      train/ensemble_f1 0.86243
wandb:         train/mil_loss 0.25852
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7k9p3yml
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173345-7k9p3yml/logs
wandb: Agent Starting Run: epbf2uhx with config:
wandb: 	actor_learning_rate: 1.133229533108596e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9761896450420128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7781761434806328
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173527-epbf2uhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/epbf2uhx
wandb: uploading history steps 160-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss ▃▃▃▃▃▂▂▂▁▅▅▅▄▄▄▄▄▄▅▅▅▅▄▄▄▄▃▅▅▅▅▄▅▅▄████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▅▄▃▃▆▅▅▆▃▄▃▃▅▄▄▅▅▄▇▃▅▅▄▆▅▄▅▆▅█▆▄▅▅▇▇▆
wandb:      train/ensemble_f1 ▄▅▆▂▂▄▅▅▄▄▄▆▃▅▁▄▅▄▆▄▆▂▃▅▄▄▄█▄▄▄▃▆█▅▅█▆▄▃
wandb:         train/mil_loss ▂█▃▃▅▃▂▂▃▄▂▃▃▃▃▃▂▅▃▇▃▇▂▂▂▂▃▇▃▃▃▆▂▂▂▃▁▂█▂
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████▃████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40782
wandb: best/eval_avg_mil_loss 1.12399
wandb:  best/eval_ensemble_f1 0.40782
wandb:            eval/avg_f1 0.40782
wandb:      eval/avg_mil_loss 1.14615
wandb:       eval/ensemble_f1 0.40782
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 1.26044
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.43826
wandb:      train/ensemble_f1 0.43826
wandb:         train/mil_loss 0.27089
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/epbf2uhx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173527-epbf2uhx/logs
wandb: Agent Starting Run: cz452q2m with config:
wandb: 	actor_learning_rate: 0.0025696645762073337
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2651058555436595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7346830041377418
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173726-cz452q2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cz452q2m
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇███▇▇▇▇▇▆▆▆▆▆▄▄▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▆▅▇▁▅▄▂▄▄▅▂▃█▃▃▃▃▅▅█▅▄▅▄▄▄▇▅▃▅▇▆▁▄▅█▅
wandb:      train/ensemble_f1 ▃▃▆▅▃▄▇▄▄▅▅▃▇▃▄▅▂▃█▃▆▂▂▄▁▂▅▄▃▂▃▇▄▅▃▅▅▃▆▅
wandb:         train/mil_loss ▆▅▄▃▄▄▁▆▇▂▅▆▆▇▆▄▇█▅▅▂▄▇▅▆▂▆▄▃▄▆▇▄▇▃▂▆▆▅█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.05642
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.00261
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.60708
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33665
wandb:      train/ensemble_f1 0.33665
wandb:         train/mil_loss 3.22216
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cz452q2m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173726-cz452q2m/logs
wandb: Agent Starting Run: qphx5f5b with config:
wandb: 	actor_learning_rate: 0.0016827938606918723
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2762237917954522
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25168768945813447
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173839-qphx5f5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qphx5f5b
wandb: uploading history steps 115-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂██
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▂██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▆▆▆▅▆▆▆▆▆▆▆▆▆██████▆▆▆▆▆▆▆▆▆▆▆▆▅▅▃
wandb:      eval/avg_mil_loss ████▇▃▃▂▁▂▅▄▄▅▅▄▅▅▅▅▅▅▅▄▄▄▄▃▄▄▄▄▄▄▅▇▇▇▇▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▇██▅▅▄▄▄▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇███▅▅▄▄▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▂▅▄▇▆▄▆▄█▃▄▃▃▃▄▃▃▁▂▄▄▃▃▄▃▄▁▁▃▂▄▄▅▂▂▅▄▁
wandb:      train/ensemble_f1 ▃▅▄▇▂▄▅▄▇▇▄█▃▃▄▂▃▁▁▃▃▁▅▃▂▃▄▂▄▄▅▁▇▁▄▃▃▂▄▄
wandb:         train/mil_loss ▂▅▆▃▅▆▅▂▃▃▄▇▅▂▆█▆▆▄▅▄▄▆▇▅▅▇▄▄▅▅▆▅▃▇▃▁▇▅▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82916
wandb: best/eval_avg_mil_loss 0.36781
wandb:  best/eval_ensemble_f1 0.82916
wandb:            eval/avg_f1 0.78829
wandb:      eval/avg_mil_loss 0.40596
wandb:       eval/ensemble_f1 0.78829
wandb:            test/avg_f1 0.85978
wandb:      test/avg_mil_loss 0.36428
wandb:       test/ensemble_f1 0.85978
wandb:           train/avg_f1 0.7837
wandb:      train/ensemble_f1 0.7837
wandb:         train/mil_loss 0.30155
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earnest-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qphx5f5b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173839-qphx5f5b/logs
wandb: Agent Starting Run: pp9hhpmy with config:
wandb: 	actor_learning_rate: 7.273222503621471e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9788490248226012
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7400356321682926
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174007-pp9hhpmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7qnfa19h
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pp9hhpmy
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▆▅▄▄▄▆▆▆▅▅▅▅▅▅▄▄▃▃▂▂▁▁▃▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▆▃▄▄▅▃▇▆▅▆▁▅▄▃▁▃▅▇▄▂█▅▄▆▆▆▃▃▃▅▄▅▄▅▄▅▄
wandb:      train/ensemble_f1 ▄▅▇▄▃▅▇▄▆▄▆▅▆█▄▃▄▁▄█▆▅▃▁▇▆▆▂▃▅▁▇▅▅▅▆▆▆▄▄
wandb:         train/mil_loss ▂▁▂▂▂▁▂▂▁▁▂▂▁▂▂▂▁▂▂▂▂▃▂▁▂▂▂▇▂▁█▂▂▂▇▁▁▂▂█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.81906
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.79062
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.34554
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3311
wandb:      train/ensemble_f1 0.3311
wandb:         train/mil_loss 0.31533
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pp9hhpmy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174007-pp9hhpmy/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: h86p1n19 with config:
wandb: 	actor_learning_rate: 0.00040369910583385593
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6909826454369435
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5337402425979482
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174149-h86p1n19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h86p1n19
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▃▃▃▃▃▃▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▄▆▆▇██████▇▆▅▅▅▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 █▆▃▃▃▃▃▃▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▃▆▅▆▄▅▄▄▄▂▄▄▆▆▅▄▄▅▄▅▆▃▂█▄▃▄▅▄▃▅▅▃▁▃▂▂
wandb:      train/ensemble_f1 ▃▂▂▃▄▄▃▆▅█▆▂▆▅▆▇▅▆▂▆▄▅▃▆▄▆▃▂▃█▅▅▄▃▁▃▄▅▂▄
wandb:         train/mil_loss ▅▇▄█▃▆▅▅▅▅▄▃▃▇▂▂▁▇▄▂▄▄▃▇▁▅▅▅▃▄▅▆▂▅▇▅▄▆▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.21269
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.23689
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.26249
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.91358
wandb:      train/ensemble_f1 0.91358
wandb:         train/mil_loss 0.30152
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h86p1n19
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174149-h86p1n19/logs
wandb: Agent Starting Run: gr5gp3ya with config:
wandb: 	actor_learning_rate: 0.00041871391165530856
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7659059801667516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9565064206362848
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174306-gr5gp3ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gr5gp3ya
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▂▄▅▄▃▅▃▄▁▂▇▄▆▆▃█▃▆▄▃▅▅▆▃▇▃▄█▅▆▇▅█▃▂▂▁
wandb:      train/ensemble_f1 ▃▄▇▅▅█▆▄▃▃▁▄▃▄▄▆▄▂▃▄▆▆▅▁▁▄▂▆▃▃▅▆▅▅▄▄▅▃▂▃
wandb:         train/mil_loss ▂▆▄▃▅▃▃▆▄▃▄▄▁▄▄▃▅▅▅▄▅▃▃▅▅▅▂▂▅▇▄▇▆▂▆▆█▇▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.3372
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.35405
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.19293
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.86478
wandb:      train/ensemble_f1 0.86478
wandb:         train/mil_loss 0.31071
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gr5gp3ya
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174306-gr5gp3ya/logs
wandb: Agent Starting Run: 1xk1hobe with config:
wandb: 	actor_learning_rate: 0.0007661882651119618
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.011951431649357304
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9448561256918044
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174424-1xk1hobe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1xk1hobe
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████████▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▇▇▇▇▇▇▇███████████████████████████▁▁▁
wandb:       eval/ensemble_f1 ████████████████████████████████▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▄▁▆▃▃▅▅▆▅▆█▇▄▅▅▅▄▃▁▇▄▄▆▅▇▃▇▄▅▄▃▄▃▅▅▇▅▇
wandb:      train/ensemble_f1 ▇▃▄▅▆▄▅▆▆▆▆█▄▁▂▂▆▅▅▃▄▅▅▄▄▄▄▅▆▄▄▄▅▇▄▆▃▄▄▃
wandb:         train/mil_loss ▃▃▄▆▄▆▆▄▇▃▂▄█▃▆▇▁▇▅▄▅▄▅█▇▄▅▅▂▃▃▅▇▇▅▅▆▃▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆██████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.31401
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.30314
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.18915
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.91709
wandb:      train/ensemble_f1 0.91709
wandb:         train/mil_loss 0.26083
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1xk1hobe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174424-1xk1hobe/logs
wandb: Agent Starting Run: p8cfxmko with config:
wandb: 	actor_learning_rate: 2.8420762318730516e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7130227615305709
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28447464875633466
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174537-p8cfxmko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p8cfxmko
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇█████████
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▆▄▄▅▃▄▃▂▄▃▂▃▂▆█▄▂▃▂▇▃▂▆▁▃▄▂▂▂▆▁▆▃▆▁▄▄▃
wandb:      train/ensemble_f1 ▄█▃▅▅▄▃▆▅▅█▃▅▄▆▇▃▁▇▄▅▄▂▅▇▄▄██▇▆▃▆▃▃█▂▅▅▅
wandb:         train/mil_loss ▄▅▄▅▅▅██▇▂▇▇▇▅▆▇▅▇▆▄▇▇▆▃▄▄▅▄▁▃▁▃▅▅▆▃▅▄▃▃
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▅▅██▆█▄▅▅▆▅▆▄▅▆▆▄▁▆▄▄▆▆▃▁▃▅█▃█▃▆▆▅▆▃▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.36432
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.37516
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.91511
wandb:      test/avg_mil_loss 0.20667
wandb:       test/ensemble_f1 0.91511
wandb:           train/avg_f1 0.85944
wandb:      train/ensemble_f1 0.85944
wandb:         train/mil_loss 0.36073
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p8cfxmko
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174537-p8cfxmko/logs
wandb: Agent Starting Run: 8wwmx79b with config:
wandb: 	actor_learning_rate: 0.0005796767281288081
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.43208274941351343
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6248625582839932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174655-8wwmx79b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8wwmx79b
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▅▅▄▄▄▄▃▃▃▄▃▃▃▄▄▄▄▄▄▄▃▃▃▂▂▁▁▁▂▂▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▃▄▃▅▇▅▅▆▃▃▅▅▆▃▂▃▂▅▂▃▄▃▅█▆▅▇▃▄▄▂▂▄▇▅▃▃
wandb:      train/ensemble_f1 ▄▃▂▄▁▄▆▅▅▅▅▇▅▃▂▃▅▁▂▄▂▅▅▃▃█▆▅▄▃▂▅▄▅▄▅▇▄▃▂
wandb:         train/mil_loss ▂▂▆▄▄▃▄▃▂▂▅▃▃▃▆▇▅▂▄▆█▅▃▁▃▃▅█▇▂▃▃▄▃▃▅▁▇▂▄
wandb:      train/policy_loss █▅█▂▂▅▅█▅▃▅▅▄▅█▁▄▄▆▁▄▄▄▅▇▄▃▃▄▂▄▅▅▅▅▄▄▄▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▂▄▇▅█▅▃█▇▅█▂▄▄▁▄▄▄▃▅▅▅▅▇▇▅▅▃▅▅▄▄▄▄▄▄▇▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.29332
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.29086
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19968
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.8986
wandb:      train/ensemble_f1 0.8986
wandb:         train/mil_loss 0.30422
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8wwmx79b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174655-8wwmx79b/logs
wandb: Agent Starting Run: rny2n5lt with config:
wandb: 	actor_learning_rate: 0.0003873140769569867
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6489818750058501
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5262146137136814
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174813-rny2n5lt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rny2n5lt
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▅▅▆▆▆▆▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄█▄▄▃▃█▇▄▄▂▄▂▃▇▃▃▇▅▁▆▄▆▂▇▄▂▄▃▄▄▅█▂▅▆▇▆
wandb:      train/ensemble_f1 ▆▂▄▂▃▆▃▄▃▂▄▂▇▆▃▅▃▅▆▁▅▃▅▄▃▄▂▁█▄▃▄▄▂▇▂▄▃▅▁
wandb:         train/mil_loss ▂▃▄▂▆▆▃▄▃▃▅▃▄▄█▆▄▅▄▅▃▅▃▃▂▄▄▁▂▄▃▂▃▅▅▄▄▃▂▆
wandb:      train/policy_loss █▆▅█▆▁▆█▅▆▁▆▁▆▃▅▆▃▁▁▅▆▃▃▃▃▅▃▆▁▅▃▆▆█▄▆▁▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▄▄▄▆█▄▄▇▇▇▁▄▇▂▆█▄▅▄▇▂▂▆▅▄▄▄▅▄▂▄▇▅█▅▅▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.31686
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.32387
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.21014
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.86048
wandb:      train/ensemble_f1 0.86048
wandb:         train/mil_loss 0.31054
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rny2n5lt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174813-rny2n5lt/logs
wandb: Agent Starting Run: 872m0k5h with config:
wandb: 	actor_learning_rate: 0.005902636378221037
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3533397938919718
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4500739253407387
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174930-872m0k5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/872m0k5h
wandb: uploading history steps 172-191, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆▇▇██
wandb: best/eval_avg_mil_loss ▅█▃▂▁▂▁▁
wandb:  best/eval_ensemble_f1 ▁▅▅▆▇▇██
wandb:            eval/avg_f1 ▁▆▇▇████████████████████████████████████
wandb:      eval/avg_mil_loss ███▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▅▇██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▃▆▇▆▇▇▇▆█▇▇▇█▇▇▆▇▇▇█▇▇▇▇▇▇█████▇██▇█
wandb:      train/ensemble_f1 ▂▁▁▂▄▆▆▇▆▆▆▆▇▆▆▆▆▇▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▅▇▇▇▇█▇
wandb:         train/mil_loss ▄▇█▄▇▄▃▄▄▂▂▄▄▃▅▄▃▄▃▃▆▃▄▂▃▃▁▃▁▃▄▃▄▃▂▃▃▄▄▃
wandb:      train/policy_loss ▄▄█▃█▅▅▅▅▅▅▅▅▅▅▅▂▃▃▃▂▂▃▁▄▃▄▂▅▄▂▃▃▂▂▂▅▂▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62637
wandb: best/eval_avg_mil_loss 2.08353
wandb:  best/eval_ensemble_f1 0.62637
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 2.05602
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.42625
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.63141
wandb:      train/ensemble_f1 0.63141
wandb:         train/mil_loss 2.07342
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/872m0k5h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174930-872m0k5h/logs
wandb: Agent Starting Run: 9bnls00c with config:
wandb: 	actor_learning_rate: 0.00013669022959855303
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4457861867496201
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7268470213443864
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175149-9bnls00c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bnls00c
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▇▃▅▅▂▃▃▆▄▅▇█▇█▁▆▄▁▅▆▄▃▃▅▆▄▅▂▆█▅▇▅█▄▆▃▅
wandb:      train/ensemble_f1 ▂▄▄▅█▂▄▅▄▆▄▄▅▃▅▄▆▆▁▄▄▅█▄▄▆▂▄▃▆▄▆▄▂▆▄▅▄▄▃
wandb:         train/mil_loss ▄▄▃▁▅▆▅▆▄▄▄▄▅▃▅▅▄█▃▅▃▄▇▅▄▆▄▃▅▆▇▄▆▄▃▅▂▅▅▄
wandb:      train/policy_loss ▅▄▄▄▄▇▄▆▄▂▂▆█▄▅▂▆▇▅▆▄█▄▅▇▆▆▇▇▂▄▁▅▄▄▅▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▇▄▄▇▄▆▆█▅▄▄▄▄▄█▄█▇▆▆▄▇▆▁▇▇▄▄▂▅▇▅▅▅▄▆▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.31205
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.30751
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.19466
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.86613
wandb:      train/ensemble_f1 0.86613
wandb:         train/mil_loss 0.3062
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bnls00c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175149-9bnls00c/logs
wandb: Agent Starting Run: 49aqcy2b with config:
wandb: 	actor_learning_rate: 0.00014762771123351745
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.826509992781232
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6637948182164933
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175307-49aqcy2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49aqcy2b
wandb: uploading history steps 196-213, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▅▅▅▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▅▅▃▁▁▅▄▆▄▅▄▆▄▄▅▄▃▄▅█▃▅▆▆▅▆▆▃▄▇▅▅▄▆▅▆▄▄
wandb:      train/ensemble_f1 ▄▅▄▃▃▅▆▄▄▄▁▆▅▅▆▁▄▃▃▃▅▆▇▅▄▇▅▃▆▃▆▅▄█▅▅█▄▇▃
wandb:         train/mil_loss ▁▂▂▃▅▂▁▃▃▂▄▂▃▄▂▁█▁▂▂▁▅▂▃▅▄▂▁▄▃▄▄▃▃▄▁▃▁▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 1.24313
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 1.2049
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.625
wandb:      test/avg_mil_loss 1.20333
wandb:       test/ensemble_f1 0.625
wandb:           train/avg_f1 0.68094
wandb:      train/ensemble_f1 0.68094
wandb:         train/mil_loss 0.26144
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49aqcy2b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175307-49aqcy2b/logs
wandb: Agent Starting Run: 8gevwfh4 with config:
wandb: 	actor_learning_rate: 0.0004082135207510656
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5266289089434362
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7728990145742016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175542-8gevwfh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8gevwfh4
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▆▇▇▆▆▅▆▆▆▆▆▆▆▆▅▆▆▆▇▇▅▃▂▂▁▁▁▁▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▅▆▅▅▆▅▆▅▅▆▅▇▅▆▇▆▅▃▄█▄▅▆▆▅▅▇▃▅▁▅▅▅▇▆▅▅
wandb:      train/ensemble_f1 ▅▄▆▇▂▅▅▇▄▆▅▃█▄▇▇▅▅▂▃▃▅▅▆▄▄▇▄▅█▃▁▄▆▆▇▇▆▄▅
wandb:         train/mil_loss ▂▇▄▂▃▆▅▃▂▆▄▅▃▄▅▇▄▇▁▆▅▅██▃▆▅▆▂█▆▂▆▄▄▅▅▂▅▄
wandb:      train/policy_loss ▅▄▂▅▃▁█▅▆▃▅▄▃▅▄▇▂▅▄█▄▄▅▆▄█▂▂▄▇▁▆▆▆█▇█▄▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▄▄██▆▄▃▆▃▅█▄▃▄▄▅▂▃▄▇▅▃▄▄▇▇▁▆▆▆█▅▅▆▅▄▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.32553
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.32398
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.20014
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.87031
wandb:      train/ensemble_f1 0.87031
wandb:         train/mil_loss 0.29853
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8gevwfh4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175542-8gevwfh4/logs
wandb: Agent Starting Run: imgltw32 with config:
wandb: 	actor_learning_rate: 0.00029892161014859745
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23532187786200587
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.838569040631446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175700-imgltw32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/imgltw32
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▃█▃▂▃▆▄▃▄▃▅▆▂▅▇▃▇▂▅▄▅▄▄▃▃▄▃▆▅▄▆▅▁▃▄▅▆
wandb:      train/ensemble_f1 ▃▄▄▂▃▃▆▃▄▃▅▃▄▂▆▄▃▂▃█▄▂▅▅▄▄▂▅▄▆▄▅▁▃▃▅▆▅▄▆
wandb:         train/mil_loss ▄▇▆▆▆▅█▁▄▃▆█▄▃▄▅▆▆▅▅▄▄▄▆▄▄▄▆▅▃▆▄▃▆▄▄▅▆▇▄
wandb:      train/policy_loss ██▃▃█▅▆▇▆▆▆▃▆█▆███▆▃▁▃▆▃▃▃▃▆██▆▆▆▃▃▃▃▃▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▃▄▇▆▆▁█▄▄▅▄▆█▆▆█▅▆█▃▄▄▂▆▄▃▆▄█▃▅▆▄▆▄▂▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.24702
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.24162
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.22164
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.90853
wandb:      train/ensemble_f1 0.90853
wandb:         train/mil_loss 0.27914
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/imgltw32
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175700-imgltw32/logs
wandb: Agent Starting Run: o128qi8e with config:
wandb: 	actor_learning_rate: 0.0003219510046790115
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3563579817889053
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7444678302143853
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175817-o128qi8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o128qi8e
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄█▅▂▁▆▄▃▃▆▆▇▅▄▆▄▇▄▇█▂▅▃▄▃▅▄▄▄▂▅▃▄▂▃▅▇▁
wandb:      train/ensemble_f1 █▅▅▅▄▄▆▆▄▃▄▄▇▆▇▆▆▅▇▅▅▇█▇▆▆▇▅▁▅▅▅▅▅█▅▄▄▆▄
wandb:         train/mil_loss ▅▄▃▂▅▃▄▆▆▃▄▄▅▃▄▇▆█▆▁▄▃▄▅▃▃▃▄▂▂▃▃▂▆▃▅▄▄▅▃
wandb:      train/policy_loss ▅▅▆▃▄▇▇▁▄█▆▂▁▄▃▆▅▅▄▇▆▅▅▅▄▅▄▄▁▄▄▆▃▇▆▂▃▅▄▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅▆▆▃▁▆▃█▇▂▄▅▂▃▇▆▅▄▅▄█▆▄▄▂▅▁▄▄▄▂▄▆▆▆▆▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.38114
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.37231
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.9375
wandb:      test/avg_mil_loss 0.15685
wandb:       test/ensemble_f1 0.9375
wandb:           train/avg_f1 0.89595
wandb:      train/ensemble_f1 0.89595
wandb:         train/mil_loss 0.30866
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o128qi8e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175817-o128qi8e/logs
wandb: Agent Starting Run: 2sjxqbs4 with config:
wandb: 	actor_learning_rate: 0.00010523241520742286
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13160401606080452
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.934267765176411
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175935-2sjxqbs4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sjxqbs4
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▆▄▄▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▁▂▄▇▇█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▅▄▄▄
wandb:       eval/ensemble_f1 █▆▄▄▄▄▄▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▂▁▁▂▂▁▁▁▂▂▂▂▂▂▂▂▃▂▂▂▂▃▁▂▃▂▃▃▃▃▄▃▂▃▄▃▄▃
wandb:      train/ensemble_f1 █▄▃▂▂▂▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▃▃▃▂▃▃▃▃▃▂▃▄▃▄▃▃
wandb:         train/mil_loss ▁▃▅▄█▄▆▇█▅▅▇▅▇▇▆▇▅▆▅▆▄▇▆▆▄▄▄▅▆▆▅▄▄▁▇▆▂▆▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇████████▇████████████▁█████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51645
wandb: best/eval_avg_mil_loss 0.61752
wandb:  best/eval_ensemble_f1 0.51645
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.6926
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 0.65944
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.44705
wandb:      train/ensemble_f1 0.44705
wandb:         train/mil_loss 0.59988
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sjxqbs4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175935-2sjxqbs4/logs
wandb: Agent Starting Run: 7dtrewfp with config:
wandb: 	actor_learning_rate: 0.0008601499619453235
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2292972492043125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9344776533791724
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180052-7dtrewfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7dtrewfp
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▅▅▅▅▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▆▆▄▃▃▁▆▄▅▇▆█▅▃▃▄▆▃▄▅▃▁▂▂▅▄▅▂▆█▃▃▅▄▃▆▆
wandb:      train/ensemble_f1 ▅▆▇▄▅▅▇▅▅█▅▄▄▆█▆▄▁▅▇▆▆▅▆▅▆▅▄▅█▆▆▅▄▄▅▄▅▇▆
wandb:         train/mil_loss ▆█▇▁▆▇▇▇█▇▆▂▄▃▆▇▅▅▅▄▆▅▃▆▃▄▆▆▆▂▇▅▆▅▃▄▅▆▇▅
wandb:      train/policy_loss ▅█▅▃▃▅▆▃▃▅▇▁▅▆▃▄▃█▃▃▅▆▆▁▃▅▃▃▃▅▃▅▁▆▆▄▃▁▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▅▅▄▃▆▅▇▃▁▅▃▁▅▃▃▆▁▇▃▇▃▃▃▃▃▆▅▃▅▃▁▅▃▅▃▃▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.31892
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.31713
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.17303
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.89576
wandb:      train/ensemble_f1 0.89576
wandb:         train/mil_loss 0.29022
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7dtrewfp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180052-7dtrewfp/logs
wandb: Agent Starting Run: dom4gfq6 with config:
wandb: 	actor_learning_rate: 0.0006381183273873633
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7724450208206666
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46234887781280853
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180211-dom4gfq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dom4gfq6
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▇▆▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▆▅▄▄▃▃▆▄▃█▅█▅▆▆▃▅▄▆▅▁▅▂▄▄▅▅▄▆▂▄█▄▇▃▇▄
wandb:      train/ensemble_f1 ▄▄▄▄▃▃▃▃▁▂▅▁▄█▄▆▆▄▃▅▃▃▁▄▄▄▅▂▃▄▂▃▄▆▂▄▆▃▇█
wandb:         train/mil_loss ▃▅▅▂▁▂▂▅▂▁▄▃▄▃▂▂▆▂▁▂▃▂▃▅▅▄▅█▃▄▄▂▄▃▃▂▂▄▃▂
wandb:      train/policy_loss ▃█▂▃▃▃▁▃▆▁▆▆▃█▃▃▄▃▁██▁▃▄▁▃▆▄▃▆▆▆▃▃▂▆▁▄▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▆▆▄▃▃▃▆▄▄▄▃▅▄▃▃▆▃▁▃▁▃▆▄▅▃▃█▁▃▄▃▄▄▃▃▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 4.14858
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 4.07378
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 4.93792
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.54468
wandb:      train/ensemble_f1 0.54468
wandb:         train/mil_loss 0.79368
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dom4gfq6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180211-dom4gfq6/logs
wandb: Agent Starting Run: mlgxzi52 with config:
wandb: 	actor_learning_rate: 0.005479667142079415
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1033517583936584
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7403234431625058
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180328-mlgxzi52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mlgxzi52
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▅▃▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▅▆▇██████████████████████████████████
wandb:       eval/ensemble_f1 ███▅▃▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▅▅▄▁▁▂▃▂▂▃▂▂▄▁▁▂▂▃▂▃▂▃▂▃▂▂▃▂▁▃▃▃▁▃▂▂▃▃
wandb:      train/ensemble_f1 ▇██▆▅▅▃▃▃▄▂▂▃▃▃▂▄▂▃▃▂▃▁▂▃▂▂▃▂▂▃▂▂▂▃▄▃▃▃▃
wandb:         train/mil_loss ▁▁▂▄▅▆█▆▅▇▇▆▆▄▄▇▅▄▇▆▇▆▆▆▄▅▆▅▅▆▄▆▆▅▇▅▅▇▆▄
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.28978
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.65764
wandb:      eval/avg_mil_loss 1.08006
wandb:       eval/ensemble_f1 0.65764
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.19235
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.75997
wandb:      train/ensemble_f1 0.75997
wandb:         train/mil_loss 0.63956
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mlgxzi52
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180328-mlgxzi52/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f1fjn8am with config:
wandb: 	actor_learning_rate: 0.004893571014600261
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6049693969724932
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4517148178007877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180521-f1fjn8am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f1fjn8am
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▂▁▃▄█▂▃▆▆▅▁▃▄▂▅▅▄▄▅▁▅█▇▄▄▇▆▂▃▃▅▅▃▄▆▃▇
wandb:      train/ensemble_f1 ▂▄▂▄▂▄█▂▇▁▄▆▆▆▆▃█▄▂▅▄▄▄▅█▄▄▂▆▂▄▅▃▄▂▁▄▇▆▄
wandb:         train/mil_loss ▃▅▆▂▄▃▅▄▅▂▇▆▄▅▄▄▁▃█▆█▅▂▅▂▁▃▃▅▆▃█▅▄▅▃▁▅▇▇
wandb:      train/policy_loss ▂▁▄▁▃▅▆▄▁▃▃▃▄▄▅▃█▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▆▃▇▁▅▄▂▇█▅▄█▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 4.44508
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 4.36046
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 5.15039
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.56567
wandb:      train/ensemble_f1 0.56567
wandb:         train/mil_loss 0.32894
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f1fjn8am
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180521-f1fjn8am/logs
wandb: Agent Starting Run: 6h95bjxd with config:
wandb: 	actor_learning_rate: 0.000629271995832018
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06501865467414658
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18385115690898568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180639-6h95bjxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6h95bjxd
wandb: uploading history steps 224-233, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▆██
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃█████▆▆▆▆▆▆▆▆█
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▃▃▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆███████▆▆▆▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▁▂▂▃▃▂▄▃▂▅▃▆▄▃▄▃▃▅▄▅▄▃▃▃▄▅▄▅▇▄▆▅▆▆▆█▆
wandb:      train/ensemble_f1 ▂▃▂▂▂▁▃▃▃▁▃▅▁▃▄▂▄▂▂▂▅▂▃▃▂▃▅▇▅▅▅▄▆█▆▆▆█▅▆
wandb:         train/mil_loss ▃▅▃▄▅▃▅▅▅▅▅▄▄▁▄▃▃▅▆▆▆▅▅▄▁▆█▇▆▁▅▇▄▆▅▄▆▆▆▃
wandb:      train/policy_loss ███████████████████████▁████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▃▁▁▁▁▁▁▁▃▁▅▁▃▁▁▁▁▁▃▁▁▁▁███████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40782
wandb: best/eval_avg_mil_loss 2.28686
wandb:  best/eval_ensemble_f1 0.40782
wandb:            eval/avg_f1 0.40782
wandb:      eval/avg_mil_loss 2.4842
wandb:       eval/ensemble_f1 0.40782
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 2.73567
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.41314
wandb:      train/ensemble_f1 0.41314
wandb:         train/mil_loss 1.93682
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6h95bjxd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180639-6h95bjxd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vu53cht9 with config:
wandb: 	actor_learning_rate: 0.0006062895829042477
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17492842018388555
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3906448949313134
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180929-vu53cht9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vu53cht9
wandb: uploading history steps 238-242, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▁▂▁▃▄▂▂▄▂▃▅▃▄▅▅▄▃▄▄▅▇▅▅▇▆▄▄▃▆▅▃▃▅▆▄▃█
wandb:      train/ensemble_f1 ▂▁▄▂▂▄▄▅▄▄▅▄▃▅▆▄▆▅▆▃▆▆▆▄▅▅▅▄▅▆▆▄▆▄▅▆▅▅▆█
wandb:         train/mil_loss ▄▇▅▆▃▁▇▂▅▆▇▄▄▅█▅▃▂▄▃▇▃█▄▂▆▅▅▅▆▄▃▅▄▄▆▄▂▃▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▂▂▂▂▁▂▂▂▁▂▂▁▂▃▁▁▁▂▃▂▁▇▇▅▇█▆▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▂▂▁▄▁▂▂▁▁▂▂▂▁▁▁▂▃▁▄█▇▅█▅▄▇▇▇▅▆▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.34917
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.33375
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.15546
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88649
wandb:      train/ensemble_f1 0.88649
wandb:         train/mil_loss 0.31445
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vu53cht9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180929-vu53cht9/logs
wandb: Agent Starting Run: 8quneoad with config:
wandb: 	actor_learning_rate: 2.378803359636273e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24852100146557532
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6271493886224915
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181225-8quneoad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8quneoad
wandb: uploading history steps 129-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▃█▇
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▃▃▆▆▆▆▆▆▆▆███████████████████████████
wandb:      eval/avg_mil_loss ▅▄███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▅▂▄▁▄█▅▇▅▃▅▅▆▅▅▄▄▅▇▆▇▆▄▆▅█▅█▅▅▆█▅▆█▅▅
wandb:      train/ensemble_f1 ▃▄█▅▆▃▂▄▅▇▃▄▂▁▃▆▄▃▄▅▁▄▃▅▆▅▃▃▅▄▇▇▃▅▇▅▅▂▆▄
wandb:         train/mil_loss ▆▄▇▂▆▆▇▂▄▆▅▁▆▅▄▄▄▃▅▃▅▄▄▃▃▆▆█▄▂▄▆▄▂▆▇▆▅▇▂
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 2.62097
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 2.56635
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 3.14862
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.56268
wandb:      train/ensemble_f1 0.56268
wandb:         train/mil_loss 1.52216
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8quneoad
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181225-8quneoad/logs
wandb: Agent Starting Run: b73zeaq7 with config:
wandb: 	actor_learning_rate: 0.0030813379821512223
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03714808094984656
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30419931904642716
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181414-b73zeaq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b73zeaq7
wandb: uploading history steps 107-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁███▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:      eval/avg_mil_loss ██████████▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▂▁▂▂▃▁▄▇▆▆▇▅▅▅▅▆▄▇▆▇▆█▇▆▇▆▆▅▅▅▇▇▅▆▆▇▅
wandb:      train/ensemble_f1 ▁▁▁▁▂▃▃▄▅▆▆▄▅▅▆▇▆▅▅▄▇▇▆▆▇▇▇▅▇▆▅▆▆▆▇▄▆█▆▅
wandb:         train/mil_loss ▇▆▇▇▅█▇▄▅▅▄▆▅▅▆▅▅▆▅▄▄▆▅▆▅▆▅▄▆▅▅▁▃▃▆▅▅▄▄▄
wandb:      train/policy_loss ▃▄▄▄▄▄▄▄▄▇▆█▁▁▁▁▁▁▁▁▁▁▁▁▁██████▃▆████▆██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▃▄▄▇███▁▁▁▁▁▁▁▁▁▁▁▁▁█████▃█▆███████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 3.82771
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 3.22555
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 4.62442
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.56366
wandb:      train/ensemble_f1 0.56366
wandb:         train/mil_loss 3.06669
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b73zeaq7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181414-b73zeaq7/logs
wandb: Agent Starting Run: y3o77l74 with config:
wandb: 	actor_learning_rate: 0.00017238971875490526
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17002697661170352
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08741180074890431
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181547-y3o77l74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y3o77l74
wandb: uploading history steps 326-330, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆███████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▃▅▄▄▅▅▄▂▆▅▅▆▇▆▃█▄▅▆▄▅▅▅▄▄▅▇▂▅▆▅█▃▄▃▇▆
wandb:      train/ensemble_f1 ▆▆▇▃▂▁▇▂▄▇▅▅▄▇▇▃▆▂▄▅▆▅▃█▅▇▄▅▄▃▇█▇▄█▃▅▂▆▆
wandb:         train/mil_loss ▅▅▄▄▁▄▄▄▄▄█▆▂▅▃▂▅▄▃▂▅▃▃▄▃▃▃▃▄▄▄▄▂▃▄▃▂▅▄▄
wandb:      train/policy_loss ▂▂▁▁▁▂▁▁▂▂▁▂▂▁▇▇█▇▅█▇▅▄█▇█▇██▇▁▁▁▂▁▁▂▁▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.33859
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.32669
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.14863
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.87017
wandb:      train/ensemble_f1 0.87017
wandb:         train/mil_loss 0.29871
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y3o77l74
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181547-y3o77l74/logs
wandb: Agent Starting Run: z0x7wfw1 with config:
wandb: 	actor_learning_rate: 0.000476187746987623
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8899544930726976
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29911859849177247
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181939-z0x7wfw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z0x7wfw1
wandb: uploading history steps 456-461, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▇█
wandb: best/eval_avg_mil_loss █▆▅▅▄▄▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▇▇▇▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▄▄▃▃▄▂▅▇▅▆▅▅▅▅▆▅▇▅▅▆▅▇▇▄▅▇▆█▄▅█▆▇▆▅▆█
wandb:      train/ensemble_f1 ▂▃▃▅▆▆▄▆▆▃▆▆▄▇▇▅▄█▁▄▆▇▃▆▆█▇▆▇▅██▇██▇██▇█
wandb:         train/mil_loss █▃▁▅▃▁▃▃▃▁▆▁▃▄▅▁▁▃▁▃▁▄▃▂▃▅▆▁▁▁▁▁▁▁▃▄▁▁▁▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▁▂▁▄▄▇███▇██▅▇▇██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▂▁▄▄▄██▇██████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66562
wandb: best/eval_avg_mil_loss 2.70696
wandb:  best/eval_ensemble_f1 0.66562
wandb:            eval/avg_f1 0.66562
wandb:      eval/avg_mil_loss 2.69276
wandb:       eval/ensemble_f1 0.66562
wandb:            test/avg_f1 0.57555
wandb:      test/avg_mil_loss 3.26636
wandb:       test/ensemble_f1 0.57555
wandb:           train/avg_f1 0.68134
wandb:      train/ensemble_f1 0.68134
wandb:         train/mil_loss 0.30051
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z0x7wfw1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181939-z0x7wfw1/logs
wandb: Agent Starting Run: 1i3nkgvh with config:
wandb: 	actor_learning_rate: 0.0006436320901482529
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6568434896766264
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4160803392275313
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182504-1i3nkgvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1i3nkgvh
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▃▃▃▃▃▂▂▂▂▂▂▃▃▃▃▃▃▃▄▅▅▅▆▆▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▂▇▄▅▂▅▆▇▂▃▄▅▃▃▃▂▇▃▄▇▁▅█▄▂▅▄▃▄▅▇▁▆▂▁▃▃▆
wandb:      train/ensemble_f1 ▆▇▅▄▄▄▂▁▅▅▆▃▅▅▇▇▇▁▅█▇▄▆▄▄▃▃█▄▅▇▄▆▆▅▃▁▃▂▆
wandb:         train/mil_loss ██▅▆▃▅▅▅▃▆▄▆▇▅▄▄▆▅▄▆▂▄▇▇▄▅▄▃▆▇▇▆▆▄▅▅▅▁▆▅
wandb:      train/policy_loss █▃▆▄▄▅▆▆▅▅▃▅▆▃▅▃▃▄▁▆█▁▃▃▅▄▄█▃▆▃▃▃▄▃▁▆▅▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▄▁▅▅▃▁▅▆▅▃▃▃▃▄▃▁▃▆▄▄▃█▆▃▃▆▁▃█▄▁▄▆▅█▃▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86967
wandb: best/eval_avg_mil_loss 0.33982
wandb:  best/eval_ensemble_f1 0.86967
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.34546
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.22775
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.87087
wandb:      train/ensemble_f1 0.87087
wandb:         train/mil_loss 0.29665
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1i3nkgvh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182504-1i3nkgvh/logs
wandb: Agent Starting Run: 055lrbuk with config:
wandb: 	actor_learning_rate: 0.0032134807514021843
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8760109118413756
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49889611296293235
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182622-055lrbuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/055lrbuk
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▇▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▄▄▆▇▇▇▇████████████████████████
wandb:       eval/ensemble_f1 ██████████▆▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆█▇█▇▅▃▃▂▄▂▃▅▃▄▄▃▄▃▃▄▄▃▄▁▄▄▃▄▅▃▃▃▃▅▅▃▃▄
wandb:      train/ensemble_f1 ▇▇▇▇▆▇█▇▇█▅▅▅▃▃▂▃▃▃▂▃▃▂▃▃▄▂▃▃▂▃▄▂▃▃▂▂▂▁▅
wandb:         train/mil_loss ▂▅▂▃█▆▄▃▂▆▂▄▃▄▅▃▁▆▄▅▃▃▄▅▆▁▃▅▂▂▂▅▂▃▁▂▃▂█▁
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.29185
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.72867
wandb:      eval/avg_mil_loss 0.51252
wandb:       eval/ensemble_f1 0.72867
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.18132
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.84121
wandb:      train/ensemble_f1 0.84121
wandb:         train/mil_loss 0.28622
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/055lrbuk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182622-055lrbuk/logs
wandb: Agent Starting Run: vc2huwj8 with config:
wandb: 	actor_learning_rate: 0.0010351475447100925
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22156796482257712
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17776824723959106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182740-vc2huwj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vc2huwj8
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆█▄▆▆█▇▅▅▆▄▅▅▄▂▄▃▆▅▄▃▆▄▆▃▁▅▅▆▃▃▅▄▃▃▅▄▃▅
wandb:      train/ensemble_f1 ▆▆▇▅▄▄▇▄▆▅▅▅▄▅▄▆▅▆▂▃▅▄▄▅▄▆▃▁▅▄▃▄▅▂▆▂█▄▄▄
wandb:         train/mil_loss ▇▇▅█▅▄▅▅▄▂▄█▁▄▅▂▅▃▆▄▆▆▅▅▆▆▅▄▇▄▅▃▄▅▆▄▅▇▅▄
wandb:      train/policy_loss ▄▂▄▅▂▄▂▁▄▂▁▂▅▂▃▄▂▄▄▁█▂▂▂▁▅▄▄▂▄▄▂▄▂▄▂▂▂▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▃▃▃▃▁▆▅█▇▅▃▄▅▆▁▁▆▁▃▂▅▇▅▂▃▅▅▅▄▆▅▃▃▃▃▃▁▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.39766
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.37916
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.17471
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.87418
wandb:      train/ensemble_f1 0.87418
wandb:         train/mil_loss 0.2859
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vc2huwj8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182740-vc2huwj8/logs
wandb: Agent Starting Run: ioh5ahav with config:
wandb: 	actor_learning_rate: 0.009431053495332482
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8864093102104945
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7248244711803267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182858-ioh5ahav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ioh5ahav
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▆▂▄▅▅▄▃█▄▄▃▄▅▃▆▅▃▇▇▂▅▆▆▄█▄▄▄▇▄▅▅▅▄▆▃▅▇
wandb:      train/ensemble_f1 ▃▁▅▂▄▇▁▄▃▃▃▅▄▃▅▆▄▆▂▅▃▄▂▃█▇▅▄▃▆▄▅▅▅▄▂▅▂▄▆
wandb:         train/mil_loss ▄▁▁▄▁▃▃▁▇▁▃▃▁▁█▃▁▃▄▆▁▅▁▃▁▁▁▆█▁▅▄▃▄▆▄▁▆▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 4.16969
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 4.12991
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 4.87984
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.48094
wandb:      train/ensemble_f1 0.48094
wandb:         train/mil_loss 0.30921
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ioh5ahav
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182858-ioh5ahav/logs
wandb: Agent Starting Run: 70z83ju9 with config:
wandb: 	actor_learning_rate: 0.00051528326447292
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04127491008923545
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1007167594815358
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183015-70z83ju9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/70z83ju9
wandb: uploading history steps 220-227, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ▇█▁▁▂▂
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▄▄▄▅▅▇▇▇▇▇▇███████████████▇▇▇▇▇
wandb:      eval/avg_mil_loss ▇▇█▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▁▁▁▁▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▂▄▄▅▇▇▇▇▇▇▇▇▇██████████████▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▅▃▅▇▆▅█▅▆▄▆▃▄▄▄▅▄▅▄▁▃▇▇▂▃▃▅▄▇▇▄▃▅▆▃▅▄
wandb:      train/ensemble_f1 ▁▆▇▆▆▅█▆▁▅▇▄▇▄▆▄▄▅▃▃▄▄▁▃▄▆▄▅▄▆▇▂▄▅▃▅▅▃▃▇
wandb:         train/mil_loss ▄▂▁▄█▆▆▄▄▇▄▁▆▃▃▇▃▂▄▅▅▇▄▂▂▅▅▄▄█▇▇▁▃▃▃▃▆▂▃
wandb:      train/policy_loss █▁▁▁▁▁▁▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.33261
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.33446
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.27486
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.87455
wandb:      train/ensemble_f1 0.87455
wandb:         train/mil_loss 0.30648
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/70z83ju9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183015-70z83ju9/logs
wandb: Agent Starting Run: 0412hqge with config:
wandb: 	actor_learning_rate: 0.0036671166100543983
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6852874067471872
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.005281910055378813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183255-0412hqge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0412hqge
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████████████▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 █████████████████████████████████████▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▅▅▁▂▄▆▆▂▆▇▅▇▇▆▅▅▆▄▅▇▄█▃▆▆▅▃▄▂▅▇▅▃▅▅▅▃
wandb:      train/ensemble_f1 ▇▅▂▆▅▁▄▆▄▆▂▃▄▇▃▆▅▇▅▅▅▅▄▅▄▃▃█▅▃▇▆▆▇▇▅▅▃▅▃
wandb:         train/mil_loss ▂▅▅▅▅▅▅▃▄▃▃▇▅▅▄▃▅▆▅▅▆▇▂▃▄▆▄▃▆▅▇█▄▁▅▅▄▃▆▅
wandb:      train/policy_loss █▁▃▅▃▅▁▅▄▆▆█▁▅█▃█▅▆▆▆▆▆▁▆▆▆▆▆▄▆▆▁▅▃▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▅▄▃▆▅▁█▅▄▆█▁█▅▆▆▆▆▆▄▆▆▁▆▆▆▄▃▅▆▅▄▆▁▅▁▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.28548
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.29501
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.18228
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.90352
wandb:      train/ensemble_f1 0.90352
wandb:         train/mil_loss 0.28691
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0412hqge
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183255-0412hqge/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t11thwk8 with config:
wandb: 	actor_learning_rate: 5.324350277728317e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9283909601608032
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28325140847746266
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183450-t11thwk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t11thwk8
wandb: uploading history steps 129-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▄▃▅▃▃▂▂▅▄▂▅▂▄▁▄▄▃▄▆▃█▃▄▅▃▆▆▃▃▅▄▅▆▅▆▂▃▃
wandb:      train/ensemble_f1 ▄▅▄▄▆▁▄▃▃▅▃▂▆▄▇▆█▆▁▃▅▃█▇▄▄▃▅▆▅▇▃▄▅▆▁▆▇▃▅
wandb:         train/mil_loss █▆▅▇▆▅▇▁▆▅▄▄▇▃█▇▄▄▆▃▃▆▅▃▃▆▄▃▃▅▄▄▁▄▄▃▄▅▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▅▅█▂██████▅▄█▅██▅█▅█▂▄██▅▂▅▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.47418
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.46367
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.3527
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.86498
wandb:      train/ensemble_f1 0.86498
wandb:         train/mil_loss 0.27513
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t11thwk8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183450-t11thwk8/logs
wandb: Agent Starting Run: 6l74i1pg with config:
wandb: 	actor_learning_rate: 0.0006557062176603747
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2727104203113496
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44266936964610326
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183637-6l74i1pg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6l74i1pg
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▁▄▆▆▅▅▄▂▆▅▆▆▆█▆▅▇▅▆▄▇▅█▇▆▆▅▆▄▆▄▇▇▅▆▆▄
wandb:      train/ensemble_f1 ▆▃▁▅▄▆▄▆▆▅▆▆▅▅▆▇▆▇▅▁▄▅▄▄▆▄▅▆▇▆▆█▄▃▄█▃▅▅▄
wandb:         train/mil_loss ▂▂▃▄▃▅▃▃▆▃▅▃▆▄█▃▃▅▃▄▃▃▆▅▅▁▃▃▄▁▂▅▁▄▃▄▃▃▂▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.35365
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.34045
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.92609
wandb:      test/avg_mil_loss 0.20186
wandb:       test/ensemble_f1 0.92609
wandb:           train/avg_f1 0.86531
wandb:      train/ensemble_f1 0.86531
wandb:         train/mil_loss 0.34725
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6l74i1pg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183637-6l74i1pg/logs
wandb: Agent Starting Run: y6xfe16d with config:
wandb: 	actor_learning_rate: 0.0010268135365045904
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2240527012833108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9352334678804076
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183754-y6xfe16d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6xfe16d
wandb: uploading history steps 218-226, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▆▆███████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▆▆█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▄▁▅▇▃▅▅▃▄▃▃▅▆▃▅▄▆▆▄▂▆▄▄▇██▇▇▇█▆▄▅▅▇█▄
wandb:      train/ensemble_f1 ▁▃▁▃▁▂▃▂▂▂▄▂▄▃▅▁▄▅▂▁▇▇▂▇▂▄▇▇▄▅▆▇▅▆▆▄▇▆█▅
wandb:         train/mil_loss ▃▇▅▄▆▄▄▅▄▆▃▃▅▅▆▆▃▂▄▇▃▅▃▃▄▂▆▂▃▃▂▆▄▂█▅▁▃▃▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▂▃▂▆▆▅▆▆▅▆▅█▅▆▅▅▆█▆▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▃▁▃▃█▃▃▆█▅▆▆▆█▆▅▆▆▅▆▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.31935
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.30706
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18863
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88856
wandb:      train/ensemble_f1 0.88856
wandb:         train/mil_loss 0.28899
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6xfe16d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183754-y6xfe16d/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2dtd3or3 with config:
wandb: 	actor_learning_rate: 8.765381527722992e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.003850061709667396
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9112598591897506
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184045-2dtd3or3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2dtd3or3
wandb: uploading history steps 177-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▇▆▅▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▅▅▆▆▆▆▆▆▆▆▆▆████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▂▄▆▅▄▄▃▅▅▄▂▂▃▃▆▃▃▆▄▅▄▃▃▄▆▃▆▂▇▄▅▄▆▄▆▅▄█
wandb:      train/ensemble_f1 ▅▁▃▃▁▃▄▄▁▇▅▅▅▅▃▅▄▅▃█▃▆▆▇▅▆▂▅▅▇▇▄▅▆▆█▇▄▅▄
wandb:         train/mil_loss ▄█▆▅▆▄▇▅▄▄▃▅▅▅▃▇▃▄▂▆▄▅▄▄▅█▃▅▃▄▆▇▅█▁▅▆▃▃▁
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.31371
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.29485
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.17746
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88883
wandb:      train/ensemble_f1 0.88883
wandb:         train/mil_loss 0.27488
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2dtd3or3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184045-2dtd3or3/logs
wandb: Agent Starting Run: er4jv20p with config:
wandb: 	actor_learning_rate: 6.14002716234079e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7692559210574191
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20766225208042643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184304-er4jv20p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/er4jv20p
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▅▄▃▃▃▃▂▂▁▁▁▇▆▆▆▆▆▆▆▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅▆▅▆█▇▆▇▆▄▆▄▇▇▆▇▆▇▆▇▆█▄▅▅▇▁▅▆▆▇▆▆▆█▇▆
wandb:      train/ensemble_f1 ▅▅▆▇▇▇▆▅█▆▇▆▄▅▄▅▅▆█▆▅▆▇▆▅▄▅▁▃▇▅▆▇▆▆▆▇▆▅▆
wandb:         train/mil_loss ▃▄█▃▄▄▃▃▅▆▄▇▄▂▂▁▄▂▁▂▆▂▅▂▄▄▅▄▄▄▃▄▃▃▂▄▅▄▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 3.4348
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 3.42347
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 4.09666
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.52794
wandb:      train/ensemble_f1 0.52794
wandb:         train/mil_loss 1.32713
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run snowy-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/er4jv20p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184304-er4jv20p/logs
wandb: Agent Starting Run: 6gjawcfj with config:
wandb: 	actor_learning_rate: 0.00012804301628457752
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4396769299958597
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6372506359794057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184422-6gjawcfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6gjawcfj
wandb: uploading history steps 242-251, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▄▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅████▅▅▅▅▅▂▂▅▅▅
wandb:      eval/avg_mil_loss ▇██▇▇▇▇▇▇▇▆▆▆▆▆▅▅▆▆▅▄▄▄▄▄▄▃▄▃▃▂▂▂▂▂▁▁▁▁▂
wandb:       eval/ensemble_f1 ▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄████▅▅▅▁▁▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▄▂▂▂▃▁▃▃▁▃▅▃▁▂▁▂▃▂▃▄▂▃▂▄▁▁▂▃▃▄▄▅▇▄▅▆▆█
wandb:      train/ensemble_f1 ▃▃▄▄▄▃▄▅▄▄▁▃▄▂▂▄▄▅▅▄▃▆▄▄▆▅▇▆▆▅▇█▇█▅▅█▇▅▅
wandb:         train/mil_loss ▄▆▄▄▆█▃▇▄▃▃▂▃▁▃▇▆▂▃▆█▅▅▁▄▄▅▅▄▃▄▃▃▄▃▃▄▃▂▁
wandb:      train/policy_loss █████████████████████████▃▆▄▆▄▆▁████▆▁▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▁▅▃█▃▆▆▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67839
wandb: best/eval_avg_mil_loss 1.17065
wandb:  best/eval_ensemble_f1 0.67839
wandb:            eval/avg_f1 0.66928
wandb:      eval/avg_mil_loss 1.15433
wandb:       eval/ensemble_f1 0.66928
wandb:            test/avg_f1 0.69562
wandb:      test/avg_mil_loss 1.04807
wandb:       test/ensemble_f1 0.69562
wandb:           train/avg_f1 0.79986
wandb:      train/ensemble_f1 0.79986
wandb:         train/mil_loss 0.4407
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6gjawcfj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184422-6gjawcfj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ayk8p1nw with config:
wandb: 	actor_learning_rate: 0.00037778167566411433
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7174175053490498
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09562180425761092
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184747-ayk8p1nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/oav6k7ms
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ayk8p1nw
slurmstepd: error: *** JOB 12116331 ON gcn122 CANCELLED AT 2025-06-01T18:51:21 DUE TO TIME LIMIT ***
