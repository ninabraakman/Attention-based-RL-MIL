wandb: Agent Starting Run: ssorhpb2 with config:
wandb: 	actor_learning_rate: 0.00022886922988568092
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09385898373428748
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06162364783400176
wandb: Agent Starting Run: ebhkxt6n with config:
wandb: 	actor_learning_rate: 0.00013932223483950382
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9319881026048183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9816275255652112
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003129-ssorhpb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ssorhpb2
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003130-ebhkxt6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebhkxt6n
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: Agent Starting Run: ww9wykkc with config:
wandb: 	actor_learning_rate: 0.008369587071816079
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1673848275873947
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40283065085301906
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003152-ww9wykkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ww9wykkc
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: Agent Starting Run: yb3swg8p with config:
wandb: 	actor_learning_rate: 1.0098026454628251e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42601208170998006
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8322540432997518
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003200-yb3swg8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yb3swg8p
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 125-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▅▅▅▄▄▄▄▄▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▄▁▅▆▄▄▄▆▄▄▄▄▇▅▆▇▃▅▅▆▄▆▆█▆▅▆▆▆▅▆▇▄▄▂▅▄▅
wandb:      train/ensemble_f1 ▁▄▅▆▆▅▅▆▄▅▄▅▅▇▅▆▅▄▅▆█▆▇▆▆█▅▇▆▅▆▅▅▅▄▃▆▅▆▅
wandb:         train/mil_loss ▅▄▃▄▅▁▃▅▆▂▃▁▄▂▅█▁▂▃▅▆▂▄▂▇▄▂▃▅▆▃▄▄▆▃▂▅▅▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.37761
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.29702
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 2.95631
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.4896
wandb:      train/ensemble_f1 0.4896
wandb:         train/mil_loss 0.41273
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebhkxt6n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003130-ebhkxt6n/logs
wandb: Agent Starting Run: 3nyxltc4 with config:
wandb: 	actor_learning_rate: 6.87121142007457e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8122661565263833
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8818073502728481
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003345-3nyxltc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nyxltc4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇▇█
wandb: best/eval_avg_mil_loss ▃▃▁██▅▄
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▃▅▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:      eval/avg_mil_loss ▅▅▅▄▄▄██▇▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▂▃▄▃▃▅▆▆▇▆▆▆▆▇▅▇▆▆▆█▇▆▅▇▇▇▇▆▇▇▇▆▇▇▆▆▇
wandb:      train/ensemble_f1 ▁▂▁▁▂▃▂▃▂▄▅▆▆▆▅▆▆▆▅▇▇▆█▇▆▇▇█▇▇▇▇▇▆▇▆▇▆▇█
wandb:         train/mil_loss ▇▄█▆▆▁▅█▁▇▅▆▄▅▄▄▅▄▃▃▅▂▂▄▅▅▃▃▅▄▄▄▃▂▃▂▄▄▂▃
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57131
wandb: best/eval_avg_mil_loss 1.9103
wandb:  best/eval_ensemble_f1 0.57131
wandb:            eval/avg_f1 0.57131
wandb:      eval/avg_mil_loss 1.68832
wandb:       eval/ensemble_f1 0.57131
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.12884
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.55485
wandb:      train/ensemble_f1 0.55485
wandb:         train/mil_loss 0.81965
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ww9wykkc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003152-ww9wykkc/logs
wandb: Agent Starting Run: aii42z6i with config:
wandb: 	actor_learning_rate: 0.006229619934827903
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6724072175747312
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4107007948540168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003407-aii42z6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aii42z6i
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▄▅▅▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▄▅▂▆▄▆▇▇▅▂▁▅▅▇▆▅▆▄▇▆▄▅▄▂▅▃▆▅█▅▅▇▇▅▅▄▄
wandb:      train/ensemble_f1 ▅▃▄▆▃▄▁▃▃▆▆▆▄▅▁▃▅▆▂▄▄▆▅▆▅▆▆▂▄▄▇▅▃█▄▄▆▆▅▄
wandb:         train/mil_loss ▅▂▄█▄▄▆▃▄▄▁▄▂▂▅▇▇▄▅▅▆▃▅▃▃▃▅▄▇▂▅▅▅▄▅▇▂█▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87981
wandb: best/eval_avg_mil_loss 0.24736
wandb:  best/eval_ensemble_f1 0.87981
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.24746
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.30563
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88367
wandb:      train/ensemble_f1 0.88367
wandb:         train/mil_loss 0.26012
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nyxltc4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003345-3nyxltc4/logs
wandb: Agent Starting Run: icioe1jb with config:
wandb: 	actor_learning_rate: 1.7992127102717694e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4178245193072675
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9834284595767642
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003528-icioe1jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/icioe1jb
wandb: uploading history steps 202-215, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆█
wandb: best/eval_avg_mil_loss ▁▁▁▅█
wandb:  best/eval_ensemble_f1 ▁▃▄▆█
wandb:            eval/avg_f1 ▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆███████▆▆▆▆▄▄▄▄
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇███████
wandb:       eval/ensemble_f1 ▁▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆███████▆▆▆▆▆▆▆▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▆▁▆▆█▆█▄▇▅▇▆▆▅▆▆▅▆█▆▆▆▇▇▆▆▆█▆▅▇▇▇▅▇▅▆
wandb:      train/ensemble_f1 ▆▄▆▄▁▄▂▅▅▇▃▅▇▅▅▄▇▄▃█▇▆▅▅▂▆▆▅▅▄▆▃▂▄▅▄▂▃▅▅
wandb:         train/mil_loss ▆▆▆▃█▆▄▂▃▅▅▄▆▄▄▅▄▄▆▅▄▅▂▄▄▃▅▅▂▅▃▄▄▄▄▁▃▆▃▄
wandb:      train/policy_loss █████████████████████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▇▅▆▅▂▅█▃▅▆▁▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▄█▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.1793
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.18733
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.18743
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.88616
wandb:      train/ensemble_f1 0.88616
wandb:         train/mil_loss 0.24257
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yb3swg8p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003200-yb3swg8p/logs
wandb: Agent Starting Run: j2ek57pc with config:
wandb: 	actor_learning_rate: 0.0004391705497588809
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6619094647766298
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0818339173871625
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003533-j2ek57pc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2ek57pc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▃▃▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▄▇▇▇▇█████████████████████████████████
wandb:       eval/ensemble_f1 ██▆▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▅▇▅▅▅▆▂▆▄▆▄▂▆▅▄▆▇▂▇▄▆▂▅▆▃▆▃▆▃▆▅▆▃▂▅▁▃▅
wandb:      train/ensemble_f1 ▄▆▄▇█▅▅▁▂▁▄▅▃▅▁▆▃▂▆▃▃▅▃▇▄▃▄▃▂▄▆▄▅▅▃▃▅▃▅▄
wandb:         train/mil_loss ▅▃▇▅▇▄▄▆▄▂▂▆▃▇▃▆█▁▄▅▅▆▄▅▅▅▅█▄▃▃▁▅▆▄▄▅▆▂▅
wandb:      train/policy_loss █▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▃▅▁▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████▁████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.19313
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.31679
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.3
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.91179
wandb:      train/ensemble_f1 0.91179
wandb:         train/mil_loss 0.24528
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aii42z6i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003407-aii42z6i/logs
wandb: Agent Starting Run: 62vdkdoi with config:
wandb: 	actor_learning_rate: 0.007547795306614421
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7108706813891139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3813586878433526
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003550-62vdkdoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/62vdkdoi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▇█
wandb: best/eval_avg_mil_loss █▆▆▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▇█
wandb:            eval/avg_f1 ▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▇▇▇▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▄▄▄▄▄▄▄▄▄▇▇▇▇▇▇▇▇▇███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▆▁▄▄▄▃▅▅▅▇▄▆█▇▅▇▇▇▅▅▆▄▇▆█▇▇▆▆▆▇▆▇▆▇▇▆
wandb:      train/ensemble_f1 ▅▅▄▄▁▄▅▅▅█▇▇▆▅▆▆▇▆▇▇▆▇█▇▇▆▆▇▆▅▆▅▇▆▇█▇▆██
wandb:         train/mil_loss ▆█▄▄▄▄▆▄▄▄▃▅▅▃▂▄▃▅▃▃▄▂▁▂▃▃█▆▅▂▃▃▄▃▃▆▄▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▆▆█▇▇▆▆▅▇▇▇▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▆▇▆▇▅▇█▇▇▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.21341
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.20865
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.20621
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.88439
wandb:      train/ensemble_f1 0.88439
wandb:         train/mil_loss 0.27037
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ssorhpb2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003129-ssorhpb2/logs
wandb: Agent Starting Run: pn2jtq6i with config:
wandb: 	actor_learning_rate: 0.0003748967590084116
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.779274207329565
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3970445057517216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003640-pn2jtq6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pn2jtq6i
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▆▇▇▇███▇▆▅▅▄▄▃▅▅▅▅▅▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▇▅▅▆▄▄▃▇█▅▇▅▅▂▆▆▄▅▆█▇▄▄▅▃▄▄▄▄▁▄▇▇▅█▇▆▃
wandb:      train/ensemble_f1 ▆▄▄▆▄▂▃▃▄▄▅█▆▅▅▄▆▄▅▅▃▁▄▆▅▃▇▃▃▄▄▄▃▅▄▃▄▆▃▂
wandb:         train/mil_loss ▃▂▄▄▃█▃▆▁▄▇▃▃▃▃▇▆▄▄▁▅▄█▅▄▃▄▃▃▅▆▅▅▂▁▄▇▄▂▂
wandb:      train/policy_loss ▆█▄▅▄▁▄▅▄▄▅▂▅▄▄▃▂▁▄▆█▄▃▄▁▂█▄▄▅▄▂▄▃▃▄▆▇▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▄▄▅▄▆▆▁▃▇▅▂▆▆▆▆▆▃▃▂▆▆▂▆▆▁▆▃▅▃▃▃▄▁▁▄▆██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.18144
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.12249
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.72332
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32031
wandb:      train/ensemble_f1 0.32031
wandb:         train/mil_loss 0.88828
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2ek57pc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003533-j2ek57pc/logs
wandb: Agent Starting Run: 0il324i7 with config:
wandb: 	actor_learning_rate: 0.000897541655448287
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6840896673494454
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9015104631103228
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003716-0il324i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0il324i7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▄█▆▄▅▆▄▆▅▅▄▆▅▆▇▂▇▁▇▅▄▆▄▅▄▆▄▄▆▅▅▃▅▁▅▅▄▃
wandb:      train/ensemble_f1 ▄▇▄█▆▃▆▆▄▆▄▅▄▆▆▁▄▃▅█▄▆▄▄▅▆▄▆▅▃▄▃▃▄▆▇▁▃▅▃
wandb:         train/mil_loss ▆▆▇▄▇▃▇▅▅▆▃▆▆▆▆▄▆▅▄▆▃▂▅▁▅▅▂▅▄▆▄▄▄▂▄▄▅▅▃█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.25594
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.26977
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.07268
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.90565
wandb:      train/ensemble_f1 0.90565
wandb:         train/mil_loss 0.28319
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/62vdkdoi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003550-62vdkdoi/logs
wandb: Agent Starting Run: s93iv20h with config:
wandb: 	actor_learning_rate: 0.002453606784640558
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9043234438696144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43294171751695953
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003734-s93iv20h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s93iv20h
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12081293/pymp-7nkwong4'
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆▆██
wandb: best/eval_avg_mil_loss ██▇▇▅▅▁
wandb:  best/eval_ensemble_f1 ▁▃▃▆▆██
wandb:            eval/avg_f1 ▂▁▂▂▂▂▅▅▇▇███▇▅▅▅▅▅▅▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▁▂▇▅▅█████▇▇▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▄▃▄▄▄▅▄▆▆▆▇▇█▇▆▇▆▇▇▇▇▇▇█▇▇▇▆▇▇███▆▇▇▇
wandb:      train/ensemble_f1 ▁▂▄▃▂▃▄▄▄▅▅▄▅▄▃▅▆▆▆▅▆▆▇▅▇▇▇▇▇▇▇▇▆▇█▇▆█▇█
wandb:         train/mil_loss ▆▇█▆▇▇▅▆▂▅▂▃▂▂▃▃▃▂▃▃▄▃▁▂▃▃▂▂▁▄▂▁▁▂▂▁▂▁▁▂
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.26654
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.24669
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.26799
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.90374
wandb:      train/ensemble_f1 0.90374
wandb:         train/mil_loss 0.27535
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/icioe1jb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003528-icioe1jb/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▅▆▆▆▃▃▂▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▅█▅▂▆▅▆▅▅▄▃▅▅▅▂▅▄▄▃▃▅▃▅▁▂▆▇▅▄▄▃▁▄▂▅▅▆
wandb:      train/ensemble_f1 █▂▂▄▆▅▄▆▃▃▅▅▅█▄▃▄▆▄▅▅▃▅▃▃▅▅▄▆▄▁▃▆▆▄▄▁▆▅▄
wandb:         train/mil_loss ▄▄▃▅▃▅▇▄▅▂▁▄▂▂▄▄▃▄▇▄▃▅▃▄▅▂▁▄▃█▆▃▃▄▁▂▂▁▂▁
wandb:      train/policy_loss ▆▆▁▄▅▅▄▄▅▄▆▅▅▄▆▆▇▄▆▆▆▅▄█▅▅▇▇▅▅▅▅▂▃▄▇▇▇▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▇▁▅▅▄▂▅▆▆▃▅▆▃▄▇▇▇▄▄▇▇▅▅▇▅▇▄▅▅▂▃▇█▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.41903
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.27119
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.61873
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.348
wandb:      train/ensemble_f1 0.348
wandb:         train/mil_loss 0.76054
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0il324i7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003716-0il324i7/logs
wandb: Agent Starting Run: vz9qyuho with config:
wandb: 	actor_learning_rate: 1.3270562622457988e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39887723434755984
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8747116622493183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003900-vz9qyuho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vz9qyuho
wandb: Job received.
wandb: Agent Starting Run: nv6olie8 with config:
wandb: 	actor_learning_rate: 0.002595279714726224
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3671839406650067
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04060927220292654
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003902-nv6olie8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nv6olie8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅█
wandb: best/eval_avg_mil_loss █▆▄▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅▅█
wandb:            eval/avg_f1 ▂▂▂▂▂█▇▇▇▇▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▁▁▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:       eval/ensemble_f1 ▃▃▃▃▃▆██▆▆▅▅▅▅▅▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▁▂▃▅▅▅█▅▅▇▄▆▂▅▆▅▃▇▆▂▄▄▇▂▄▅▆▇▇▆▂█▄▂▆▆▄
wandb:      train/ensemble_f1 ▄▃▃▁▂▅▁▄▅▆██▆▄▇▅▆▅▆▅▆▆▂▄█▆▄▅▇▆█▅▆█▇▁▅▂▆▄
wandb:         train/mil_loss ▆▃▅▅▆▂▄▅▇▃▂▃▄▆▁▅▅▆▄▃▇▃▃▃█▃▆▆▅▂▅█▄▃▅▅▅▁▅▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▆▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.15074
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.28106
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.18353
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.90152
wandb:      train/ensemble_f1 0.90152
wandb:         train/mil_loss 0.25765
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s93iv20h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003734-s93iv20h/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hmvjw5lw with config:
wandb: 	actor_learning_rate: 0.006025598848698138
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9747450842372056
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05436950275057584
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_003943-hmvjw5lw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmvjw5lw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▆▆▆▆▆▆▆▆▆▃▃▃▃▃▁▁▁▃▃▁▁▁▃▃▃▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▆▆▆▆▅▃█▇█▇▆▆▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ████▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▁▁▃▃▃▃▃▃▃▁▁▁▃▃▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▄▅▆▇▇▄█▅▃█▅▄▄▇▆▇▇▄▅▆▄▅▃▄▂▇▆▆▅▆▆▅▆▄▄▁▃
wandb:      train/ensemble_f1 ▃▃▇▅▅▆▇▅▅▅▄▅▇▅▅▇▇▅▄▅▆▆▇█▆▆▅▄▅▆▆▂▅▆▆▆▇▄▁▆
wandb:         train/mil_loss ▅▃█▇▇▅▃▅▄▃▃▄▃▅▅▇▃▄▄▃▂▇▁▂▆▄▄▄▅▅▂▄▆▅▅▄▃▃▅▄
wandb:      train/policy_loss ██████▁████████████████████████▂████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████▁████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.27135
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.26397
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.9592
wandb:      test/avg_mil_loss 0.291
wandb:       test/ensemble_f1 0.9592
wandb:           train/avg_f1 0.87338
wandb:      train/ensemble_f1 0.87338
wandb:         train/mil_loss 0.27737
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vz9qyuho
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003900-vz9qyuho/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▄▅▅▅▅▃▂▁▁▄▄▄▄▄▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃██▅▆▅▅▄▇▆▇▅▇▆▆▇▅▄▆▇▆█▆▇█▅▁▅▅▆▆█▅█▆▆▅▅▃
wandb:      train/ensemble_f1 ▅▂▆▄▆▁▄▃▂▄▂▄▄▇▆▄▅▆▄▃▂▆▃▅▄▆▄▄▆▃▄▇▄▅█▅▄▅▃▁
wandb:         train/mil_loss ▃▂▅▅▇▄▄▇▇▄█▄▃▆▄▅█▂▄▄▅▅█▄▃▄▅▇▆█▅▃▃▅▂▅▇▄▄▁
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄█▄▄▄▄▄▄▄▄▃▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.26204
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.27593
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.27268
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.87106
wandb:      train/ensemble_f1 0.87106
wandb:         train/mil_loss 0.2337
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nv6olie8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003902-nv6olie8/logs
wandb: Agent Starting Run: a03r0r7g with config:
wandb: 	actor_learning_rate: 1.072488691612485e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03485944524562079
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7692136650192447
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004043-a03r0r7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a03r0r7g
wandb: Agent Starting Run: qox2s0f7 with config:
wandb: 	actor_learning_rate: 0.0005156360879108251
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4819495221539576
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8463600019235479
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004047-qox2s0f7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qox2s0f7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▅▇▇▇█
wandb: best/eval_avg_mil_loss ▇█▇▆▆▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▅▇▇▇█
wandb:            eval/avg_f1 ▂▂▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▄▅▅▇▅▇▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▃▃▅▄▅▅▄▅▃▆▆▇▆▇█▄▇▇▅▆█▆▇▆▇▆▇▆▇█▇▆▅▇▇▆▇
wandb:      train/ensemble_f1 ▂▁▂▄▄▂▄▃▄▅▆▇█▆▅▅▃▆▂▇██▆▆▆▄▇█▆▄▆▄▇▅▇▆▆█▆▅
wandb:         train/mil_loss █▃▆▃▃▃▅▄▆▆▄▅▂▃▃▂▃▃▃▃▃▃▄▃▅▃▂▂▃▂▄▁▂▃▃▃▄▃▁▂
wandb:      train/policy_loss ▇▅▅▅▁▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▆▆▆▆▄▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86999
wandb: best/eval_avg_mil_loss 0.36912
wandb:  best/eval_ensemble_f1 0.86999
wandb:            eval/avg_f1 0.86999
wandb:      eval/avg_mil_loss 0.3661
wandb:       eval/ensemble_f1 0.86999
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.31003
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.85552
wandb:      train/ensemble_f1 0.85552
wandb:         train/mil_loss 0.28162
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pn2jtq6i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003640-pn2jtq6i/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xyowo2qh with config:
wandb: 	actor_learning_rate: 0.007341930098275586
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11411199027756767
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5389973166715045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004123-xyowo2qh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xyowo2qh
wandb: uploading history steps 125-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅███████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▅▆▅▅▅▅▄▄▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▄▅▂▃▄▄▃█▄▂▄▅▃▇▅▁▄▆▅▃▅▆▅▇▅▄▅▆▆▅▃▅▅▅▃▆▆
wandb:      train/ensemble_f1 ▃▄▁▄▂▄▂▄▅▃▄▃▄▅▅▄▅▃▅▄▆▄▆▃▄▅▅▅▆▅▆▄▅█▄█▆▅▅▆
wandb:         train/mil_loss ▄▇▃▅▄▆▂▂▂▇▁▃▆▇▂▅▅▃▄▂▇▇▂▂▄▂▃█▄▁▃▄▂▃▃▁▄▃▅▆
wandb:      train/policy_loss █▇█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇█▇▇▇███▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 2.03535
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 1.92936
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.4223
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.57365
wandb:      train/ensemble_f1 0.57365
wandb:         train/mil_loss 0.22983
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmvjw5lw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_003943-hmvjw5lw/logs
wandb: Agent Starting Run: 8dqlxm42 with config:
wandb: 	actor_learning_rate: 0.007810234211006986
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8604510604956336
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5623354444486217
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004203-8dqlxm42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8dqlxm42
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁█▅▂▆█▆▅█▂▅█▅▅▄▇▃▅▅▆▃▃▃▇▆▆▆▄▆▅▆▇▆█▅▆▇▃▆▇
wandb:      train/ensemble_f1 ▆▁▅▂▃▁▃▄▇▃▃▃▅█▆▃▄▅▆▄▁▂▅▅▃▅▅▅▄▅▆▆▄▆▅▂▅▃▅▇
wandb:         train/mil_loss ▄▃▃▄▂▆▄▁▃▅▄▄█▄▁▄▄▃▂▃▁▅▅▅▄▅▂▄▂▄▇▄▁▅▅▂▁▆▅▂
wandb:      train/policy_loss ▅▅▃█▃▄▂▅▁▆▅▄▅▂▅▆▄▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▁▅▃▅▃▂▄▄▅▅█▄▃▃▅▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.29775
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.27424
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.12594
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.90776
wandb:      train/ensemble_f1 0.90776
wandb:         train/mil_loss 0.22843
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qox2s0f7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004047-qox2s0f7/logs
wandb: Agent Starting Run: 5zu9hjg3 with config:
wandb: 	actor_learning_rate: 0.00016190490198989108
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5190979885482914
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9960373655137212
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004231-5zu9hjg3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5zu9hjg3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▅▅▅▅▁▅▅▁▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▃▃▃▃▄▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:       eval/ensemble_f1 █▅▅▅▁▅▁▅▅▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇█▆█▇▅▆▅▄▅▅▄▃▆▆▅▄▆▆▅▅▁▅▇▄▆▄▇▅▇▆█▆▆▄▅▅▅
wandb:      train/ensemble_f1 ▂▇▇█▄▅▅▇▄▃▆▄▄▅▆█▆▄▅▃▅▃▂▂▇▁▂▅▂▇▄█▆▆▅▇▆▄▅█
wandb:         train/mil_loss █▅▆▄█▂▆▇▅▄▅▄▅▄▆▄▄▂▃▂▃█▅▂▅▄▄▄▁▅▅▄▄▂▂▆▅▇▄▄
wandb:      train/policy_loss █▃▃▃▃▃▄▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃▃▃▃▃▁▃▄▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.1867
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.27916
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.94914
wandb:      test/avg_mil_loss 0.21468
wandb:       test/ensemble_f1 0.94914
wandb:           train/avg_f1 0.92055
wandb:      train/ensemble_f1 0.92055
wandb:         train/mil_loss 0.23636
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8dqlxm42
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004203-8dqlxm42/logs
wandb: Agent Starting Run: yjd2y3xb with config:
wandb: 	actor_learning_rate: 0.0025920273218328145
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7886144074094098
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5329432375019683
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004346-yjd2y3xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjd2y3xb
wandb: uploading history steps 204-215, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▅▅▅▅▄▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▂▂▂▂▂▁▁▁▃▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇████▇▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▁▁▄▃▆▃▅▄▅▅▅▄▅▅▆▅▆▇▅▆▅▆▅██▆▆▇▆▇▇█▆██▆▇
wandb:      train/ensemble_f1 ▂▃▂▂▂▃▃▁▃▁▄▅▄▄▆▃▅▃▅▄▆▆▆▅▄▅▄▅▅▆▇▅▅▅▆▆█▆▇▇
wandb:         train/mil_loss █▇▆▆▇▆▇▄▆▆▄▆▆▃▅▅▆▄▃▅▅▃▄▂▄▃▄▃▃▃▁▂▃▂▃▄▃▂▃▄
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.23427
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.22017
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.89854
wandb:      test/avg_mil_loss 0.32944
wandb:       test/ensemble_f1 0.89854
wandb:           train/avg_f1 0.9062
wandb:      train/ensemble_f1 0.9062
wandb:         train/mil_loss 0.27756
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a03r0r7g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004043-a03r0r7g/logs
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▅▅▅▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄████
wandb:      eval/avg_mil_loss ███▇▇▃▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███████▆▆▆▃▃▁▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆▄▆▄▄▅▃█▂▅▄▂▁▃▃▄▆▄▇█▇▃▇▆▃▂▄▃▂▆▅▅▅▆▄▅▆▃
wandb:      train/ensemble_f1 ▃▃▄▅▄▄▄▁▄▅█▄█▅▅▄▅▅▂▆▃▅▅▄▅▇▄▇▆▆▄▄▃▂▅▆▆▅▆▆
wandb:         train/mil_loss ▄▆█▆▇▅▅▄▇▄▄▃▃▇▇▅▄▄▄▄▂▄▅▅▅▇▃▃▅▅▃▄▄▄▇▁▄▃▂▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.19623
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.91987
wandb:      eval/avg_mil_loss 0.17889
wandb:       eval/ensemble_f1 0.91987
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.24668
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.89357
wandb:      train/ensemble_f1 0.89357
wandb:         train/mil_loss 0.24542
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5zu9hjg3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004231-5zu9hjg3/logs
wandb: Agent Starting Run: stjbv8uf with config:
wandb: 	actor_learning_rate: 0.009192820035551656
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3756162456547708
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7356274342556062
wandb: Agent Starting Run: er3f175v with config:
wandb: 	actor_learning_rate: 1.4105960763554803e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17799078535601542
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8792682061374438
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004415-stjbv8uf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/stjbv8uf
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004416-er3f175v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/er3f175v
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▆███████████████████████
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▃▁▃▂▅▅▃▅▆▇▆▅▆▅▄▇▆▅▅▅▅▄▄▇▆▄▅▅▆▇▆▆▄███▇
wandb:      train/ensemble_f1 ▃▂▃▁▅▄▃▅▃▄▂▃▂▄▅▄▅▄▆▅▃▆▅▇▅▅▇▆▃▃▄▆▄▅▅▅▇▄▆█
wandb:         train/mil_loss █▅▆▄▇▆▆▅▅▅▇▆▄▃▃▇▅▅▇▂▆▆▃▅▄▁▃▃▃▄▅▄▁▅▃▃▃▂▁▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▇▅█▅▆█▇▆▆▇▇▆▇▆▇▆▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇▅▆▇▆▅▆▇▇▇▇▆█▆▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.2466
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.2333
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19933
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.89485
wandb:      train/ensemble_f1 0.89485
wandb:         train/mil_loss 0.30605
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xyowo2qh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004123-xyowo2qh/logs
wandb: Agent Starting Run: s55y08s3 with config:
wandb: 	actor_learning_rate: 0.00030496537423889983
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1433623405079257
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08599514074030379
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004505-s55y08s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s55y08s3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▄▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb:       eval/ensemble_f1 ████▃▂▂▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▅▆▆▅▃▆▄▇▅▆█▄▅▃▃▄▃▃▁▆▄▄▃▄▆▄▁▄▄▂▅▆▄▅▇▇▄
wandb:      train/ensemble_f1 ▆▇▆██▄▇▆▅▆█▅▅▄▇▄▅▃▇▅▇▅▃▅▇▆▃▅▅▅▄▃▆▁▄▂▆▅█▇
wandb:         train/mil_loss ▆▇▇▅▁▇▅▁▂▅▇▄▄▄▃█▂▅▁▄▇▆▅▄▄▆█▂▄█▂▄▂▃▂▅▄▃▄▇
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94999
wandb: best/eval_avg_mil_loss 0.13615
wandb:  best/eval_ensemble_f1 0.94999
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.26439
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.17673
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.89455
wandb:      train/ensemble_f1 0.89455
wandb:         train/mil_loss 0.21898
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjd2y3xb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004346-yjd2y3xb/logs
wandb: Agent Starting Run: huwk27uo with config:
wandb: 	actor_learning_rate: 0.000936006302977194
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9811076027368192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7229381117521828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004531-huwk27uo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huwk27uo
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████████▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ███████████████████████████████████▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▅▆▆▄▃▇▄▅▄▄▄▅▅▃█▇▂▃▂▆▇▃▁▆▆▅▅▃▃██▃▅█▆▂▅▃
wandb:      train/ensemble_f1 █▆▃▃▃▃▂▂▃▅▄▆▂▇▆▂▂▂▆▄▄▂▅▃▅▅▂▄▂▇▇▂▄▇▄▁▇▃▄▂
wandb:         train/mil_loss ▄▁▅▂▇▃▄▄▅▅▅▁▃▁▆▂▁▄▃▅▄▄▄▃▃▄▃█▆▄▄▄▃▁▅▄▇▂█▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▇▆▆▆█▆█▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.36765
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.34402
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.16595
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.8683
wandb:      train/ensemble_f1 0.8683
wandb:         train/mil_loss 0.29414
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/stjbv8uf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004415-stjbv8uf/logs
wandb: Agent Starting Run: qse63iwu with config:
wandb: 	actor_learning_rate: 0.005504178573117197
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7942827544804404
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25619705685053273
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004558-qse63iwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qse63iwu
wandb: uploading history steps 95-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇████▇███▇▇▅▅▅▅▅▅▅▅▅▃▃▃▂▂▁▁▁▁▁▁▂▂▂▂▂▃▅
wandb:      eval/avg_mil_loss ▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁█▇▇▆▆▆▆▆▆▆▇████▆▆▆▆▆▅▅▅▅▄
wandb:       eval/ensemble_f1 ▇▇▇▇█▇███▇▇▇▇▇▅▅▅▅▅▅▄▄▄▄▄▃▃▂▂▂▁▁▂▂▂▃▃▃▃▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▆▃▅▁▃▃▃█▅▄▄▆▃█▁▃▆▆▆▄▅▅▅▅▄▅▇▅▆█▇▅▃▆▇▅▇
wandb:      train/ensemble_f1 ▁▄▂▃▇▃▂▃█▅▄▄▆▄▃▃▂▃▆▄▄▄▅▂▆▄▇▄▅▅▂█▇▅▆▃▅▆▆▄
wandb:         train/mil_loss ▆▆██▆▆▆▅▄▅▅▄▇▆▆▁▇▇▆▆▅▅▃▆▄▂▃▅▃▄▃▅▄▃▂▄▃▅▄▃
wandb:      train/policy_loss ███████████▅███████████████████████████▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▆▆▆▆▁▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76655
wandb: best/eval_avg_mil_loss 0.64973
wandb:  best/eval_ensemble_f1 0.76655
wandb:            eval/avg_f1 0.73034
wandb:      eval/avg_mil_loss 0.65311
wandb:       eval/ensemble_f1 0.73034
wandb:            test/avg_f1 0.625
wandb:      test/avg_mil_loss 1.05401
wandb:       test/ensemble_f1 0.625
wandb:           train/avg_f1 0.65492
wandb:      train/ensemble_f1 0.65492
wandb:         train/mil_loss 0.63717
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/er3f175v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004416-er3f175v/logs
wandb: Agent Starting Run: zoy7nd8y with config:
wandb: 	actor_learning_rate: 1.3020200114163956e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.005271106966261652
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4572205275835577
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004605-zoy7nd8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zoy7nd8y
wandb: uploading history steps 107-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅██▅▅▅▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████
wandb:      eval/avg_mil_loss ▆▅▅▅▅▇▆▇▇██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅██▅▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▄▂▂▃▁▃▃▃▅▅▁▆▄▄▄▄▄▄▆▃▅▆▅█▃▆▄▆▂▂▅▄▄▄▅██
wandb:      train/ensemble_f1 ▂▂▅▂▂▅▂▃▄▁▃▂▃▅▃▄▃▆▂▃▅▅▆█▄▄▂▅▅▄▄▂▅▄▂▄▅▅▁▄
wandb:         train/mil_loss ▃▄▁▃▄▅▄█▃▁▄▇▄█▄▅▆▆▆▆▃▄▃▃▅▅▂▅▃▃▄▅▆▅▇▄▃▂▃▁
wandb:      train/policy_loss ▁▁▂▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▂▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 4.71169
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 4.6308
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 5.33242
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.492
wandb:      train/ensemble_f1 0.492
wandb:         train/mil_loss 3.22102
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s55y08s3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004505-s55y08s3/logs
wandb: Agent Starting Run: cgqjuyuo with config:
wandb: 	actor_learning_rate: 7.353094390107869e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3383984768200392
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5021052088589377
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004704-cgqjuyuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgqjuyuo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄█▅▅▆▅▄█▇▆▆▆▇▅▆▄▄▆▄▆▄▅▆▅▄▃▃▆▃▄▄▄▅▃▂▃▃▁▄
wandb:      train/ensemble_f1 ▆▆█▅▅▅▄▄▁▅▃▅█▆▆▃▆▆▄▇▅▆▃▅▆▅▃▆▅▄▂▃▆▄▄▅▂▂▂▄
wandb:         train/mil_loss ▃▄▅▄▅█▄▄▄▃▃▆▅▅▅▃▄▄▂▅▃▆▄▅▅▃▅▆▄▃▄▅▄▁▄▃▄▄▅▃
wandb:      train/policy_loss ▃▁▃▁▁▁▁▁▃▃▁▁▁▁▆▃▃▃▁█▃▁▃▁▁▁▃▁▁▁▆▁▁▁▁▁▁▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▁▃▁▁▁▃▃▁▁▃▁▃▃▃▁▃▆▃█▃▁▃▃▃▁▁▃▃▁▁▁▁▆▁▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.26223
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.31163
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.09639
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.90018
wandb:      train/ensemble_f1 0.90018
wandb:         train/mil_loss 0.21903
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huwk27uo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004531-huwk27uo/logs
wandb: Agent Starting Run: az8fdgl1 with config:
wandb: 	actor_learning_rate: 0.005407158595185001
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.968550124561801
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9682097223498064
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004714-az8fdgl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az8fdgl1
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▂▂▃▄▄▄▄▄▆▆▆▆▆▆▆▇▇▇████████████████
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▄▅▄▂▄▄▄▄▅▆▅▃▄▃▁▄▆▅▂█▅▃▅▄▄▄▅▃▁▆▄▆▄▇▃▅▅
wandb:      train/ensemble_f1 ▅▅▃▄▂▄▇▄▅▆▃▆▁▄▄▁▄▄▃▅▂▅▅▆▄▅▄▄▄▅▅▃▆▁▄▃▄▅▄█
wandb:         train/mil_loss ▅▅▅▅▃▄▆▅▅▅▃▅▄▄▆▄▇▃▃▃▆▅▅▆▅▅▃█▁▃▆▃▃▄▄▆▃▄▅▄
wandb:      train/policy_loss ▃▃▃▂▅▂▅▄▅▃▁▅▂███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▃▂▁▄▃█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.2689
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.29554
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.1602
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.92321
wandb:      train/ensemble_f1 0.92321
wandb:         train/mil_loss 0.25611
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qse63iwu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004558-qse63iwu/logs
wandb: Agent Starting Run: 92tia935 with config:
wandb: 	actor_learning_rate: 0.001395556053016378
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19272318602463445
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4834244523214832
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004742-92tia935
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92tia935
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▄▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▃▃▃▅▅▅▅▆▇▇▇▇▇▇▇▇███████▇▇▆▆▆▆▆▆▅▃▂▂▂
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▃▃▃▃▅▅▅▇▇▇▇▇▇██████████▇▇▇▆▆▆▆▆▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▃▃▂▃▃▅▅▅▄▅▅▅▅▆▆▄▅▅▆▆▆▆▆▆▅▆▅▇▆▆▆█▅▇█▆█
wandb:      train/ensemble_f1 ▄▅▁▃▂▂▃▃▃▃▅▄▄▃▅▅▅▅▅▆▅▆▇▆▆▆▅▇▇▅▆▇▇▆▆▆██▆▇
wandb:         train/mil_loss ▇█▆▅▅▆▆▅▅▃▅▄▆▄▅▅▃▃▄▁▃▃▃▃▂▃▃▄▃▂▁▂▄▃▁▁▁▂▄▂
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.2437
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.23909
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.89854
wandb:      test/avg_mil_loss 0.30118
wandb:       test/ensemble_f1 0.89854
wandb:           train/avg_f1 0.88496
wandb:      train/ensemble_f1 0.88496
wandb:         train/mil_loss 0.26912
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zoy7nd8y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004605-zoy7nd8y/logs
wandb: Agent Starting Run: ihlgktvf with config:
wandb: 	actor_learning_rate: 1.1089731153566795e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11394668139273378
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5937000667669822
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄█████████████▅███████████
wandb:      eval/avg_mil_loss ▁██▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄███████████████▅▅▅██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▃▄▂▅▄▂▃▅▃▂▅▅▅▅▃▇▄▅▄▁▄▄▂▂▂▃▄▄▂▄▆▇▂▆▄█▃
wandb:      train/ensemble_f1 ▄▄▇▃▁▁▅▇▂▃▆▃▄▅▃▆▆▅▄▃▄▆▅▄▅▄▅▅▃▇▅▅▇▅▇▅█▅▇▄
wandb:         train/mil_loss █▅▄▄█▄▅▆▂▄▄▅▅▂▄▆▄▆▅▅▆▅▄▂▄▃▄▃▅▃▅▄▆▁▅▂▄▃▃▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅█▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▇▇▇▇▇▇▂▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.26052
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.25792
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.13428
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.88992
wandb:      train/ensemble_f1 0.88992
wandb:         train/mil_loss 0.17892
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92tia935
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004742-92tia935/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004922-ihlgktvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ihlgktvf
wandb: Agent Starting Run: xirecwk3 with config:
wandb: 	actor_learning_rate: 1.9700282747678096e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24058855124455436
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7302983856149786
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004926-xirecwk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xirecwk3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▄█▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▄▄▄▄▂▂▁▇████▇▇▇▇▇▇▇▇▇▇▇███████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▄▄▄▄▄▃▅▆▇▇█▆▆▅▄▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▄▄▄▄▄▁▂▂▂▇▇██▇▇▇▇▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▄▇▆▃▂▆▂▁▁▄▄▂▇▂▂▄▂▅▃▂▄▆█▆▅▂█▆▄▂▅▆▃▃▅▄▇▃
wandb:      train/ensemble_f1 █▆▆▇▄▅▆▆▅▃▆▅▃▁▄▃▂▄▃▆▃▆▄▅▆▅▅▅▃▅▃▄▃▅▆▆▅▂▄▅
wandb:         train/mil_loss ▇▅▅▂█▂▇▄▄▅▆▄▆▃█▆▆▄▂▂▇▇▇▅▇▁▇▂▇▃▄▃▄▃▅▆▄▆▃▄
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▅▅▁▅▁█▁▁▁▇▂▂▂▁▂▁▁▁▁▂▁██▇█▁▁▁▁▁▁▁▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.17623
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.18772
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.1057
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.91498
wandb:      train/ensemble_f1 0.91498
wandb:         train/mil_loss 0.25411
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az8fdgl1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004714-az8fdgl1/logs
wandb: Agent Starting Run: frvxkolz with config:
wandb: 	actor_learning_rate: 0.0010879934678180196
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.813739472807008
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9918778586458806
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_004928-frvxkolz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frvxkolz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▂▅▅▅▆▆▇▇█▇▇▇█████████▇█████████
wandb:       eval/ensemble_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▅▅▅██▃▄▅▆▆▆▅▅▆▅▇▄▅▆▄▅▅▄▅▅▆▆▃▅▂▅▄▇▅▄▆▁
wandb:      train/ensemble_f1 ▇▅▆█▇▄▆▃▄▄▅▅▆▅▄▅▄▆▆▅▅▂▂▄▃▄▅▄▃▅▅▄▁▅▄▅▄▃▄▄
wandb:         train/mil_loss ▄▅▄▄▄▄▂▃▂▅█▂▃▃▅▃▆▇▆▃▁▂▃▅▅▃▅▄▅▃▄▅▂▇▄▃▃▅▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.34034
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.36373
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.89275
wandb:      test/avg_mil_loss 0.15895
wandb:       test/ensemble_f1 0.89275
wandb:           train/avg_f1 0.87179
wandb:      train/ensemble_f1 0.87179
wandb:         train/mil_loss 0.25562
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frvxkolz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004928-frvxkolz/logs
wandb: Agent Starting Run: 5uqn5ppr with config:
wandb: 	actor_learning_rate: 1.2482015139953046e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9972762721908596
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8911176913891256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005112-5uqn5ppr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5uqn5ppr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ▅█▇▆▅▅▃▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▃▃▄▄▃▃▃▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss ▆▆████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▃▃▃▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▃▃▃▃▂▄▃▄▃▃▄▅▅▅▅▅▆▅▆▇▇▇█▅▇▆▆▇█▆█▇█▆▇
wandb:      train/ensemble_f1 ▁▁▁▂▂▂▂▃▂▂▂▂▂▃▃▄▃▃▄▃▃▅▅▆▅▅▅▅▅▅▇▇█▇▇▇▇█▇▇
wandb:         train/mil_loss ▆▄▄▂▅▅▇▃▄▇▂▃▅▃▃▃▄▂▃▆▁█▆▅▃▄▆▄█▅▄▂▅▂▂▂▃▁▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 4.23536
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 4.07699
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 5.03402
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.52
wandb:      train/ensemble_f1 0.52
wandb:         train/mil_loss 1.92347
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgqjuyuo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004704-cgqjuyuo/logs
wandb: Agent Starting Run: g984laii with config:
wandb: 	actor_learning_rate: 5.915565627483118e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5991774566089015
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2545242799634725
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005148-g984laii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g984laii
wandb: uploading history steps 250-251, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅▆█
wandb: best/eval_avg_mil_loss ██▅▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▆▆▆██████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▃▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▄▆▆▄▆▇▂▄▁▇▄▃█▁▇▆▆▇▅█▄▄▅▃▆▇█▅▆▃▅▇▅▅▇▅▄▆
wandb:      train/ensemble_f1 ▆▄▅▅▄▃▆▆▄▃▁▆▅▃▅▆▇▅▅▇▆▆▇▅█▄▇▄▃▅▆▆▅▆▆▆▅▄▆▆
wandb:         train/mil_loss ▇▃▅█▅▅▆▁▇▄▅▄▄▅▄▄▃▁▅▆▆▄▄▃▅▅▃▆▃▂▆▃▆▇▅▃▂▂▆▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.22551
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.21854
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.12436
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.90232
wandb:      train/ensemble_f1 0.90232
wandb:         train/mil_loss 0.25688
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xirecwk3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004926-xirecwk3/logs
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▄▅▆▆▆▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃█▃▆▅▂▆▇▁▇▇▅▆▆▄▂▅▆▄▅▄▆▃▅█▂▂▄▄▆▆▆▆▆▂▅▅▅▆
wandb:      train/ensemble_f1 ▆▃▅▃▅▇▅▆█▁▆▄▄▂▅▂▂█▆▄▇▅▆▄▅▇▅▅▂▁▆▃▆▅▄▄▄▂▄▅
wandb:         train/mil_loss ▆▆▆▅▆▅▅▅▆▆▄▆▅▆▅█▄▅▇█▆▆▃▅▅▄▆▅▇▇▁▄▇▇▅▅▃▃▄▃
wandb:      train/policy_loss ▃▇▄█▆▄▇█▄▇▄▇▅▄▄▅▄▂▄▅▅▄▄▃▄▅▆▂▅▄▄▅▃▁▄▇▃▆▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▃▆▅▃▂▃▅▅▆▄▁▄▄▂▁▅▄▃▄▂▄▃▄▂▄▄▂▅▂▄▃▄▅▅▂▅▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.22556
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.2415
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.15651
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.88582
wandb:      train/ensemble_f1 0.88582
wandb:         train/mil_loss 0.2506
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g984laii
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005148-g984laii/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: czvte9r7 with config:
wandb: 	actor_learning_rate: 8.117494905092311e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7750816632844307
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3401573503640778
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005337-czvte9r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czvte9r7
wandb: Job received.
wandb: Agent Starting Run: 15wnqs0s with config:
wandb: 	actor_learning_rate: 0.009592383431734975
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6331766141555546
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4019552403073392
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005340-15wnqs0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15wnqs0s
wandb: uploading history steps 170-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▆█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▁▆█
wandb:            eval/avg_f1 ▄▄▁▁▁▁▂▂▄▄▄▄▇▇▇▇▇▇▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:      eval/avg_mil_loss ██▇▇█▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▁▁▁▁▁▁▁▁▁▂▂▂▂▄▇▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▂▃▁▃▃▂▄▄▅▃▅▅▆▅▄▆▅▃▅▆▃▅▆▅▇▆██▅▇▅▇▆▅▅▇▄
wandb:      train/ensemble_f1 ▂▃▃▁▁▂▃▂▃▄▃▅▂▅▇▄▄▅▅▄▃▄▇▅▄▇▄█▇▅▄▇▇▅▇█▅▆▆█
wandb:         train/mil_loss ▆▆▄▅▇▃▃▃▇▄▃▃▂▄▂▂▂█▃▇▅▄▁▁▃▅▃▃▅▄▄▆▅▄▅▄▄▃▃▄
wandb:      train/policy_loss ▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.50169
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.47146
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.72867
wandb:      test/avg_mil_loss 0.83322
wandb:       test/ensemble_f1 0.72867
wandb:           train/avg_f1 0.73895
wandb:      train/ensemble_f1 0.73895
wandb:         train/mil_loss 0.23688
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5uqn5ppr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005112-5uqn5ppr/logs
wandb: Agent Starting Run: ga6i39xx with config:
wandb: 	actor_learning_rate: 0.009932162179563282
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7806312103377111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8527591515126367
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005408-ga6i39xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ga6i39xx
wandb: uploading history steps 334-344, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▇█
wandb: best/eval_avg_mil_loss █▆▄▄▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▄▅▅▅▅▅▅▅▅▇▇████▇▇▇██
wandb:      eval/avg_mil_loss █▇▇▇▇▇██▇▇▇▆▆▆▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▄▄▅▅▅▅▅▅▅▅▇▇▇███▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▇▄▆▇▇█▃▆▇▆█▅▄▇▄▄▅█▆▃▆▇▄▅▄▄▆▅▄▁▆▆█▅▄▄▂▁
wandb:      train/ensemble_f1 ▄▃▃▆▅▅▅▇▅▅▅▄▇▆▅▅▆█▇▆▅▆▄▃▃▆▂▅▅▄▄▄▂▅▁▃▃▅▃▆
wandb:         train/mil_loss ▇█▆▆█▄▇▇▅▇▇▄▄▇▂▅▄▃▄▄▄▂▄▆▃▅▂▄▅▂▄▃▃▁▄▃▂▄▄▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▇█▅▅▅▁▁▅▅▅▅▅▅▅▂▁▁▅▅▅▅▅▅▁▃▂▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████▁██████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85978
wandb: best/eval_avg_mil_loss 0.275
wandb:  best/eval_ensemble_f1 0.85978
wandb:            eval/avg_f1 0.85978
wandb:      eval/avg_mil_loss 0.26707
wandb:       eval/ensemble_f1 0.85978
wandb:            test/avg_f1 0.82985
wandb:      test/avg_mil_loss 0.53862
wandb:       test/ensemble_f1 0.82985
wandb:           train/avg_f1 0.83419
wandb:      train/ensemble_f1 0.83419
wandb:         train/mil_loss 0.38527
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ihlgktvf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_004922-ihlgktvf/logs
wandb: Agent Starting Run: bicsl9ai with config:
wandb: 	actor_learning_rate: 1.1379638166472902e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7070932704822571
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9726017414919488
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005452-bicsl9ai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bicsl9ai
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▆▃▅▆▄▃▆▅▅▇▂█▄▆█▅▄▄▅▃▅█▂▅▅▅▅█▁▆▄▆▅▂▅▁
wandb:      train/ensemble_f1 ▅▃▅▂▄▅▃▅▆▃▇▇▅▅▆▄█▄█▅▇▃▆▂▅▅▆▄▆▅▃▆▇▇▁▇▁▇▆▃
wandb:         train/mil_loss ▇▇█▅▅▅▄▅▇▄▇▄▄▃▆▆▅▆▅▆▅▆▅▄▂▅▄▇▁▆▄▃▃▄▅▅▄▄▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.2268
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.23715
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.3926
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.89245
wandb:      train/ensemble_f1 0.89245
wandb:         train/mil_loss 0.26823
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czvte9r7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005337-czvte9r7/logs
wandb: Agent Starting Run: t4637w64 with config:
wandb: 	actor_learning_rate: 0.002247260448462
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7940319037039898
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6848000997070826
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005526-t4637w64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t4637w64
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇▇▇████
wandb: best/eval_avg_mil_loss █▆▄▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▁▇▇▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇
wandb:      eval/avg_mil_loss █████▆▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▁▇█████▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█
wandb:      train/ensemble_f1 ▂▁▁▆▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇█▇▇▇█▇
wandb:         train/mil_loss █▄█▅▃▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▃▂▃▂▂▁▂▂▂▁▃▂▂▂▂▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.1679
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.3008
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.92943
wandb:      test/avg_mil_loss 0.3276
wandb:       test/ensemble_f1 0.92943
wandb:           train/avg_f1 0.85958
wandb:      train/ensemble_f1 0.85958
wandb:         train/mil_loss 0.18976
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ga6i39xx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005408-ga6i39xx/logs
wandb: Agent Starting Run: fqnygc91 with config:
wandb: 	actor_learning_rate: 1.156588682247404e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3761955997733455
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.952783988629712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005618-fqnygc91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqnygc91
wandb: uploading history steps 172-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss █▇▅▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▃▃▅▅▅▅▅▅▅█████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▆▆▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▃▁▄▄▄▅▅▇▄▆█▆▆▆▆▇▇▇▆█▆▆▆▇▆▅▆▆▅▇██▅▇▄▆▆
wandb:      train/ensemble_f1 ▁▃▂▂▅▃▂▄▆▆▇▅▆█▆▆▆▇▅▇▅▆▅▅█▆▅▇▆▇▇▇▅█▅▇▆▆▇▆
wandb:         train/mil_loss ▇▃▃▅▇▆█▃▅▅▅▃▆▂▄▃▅▄▁▂▆▂▁▄▄▄▇▅▂▄▂▃▆▆█▄▃▅▃▅
wandb:      train/policy_loss ▇▇▅▁▃▅█▅▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55587
wandb: best/eval_avg_mil_loss 2.17656
wandb:  best/eval_ensemble_f1 0.55587
wandb:            eval/avg_f1 0.55587
wandb:      eval/avg_mil_loss 2.08083
wandb:       eval/ensemble_f1 0.55587
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.68102
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.54906
wandb:      train/ensemble_f1 0.54906
wandb:         train/mil_loss 0.99088
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15wnqs0s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005340-15wnqs0s/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▇▇████████████████████████████████████
wandb:       eval/ensemble_f1 ██▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▄▂▃▁▂▁▁▁▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      train/ensemble_f1 ███▄▃▃▁▂▂▁▂▁▂▂▂▂▁▂▂▁▂▁▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/mil_loss ▁▂▁▂▄▃▄▄▁▆▄▅▁█▃▅▆▃▄▄█▆▄▅▅▁▂▄▅▃▅▄▄▇▆▁▃▄▃▄
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67839
wandb: best/eval_avg_mil_loss 1.57635
wandb:  best/eval_ensemble_f1 0.67839
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 5.04221
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.70645
wandb:      test/avg_mil_loss 2.13923
wandb:       test/ensemble_f1 0.70645
wandb:           train/avg_f1 0.43967
wandb:      train/ensemble_f1 0.43967
wandb:         train/mil_loss 0.70049
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t4637w64
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005526-t4637w64/logs
wandb: Job received.
wandb: Agent Starting Run: 993kuesm with config:
wandb: 	actor_learning_rate: 0.0021492230658484005
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10417176670118412
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9379102609045884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005710-993kuesm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/993kuesm
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wj952zmt with config:
wandb: 	actor_learning_rate: 0.0001032540650695348
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2007269334059575
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13539368180055333
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005720-wj952zmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj952zmt
wandb: uploading history steps 32-46, summary
wandb: uploading history steps 47-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁█▁▁███████████████▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 █▁▁▁▁███████████▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▄▃▆▅▃▄▃▃▃▃▁▃▆▄▅▂▅▃▄▅▅▄▅▄▅▆▃▆▅▆▅▅▅▆▆█▆
wandb:      train/ensemble_f1 ▅▃▄▃▆▆▄▁▃▁▅▂▃▆▅▄▂▂▃▄▇▆▅▂▅▅▄▆▆▅█▆▅▅▄▅▆▇▇▃
wandb:         train/mil_loss ▅▅▅█▆▅▆▄▅▆▄▆▂▄▄▄▅▂▂▁▃▅▁▅▄▄▄▄▂▄▃▃▅▆▃▅▄▄▃▆
wandb:      train/policy_loss █▁▃██▅▅▄▃▄▆▇▄▅▁▄▃█▆▃▆▅█▁████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃███▄▄▆▇▆▆▆▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85632
wandb: best/eval_avg_mil_loss 0.50247
wandb:  best/eval_ensemble_f1 0.85632
wandb:            eval/avg_f1 0.84655
wandb:      eval/avg_mil_loss 0.40841
wandb:       eval/ensemble_f1 0.84655
wandb:            test/avg_f1 0.72669
wandb:      test/avg_mil_loss 1.0295
wandb:       test/ensemble_f1 0.72669
wandb:           train/avg_f1 0.7531
wandb:      train/ensemble_f1 0.7531
wandb:         train/mil_loss 0.56766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqnygc91
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005618-fqnygc91/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▅▅▅▄▃▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▃▄▄▅▆▆▆▆▆▆▆▆▇██████████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▄▄▄▄▄▅▆▆▆▆▆▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▄▂▃▃▃▃▃▅▄▄▆▆▄▆▅▆█▆▆▇▆▆▇▇▆▆▇▆▆▇▇▇▇▇▆█▇
wandb:      train/ensemble_f1 ▁▁▂▂▂▂▃▃▂▆▅▆▆▆▆▇▅▅▅▇▅▆█▆▆▇▆▅▇▇██▇▆██▇██▇
wandb:         train/mil_loss █▆▅▆▆▄▄▆▆▄█▅▆▅▃▄▆▄▃▇▆▄▄▅▇▄▄▂▃▄▁▃▅▂▄▅▄▃▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.23193
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.21412
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.89854
wandb:      test/avg_mil_loss 0.3355
wandb:       test/ensemble_f1 0.89854
wandb:           train/avg_f1 0.87741
wandb:      train/ensemble_f1 0.87741
wandb:         train/mil_loss 0.263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bicsl9ai
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005452-bicsl9ai/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r18spi64 with config:
wandb: 	actor_learning_rate: 1.4015567857476684e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.020192187739513145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14900190347250053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005848-r18spi64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r18spi64
wandb: Job received.
wandb: Agent Starting Run: qzscdy7o with config:
wandb: 	actor_learning_rate: 1.3468386575958894e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.661425028658567
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4141292897794162
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005852-qzscdy7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzscdy7o
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▄▄▃▃▆▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▅▅▄▅█▄▄▄▄▂▂▂▁▆▆▆▆▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▆▇▇▅▆▆▃▄▇▃▇▇▄▄▆▅▆▄▄▅▆▅▅▄▃▁▅█▄▅▄▅▆▅▅▅▄
wandb:      train/ensemble_f1 ▄▆█▅▃▁▇█▆▆▆▆▇▂▅▅▄▅▄▅▆▆▆▆▄▅▃▅▆▇▄▆▆▆▅▆▅▄▆▄
wandb:         train/mil_loss ▃▁▄▃▄▃▂▃▂▅▄▂▅▄▂▅▂▆▅▃▄▂▃▄▃▂▂▂▂▁▃▃█▂▃▅▅▆▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.23683
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.23622
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.23118
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.8773
wandb:      train/ensemble_f1 0.8773
wandb:         train/mil_loss 0.29456
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj952zmt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005720-wj952zmt/logs
wandb: Agent Starting Run: z3v00ci4 with config:
wandb: 	actor_learning_rate: 0.002855993323451595
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14265355347856468
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20915347221853797
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_005939-z3v00ci4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z3v00ci4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▃▃▁▇▆▅▄▃█▇▇▆▆▆▅▄▄▃▂▇▆▆▆▅▅▅▃▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▃▅▆▇▄▆▃▇▃▃▁▃▁▆▄▄▆█▃▇▅▁▄▅▇▅▅▅▇▄▂▇▆▅▄▄▆
wandb:      train/ensemble_f1 ▆▄▃▄▇▄▄▅▇▅▅▄▅▅▆▇█▅▄▅▄▄▁▆▅█▄▆▁▃▅▄▇▆▄▃▆▄▇▄
wandb:         train/mil_loss ▅▆▄▅▆█▆▆▁▇▆▆▆▅▅█▇▄▇▃▅▃▄▄▆▅▅▆▃▆▃▃█▄▆▆▅▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.36478
wandb: best/eval_avg_mil_loss 3.4238
wandb:  best/eval_ensemble_f1 0.36478
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 3.37461
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 3.58864
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.35309
wandb:      train/ensemble_f1 0.35309
wandb:         train/mil_loss 2.81565
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r18spi64
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005848-r18spi64/logs
wandb: Agent Starting Run: hqxfiwym with config:
wandb: 	actor_learning_rate: 1.1303636190465195e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.00467851402041819
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5985893886799744
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010031-hqxfiwym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hqxfiwym
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▃▃▃▄▃▄▄▄▄▄▅▅▅▅▅▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅█▄▆▆▂▅▄█▄▅▂▃▆▄▃▅▄▃▄▂▃▄▄▃█▄▅▄▆▅▆▅▇▁▃▆▄
wandb:      train/ensemble_f1 ▆▅▄▄▅▅▆▆▅▆▅▃▅▅▅█▅▄▅▄▆▅▃▆▁▇▄▄▆█▅▅▅▆▆▃▅▆▄▅
wandb:         train/mil_loss ▂▅▄▇▆▆▅▁▁█▂▄▃▄▃▇▄▅▂▆█▅▇▃▃▃▃▄▆▇▄█▅▃▃▅▄▆▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.2379
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.25492
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.0755
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.90918
wandb:      train/ensemble_f1 0.90918
wandb:         train/mil_loss 0.23181
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzscdy7o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005852-qzscdy7o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o364ioth with config:
wandb: 	actor_learning_rate: 6.979362005306952e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8286720239852914
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5463758890071133
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010046-o364ioth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o364ioth
wandb: uploading history steps 238-253
wandb: updating run config
wandb: updating run config; uploading history steps 90-103, summary
wandb: updating run config
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▅▅▅▁▁▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▁▂▂▂▁▁▁▂█▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃
wandb:       eval/ensemble_f1 █████▅▅▅▅▅▁█▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▂▄▅▃▅▁▂▅▄▄▅▆▄█▅▅▄▆▅▅▂▆▄▄▃▆▄▅▅▃▆▆▃▅▂▅▄
wandb:      train/ensemble_f1 ▅▁▄▃▅▄▃▄▅▄▁▆▄▄▆▄▅▇▁▂▃▄▇█▂█▃▅▅▅▅▆▇▃▅▂▂▄▆▄
wandb:         train/mil_loss ▄▇▆▄▄▄▅▅██▇▇▄▄▄▅▄▇▆▆▆▅▄▄▆▄▃▅▄▆▆▃▄▁▆▆▆▆▅▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄█▄▁▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁███████▄█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.20961
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.21381
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.2342
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.89621
wandb:      train/ensemble_f1 0.89621
wandb:         train/mil_loss 0.26115
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z3v00ci4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005939-z3v00ci4/logs
wandb: Sweep Agent: Waiting for job.
wandb: uploading history steps 254-266, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇▇█
wandb: best/eval_avg_mil_loss █▆▆▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▅▂▄▄▄▄▆▆▆▆▆▆████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▃▄▄▄▄▆▆▆▆▆▆▆▆▆▆███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▁▂▅▄▇▄▃▅▄▂▄▃▄▃▅▄▄▅▄▅▅▄▄▅▂▇▄▆█▅▄▄▇▆▆▅█
wandb:      train/ensemble_f1 ▄▅▃▃▂▅▂▄▃▆▂▁▄▄▅▆▅▅▅▅▃▃▆▇▄▆▆▅▇▆▇▇▄▄▅█▇█▇▅
wandb:         train/mil_loss ▆▅▅▄▆▇▅▄▇▇▇▆▇▆▆▅█▆▄▄▃▅▄▆▆▄▅▆▃▅▅▃▄▁▅▅▃▄▄▂
wandb:      train/policy_loss ████████▁▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄█▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57131
wandb: best/eval_avg_mil_loss 2.12152
wandb:  best/eval_ensemble_f1 0.57131
wandb:            eval/avg_f1 0.56342
wandb:      eval/avg_mil_loss 1.94246
wandb:       eval/ensemble_f1 0.56342
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 2.54752
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.60787
wandb:      train/ensemble_f1 0.60787
wandb:         train/mil_loss 1.2932
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/993kuesm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_005710-993kuesm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f4vuhrf8 with config:
wandb: 	actor_learning_rate: 0.0050196440277056895
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9804110995786776
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4925075917899782
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010226-f4vuhrf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4vuhrf8
wandb: Job received.
wandb: Agent Starting Run: krvle5r4 with config:
wandb: 	actor_learning_rate: 0.0023029720251263605
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2288362378422093
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6887307364673824
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010236-krvle5r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krvle5r4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████████
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄█▇▄▂▅▅▅▆▄▂▆▄▆▄▃▇▅▅▇▆▇▄▅▃▂▅▇▃▅▅▄▃▃▁▄▆▂▄
wandb:      train/ensemble_f1 ▄▁▄▂▅▅▃▅▂▅▅▂█▅▂▄▆▅▃▃▆▅▄▂▃▂▇▂▃▄▃▁▃▄▂▇▅▅▃▃
wandb:         train/mil_loss ▅▆▅▇▂▅▅▅▃▄▆▄▅▁▅▅▅▆▃▃█▅▅▄▄▄▄▅▅▇▃▅▂▄▆▃▂▆▂▅
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84998
wandb: best/eval_avg_mil_loss 0.416
wandb:  best/eval_ensemble_f1 0.84998
wandb:            eval/avg_f1 0.84998
wandb:      eval/avg_mil_loss 0.40935
wandb:       eval/ensemble_f1 0.84998
wandb:            test/avg_f1 0.87825
wandb:      test/avg_mil_loss 0.33604
wandb:       test/ensemble_f1 0.87825
wandb:           train/avg_f1 0.89125
wandb:      train/ensemble_f1 0.89125
wandb:         train/mil_loss 0.24601
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o364ioth
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010046-o364ioth/logs
wandb: Agent Starting Run: f0btaavn with config:
wandb: 	actor_learning_rate: 1.0310803783545837e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.274807427409527
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27494399463424424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010342-f0btaavn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f0btaavn
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▅▄▂▂▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▄▇████████████████████████████████
wandb:       eval/ensemble_f1 █████▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇████████▆▃▂▂▁▂▂▁▁▂▁▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▂▂▂▁▂
wandb:      train/ensemble_f1 █▇█████▆▅▂▂▁▂▁▁▂▁▁▁▂▂▁▁▂▁▂▁▂▁▂▁▂▁▁▂▁▁▂▁▁
wandb:         train/mil_loss ▄▂▄▃▄▄▃▅▃▆▄█▇▃▃▃▃█▃▃▅▂▅▃▄▂▁▃█▆▂▄▅▆▅▃▃▃▄▂
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78897
wandb: best/eval_avg_mil_loss 0.48794
wandb:  best/eval_ensemble_f1 0.78897
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.58689
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.56493
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.42709
wandb:      train/ensemble_f1 0.42709
wandb:         train/mil_loss 0.23888
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4vuhrf8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010226-f4vuhrf8/logs
wandb: Agent Starting Run: 8ojqdi8p with config:
wandb: 	actor_learning_rate: 0.009179148343924614
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2417310311394184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6726061233291735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010410-8ojqdi8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ojqdi8p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▆▆▅▄▃▂▁▂
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆███████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▄▄▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▁▁▂▃▃▂▄▂▃▃▃▄▄▄▄▅▅▃▅▅▄▄▅▆▅▅▅▆█▆▆▇▅▇▅▇▆
wandb:      train/ensemble_f1 ▂▃▂▃▂▁▄▃▄▃▃▃▃▂▄▅▄▆▅▆▆▆▆▅▄▅▅▄▅▆▇▅▆▆▆█▆▆▇▆
wandb:         train/mil_loss ▇█▇▇█▅▅▆▆▅▄▅▄▄▅▄▄▅▅▄▃▄▄▂▃▂▅▂▂▃▂▄▂▂▃▁▂▃▁▂
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▅███▆████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71429
wandb: best/eval_avg_mil_loss 1.70615
wandb:  best/eval_ensemble_f1 0.71429
wandb:            eval/avg_f1 0.71429
wandb:      eval/avg_mil_loss 1.53645
wandb:       eval/ensemble_f1 0.71429
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.39537
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.56016
wandb:      train/ensemble_f1 0.56016
wandb:         train/mil_loss 1.60202
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hqxfiwym
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010031-hqxfiwym/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: z2xxukau with config:
wandb: 	actor_learning_rate: 1.170573394629834e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2311921760524298
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6395424572216541
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010447-z2xxukau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2xxukau
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁█
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁█
wandb:            eval/avg_f1 ████████████▁▁▁▁██▁▁██████████▁▁▁▁▁▁▁███
wandb:      eval/avg_mil_loss █▇▇▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁██▁▁██████▁█▁▁▁▁▁▁▁▁█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▄▄▁▄▆▄▄▄▅▅▅▄▅▄▅▅▆▅▅▅▄▆▆▇█▅▇▇▆▆▆▇▆▅▆▆▇
wandb:      train/ensemble_f1 ▁▄▃▁▄▄▅▄▅▄▅▅██▆█▅▇█▇▆▅▇▇▅▇▇▆▇▇▇▆▆▅▅▅▇▇▇█
wandb:         train/mil_loss ▄█▆▆▇▄▅▅▅▅▄▄▃▄▄▄▄▄▃▂▁▂▂▄▄▃▄▂▃▄▂▂▂▃▃▂▁▃▅▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.21198
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.17487
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.42998
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.91371
wandb:      train/ensemble_f1 0.91371
wandb:         train/mil_loss 0.25194
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krvle5r4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010236-krvle5r4/logs
wandb: Agent Starting Run: 1sx6pelp with config:
wandb: 	actor_learning_rate: 0.00010120743677359904
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.46727340406167395
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1436998481818046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010551-1sx6pelp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1sx6pelp
wandb: uploading history steps 94-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆██████▆▆▆▆▆▆▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▃▃▃▃▃
wandb:      eval/avg_mil_loss ▆▆▆▆▆▅▄▄▄▄▃▃▃▂▃▂▁▁████▇▇▆▅▅▅▆▆▆▆▅▅▅▆▆▅▅▅
wandb:       eval/ensemble_f1 ▆▆████████▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇█▆▇▆█▇▇▅▇▆▅▆▃▆▃▄▂▃▃▄▅▂▃▁▄▂▄▅▅▃▃▄▃▅▂▂▂▅
wandb:      train/ensemble_f1 ▆▇▅▆█▇█▆▇▇▆▆█▆▇▆▅▇▅▅▃▁▃▂▁▂▄▄▅▅▅▄▁▂▇▆▅▂▁▅
wandb:         train/mil_loss ▃▄▃▅▄▆▄▄▇▅▆▂▄▅▄▁▅▁▄▃▃▆█▆▆▇▇▅▇▇▃▆▄▆▅▇▆▄▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71591
wandb: best/eval_avg_mil_loss 0.90124
wandb:  best/eval_ensemble_f1 0.71591
wandb:            eval/avg_f1 0.68286
wandb:      eval/avg_mil_loss 0.89639
wandb:       eval/ensemble_f1 0.68286
wandb:            test/avg_f1 0.8
wandb:      test/avg_mil_loss 0.89456
wandb:       test/ensemble_f1 0.8
wandb:           train/avg_f1 0.78256
wandb:      train/ensemble_f1 0.78256
wandb:         train/mil_loss 0.602
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ojqdi8p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010410-8ojqdi8p/logs
wandb: Agent Starting Run: p7p5yi5k with config:
wandb: 	actor_learning_rate: 0.0009552750175192212
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9958041885332806
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.008635931917664097
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010558-p7p5yi5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p7p5yi5k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁█▇▇▆▆▅▅▅▄▄▄▄▄▃▃▄▄▄▄▄▄▄▄▄▃▄▄▄▄▃▃▂▃▃▃▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▆▃▆▇▅▅▅▇▅▇▃▃▄▆▆▆▄▇▆▆▅▅▂▄▅▄▂█▃▆▄▁▇▃▇▅▄▇
wandb:      train/ensemble_f1 ▄▅▆▅▅▂▃█▆▃▅▆▇▂▁▅▃▆▄▆▂▃▂▅▄▄▃▄█▇▃▄▅▃▃▃▇▆▄█
wandb:         train/mil_loss ▅▃▂▆▃▆█▄▆▄▅▇▅▆▅█▃▁█▇▅▇▃▇▃▅▄▁▃▅▅▃▅▅▃▁▅▃▇▃
wandb:      train/policy_loss ▄▆▄▇▃▆▄▂▂▅▄▂▄▄▂▄▁▄▄▂▄█▆▄▆▄▆▂▄▃▃▇▆▆▃▄▄▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▇▄▃▅▆▇▄▅▂▄▂▄▁▅▆▄▂▃▆▇▄▅▄▅▃▅▇▅▃▄▃▅▆█▄▄▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.78496
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.79172
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.18502
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34372
wandb:      train/ensemble_f1 0.34372
wandb:         train/mil_loss 1.97894
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2xxukau
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010447-z2xxukau/logs
wandb: Agent Starting Run: jigtrs9x with config:
wandb: 	actor_learning_rate: 6.795399083632337e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6184104424562044
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9912231947937514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010627-jigtrs9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jigtrs9x
wandb: uploading history steps 170-178, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▁▁▁▁▁▁▅▅▅███████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▂▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▁▁▁▅▅▅▅▅▅▅▅▅██████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▆▁▄▆▅▅▃▃▅▆▃▇▄▃▅▅▇█▇▄▅▅▅▅▄▇▆▅▅▅▅▆▆▅▅▆▄
wandb:      train/ensemble_f1 ▄▃▃▁▄▅▅▄▅▃▄▅▅▂▃█▃▃▄▄▅▄▅▅▅▆▆▆▅▇▆▅▅▄▄▃▆▇▆▆
wandb:         train/mil_loss ▄▄▄▄▅▆▆▄▅▄▅▅▃▅▅▄▁▆▄▅▇▆▁▂█▂▃▃▇▄▃▆▃▂▄▂▂▄▂▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▂▂▂▁▁▂▂▆▆▇▇█▇▇▆▆▆█▇▇▆▇▆▇▇▇▆▇▇▇▇▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91971
wandb: best/eval_avg_mil_loss 0.21608
wandb:  best/eval_ensemble_f1 0.91971
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.20059
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.85994
wandb:      test/avg_mil_loss 0.37888
wandb:       test/ensemble_f1 0.85994
wandb:           train/avg_f1 0.8686
wandb:      train/ensemble_f1 0.8686
wandb:         train/mil_loss 0.29113
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f0btaavn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010342-f0btaavn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8476t5lo with config:
wandb: 	actor_learning_rate: 1.1734052559774165e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.48752632008305186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0697119546342646
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010708-8476t5lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8476t5lo
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▇▇▇▇▇▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▁▃▆▄▄▄▃▄▅▂█▄▆▂▅█▆▁▂▄▃▄▅▆▄▄▄▅▅▇▅▂▅▅▇▃▂
wandb:      train/ensemble_f1 ▅█▁▄▅▄▂▃▁▅▄▄▅▄▇▄▅▄▇▃▃▇▄▅▄▆▆▄▄▄▄▇▆▅▁▆▄▆█▃
wandb:         train/mil_loss ▃▄▁▄▃▄▃▃▄▇▂▄▅▅▄▄▃▆▄▄▅▆▂▅▄▄▄▃▄▄▃▆▃▄▃▃█▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.33919
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.32389
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.904
wandb:      test/avg_mil_loss 0.18084
wandb:       test/ensemble_f1 0.904
wandb:           train/avg_f1 0.86014
wandb:      train/ensemble_f1 0.86014
wandb:         train/mil_loss 0.31113
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1sx6pelp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010551-1sx6pelp/logs
wandb: Agent Starting Run: 5bt2uo82 with config:
wandb: 	actor_learning_rate: 0.004428346581134592
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2318315257696667
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7024964949510385
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010739-5bt2uo82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bt2uo82
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▆▅▅▂▄▁▅▆▄▅▄▇█▅▅▆▅▇▃▆▆▅▇▆▅▃▇▆▅▆▇▅▅▅█▇▇▆
wandb:      train/ensemble_f1 ▂▄▃▃▃▃▃▅▃▃▆▂█▄▄▄▄▆▄▃▅▄▄▆▄▄▄▃▂▅▃▆▁▅▅▂▅▃▅▄
wandb:         train/mil_loss ▇▅▆▅▃▃▅▅▅▃▄▇▂▅▄▆▅▄▄▅▂▄▄▆▅▃▃▂▆▁█▄▁▄▄▂▃▅▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.18904
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.20152
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.18895
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.88792
wandb:      train/ensemble_f1 0.88792
wandb:         train/mil_loss 0.28394
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jigtrs9x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010627-jigtrs9x/logs
wandb: Agent Starting Run: 0ncr91kr with config:
wandb: 	actor_learning_rate: 4.197337248712508e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10103547587778738
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3947178918755351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010811-0ncr91kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ncr91kr
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▅▆▇▇██████████████████████████████
wandb:       eval/ensemble_f1 █████▃▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▆▅▆▆▆█▃▂▁▂▂▂▁▂▃▃▂▂▂▂▃▂▂▂▃▃▃▄▃▅▄▃▄▃▄▄▆
wandb:      train/ensemble_f1 ▆▆█▆██▆▂▂▂▂▃▃▂▁▂▂▃▂▃▂▃▄▂▃▅▅▆▄▅▅▅▃▅▄▅▃▅▄▄
wandb:         train/mil_loss ▁▁▁▁▁▁▅▆██▅▇█▆█▅▇▅▆▆▇▆▇▇▅▆▇▆▆▆▆▅██▇▆▆▆▇▇
wandb:      train/policy_loss ██████████████████████████▁███████▂█████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46576
wandb: best/eval_avg_mil_loss 1.20352
wandb:  best/eval_ensemble_f1 0.46576
wandb:            eval/avg_f1 0.42827
wandb:      eval/avg_mil_loss 5.0842
wandb:       eval/ensemble_f1 0.42827
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 1.4451
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.39427
wandb:      train/ensemble_f1 0.39427
wandb:         train/mil_loss 3.65103
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bt2uo82
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010739-5bt2uo82/logs
wandb: Agent Starting Run: i0qsgtpd with config:
wandb: 	actor_learning_rate: 0.007959463399076331
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6148890654774686
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15880393822243932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_010930-i0qsgtpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i0qsgtpd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▄████▅▅▅▅▅▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ███████▇▁▁▁▂▂▂▂▂▂▂▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▄▄▄█████▅▅▅▅▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▃▅▃▅▄▂▆▄▃▄▄▆▇▄▅▅▄▅▄▅▅█▆▅▃▃▄▄▅▄▆▆▅▆▅▆▆
wandb:      train/ensemble_f1 ▃▂▁▁▃▁▂▁▃▆▄▅▂▄▅▁▄▂▆▄▃▃▄▄▁▃▅▁▄█▆▄▃▃▄▆▅▅▆▄
wandb:         train/mil_loss █▁▃▄▅▇▃▄▃▅▃▄▇▆▃▂▄▃▃▄▆▄▅▄▃▁▄▃▄▃▄▄▄▄▃▄▃▂▄▃
wandb:      train/policy_loss ███▇██████▇▇▁▂▂▁▁▁▄▄██▇█▇▇▇▇█████▆█▇██▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇█▇███▇██▇▁▁▂▂▁▅▅▅▅█▇█▇█▇█▇█▇▇██▆▆█▇█▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.15906
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.16087
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.27085
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.9059
wandb:      train/ensemble_f1 0.9059
wandb:         train/mil_loss 0.21915
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ncr91kr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010811-0ncr91kr/logs
wandb: Agent Starting Run: xj2ep8v6 with config:
wandb: 	actor_learning_rate: 0.0001632008108208528
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.553464122860872
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4810566887980381
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011020-xj2ep8v6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xj2ep8v6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅▆▇▇█
wandb: best/eval_avg_mil_loss ██▆▆▆▅▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▃▃▄▄▅▅▆▆▆▆▆▇▇▇▇▆▆▇▇██████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▄▄▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▆▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▂▂▂▃▄▄▄▄▃▄▃▃▆▆▆▅▆▆▆▅▇█▆█▇▆▇▆▇▇▆▇▆▇▆██
wandb:      train/ensemble_f1 ▃▂▁▁▃▂▃▂▃▃▃▂▆▄▅▅▆▆▇▅▇▆▆▅▆▇███▆▆▇▇▆▇▇▇▇▇▆
wandb:         train/mil_loss █▄▅▃▅▂▃▆▄▃▆▂▅▆▇▁▄▅▄▇▅▂▅▄▂▅▅▅▄▇▆▅▁▃▂▂▄▄▄▂
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56363
wandb: best/eval_avg_mil_loss 2.23241
wandb:  best/eval_ensemble_f1 0.56363
wandb:            eval/avg_f1 0.56363
wandb:      eval/avg_mil_loss 2.08023
wandb:       eval/ensemble_f1 0.56363
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.55667
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.49791
wandb:      train/ensemble_f1 0.49791
wandb:         train/mil_loss 0.77107
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8476t5lo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010708-8476t5lo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e2e68xw7 with config:
wandb: 	actor_learning_rate: 1.358517658509175e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2910720398207133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4578036771104368
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011040-e2e68xw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2e68xw7
wandb: uploading history steps 296-308, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▄▅▅▅▅▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▆▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▄▅▅▅▅▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▄▄▄▅▅▅▅▅▅▅▇▇▇▇█████████████████████
wandb:      eval/avg_mil_loss █▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▄▄▄▅▅▅▅▅▆▆▇▇██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▂▃▅▄▄▆▄▅▅▅▇▇▇▇▇▆▇▇▇▇█▆▇▇▇▇▇█▇▇██▇▆█▇█
wandb:      train/ensemble_f1 ▁▁▄▃▄▂▅▄▆▅▄▅▅▆▇▆▇▇▇▇██▆█▇█▇▇█▇▆▆█▇▇▆██▇█
wandb:         train/mil_loss █▆▅▆▂▁▆▄▅▆▅▃▃▁▃▆▇▄▄▃▄▄▇▅▅▄▆▅▅▆▄▄▂▅▃▂▅▁▄▄
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71492
wandb: best/eval_avg_mil_loss 0.50587
wandb:  best/eval_ensemble_f1 0.71492
wandb:            eval/avg_f1 0.70576
wandb:      eval/avg_mil_loss 0.5031
wandb:       eval/ensemble_f1 0.70576
wandb:            test/avg_f1 0.63054
wandb:      test/avg_mil_loss 0.64715
wandb:       test/ensemble_f1 0.63054
wandb:           train/avg_f1 0.62083
wandb:      train/ensemble_f1 0.62083
wandb:         train/mil_loss 0.25017
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p7p5yi5k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010558-p7p5yi5k/logs
wandb: Agent Starting Run: wnrs11j8 with config:
wandb: 	actor_learning_rate: 0.00015777255442294511
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8305177209729852
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.68846594239798
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011058-wnrs11j8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wnrs11j8
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▃▄▄▄▄▄▅▅▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇███████▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▅▆▂█▁▃▃▄▄▆▄▃▂▃▃▃▅▄▃▁▇▃▄▂▅▃▃▆▄▂▅▃▃▄▄▇▃▃
wandb:      train/ensemble_f1 ▅█▃▅▆▆▅▆▅▆▆▄▅▇▁▆▅▄▅▁▇▄▆█▆▄▃▆▄▅█▆▅▄▄▇▅▇▅▂
wandb:         train/mil_loss ▄▇▃▆▃▂▄▆▄▆█▅▇▄▄▁▅█▄▄▄▅▂▂█▇▄▂▆▅▂▃▆▁▄▄▂▄▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.2908
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.29638
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.904
wandb:      test/avg_mil_loss 0.19819
wandb:       test/ensemble_f1 0.904
wandb:           train/avg_f1 0.83298
wandb:      train/ensemble_f1 0.83298
wandb:         train/mil_loss 0.31479
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i0qsgtpd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_010930-i0qsgtpd/logs
wandb: Agent Starting Run: 37ff84nc with config:
wandb: 	actor_learning_rate: 1.5769141975959232e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39100927888135806
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4267805972038531
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011119-37ff84nc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ff84nc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▁▄▃██████▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▃▃▆▇▆▅▅▅▁▂▄▅▁▄▄▇▅▆▅▆▅▅▇█▅█▃▇▇▅▂█▆▆▆▇▄
wandb:      train/ensemble_f1 ▅▄▄▅▆▆▆▆▇▅▆▃▁▇▃▅▇▄▅▆▅▇▆▆▄█▅▇▆▅▅▅█▆▅▇▇▅▆▅
wandb:         train/mil_loss █▅▆▆▄▆▆▆▅▇▃▃▆▄▅▆▅▆▂▇▅█▅▆▃▃▂▁▄▅▄▄▁▃▆▄▃▄▆▅
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.27214
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.27693
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.89854
wandb:      test/avg_mil_loss 0.34626
wandb:       test/ensemble_f1 0.89854
wandb:           train/avg_f1 0.87363
wandb:      train/ensemble_f1 0.87363
wandb:         train/mil_loss 0.2943
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xj2ep8v6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011020-xj2ep8v6/logs
wandb: Agent Starting Run: 28auccha with config:
wandb: 	actor_learning_rate: 4.0900263379268134e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4023140146497305
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1899756449867389
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011204-28auccha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/28auccha
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁██████████████████████████████▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▄█▃▄▄▂▄▄▁▄▁▄▄▇▄▂▄▄▅▆▃▃▄▅▅▃▅▅▄▄▆▅▄▄▄▇▇
wandb:      train/ensemble_f1 ▂▃▄▃▁▄▆▃▇▆▂▃▂▃▂▄▄▄▃▃▆▂▁▆▂▃▁▆▄▁▃▄▄▄▅▃█▄▄▇
wandb:         train/mil_loss █▆▃▃▄▄▆▄▃▄▄▇▁▄▄▄▇▂▅▂▂▄▄▅█▃▃▂▄▃▇▄▃▃▅▃▅▄▂▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▃▅▅▅▅█▅▄▅▃▄▅▂▆▅▆▇▇▅▇▅▅▅▆▂▃▆▆▄▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▅▃▆▆▅▅▅▃█▅▆▄▃▃▂▇▅▇▇▇▅▂▃▆▄▅▇▅▆▅▆▄▄▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46082
wandb: best/eval_avg_mil_loss 3.0168
wandb:  best/eval_ensemble_f1 0.46082
wandb:            eval/avg_f1 0.44191
wandb:      eval/avg_mil_loss 2.92397
wandb:       eval/ensemble_f1 0.44191
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 3.54778
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.43391
wandb:      train/ensemble_f1 0.43391
wandb:         train/mil_loss 0.67527
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wnrs11j8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011058-wnrs11j8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c325rl9x with config:
wandb: 	actor_learning_rate: 0.0013728775502386845
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5504464883743467
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7458741365304504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011308-c325rl9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c325rl9x
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▂▂▂▂▁▄▄▄▇▄▇▇█████████████████▇▇▅▅
wandb:      eval/avg_mil_loss █▇▆▇▆█▆▆▆▅▅▄▇▇▇▆▆▅▅▅▄▄▄▃▂▃▂▂▂▂▁▁▂▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▁▁▁▃▃▆▃▃█████████████████▆▆▆▆▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▂▃▃▃▅▃▃▄▄▄▅▃▄▄▁▅█▅▄▆▆▅▆▇▄▆▆▆▅▅▄▅▅▇▆▆▆
wandb:      train/ensemble_f1 ▁▃▃▃▄▅▆▅▄▆▄▅▆▂▄▅▄▄▁▆▅▇▆▄▆▇▃▇▅▅██▄▄▅▆▆▅▅▇
wandb:         train/mil_loss █▅▃▅▃▄▆▃▅▆▁▄▂▄▄▄▄▃▂▂▃▄▄▃▄▄▃▅▅▂▂▄▄▃▃▄▃▁▁▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56363
wandb: best/eval_avg_mil_loss 1.27043
wandb:  best/eval_ensemble_f1 0.56363
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 1.18168
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 1.28334
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.57065
wandb:      train/ensemble_f1 0.57065
wandb:         train/mil_loss 0.73516
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2e68xw7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011040-e2e68xw7/logs
wandb: Agent Starting Run: 7n1jhgw9 with config:
wandb: 	actor_learning_rate: 0.0031919158563015445
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9195169255326624
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7923142608401813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011325-7n1jhgw9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7n1jhgw9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▄▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▃▄▄▄▅▅▅▅▄▆▆▆▆▆▆▇▇▇▇▇▇██████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▅▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▂▅▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▂▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▁▂▂▃▃▂▂▃▄▄▄▅▃▄▅▄▄▄▅▅▅▆▄▄▅▅▆▅▆▇▆▅▆▆▆█▇▆
wandb:      train/ensemble_f1 ▃▂▂▂▁▃▂▃▃▃▄▃▄▄▅▆▅▅▅▅▆▅▅▆▆▅▅▅▅▇▆▆▆▇█▇▇██▇
wandb:         train/mil_loss █▄█▇█▅▂▃▄▆▄▃▁▄▅▅▄▂▃▄▄▄▂▄▂▁▃▃▁▂▂▁▃▃▁▂▂▃▃▃
wandb:      train/policy_loss ▄▁▄▄▄▄▄▄▄█▂▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▇▄▄▄▄▄▄█▂▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 1.33538
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 1.45368
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 1.7302
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.5698
wandb:      train/ensemble_f1 0.5698
wandb:         train/mil_loss 0.85139
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ff84nc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011119-37ff84nc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3ccuz452 with config:
wandb: 	actor_learning_rate: 0.00028525629556603563
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7597731195150103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16590844475196995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011456-3ccuz452
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ccuz452
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▅▄▅▃▁▄▃▆▃▅▅▄▆▄▄▅▃▃▃▆▇▅▄▃▆▆▆▆▆▅▃▄▄▆█▅▄▅
wandb:      train/ensemble_f1 ▁▅▄▂▅▆▆▄▃▅▂▄▄▅▅▅▅▃▅▇▄▄▆▆▆▆▆▆▄▅▆▄▆▇█▄▆▆▃▇
wandb:         train/mil_loss ▅▅▆▅▄▆█▃▆▄▆▅▅▆▄▇▅▆▂▄▃▇▆▆▅▄▃▁▅▅▆█▄▇▃▄▅▆▇▂
wandb:      train/policy_loss ███████████████████████▁████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.19411
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.20121
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.92943
wandb:      test/avg_mil_loss 0.30336
wandb:       test/ensemble_f1 0.92943
wandb:           train/avg_f1 0.92248
wandb:      train/ensemble_f1 0.92248
wandb:         train/mil_loss 0.23732
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7n1jhgw9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011325-7n1jhgw9/logs
wandb: Agent Starting Run: 5bvyhtk6 with config:
wandb: 	actor_learning_rate: 0.0026195134350964085
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9666964413062832
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6159533757358301
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011556-5bvyhtk6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bvyhtk6
wandb: uploading history steps 204-219, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss █▅▇▆▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▂▃▃▃▃▃▄▄▄▄▄▄▄▆▆▆▆▇█████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆███▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▃▄▄▄▄▄▄▄▄▄▆▆▆▆▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▃▃▂▃▄▃▃▃▅▂▆▇▇▅▆▄▆▆▆▆▅▅▅█▇▆▅▆█▅▇▆▇█▄▇
wandb:      train/ensemble_f1 ▂▁▂▃▂▃▃▃▃▁▄▁▅▂▃▃▄▆▅▅▆▂▄▆▅▇▆▆▅▆▅▆█▆▇▇▇▆█▆
wandb:         train/mil_loss ▅▆▂▂█▃█▃▃▃▂▃▁▃▃▃▅▇▂▂▃▆▄▂▃▃▂▅▄▂▅▂▁▃▂▅▃▃▃▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.46454
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.31139
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.87203
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.47364
wandb:      train/ensemble_f1 0.47364
wandb:         train/mil_loss 0.51841
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c325rl9x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011308-c325rl9x/logs
wandb: Agent Starting Run: 9dz23u8w with config:
wandb: 	actor_learning_rate: 2.418312346839209e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1588109666705788
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14391378937445565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011645-9dz23u8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dz23u8w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▃▄▅▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▄▄▄▄▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▃▄▅▅▅▆▇▇█
wandb:            eval/avg_f1 ▂▂▂▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▄▄▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▃▃▅▄▅▄▅▅▅▅▅▇▇▇▆▇▇▇▆▆▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▄▄▄▄▅▄▄▅▄▅▆▅▄▆▅▅▆▆▇▆█▆▆▇▇█▇▇▇▇▇▆▆▇▇█
wandb:      train/ensemble_f1 ▁▂▂▄▂▄▄▃▃▄▅▄▅▅▃▆▅▅▆▇▆▆▇▆▆▆█▇▇▇▇▇▇▇▇▆▆▇▇▇
wandb:         train/mil_loss ▆▆▇█▅▅▃▃▅▃▅▃▃▄▄▃▂▃▂▂▃▃▅▂▁▃▃▂▂▂▂▃▃▂▁▃▁▂▁▃
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.25306
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.24598
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.28473
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.935
wandb:      train/ensemble_f1 0.935
wandb:         train/mil_loss 0.29219
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/28auccha
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011204-28auccha/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qtc230lv with config:
wandb: 	actor_learning_rate: 0.005372760575033463
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31802503048028774
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6392291756933304
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011707-qtc230lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qtc230lv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▅▁▁▁▃▃▃▃▅▆█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▃██████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▇▇▅▃▁▁▁▁▁▃▅███████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▂▂▂▂▂▂▂▂▃▁▁▂▃▄▄▃▄▄▄▃▃▄▄▂▃▄▃▂▅▂▃▃▅▃▄▄▄▄
wandb:      train/ensemble_f1 ▆▅▂▄▃▂▃▃▃▂▂▅▂▂▂▁▅▅▃▂▆▅▃▄▅▄▄▃▆▃▇▅▄▆█▅▆█▅▇
wandb:         train/mil_loss ▃▃▄▁▂▃▃▂▃▅▄▃▂▃▃▂▄█▆▄▃▅▆▂▄▄▅▂▅▄▆▁▂▄▂▅▂▃▃▂
wandb:      train/policy_loss ▆▆█▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50397
wandb: best/eval_avg_mil_loss 5.39731
wandb:  best/eval_ensemble_f1 0.50397
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 5.24077
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 6.20971
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.43723
wandb:      train/ensemble_f1 0.43723
wandb:         train/mil_loss 1.68006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ccuz452
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011456-3ccuz452/logs
wandb: Agent Starting Run: 69475yt3 with config:
wandb: 	actor_learning_rate: 0.003541993311884008
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.019289299497856516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7198935376076502
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011721-69475yt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69475yt3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▅▄▄▃▂▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▆▇▇██████████████████████████████
wandb:       eval/ensemble_f1 ██████▅▄▄▄▂▂▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▇▇▇▇█▄▂▁▂▁▁▁▂▁▂▂▂▂▂▂▂▂▂▃▂▃▂▂▃▃▂▃▃▂▂▂▄
wandb:      train/ensemble_f1 ▇▇▇▇▇█▄▄▂▂▁▁▁▁▁▂▂▁▃▂▁▁▂▂▃▂▃▂▂▃▃▂▃▂▂▃▂▃▃▄
wandb:         train/mil_loss ▂▁▂▂▂▂▁▂▂▂▇▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▆██▇
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63492
wandb: best/eval_avg_mil_loss 2.48322
wandb:  best/eval_ensemble_f1 0.63492
wandb:            eval/avg_f1 0.44191
wandb:      eval/avg_mil_loss 4.95602
wandb:       eval/ensemble_f1 0.44191
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 3.55797
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.47624
wandb:      train/ensemble_f1 0.47624
wandb:         train/mil_loss 4.08163
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69475yt3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011721-69475yt3/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▆▆▆▆▆▆▆▆▆█████████▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▅▆▁▄▃▄▅▅▇▄▄▆▄▄▆▄▄▄▆▄▅▄▅▄▆▅█▄▇▇▅▇▅▇▃▇▆▆
wandb:      train/ensemble_f1 ▄▂▂▃▁▁▄▄▄▃▄▄▆▆▆▅▆▅▅▄▇▆▅▇▇▆▇▅▆▇▄▅▇▄▇▇▅▄▅█
wandb:         train/mil_loss ▅▇▅▅▅▅▆▅▂▆▃▆▃▅█▄▁▂▃▂▄▃▃▄▁▅▃▂▄▄▄▃▁▅▂▇▂▃▅▄
wandb:      train/policy_loss ███████████▂▂▂▁▁▂▃▂▂████████▁▃▁▂▂▁▁▁▂▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.26139
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.26323
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.80983
wandb:      test/avg_mil_loss 0.6851
wandb:       test/ensemble_f1 0.80983
wandb:           train/avg_f1 0.84986
wandb:      train/ensemble_f1 0.84986
wandb:         train/mil_loss 0.27444
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bvyhtk6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011556-5bvyhtk6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: jstuo04j with config:
wandb: 	actor_learning_rate: 0.0017577181951423828
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9768111406273527
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9189378041342576
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011912-jstuo04j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jstuo04j
wandb: Job received.
wandb: Agent Starting Run: lcrmk93d with config:
wandb: 	actor_learning_rate: 7.047885452205002e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8710390695907443
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2630353834049254
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_011922-lcrmk93d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcrmk93d
wandb: uploading history steps 223-232, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▁█▅
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▄▁▁▁▆▆▇▆▆▆▆▆▆▆▆▆▆▇▇▇██████████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▇███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▆▁▁▂▃▃▄▅▅▆▆▇▇▇▆▆▆▆▆▇████████████▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▃▃▃▄▅▆▆▆▅▁▆▄▃▅▃▅▅▄▅▅▆▇▄▅▇▇▆▃█▄▇▅█▆▆▆
wandb:      train/ensemble_f1 ▇▁▃▄▃▂▃▅▂▅▄▆▆▇▅▇█▆▅█▄▅▄▇▅▇▃▆█▇█▇▆▅▇▇▇▆▇▇
wandb:         train/mil_loss ▁▄▇▇▆█▅▅▅▆█▅▅▇▄▅▄▆▄▇▄▄▆▅▆▅▆▃▅▅▅▄▁▇▅▂▆▄▄▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63235
wandb: best/eval_avg_mil_loss 1.10021
wandb:  best/eval_ensemble_f1 0.63235
wandb:            eval/avg_f1 0.61766
wandb:      eval/avg_mil_loss 0.95468
wandb:       eval/ensemble_f1 0.61766
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 1.77997
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.52464
wandb:      train/ensemble_f1 0.52464
wandb:         train/mil_loss 1.02357
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qtc230lv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011707-qtc230lv/logs
wandb: Agent Starting Run: ipgs70ao with config:
wandb: 	actor_learning_rate: 2.7747296434963992e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5267622654219228
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5503011861633728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012049-ipgs70ao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipgs70ao
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▄▄▄▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████
wandb:       eval/ensemble_f1 ███████████████▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▂▄▅▄▇█▂▄▃▆▃▄▄▄▃▄▅▄▆▁▁▁▄▂▁▃▆▅▃▁▆▂▄▅▅▄▃
wandb:      train/ensemble_f1 ▃▂▃▅▅█▆▄▄▃▁▅▄▃▅▄▃▄▂▂▄▁▁▂▄▄▃▅▆▆▁▃▇▁▆▅▄▃▅▅
wandb:         train/mil_loss █▄▅▄▅▅▆▇▅█▆▄▅▆▆▇▃▁▃▇▆▄▄▄▃▆▆▄▄▆▄▅▄▆▇▆▆▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▂▁▂▂▁▁▂▁▁▁▁▂▁▁▁▂▂▁▁▂▁▁▂▁▂▂▁▁██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.31088
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.35622
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.11328
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.89994
wandb:      train/ensemble_f1 0.89994
wandb:         train/mil_loss 0.21784
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jstuo04j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011912-jstuo04j/logs
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇█
wandb: best/eval_avg_mil_loss █▆▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▃▂▂▂▂▂▂▄▄▄▄▇▇▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇▇▇▅▇
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▃▃▃▃▂▂▄▄▄▄▄▄▅▇▇▇▇▇███████▇▇▇▇▇▇▇▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▃▄▃▅▄▅▅▄▅▅▅▆▄▆▄▅▅▅▆▆▇▆▆▇▇▇▇█▇▆▆██▇▇▇█
wandb:      train/ensemble_f1 ▂▂▂▁▃▃▃▂▄▅▅▅▄▅▄▄▃▅▅▄▅▅▄▆▅▇▇▇▆▆▅▆▆▆▆▅▇██▇
wandb:         train/mil_loss ▇█▄▆█▆▆▅▄▂▅▅█▃▄▅▄▅▄▅▇▄▅▃▅▃▄▄▄▅▅▆▄▅▄▃▁▄▄▁
wandb:      train/policy_loss ▄▄▄▄▄▆▇▇▇▄▄▄▄▄▄▄▁▂▇▇▇▇▇▇█▇▇▇▇▄▄▄▇▇▇▇██▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.41561
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.24279
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.79562
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.50256
wandb:      train/ensemble_f1 0.50256
wandb:         train/mil_loss 1.68229
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dz23u8w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011645-9dz23u8w/logs
wandb: Agent Starting Run: l9kta312 with config:
wandb: 	actor_learning_rate: 1.0004679641597917e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06738156185041133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20845050965083425
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012101-l9kta312
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l9kta312
wandb: Agent Starting Run: 0g63lzm4 with config:
wandb: 	actor_learning_rate: 0.009213433120476825
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.219150630792156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5503497434516172
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012104-0g63lzm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0g63lzm4
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▆▆▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████
wandb:       eval/ensemble_f1 ██▆▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄█▅▅▅▇▂▅▆▄▅▄▅▃▅▅▃▆▄▆▂▃▁▃▆▄▅▄▄▅▅▃▅▅▅▃▆▃▃
wandb:      train/ensemble_f1 ▅▅▂▇▇▆▅▆▆▄▄▅▇▇█▇▆▆▄▄▆▁▇▃▄▁▃▅▇▇▅▄▅▆█▃▄▇▃▅
wandb:         train/mil_loss ▇▄▇▄▅▅▃▃▂▇▆▆▂▇▇▅▅▅▆▃▂▆▄▃▄▂▆█▆█▄▄▄▁▃▂█▄▂▆
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.30127
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.33308
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.17044
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.87638
wandb:      train/ensemble_f1 0.87638
wandb:         train/mil_loss 0.26269
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcrmk93d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_011922-lcrmk93d/logs
wandb: Agent Starting Run: ad0x1zre with config:
wandb: 	actor_learning_rate: 0.00013786769897337342
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.971782495738688
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40495501106750176
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012110-ad0x1zre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ad0x1zre
wandb: uploading history steps 96-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄███
wandb:      eval/avg_mil_loss ▂▂▂▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▅▅▅▅▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▄▇▇▃▅▆▅▄▆▇▅▄▄▂▆▃▆▄▆▃▂▆▄▁▆▃▅▅▄▆▅▄▄▁▅█▂
wandb:      train/ensemble_f1 ▄▃▇▃▇▆▂▄▆▄▆▃▄▄▂▅▂▂▄▄▃▂▆▇▅▁▄▁▃▂█▂▄▆▅▆▁▅█▂
wandb:         train/mil_loss ▇▄▄▄▇▆█▅▅▃▃▅▄▁▃▅█▅▂▅▂▄▄▃▁▅▅▅▅▄▄▅▃▄▄▅▄▅▄▂
wandb:      train/policy_loss ▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.19491
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.20553
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.2617
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88875
wandb:      train/ensemble_f1 0.88875
wandb:         train/mil_loss 0.2462
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipgs70ao
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012049-ipgs70ao/logs
wandb: Agent Starting Run: oaf6ih2m with config:
wandb: 	actor_learning_rate: 2.0021646995445728e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4635979661778534
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8948983547329911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012238-oaf6ih2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oaf6ih2m
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃▇▂▂▃▄▅▃▁▄▄█▁▅▄▆▄▆▅▄▃▅▃▂▃▄▂▆▃▃▄▂▅▅▄▄▂▃
wandb:      train/ensemble_f1 ▆█▂▄▃▂▄▇▆▅▆▂▅▅▃▇▇▅▅▆▅▇▄▇▇▆▃▄▅▃▁▃▄▄██▃▇▇▆
wandb:         train/mil_loss ▆▄▆▃█▃▅▂▄▅▂▇▅▆▇▂▄▃▄▅▃▃▄▅▃▂▄▂▄▅▂▂▄▁▅▂▄▆▃▃
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.22774
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.21087
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.104
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.92999
wandb:      train/ensemble_f1 0.92999
wandb:         train/mil_loss 0.17479
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l9kta312
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012101-l9kta312/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: j6bwi8q2 with config:
wandb: 	actor_learning_rate: 1.2577252018613908e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7804411862635156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5287195013603507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012255-j6bwi8q2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6bwi8q2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 █████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▃▃▃▃▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▄▅▆▆▅▅██▆▆▅▅█▄▅▃▆▆▃▃▆▇▇▅▄▄▅▄▄▃▆▅▁▅▄▅▇▂
wandb:      train/ensemble_f1 ▅█▇▆▆▅█▆▅▃▅▅▃▆▃▃▄▆▃▇▃▅▃▄▅▆▃▂▆▅▆▁▆▆▂▅▅▂█▄
wandb:         train/mil_loss █▅▅▅▄▁▂▆▆▄▇▄▂▃▃▅▃▃▅▄▄▄▄▃▃▂▂▄▂▃▇▃▁▁▃▆▄▃▂▄
wandb:      train/policy_loss █████████████████████████████████▁██████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▂▁▂▁▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.25523
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.8164
wandb:      eval/avg_mil_loss 0.29567
wandb:       eval/ensemble_f1 0.8164
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18815
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.85383
wandb:      train/ensemble_f1 0.85383
wandb:         train/mil_loss 0.29718
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ad0x1zre
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012110-ad0x1zre/logs
wandb: Agent Starting Run: ezkfehdm with config:
wandb: 	actor_learning_rate: 0.0001043051867991607
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8937459799745537
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8467067649640696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012259-ezkfehdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ezkfehdm
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅█▆▇▅▆▇▃▆▄▅▆▃▆█▅▆▆▅▅▅█▄▄▃▆▄█▄▅▆▁▄▄▄▃▃▇
wandb:      train/ensemble_f1 ▅▅▅▄▅█▅▅▄▅▆▃▅▅▄▄▅▆▅▅▃▃▃▆▃▅▅▂▄▄▁▃▃▃▃▃▃▂▆▅
wandb:         train/mil_loss ▄▄▄▄█▃▄▄▃▄▂▂▇▅▅▆▄▃▃▃▄▄▂▄▆▄▂▁▂▅▂▂▃▄▄▃▃▂▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.27263
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.31035
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.1945
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.86425
wandb:      train/ensemble_f1 0.86425
wandb:         train/mil_loss 0.27585
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ezkfehdm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012259-ezkfehdm/logs
wandb: Sweep Agent: Waiting for job.
wandb: uploading history steps 108-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▅▅▅▅▅▅▅▅▅██████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▅▅▄▃▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▅▅▅█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▃▁▃▃▂▃▁▁▄▄▃▃▃▄▅▃▆▆▅▇▅▅▆▂▄▆▂█▄▇▆▅▇▆▆▄▅
wandb:      train/ensemble_f1 ▁▂▂▃▂▁▂▃▃▂▂▂▁▁▃▃▆▄▅▃▃▄▅▅▆▄▆▆▅██▄▅▄█▅▇▇▄▅
wandb:         train/mil_loss ▅▅▇▄▄▅▃▃▄▆▅▃▅▅▃▇▆▅▄▃▄▄█▇▃▄▂▅▂▇▁▃▃▄▃▂▁▄▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56363
wandb: best/eval_avg_mil_loss 2.0136
wandb:  best/eval_ensemble_f1 0.56363
wandb:            eval/avg_f1 0.56363
wandb:      eval/avg_mil_loss 1.88537
wandb:       eval/ensemble_f1 0.56363
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.37457
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.50395
wandb:      train/ensemble_f1 0.50395
wandb:         train/mil_loss 0.37554
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6bwi8q2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012255-j6bwi8q2/logs
wandb: Agent Starting Run: qrugfa7p with config:
wandb: 	actor_learning_rate: 0.00012830672512987687
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4865224449624427
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8265827935006337
wandb: uploading history steps 128-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁█▇▇
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▅▃▃▃▃▂▁▁▂▅▆▇█▇▇▃▆▆▆▆▇▇▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▆
wandb:      eval/avg_mil_loss ▄▃▃▂▂▂███▇▇▇▆▆▅▅▄▅▄▅▅▅▄▃▃▄▄▄▄▃▃▂▂▁▁▆▆▅▄▄
wandb:       eval/ensemble_f1 ▅▃▃▃▃▁▂▅▅▅▆█▇▇▆▆▃▃▅▅▆▆▆▇▅▅▅▅▆▆▆▆▅▅▅▆▆▆▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▂▁▁▂▂▂▃▂▃▂▃▅▆▅▃▃▁▁▃▃▄▃▅▃▄▂▄▅▆▆▆▅▇▅█▆▇
wandb:      train/ensemble_f1 ▄▃▃▃▃▄▅▂▄▆▃▃▇▄▄▄▄▆▁▆▄▃▆▅▄▆▆▄▅▆▅▆▇█▇█▆██▇
wandb:         train/mil_loss ▅▄▄▇█▃▅▂▃▃▅▄▆▃▅▃▃▂▅▄▅▄▂▄▃▅▃▁▃▂▆▁▃▃▁▂▄▄▄▂
wandb:      train/policy_loss ▄▄▅▄▄▄▄▄▄▁▆▄▄▄▄▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78517
wandb: best/eval_avg_mil_loss 0.47625
wandb:  best/eval_ensemble_f1 0.78517
wandb:            eval/avg_f1 0.75369
wandb:      eval/avg_mil_loss 0.46823
wandb:       eval/ensemble_f1 0.75369
wandb:            test/avg_f1 0.76979
wandb:      test/avg_mil_loss 0.49814
wandb:       test/ensemble_f1 0.76979
wandb:           train/avg_f1 0.80215
wandb:      train/ensemble_f1 0.80215
wandb:         train/mil_loss 0.34472
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run snowy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oaf6ih2m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012238-oaf6ih2m/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012454-qrugfa7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qrugfa7p
wandb: Agent Starting Run: eaptg95s with config:
wandb: 	actor_learning_rate: 0.0014756829826948266
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0974735645037118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05213858355507328
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012458-eaptg95s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eaptg95s
wandb: Job received.
wandb: Agent Starting Run: 30565cbv with config:
wandb: 	actor_learning_rate: 0.00016683399457959622
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12206758736069924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34331535420682635
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012510-30565cbv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/30565cbv
wandb: uploading history steps 249-261, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▅▃▁▁▁▂▁▂▂▂
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▆▇▇▇▇█████████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇▅▄▂▂▁▁▁▁▁▁▂▂▂▂▃▃▃▂▂▃▃▃▃▃▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▂▅▅▅▇▇██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▂▁▁▂▂▁▃▄▄▄▄▆▅▆▅▆▅▆▇▆▇▇▇▇▇▇▇█▆▇█▇▇█▇█
wandb:      train/ensemble_f1 ▁▁▂▁▁▂▄▅▅▆▅▅▆▅▆▅▇▅▅▆▆▅▆▆▇▆▆▆▇▇▇▆▆▇▆▆█▇▇▆
wandb:         train/mil_loss ▇▆█▆▇▇▆▅█▆▃▃▁▄▃▄▄▂▃▂▄▄▄▄▅▄▃▃▃▄▅▄▂▄▃▅▃▄▄▂
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▆▁▁▁▄▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 2.18775
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 2.13887
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.61354
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.58029
wandb:      train/ensemble_f1 0.58029
wandb:         train/mil_loss 1.53231
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0g63lzm4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012104-0g63lzm4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 377qmw2j with config:
wandb: 	actor_learning_rate: 0.00021761126197975371
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8134389938919606
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7885653373310292
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012547-377qmw2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/377qmw2j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅████▇▇▇▇▆▆▅▅▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▆▅▇▂▄▅█▃▅▂▃▆▆▅▃█▂▃▅▄▃▃▇▆▁▃▄█▇▅▄▅▅▄▆▅▄▅
wandb:      train/ensemble_f1 ▂▂▄▃▃▅▄▂▄▂▁▂▄▅▅▄▆▂▂▂▄▂▂▆▄▃▃▂▅▄▃▂▃▅▅▃█▃▃▂
wandb:         train/mil_loss ▆▆▅▆▄▇▆▇▅▆▄▄▆▆▆▄▃▆▇▅▃▇▄▄▅▅▇▅▄▅▁▇▅▆▄▃▅▅█▅
wandb:      train/policy_loss ▅█▇▁▅▃▅▃▂▃▂▆▂▂▃▆▃▃▁▄▃▄▃▃▇▃▄▃▃▃▁▆▂▁▄▄▇▂▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▃▅▆▂█▃▇▁▆▃▆▃▆▅▃▃█▃▃▃▄▄▄▃▂▁▆▃▂▂▄▃▇▃▆▄▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.31337
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.20705
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.94566
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33333
wandb:      train/ensemble_f1 0.33333
wandb:         train/mil_loss 2.71813
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eaptg95s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012458-eaptg95s/logs
wandb: uploading history steps 94-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:       eval/ensemble_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▄▄▇▄▃▃▅▇▆█▄▆▃▄█▄▅▅▅▇▇▅▅▆▅▄▁▆▅▆▆▂▆▆▆▅
wandb:      train/ensemble_f1 ▅▄▄▄▆▂▃▇▆▃▅▅▃▁▆▃▄█▇▇▄▅▅▆▆▆▇▄▅▇█▁▆▅▅▆▅▅▃▅
wandb:         train/mil_loss ▄▄▃▆▇█▅▆▅▄▆▆▇▅▄▇█▅▄▄▅▅▅▅▅▅▆▅▂▅▅▆▁▇▇▄▇▃▄▃
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.20723
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.22313
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.92943
wandb:      test/avg_mil_loss 0.2931
wandb:       test/ensemble_f1 0.92943
wandb:           train/avg_f1 0.91729
wandb:      train/ensemble_f1 0.91729
wandb:         train/mil_loss 0.1981
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qrugfa7p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012454-qrugfa7p/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: ugqi03ez with config:
wandb: 	actor_learning_rate: 0.0016134616461326028
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8870885658769637
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.646722920657323
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012643-ugqi03ez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ugqi03ez
wandb: Job received.
wandb: Agent Starting Run: bqbqve7e with config:
wandb: 	actor_learning_rate: 0.00449142626078843
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27178486453590744
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23064514444285045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012647-bqbqve7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqbqve7e
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆▆▆▆▆███▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████
wandb:       eval/ensemble_f1 ▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▆▆▆▄▇▂▄▅▆▆▃▆▆▄▆▂▆▄▅▅▆▃▇▆▁▄▄▃▃▅▆▄▆▆▅▆▅
wandb:      train/ensemble_f1 ▅█▆▆▆▅▆▃▄▄▄▇▂█▆▆▆▅▄▃▆▅▇▄▆▇▆▃▁▄▃▇▇▃▄▆▄▄▅▅
wandb:         train/mil_loss ▆▆▃▆▄▇▅▇▇▃▅▃▇█▂▅▆▃▅▆▁▆▄▃▄▅▄▇█▇▇▅▅▄█▇▃▃▇▆
wandb:      train/policy_loss ▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████▁▅██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.21507
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.23286
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.12262
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.91213
wandb:      train/ensemble_f1 0.91213
wandb:         train/mil_loss 0.23683
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/377qmw2j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012547-377qmw2j/logs
wandb: Agent Starting Run: x7kzxr9s with config:
wandb: 	actor_learning_rate: 0.006483540256328832
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3138099201096072
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7437154457599551
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012748-x7kzxr9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x7kzxr9s
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▃▃▇████████████████████████████████████
wandb:       eval/ensemble_f1 ██▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁▅▆▆▆█▆▆▆▆▇▆▆█▆▆▆▇▆▆▆▆▆▇▆█▇▇▆▆▇▆█▆▇▆▇▅▆
wandb:      train/policy_loss ██▄▅▄▅▆▄▂▃▄▃▄▅▄▄▄▃▂▄▄▅▅▃▁▅▃▄▄▂▃▁▂▂▃▅▅▁▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87981
wandb: best/eval_avg_mil_loss 0.18875
wandb:  best/eval_ensemble_f1 0.87981
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.38754
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.24948
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.32886
wandb:      train/ensemble_f1 0.32886
wandb:         train/mil_loss 2.44054
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqbqve7e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012647-bqbqve7e/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▁▅▅▅▅██████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▂▂▂▁▁▄▄▄▄▅▅▅▅▃▄▄▄▄▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁█▁▁▁▁▁▁█████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▄▅▅▄▆▄▃▄▆▄▅▅▄▅▆█▆▅▅▅▆▄▆▅▅▇▄▇▃▄▃▄▅▃▅▄
wandb:      train/ensemble_f1 ▁▂▁▃▄▂▄▆▃▆▇▅▄▄▂█▅▇▅▇▅▄▇▆▅▇▇▅▃█▁█▅▄▆▄▆▆▆▆
wandb:         train/mil_loss ▃▂▂█▄▆▅▄▄▇▇▅▃▄▄▄▄▂▁█▅▁▅▆▃▅▅▃▄▁▃▅▄▅▄▅▅▆▃▄
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▂▃▄▄▂▂▂▃█████████▂▃▁▃▄▄▂▃▂▄▄▂▂▄▃▂▁▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.26306
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.28676
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.18
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.90798
wandb:      train/ensemble_f1 0.90798
wandb:         train/mil_loss 0.24591
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ugqi03ez
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012643-ugqi03ez/logs
wandb: Agent Starting Run: 6c00brcr with config:
wandb: 	actor_learning_rate: 0.0002177629337431416
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3947684697844899
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3861106773527071
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012831-6c00brcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6c00brcr
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q44m6b96 with config:
wandb: 	actor_learning_rate: 0.0010336830473050022
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2780342615684054
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24123935070727545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_012842-q44m6b96
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q44m6b96
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▅▁█
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▅▅▅▁▄▄▄▄▇▇▇▇▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄██████
wandb:      eval/avg_mil_loss ▁▂▂▃▇▇▇████████▇▇▇▇▇▆▆▆▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▅▅██▄▄▄▇▇▇▇▄▄▄▄▄▄▄▄▄▄▄▄▄██▄▄▄▄▄▄▄█████▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▅▇▃▂▃▂▁▄▄▄▄▄▃▅▄▂▅▅▅▃▆▆▅▅▆▆▆▅▄▅▇▅▆▆▇██
wandb:      train/ensemble_f1 ▆▆█▄▅▆▂▁▁▃▃▃▄▄▃▃▃▂▄▅▄▄▃▃▆▆▇▅▃▅▅▇▃▅▆▆███▂
wandb:         train/mil_loss ▁▃▁▄▂▅██▇▇▆▇▅▇▄▄▄▆▄▅▆▅▅█▆▆▅▇▆▇▇▆▅▄▄▅▅▆▄▅
wandb:      train/policy_loss ▆▆▂▄█▆▆▆▆▆▆▆▆▂▃▃▂▂▂▂▃▅▂▆▆▂▂▅▂▂▂▁▆▆▆▆▆▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▂█▆▆▆▆▆▆▆▃▂▂▃▂▃▄▂▂▂▂▃▆▆▂▄▁▃▃▆▆▆▆▆▆▆▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.48673
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.8164
wandb:      eval/avg_mil_loss 0.43916
wandb:       eval/ensemble_f1 0.8164
wandb:            test/avg_f1 0.694
wandb:      test/avg_mil_loss 0.82204
wandb:       test/ensemble_f1 0.694
wandb:           train/avg_f1 0.7679
wandb:      train/ensemble_f1 0.7679
wandb:         train/mil_loss 0.51019
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q44m6b96
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012842-q44m6b96/logs
wandb: Agent Starting Run: h4ci3241 with config:
wandb: 	actor_learning_rate: 0.00010096053699029644
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.833128854827895
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25906567670431935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013036-h4ci3241
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h4ci3241
wandb: uploading summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████▁▁▁▁▁▁█████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▅▅▄▄▄▄▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████▁▁▁███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▃▂▁▂▃▁▃█▃▄▄▅▃▄▂▆▃▃▅▅▆▆▅▄▆▄▆▄▄▆▇▆█▅▅▆▆
wandb:      train/ensemble_f1 ▁▂▃▄▂▃▂▃▄▃█▃▅▃▅▄▆▃▄▅▅▄▄▂▄▅▄█▄▅▅▅▂▅▃▇▄▆▆▆
wandb:         train/mil_loss ▅▅▅▆▆▆▆█▄▆▄▄▃█▅▅▇▆▅▄▆▇▄▅▆▅▇▆▄▃▂▅▇▅▅▇▃▄▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▂▂▂▄▄▃▂█████▂▅▄▃▂▄▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 2.34373
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.2246
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.66634
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.54513
wandb:      train/ensemble_f1 0.54513
wandb:         train/mil_loss 1.49909
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x7kzxr9s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012748-x7kzxr9s/logs
wandb: Agent Starting Run: bp0um4o5 with config:
wandb: 	actor_learning_rate: 1.6739567674874657e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6316060406541231
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3918109863295355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013054-bp0um4o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bp0um4o5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▅▅▅▅███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▂▁▁▂▁▁▁▄▅▅▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▆▃▅▂▃█▅▄▅▄▆▄▅▇▄▄▇▅▄▃▄▄▅▆▄▄▅▆▁▅▆▅▇▄▆▄▅▄
wandb:      train/ensemble_f1 ▄▅▄▁▂▅▁▅▆▄▄▄▂▃▃▂▄▃▄▆▃▆▅▄▃▅▃▅▄▃▂▅█▁▃▆▅▄▄▄
wandb:         train/mil_loss ▄▆█▅▄▃▆▆██▅▂▅▃▂▃▂▃▄▅▃▃▆▅▆▅▇▅▁▆▃▂▄▄▄▅▅▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38667
wandb: best/eval_avg_mil_loss 1.8965
wandb:  best/eval_ensemble_f1 0.38667
wandb:            eval/avg_f1 0.38667
wandb:      eval/avg_mil_loss 1.91445
wandb:       eval/ensemble_f1 0.38667
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.65003
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33723
wandb:      train/ensemble_f1 0.33723
wandb:         train/mil_loss 1.23801
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6c00brcr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012831-6c00brcr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pxl3uzj7 with config:
wandb: 	actor_learning_rate: 0.0010632500271215775
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5879164558435789
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5771277090407245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013126-pxl3uzj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pxl3uzj7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▁▁▃▃▃▃▃▄▆█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▆
wandb:      eval/avg_mil_loss ██▇▇▅▅▅▄▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▄████▆▆▆▆▄▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▆▅▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▆▂█▂▄▄▂▂▅▄▅▂▄▅▄▅▆▁▄▄▂▇▃▆▆▅▆▅▃▄▅▆█▅▆▆▄▁
wandb:      train/ensemble_f1 ▅▃▅▃▅▄█▅▃▄▄▄▃▂▅▁▃▄▅▅▃▆▅▄▅▄█▇▆▇▅▆▄▄▆▆▅▅▇▄
wandb:         train/mil_loss ▆▅▅▂▄▅▄▃▇▆█▇▇▅▆▂▄█▅▅▄▆▄▅▅▄▅▁▂▃▂▅▆▅▄▅▅▅▂▄
wandb:      train/policy_loss ▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████████████▁███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.21845
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.19814
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.83994
wandb:      test/avg_mil_loss 0.60079
wandb:       test/ensemble_f1 0.83994
wandb:           train/avg_f1 0.84639
wandb:      train/ensemble_f1 0.84639
wandb:         train/mil_loss 0.25104
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h4ci3241
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013036-h4ci3241/logs
wandb: Agent Starting Run: 32ovpouo with config:
wandb: 	actor_learning_rate: 0.0058865199585950425
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.602422458219566
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3321120355130075
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013245-32ovpouo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/32ovpouo
wandb: uploading history steps 155-168, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅█████████████▁▁▁▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅████████▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▄▅▅▅▅▅▄▄▄▄▄▄▅▅▄▆▄▅▃▃▅▆▆▆▅▅▇▆▅▅▅▄▅▇▅█▇█
wandb:      train/ensemble_f1 ▄▄▁▂▄▆▅▃▃▂▃▃▁▂▃▂▅▅▅▂▁▁▄▃▃▅▄▃▃▅▅█▆▆▄▇█▃██
wandb:         train/mil_loss ▂▄▆▄▇▅▁▆▃▃█▂▅▄▄█▄▂▂▅▅▄▄▇▃▆▃▅▅▄▅▅▆▅▂▄▅▂▃▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▃▄▅▃█▃▃▁▃█▆▅▅▅▅▅▅▅▅▆▅▆▅▇█▅█▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 2.70034
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.59274
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 3.09514
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.4988
wandb:      train/ensemble_f1 0.4988
wandb:         train/mil_loss 1.32961
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bp0um4o5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013054-bp0um4o5/logs
wandb: Agent Starting Run: lqb5a2pf with config:
wandb: 	actor_learning_rate: 7.739040075669611e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11582482532902771
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3295558479589734
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013340-lqb5a2pf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqb5a2pf
wandb: uploading history steps 580-583, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▆▆▃▃▃▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▇▇▇▇▇▇▇█████████
wandb:      eval/avg_mil_loss ▇▇███▇▇▇▇▇▇▇▆▆▆▆▆▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▃▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▄▄▃▄▃▄▃▅▅▄▅▅▆▅▄▆▅▅▆▅▅▆▆▇▇▆▆▇▇▇▇▇▇▇▆▇█
wandb:      train/ensemble_f1 ▂▃▁▁▂▂▂▄▃▄▃▄▃▄▅▄▅▅▅▄▅▅▅▅▅▅▆▅▅▆▆▇▇▆▇▇▇▆▇█
wandb:         train/mil_loss ▅██▆▇▆▇▅▅▄▃▄▄▅▅▄▄▂▂▃▅▃▃▃▄▃▃▃▄▁▁▃▂▁▃▂▂▁▁▂
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▇▆▇▆█▇▄▄▄▄▄▄▄▄▄▇▄▄▄▁▁▇▆▇▇▇██▇▇▇▇▁▂▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84926
wandb: best/eval_avg_mil_loss 1.22228
wandb:  best/eval_ensemble_f1 0.84926
wandb:            eval/avg_f1 0.84926
wandb:      eval/avg_mil_loss 1.19433
wandb:       eval/ensemble_f1 0.84926
wandb:            test/avg_f1 0.77921
wandb:      test/avg_mil_loss 2.80391
wandb:       test/ensemble_f1 0.77921
wandb:           train/avg_f1 0.86383
wandb:      train/ensemble_f1 0.86383
wandb:         train/mil_loss 0.89381
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/30565cbv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_012510-30565cbv/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▅▆▇██
wandb: best/eval_avg_mil_loss █▆▆▅▄▄▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▅▆▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▂▇▇▇███████████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▂▅███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▁▁▁▂▄▆▆█▆▆▇▆▆▇▇▇▆▇▇▇▇█▇▇▇▇▇▆█▇▇▇▇▇▇
wandb:      train/ensemble_f1 ▂▁▁▁▁▁▂▁▁▁▆█▇▆▆▇▆▇▆▆▇▇▇▆▇▇█▇▇▆▇▇▇▇▆█▆▇▇▇
wandb:         train/mil_loss █▃▇▅▄▆▂▆▂▂▆▄▄▁▁▄▂▅▃▄▂▁▂▄▅▃▃▂▆▅▅▁▆▂▂▃▂▁▂▅
wandb:      train/policy_loss ▂▂▅▂▃▄▄▄▃▁▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57924
wandb: best/eval_avg_mil_loss 1.69825
wandb:  best/eval_ensemble_f1 0.57924
wandb:            eval/avg_f1 0.57924
wandb:      eval/avg_mil_loss 1.53287
wandb:       eval/ensemble_f1 0.57924
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 2.1153
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.57434
wandb:      train/ensemble_f1 0.57434
wandb:         train/mil_loss 0.81228
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/32ovpouo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013245-32ovpouo/logs
wandb: Agent Starting Run: jnqrj7yp with config:
wandb: 	actor_learning_rate: 0.00035915098666002937
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9347605746691484
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.018552704292911223
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013520-jnqrj7yp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jnqrj7yp
wandb: Job received.
wandb: Agent Starting Run: f98azbx3 with config:
wandb: 	actor_learning_rate: 1.161828218268325e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.317150745679734
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9481095540350124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013526-f98azbx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f98azbx3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▂▂▄▅▇▃▆▁▄▅▆▅▃▅▇█▂▅▆▅▅▅█▅▆▇▃█▇▄▇▄▃▄▃▄▄▃
wandb:      train/ensemble_f1 ▁▂▃▅▇▄▃▄▆▆▆▄▆▄▇▅▄▆▆▇▆█▆▅█▅▇▇▇▇▅▅▇▇▆▄▅▆▇▇
wandb:         train/mil_loss ▅▅▆▆▅▆▄▅▆▄▁▃▂▅▅▄█▆▃▇▃▄▂▄▂▅▃▃▅▄▆▅▂▃▄▆▄▃▄▆
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▇▆▆▇▇▆▆█▆██▇▇▆▆▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.23514
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.21949
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.14215
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91623
wandb:      train/ensemble_f1 0.91623
wandb:         train/mil_loss 0.18132
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqb5a2pf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013340-lqb5a2pf/logs
wandb: Agent Starting Run: kbwlp3xp with config:
wandb: 	actor_learning_rate: 4.136820800794744e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8892675385458122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39912131101251014
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013626-kbwlp3xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kbwlp3xp
wandb: uploading history steps 349-359, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▄▅▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▆▆▆▆▅▅▅▄▄▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▄▅▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss ██▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▃▃▃▄▄▅▄▅▅▅▅▅▅▆▇▇▇▇▇▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▁▂▄▅▆▅▄▆▅▅▅▅▄▃▄▆▅▅▆▅▅▅▇▇▆▇▅▅▇▆█▅▆▇▇▆█
wandb:      train/ensemble_f1 ▁▂▂▁▁▁▂▃▃▅▅▃▅▆▄▅▅▄▇▆▇▆▅▆▄▆▆▅▇▅▅▆▇▆▇▆▇▆█▇
wandb:         train/mil_loss ▅▅▅▄▇▄▅▆█▅▃▄▅▄▂▃▃▃▃▄▃▁▁▃▂▁▃▁▂▂▁▂▂▃▂▁▂▂▂▂
wandb:      train/policy_loss ▅▅▄▆▅▅▅▅▅▅▅▁▄▅▃█▅▄▆█▅▅▅▅▅▃▃▇▄▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▆▂▄▄▄▄▄▄▄▄▄▄▁▂▂▄▄▄▄▄▄▅▃▅██▆▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.32503
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.29365
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.7182
wandb:      test/avg_mil_loss 0.84883
wandb:       test/ensemble_f1 0.7182
wandb:           train/avg_f1 0.78668
wandb:      train/ensemble_f1 0.78668
wandb:         train/mil_loss 0.39316
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pxl3uzj7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013126-pxl3uzj7/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██████▅▃▁▃▁▁▂▂▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▄▄▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▁▁██████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄
wandb:       eval/ensemble_f1 █████▁▃▃▁▁▁▁▁▂▂▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▄▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▆▆▁▂▃▃▂▂▄▂▂▄▄▂▄▃▄▃▃▂▄▃▄▄▂▄▄▃▁▂▄▃▂▅▃▂▁▂
wandb:      train/ensemble_f1 ▆██▇█▄▄▅▄▃▃▃▃▃▄▄▅▃▄▅▃▆▅▄▄▄▂▃▃▃▃▂▅▃▂▂▄▁▆▁
wandb:         train/mil_loss ▇▁▂▄▃▃▄▃▇▃▇█▅▂▆▄▂▃▅▄▃▁▆▅▅▆▃▆▃▃▄▃▃▆▃▇▆▆▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▁▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74425
wandb: best/eval_avg_mil_loss 0.64908
wandb:  best/eval_ensemble_f1 0.74425
wandb:            eval/avg_f1 0.68474
wandb:      eval/avg_mil_loss 0.64131
wandb:       eval/ensemble_f1 0.68474
wandb:            test/avg_f1 0.80983
wandb:      test/avg_mil_loss 0.97129
wandb:       test/ensemble_f1 0.80983
wandb:           train/avg_f1 0.73526
wandb:      train/ensemble_f1 0.73526
wandb:         train/mil_loss 0.22733
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jnqrj7yp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013520-jnqrj7yp/logs
wandb: Agent Starting Run: esq8kq61 with config:
wandb: 	actor_learning_rate: 0.0008296547803778444
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5286805084448642
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6949537110806149
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013712-esq8kq61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/esq8kq61
wandb: Agent Starting Run: oux0e5zs with config:
wandb: 	actor_learning_rate: 0.0009601137519307726
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.584986881916701
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2769434162389446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013713-oux0e5zs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oux0e5zs
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▆▇▄▄▅▂▅▆▄▃▅▅▆▆▁▃▃█▄▅▆▃▃▆▇▅▄▃▆▄▆▂▄▃▃▃▃▅
wandb:      train/ensemble_f1 ▂▅▃▃▁▆▃▃▄▃▄▃▂▅▆▁▇▇█▃▃▅▁█▂▄▃▅▇▇▃▃▇▇█▃▃▄▂▁
wandb:         train/mil_loss ▁▆▇▃▄▂█▅▄▃▂▃▃▄▆▄▅▅▇▃▇▃▄▂▅▃▃█▇▅█▂▃▃▁▄▄▅▂▂
wandb:      train/policy_loss ▆▃▃▄▇▂▃▃▃▆▃▅▃▅▅█▁▄▇▆▁▁▄▄▄▃▄▃▂▄▄▆▅▄▄▂▆▆▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▂▇▃▅▃▅▃█▃▅▅▂▇▄▂▅▃▄▄▄▃▄▂▄▆▁▄▄▅▄▃▅▃▂▆▅▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.28083
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.26964
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.92677
wandb:      test/avg_mil_loss 0.17103
wandb:       test/ensemble_f1 0.92677
wandb:           train/avg_f1 0.90708
wandb:      train/ensemble_f1 0.90708
wandb:         train/mil_loss 0.20778
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oux0e5zs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013713-oux0e5zs/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k0p2p8na with config:
wandb: 	actor_learning_rate: 1.8807964640201503e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3274355049840043
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6180001587790965
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013907-k0p2p8na
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0p2p8na
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▆▇█
wandb: best/eval_avg_mil_loss █▆▆▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▄▄▄▄▄▄▄▄▅▅▆▇▇▇▇████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▁▁▃▂▁▃▃▃▅▃▄▅▄▅▅▄▄▄▅▅▆▄▅▆▅▆▆▆▇▆██▇▇▆▅▇
wandb:      train/ensemble_f1 ▁▂▁▂▂▃▂▃▃▂▃▃▃▄▄▅▅▂▄▄▄▆▄▆▅▅▄▅▆▆▅▆▇▇█▇▇▆██
wandb:         train/mil_loss ▇▅▇▅▇▂▅▄▅▇▅▅▆█▇▇▄▄▃▆▅▃▆▃▅▂▂▄▃▅▇▄▅▃▆▄▁▆▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▆▇█████████████████▄▄▇▄▇▄▄▆▄▃▁▅▅▂▅▆▄▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46082
wandb: best/eval_avg_mil_loss 5.20845
wandb:  best/eval_ensemble_f1 0.46082
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 4.96919
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 6.03363
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.46858
wandb:      train/ensemble_f1 0.46858
wandb:         train/mil_loss 2.74915
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f98azbx3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013526-f98azbx3/logs
wandb: Agent Starting Run: de4lfabn with config:
wandb: 	actor_learning_rate: 3.685022353473883e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2156282969433897
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.928990617811966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013940-de4lfabn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/de4lfabn
wandb: uploading history steps 143-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▇█
wandb: best/eval_avg_mil_loss █▆▃▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▄▅▅▅▅▅▅▆▆▆▆▇▇█▇▆▆▆▆▆▇▇▇██▇█▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▅▅▆▆▆▆▆▆▇▇▇▇▇▇▆▆▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▃▃█▅▅▇▆▃▇█▄▅▄▃▂▆▅▅▅▃▁▅▆▄▅▄▄▂▅█▅█▄█▇▅█
wandb:      train/ensemble_f1 ▃▁▃▄▃▄▅▆▃▅▇▇▃▄▂▃█▄▁▇▆▄▄▅▅▂▅▆▆▆▄▅▃▇█▆▆▆▅▆
wandb:         train/mil_loss ▇█▆▅▇▅▄▄▄▆▅▅▅▄▅▄▅▄▄▄▃▃▅▃▄▅▅▁▃▅▃▅▄▃▄▂▃▃▁▂
wandb:      train/policy_loss ▆▁▆▆▆▆▆▆▆▆▆█▆▄▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆█▁▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94
wandb: best/eval_avg_mil_loss 0.16343
wandb:  best/eval_ensemble_f1 0.94
wandb:            eval/avg_f1 0.92994
wandb:      eval/avg_mil_loss 0.15979
wandb:       eval/ensemble_f1 0.92994
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.25675
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.87681
wandb:      train/ensemble_f1 0.87681
wandb:         train/mil_loss 0.27358
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/esq8kq61
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013712-esq8kq61/logs
wandb: Agent Starting Run: 4orkndmi with config:
wandb: 	actor_learning_rate: 1.7067303687331065e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8363378957269235
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5968761547093266
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_013948-4orkndmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4orkndmi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▃▁▆
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▅▅▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▅▅▄▃▃▂▂▂▁▁▁▆▅▅▇▇▇▆▆▆▆▆▆▆▆▆▆▅▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▅▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅██████████████▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▄▅▇▄▆█▆▅▇▃▆▅▄▂▄▆▇▆▆▅▄▇▃▇█▆▅▅▅▅▃▆▁▇▇▇▆
wandb:      train/ensemble_f1 ▃▃▆▄▅▁▄▄▄▆▃▁▄▄▃▇▃▃▅▅▃▁█▆▆▄▅▄▅▄▁▆▄▂▅▆▃▅▅▇
wandb:         train/mil_loss ▅▄▅▆▆▄▃▃▄▄▃▅▂▁▅▅▄▂▆▇▃▂▄▆▆▁▃▃█▄▃▄▂▅▃▄▃▅▇▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.5864
wandb: best/eval_avg_mil_loss 1.8094
wandb:  best/eval_ensemble_f1 0.5864
wandb:            eval/avg_f1 0.57835
wandb:      eval/avg_mil_loss 1.77166
wandb:       eval/ensemble_f1 0.57835
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.78073
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.56795
wandb:      train/ensemble_f1 0.56795
wandb:         train/mil_loss 0.26791
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kbwlp3xp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013626-kbwlp3xp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: clbz5jd8 with config:
wandb: 	actor_learning_rate: 0.0003543638676017558
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8357736559797709
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6418213111444061
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014100-clbz5jd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/clbz5jd8
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▁▁▁▁▁▁▁▁██████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▅▄▁▅▅▄▆▄▆▅▆▄▆▅▄▄▃▆▄▄▅▄█▄▆▆█▅▆▇▅▇▆▅▅█▅
wandb:      train/ensemble_f1 ▅▄▅▆▅▆▁▃▄▆▆▇▆▅▇▇▄▅▄▅▆▆▅▇▃█▃▆▅▅▅▅▇█▇▄▄█▅▅
wandb:         train/mil_loss ▆▇▃▄▅▄▅▅▆▃▅▄▃▁▃▅▆▂▂▄▄▃▂▅▃▇▆▅▃▇▁▄▄▃▆█▆▅▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.25887
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.24
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.13233
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.91485
wandb:      train/ensemble_f1 0.91485
wandb:         train/mil_loss 0.25983
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0p2p8na
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013907-k0p2p8na/logs
wandb: Agent Starting Run: mq7awkkd with config:
wandb: 	actor_learning_rate: 0.0003614990641506928
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4892064727380619
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.821902713182369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014123-mq7awkkd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq7awkkd
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▇▄▅▄▂▆▆▅▆▁▄▆▅▆▄▆▆▅▅▅▄▄▅▇▅▆▅▆▄▆▅▆▄█▅▆▆
wandb:      train/ensemble_f1 ▅▃█▃▃▃▄▁▆▄▂▄▅▅▆▆▅▆█▄▅▃▄▂▄▄▅▄▄▄▆▅▆▆▅▆▂▆▃▂
wandb:         train/mil_loss ▄▂▂█▂▆▆▃▃▃▃▃▄▅▃▂▄▄▄▄▂▂▆▅▃▄▅▃▃▄▃▆▃▆▅▄▆▆▁▁
wandb:      train/policy_loss ▇▄▆▆▁▄▃▅▇▅▂▆▁▅▄▂▅▇▆▃▆▄▄▇▅▅▃▆▅▆▂▆▃▃▅▇▃▇██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▅▁▇▅▄▃▃▅▅▅▅▂▅▅▄▅▆▃▅▆▅▅▄▅▅▄▃▅▄▅▅▃▂▅▃▃▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.62823
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.54515
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 4.07031
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31741
wandb:      train/ensemble_f1 0.31741
wandb:         train/mil_loss 0.40956
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4orkndmi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013948-4orkndmi/logs
wandb: Agent Starting Run: fpr561w6 with config:
wandb: 	actor_learning_rate: 0.0008148450679888312
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13120360933849673
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3893361415393203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014131-fpr561w6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fpr561w6
wandb: uploading history steps 135-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅█████▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▅▄▃▆▄▅▄▄▅▄█▃▄▃▄▂▅▁▃▆▁▃▆▂▃▆▄▅▂▅█▃▅▄▃▃▆
wandb:      train/ensemble_f1 ▅▄▆▇▅▅▆▅▄▆▆▄▅▂▆▄▄▃▅▅▃▃▂▄▂▆▆▂▅▁▄▃█▅▅▇▅▅▆▁
wandb:         train/mil_loss ▄▅▅▃▅▇▆▇▇▄▄▇▅▄▆▅▆▆█▃▃▅▇▆▆▅▆▂▁▄▅▆▄▂▆▂▂▄▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.26531
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.84878
wandb:      eval/avg_mil_loss 0.25812
wandb:       eval/ensemble_f1 0.84878
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.22007
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.88344
wandb:      train/ensemble_f1 0.88344
wandb:         train/mil_loss 0.27721
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/de4lfabn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_013940-de4lfabn/logs
wandb: Agent Starting Run: ea6lficn with config:
wandb: 	actor_learning_rate: 3.2915648408660815e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1032568255534847
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6027795640726971
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014210-ea6lficn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ea6lficn
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▇▃▁▇▇▅▂▄▆▆▃▄▂▆▃▃▅▄█▁▃▂▅▃▃▅▄▄▃▃▆▄▅▆▅▄▆▆
wandb:      train/ensemble_f1 ▅▇▅▅▁▇▆▄▂▇▅▄▇▅▅▆▆▄▅▅█▂▃▄▃▄▅▄▇▁▅▇▅▅▅█▆▆▅▆
wandb:         train/mil_loss ▄▆▇█▅▄▄█▄▃▄▇▃▆▆▄▅▃▁▆▅▅▆▄▄▅█▇▅▄▅▇▃▆▃▄▁▂▆▂
wandb:      train/policy_loss ▆█▃▃▃▄▆▅█▆▅▄▅▆▄▇▄▆▆▇▂▃▆▁▄▄▃█▃▂▄▄▃▆▃▆▄▆▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▃▃▄▅▅▄▂▅▄▄▇▆▆▇▆▃▆▆▇▄▁▄▆▃▄▇▃▁▃▄▂▂▅█▅▆▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.72055
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.50954
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 4.23295
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3372
wandb:      train/ensemble_f1 0.3372
wandb:         train/mil_loss 2.54465
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fpr561w6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014131-fpr561w6/logs
wandb: Agent Starting Run: qxxrl8cb with config:
wandb: 	actor_learning_rate: 5.86511557745454e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5608823077911391
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6650985587043444
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014315-qxxrl8cb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxxrl8cb
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▆▆▆▆▅▅▄▄▄▄▄▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██████████████
wandb:      eval/avg_mil_loss ██▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▃▄▅▄▅▅▅▆▆▆▆▅▆▇▇▆▆▇▇▆▆▇█▇█▇▇▇▇▇▇▇█▇█
wandb:      train/ensemble_f1 ▁▁▁▁▂▃▃▃▄▄▅▅▆▅▆▆▇▇▆▆▇▇▇▇▇▇▆▇▇▇▇█▇▇▇█▇█▇█
wandb:         train/mil_loss ▄█▇█▄▄▃▇▆▄▄▅▁▇▄▅▆▄▅▂▆▃▃▃▅▃▄▅▄▂▄▅▄▃▁▄▂▂▂▄
wandb:      train/policy_loss █████████████████████▇█▁████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 1.33458
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59066
wandb:      eval/avg_mil_loss 1.27719
wandb:       eval/ensemble_f1 0.59066
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 1.64698
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.60307
wandb:      train/ensemble_f1 0.60307
wandb:         train/mil_loss 0.76501
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq7awkkd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014123-mq7awkkd/logs
wandb: Agent Starting Run: 9idcxh6j with config:
wandb: 	actor_learning_rate: 7.138797845769657e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4252365679864776
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.977266924322665
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014648-9idcxh6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9idcxh6j
wandb: uploading history steps 93-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▁▁▅▇▆▆▇▇▇███████▇▇▇▇█████▇▇▇▇▂▂▄▄▄▄▄▅▅▅
wandb:       eval/ensemble_f1 ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▃▄▄▅▅▆▄▆▅▇▃▅▇▅█▆▃▆▅▄▅▇▅▅▅▅▅▄▆▄▇▅█▄▅▄▃▆
wandb:      train/ensemble_f1 ▅▆▅▁▃▄▅▆▅▄▄▆▆▄▅▇▇▅▅▃▇▄▇▆▇▅▆▆▅▇▅▄▅██▆▅▆▅▆
wandb:         train/mil_loss ▅▅▅▅▂▁▅▄▄▆▅▃▅▄▅█▄▃▅▄▃▃▃▄▄▁▅▄▅▄▁▄▃▆▄▂▇▂▆▁
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.21468
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.21858
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.12047
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.93243
wandb:      train/ensemble_f1 0.93243
wandb:         train/mil_loss 0.19236
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9idcxh6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014648-9idcxh6j/logs
wandb: Agent Starting Run: 8q7taaf1 with config:
wandb: 	actor_learning_rate: 0.00797674100464229
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.032854324127945866
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8120154628521582
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014837-8q7taaf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8q7taaf1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▄▄▅▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▅▅▅▄▄▂▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▄▄▅▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▄▄▅▅▃▄▄▃▃▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇▇████▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▄▃▄▅▅▅▄▄▄▄▅▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▇▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▃▄▃▃▄▅▅▅▄▅▄▆▅▅▆▅▇▇▆▆▆▄▆█▆▇▇▇▇▅▇▇▇▇▇▇▇
wandb:      train/ensemble_f1 ▁▂▂▁▄▂▃▅▃▃▃▄▆▅▅▆▆▆▅▅▅▆▆▆▅▆▇▆▇▇█▇▇▇▇▆▇▇▆█
wandb:         train/mil_loss ▅▄▅█▃▄▃▄▃▄▅▂▅▆▄▅▂▃▃▆▅▃▄▄▂▄▄▃▁▂▃▄▁▁▁▄▃▄▁▂
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▃▃▃▃█▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75758
wandb: best/eval_avg_mil_loss 1.41908
wandb:  best/eval_ensemble_f1 0.75758
wandb:            eval/avg_f1 0.74796
wandb:      eval/avg_mil_loss 1.39818
wandb:       eval/ensemble_f1 0.74796
wandb:            test/avg_f1 0.8
wandb:      test/avg_mil_loss 2.27543
wandb:       test/ensemble_f1 0.8
wandb:           train/avg_f1 0.8112
wandb:      train/ensemble_f1 0.8112
wandb:         train/mil_loss 0.83127
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ea6lficn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014210-ea6lficn/logs
wandb: Agent Starting Run: jl8s2o1n with config:
wandb: 	actor_learning_rate: 0.00016686447815868132
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20936285756641937
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23881696042734368
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_014934-jl8s2o1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jl8s2o1n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▆█▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▄█▆▆▆█████▅▅▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▆▂▂▂▁▁▁▁▁▆██████████████████████████████
wandb:       eval/ensemble_f1 ▃▆▆▆▆██████▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▇▆█▆▅▇█▇▇▅▆▆▆▅▆▅▆▆▆▅▆▆▆▆▆▇▇▆▆▅▅▇▆▅▆▅▆▇
wandb:      train/ensemble_f1 ▁▇▇▇▇█▇▇▇█▅▅▆▆█▆▆▅▆▅▅▇▇▆█▆▆▆▆▇█▇▆▇▇▇██▅▆
wandb:         train/mil_loss █▁▅▃▂▄▂▃▁▂▄▅▂▂▄▂▆▅▄▄▅▄▅▆▄▅▄▄▄▃▆▄▅▂▃▃▁▅▃▄
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.27633
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.34274
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.91667
wandb:      test/avg_mil_loss 0.1771
wandb:       test/ensemble_f1 0.91667
wandb:           train/avg_f1 0.89233
wandb:      train/ensemble_f1 0.89233
wandb:         train/mil_loss 0.28158
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8q7taaf1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014837-8q7taaf1/logs
wandb: Agent Starting Run: ibmqhwk0 with config:
wandb: 	actor_learning_rate: 2.7616943971570044e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09760280640013563
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37682111785786354
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015026-ibmqhwk0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibmqhwk0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▆▆▆▅▄▄▄▄▃▃▃▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇███████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▃▃▃▃▄▄▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▁▁▂▁▂▂▃▂▄▄▃▄▄▅▅▅▅▆▅▅▆▅▆▇▆▇▇▇▇▇█▇██▇▇█
wandb:      train/ensemble_f1 ▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▅▄▄▅▅▅▅▆▅▅▆▆▇▇▆▇▇▇█▇▇
wandb:         train/mil_loss █▅▇▄▅▄▅▄▄▄▆▅▆▄▆▄▃▄▃▃▅▃▄▄▄▄▃▃▄▃▄▂▂▂▁▃▃▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▅▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86777
wandb: best/eval_avg_mil_loss 0.40963
wandb:  best/eval_ensemble_f1 0.86777
wandb:            eval/avg_f1 0.86777
wandb:      eval/avg_mil_loss 0.35216
wandb:       eval/ensemble_f1 0.86777
wandb:            test/avg_f1 0.71591
wandb:      test/avg_mil_loss 0.72065
wandb:       test/ensemble_f1 0.71591
wandb:           train/avg_f1 0.75831
wandb:      train/ensemble_f1 0.75831
wandb:         train/mil_loss 0.414
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxxrl8cb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014315-qxxrl8cb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 75qozgib with config:
wandb: 	actor_learning_rate: 5.990745450013841e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24195213598192167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2640767740374136
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015145-75qozgib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/75qozgib
wandb: uploading history steps 119-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅███████████████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▅▅▅█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▅▄▄▅▅▃▆▄▅▅▃▅█▁▅▇▃▂▅▇▃▄▇▅▄▆▅▆▃▄▆▅█▇▇▃▇
wandb:      train/ensemble_f1 ▂▄▃▃▃▅▅▆▃▅▄▃▅▃▄▅▅▆▅█▅▁▃▃▃▆▄▇▃▇▃▄▄▆▇█▇▆▃▇
wandb:         train/mil_loss ▆▅▁▆▇▄▅▃▅▄▃▆▅▅▁▃▃▂▇▄▃▆▅▇▂▆▂▅▃▇▆▄▄▅▅▃█▇▅▃
wandb:      train/policy_loss ████▇▇▂▁▃▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52381
wandb: best/eval_avg_mil_loss 4.76671
wandb:  best/eval_ensemble_f1 0.52381
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 4.5754
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 5.12787
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.54684
wandb:      train/ensemble_f1 0.54684
wandb:         train/mil_loss 2.76518
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jl8s2o1n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014934-jl8s2o1n/logs
wandb: Agent Starting Run: 45q4u456 with config:
wandb: 	actor_learning_rate: 2.233066380591903e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7716959756978055
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4723401029508132
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015154-45q4u456
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/45q4u456
wandb: uploading history steps 670-681, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▆▆▆▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▂▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss █▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▂▃▄▄▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█
wandb:      train/ensemble_f1 ▁▂▂▂▂▂▃▂▂▃▃▃▄▃▃▃▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇
wandb:         train/mil_loss █▇▇▅█▂▅▅▆▅▂▅▃▃▄▃▂▅▄▂▄▃▄▃▂▆▃▃▄▄▃▃▄▁▄▃▂▃▃▃
wandb:      train/policy_loss ▂█▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁█▅▅▅▅▅▅▁▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.41155
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.82792
wandb:      eval/avg_mil_loss 0.40735
wandb:       eval/ensemble_f1 0.82792
wandb:            test/avg_f1 0.78998
wandb:      test/avg_mil_loss 0.43007
wandb:       test/ensemble_f1 0.78998
wandb:           train/avg_f1 0.79067
wandb:      train/ensemble_f1 0.79067
wandb:         train/mil_loss 0.30655
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/clbz5jd8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_014100-clbz5jd8/logs
wandb: Agent Starting Run: q5qva384 with config:
wandb: 	actor_learning_rate: 0.0034286178283459584
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7981076625081595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.020776736733788215
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015201-q5qva384
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q5qva384
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▃▃▃▄▄▃▃▄▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇████████
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▄▁▃▆▃▆█▇▄▅▄▄▆▄▃▃▅▄▃▇▄▆▇▅▅▅▇▇▂▅▆▂▃▆▅▅█
wandb:      train/ensemble_f1 ▅▅▄▁▄▄▂█▂▄▄▅▄▆▆▆▃█▅▃▆▄▇▄▁▅▄▅▇▂▆▅▂▅▅▆▅█▅█
wandb:         train/mil_loss ▆▆▇▃▃▆▅▄▆█▇▃▅▅▆▅▅█▆▄▄▃▇▇▄▁▄▅▄▄▅█▆▆▇▇▅▄▆█
wandb:      train/policy_loss ██████████████████████▁█████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.16746
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.17286
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.21829
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.92076
wandb:      train/ensemble_f1 0.92076
wandb:         train/mil_loss 0.28349
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/75qozgib
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015145-75qozgib/logs
wandb: Agent Starting Run: fb14bzyc with config:
wandb: 	actor_learning_rate: 0.004441547571925476
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5952375947088224
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5875617673932606
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015324-fb14bzyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fb14bzyc
wandb: uploading history steps 125-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇█▇█▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▃▅▇█▃▆▃▇▃▁▅▄▅▆▁▆▆▆▄▂▂▃▃▁▃▅▆▆▄▅▂▄▅▄▄▆▄
wandb:      train/ensemble_f1 ▄▇▇█▃▆█▄▄▇▇▅▁▅▂▁▁▇▆▆▃▆▄▂▂▄▂▃▁▄▅▃▂▆▂▄▃▃▆▃
wandb:         train/mil_loss █▇▆▃█▆▃▇▃▇▇▃▃▃▆▅▆▄▃▅▇▇▄▆▅▁▃▁▆▅▆▆▆▄▃▂▅▆▅▃
wandb:      train/policy_loss ▇▃▄▃▇▇▄█▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▇▂██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52381
wandb: best/eval_avg_mil_loss 2.32714
wandb:  best/eval_ensemble_f1 0.52381
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 2.24786
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 2.57622
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.54132
wandb:      train/ensemble_f1 0.54132
wandb:         train/mil_loss 0.49569
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q5qva384
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015201-q5qva384/logs
wandb: Agent Starting Run: aebmdfnu with config:
wandb: 	actor_learning_rate: 0.0018206524647417224
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4834447823530935
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5043053311343404
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015415-aebmdfnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aebmdfnu
wandb: uploading history steps 248-252, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅███████████████████
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▅▅▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█▅██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▅▄▁▂▄█▂▃▄▃▃▂▁▆▅▄▆▅▄▆▇▄▇▂▇██▆▇▃▅▅▆▆█▄▄▇
wandb:      train/ensemble_f1 ▄▄▅▅▂█▂▆▄▄▄▅▃▇▄▄▄▆▇▄▇▇▅▇▁▇▇▆▆█▇▄▇█▆▆██▆▄
wandb:         train/mil_loss ▃▆▅▆▄▅█▃▄▄▆▄▄▁█▂▆▃▅▇▂▂▂▃▆▆▇▇▁▆▄▅▅▄▄▅▆▃▁▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▁▁▂▁▂███▇█████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87981
wandb: best/eval_avg_mil_loss 0.25643
wandb:  best/eval_ensemble_f1 0.87981
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.25395
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.17898
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.91735
wandb:      train/ensemble_f1 0.91735
wandb:         train/mil_loss 0.23992
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibmqhwk0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015026-ibmqhwk0/logs
wandb: Agent Starting Run: q7238ncg with config:
wandb: 	actor_learning_rate: 3.326118755414715e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06496132345416905
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37050684497092146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015434-q7238ncg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q7238ncg
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▆▅▅▅▄▃▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▅▄▄▂▅▃▅▃▆▂▅█▆▄▄▃▅▃▄▄▄▃▄▃▅▅▅▃▃▂▁▅▅▄▃▆▅
wandb:      train/ensemble_f1 ▄▅▂▄▅▃▂▃▁▂█▆▄▄▄▅▆▄▄▃▃▃▄▅▅▄▃▂▆▃▆▄▅▄▅▂▄▂▄█
wandb:         train/mil_loss ▃▁▅▂▄▂█▂▃▃▃▆▂▁▁▄▆▂▂▅▄▁▄▂▂▂▆▄▅▁▃▂▇▂▃█▂▂▃▂
wandb:      train/policy_loss ▇▄▄▇▆▄▆▃▄▆▆▆▃▆▆▇▄▃▅▄█▃▃▆▆▂▃▄▂▅▆▂▄▅▅▆▅▁▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇█▅▅▅▆▇▂▄▆▆▇▆▇█▅▃▃▅▅▇▃▆▁▆▃▆▅▆▃▅▆▆▆▆▆▂▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.48997
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.38785
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.92338
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34451
wandb:      train/ensemble_f1 0.34451
wandb:         train/mil_loss 1.1899
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fb14bzyc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015324-fb14bzyc/logs
wandb: Agent Starting Run: ut39jv3r with config:
wandb: 	actor_learning_rate: 0.00017533000190439867
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.964381662460763
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.009360102187912611
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015508-ut39jv3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ut39jv3r
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ████▆▆▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▄▃▃▃▃▅▁▇▄▁▃▃▂▅█▅▅▆▆▂▃▆▆▅▄▆▅▄▄▄▅▇▅▅▆▇▄
wandb:      train/ensemble_f1 ▃▃▄▄▅▇▄▃▅█▅▆▃▅▇▆▃▁▄▃▅▇▆▃▃▆▆▅▆▆▄▅▄▅▅▅▂█▄▇
wandb:         train/mil_loss █▆▅▆▇▄▆▃▆▆▄▅▅▆█▄▃▃▆▄▁▄▄▁▃▇▄▅▄▆▂▆▄▃▅▁▃▄▄▃
wandb:      train/policy_loss ██▇█▆▇▁▁▁▁▁▁▁▁▁▁▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.22263
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.20868
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.08715
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.94183
wandb:      train/ensemble_f1 0.94183
wandb:         train/mil_loss 0.1961
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q7238ncg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015434-q7238ncg/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆█
wandb: best/eval_avg_mil_loss ▁▅██▆
wandb:  best/eval_ensemble_f1 ▁▃▄▆█
wandb:            eval/avg_f1 ▁▁▁▃▁▁▁▁▁▁▁▃▆▆▆▆▆▆██████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▆████▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▄▄▄▄▃▃▃▃▃
wandb:       eval/ensemble_f1 ▁▁▃▁▁▁▁▁▁▁▁▁▃▃▆▆▆▆▆▆▆███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▃▂▃▂▂▃▄▃▄▃▄▄▅▁▃▆▆▅▆▄▄▅▅▆▆▅▅▇▆▆█▆▇▇█▆▅
wandb:      train/ensemble_f1 ▃▃▅▃▅▂▁▁▂▂▃▂▂▂▂▃▆▅▆▅▄▄▃▅▆▅▇▃▆▄▄██▆▄▇▃▇▆▅
wandb:         train/mil_loss ▄▄▆▂▄█▅▃▄▂▆▄▅▄▆▅▆▄▅▇▅▄▅▄▅▅▃▂▃▁▆▃▃▆▆▄▇▃▄▅
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▁▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42241
wandb: best/eval_avg_mil_loss 2.71525
wandb:  best/eval_ensemble_f1 0.42241
wandb:            eval/avg_f1 0.42241
wandb:      eval/avg_mil_loss 2.61972
wandb:       eval/ensemble_f1 0.42241
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 3.19207
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.38972
wandb:      train/ensemble_f1 0.38972
wandb:         train/mil_loss 1.5012
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aebmdfnu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015415-aebmdfnu/logs
wandb: Job received.
wandb: Agent Starting Run: wu9exkds with config:
wandb: 	actor_learning_rate: 0.007869381228117013
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1840297159748272
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3651323656319596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015750-wu9exkds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wu9exkds
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: syuoedy7 with config:
wandb: 	actor_learning_rate: 0.00013911891800589751
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.513243339975229
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5261517178143449
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015759-syuoedy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/syuoedy7
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████
wandb:      eval/avg_mil_loss ▆▆▆▆▆▇▇▇▇███▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▄▅▅▄▄▄▄▄▄▅▅
wandb:       eval/ensemble_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▃▅▅▆▄▅▃▄▆▅▄▁▇█▅▅▅▅▄▅▅▃▆▄▄▅▆▃▃▇▅▅▄▅▄▅▄
wandb:      train/ensemble_f1 ▄▄▄▃▇▅▅▄▅▇▅▆▇█▆▅▅▅▄▁▅▄▃▄▆▄▅▃▆▃▇▁▅▅▁▃▅▃▄▄
wandb:         train/mil_loss ▃▅▅▆█▇▆▆▅▆▂▃▂▂▄▆▃▄▂▆▃▄▃▄▄▅▆▆▄▆▄▄▅▂▅▄▃▁▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.2443
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.24219
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.33304
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.87361
wandb:      train/ensemble_f1 0.87361
wandb:         train/mil_loss 0.25637
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/syuoedy7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015759-syuoedy7/logs
wandb: Agent Starting Run: 00osnqye with config:
wandb: 	actor_learning_rate: 0.00109690630652389
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5508926794220812
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4634914742683181
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_015943-00osnqye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00osnqye
wandb: uploading history steps 286-297, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss ██▇▆▅▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▃▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▃▃▃▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▁▃▃▂▂▅▂▃▃▄▃▂▃▃▃▆▄▄▅▄▅▅▅▆▇▅▇▆██▆▇▆▅▆▇█▅
wandb:      train/ensemble_f1 ▁▂▄▂▅▅▄▄▄▃▅▄▇▄▄▄▅▄▇▇▆▆█▇▇▇▇▇▆▆▇▇▇▅▆▇▆▇█▇
wandb:         train/mil_loss █▄▅▅▆▆▃▄▄▂▆▅▄▄▂▃▃▂▃▃▃▁▃▂▃▂▁▄▃▃▄▂▃▅▅▃▆▅▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73958
wandb: best/eval_avg_mil_loss 0.70409
wandb:  best/eval_ensemble_f1 0.73958
wandb:            eval/avg_f1 0.73958
wandb:      eval/avg_mil_loss 0.65422
wandb:       eval/ensemble_f1 0.73958
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.60769
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.61357
wandb:      train/ensemble_f1 0.61357
wandb:         train/mil_loss 0.23636
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ut39jv3r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015508-ut39jv3r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pyhkkba9 with config:
wandb: 	actor_learning_rate: 0.0023095411657457947
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7628142867031562
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8472801965657297
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020002-pyhkkba9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pyhkkba9
wandb: uploading history steps 156-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁████
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁████
wandb:            eval/avg_f1 ▁▁█▇▇▇▇▇████████████████████████████████
wandb:      eval/avg_mil_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▄▃▅▆▅▄▃▅▅▄▅▂▂▄▄▄▆▁▆▆▄▅▃▇▂▇▃▃▄█▂▅▂▆▆▄▄
wandb:      train/ensemble_f1 ▁▂██████████████▇█▇█████████▇███████████
wandb:         train/mil_loss █▂▂▁▂▂▂▂▂▂▂▁▁▂▁▂▁▁▂▁▁▂▂▂▂▂▁▁▂▁▂▁▁▁▁▂▁▁▁▂
wandb:      train/policy_loss █▁██████████████▇███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▄▅▆▇▆█▁▁▁▇▇▇▆▇▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.2493
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.21788
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.08422
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91246
wandb:      train/ensemble_f1 0.91246
wandb:         train/mil_loss 0.21802
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wu9exkds
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015750-wu9exkds/logs
wandb: Agent Starting Run: eq1ew9i9 with config:
wandb: 	actor_learning_rate: 2.1488680480305267e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3937111043801575
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08453679852338725
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020031-eq1ew9i9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eq1ew9i9
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▃▃▂▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆█
wandb:      eval/avg_mil_loss ▂▁▁▁▁▆▆▆▇▇████████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▃▃▂▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇██▇▇█▃▃▄▄▃▂▂▁▂▃▅▁▂▅▆▄▄▄▄▅▄▃▅▄▆▅▄▃▄▆▅▄
wandb:      train/ensemble_f1 ▆██▇█▄▄▄▄▃▄▃▂▂▁▃▃▃▃▄▂▃▄▅▂▅▃▅▅▅▄▆▅▅▅▃▄▆▄▇
wandb:         train/mil_loss ▄▅▅▆▂▂▁▅▆▅▄▅▆▅▅▄▄▇▆▂▅▆▆▆▇▅▇▅▃▄▄▂▅▅▅▄█▅▅█
wandb:      train/policy_loss ▆▆▆▆▆█▆▆▆▆▆▅▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▄▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42241
wandb: best/eval_avg_mil_loss 2.35323
wandb:  best/eval_ensemble_f1 0.42241
wandb:            eval/avg_f1 0.42241
wandb:      eval/avg_mil_loss 2.51147
wandb:       eval/ensemble_f1 0.42241
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.6713
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.48337
wandb:      train/ensemble_f1 0.48337
wandb:         train/mil_loss 1.5468
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00osnqye
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015943-00osnqye/logs
wandb: Agent Starting Run: wjilutzx with config:
wandb: 	actor_learning_rate: 0.003377162525669273
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.38960105951394663
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7598585051741424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020126-wjilutzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wjilutzx
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆█████████████████████████
wandb:      eval/avg_mil_loss ▄▄▄▄▄▄▄▁▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▆▆▆▆▆▆▆████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▁▄▁▁▆▇▇▄▃▂▅▃▅▄▅▄▄▆▆▂▄▄▆▂▆▃▅▃█▅▇▆▅▂▂▅▅▃
wandb:      train/ensemble_f1 ▁▆▅▆▅▆█▃▂▆▁▃▄▆▄▃▆▃▅▃▅▂▅▅▁▃▁▃▄▄▄▆▄▄▄▁▃▂▂▂
wandb:         train/mil_loss ▄▄▂▅▄▅▆▆▃▅▃▂▅▆▃▆▅▂▆▂▁▁█▂▄▁▂▅▅▄▁▂▃▄▅▃▃▃▄▃
wandb:      train/policy_loss █▂█████████▃▄▇▄▄▃▅▂▂▄▂▃▅▅▇▄▅▁▁▃▃▅▅█▃▁▅▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▄▄▆▄▅▄▅▄▄▅▄▁▄▄▄▄▅▄▂▅▂▅▃▄█▁▅▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.21088
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.22515
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.21215
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.88169
wandb:      train/ensemble_f1 0.88169
wandb:         train/mil_loss 0.28484
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pyhkkba9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020002-pyhkkba9/logs
wandb: Agent Starting Run: 2gioatut with config:
wandb: 	actor_learning_rate: 0.0003188574231141676
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8779896510323337
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3095652274619226
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020157-2gioatut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gioatut
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▄▄▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁███████▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▆▂▃▄▃▂▄▅▃▃█▄▆▄▃▃▆▆▇▂▃▅▄▆▆▄█▆▄▂▄▁▃▅▃▄▄
wandb:      train/ensemble_f1 ▄█▃▄▆▃▄▄▂▃▁▄▅▃█▆▂▇▆▄▁▂▅▅▆▄▅▂▆▂▄█▄▄▁▃▅▄▅▄
wandb:         train/mil_loss █▆▃▇▅▇▆▃█▇▆▄▆▅▇█▇▆▆▅▂▂▇▇▄▁▃▅▂█▂▄▄▄▅▄▄▁▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82
wandb: best/eval_avg_mil_loss 0.39553
wandb:  best/eval_ensemble_f1 0.82
wandb:            eval/avg_f1 0.82
wandb:      eval/avg_mil_loss 0.39728
wandb:       eval/ensemble_f1 0.82
wandb:            test/avg_f1 0.86894
wandb:      test/avg_mil_loss 0.42927
wandb:       test/ensemble_f1 0.86894
wandb:           train/avg_f1 0.85744
wandb:      train/ensemble_f1 0.85744
wandb:         train/mil_loss 0.27082
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earnest-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eq1ew9i9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020031-eq1ew9i9/logs
wandb: Agent Starting Run: vmdeus6k with config:
wandb: 	actor_learning_rate: 0.0003291152284584757
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7011274293202284
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.523862598818933
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020215-vmdeus6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmdeus6k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▂▁▁▁▁▁▁▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆███████
wandb:      eval/avg_mil_loss ▁▁▂▅▆▇▇▇▇▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▆▆
wandb:       eval/ensemble_f1 █▇▄▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███▄▃▂▂▂▂▂▂▁▂▂▂▂▂▁▁▃▁▁▂▂▁▁▂▂▃▂▂▂▂▁▂▂▂▃▂▂
wandb:      train/ensemble_f1 █▇▄▃▂▂▂▂▂▂▂▂▃▂▁▂▂▂▁▂▂▂▂▂▂▁▁▂▂▂▂▃▃▂▃▂▃▃▃▃
wandb:         train/mil_loss ▂▆▂▇▆▃▇▂█▄▂▃▅▃▅▆▅▂▅▇▄▂▆▆▇▄▄▄▃▂▄▅▃▃▁▆▃▆▇▅
wandb:      train/policy_loss ████████████████████▁███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78214
wandb: best/eval_avg_mil_loss 0.31462
wandb:  best/eval_ensemble_f1 0.78214
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 1.08182
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.79992
wandb:      test/avg_mil_loss 0.48795
wandb:       test/ensemble_f1 0.79992
wandb:           train/avg_f1 0.56952
wandb:      train/ensemble_f1 0.56952
wandb:         train/mil_loss 0.40042
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gioatut
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020157-2gioatut/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████
wandb:      eval/avg_mil_loss ▄▄▄▃▁▃▃▄▄▅▆▆▆▆▆▆▆▅▇▇▆▇▆▇▇▆▅▅▆▆▇███▇▇▇▇▇█
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▅▅▇▆▄▃▂▅▄▁▅▅▇▆▆▂▃▅▅▅▅▅▃█▁▄▅▅▄▂▃▄▆▄▅▂▃▇
wandb:      train/ensemble_f1 █▃▅▃▇▂▅▂▃▃▅▃▇▂▄▄▄▃▁▄▃▅▃▃▄▅▅▄▂█▃▄▄▄▄▅▃▁▅▅
wandb:         train/mil_loss ▂▃▅▃▃▆▆▄▄▅▄▂▆▃▁▅▆▅▄▄▂▅▂█▃▄▆▂▁▂▁▁▅▃▄▃▃▁▄▄
wandb:      train/policy_loss █▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▄▆▇▅▂▅▇▅▅▅▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▄▃▆▃▅█▅▄▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.27386
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.27776
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.08923
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.92697
wandb:      train/ensemble_f1 0.92697
wandb:         train/mil_loss 0.25311
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earnest-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmdeus6k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020215-vmdeus6k/logs
wandb: Job received.
wandb: Agent Starting Run: vyz0aco9 with config:
wandb: 	actor_learning_rate: 0.0002449563744012331
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.044770466853809365
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21263597285445743
wandb: Agent Starting Run: kwaxoxzh with config:
wandb: 	actor_learning_rate: 0.0003755193249907853
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18314332579800685
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8869398232419067
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020359-vyz0aco9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vyz0aco9
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020401-kwaxoxzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwaxoxzh
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▃▂▃▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:      eval/avg_mil_loss █▇▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▄▄▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▂▂▂▃▄▄▆▅▆▅▆▆▆▆▆▇▆▇▇▇▇█▇█▇▇████▇████▇
wandb:      train/ensemble_f1 ▁▁▁▂▁▂▂▃▃▃▄▄▄▅▅▆▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇
wandb:         train/mil_loss ▅▆███▄▆▇▆▆▄▇▆▅▄▄▅▃▂▆▃▄▄▄▄▄▄▃▁▄▃▄▃▄▃▄▃▂▄▄
wandb:      train/policy_loss █▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▆▅▆▁▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████▁█████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78639
wandb: best/eval_avg_mil_loss 0.41931
wandb:  best/eval_ensemble_f1 0.78639
wandb:            eval/avg_f1 0.78639
wandb:      eval/avg_mil_loss 0.41448
wandb:       eval/ensemble_f1 0.78639
wandb:            test/avg_f1 0.81993
wandb:      test/avg_mil_loss 0.45255
wandb:       test/ensemble_f1 0.81993
wandb:           train/avg_f1 0.81949
wandb:      train/ensemble_f1 0.81949
wandb:         train/mil_loss 0.33471
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/45q4u456
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_015154-45q4u456/logs
wandb: Sweep Agent: Waiting for job.
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁███▇▇▇▇█▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▃▅▄▇▂▇▄▄▇▃▂▂▆▆▃▄▃▁▃▃▄▂▅▄▆▃▂▄█▆▆▅▆▁▄▆▄
wandb:      train/ensemble_f1 ▄▄▅▅▃▅▃▇▃▇▃▅▆▇▆▃▄▄▃▆▄▄▅▄▅▆▃▅▅▆▆▁▃█▆▆▁▇▄▄
wandb:         train/mil_loss ▄▄▇▄▃▂▇▄▄█▄▅▄▁▄▅▅▅▆▄▅▄▄▁▂▅▅▂▆▅▅▂▂█▁▃▁▇▅▆
wandb:      train/policy_loss ▃▁▁▃▁▃▁▃▃▃▁▆▄▁▃▁▁▃▁▁▃▄▆▃▃▃▃▁▆▅▁▃▃▁▆█▁▁▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▅▁▂▂▄▂▂▂▁▅█▄▁▄▁▂▂▁▁▂▅▂▂▅▂▂▁▂▂▂▂▂▁▄▂▇▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.96103
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.97979
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.33113
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 1.67123
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vyz0aco9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020359-vyz0aco9/logs
wandb: Agent Starting Run: 9ich1e4k with config:
wandb: 	actor_learning_rate: 0.001019169362844065
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2665952982500406
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5947008731082145
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020543-9ich1e4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ich1e4k
wandb: Job received.
wandb: Agent Starting Run: s4uolmp0 with config:
wandb: 	actor_learning_rate: 3.953685004405665e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9193319732780822
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8848774462770653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020558-s4uolmp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4uolmp0
wandb: uploading history steps 219-223, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▇▇▇██
wandb: best/eval_avg_mil_loss █▆▄▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▇▇▇██
wandb:            eval/avg_f1 ▁▆▇▇▇███████████████████████████████████
wandb:      eval/avg_mil_loss █▄▄▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█████████████▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▆█▆▅▆▅▅▅▇▅▅▇▆▆▄▇▆▇█▅█▇▆█▇▇█▇▆▆▆▆▇▆▄█▇
wandb:      train/ensemble_f1 ▇▄▃▄▄▁▅▅▂▄▆▃▄▃▅▄▄▅▇▆▄▅█▆▇▃█▄▄▆▅▅▆▆▆▆▇▇▅█
wandb:         train/mil_loss ▇█▆▄▂▂▁▂▂▂▁▁▁▁▂▁▁▂▁▁▂▁▂▁▁▂▂▂▂▁▁▁▁▁▂▂▁▁▁▂
wandb:      train/policy_loss █▂▇▅▅▂▂▂▃▂▂▂▃▂▂▂▂▂▂▅▅▅▅▅▅▅▅▅▅▅▅▂▁▂▂▃▃▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▂▅▂▅▃▂▃▅▁▃▃▂▄▂▂▂▂▂▁█████████████▂▃▃▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.35615
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.82985
wandb:      eval/avg_mil_loss 0.35493
wandb:       eval/ensemble_f1 0.82985
wandb:            test/avg_f1 0.9179
wandb:      test/avg_mil_loss 0.26112
wandb:       test/ensemble_f1 0.9179
wandb:           train/avg_f1 0.86997
wandb:      train/ensemble_f1 0.86997
wandb:         train/mil_loss 0.26934
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwaxoxzh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020401-kwaxoxzh/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆███
wandb: best/eval_avg_mil_loss █▃▁▁▁
wandb:  best/eval_ensemble_f1 ▁▆███
wandb:            eval/avg_f1 ▁▁▆█████▇▇▇▇▇▇▇█████████████████████████
wandb:      eval/avg_mil_loss ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁████▇▇▇▇▇▇▇▇██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇▇▇████▇█▇
wandb:      train/ensemble_f1 ▁▁▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇███▇█▇▇▇▇██▇██▇
wandb:         train/mil_loss ▇█▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▂▁▂▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▇▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.19055
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.20209
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.89936
wandb:      test/avg_mil_loss 0.38262
wandb:       test/ensemble_f1 0.89936
wandb:           train/avg_f1 0.88375
wandb:      train/ensemble_f1 0.88375
wandb:         train/mil_loss 0.29394
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ich1e4k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020543-9ich1e4k/logs
wandb: Agent Starting Run: s6l0gxb7 with config:
wandb: 	actor_learning_rate: 5.632147291978487e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9645507481433946
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3004743761525225
wandb: Agent Starting Run: f7ul2zec with config:
wandb: 	actor_learning_rate: 0.003863750450371091
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11337980050413764
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1280957856526862
wandb: uploading history steps 90-103, summary
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020742-s6l0gxb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s6l0gxb7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▄▆▄▅▅▄▆▄▆█▆▆▅▃▄▃▄▂▃▃▄▃▃▂▄▃▂▅▄▅▄▃▄▃▅▂▅▅
wandb:      train/ensemble_f1 ▄▄▄▅▆▄▇▄▅▇▃▄▆▄█▅▁█▃▃▆▃▂▃▃▂▄█▆▂▄▄▄▃▃▄▂▄▄▁
wandb:         train/mil_loss ▅█▆▇▆▃▄▆▄▃▄▆▄▃▄▂▃▄▆▅▃▄▆▄▃▃▃▁▃▃▄▃▂█▄▁▂▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.28413
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.32923
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.904
wandb:      test/avg_mil_loss 0.20555
wandb:       test/ensemble_f1 0.904
wandb:           train/avg_f1 0.86588
wandb:      train/ensemble_f1 0.86588
wandb:         train/mil_loss 0.27977
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4uolmp0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020558-s4uolmp0/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020743-f7ul2zec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f7ul2zec
wandb: Agent Starting Run: 9kaatp4k with config:
wandb: 	actor_learning_rate: 1.0556335074552067e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7940048819553576
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9604148973862412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020747-9kaatp4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kaatp4k
wandb: uploading history steps 485-499, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▆▆▅▅▅▅▄▄▄▃▃▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████████
wandb:      eval/avg_mil_loss ████▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▃▃▃▄▃▄▃▄▄▅▄▄▅▄▆▅▆▆▆▆▇▆▆▇▇██▇█▇▇█▇██▇
wandb:      train/ensemble_f1 ▁▁▁▁▃▂▃▄▃▃▄▄▅▄▅▄▅▄▅▄▅▅▆▆▆▇▆▆▆█▇▆▇▇▆▇▇█▇█
wandb:         train/mil_loss █▅▃▅▅▄▃▄▄▄▅▇▆▃▄▂▃▄▂▄▄▃▅▂▂▂▃▃▂▃▅▃▄▃▃▂▄▃▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▁▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▇▆▅█▅▄▁▃▂▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7426
wandb: best/eval_avg_mil_loss 1.42152
wandb:  best/eval_ensemble_f1 0.7426
wandb:            eval/avg_f1 0.7426
wandb:      eval/avg_mil_loss 1.32734
wandb:       eval/ensemble_f1 0.7426
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 1.95494
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.65276
wandb:      train/ensemble_f1 0.65276
wandb:         train/mil_loss 0.62877
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wjilutzx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020126-wjilutzx/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 █████▃▃▂▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▂▂▂▁▃██▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ███▇▄▃▃▄▂▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇██▇▄▃▁▅▅▅▅▅▄▅▅▅▅▅▄▅▆▅▅▆▅▆▅▆▆▆▆▆▆▆▆▇▆▆▆
wandb:      train/ensemble_f1 ▇▇█▇▇▆▃▂▃▂▁▂▃▃▂▃▃▃▃▃▃▃▃▄▄▄▄▄▃▃▄▄▄▅▄▅▅▄▆▅
wandb:         train/mil_loss ▂▂▁▁▅▆▅▅▇█▇▅▅▄▄▃▄▄▄▃▃▃▃▃▄▃▃▃▃▃▂▃▃▃▃▄▃▂▃▂
wandb:      train/policy_loss ▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄█▄▄▄▄▄▄▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████▁███████████████▆███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.18548
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.77965
wandb:      eval/avg_mil_loss 0.39553
wandb:       eval/ensemble_f1 0.77965
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.15264
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.82863
wandb:      train/ensemble_f1 0.82863
wandb:         train/mil_loss 0.27909
wandb:      train/policy_loss 0.02984
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.02984
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f7ul2zec
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020743-f7ul2zec/logs
wandb: Agent Starting Run: bb1u8f2h with config:
wandb: 	actor_learning_rate: 0.00017026515287017866
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7608182189631575
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4540137394556987
wandb: uploading history steps 89-103, summary
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_020931-bb1u8f2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bb1u8f2h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▂▂▃▅▇▅▄▅▁▆▅▄▄▅▄▅▃▄▃▄▄▅█▄▅▅▆▆▄▄▇▆▆▇▆▇▅
wandb:      train/ensemble_f1 ▃▅▄▆▄▂▅▅▁▅▃▁▆▄▅▅▄▃▃▅█▄▅▇▅▇▅▆▇▆▄▇▆▇▇▇▃▆▆▇
wandb:         train/mil_loss ▃▆▁▃▆▄▅▂▂▅▄▂▂▄▆▁▁▂▅▆▃█▃▅▃▃▄▄▃▄▅▃▃▃▂▂▄▁▃▂
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▅▃▂▃▆▅▂▂▅▅▅▃█▁▁▃▄▅▂▃▂▃▅▂▅▃▅▁▅▇▄▅▃▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67033
wandb: best/eval_avg_mil_loss 3.99799
wandb:  best/eval_ensemble_f1 0.67033
wandb:            eval/avg_f1 0.66154
wandb:      eval/avg_mil_loss 3.84708
wandb:       eval/ensemble_f1 0.66154
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 5.34423
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.66831
wandb:      train/ensemble_f1 0.66831
wandb:         train/mil_loss 0.69677
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kaatp4k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020747-9kaatp4k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zrc217pl with config:
wandb: 	actor_learning_rate: 4.585092280997661e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41411846859326074
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.569605415352382
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021003-zrc217pl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zrc217pl
wandb: Job received.
wandb: Agent Starting Run: ufk2op3k with config:
wandb: 	actor_learning_rate: 0.00016662421304035278
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3932148013372281
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3872592836329184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021012-ufk2op3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ufk2op3k
wandb: uploading history steps 129-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▅▅▅▅▅▅▅▅▅████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▅▅▅▅▅▅███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▁▆▄▅▄▆▅█▄▄▆▄▆▄▃▄▃▄▆▅▄▃▅▇▆▅▅▆▅▇▆▆▅▅▆▆▆
wandb:      train/ensemble_f1 ▂▁▄▁▆▃▄▄▅▆▂▃▆▃▃▄▆▄▄▅▂▄▄▅▂▅▄▆▃▃▆▃█▄▆▄▇▅▅▄
wandb:         train/mil_loss ▃▄█▄▄▆▆▆▂▃▃▂▄▄▃▄▂▁▂▃▆▄▂█▂▂▇▂▃▂▂▅▆▅▄▅▄▂▂▇
wandb:      train/policy_loss ▂▁▃▃▃▃▃▃▃▃▅▆▃▆▆▅▅▆▇▆▆▇▇▇▆▆▅▆▇▅▆▆▅▆▇▅▆▇█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃█▅▇▅▇▄▅▃▅▇▆▅▅▅▅▃▆▆▆▃▄▄▆▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 2.71652
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.60613
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 3.14903
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.47024
wandb:      train/ensemble_f1 0.47024
wandb:         train/mil_loss 1.00618
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bb1u8f2h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020931-bb1u8f2h/logs
wandb: Agent Starting Run: 95sqkbfm with config:
wandb: 	actor_learning_rate: 0.0004971603589652822
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9168081627333484
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6651125000624407
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021147-95sqkbfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95sqkbfm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▃▃▃▃▃▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████▇███
wandb:       eval/ensemble_f1 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▆▅▂▇▅▁▅▂▇▅▄▅█▄▂▄▃▄▇▄▆▃▃▂▄▄▅▄▂▅▄▇▆▅▅▃▇
wandb:      train/ensemble_f1 ▂▆▃▅▅▄▆▅▂▁▇▆▅▄▃▄█▄▁▅▄▅▇▃▆▃▂▄█▁█▅▄▄▃▁▅▅▁▄
wandb:         train/mil_loss ▆▇▄▅▆▄▅▄▇▂▅▃▅▃▁▆▇▃▃▃▂█▅▆▅▅▇▅▅▅▆▅▂▇▇▂▃▄▂▅
wandb:      train/policy_loss ▃▄▄▆▂▃▄█▃▅▃█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▅▇▅█▃█▂▄▅▅▆▃▄▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.16264
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.17466
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.94914
wandb:      test/avg_mil_loss 0.12244
wandb:       test/ensemble_f1 0.94914
wandb:           train/avg_f1 0.93621
wandb:      train/ensemble_f1 0.93621
wandb:         train/mil_loss 0.214
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ufk2op3k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021012-ufk2op3k/logs
wandb: Agent Starting Run: vsee0pny with config:
wandb: 	actor_learning_rate: 0.0002509866116600629
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27276837123734043
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4517222352268804
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021155-vsee0pny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vsee0pny
wandb: uploading history steps 305-315, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅▆█
wandb: best/eval_avg_mil_loss █▅▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅▆█
wandb:            eval/avg_f1 ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▆▆▆▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▁▃▂▆▅▅▅▆▄▄▆▆▆▅▇▅▇▆▆▄▇▅▇▆▇▅▅▇▇█▆▅█▇██▆▆
wandb:      train/ensemble_f1 ▅▃▂▁▅▅▆▅▆▇▅▆▃▄▅▅▄▅▇▅▇▆▆▆▅▇▅▆▆▇▅█▇█▇▇▆▇▆█
wandb:         train/mil_loss ▆▆▅█▆▅▃█▇▆▅▄▂▄▃▄▆▃▅▃▃▂▁▄▂▅▂▁▅▂▂▂▃▂▂▃▄▂▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▂▁▁▁▅▅▅▅▅▅▅▅▂▁▁▁▁▃▁▁▁▁▁▁▂▂▁▂▁▁▁▁▂▁▂▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.13537
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.92999
wandb:      eval/avg_mil_loss 0.13563
wandb:       eval/ensemble_f1 0.92999
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.49021
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.86247
wandb:      train/ensemble_f1 0.86247
wandb:         train/mil_loss 0.28675
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s6l0gxb7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_020742-s6l0gxb7/logs
wandb: Agent Starting Run: at9mchek with config:
wandb: 	actor_learning_rate: 2.116664554990356e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03337307276243906
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14982004914025435
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021242-at9mchek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/at9mchek
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▁▄▆█▅▃▃▂▂▃▇▄▄▅▄▆▃▁▅▄▆▄▂▅▃▂▂▃▄▃▅▅▂▆▆▃▅▆
wandb:      train/ensemble_f1 ▂▅▄▁▅▄█▃▃▇▄▁▅▃▅▆▄▂▅▃▄▂▃▅▃▁▃▃▁▃▃▄▄▅▂▆▆▆▃▅
wandb:         train/mil_loss ▃▅▃▄▅▄▃▃▃█▃▅▁▅▅▆▇▅▅▃▅▂▁▁▅▄▁▅▁▂▂▂▁▃▄▅▄▆▆▅
wandb:      train/policy_loss ▇▆▅▇▇▆▇▆▆▅▄▅▅█▇▃▅▄▇▇█▆▄▅▄▅▂▇▇█▆▆▆▆▃▄█▁▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▇▅▅▄▅▇▇█▂▇▇▅▂▄█▄▅▇▇▂▄█▂▄▄▄▇▇▅▁▅██▅▅▅▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40229
wandb: best/eval_avg_mil_loss 2.83549
wandb:  best/eval_ensemble_f1 0.40229
wandb:            eval/avg_f1 0.40229
wandb:      eval/avg_mil_loss 2.72136
wandb:       eval/ensemble_f1 0.40229
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 3.26003
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.38414
wandb:      train/ensemble_f1 0.38414
wandb:         train/mil_loss 0.43252
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95sqkbfm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021147-95sqkbfm/logs
wandb: Agent Starting Run: 2bcxja3f with config:
wandb: 	actor_learning_rate: 0.0031235002932347013
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8508818949363672
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4861467972652651
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021331-2bcxja3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2bcxja3f
wandb: uploading history steps 267-279, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▆▇█
wandb: best/eval_avg_mil_loss █▆▅▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▄▅▅▆▆▆▆▆▇▇▇▇▇██████▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▂▂▂▄▄▅▆▆▆▆▆▆▆▇▇▇▇██████▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▁▁▂▂▂▁▃▃▃▂▃▃▄▄▃▅▄▅▅▅▅▇▅▅▇▆▆█▇▇▇▆▇▆▇
wandb:      train/ensemble_f1 ▁▁▂▁▂▂▂▂▃▃▁▃▄▃▃▄▆▅▄▅▅▇▅▅▄▆▄▅▅▆▇▆▆▅█▇▆▇██
wandb:         train/mil_loss ▇▅▄█▅█▆▆▆▄▆▂▃▄▅▅▃▄▃▂▇▄█▆▆▆▆▄▅▆▁▃▆▄▃▅▄▅▆▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅█▇▅▄▁▃▁▃▃▃▁▁▅█▇▅▅▁▄▅▂▂▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▇▅▅▄▄▄▅▄▄▄▁▁▁▃▃▂▃▅▅█▆▆█▃▃▃▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 5.12221
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 4.92648
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 5.92336
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.47604
wandb:      train/ensemble_f1 0.47604
wandb:         train/mil_loss 3.0551
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zrc217pl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021003-zrc217pl/logs
wandb: Agent Starting Run: cxsez7o2 with config:
wandb: 	actor_learning_rate: 0.0010777726330036212
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08874367980888553
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3227615756623181
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021452-cxsez7o2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cxsez7o2
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████████████▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ██████████████████████████████████▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▃▃▇▄▄█▆▆▅▇▄▅▆▂▂▃▃▄▆▄▃▇▄▁█▄▄▅▆▅▄▄▃▂▅▁▆
wandb:      train/ensemble_f1 ▃▅▁▅▃▄▆▄▄▃▆▃▅▄▃▆▅▆▄▅▃▆█▃▅▄▄▄▃▄█▅▃▂▆▅▅▄▃▅
wandb:         train/mil_loss ▁▄▃▃▃▅▅▇▄▄▂▅▃▅▄▃▅▅▄▆█▃█▂▄▃▁▁▅▅▄▆▃▁▇▅▁▄▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.33853
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.3682
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11395
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88612
wandb:      train/ensemble_f1 0.88612
wandb:         train/mil_loss 0.25709
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2bcxja3f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021331-2bcxja3f/logs
wandb: Agent Starting Run: znum2trd with config:
wandb: 	actor_learning_rate: 0.00013628596688173035
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7440386090977897
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5687426832383632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021514-znum2trd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znum2trd
wandb: uploading history steps 202-217, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▆▁▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆████████████████████
wandb:      eval/avg_mil_loss ██▇▇█▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▄▄▄▁▅▂▆▄▃▃▅▄▃▅█▄▆▂▃▆▅▄▅▅▃▅▅▅▇▃▃▄▆▅▃▆▅
wandb:      train/ensemble_f1 ▁▂▃▁▃▄▅▃▂▃▁▂▇▄▆▆▃▆▅▆▇▄▅▂▃▂█▆▅▇▄▆▇▄▄█▃▅▃▇
wandb:         train/mil_loss █▂▃▅▆▄▂▅▄▁▅▃▄▆▁▂▃▆▂▄▇▇▇▄▃▅▃▄▄▅▇▃▂▆▄▆▇▅▃▇
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▆█▄▇▄▅▅▄▆▄▅▆▆▆▆▇▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.23544
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.22633
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.11547
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.92142
wandb:      train/ensemble_f1 0.92142
wandb:         train/mil_loss 0.22597
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vsee0pny
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021155-vsee0pny/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oypp717p with config:
wandb: 	actor_learning_rate: 3.763782329565949e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02067877061029688
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40364677785375225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021548-oypp717p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oypp717p
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▅▅▅▅▅▆▅▄▅▅▁▁▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆█▇▇██
wandb:       eval/ensemble_f1 █████████████████████████▆▆▆▆▆▆▆▆▆▆▃▃▃▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▇▂▆▂▆█▆▄▁▅▄▅▄▇▃▄▅▅▄▂▄▄▄▅▆▅▆▄▃▄▄▅▄▂▃▅▃
wandb:      train/ensemble_f1 ▅█▂▇█▃▆▁▄▆▃▇▂▂▅▇▆▆▅▆▅▆▄▅▆▆▃▆▃▄▂▅▃▄▂▆▆▃▅▅
wandb:         train/mil_loss ▇▃▅▅▆█▃▄▅▆▃▇▄▁▅▄▃▄▆▆▅▅▄▆▅▅█▃▅▄█▄▄▄▄▄▆▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▁▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.33507
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.82792
wandb:      eval/avg_mil_loss 0.33844
wandb:       eval/ensemble_f1 0.82792
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.1482
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.88957
wandb:      train/ensemble_f1 0.88957
wandb:         train/mil_loss 0.27729
wandb:      train/policy_loss -0.10504
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.10504
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znum2trd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021514-znum2trd/logs
wandb: Agent Starting Run: bd49lngg with config:
wandb: 	actor_learning_rate: 0.00026928967658508643
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08976113244212891
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5749624475128082
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021658-bd49lngg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bd49lngg
wandb: uploading history steps 120-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▅▅▅██████████████████████████████
wandb:      eval/avg_mil_loss █▇▆▅▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▅▇▃▄▅▄▅▃▄▆▂▅▅▆▅▅▇▄▆▃█▃▄▄▅▆▄▅▆▅▅▆█▆▂▇▇
wandb:      train/ensemble_f1 ▃▁▄▅▆▄▃▃▄▄▂▅▃▄▄▅▄▅▅▅▅▄▄▃▅▆▄▅▇█▆▆▇▄▂▆▄▂▆▄
wandb:         train/mil_loss ▇▆▄▅▅▅▆▅▆▄▃▃▃█▄▂▅▅▅▃▄▃▅▃▃▄▂▃▁▅▄▄▁▃▄▃▆▃▁▄
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.24603
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.22421
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18664
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.90215
wandb:      train/ensemble_f1 0.90215
wandb:         train/mil_loss 0.31731
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cxsez7o2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021452-cxsez7o2/logs
wandb: Agent Starting Run: 9uz48e30 with config:
wandb: 	actor_learning_rate: 3.851823089517679e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23713255372585473
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7612782429351395
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021712-9uz48e30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9uz48e30
wandb: uploading history steps 109-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss ██▇▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▁████▆▆▆████▆▆▃▃▃▆▆▆▃▃▃▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▅▅▅▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃██▆████▃▃▃▃▃▆▆▆▃▃▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▁▄▄▂▂▆▅▄▅▂▄▆▃▄▅▄▅▅▅▅▅▅▅▄▇▇▇▅▇▅▄█▇█▇█▆▆
wandb:      train/ensemble_f1 ▁▁▂▄▃▅▃▃▄▅▅▆▄▂▅▆▄▃▅▄▅▄▄▅▄▄▄▅▆▇▇▃▇▇▄▆█▅▅▅
wandb:         train/mil_loss ▇██▇▆▆▆▅▇▄▇▄▇▆▅▃▆▂▅▄▃▄▃▄▃▄▄▄▅▃▃▃▃▃▁▄▁▃▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▇▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▇█▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.24245
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.22437
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.25091
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.90108
wandb:      train/ensemble_f1 0.90108
wandb:         train/mil_loss 0.25094
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oypp717p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021548-oypp717p/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.32.4:39984->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 7yy3b4ty with config:
wandb: 	actor_learning_rate: 0.0013409716625568783
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8358190358558557
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5456607515458806
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021816-7yy3b4ty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7yy3b4ty
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▄▄▆▅▅▅▃▄▅▅▅▁▅▅▆▅▅▅▄▄▄▅▆▅▅▆▃▇▆▆▆▆▆▇█▄▇
wandb:      train/ensemble_f1 ▂▄▃▃▂▅▄▅▅▂▂█▄▂▁▄▇▅▄▄▄▆▅▄▃▆▃▃▆▅▄▁▁▅▅▆█▅▃█
wandb:         train/mil_loss ▃▆▃▂▇▅▅▁▅▂█▇▅▃▆▅▄▂▂▃▄▃▄▆▆▄▅▇▆▂▅▅▃▃▂▄▅▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 4.5613
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 4.37279
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 5.16362
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.53871
wandb:      train/ensemble_f1 0.53871
wandb:         train/mil_loss 2.878
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9uz48e30
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021712-9uz48e30/logs
wandb: Agent Starting Run: 4sl58xig with config:
wandb: 	actor_learning_rate: 1.226280847749691e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42582857340300184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.778571409761585
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021901-4sl58xig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4sl58xig
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▅▅▅▆▆▆▆▆▆██████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▅▅▅▅▆▆▆███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▃▂▃▂▁▂▄▃▆▆▃▆▄▄▆▆▅▆▅▄▆▆▆▄▆▄▅▆▅▅▄▇█▄▇▅▅
wandb:      train/ensemble_f1 ▄▁▃▂▄▄▅▅▅▄▄▅▅▇▄▅▄▆▅▅▄▄▆▃▅▅▆▅▆▅▄▅▇█▆▄▆▇▅▅
wandb:         train/mil_loss ▅▆▅▆▇█▅▄▆▃▅▆▅▅▄▄▆▅▆▃▄▁▂▅▄▄▅▅▄▂▂▄▄▅▄▂▃▄▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▇█▇▇▇▅▇▇▇▇█▇▅█▇█▇█▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.34077
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.29528
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.12546
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.90195
wandb:      train/ensemble_f1 0.90195
wandb:         train/mil_loss 0.2626
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bd49lngg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021658-bd49lngg/logs
wandb: Agent Starting Run: n62bhpw1 with config:
wandb: 	actor_learning_rate: 3.642493031928153e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2994607337939632
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8471583868378637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_021944-n62bhpw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n62bhpw1
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▅▄▇▆▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇██████████
wandb:       eval/ensemble_f1 ██▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▇▆▅▆▆▆▆▆▅▇▇▅▂▅▅▇▆▅▄▅▆▂▃▄▅▄▅▃▆▆█▆▇▆▅▁▆▅
wandb:      train/ensemble_f1 ▅▆▅▃▆▆▄▆▅▆▄▄▅▅▄▆█▅▄▇▆▄▅▆▆▂▃▅▃▄▅▆▅▆▅▆▃▁▅▄
wandb:         train/mil_loss █▃▃▄▄▄▃▃▅▄▄▄▅▄▁▄▄▄▂▃▃▃▂▄▄▄▅▃▃▂▂▂▃▆▃▅▂▅▆▂
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.27294
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.3053
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.1012
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.86216
wandb:      train/ensemble_f1 0.86216
wandb:         train/mil_loss 0.21086
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7yy3b4ty
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021816-7yy3b4ty/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g0au2i9g with config:
wandb: 	actor_learning_rate: 2.8409685453755376e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3095611510004671
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14475727598717758
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022040-g0au2i9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0au2i9g
wandb: uploading history steps 195-203, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss █▇▆▄▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▃▃▃▄▄▄▄▄▄▅▆▆▆▇████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ██▆▆▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▃▃▃▃▃▄▄▄▄▄▄▄▅▆▆▆▆▇▇████▇▇▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▂▂▄▂▅▃▆▄▅▃▃▇▅▄▆▃▄▅▄▅▆█▆▄▆▇▆▆█▄▄▄▆▃▅▄█
wandb:      train/ensemble_f1 ▁▃▃▂▃▃▃▁▆▅▄▄▅▂▄▄▄▆▄▄▄▄▄▄▅▄▄▆█▆▆▆▅▃▄▇▆▄█▄
wandb:         train/mil_loss ▄▆▆▆█▄▆▅▄▅▅▃▃▄▄▄▅▅▄▃▃▄▄▄▃▄▂▂▄▂▃▄▃▃▃▂▃▁▂▂
wandb:      train/policy_loss ▅▇▆▅▅▅▅▅▅▅▇▆▆▇▅▅▆▅▆▄▄▃▅▅▁▆▅▆█▇▇█▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▆▆▄▇▆▅▇▅▄▄▄▄▄▃▃▁▄█▆▆▆▅▇▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.24813
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.19549
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.80998
wandb:      test/avg_mil_loss 0.69795
wandb:       test/ensemble_f1 0.80998
wandb:           train/avg_f1 0.86367
wandb:      train/ensemble_f1 0.86367
wandb:         train/mil_loss 0.43392
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4sl58xig
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021901-4sl58xig/logs
wandb: Agent Starting Run: c1nm3uw4 with config:
wandb: 	actor_learning_rate: 0.00318158235291636
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7457237193902475
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3097832856672973
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022229-c1nm3uw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1nm3uw4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▃▆▂▆█▅▅▃▃▃▃▂▄▃▄▆▆▆▅▅▁▃▄▄▂▃▅▃▅▄▅▆▃▄▅▆▃
wandb:      train/ensemble_f1 ▃▇▆▃▃▇▂▅▄▃▅▆▅▅▃▅▃▂▃▆▄▅▁▄▇▅▄▆▄█▃▆▅▅▄▃▄▄▄▅
wandb:         train/mil_loss ▆▅▅▃▇▄▆▃▄▇▅▃▄▃▅▄▃▁▃▅▂▆▅▄▃▅▅▂▄▄▃▁▄▃█▅▅▆▃▄
wandb:      train/policy_loss ▂▆▅▄▅▆▆▅▂▇▄▆█▅▄▇▃▆▃▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▅▆▇▅▅▆▇▇▅▂▅▅▅▅▅█▄▅▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.27834
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.26021
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.20888
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.8994
wandb:      train/ensemble_f1 0.8994
wandb:         train/mil_loss 0.31753
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n62bhpw1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021944-n62bhpw1/logs
wandb: Agent Starting Run: yh49bn63 with config:
wandb: 	actor_learning_rate: 0.0005395764697878827
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8362547452026887
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3611382262954708
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022254-yh49bn63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yh49bn63
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▅▆▇█
wandb: best/eval_avg_mil_loss █▆▄▄▃▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▅▆▇█
wandb:            eval/avg_f1 ▁▂▁▁▁▂▂▃▃▃▃▃▅▅▅▅▆▅▅▅▆▇██████████████████
wandb:      eval/avg_mil_loss ██▇▆▆▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▄▅▅▅▅▅▅▆▆▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▂▅▃▃▄▅▅▄▅▂▄▅▅▅▄▅▅▇▆▅▇▅▆▆█▆▇▅▆▇▆▆▅▅▆▇█
wandb:      train/ensemble_f1 ▁▂▄▄▃▅▅▄▅▆▅▅▄▅▅▅▅▅▇▆▅▆▆▇▇▅▆▇▆▆▆▆▇▆▇▇▆▇▇█
wandb:         train/mil_loss ▇▇▇█▇▅▅█▃▇▄▄▄▄▄▄▂▄▁▄▂▃▅▃▄▂▄▃▃▅▅▃▄▄▁▂▁▃▅▃
wandb:      train/policy_loss █▅███████▃▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▄▅█▅▅▅▅▅▅▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.22399
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.21524
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.17532
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.89872
wandb:      train/ensemble_f1 0.89872
wandb:         train/mil_loss 0.23115
wandb:      train/policy_loss -0.17201
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.17201
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0au2i9g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022040-g0au2i9g/logs
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▇▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▃▃▃▂▃▅▄▅▅▅▄▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇████
wandb:      train/ensemble_f1 ▁▂▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▄▅▆▆▆▇▆▆▆▇▇▇▇▇█▇███
wandb:         train/mil_loss █▇▇▇▆▇▆▇▆▇▇▆▅▆▅▄▄▄▃▄▃▃▃▃▃▃▂▂▂▁▂▁▂▂▁▂▁▁▁▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▄▄██▄▁▁█████▄▄▄▄▄▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▂████████▆███████████▁████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.898
wandb: best/eval_avg_mil_loss 0.34075
wandb:  best/eval_ensemble_f1 0.898
wandb:            eval/avg_f1 0.87825
wandb:      eval/avg_mil_loss 0.29593
wandb:       eval/ensemble_f1 0.87825
wandb:            test/avg_f1 0.73833
wandb:      test/avg_mil_loss 0.78263
wandb:       test/ensemble_f1 0.73833
wandb:           train/avg_f1 0.81921
wandb:      train/ensemble_f1 0.81921
wandb:         train/mil_loss 0.4787
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/at9mchek
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_021242-at9mchek/logs
wandb: Agent Starting Run: 9cz8rys7 with config:
wandb: 	actor_learning_rate: 0.005509869473533502
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5696899670973125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.276818407781132
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022402-9cz8rys7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cz8rys7
wandb: Agent Starting Run: axl6a9d0 with config:
wandb: 	actor_learning_rate: 0.00018664170956495137
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20425991855257183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7631614746867571
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022404-axl6a9d0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axl6a9d0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████
wandb:       eval/ensemble_f1 ████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅█▇▆▃▂▆▆▃▅▄▅▃▇▄▆▃▄▃▅▃▃▄▂▄▂▃▆▅▅▄▅▃▃▁▄▄▃▅
wandb:      train/ensemble_f1 ▇▄▅▅▅▄▂▂█▅▅▄▃▅▅▃▃▃▃▅▅▃▅▃▃▂▃▄▄▅▅▆▃▄▆▁▄▄▃▅
wandb:         train/mil_loss ▃▃▅▇▇▅▄▇▄▆▅▄▆▇█▆▅▅▆▅▆▄▆▁▄▅▄▅▇▇█▄▇▅▅▅▇█▄█
wandb:      train/policy_loss ▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████▁████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.23058
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.27053
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11407
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.90918
wandb:      train/ensemble_f1 0.90918
wandb:         train/mil_loss 0.24734
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earnest-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yh49bn63
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022254-yh49bn63/logs
wandb: Agent Starting Run: 0rqc569m with config:
wandb: 	actor_learning_rate: 0.00012836855841292315
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07361013537156924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6012430599021074
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022438-0rqc569m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0rqc569m
wandb: uploading history steps 148-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▃▅▅▇▇▇▇██████
wandb: best/eval_avg_mil_loss █▇▇▇▆▅▄▃▃▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▃▅▅▇▇▇▇██████
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▃▇▇██████████▇▇▇▇████████████████
wandb:      eval/avg_mil_loss ███▇▇▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▅▇▇▇▇▇████████▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▆▆▇▇▇██▇▇▇▇▇▇████▇▇▇▇▇██▇██▇▇▇▇██▇███
wandb:      train/ensemble_f1 ▁▁▁▁▇▇▇███▇▇████████▇█▇██▇███████████▇██
wandb:         train/mil_loss █▆▄▅▄▂▄▂▁▂▃▃▂▃▂▂▂▂▂▂▂▃▂▃▄▃▁▂▂▂▂▂▂▂▂▁▂▁▂▂
wandb:      train/policy_loss ▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄█▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86
wandb: best/eval_avg_mil_loss 0.32476
wandb:  best/eval_ensemble_f1 0.86
wandb:            eval/avg_f1 0.85978
wandb:      eval/avg_mil_loss 0.32915
wandb:       eval/ensemble_f1 0.85978
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.29918
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.86092
wandb:      train/ensemble_f1 0.86092
wandb:         train/mil_loss 0.29789
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1nm3uw4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022229-c1nm3uw4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y6yo71fx with config:
wandb: 	actor_learning_rate: 5.521209554536135e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5787565502409119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4079605758954088
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022519-y6yo71fx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6yo71fx
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▄▂▁▂▂▂▁▂▃▃▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▂▄▅▆▆▆███▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂
wandb:       eval/ensemble_f1 █▂▂▂▂▁▃▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▃▁▄▆▄▅▄▁▅▄▄▅▂▅▇▄▄▆▃▄▅▅▆▄▇▆▇▅▆▆▆███▅▇▆
wandb:      train/ensemble_f1 █▂▁▂▁▂▂▂▂▂▃▂▃▂▃▃▁▃▄▃▂▃▄▂▃▃▅▄▂▅▄▅▄▅▄▅▃▆▅▇
wandb:         train/mil_loss ▂▅▆▇▇▄█▆█▆▆▆▅▆█▇▃▄▃▆▆▃▃▂▂▄▃▃▁▄▃▂▂▃▃▁▃▃▂▃
wandb:      train/policy_loss ▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.39878
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.796
wandb:      eval/avg_mil_loss 0.39317
wandb:       eval/ensemble_f1 0.796
wandb:            test/avg_f1 0.78947
wandb:      test/avg_mil_loss 0.61264
wandb:       test/ensemble_f1 0.78947
wandb:           train/avg_f1 0.83849
wandb:      train/ensemble_f1 0.83849
wandb:         train/mil_loss 0.40933
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0rqc569m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022438-0rqc569m/logs
wandb: Agent Starting Run: h9a25upt with config:
wandb: 	actor_learning_rate: 0.0019080896704002216
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.43913237373233616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09400794565939974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022622-h9a25upt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h9a25upt
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▃▄▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▅▆▃▁▅▅▄▅▄▄▇▆▁▄▃▆▆▂▅▄▄▇▆▃▄█▃▂▄▂▁▅▂▄▆▄▆
wandb:      train/ensemble_f1 ▅▅▅▅▃▅▃▅▇▃▁▃▅▄▃▃▅▇▆▂▃▆▃▃▅▃▂▄▃█▄▆▂▂▁▃▂▁▃▄
wandb:         train/mil_loss ▃▄▅▃▆▂▅▁▄▅▅██▅▃▂▁▂▂▇▂▇▆▄▁▅▃█▃▇▅▄▄▅▅▃▃▆▂▃
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.25348
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.26065
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19359
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88632
wandb:      train/ensemble_f1 0.88632
wandb:         train/mil_loss 0.29895
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y6yo71fx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022519-y6yo71fx/logs
wandb: Agent Starting Run: svtrsk0k with config:
wandb: 	actor_learning_rate: 0.001156096353921214
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5663363665734403
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7698118756579369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022707-svtrsk0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/svtrsk0k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss █▃▂▁▂
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▁▁▁▁▁▃████████████▆▆▆▆██████████████████
wandb:      eval/avg_mil_loss █▃▃▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▆██████████▆▆▆▆▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▃▆▂▇▅██▄▆▄▃▄▇▆▅▅▇▅▇▅▆▆▆▆▆▇█▇▆▇▅█▇▇▆▇▅
wandb:      train/ensemble_f1 ▃▁▂▄▃▆▅▂▃▅▆▅▅▄▄▅▄▅▅▅▇▅▆▅▇▇▅▇▇▆▅▆▅█▅▆▅▅▆▅
wandb:         train/mil_loss ▇▆▇▆▅█▄▇▆▇▅▅▄▄▄█▆▃▃▅▆▆▇▆▆▄▇▅▁▄▄▄▂▆▅▆▆▆▆█
wandb:      train/policy_loss ▅▅▅▅▄▁▆▄▃▃▄▄▄▅▅▅▇▇▇▇▆▆▆▆▅▇▅▄▇█▅▇▇▆█▇▅▆▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.17315
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.92
wandb:      eval/avg_mil_loss 0.17941
wandb:       eval/ensemble_f1 0.92
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.17234
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.9275
wandb:      train/ensemble_f1 0.9275
wandb:         train/mil_loss 0.23712
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cz8rys7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022402-9cz8rys7/logs
wandb: Agent Starting Run: 2071248u with config:
wandb: 	actor_learning_rate: 0.002149245697459115
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0052527241526666435
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09702812351865776
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022724-2071248u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2071248u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▅▂▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆▆███▆▆▆▆▁▁▁▁▁▁▃▃▃▃
wandb:      eval/avg_mil_loss █▇▇▆▆▅▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▃▃▃▃▄▄▄▄▄▄▆▆▆▆▆▆▆▆██████▆▆▆▆▆▁▁▁▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▃▄▃▄▆▅▅▅▄▄▅▅▄▆▇▆▅▅▆▆▆▆▆▆▆▇▇▆▅▆▆▇█▇▇▇
wandb:      train/ensemble_f1 ▁▁▂▂▃▃▂▂▅▃▆▅▃▇▄▄▄▅▅▅▅▆▆▆▆▅▆▅▇▆▆▇▅▅▇▆█▇▇▇
wandb:         train/mil_loss █▇█▆▇▆▄▆▅▃▃▅▇▅▅▄▄▄▃▅▄▃▃▂▃▄▄▂▄▄▃▃▃▃▁▂▁▂▃▅
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.19163
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.19155
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.898
wandb:      test/avg_mil_loss 0.29644
wandb:       test/ensemble_f1 0.898
wandb:           train/avg_f1 0.89111
wandb:      train/ensemble_f1 0.89111
wandb:         train/mil_loss 0.28786
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axl6a9d0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022404-axl6a9d0/logs
wandb: Agent Starting Run: n8mor3mv with config:
wandb: 	actor_learning_rate: 0.0022314698321257704
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1339960740029723
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25861796757357225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022802-n8mor3mv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8mor3mv
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████
wandb:       eval/ensemble_f1 ████████████████████▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅█▄▅▇▃▄▆▃█▃▄▅▇▄▁▆▆▃▇▇▄▅▄▆▇▄▃▄▅▅▇▄▅▇▇▂▁▃
wandb:      train/ensemble_f1 ▅▅▇▅▆█▅█▄▄▆▇█▆▇▇▄▄▅▇▅▅▆▄▅▆█▄▅▆▄▅▆▃▇▁▆▃▅▄
wandb:         train/mil_loss ▃▇▅▆▅▄▅▄▄▆▇▄▅▄▄▄▄▅▄▃▄▅▅▃▄▂▅▃▂▄█▆▄▆▁▃▇▅▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▆▇█▅▅█▇▄▇▃▃▂▁▇▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.24112
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.25323
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.3258
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.89124
wandb:      train/ensemble_f1 0.89124
wandb:         train/mil_loss 0.29393
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/svtrsk0k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022707-svtrsk0k/logs
wandb: Agent Starting Run: krrr2qgg with config:
wandb: 	actor_learning_rate: 0.002580416372965808
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09869084320436228
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5716933496602153
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022856-krrr2qgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krrr2qgg
wandb: uploading history steps 105-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▆▆▆▆▆▆▇██▆▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁██████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▆▆▆▆▆▆▇█▅▆▃▂▁▁▂▂▃▃▃▄▃▃▃▃▄▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇██▇██▆▅▄▂▁▁▂▃▂▃▃▂▂▃▄▂▃▃▃▄▃▃▃▃▄▃▃▄▃▄▄▃▄▄
wandb:      train/ensemble_f1 ▇█▇█▇█▇▇█▄▃▃▂▁▁▂▂▂▃▃▃▂▃▃▃▂▄▃▄▃▃▃▃▃▃▃▄▄▄▄
wandb:         train/mil_loss ▁▁▁▁▁▂▂▆▇▇█▇▇█▇▇▇▇▆█▆▆▇▆▅▆▅▆▆▆▅▇▅▆▆▆▆▆▅▅
wandb:      train/policy_loss ▆█▆▆▆▆▃▆▆▅▆▆▆▄▆▆▆▅▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.22022
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.78631
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.23634
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.77983
wandb:      train/ensemble_f1 0.77983
wandb:         train/mil_loss 0.79305
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2071248u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022724-2071248u/logs
wandb: Agent Starting Run: sfewdqvp with config:
wandb: 	actor_learning_rate: 0.0007333694933787117
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3774928523806397
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.451349469757515
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_022927-sfewdqvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hgopggn3
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfewdqvp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇██████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▅▃▆▄▄▃▁▆▃▆▁▄▅█▃█▇▆▄▅▃▆▄▅▃▆▃▇▅▆▆▅▂▄▃▅▄
wandb:      train/ensemble_f1 ▄▂▄▅▆▆▆█▅▃▃▂▁▄▆▂▅▄▃▄▁▄▄▅█▄▆█▆▃▆▆▅▁▆▁▄▄▂▃
wandb:         train/mil_loss ▃▇▇▄▄▄▆▂▄▃▅▄▇█▅█▄▆▂▄▅█▅▃▆▇▁▅▃▄▄▃▄▅▂▃▂▇▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.17575
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.17797
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.21907
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.9022
wandb:      train/ensemble_f1 0.9022
wandb:         train/mil_loss 0.22993
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8mor3mv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022802-n8mor3mv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vwncsu40 with config:
wandb: 	actor_learning_rate: 2.5219063154467845e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7967452182458592
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48016194115570954
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023016-vwncsu40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vwncsu40
wandb: uploading history steps 106-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█████
wandb: best/eval_avg_mil_loss █▅▅▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅█████
wandb:            eval/avg_f1 ▁▄██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▇▇▇▇▇████████████▇█████████████████▇▇█
wandb:      train/ensemble_f1 ▁▅▇▇▇▇▇█████████▇██▇▇████████▇███▇██████
wandb:         train/mil_loss █▂▁▁▁▂▂▂▂▂▁▁▂▂▂▁▂▂▂▁▁▁▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▂▁
wandb:      train/policy_loss ▂▂▂▂▆▁▆▅▂▂▂▂▆▇▃█▆▃▆▅▁▅▇▃▆█▅▅▃▇▂▇▃▅▂▆▅▃▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94
wandb: best/eval_avg_mil_loss 0.15599
wandb:  best/eval_ensemble_f1 0.94
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.20769
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.92943
wandb:      test/avg_mil_loss 0.31177
wandb:       test/ensemble_f1 0.92943
wandb:           train/avg_f1 0.91614
wandb:      train/ensemble_f1 0.91614
wandb:         train/mil_loss 0.21092
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfewdqvp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022927-sfewdqvp/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▅▆▇█
wandb: best/eval_avg_mil_loss █▆▄▃▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▃▅▃▃▃▃▃▃▃▅▅▅▅▅▆▇▇▇███████████
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▅▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▄▃▄▄▃▃▁▃▃▅▅▅▄▇▄▅▅▅▇▅▆▆▄▅▅▆▅▅▇█▅▆█▆▇▇█▇
wandb:      train/ensemble_f1 ▁▄▃▅▅▃▇▄▃▃▄▆▅▆▃▇▅▆▄▆▄▆▆▅▆▆▄▄▄▅▆▆▆▇█▇▆█▆█
wandb:         train/mil_loss ▆▇▆▇▆▃▄▆▆█▄█▇▄▅▅▁▃▃▆▄▄▅▄▃▂▄▂▃▃▅▄▂▄▃▃▂▃▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.37608
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.35667
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.76979
wandb:      test/avg_mil_loss 0.69438
wandb:       test/ensemble_f1 0.76979
wandb:           train/avg_f1 0.82959
wandb:      train/ensemble_f1 0.82959
wandb:         train/mil_loss 0.32764
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h9a25upt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022622-h9a25upt/logs
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 69xdnvw0 with config:
wandb: 	actor_learning_rate: 3.589892570262125e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8048007203442983
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7550317173759119
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023133-69xdnvw0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69xdnvw0
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▃▃▃▄▃▃▃▃▃▃▂▃▃██████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▅▆▆▆▅▃▄▂▄▃▂▃▃▅▆▄▃▇▅▁▆▄▇▄▃▄▄▅▇▃█▅▃▆▅▅▃
wandb:      train/ensemble_f1 ▆▆▇▆▆▃▄▃▅▆▃▆▅▆▆▆▄▄▅▄▄▅█▂▆▃▅▄▅▄▇▆▇▁▄▅▇▅▅▃
wandb:         train/mil_loss ▄▄▃▃▅▆▆▃▃▃▇▂█▆▂▄▄▆▃▅█▂▂▆▇▂▄▁▄▆▁▆▄▂▆█▃▄▃▃
wandb:      train/policy_loss ▇▆▅▄▆█▄▅▅▇▆▆▂▄▇▅▄▄▅▄▁▂▇▅▃▅▇▅▅█▄▃▇▅▃▅▃▅▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▄▆█▆▄▄▆▅▂▃▅▇▁▆▆▇▄▃▄▅▆▆▃▆▄▅█▆▄▆▄▄▄▃▂▆█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.7537
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.84103
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.31153
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32318
wandb:      train/ensemble_f1 0.32318
wandb:         train/mil_loss 0.67792
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vwncsu40
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023016-vwncsu40/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅███████▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▆▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅█████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▃▄▂▁▅█▃▂▅▅▃▄▄▃▆▅▆▆▃▇▄▅▅▅▄▇▄▅▆▆▄▆▅▇▄▃▇
wandb:      train/ensemble_f1 ▃▃▁▅█▃▄▃▄▅▆▅▅▆▃▅▇▇▅▆▅▄▂▄▅▃▅▇▅▅▃▇▅▆▅▃▅█▇▅
wandb:         train/mil_loss ▅▅█▆▆▆▇▆▆▃▅▃█▅▃▇▂▄▆▄▅▅▅▅▄▁▄▆▆▄▄▅▆▂▃▂▁▄▄▄
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▅▇█▇▁▁▁▁▁▇▇▇▇█▇▆▆▇█▇▇▆▅▆▆▇▅▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.23477
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.22141
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18617
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.89724
wandb:      train/ensemble_f1 0.89724
wandb:         train/mil_loss 0.26127
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krrr2qgg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_022856-krrr2qgg/logs
wandb: Agent Starting Run: 2ydhjvot with config:
wandb: 	actor_learning_rate: 0.003167408116980829
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7061394575681156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4062720833137311
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023157-2ydhjvot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ydhjvot
wandb: Agent Starting Run: f0epdqn2 with config:
wandb: 	actor_learning_rate: 0.0005728446560894651
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02412495433375339
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7289810958323043
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023159-f0epdqn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f0epdqn2
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▃▃▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██▇██▇███
wandb:       eval/ensemble_f1 █████▁▁█████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▅▆▅▆▆▇▅▁▄▅▅▅▃▅▂▄▁▁▃▇▄▄▃█▁▅▄▅▃▃▆▂▃▄▃▂▃
wandb:      train/ensemble_f1 ▇▅▅▅▇▆█▃▂▄▅▅▅▅▆▆▄▃▃▅▇▂▃▅▄▄▆▃▄▂▄█▂▁▂▆▃▄▃▄
wandb:         train/mil_loss ▄▇▅▆▇▄▆▄▆▅▄▅▆▄▅▅▆▇▄▅▇▄▃▅▆▁▄▅█▆▆▅▄▄▆▆▃▃▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84878
wandb: best/eval_avg_mil_loss 0.2538
wandb:  best/eval_ensemble_f1 0.84878
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.26775
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.21906
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.86645
wandb:      train/ensemble_f1 0.86645
wandb:         train/mil_loss 0.32161
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ydhjvot
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023157-2ydhjvot/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a9735f2w with config:
wandb: 	actor_learning_rate: 1.731552112558046e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6309747922400688
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5986814454481589
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023405-a9735f2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a9735f2w
wandb: uploading history steps 229-245, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▁▄█
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅████████████▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▃▃▃▃▄▄▄▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇███▇█
wandb:       eval/ensemble_f1 ▃▃▃▃▃▃▃▃▃▃▁▁▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆██████▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▆▄▂▆▁▅▁█▄▄▆▃▃▅▂▃█▂▆▃▃▅▅▆▅▄▆▃▅▅▃▃▁▃▆▇▆
wandb:      train/ensemble_f1 ▃▂▄▂▁▆▆█▇▆▇▄▃▂▄▄▄▄▅▄▄▅▅▁▄▄▂▃▄▆▅▇▄▆▂▂▄▅▄▆
wandb:         train/mil_loss ▄▃▄▃▃▄▅▂▆▅▄▄▅▄▅▅▆▃▆▅▃▇▂▆▁▃▂▄▃▄█▃▂▄▁▄▄▂▃▃
wandb:      train/policy_loss ▅▅▅▅▅▅███████████▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.17404
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.91987
wandb:      eval/avg_mil_loss 0.17546
wandb:       eval/ensemble_f1 0.91987
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.23187
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.9099
wandb:      train/ensemble_f1 0.9099
wandb:         train/mil_loss 0.23941
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f0epdqn2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023159-f0epdqn2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u71j8k5r with config:
wandb: 	actor_learning_rate: 0.0007768423816201447
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8823604510047496
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.055877460662455136
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023619-u71j8k5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u71j8k5r
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▅▃▃▃▃▃▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▃▃▃▃▃▃▃▃▃▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▄▃▃▃▄▄▄▅▆▅▄▅▆▅▅▆█▅▇▇▆▅▆▇▆▆▅▅▇▆▄▆▆▇▆▆▆
wandb:      train/ensemble_f1 ▄▃▁▄▂▃▄▄▅▅▆▅▅▅▄▅▇▇▅▇▇▆██▆█▆▅▆▅▇▇▅▆▆▆▅▆▇▇
wandb:         train/mil_loss ▇█▇▆▃▆▆▆▅▄▂▄▅▅▄▆▆▆▇▅▄▃▅▅▅▆▃▅▂▄▅▁▆▃▅▂▇▅▄▃
wandb:      train/policy_loss ████████████▅████████████████▁██████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▆▅▅▅▅▅▅█▅▁▅▄▅▅▅▅▅▅▅▅▅▅▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.43251
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.81971
wandb:      eval/avg_mil_loss 0.42426
wandb:       eval/ensemble_f1 0.81971
wandb:            test/avg_f1 0.83942
wandb:      test/avg_mil_loss 0.40334
wandb:       test/ensemble_f1 0.83942
wandb:           train/avg_f1 0.83111
wandb:      train/ensemble_f1 0.83111
wandb:         train/mil_loss 0.28975
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69xdnvw0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023133-69xdnvw0/logs
wandb: Agent Starting Run: rkfk9lbc with config:
wandb: 	actor_learning_rate: 2.423723648280614e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2479565075853558
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9346062531903016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023653-rkfk9lbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rkfk9lbc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅▅███▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▅▅▄▃▂▂▂▁▆▅▅▅▄▄▃▃▃▂██▇▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▆▁▅▅▃▃▂▁▃▄▂▁▂▃▅▅▄▄▃▆▆▄▅▂▁▆▁▁▄▅▇▄▄▄▅█▄
wandb:      train/ensemble_f1 ▄▄▅▅▂▃▇▃▄▆▆▁▄▆▅▅▅▄▄▅▅▅▄▂▆▆▆▅▇▃▂▆▄▅▄▅▃█▄█
wandb:         train/mil_loss █▄▅█▄▄▇▃▅▇▅▇▆▇▇▅▇▅▇▅▂▅▂▅▃█▄▅▄▃▁▂▂▆▃▃▃▂▄█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53861
wandb: best/eval_avg_mil_loss 2.57045
wandb:  best/eval_ensemble_f1 0.53861
wandb:            eval/avg_f1 0.50397
wandb:      eval/avg_mil_loss 2.57156
wandb:       eval/ensemble_f1 0.50397
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 3.12133
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.38439
wandb:      train/ensemble_f1 0.38439
wandb:         train/mil_loss 0.81908
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u71j8k5r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023619-u71j8k5r/logs
wandb: Agent Starting Run: aqf8xfwb with config:
wandb: 	actor_learning_rate: 2.093735115888009e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8785315201320141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5234701270594663
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023828-aqf8xfwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqf8xfwb
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ███▇█▇▇▆▆▆▆▅▅▄▄▄▄▃▂▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▂▁▂▃▄▄▄▄▅▆▆▆▆▆▆▆▆▇▇████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▄▅▆▅▅▅▆▆▆▅▆▇▆▆▇▆▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      train/ensemble_f1 ▁▂▃▃▃▄▄▅▆▅▅▆▇▆▇▇▇▇▇██▇█▇▇██▇▇██████▇▇▇▇█
wandb:         train/mil_loss ▇█▅▆▅▄▃▅▆▃▅▄▅▃▅▅▃▃▃▃▄▄▅▂▃▂▄▄▂▂▁▂▃▃▄▃▂▃▁▃
wandb:      train/policy_loss ██▁▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁██▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.42338
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.41251
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.88811
wandb:      test/avg_mil_loss 0.38058
wandb:       test/ensemble_f1 0.88811
wandb:           train/avg_f1 0.84781
wandb:      train/ensemble_f1 0.84781
wandb:         train/mil_loss 0.31893
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a9735f2w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023405-a9735f2w/logs
wandb: Agent Starting Run: vy66bkty with config:
wandb: 	actor_learning_rate: 0.0002850635593925728
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31854871937351303
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9841251920868908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023925-vy66bkty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vy66bkty
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▃▆▃▃▃▃▃▃▃▆▆██████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▁▂▂▁▂▂▃▅▃▃▄▃▃▄▄▅▅▆▆▅▄▅▅▅▅▄▅▅▆▆▅▅█▅▅▆▇█
wandb:      train/ensemble_f1 ▁▂▂▃▁▁▃▄▃▃▃▄▄▅▅▄▄▆▆▆▅▄▆▅▅▃▅▄▄▅▄▅▄▃▅▄█▅▇█
wandb:         train/mil_loss █▅▅▅▇▄▆▃▄▃▅▅▂▄▆▃▆▅▇▃▄▃▃▄▅▄▅▂▂▄▂▃▁▂▂▄▄▂▄▄
wandb:      train/policy_loss ▁▂▆████████████████▃▃▅▄▅▄▂▆▂▄▄▅▃▂▃▆▄▂▃▆▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▂▃▅█████████████▂▃▄▃▄▅▃▂▃▃▂▂▄▅▁▃▅▄▄▄▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46082
wandb: best/eval_avg_mil_loss 2.57055
wandb:  best/eval_ensemble_f1 0.46082
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.41487
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 2.93871
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.44747
wandb:      train/ensemble_f1 0.44747
wandb:         train/mil_loss 1.48974
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rkfk9lbc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023653-rkfk9lbc/logs
wandb: Agent Starting Run: axjqg7wa with config:
wandb: 	actor_learning_rate: 0.0001039017532309584
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8118083307533663
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.799052544745658
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_023948-axjqg7wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axjqg7wa
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▄▄▄▄▃▃▃▃▃▂
wandb:       eval/ensemble_f1 ███████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▂▅▇▃▄▆▇▄▅▄▇▄█▅▅▇▃▄▇▃▄▃▄▁▇▄▇▅█▄▄▅▄▇▂▅▆
wandb:      train/ensemble_f1 ▄▃▆▄▆▆▃▇▄█▄▅▇▆▆▇▆▄▃▄▆▄▃▃▆▁▆▃▃▄▂█▂▃█▄▃▄▆▅
wandb:         train/mil_loss ▂▅▆▂▅▄▆█▄▄▃▄▄▃▂▅▂▂▅▂▄▄▂▅▃▅▂▃▁▄▃▂▆▆▂▅▃▁▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38667
wandb: best/eval_avg_mil_loss 2.86674
wandb:  best/eval_ensemble_f1 0.38667
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 2.78696
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 3.07677
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.35354
wandb:      train/ensemble_f1 0.35354
wandb:         train/mil_loss 0.59621
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqf8xfwb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023828-aqf8xfwb/logs
wandb: Agent Starting Run: 3os1mmbb with config:
wandb: 	actor_learning_rate: 6.362044345421178e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16351297259145292
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11287235190050826
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024007-3os1mmbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3os1mmbb
wandb: uploading history steps 108-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁██████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁██████████
wandb:      eval/avg_mil_loss ████▆▅▅▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄█▄▁▃▅▅▂▂▄▆▆▄▃▄▇█▄▄▃▃▅▄▄▅▅▅█▂▄▃▄▄▂▄▆▄▅
wandb:      train/ensemble_f1 ▆▃▄▄▄▃▆▃▅▅▄▃▂▄▆▅▁▅▄█▅▄▆▄▄▄▄▅▃▅▄▃▅▄▃█▆▄▆▆
wandb:         train/mil_loss ▅▇▄▇█▆▃▆▇▇▅▂▄▂▁▃▃▄▃▃▃▄▁▂▂▁▂▃▄▂▂▃▃▁▃▁▃▄▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 3.63224
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54772
wandb:      eval/avg_mil_loss 2.41535
wandb:       eval/ensemble_f1 0.54772
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 4.21757
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.59601
wandb:      train/ensemble_f1 0.59601
wandb:         train/mil_loss 1.3617
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vy66bkty
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023925-vy66bkty/logs
wandb: Agent Starting Run: milbap1c with config:
wandb: 	actor_learning_rate: 0.00859545881392408
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6971164460177792
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7773917653876005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024124-milbap1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/milbap1c
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████████▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▆█████
wandb:       eval/ensemble_f1 ███████████████████████████████████▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▅▄▄▃▂▄▇▅▂▆▇▄▃▃▆▅▆▂▆▄▄▂▅▇▅▄▅▆▆▂▇▃▃▁▆▅▅▂
wandb:      train/ensemble_f1 ▄▃▃▅▆▃▄▅▃█▇▁▆▂▆▇▆▆▆▃▅▂▇▇▆▇▆▇▇▅█▄▄▆▆▆▆▆█▃
wandb:         train/mil_loss ▇▅▅▁█▆▅▆▇▇▄▄▆▅▄▃▃▃▁▄▄█▆▅▄▄▇▇▂██▄▄▆▂▂▄▂▃▇
wandb:      train/policy_loss ▇▇▅▆▆▅▇▆▇▄▆▅▆█▆▇▆▇▇▆▇▇▅▆▅▅▅▅▇▇▆▇▆▆▆▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.15513
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.16012
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.25145
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.88619
wandb:      train/ensemble_f1 0.88619
wandb:         train/mil_loss 0.26901
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3os1mmbb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024007-3os1mmbb/logs
wandb: Agent Starting Run: fs6eae81 with config:
wandb: 	actor_learning_rate: 4.969805180419144e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5412739206045517
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5457748042589341
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024145-fs6eae81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fs6eae81
wandb: uploading history steps 128-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▅▅▅▅▅▅▅▅▅▅▅████████▅▅▅▅██████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▅▆▆▆▆▅▅▅▄▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁█████████████▁▁█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▅▃▅▄▅▆▆▄▅▆▅▄▅▄▆▅▇▇▃▄▅▅▄▄▇▇▅▅▃▇▆█▇▇▆▄▇
wandb:      train/ensemble_f1 ▂▄▂▄▁▃▄▃▅▄▄▅▂▆▆▄▄▅▅▃▅▅▆▃▅▅▄▄▅▆▆█▇▅▅▃▃▇▇▅
wandb:         train/mil_loss ▄▅▃▃▅▆▂▆▃▄▄█▅▆▂▄▃▄▁▃▃▃▄▄▄▃▄▅▄▂▄▃▂▃▁▄▄▆▄▃
wandb:      train/policy_loss █████████████████████▁██████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 2.18638
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 2.1158
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.51335
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.53743
wandb:      train/ensemble_f1 0.53743
wandb:         train/mil_loss 0.44922
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axjqg7wa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_023948-axjqg7wa/logs
wandb: Agent Starting Run: x73edg7c with config:
wandb: 	actor_learning_rate: 0.00832168815570816
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.46257436943559194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4059683576597387
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024203-x73edg7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x73edg7c
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▆▄▅▃▆█▅▅▄▆▄▃▇▅▃▅▃▁▂▆▇▃▄▃▆▂▄▄▃▃▄▁▃▅▄▆▃▆
wandb:      train/ensemble_f1 ▆▂▅█▄▃▆▆▄▄▄▇▆▃▅▃▆▇▄▁▅▆▃▃▃▂▆▄▄▂▁▃▄▄▂▂▇▄▆▆
wandb:         train/mil_loss ▄▆▄▄▆▂▄▂▇▄▃▆▅▁█▄▆▅▅▄▄▅▄▄▆▃▅▄▁▃▆▄▅▄█▅▃▆▃▃
wandb:      train/policy_loss ▆▄▇▇▄▂▄▄█▅▆▅▅▃▄▄▄▅▇▄▄▄▄▄▄▄▅▃▃▄▅▁▅▇▆▆▂▇▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▆▆▃▄▁▆▃▆▂▂▂▃▃▄▄▄▄▄▄▂▄▃▃▆▂█▅▃▅▇▆▅▄▄▆▆██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.87562
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.69752
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 2.13031
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.34395
wandb:      train/ensemble_f1 0.34395
wandb:         train/mil_loss 0.56568
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fs6eae81
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024145-fs6eae81/logs
wandb: Agent Starting Run: 482edktv with config:
wandb: 	actor_learning_rate: 0.0025532634938267413
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19720487999267644
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23822638171550217
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024323-482edktv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/482edktv
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄█▇▅▄▇▅▆▁▄▄█▅▃▇▄▆▆▄▄▅▅▅▆▄▃▅▆█▅▇▆▆▄▃▇▆▆
wandb:      train/ensemble_f1 ▅▅▄▂▆▇▇▅▅█▆█▃▇█▃▇▄▅▇▂▁█▁▆▃▄██▅▅▇▇█▃▄▅▇▂▃
wandb:         train/mil_loss █▅▄▅▃▃▇▁▃▅▄▄▆▄▃▅▄▆▅▃▂▃▃▅▆█▂▄▅█▃▃▂▇▅▄█▇▂▅
wandb:      train/policy_loss ▄▄▂▃▁▅▅▆▃▂█▆▇▅▅▆▃▂▅▂▆▄▄▄▃▄▃▆▆▂▄▄▄▆▃▄▇▄▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▃▂▂▄▅▇█▆▅▆▇▅▅▅▄▂▃▅▆▅▄▅▆▆▄▅▃▄▄▆▅▇▅▇▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.24861
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.23651
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11711
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91221
wandb:      train/ensemble_f1 0.91221
wandb:         train/mil_loss 0.20855
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x73edg7c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024203-x73edg7c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gtii1yae with config:
wandb: 	actor_learning_rate: 0.00018262623950102431
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7380935364828618
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.547017630226508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024352-gtii1yae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gtii1yae
wandb: uploading history steps 98-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss █▃▁▁
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▁▅██████████████████████████████████████
wandb:      eval/avg_mil_loss ████▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁█████▇█████████████▇██████████████████
wandb:      train/ensemble_f1 ▁▁▁█████▇█████████████████████▇█████████
wandb:         train/mil_loss ▇▆█▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▄▅▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.25437
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.22436
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.2755
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88686
wandb:      train/ensemble_f1 0.88686
wandb:         train/mil_loss 0.26717
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/482edktv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024323-482edktv/logs
wandb: Agent Starting Run: 44ooqmod with config:
wandb: 	actor_learning_rate: 0.0037236582837282153
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.840457284756634
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47039172775433946
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024507-44ooqmod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/44ooqmod
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆████████████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▆▇▅█▄▆▆▃▅▅▅▂▅▃▆▄▃▅▄▆▇▆▆▄▄▆▆▇▅▆▁▆▅▄▂▅▂
wandb:      train/ensemble_f1 ▅▆▆▄▆▅██▆▆▅▅▅▂▃▅▆▃▃▄▇▁█▆▄▄▆▆▆▃▁▆▅▆▄▇▄▅▅▄
wandb:         train/mil_loss ▃▄▄▆▄▄▃▃▇▃▃▅▅▄▁▅▇▇█▄▆▄▂▂▅▇▅▆█▇▄▆▃▅▃▄▅▇▆▅
wandb:      train/policy_loss ▆▆▅▂▄▅█▅▇▃▃▅▃▇▃▇▄▆▇▂▁▆▃▃▅▃▃▆▆▄▇▂▄▂▅▆▂▂▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▂▄▄▅▅█▇▃▄▅▅▃▂▃▁▆▅▅▃▄▅▄▂▇▇▆▄▇▂▇▂▅▅▄▆▄▅▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.35626
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.36654
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.13071
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88439
wandb:      train/ensemble_f1 0.88439
wandb:         train/mil_loss 0.28401
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gtii1yae
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024352-gtii1yae/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0b3ttlam with config:
wandb: 	actor_learning_rate: 4.904059003214055e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8299087383321319
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9652522550641964
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024541-0b3ttlam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0b3ttlam
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 █▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▅██▅▅▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▄▆▇▆▇▇▆▇▅▇▆▇▇▆▇▇▆▆▇▇█▆▇███▇▇▆▇▇█▆▆▇█▇▅
wandb:      train/ensemble_f1 ▁▆▆█▇▇▇▆▇▇▅▇▆▇▆█▇▆██▇▇▇▆▇▆██▇▇▇▅▇▆█▇▅▆█▆
wandb:         train/mil_loss ▅▇▆▄▅▇█▅▅▄▇▄▄▆▂▅▁▇▃▄▄▁▂▃▃▄▂▃▃▃▆▄▃▅▃▁▄▅▄▃
wandb:      train/policy_loss █▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃████████▄▃▃▃▄▃▄▄▃▄▃▅▄▅▃▃▂▂▃▃▃▂▅▁▅▃▃▂▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.18506
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.20056
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.22921
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.88853
wandb:      train/ensemble_f1 0.88853
wandb:         train/mil_loss 0.27145
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/44ooqmod
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024507-44ooqmod/logs
wandb: Agent Starting Run: 2ww4vrdr with config:
wandb: 	actor_learning_rate: 0.00044959930765329007
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4343995614121942
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39243878243885344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024651-2ww4vrdr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ww4vrdr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▄▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▆▅▅▅▄▄▄▃▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▄▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:      eval/avg_mil_loss ██████▇▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▂▃▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▅▅▄▅▅▅▃▃▇▅▇▅▇▇▇▆▆▇▆█▇█▆▇▆█▇▅▇▆▆▆▇▇▆▇▆
wandb:      train/ensemble_f1 ▃▃▁▃▆▆▇▆▆▆▆▇█▇▆▇▇▇▇▇█▆█▆█▇▇▇▇▇▆▇█▇▇▇▇▇▇▇
wandb:         train/mil_loss ▇▄▇█▁▄▅▃▄▄▃▂▂▂▁▂▃▂▂▄▂▂▃▃▁▃▂▃▃▂▃▂▂▂▄▂▄▂▃▃
wandb:      train/policy_loss ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▆▄▄▄▅▃▆▆█▇▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆█▁▆▄▅█▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75196
wandb: best/eval_avg_mil_loss 0.98365
wandb:  best/eval_ensemble_f1 0.75196
wandb:            eval/avg_f1 0.74256
wandb:      eval/avg_mil_loss 1.16594
wandb:       eval/ensemble_f1 0.74256
wandb:            test/avg_f1 0.71717
wandb:      test/avg_mil_loss 1.60058
wandb:       test/ensemble_f1 0.71717
wandb:           train/avg_f1 0.72192
wandb:      train/ensemble_f1 0.72192
wandb:         train/mil_loss 0.4962
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/milbap1c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024124-milbap1c/logs
wandb: Agent Starting Run: k4nfh7f2 with config:
wandb: 	actor_learning_rate: 0.0022039592848991565
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22908544614432869
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47109473914572575
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024721-k4nfh7f2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k4nfh7f2
wandb: uploading history steps 145-154, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁██████████████████▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▂▁▃▁▄▃▂▂▆▅▃▆▆▅▇▇▆▄▆▃█▅▂▆▅▂█▃▅▄▅▃▄▆▆▂▄▃
wandb:      train/ensemble_f1 ▄▂▄▁▄▁▄▃▂▅▃▆▆▄▅▂█▆█▄▆▅▅▄▂▅▆▄█▂▆▆▇▄▅▅▅▆▃▄
wandb:         train/mil_loss ▆▄▅▇▃▃▄▇█▄█▅▄▇▅▇▇▁▃▇▄▆▃▆▃█▃▄▄▂▇▄▆▆▆▅▇▇▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46082
wandb: best/eval_avg_mil_loss 2.78751
wandb:  best/eval_ensemble_f1 0.46082
wandb:            eval/avg_f1 0.44191
wandb:      eval/avg_mil_loss 2.69248
wandb:       eval/ensemble_f1 0.44191
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 3.21155
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.46464
wandb:      train/ensemble_f1 0.46464
wandb:         train/mil_loss 0.35155
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0b3ttlam
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024541-0b3ttlam/logs
wandb: Agent Starting Run: b21zuayx with config:
wandb: 	actor_learning_rate: 0.009100423040191171
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6405152160387928
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7124543575645055
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024810-b21zuayx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b21zuayx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▇▆▇▇▃▆▇▄▅▇▂▁▇▅▇▇▅▆▇▆▆▆▇▄▅▃▄▅▅▅▇▄▃▅▃▄▅▅
wandb:      train/ensemble_f1 ▇▅█▁▄▅▇▇▅▂▇▅▆▆▅▄▇▇▄▅▅▃▆▄▆▆▅▅▇▃▆▄▄▅▆▃▃▃▅▇
wandb:         train/mil_loss ▆▃▁▄▃▅▆▂▆▄▇▅▆▆▅▅▅▃▄▄▆▆▃▆█▅▃▄▂▆▄▇▅▃▅▂▂▅▇▃
wandb:      train/policy_loss ▁█▆▄▇▃▆▃▇▁▂▂▆▁▃▃▂▃▃▅▂▄▂▃▁█▅▅█▇▁▅▆▅▆▃▆▅▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂█▃▇▅▇▄▂▇▃▅▃▆▂▄▁▂▅▅▅▁▂▄▃▃▃▆▅▄▅▄▄▂▅▄▅▃▆▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.13973
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.97347
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.64124
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34156
wandb:      train/ensemble_f1 0.34156
wandb:         train/mil_loss 1.50368
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ww4vrdr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024651-2ww4vrdr/logs
wandb: Agent Starting Run: 5risy7h1 with config:
wandb: 	actor_learning_rate: 3.356821240829448e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.883897216503337
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6261223268748123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024829-5risy7h1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5risy7h1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▂▂▆█████████████████████████████
wandb:       eval/ensemble_f1 ████▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █████▅▁▂▂▁▁▂▁▁▂▂▁▁▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁
wandb:      train/ensemble_f1 ████▇▂▁▁▂▂▁▁▁▂▂▁▁▂▁▂▂▂▂▁▂▁▂▂▂▂▂▁▂▂▂▂▂▂▁▂
wandb:         train/mil_loss ▁▁▁▁▁▂▄▆▆▅▇▆▇▇▆▆▆█▇▆▇▆▆▆▆█▅▇▇▆█▅▆▇▆▆▆▇▆▇
wandb:      train/policy_loss █▆█▇▆▂▄▂▃▂▂▂▂▃▂▃▁▃▃▃▂▃▃▂▃▃▃▂▄▃▁▄▂▃▃▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90977
wandb: best/eval_avg_mil_loss 0.24673
wandb:  best/eval_ensemble_f1 0.90977
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 5.09459
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.83994
wandb:      test/avg_mil_loss 0.61466
wandb:       test/ensemble_f1 0.83994
wandb:           train/avg_f1 0.57115
wandb:      train/ensemble_f1 0.57115
wandb:         train/mil_loss 3.06081
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k4nfh7f2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024721-k4nfh7f2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fqi4jada with config:
wandb: 	actor_learning_rate: 9.320970987266391e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6901207233235075
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8408597113869735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_024938-fqi4jada
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqi4jada
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅███
wandb: best/eval_avg_mil_loss █▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▅███
wandb:            eval/avg_f1 ▁▅██████████████████████████████████████
wandb:      eval/avg_mil_loss ████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▅▆▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▁▅▆▆▇▇▇▇▇█▇▇██▇█▇▇██▇▇▇█▇▇▇▇█▇███▇██▇█
wandb:         train/mil_loss ▇▅█▇▄▃▂▃▃▃▂▂▃▄▃▃▁▂▃▂▂▃▁▃▂▃▂▃▂▂▂▃▂▄▂▂▃▂▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▇▇▆▇▃▆▇▅███▅▁▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9
wandb: best/eval_avg_mil_loss 0.29106
wandb:  best/eval_ensemble_f1 0.9
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.23396
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.90845
wandb:      test/avg_mil_loss 0.29564
wandb:       test/ensemble_f1 0.90845
wandb:           train/avg_f1 0.91873
wandb:      train/ensemble_f1 0.91873
wandb:         train/mil_loss 0.20959
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b21zuayx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024810-b21zuayx/logs
wandb: Agent Starting Run: m4eoh441 with config:
wandb: 	actor_learning_rate: 0.004229489512333365
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9815148914847616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9580304370497532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025000-m4eoh441
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m4eoh441
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▆▃▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▃▃▃▃▃▅▆▆▅▅▅▅▅▄▄▄▄▄▅▅▅▇▇▇▇██████
wandb:       eval/ensemble_f1 █████████▆▁▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▅▇▂▇▁▅▄▄█▃▇▆▅▆▅▅▇▄▆▄▅█▇▆▇▇▄▄▆▆▆▇▆▇▅▆▄
wandb:      train/ensemble_f1 ▇▂▆▇▄▅▄▁▆▃▂▆▆▅▁▄▆▆▅▆▇▃▇▄█▇█▆▇▃▃▅█▆█▄▅▆▄▆
wandb:         train/mil_loss ▅▂▄▄▅▄▄▂▅▅▅▃█▃▄▄▁▅▃▃▂▄▄▃▁▃▃▂▄▁▃▂▂▂▄▁▁▁▃▄
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▇██▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.24504
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.25329
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.28127
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.89749
wandb:      train/ensemble_f1 0.89749
wandb:         train/mil_loss 0.26648
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5risy7h1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024829-5risy7h1/logs
wandb: Agent Starting Run: xe3jj0z7 with config:
wandb: 	actor_learning_rate: 0.002855761334380165
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9902058135112316
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6153324146825823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025008-xe3jj0z7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xe3jj0z7
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss ▁██▇
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁███▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▅▅▄▆▄▄▆▄▅▅▅█▆▅▄▇▇▇▅▇▅▆▅▇▇▄▇▄▅▅▄█▃▇▅▇█
wandb:      train/ensemble_f1 ▁▁▆▅▅▅▅▇▄▄▅▄▆▆▄▅█▆▄▆▇▅▆▇▇▆▆▅▅▅▅▇▅▅▅▅▆▇██
wandb:         train/mil_loss ▄▃▃█▄▃▃▆▃▄▂▃▃▄▃▄▄▃▇▄█▂▃▄▂▃▃▂▄▇▂▇▃▆▅▁▄▃▂▃
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.61818
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.60148
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 3.16159
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.47356
wandb:      train/ensemble_f1 0.47356
wandb:         train/mil_loss 0.27129
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m4eoh441
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025000-m4eoh441/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 16q380ig with config:
wandb: 	actor_learning_rate: 0.0003680440268006816
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39631395723532703
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1678583159947542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025153-16q380ig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16q380ig
wandb: uploading history steps 130-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████████████▆▆▃▃▃▃▃▃▆▃▃▃▃▃▃▃▃▁▁▁▁▁▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb:       eval/ensemble_f1 ██████████▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▇▄▃▃▅▇▅▄▄▇▁▅▃▆▄▄▄▄█▅▃▄▆▂▅▆▆▅▃▆▆▄▁▂▃▃▅
wandb:      train/ensemble_f1 ▃█▄▇▄▅█▂▄▂▄▂▅▃▆▄▆▄▆▁▃█▆▁▆▆▆▁▆▇▄▇▄▅▃▁▃▄▂▆
wandb:         train/mil_loss ▂▇▆▅▄▃█▄▇▄▆▇▆▄█▄▂▅▇▅██▄▅▅▄▄▇▁▄▁▄▃▁▁▄▄▃▄▃
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.17522
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.22385
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.28494
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.88471
wandb:      train/ensemble_f1 0.88471
wandb:         train/mil_loss 0.2942
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xe3jj0z7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025008-xe3jj0z7/logs
wandb: Agent Starting Run: opbfnipd with config:
wandb: 	actor_learning_rate: 0.0006897288463979725
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.168173357363117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.415301494909315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025217-opbfnipd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9hug5gtx
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opbfnipd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▅▄▄▄▃▃▃▃▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ██████████████▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▃▃▂▃▄▄▃▅▃▆▃▆▂▄▃▅▆▆▃▅▆▄▃▅▅▄▅█▇█▆█▆▄▆▆▆
wandb:      train/ensemble_f1 ▄▁▃▃▂▃▄▂▂▄▄▃▃▅▆▃▃▄▅▄▅▅▄▄▆▅▅▇▆▇▇▆▇▇▆▄█▄█▆
wandb:         train/mil_loss ▇▇▅█▄▃▆▅▃▅▅▂▄▂▄▂▆▅▄▂▃▃▃▃▃▅▃▄▂▅▃▃▄▂▃▂▅▂▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▅▅█▅▆▅▇▆▇▃▂▃▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.19708
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.19055
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.2884
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.90611
wandb:      train/ensemble_f1 0.90611
wandb:         train/mil_loss 0.26325
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comfy-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16q380ig
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025153-16q380ig/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dhzb1j19 with config:
wandb: 	actor_learning_rate: 0.002168979858306953
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8040240674491992
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37245505030569814
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025342-dhzb1j19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dhzb1j19
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▁▁▃▄▃▆▆▆▆▆▅▅▃▄▆▅▄▅▅▅▆▆▅▇▆▆▆▆▇███▇▆▅▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▄▄▃▃▃▂▁▃▃▂▃▃▂▄▁▅▃▄█▃▄▂▄▁▄▃▄▄▄▃▃▃▃▁▃▂▃
wandb:      train/ensemble_f1 ▅▆▄▆▄▆▆▇▆▆▄▄▆▅▄▄█▃▆▅▄▅█▆▇▄▄▅▅▆▇▇▇▄▄▇▅▄▅▁
wandb:         train/mil_loss ▄▆▅█▄▇▅▇▇▄▇▅▃▆▁▄▆▂▆▇▆▄▆██▃█▆▇▄▆▆▅▅▆▂▄▅▅▇
wandb:      train/policy_loss ▆▃▅▅▆▁▅▅▄▂▅▄▆▆▁▃▅▃█▆▂▃▆▃▂▅▅▄▆▇▆▂▅▅▄▅▆▇▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▆▂▆▆▅▃▅▄▅▇▃▂▅█▆█▁▆▂▂▂▃▃▁▂▇▅▅▂▅▆▃▂▅▃▃▅▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.66295
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.7041
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.13477
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 2.14285
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opbfnipd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025217-opbfnipd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: uploading history steps 100-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 ▃▁██▆▆████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ██▂▁▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ▃▃▃▁▆▆█▅▅▅▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▆▇▇▇▇▇▇▆█▇▇▆▇▆▆▇▇▇▇▆▇▆▆▇▇▇█▇▆▆▇▇▇▅▇▇▆▅
wandb:      train/ensemble_f1 ▁▂▄▆▆▆▇▇▇█▇█▇█▇▇▇▇▇▇▇▇▇▇▆▇▇▇▆▆▇▇▇▇▇▆▇▇██
wandb:         train/mil_loss █▄▃▁▃▂▄▂▄▃▆▁▂▅▃▃▄▃▁▅▆▃▄▁▅▃▂▅▂▆▃▅▄▂▃▃▂▃▂▄
wandb:      train/policy_loss ███████████████████████████▁████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅▅▅▃▃▁▂▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▂▃▂▁▂▃▃▃▂▃▃▃▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.16808
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.24533
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.18937
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.90523
wandb:      train/ensemble_f1 0.90523
wandb:         train/mil_loss 0.25092
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dhzb1j19
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025342-dhzb1j19/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3jc5s9eh with config:
wandb: 	actor_learning_rate: 0.00651124502895053
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5805116261060163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6966678878920344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025536-3jc5s9eh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ozvslx22
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jc5s9eh
wandb: uploading history steps 203-212, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss ▁██▇▆▅▅▅
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▄▄▄▅▅▅▆▆▆▆▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁███▇▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▁▁▃▃▆▆▅▆▆▆▆▇▇▅▆▇▆▇▅▇█▇▆▇▅▇▆▇█▇█▇▇▅▆▇
wandb:      train/ensemble_f1 ▁▁▁▂▂▁▂▁▃▄▄▆▄▆▅▆▆▆▇▆▆▆▇▆▆▅▇▇▇▇▆▆▇▆▆█▇▇▇▇
wandb:         train/mil_loss ▁▁▂▂▃▄▅▄▇▆▄▅▆▄▃▅▆▃▅▄▇▂█▆▃▂▄▆▃▄▄▅▅▄▄▆▅▆▃▄
wandb:      train/policy_loss █▅▆▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▁▆▁▃▆▂▂▂▃▄▄▂▅▆▄▁▂▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 2.09303
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.45437
wandb:      eval/avg_mil_loss 1.99313
wandb:       eval/ensemble_f1 0.45437
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.33643
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.49863
wandb:      train/ensemble_f1 0.49863
wandb:         train/mil_loss 0.70444
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jc5s9eh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025536-3jc5s9eh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss ▄▆▇███▇▇▇▇▆▅▄▄▃▂▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▂▂▂▂▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▃▃▃▃▄▄▃▄▃▄▄▅▆▅▆▅▅▇▆▆▇▆▇▇▇▇▇▇▆▇█▇▇████
wandb:      train/ensemble_f1 ▁▅▅▅▅▅▅▆▅▆▅▆▅▅▆▆▆▆▆▆▇▇▇▇▇█▇▇█▇███▇██████
wandb:         train/mil_loss █▄█▄▄▆▆▆█▄▅▄█▄▅▆▂▄▅▄▃▃▃▃▁▁▂▂▂▃▂▁▂▂▂▂▂▁▂▂
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▆▆▇▁▄▄▆▃▅▅▅▅▄▅▇▄▅█▆▅▅▅▅▅▅▅▅▃▄▃▃▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.40366
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.79708
wandb:      eval/avg_mil_loss 0.38662
wandb:       eval/ensemble_f1 0.79708
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.37106
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.83063
wandb:      train/ensemble_f1 0.83063
wandb:         train/mil_loss 0.38654
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqi4jada
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_024938-fqi4jada/logs
wandb: Agent Starting Run: yhaangyc with config:
wandb: 	actor_learning_rate: 8.3497504944322e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19107990908502048
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9908655839430668
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_025927-yhaangyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yhaangyc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ▁▆▆▇▇█▇▇▇
wandb:  best/eval_ensemble_f1 ▁▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▃▃▄▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇████████████████
wandb:      eval/avg_mil_loss ▁▁▃▃▄▄▄▄▄▄▄▅▅▅▄▄▅▄▄▄▄▄▄▄▅▅▅▅████████████
wandb:       eval/ensemble_f1 ▁▃▃▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▃▄▃▃▄▄▃▄▅▆▅▅▅▅▆▆▅▆▅▆▆▅▇▇▇█▆█▇▇▇▇▆▆█▇
wandb:      train/ensemble_f1 ▂▁▂▂▁▁▂▂▃▃▂▃▃▃▄▄▄▅▄▅▆▄▅▅▅▅▄▅▅▅▄▆▅▇▇▆▇▆▆█
wandb:         train/mil_loss ▄▄▃▂▄▆▁▃▅▅▄▄▄▅▃▄▇▃▆▅▃▅▄▄▅▆▆▆▃▆▇▅▆▄▅▇█▇▅█
wandb:      train/policy_loss ▄▄▄▄▄▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 3.86628
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 4.46609
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 4.78598
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.55375
wandb:      train/ensemble_f1 0.55375
wandb:         train/mil_loss 2.47932
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yhaangyc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_025927-yhaangyc/logs
wandb: Agent Starting Run: e9o1pxv0 with config:
wandb: 	actor_learning_rate: 1.9673147412126603e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11144903877155032
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7414455360217892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_030238-e9o1pxv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9o1pxv0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅█
wandb: best/eval_avg_mil_loss █▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ███▇▇▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▂▃▄▆▄▆▃▄▅▁▆▄▅▄▅▄▅█▄▃▇▅▇▇▅▅▄▅▇█▄█▅▅▆▅▅
wandb:      train/ensemble_f1 ▂▃▃▃▁▆█▇▄▅▇▅▇▄▅█▆▆▆▄▆▆▆▅▇▅▆▇▅█▅▅▇▆▇▆▅▆▄▃
wandb:         train/mil_loss ▄▇▅▆▇█▆▃▅▃▃▁▃▃▃▆▆▅▂▆▄▅▅█▄▅▅▇▄▆▃▃▂▂▄▂▄▂▄▃
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.2362
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.22732
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.20094
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.87625
wandb:      train/ensemble_f1 0.87625
wandb:         train/mil_loss 0.29875
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9o1pxv0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_030238-e9o1pxv0/logs
wandb: Agent Starting Run: jp143k7v with config:
wandb: 	actor_learning_rate: 0.00025259146987569085
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9408755530205376
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47230174194189234
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_030605-jp143k7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jp143k7v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆▆▆█████▆██████████▆▆▆▆▅▅▅▅▅▃▃▃▃▃▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▂▂▂▂▂▂▁▁▂▂▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇████
wandb:       eval/ensemble_f1 ▆▆▆▆▆▆▆██████████▆▆▆▅▅▅▅▅▅▅▅▅▃▃▃▃▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▅█▃▅▅▆▂▃▆▆▆▃▂▆▃▇▄▅▅▄▅▃▄▇█▃▁▃▅▄▃▆█▁▁▆▅
wandb:      train/ensemble_f1 ▇▆▅▇▆█▄▅▄▆▄▆▆▃▅▆▁▇▅▆▅▅▄▆▇▅▅▅▄▆▄▄▅▆▄▃▅▆▆▇
wandb:         train/mil_loss ▆▅█▂▇▅▆▅▅▇▅▆▄▆▃▆▆▃▄▁▆▆▇▄▅▄▄▄▂▆▄▂▇▆▃▄▃▃▇▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.22005
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.23197
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.23931
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.90104
wandb:      train/ensemble_f1 0.90104
wandb:         train/mil_loss 0.30502
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jp143k7v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_030605-jp143k7v/logs
wandb: Agent Starting Run: 5355iou3 with config:
wandb: 	actor_learning_rate: 0.003982959393509794
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09609905799492456
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47311936787983033
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_030754-5355iou3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5355iou3
wandb: uploading history steps 175-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss ██▁▇▄
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▃▃▃▃▁▁▁▁▃▃▅▅▅▅▅▆████████████████████████
wandb:      eval/avg_mil_loss ▅▅▅▄▄▃▅▅▇██▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▅▁▁▁▅▅▅▅▅▅▅▆▆████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▂▄▁▅▂▅▃▂▇▄▅▃▅▅▅▅▆▃▅▅▆▆▄▅▆▇▅▆▂▇▄▆▅▅▇▃█▅
wandb:      train/ensemble_f1 ▃▃▂▁▃▁▂▆▃▃▆▄▃▆▅▆▅▅▅▄▃▄▇▆█▅▅▆█▅▇▆▆▅▇▄█▅▅▆
wandb:         train/mil_loss ▆▂▅█▆▃▆▄▃▇▄▇▃▆█▄▆▂▇▄▇▅▃▁▄▂▄▂▆▅▃▆▇▃▃▃▅▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇█▇▇▇▆▇▇█▇▆▅█▆▇█▇▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.25962
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.24532
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.19308
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.90613
wandb:      train/ensemble_f1 0.90613
wandb:         train/mil_loss 0.26198
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5355iou3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_030754-5355iou3/logs
wandb: Agent Starting Run: o5yl9dai with config:
wandb: 	actor_learning_rate: 0.002009074253275713
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.018061104504959458
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2927669928558596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_031040-o5yl9dai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5yl9dai
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss █▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▄▄▄▄▄▅▆▆▆▆▆▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▂▃▄▃▄▅▄▅▆▆▆▆▆▇▇▇▇▇▇███▇▇████████████
wandb:      train/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇███▇██████████
wandb:         train/mil_loss ███▇▆▆▆▆▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▂▄▁▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.37149
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.86999
wandb:      eval/avg_mil_loss 0.34493
wandb:       eval/ensemble_f1 0.86999
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.37128
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.86204
wandb:      train/ensemble_f1 0.86204
wandb:         train/mil_loss 0.39404
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5yl9dai
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_031040-o5yl9dai/logs
wandb: Agent Starting Run: 2888q1u4 with config:
wandb: 	actor_learning_rate: 0.0003880006540744353
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5929274347620375
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.907295445041366
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_031534-2888q1u4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2888q1u4
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇██████▇▇▇███▇▇▇█▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▂▅▆▂▇▃▄▄▅▆▄▅▃▁▃▃▅▄▅▅▄█▅▆▅▅▄▅▃▄▂▄▆▅▃▃▆▅
wandb:      train/ensemble_f1 ▆▃▃▃▁▆▃▅▄▂▃▄▂▁▁▃▃▅▄▄█▅▃▂▆▃▅▆▅▄▄▃▇▅▂▅▃▅▂▄
wandb:         train/mil_loss ▃▃▄▅▅▂▄▁▂▅▆▅▆▃█▃▄▅▄▄▃▂▅▃▅▄▅▂▄▆▅▄▄▃▅▂▃▂▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.25998
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.26508
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18879
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.87398
wandb:      train/ensemble_f1 0.87398
wandb:         train/mil_loss 0.30106
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2888q1u4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_031534-2888q1u4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lqvb2jti with config:
wandb: 	actor_learning_rate: 0.00013769765243579448
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05860353727423517
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2051150389806005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_031719-lqvb2jti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqvb2jti
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇▇█
wandb: best/eval_avg_mil_loss █▆▆▄▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▂▄▄▄▅▅▅▇▇▇▇▇▇▇▇▇▅▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▅▅▅▅▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▃▁▂▃▄▃▂▁▄▄▄▃▅▅▃▅▅▅▆▅▅▃▅▆▃▅▂█▇▆▅▄▅▄▃▆▅
wandb:      train/ensemble_f1 ▆▅▁▅▃▅▄▂▄▃▄▄▃▄▅▄▄▆▄▆▅█▃▄▂▆▂▄▇▄▆▆▅▅▃▃█▅▅▆
wandb:         train/mil_loss █▄▄▅▇█▇▆▆▇▅▅▅▄▅▄▂▅▃▄▃▅▆▃▄▄▃▅▄▂▂▅▄▃▄▁▅▃▁▂
wandb:      train/policy_loss █████████████████████▁██████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▇████▇▇▇▁▁▁▁▁▁▁▇██████▇████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.25665
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.24976
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.20126
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.89125
wandb:      train/ensemble_f1 0.89125
wandb:         train/mil_loss 0.24976
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqvb2jti
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_031719-lqvb2jti/logs
wandb: Agent Starting Run: q1vk74m2 with config:
wandb: 	actor_learning_rate: 0.003972238090724771
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9119205094501626
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8870824234647223
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250530_032142-q1vk74m2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cmovhybn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q1vk74m2
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▁▂▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ████▆▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▅▆▄█▆█▇▇▄▄█▃▄▄▅▆▅▆▇▆▅▆▄▁▂▃▅▆█▅▅▅▆▂▄▃▄
wandb:      train/ensemble_f1 ▅▆█▅▆▆▆▇▄▄▄▃▆▆▅▄▅▄▅▅▅▄▅▁▅▅▄▅▅▃▆▇▄▄▂▄▂▅▄▅
wandb:         train/mil_loss ▅▇▆▄▃█▆▆▃▆▆▄▆▆▂▅▅▃▅▄▄▅▆▆▄▁▇▆▆▄▆▄▅▅▄▆▆▅▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▁████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.25129
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.28682
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19528
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.87109
wandb:      train/ensemble_f1 0.87109
wandb:         train/mil_loss 0.29731
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run serene-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q1vk74m2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_032142-q1vk74m2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
