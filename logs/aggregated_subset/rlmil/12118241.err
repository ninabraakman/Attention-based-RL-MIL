wandb: Agent Starting Run: 4vsfuzor with config:
wandb: 	actor_learning_rate: 3.6401099163729114e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02022005945000982
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.56094654364648
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195750-4vsfuzor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4vsfuzor
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 262-288, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆█
wandb: best/eval_avg_mil_loss █▄▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆████████████
wandb:      eval/avg_mil_loss ███▇▇▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▄▄▄▄▄▅▅▅▅▆▆███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▃▃▃▃▄▃▂▁▄▃▅▃▄▄▄▄▃▃▄▄▃▅▄▅▆▄▆▆▄▇▆▇▇▆▇██
wandb:      train/ensemble_f1 ▃▅▃▃▂▃▄▄▂▄▂▄▄▁▄▂▃▄▂▃▂▄▄▁▃▂▂▅▄▂▆▃█▆▇▇▅▄▇▆
wandb:         train/mil_loss ▆▇▅▅▃▅▅▅▆▃█▄▃▄▅▂█▆▅▄▅▅▅▄▄▅▆▂▅▄▅▅▅▄▆▁▃▃▂▄
wandb:      train/policy_loss ▁▃▁▁▁▁▃▁▃▁▁████████████████▁▁▁▁▁▁▁▁▁▁▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▁▁▁▃▁▁████████████▁▁▁▁▁▁▃▁▁▁▁▁▃▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68166
wandb: best/eval_avg_mil_loss 1.52088
wandb:  best/eval_ensemble_f1 0.68166
wandb:            eval/avg_f1 0.68166
wandb:      eval/avg_mil_loss 1.47185
wandb:       eval/ensemble_f1 0.68166
wandb:            test/avg_f1 0.625
wandb:      test/avg_mil_loss 1.88514
wandb:       test/ensemble_f1 0.625
wandb:           train/avg_f1 0.7167
wandb:      train/ensemble_f1 0.7167
wandb:         train/mil_loss 1.23539
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4vsfuzor
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195750-4vsfuzor/logs
wandb: Agent Starting Run: v58nyvgz with config:
wandb: 	actor_learning_rate: 0.005299028189146382
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3556805058614422
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24158311377735697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200126-v58nyvgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v58nyvgz
wandb: uploading history steps 163-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss ▃▃▂▂▂▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁██▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▇▆▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▄▃▆▇▃▃▆▃▃▅▂▃▆▁▃▅▃▆▄▃▅▅▄▂▆▆▄▅▇█▆▂▄▇▅▃▄
wandb:      train/ensemble_f1 ▅▄▄▄▄▃▃▆▅▄▅▅▁▆▅▆▇▄▆▄▃▆▆▆▃▃▄█▆▄▄▄▄▅▃▅▃▅▆▄
wandb:         train/mil_loss ▃▄▆▅▆▆▆▄▅▇▅▄▁▄█▃▄▆▆▆▁▄▁▅▇▂▃▁▆▆▄▅▂▃▆█▆▇▆█
wandb:      train/policy_loss ▂▄▁▂▂▂▄▁▁▁▂▃▄▄▃▄▅▆▄▅▇▅▅▆▆▇▇▆▅▇▅▅▇▇▅▇▆▇▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▃▂▂▄▃▄▃▂▁▂▃▂▃▃▁▃▆▅▅▆█▅▆▇▇▅▆▇▆▇▅▅▆▃▇▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 1.84947
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 1.88766
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.58822
wandb:      test/avg_mil_loss 1.84974
wandb:       test/ensemble_f1 0.58822
wandb:           train/avg_f1 0.62982
wandb:      train/ensemble_f1 0.62982
wandb:         train/mil_loss 1.61094
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v58nyvgz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200126-v58nyvgz/logs
wandb: Agent Starting Run: deb4nm2b with config:
wandb: 	actor_learning_rate: 1.4944625445530576e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3486574637768376
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.954504213057858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200305-deb4nm2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/deb4nm2b
wandb: uploading history steps 189-193, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆█████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇██▇▇▇▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▄▂▃▄▄▄▃▇▆▁▆▅▂▄▂▆▆▇▅▅▇▅█▅▆▆▇▇▅█▄▆▆█▇▇▆
wandb:      train/ensemble_f1 ▅▅▄▅▄▅▇▃▄▆▂▁▄▄▂▃▄▄▇▅▄▁▅▃▅▇▆▆▅▆▅▅▄▄██▅▄▇█
wandb:         train/mil_loss ▆▁▇▅▆▅▆▆▅█▆█▅▇▆▆▃▅▅▄▄▆▄▇▄▅▄▆▅▃▆▂▄▅▄▄▃▃▄▄
wandb:      train/policy_loss ███████████████▅▁▂██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60114
wandb: best/eval_avg_mil_loss 2.54241
wandb:  best/eval_ensemble_f1 0.60114
wandb:            eval/avg_f1 0.60114
wandb:      eval/avg_mil_loss 2.49444
wandb:       eval/ensemble_f1 0.60114
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.80466
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.60275
wandb:      train/ensemble_f1 0.60275
wandb:         train/mil_loss 1.39164
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/deb4nm2b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200305-deb4nm2b/logs
wandb: Agent Starting Run: svcp6npn with config:
wandb: 	actor_learning_rate: 2.873439229566389e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9200106325312952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.804679315618497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200458-svcp6npn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/svcp6npn
wandb: uploading history steps 107-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁██████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▄▃▆▇▃▃▄▄▄▅▄▆▂▆▁▄▂▅▄▂▄▃▅▆█▃▄█▄▆▆▅▄▇▄▃▆
wandb:      train/ensemble_f1 ▄▄▃▆▂▅▆▅▄▃▄▅▁▆▅▄▄▁▃▄▅▅▄▇▃▄▅▅▅▆▇▆▃▄▆▃█▆▆▆
wandb:         train/mil_loss ▄▅▅▅▃▄▆█▄▃▃▅▂▂▃▃▅▆▄▅▆▄▄▄▁▄▄▄▃▅▄▂▁▃▃▃▆▇▅▂
wandb:      train/policy_loss ▁▁▂▂▁████▆▆██▇▇▇█▇▇█▆▇████▇█▇███▇██▆▇██▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▃▂▂▁▁▂▂██▆▇█▇█▆█▇██▆▇▇█▇████▇▇█▆█▇▇▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.33653
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.35876
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.16605
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.90037
wandb:      train/ensemble_f1 0.90037
wandb:         train/mil_loss 0.27035
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/svcp6npn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200458-svcp6npn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vfsyv8id with config:
wandb: 	actor_learning_rate: 0.0006393320131305898
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6760148383288473
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4266536739053285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200621-vfsyv8id
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vfsyv8id
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▇▄▅▅▂▇▁▄▅▆▆▄▃▆▅▆▄█▆▃▇▅▃▄▄▃▅▇▆▅▁▁▃▄▃▄▅▄
wandb:      train/ensemble_f1 █▄▄▄▅▅▄▇▅▄▆▅▆▆▃▆▅▆▂▆█▃▄▄▅▃▅▄▅▄▁▁▆▇▅▅▄▁▅▅
wandb:         train/mil_loss ▅▄▅▅█▃▃█▅▅▆▆▅▁▇▆▆▃▆▇▆▄▇▅▅▆▄▇▃█▅▄▁▄▄▃▁▂▅█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.38518
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.392
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.91511
wandb:      test/avg_mil_loss 0.18087
wandb:       test/ensemble_f1 0.91511
wandb:           train/avg_f1 0.86871
wandb:      train/ensemble_f1 0.86871
wandb:         train/mil_loss 0.28774
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vfsyv8id
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200621-vfsyv8id/logs
wandb: Agent Starting Run: lc9nrcs5 with config:
wandb: 	actor_learning_rate: 0.000203921319124554
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9055431870853732
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7707714821159486
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200724-lc9nrcs5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lc9nrcs5
wandb: uploading history steps 106-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅█
wandb: best/eval_avg_mil_loss █▇▆▁▂
wandb:  best/eval_ensemble_f1 ▁▄▅▅█
wandb:            eval/avg_f1 ▁▁▄▄▄▅▁▅▅███████████████████████▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ███▇▇▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▁▁▄▄▁▅▁▅▅█████████████████████████████▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▆▄▃▁▁▄▅▄▂▇▄▂▁▃▂▂█▅▆▆▂▅▄▄▂▆▆▄▁▃▅▆▂▇▅▅▂
wandb:      train/ensemble_f1 ▃▃▅▄▇▅▅▅▄▄▇▆▁▃▄▇▇██▅▇▆▄▆▃▇▅▄▃▇▆▃▅▅█▄█▇▄▃
wandb:         train/mil_loss ▂▆▆▅▆▇▄▃▃▃▃▃▄▄▇▄▃▃▅▄▅▄▃▃▅▄▃▃▃▃▅█▄▃▂▁▃▅▃▅
wandb:      train/policy_loss ▃▄▆▆▄▁█▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▇▇▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▁▃▃▃▃▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.2892
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.29538
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.24225
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.87392
wandb:      train/ensemble_f1 0.87392
wandb:         train/mil_loss 0.29509
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lc9nrcs5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200724-lc9nrcs5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o2vpyb0u with config:
wandb: 	actor_learning_rate: 0.00017589114649500885
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8953955617908741
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5438446965711318
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200948-o2vpyb0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o2vpyb0u
wandb: uploading history steps 81-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▅▂▂▂▂▂▁▁▁▁▁▂▂▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▃▄████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 █▅▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▁▁▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▂▃▃▃▁▁▂▁▁▁▁▂▂▂▂▂▃▃▃▁▂▂▁▂▃▂▂▂▃▄▃▄▃▄▃▄▄▄
wandb:      train/ensemble_f1 ██▅▄▂▃▃▁▁▁▁▂▁▁▁▂▁▃▂▃▂▂▃▃▃▃▂▃▄▂▃▄▃▄▃▃▃▃▄▅
wandb:         train/mil_loss ▅▆▃▃█▃▄▅▁▅▃▆▅▆▅▃▄▅▆▁▄▅▄▄▃▄▅▄▇▅▃▄▃▄▆█▆▂▃▅
wandb:      train/policy_loss ▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86999
wandb: best/eval_avg_mil_loss 0.36307
wandb:  best/eval_ensemble_f1 0.86999
wandb:            eval/avg_f1 0.77263
wandb:      eval/avg_mil_loss 0.46402
wandb:       eval/ensemble_f1 0.77263
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.30648
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.77247
wandb:      train/ensemble_f1 0.77247
wandb:         train/mil_loss 0.30021
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o2vpyb0u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200948-o2vpyb0u/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1dsohik6 with config:
wandb: 	actor_learning_rate: 0.0015790930793224702
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.907559939201313
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6509412715276197
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201101-1dsohik6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1dsohik6
wandb: uploading history steps 267-281, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▄▆▆▆▆▆▆▆▆▆▆▆██▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▇▆▇▆▇▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▅▅▄▄▆▆▆▆▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▂▃▂▄▄▄▄▄▄▂▃▄▆▄▅▆▆▅▅█▅▅▇▇▆▅▇▇▇█▅█▇▇▇▆▇
wandb:      train/ensemble_f1 ▁▂▁▂▁▂▂▂▂▂▁▃▄▃▃▃▂▃▃▃▅▅▆▃▄▄▄▅█▅▄▅▄▇▄▅▆▆▇█
wandb:         train/mil_loss ▃█▅▅▂▃▃▂▄▃▂▃▃▆▆▃▂▁▃▁▅▃▇▄▁▃▃▂▃▇▃▂▃▁▁▂▂▄▄▅
wandb:      train/policy_loss ▇▇▇▇█▇████▆▆▆▆▆▆▆▆▆▇███▇▇██▄▁▇██████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.44191
wandb: best/eval_avg_mil_loss 0.73359
wandb:  best/eval_ensemble_f1 0.44191
wandb:            eval/avg_f1 0.43574
wandb:      eval/avg_mil_loss 0.69632
wandb:       eval/ensemble_f1 0.43574
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 0.86511
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.49306
wandb:      train/ensemble_f1 0.49306
wandb:         train/mil_loss 0.38164
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1dsohik6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201101-1dsohik6/logs
wandb: Agent Starting Run: s90ojbmz with config:
wandb: 	actor_learning_rate: 0.00013030597377951803
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9714451530131966
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8761458509379666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201346-s90ojbmz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s90ojbmz
wandb: uploading history steps 239-256, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▆▆▆█▇▇▇▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █▇▇▇▇█▇▇▆▆▆▅▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▁▁▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▁▁▂▁▂▃▄▄▄▄▄▄▄▅▅▅▆▆▇█▇▇▇▇▇▇▅▅▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▅▄▃▅▅▃▄▄▆▆▅▆▅▆▅▅▅▆▇▆▅▆▆▆█▆▆▇▆▆▇▅▆█▇▇▅█
wandb:      train/ensemble_f1 ▄▃▃▂▃▃▂▂▃▁▂▃▄▃▂▁▃▅▃▄▇▅▄▄▇▅▅▆▅▆▆▆▅▇▅▇▇▇█▇
wandb:         train/mil_loss ▅▅▄▆▄▇▅▆█▃▃▆▃▇▂▂▁▅▆▃▃▃▄▅▄▄▂▂▄▃▂▄▄▄▃▄▆▂▄▄
wandb:      train/policy_loss ███▆████▆▇▇████████▆▆█████▁▆▆▆▆▆▆▆█▃████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▇▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85978
wandb: best/eval_avg_mil_loss 0.40743
wandb:  best/eval_ensemble_f1 0.85978
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.40433
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.89964
wandb:      test/avg_mil_loss 0.39853
wandb:       test/ensemble_f1 0.89964
wandb:           train/avg_f1 0.82805
wandb:      train/ensemble_f1 0.82805
wandb:         train/mil_loss 0.2615
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s90ojbmz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201346-s90ojbmz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xodgac95 with config:
wandb: 	actor_learning_rate: 2.4639616890351135e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9826958996752576
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5824917049281741
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201626-xodgac95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xodgac95
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▅▃▄▇▂▅▂█▄▅▄▄▂▄▄▅▇▆▅▃▄▄▅▃▅▄▁▅▆▅▄▅▃▆▇▃▆
wandb:      train/ensemble_f1 ▄▄▆▆▂▂▂▂▂▃▅▃▄▁▃▄▅▄█▂▃▅█▄▁▃▅▅▇▇█▇▆▄▆▂▃▇▄▄
wandb:         train/mil_loss █▁▂▁▇▂▂▂▂▂▁▂▁▁▆▁▂▂▂▇▁▂▁▂▁▁▁▂▁▁▁▇▁▁▁█▂▁▁▂
wandb:      train/policy_loss ▁▁▁▁▁▄▄▁▁▁▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▁▁▁▁▁▄▁▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 3.86053
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 3.83263
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 4.69852
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.47297
wandb:      train/ensemble_f1 0.47297
wandb:         train/mil_loss 0.30574
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xodgac95
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201626-xodgac95/logs
wandb: Agent Starting Run: ab2r10w9 with config:
wandb: 	actor_learning_rate: 0.001188194256594661
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4452237904227752
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44076484150486805
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201749-ab2r10w9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ab2r10w9
wandb: uploading history steps 214-220, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅███████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▅▄▄▃▃▃▃▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▃▄▁▅▃▂▃▅▅▁▅▄▄▄▄▄▅▃▁▅▆▆▃▅█▇▆█▅▆▃▆▇▆█▄▅
wandb:      train/ensemble_f1 ▅▅▁▄▁▃▂▄▅▄▅▃▂▅▃▆▃▆▅▄▄▅▇▇▂▇▂▃▄▇█▆▄▆▄▆▆▆▂▇
wandb:         train/mil_loss ▆▅▄▇▆▆▅▃█▃▇▄▅▄▄▆▅▃▃▆▄▅▃▆▆▄▅▅▁▃▄▄▄▄█▃▅▄▅▅
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▄▁▅█▂▂▆▄▄▂▆▅██▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▆▂▄▅▃▁▃▅▄▂██▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 3.11871
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 3.09739
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 3.67651
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.54213
wandb:      train/ensemble_f1 0.54213
wandb:         train/mil_loss 1.92069
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ab2r10w9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201749-ab2r10w9/logs
wandb: Agent Starting Run: wye4jajn with config:
wandb: 	actor_learning_rate: 0.0008170271983234
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3725038703170188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2983959935597633
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201958-wye4jajn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wye4jajn
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▆▆███▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▂▂▂▄▅▁▃▂▃▃▂▆▃▆▃▇▅▄▁▃▅▂▁▃▅▅▂▃▅▄▁▄▃▃▆▅█▃
wandb:      train/ensemble_f1 ▂▃▃▃▆▁▃▃▃▃▂▂▃▃▅▃▄▂▁▄▅▁█▃▄▄▂▃▃▂▁▄▃▄▄▃▂▄▆▅
wandb:         train/mil_loss ▂▅▆█▅▅▄▅▆▅▄▃▅▆▆▄▃▃▅▅▄▄▆▃▄▆▃▃▄▆▇█▇▄▅▄▇▁▅▃
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 2.39797
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 2.35949
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 2.98051
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.59852
wandb:      train/ensemble_f1 0.59852
wandb:         train/mil_loss 1.14293
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wye4jajn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201958-wye4jajn/logs
wandb: Agent Starting Run: lajbqtig with config:
wandb: 	actor_learning_rate: 0.0026293997022716967
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9334259914480256
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8341847729082007
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202100-lajbqtig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lajbqtig
wandb: uploading history steps 266-269, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▅▅▅▅▅▅▅██████████████████
wandb:      eval/avg_mil_loss █▇▇▄▄▃▃▃▆▆▆▇▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▅▅▅▅▅▅▅▅███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▄▁▇▁▂▃▅▂▃▃▂▅▃▅▂▇▅▅▃▄▅▃▇▆▄▇▄▂▄█▄▅▂█▆█▅▇
wandb:      train/ensemble_f1 ▁▂▃▂▃▅▆▁▁▂▂▂▂▃▄▅▄▄▅▃▃▄▅▄█▅▆▆▃▅▃▅▃▃▃▄▆▆▅▅
wandb:         train/mil_loss █▃▄▇▆▅▆▆█▃▂▃▅▄▄▃▂▄▅▅▄▅▄▁▃▄▂▃▂▂▂▂▂▃▇▂▃▂▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▂▁▅▅▅▅▅▅▅▅▅▅▁▁▂▁▁▁▁▇▇█▇▇██▆█████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94995
wandb: best/eval_avg_mil_loss 0.18952
wandb:  best/eval_ensemble_f1 0.94995
wandb:            eval/avg_f1 0.94995
wandb:      eval/avg_mil_loss 0.18966
wandb:       eval/ensemble_f1 0.94995
wandb:            test/avg_f1 0.83942
wandb:      test/avg_mil_loss 0.26689
wandb:       test/ensemble_f1 0.83942
wandb:           train/avg_f1 0.8674
wandb:      train/ensemble_f1 0.8674
wandb:         train/mil_loss 0.24785
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lajbqtig
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202100-lajbqtig/logs
wandb: Agent Starting Run: gmp3ajnw with config:
wandb: 	actor_learning_rate: 0.0007587320137361217
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24608749967946475
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6767105790120488
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202340-gmp3ajnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmp3ajnw
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▄▃▁▄▇▃▃▆▄▃▃▂▄▅▃▆▅▄█▆▁▄▇▅▅▅▅▇▅▃▃▅▃▅▇▅▅
wandb:      train/ensemble_f1 ▁▃▄▃▅▁▅▆█▄▃▂▂▃▃▃▆▆▄▅▆▆▅▄▄▄▇▇▇▅█▄▆██▆▄▅▆▆
wandb:         train/mil_loss ▇▅▇▆▆▆▇▆▆▄▃▂▅█▆▇▅▄▆▆▄▅▆▃▇▃▂▆▅▂▄▃▆▂▁▃▅▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.37173
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.15232
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.57555
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.36212
wandb:      train/ensemble_f1 0.36212
wandb:         train/mil_loss 1.27214
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmp3ajnw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202340-gmp3ajnw/logs
wandb: Agent Starting Run: kl5ak8tm with config:
wandb: 	actor_learning_rate: 2.1556873345791063e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5668902745780651
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4906586464818731
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202442-kl5ak8tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl5ak8tm
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇███
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▇▅▃█▆▆▄▆▇▃▁▅▇▅▄▅▅▆▆▁▆█▆▅▇▆▅▆▃▄▆█▃▄▇█▅▄
wandb:      train/ensemble_f1 █▂▇▅▄▄▄▁▆▄▃▅▇▂▂▃▅▆▅▃█▅▆▆▅▆▅▃█▆▂▂▆▆██▆▂▆▄
wandb:         train/mil_loss ▇▂▆▆▄▆▄█▆▆▅▄▄▄▆▅▃▆▄▃▅▆▂▃▃▁▇▄▅▄▅▄▄▄▅▄▄▅▅▃
wandb:      train/policy_loss ▅▅▅▅▅▄▆▆█▇▇▅▅▇▃▄▆▅▆▅▆▄▄▅▅▅▄▄▅▇▅▅▆▃▂▅█▂▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.27504
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.28031
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.23312
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.89984
wandb:      train/ensemble_f1 0.89984
wandb:         train/mil_loss 0.26788
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kl5ak8tm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202442-kl5ak8tm/logs
wandb: Agent Starting Run: uvgj8jd5 with config:
wandb: 	actor_learning_rate: 0.0002938142886087422
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1803791388511622
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35065614524807165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202545-uvgj8jd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvgj8jd5
wandb: uploading history steps 295-312, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▆▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▂▂▂▂▁▁▁▁▁▁▁▁▁▄▆▅▅▅▆▆▆▆▆▆▆▆██████████████
wandb:      eval/avg_mil_loss ██████████▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▁▁▁▁▁▁▁▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▆▆████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▃▁▁▃▂▁▂▄▁▃▄▄▄▄▅▅▅▅▅▅▅▇▆▆▆▆▆▇▇▅▇█▆▇▇▇█
wandb:      train/ensemble_f1 ▂▁▁▃▅▁▂▃▂▄▂▃▄▆▅▄▅▅▆▅▆▆▄▅▆▅▄▄▆▇▆▆▆▇▇▇▅█▇▇
wandb:         train/mil_loss ▆▅▅▆▄▇▃█▆▃▃▄▇▅█▆▆▃▂▃▇▇▄▆▃▃▅▅▂▅▅▁▄█▃▄▁▆▃▃
wandb:      train/policy_loss █▇█▇▇▁▁▂▃▁▄▁▂▂██▂▁▅▁▂▂▂▁▂▁▄▆▇▅▆█▇▆▇██▆██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▇█▅██▇▇▃▂▁▄▄▂▁█▃▃▃▅▂▄▁▂▁▁▁▆█▆▄█▇▇▆▇▅▅▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 2.10267
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 2.03203
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.61293
wandb:      test/avg_mil_loss 2.66956
wandb:       test/ensemble_f1 0.61293
wandb:           train/avg_f1 0.72836
wandb:      train/ensemble_f1 0.72836
wandb:         train/mil_loss 1.66468
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run woven-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvgj8jd5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202545-uvgj8jd5/logs
wandb: Agent Starting Run: pu3hcbb0 with config:
wandb: 	actor_learning_rate: 0.00642333587833788
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5771080680547063
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9605833220152112
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202845-pu3hcbb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pu3hcbb0
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▁▂▂▁▂▃▄▄▄▅▆▆▆▅▅▅▄▄▄▄▅▅▅▄▄▇█████▇▇▅▅▆▆▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▆▆▂▅▇▄▆▄▇▅▃█▃▂▄▄▅▂▄▅▅▅▁▄▆▆▇▂▄▆▂▂▄▃▄▅▂▆
wandb:      train/ensemble_f1 ▁▄▆▅▅▄▃▃▃▃▄▄▂▁▃▄▄▂▄▃▃▃▅▄▇▂█▄▄▅▂▂▄▄▅▃▃▃▂▆
wandb:         train/mil_loss ▆▆▃▅▅▅▂▂▁▃▄▂▇▃▅▆▆▃▇▇▇▇▆▆▂▄▄▄▆▆█▅▅▃▂▇▄▄▃▃
wandb:      train/policy_loss ▅▄▇▁▃▃▃▄▅▄▇▅▅▅▅▄▄▅▂▁▄▁▂▅▆▆█▅▇▄▅▅▅▁▅█▄▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▁▄▂▄▄▅▄█▅▃▄▆▂▆▄▃▆▆▆▇▅▆▄▇▄▄▇▅▁▆▆▂▁▅▄▄▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.38415
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.38608
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.9375
wandb:      test/avg_mil_loss 0.1702
wandb:       test/ensemble_f1 0.9375
wandb:           train/avg_f1 0.89443
wandb:      train/ensemble_f1 0.89443
wandb:         train/mil_loss 0.32875
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pu3hcbb0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202845-pu3hcbb0/logs
wandb: Agent Starting Run: f8e6dc0c with config:
wandb: 	actor_learning_rate: 0.0003367903621755532
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6669353813394505
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09303457091136702
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202948-f8e6dc0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8e6dc0c
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▃▅▅▄▂▅▆▅▃▆▇▅▃▃▅▃▄▆▂▃▆▄▅▃▅▃▂▆▃▁▅▄▆▄▃█▃▄
wandb:      train/ensemble_f1 ▃▇▄▅▆▄▄▆▄▆▆▄▅▆▆▄▅▅▇█▃▇▂▃▆▄▁▄▄▃▆▇▆▃▂▆▅▄▄▅
wandb:         train/mil_loss ▄▃▆▃▇▇▄█▆▄▅▅▃█▅▃▃▅▄▅▅▆▆▃▄▅▃▅▆▅▅▄▅▃▃▅▃▇▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.35385
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.36049
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.92609
wandb:      test/avg_mil_loss 0.20563
wandb:       test/ensemble_f1 0.92609
wandb:           train/avg_f1 0.8697
wandb:      train/ensemble_f1 0.8697
wandb:         train/mil_loss 0.3001
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8e6dc0c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202948-f8e6dc0c/logs
wandb: Agent Starting Run: lb4ouydu with config:
wandb: 	actor_learning_rate: 0.0025774651332720784
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2976048830599811
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25358490138762735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203049-lb4ouydu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lb4ouydu
wandb: uploading history steps 159-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇▇█
wandb: best/eval_avg_mil_loss ▁█▇▆▅▅▅
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇▇█
wandb:            eval/avg_f1 ▁▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb:      eval/avg_mil_loss ▁▁█▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▅▆▆▅▆▅▆▆▆▆▇▆▆▇▆▆▆▄▇▅▆▆▆▆▇▅▇█▆▇▇▆▆█▇█▇
wandb:      train/ensemble_f1 ▁▃▄▃▄▄▅▃▄▆▅▃▅▄▆▅▆▃▇▆▅▅▇▄▆▄▄▅▃▄▃▆▄▄▇▅▃▆▅█
wandb:         train/mil_loss ▂▁▇▄▇▅▅█▆▃▃▅▆▃▂▄▄▆▅▅▇▂▇▂▄▄▆▄▇▆▆▄▃▆▃▅▆▅▂▅
wandb:      train/policy_loss ▃▁▃▃▃▃▃▃▃▃▃▃▃▇▇▅▇▇█▇▇▅▅▇▆▆█▆▇▆█▅▅▇▆▅▆▄▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁██▃▅▃▆▂█▅▆█▆▅▃▂▃▅▅▆▅█▅▃▂▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63108
wandb: best/eval_avg_mil_loss 1.44771
wandb:  best/eval_ensemble_f1 0.63108
wandb:            eval/avg_f1 0.63108
wandb:      eval/avg_mil_loss 1.39824
wandb:       eval/ensemble_f1 0.63108
wandb:            test/avg_f1 0.63689
wandb:      test/avg_mil_loss 1.37919
wandb:       test/ensemble_f1 0.63689
wandb:           train/avg_f1 0.66263
wandb:      train/ensemble_f1 0.66263
wandb:         train/mil_loss 1.07625
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lb4ouydu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203049-lb4ouydu/logs
wandb: Agent Starting Run: dierku3o with config:
wandb: 	actor_learning_rate: 0.007080560516803652
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8751478202775982
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19826959898720545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203233-dierku3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dierku3o
wandb: uploading history steps 292-310, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇██
wandb: best/eval_avg_mil_loss ▄▃▃█▇▆▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇██
wandb:            eval/avg_f1 ▃▃▃▃▃▁▂▂▃▃▃▅▅▅▅▆████▇▇▇▇▇▆▆▆▇███████████
wandb:      eval/avg_mil_loss ▄▃▃▃▂▂▂▅████▇▇▆▆▆▆▅▅▅▅▅▅▄▄▂▂▂▂▁▁▁▁▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▂▂▃▃▅▂▂▁▅▅██▇▇▇▇▇▆▆▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▃▄▆▃▁▄▅▄▃▅▅▄▅▅▄▄▁▇▇▃▆▆▅▆▆▇█▆▇▅▆▅█▅▇▆█
wandb:      train/ensemble_f1 ▃▃▆▃▃▄▄▂▁▃▂▁▄▁█▄▅▆▅▆▆▅▄▄▆▄▄▆▆▆▅▆▄▅▅▆▄█▇▅
wandb:         train/mil_loss ▄▄▃▅▄▂▄▃▄▁▅▃▂▃▃▂▃▄▅▆▂▅▁▃▁▃█▁▃▄▂▅▃▄▃▄▄▃▄▃
wandb:      train/policy_loss ▆▇▅▆███▂▁▄▆▆▄▆▅▆▅▆██▄▆▁██▄█▆█▆▄█▅▆▆██▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▆▇█▄█▁▄▄▄▆▆▄▄▆█▅▅█▅█▄▁██▅▄▆█▆▅█▅██▅▆█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.40954
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.4096
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.90927
wandb:      test/avg_mil_loss 0.38244
wandb:       test/ensemble_f1 0.90927
wandb:           train/avg_f1 0.84712
wandb:      train/ensemble_f1 0.84712
wandb:         train/mil_loss 0.29693
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dierku3o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203233-dierku3o/logs
wandb: Agent Starting Run: tx2cquis with config:
wandb: 	actor_learning_rate: 1.1756344757041578e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6566328371022088
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3153343856953785
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203534-tx2cquis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tx2cquis
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▄▆▆▅▆█▄▄█▃▅▅▆▄▇▃▇▄▅▆▄▄▃▅▇▄▇▄▅▄▄▄▆▅▂▄▁
wandb:      train/ensemble_f1 ▅▆▂▅▅▂▅▇▅▅▃█▄▄▅▆▆▆▃▂▁▆▆▅▄▂▃▁▇▃▃▂▃▅▅▂▅▃▄▂
wandb:         train/mil_loss ▆█▄▁▅▆▃▆▆█▅▃▄▇▆▄▆▃▆▆▆▄▅▅▅▆▆▂▃▄▄▅▅▆▄▆▃▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.34419
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.35058
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.19447
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.85958
wandb:      train/ensemble_f1 0.85958
wandb:         train/mil_loss 0.30298
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tx2cquis
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203534-tx2cquis/logs
wandb: Agent Starting Run: bleanwxs with config:
wandb: 	actor_learning_rate: 0.0035167419151055377
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8495307274202093
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5903096401841181
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203636-bleanwxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bleanwxs
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████▅▅▅▅▅▁▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▆▆▇▇▇█
wandb:       eval/ensemble_f1 ███████████████████▅▅▅▅▅▁▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▅▅▆▆▆▄▆█▁▇▆▅▄▅▄▁▅▆▂▇▂▆▅▃▇▄▅▇▃▅▄▁▅▂▄▅▄
wandb:      train/ensemble_f1 ▅▄▄▆▅▁▅▅▄▄▅▅▄▅█▂▄▄▇▂▄▅▂▂▆▅▇▅▄▆▅▄▃▄▄▁▅▅▁▃
wandb:         train/mil_loss ▆▃▅▄▃▆▂▃▃█▃▅▄▆▅▄▄▄▃▄▆▆▅▆▃▆▅▇▆▄▄▅▅▃▃▅▇▁▃▄
wandb:      train/policy_loss ▆█▆▆██▆▅█▆▅▆███▅▆▆█▆▅▅▆▅▄▅▆▅▆▆▅▆▅▆▆▁▁▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.28129
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.29986
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.15989
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88801
wandb:      train/ensemble_f1 0.88801
wandb:         train/mil_loss 0.30166
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bleanwxs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203636-bleanwxs/logs
wandb: Agent Starting Run: y91m9zyz with config:
wandb: 	actor_learning_rate: 0.0012703248640391982
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3952250380461134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2376940483554809
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203739-y91m9zyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y91m9zyz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▃▄▃▅▆▆▅▃▄▅▆▁▅▆▇▃█▄▃▆▅▄▅▆▆▅▄▃▇▆▅▆▇▄▆▃▅
wandb:      train/ensemble_f1 ▇▅▇▅▄▇▂▄▆▆▆▅▄▂▃█▄▇▇▆▆▁▄▅▅▇▅▇▇▆█▄▅▆▇▅▇█▃▄
wandb:         train/mil_loss ▅▃▆▄▃▆▆▄▄▃▆▄▄▁▄█▂▃▅▄▆▄▆▆▃▁▄▃▅▄▄▆▃▂▇▂▃▆▃▃
wandb:      train/policy_loss ▃▅▅▃▃▃▄▃▃▄▃▃▄▃▃▂▅▃▅▅▆▃▄█▆▄▃▄▂▆▆██▂█▆█▁▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.30049
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.29579
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19861
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88236
wandb:      train/ensemble_f1 0.88236
wandb:         train/mil_loss 0.27957
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y91m9zyz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203739-y91m9zyz/logs
wandb: Agent Starting Run: az65lxcn with config:
wandb: 	actor_learning_rate: 0.0010947754800222588
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.33627213021998315
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28791033426688317
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203932-az65lxcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az65lxcn
wandb: uploading history steps 134-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ██▅▇▇▇▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▁▄▁▅▆▃▄▃▆▆▄▄▇▆▂▄▅▇▅▃▄▅██▇▇▄▇▁▄▄▅▅▂█▅▆▅
wandb:      train/ensemble_f1 ▅▇▃▂▃▄▃▆▅▁▅▅▂▁▃▃▄▇▃▆█▇▇▅█▄▃▄▇▇▇▂▄▆▅▄▅▂▇▃
wandb:         train/mil_loss ▆▇▆▃▁▃▄▅▄▄▆▅▃▅▆▆▁▅▇▅▆▃▆▁▆█▅▅▇▃▂▆▄▆▃▇▂▃█▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.2643
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.26198
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.18371
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.90347
wandb:      train/ensemble_f1 0.90347
wandb:         train/mil_loss 0.29358
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az65lxcn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203932-az65lxcn/logs
wandb: Agent Starting Run: oi7wp3a4 with config:
wandb: 	actor_learning_rate: 7.44770424997959e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16591182996797216
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39566707648951993
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204101-oi7wp3a4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oi7wp3a4
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▅▄▆▃▆▇▂█▂▃▅▄▆▄▄▇▄▂▄▄▁▃▆▆▆▃▃▃▁▂▇▆▄▅▄▅▇
wandb:      train/ensemble_f1 ▃▆▆▆▂▆█▃▅▄▄▄▄▄▆▄▄▁▃▃▄▃▄▄▃▄▁▅▇▄█▄▄▆▇▄▅▅▅▄
wandb:         train/mil_loss ▅▇▇▆▃▅▁▅▆▅▁▄▆▆▆▅▄▅▅▆▄▅▇▄▅▄█▅▇▇▆▅▄▄▅▁▅▄█▅
wandb:      train/policy_loss ██▄██▆▁▃▃▅█▄▆▆█▆██▆▅▃█▆▆▆█▄▆▆█▅▄█▅▄▃▆██▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇████▆▁▆█▁██▇▆▆▃▁▆▆▃▁▆▆█▃▃▆▃▆▇▃▃▁▁▃██▃█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.29637
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.28826
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.18853
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.90986
wandb:      train/ensemble_f1 0.90986
wandb:         train/mil_loss 0.27899
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oi7wp3a4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204101-oi7wp3a4/logs
wandb: Agent Starting Run: t6uz46zr with config:
wandb: 	actor_learning_rate: 0.0003701713612683752
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3701977593454283
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9313414874073483
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204203-t6uz46zr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t6uz46zr
wandb: uploading history steps 134-143, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▅▅▄▄▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▇▅▄▄▆▇▆▆█▃▇█▆▅▅▄▃▃▄▅▁▃▄▅▇▁▇▂▇▅▅▄▅▄▇▄▆▂
wandb:      train/ensemble_f1 ▄▂▃▆▅▄▁▄█▃▅▄▃▄▅▆▄▄▃▄▅▆▄▂▄▄▄▁▂▂▅▄▄▄▇▁▄▄▃▂
wandb:         train/mil_loss ▄▂▅▅▃▁▂▃▃▄▅▂▂▅▂▁▂▆▄▄▄▄▅▂▇▄▃█▅▃▃▅▃▂▃▁▃▄▃▃
wandb:      train/policy_loss ▅▅▆▇▇▆▅▅▇▆▅▆▅▅█▃▃▃█▄▅▃█▆▃▁▃▃█▄▄▅▆▁▃▆▃▃▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▄▅▄▅▅▆▅▂▄▃▄▁▃▄▆▄▃▁▅▂▅▅▂▃▂▄▄▅▂▃▁▂█▅▅▄▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.3485
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.34528
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.17494
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.90114
wandb:      train/ensemble_f1 0.90114
wandb:         train/mil_loss 0.2923
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t6uz46zr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204203-t6uz46zr/logs
wandb: Agent Starting Run: n9q3vj6f with config:
wandb: 	actor_learning_rate: 0.0007523084786243596
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8487898077881838
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14396312096251151
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204331-n9q3vj6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n9q3vj6f
wandb: uploading history steps 160-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇▇▆▆▆▆▆▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▅▁▃▄▂▅▃▆▄▅▇▅▅▄▄▄▃▄▆▄▄▅▇▇▆█▄▄██▅▅▃▇▆▅▆
wandb:      train/ensemble_f1 ▃▃▂▂▃▁▃▃▃▄▄▃▄▂▂▃▁▃▇▆▃▄▅▃▄▃▃▄▄▆▄▅▃█▂▄▄▅▄▃
wandb:         train/mil_loss ▁▆▄▃▁█▇▆▁▁▄▁▃▁▆▄▁▄▁▄▁▃▃▄▆▄▁▆▁▁▆▁▁▃▃▁▃▆▇▄
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▃▁▁▄▆▃▃▁▁▁▁█▅▃▃▄▄▃▅▃▃▄▃▃▃▃▃▅▅▅▄▃▄▄▄▄▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46082
wandb: best/eval_avg_mil_loss 4.23584
wandb:  best/eval_ensemble_f1 0.46082
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 4.19971
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 5.18522
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.47533
wandb:      train/ensemble_f1 0.47533
wandb:         train/mil_loss 0.90946
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n9q3vj6f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204331-n9q3vj6f/logs
wandb: Agent Starting Run: 40c9p6nv with config:
wandb: 	actor_learning_rate: 7.012123186529552e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5890507323802687
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06113771382494104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204509-40c9p6nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40c9p6nv
wandb: uploading history steps 133-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▁█▆
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▆████████████████████████████
wandb:      eval/avg_mil_loss ▆▅▅▅▆▅▅▅▆▆█████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▆▆██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▄▄▅▄▁▅▃▆▂▄▅▃▅▄▅▄▅▆▄▅▄▅▄▅▄▄▄▅█▄▆▅▆▅▄▇▆
wandb:      train/ensemble_f1 ▃▃▄▄▂▃▁▁▄▄▃▄▆▂▄▄▆▃▅▃▅▂▅▄▄▃▄▄▅▄▃▃▅▄▄▄▇▆█▅
wandb:         train/mil_loss ▄▄▇▄▅▅▃▄▂▄▅▂▃▄█▂▃▂▅▇▂▂▆▃▆▄▄▁▂▅▆▃▄▃▃▃▃▄▆▅
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 3.44778
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 3.374
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 4.20126
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.51889
wandb:      train/ensemble_f1 0.51889
wandb:         train/mil_loss 1.45021
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40c9p6nv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204509-40c9p6nv/logs
wandb: Agent Starting Run: rk6r4pcz with config:
wandb: 	actor_learning_rate: 0.0063709469491996665
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7184988845600451
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3861167283179293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204637-rk6r4pcz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rk6r4pcz
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██████
wandb:       eval/ensemble_f1 ████████████████████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▄▄▇▅█▃▆▅▄▃▆▇▆▃▅▅▃▄▅▅▆▅▄▅▄▄█▄█▃▃▃▂▃▆▅▁
wandb:      train/ensemble_f1 ▆▇▅▄▃▆▆▇▅▅▇▅▃█▄▆▃▄▃▂▃▁▄▇▄▅▅▅▅▄▅▃▅▄▄▃▄▆▄▆
wandb:         train/mil_loss ▅▅▆▇▃▆▄▃▅▄▇█▅▅▄▅▆▆▄▁▃▄▆▅▅▆▅▆▃▆▄▆▅▅▅▅▆▆▂▆
wandb:      train/policy_loss █████████████████████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▆▆█▇▇▇▅▇▇▇▇▇█▇▆▇▇▇▇▂▁▅▂▅▂▄▄▃▁▂▂▄▅▂▄▁▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.28466
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.29917
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.20506
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89538
wandb:      train/ensemble_f1 0.89538
wandb:         train/mil_loss 0.29631
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rk6r4pcz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204637-rk6r4pcz/logs
wandb: Agent Starting Run: 4i1nmlqb with config:
wandb: 	actor_learning_rate: 0.002661752924816798
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19895260474774612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02920834040016695
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204740-4i1nmlqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4i1nmlqb
wandb: uploading history steps 107-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:      eval/avg_mil_loss ▇▇▇▇▇▆▆▆▆▆▆██▆▆▆▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▁▅▅▆▄▆▄▂▇▄▆█▆▇▇▅▆▅▆█▇▁▂█▆▅▆▆▃▇▅▆▆▆▆▄▅▅
wandb:      train/ensemble_f1 ▄▆▅▅▅▆▃▂▄▇▅▁▃▂▄▁▅▆█▄▅▂▅▆▆▂▂▆▅▄▄▃▅▄▂▇▄▅▆▆
wandb:         train/mil_loss ▅▆▆▄▄▄▂▆▃▂▄▃█▄▃▅▂▄▆█▅▅▅▃▄▄▅▃▆▄▂▄█▆▁▆▄▅▃▂
wandb:      train/policy_loss ▂▄▃▁▂▁▁▁▄▃█▃▁▃▂▅▅▅▆▆█▆█▃▆▅▆█▆█▆▅▅█▅▃▅▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.30599
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.28724
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.19383
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.87293
wandb:      train/ensemble_f1 0.87293
wandb:         train/mil_loss 0.27776
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4i1nmlqb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204740-4i1nmlqb/logs
wandb: Agent Starting Run: ll049ffg with config:
wandb: 	actor_learning_rate: 0.008942670173001812
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4425548847220697
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05322496679962796
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204857-ll049ffg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll049ffg
wandb: uploading history steps 134-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █████████████▆▅▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▅▄▄▅▅▁▅▃▇▅▇▄▅▅▄▄▆▆▅█▃▆▆▇▄▇▆▆▇▆▆█▆▅▇█▅
wandb:      train/ensemble_f1 ▅▄▂▆▆▁▂▂▃▁▅▅▄▄▃▆▅▇▃▆▂▅█▃▇▆▇▄▆▆▄▅▄▇██▆█▄▇
wandb:         train/mil_loss ▅▃▅▄▁▄▂▁▄▄█▅▆▃▄▄▃▁▄▁▅▂▃▅▂▅▄▃▃▅▆▅▇▆▅▄▅▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55587
wandb: best/eval_avg_mil_loss 3.68712
wandb:  best/eval_ensemble_f1 0.55587
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 3.4288
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 4.34097
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.54227
wandb:      train/ensemble_f1 0.54227
wandb:         train/mil_loss 1.64133
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll049ffg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204857-ll049ffg/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.234.4:57390->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: rny85rt3 with config:
wandb: 	actor_learning_rate: 0.0007678082703162338
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10849018981684976
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6969636116309424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205048-rny85rt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rny85rt3
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▆▆▅▅█▅▅▆▆▂▅█▅▇▄▅▆▅▃▄▆▅▄▄▇▃▄▇▂▅▅█▁▆▆▆▄█
wandb:      train/ensemble_f1 ▃▃█▆▆█▇▇▆▆▃▆▂▅██▂▄▇▅▄▃▄▄▄▇▅▄▃▇▄▅▅█▁▆▇▄▄▃
wandb:         train/mil_loss ▃▄▁▄▆▆▆▃▄▅▂▆▃▆▂▄▅▇▅▂▁▅▄▂▃▅▄▄▃▆▆▁▃▃▁▅▅█▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.3774
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.35215
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.89275
wandb:      test/avg_mil_loss 0.21812
wandb:       test/ensemble_f1 0.89275
wandb:           train/avg_f1 0.88525
wandb:      train/ensemble_f1 0.88525
wandb:         train/mil_loss 0.31703
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rny85rt3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205048-rny85rt3/logs
wandb: Agent Starting Run: pj86xiu8 with config:
wandb: 	actor_learning_rate: 0.0011225445918806637
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8304320393346516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5149011877861382
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205150-pj86xiu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pj86xiu8
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████▁▁████████████
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ██████████████████████████▁█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▆▆▁▅▃▄▁▂▄▄▇▄▃▃▃▂▂▃▆▆▅▆▅▂▆▃▄▃█▄▆▅▄▄▅▃▃▂
wandb:      train/ensemble_f1 ▆▅▅▆▆▄▅▅▄▃▅▂▁▁▂▄▇▃▄▃▂▂▆▆▄▅▅▄▄█▂▅▅▇▄▃▄▄▅▆
wandb:         train/mil_loss ▇▄▄▅▆▆▄▇▄▇▅▃▅▅▆▇█▆▅▅▂▅▃▆▁▅▄▄▄▃▇▆▇▆▄▄▆▅▃▃
wandb:      train/policy_loss ██████████████████████████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████▁██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.32868
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.3487
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.17459
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.9028
wandb:      train/ensemble_f1 0.9028
wandb:         train/mil_loss 0.2731
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pj86xiu8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205150-pj86xiu8/logs
wandb: Agent Starting Run: f2w9kkqp with config:
wandb: 	actor_learning_rate: 0.0006589512713856693
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7041110999394705
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9345385073023974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205252-f2w9kkqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2w9kkqp
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▁▄▃▆▄▃▅▃▃▃▆▂▃▂▅▅▂▄▄▄▂▄▂▃▃▂▄▂▃▄▃▂▂▅▃▃█▅
wandb:      train/ensemble_f1 ▅▂▅▇▆▃▆▅▄▄▆▃▅▅▂▅▄▇▂▅▃█▃▁▂▄▄▆▄▂▃▃▇▃▄█▅▃█▆
wandb:         train/mil_loss ▇▇▇▅█▅▃▃▂▄▇▂▂▂▅▅▃▄▁▅▅▃▅▃▄▆▄▅▃▅▆▆▆▁▄▆▁▆▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.38494
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.39636
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.17761
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.88927
wandb:      train/ensemble_f1 0.88927
wandb:         train/mil_loss 0.28912
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2w9kkqp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205252-f2w9kkqp/logs
wandb: Agent Starting Run: zu70f01c with config:
wandb: 	actor_learning_rate: 2.896984995720445e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09263205493926384
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8660517132102854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205354-zu70f01c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zu70f01c
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████
wandb:       eval/ensemble_f1 ██████████████████▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▄▃▅▃▅▄▂▃▅▂▃▂▄▆▃▅▅▅▄▃▆▄█▁▃▄▅▂▅▄▂▆▅▅▅▄▃▃
wandb:      train/ensemble_f1 ▁▃▁▂▅▂▄▂▅▃▃▄▅▂▂▃▅▅▂▅▅▃▃▃▄▄█▃▄▅▄▄▆▃▆▃▃▅▃▂
wandb:         train/mil_loss ▂▇▄▇▆▆▄▆▅▆▆▁▄▄▄██▆▃▆▄▆▇▄▃▃▄▄▅▆▇▄▃▄▇▄▃▅▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.36436
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.36657
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.24708
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.87868
wandb:      train/ensemble_f1 0.87868
wandb:         train/mil_loss 0.29339
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zu70f01c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205354-zu70f01c/logs
wandb: Agent Starting Run: k0zahb06 with config:
wandb: 	actor_learning_rate: 6.83915533841278e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4081926621635671
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4121844486157415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205456-k0zahb06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0zahb06
wandb: uploading history steps 107-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▂▂▂▁▂▇▇▇▆▆▅▅▅███▇▇▇██▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▂▂▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁█████████████████████████████▁█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▃▃▅▇▁▆▅▃▄▃▃▄▆▇▅▄▅▂▅▆▄▅▆▅▅▄▅▄▆▄▅▆▄▅▄▆▄▄
wandb:      train/ensemble_f1 ▄▅█▃▅▅▆▅▄▇▂▆▅▄▄▅▁▄▂▆▆▆▃▅▄▄▆▇▆▅▄▅▅▅▅▄▄▅▅▂
wandb:         train/mil_loss ███▆▆▇▄▇▇█▆▃█▆▃▅▇▇▅▆▅▇▄█▆▆█▅▄▇▆▄▇▁▆▆▆▅▄█
wandb:      train/policy_loss ▆▆▆▆▆▆▃▃▃▄▃▄▂▅▅▄▄▁▂▄▅▄▂▅▆▆▄▄▄▁█▃▆▅▃▄▆▅▅▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▄▆▄▇▂▄▇▂▅▅▃▇▅▁▆▂▄▅▆▇▇▄▄▂▄▁▅▄▄█▄▅▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54044
wandb: best/eval_avg_mil_loss 1.47526
wandb:  best/eval_ensemble_f1 0.54044
wandb:            eval/avg_f1 0.53276
wandb:      eval/avg_mil_loss 1.48274
wandb:       eval/ensemble_f1 0.53276
wandb:            test/avg_f1 0.53619
wandb:      test/avg_mil_loss 1.61575
wandb:       test/ensemble_f1 0.53619
wandb:           train/avg_f1 0.551
wandb:      train/ensemble_f1 0.551
wandb:         train/mil_loss 1.28024
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0zahb06
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205456-k0zahb06/logs
wandb: Agent Starting Run: 2u4z6wc1 with config:
wandb: 	actor_learning_rate: 6.598262845092153e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05354192481775133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.36307827505728496
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205604-2u4z6wc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2u4z6wc1
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆█▇▂▅▃▇▅▄▂▂▃▃▂▂▂▆▅▄▅▅▄▆▃▄▁▁▂▅▄▄▁▄▄▅▇▇▄
wandb:      train/ensemble_f1 ▆█▅▄█▅▃▅▇▆▇▂▅▅▃▄▆▃▆▁▃▆▇▄▄▂▂▂▅▅▆▇▂▅▁▆▂█▁▅
wandb:         train/mil_loss ▄▅▅▇▆▃▅▄▆▅▆▄▆▇▆▃▄▃▄▆▄▅▂▄▅▁▂▅▃▇█▅▆▅▃▄▃▇▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.31816
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.31406
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.20849
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.89737
wandb:      train/ensemble_f1 0.89737
wandb:         train/mil_loss 0.2612
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2u4z6wc1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205604-2u4z6wc1/logs
wandb: Agent Starting Run: a4a8zho6 with config:
wandb: 	actor_learning_rate: 0.00016309924424884925
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8819908232605564
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9997247630626114
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205706-a4a8zho6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a4a8zho6
wandb: uploading history steps 133-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃▂▃▄▅▃▅▃▅▅▄▅▄▆▁▃▂▆▃▄▃▄▁▄▄▃▅▄█▄▅▆▃▅▆▅▃▅
wandb:      train/ensemble_f1 ▇▆▃▂▆▅▅▆█▁▅▇▅▇▅▄▂▃▅▆▄▄▇▇█▆▅▄▆▄▄▆▅▅▇▆▇▆▅▆
wandb:         train/mil_loss ▃▄▄█▅▅▁▃▄▁▁▃▁▃▅▁▁▃▃▁▁▃▃▃▅▃▃▃▇▁▄▁▃▁▃▁▁▁▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 3.80459
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 3.78667
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 4.35102
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.57131
wandb:      train/ensemble_f1 0.57131
wandb:         train/mil_loss 0.7193
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a4a8zho6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205706-a4a8zho6/logs
wandb: Agent Starting Run: fxsmn0xj with config:
wandb: 	actor_learning_rate: 1.4529435336698432e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5420587981903692
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5733628319227415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205839-fxsmn0xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fxsmn0xj
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████▁█████████████
wandb:      eval/avg_mil_loss ▄▄▄▄▅▆▆▇▇▇▇███▇▇█▆▅▅▅▅▄▄▅▆▆▆▆▆▇█▇▆▃▁▁▂▂▂
wandb:       eval/ensemble_f1 ███████████████████████████▁████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▆▃▃▆▄▅▂▅▇▃▆▆▃▁▂▄▇▅▅▇▄▆▄▄▂▆▂▁▄▃▆█▆▆▄▅▃
wandb:      train/ensemble_f1 ▃▂▄▆▃▃▂█▆▅▄▃▆▆▄▇▅▃▅▇▄▄▄▇▆▁▄▆▂▄▆▁▄▃▃█▂▄▅▂
wandb:         train/mil_loss ▅▂▃▃▂▄▆▄▃▂▁▄▃▇▆▃▄▄▄▃▄▂▃▃▂▂▃▄█▄▄▁▄▄▂▃▂▂▅▂
wandb:      train/policy_loss ██████████████████████████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▄██▁███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.33433
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.33388
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.20677
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.85575
wandb:      train/ensemble_f1 0.85575
wandb:         train/mil_loss 0.34833
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fxsmn0xj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205839-fxsmn0xj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 12j0vmye with config:
wandb: 	actor_learning_rate: 0.0005360680238162594
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9223057541882594
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2142908098247119
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210009-12j0vmye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12j0vmye
wandb: uploading history steps 106-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁█▅▅▅▅▅▅▅▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ██████▇▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁██████████▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▃▃▄▄▄▂▁▅▂▂▄▇▄▄▆▅▁█▅▇▅▆▇▆▆▇▄▄▅▅▅▆▅▄▆▅▆
wandb:      train/ensemble_f1 ▂▂▃▃▄▃▄▁▃▅▂▅▆▃▅▇▅▅▂▇▆▅▇▇█▅█▆▆▇▆▆▇▅▆▇▅▆█▇
wandb:         train/mil_loss ▄█▁▁▁▁▂▄▅▂▄▁▁▂▁▁▁▄▁▇▁▄▁▁▁▄▁▇▄▁▄▇▄▁▁▁▅▄▁▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▁▁▅▅▅▅▅█▅███▇▇███▆▅▆█▆██▅▇████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 3.70454
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.51645
wandb:      eval/avg_mil_loss 3.52757
wandb:       eval/ensemble_f1 0.51645
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 4.36276
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.53756
wandb:      train/ensemble_f1 0.53756
wandb:         train/mil_loss 0.68793
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12j0vmye
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210009-12j0vmye/logs
wandb: Agent Starting Run: zqaligka with config:
wandb: 	actor_learning_rate: 3.0511045221578452e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5605845884675388
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1632150669491219
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210126-zqaligka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqaligka
wandb: uploading history steps 290-307, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▃▃▄▄▅▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss ██▆▆▅▅▄▃▃▃▃▃▃▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▃▃▄▄▅▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▆▆▆▆▆▇▆▆▆▇▇▇▇██████▇▇▇▇▆▇
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▁▂▂▁▁▁▄▄▄▅▇▇▇▇▇▇▇▇▇▇██████████████▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▁▂▂▃▂▃▃▄▄▅▄▅▄▆▅▅▆▆▆▅▆▇▅▇▆██▆▇▆█▇█▇▇▇▇
wandb:      train/ensemble_f1 ▄▁▂▃▂▄▃▄▃▄▅▅▅▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▆▇▇▇█▇▇▇
wandb:         train/mil_loss ▆▆▅█▅▅▃▃▇▃▃▄▁▄▄▃▆▄▄▄▄▅▂▁▃▄▃▁▃▂▃▂▁▄▃▄▂▅▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77679
wandb: best/eval_avg_mil_loss 0.47112
wandb:  best/eval_ensemble_f1 0.77679
wandb:            eval/avg_f1 0.74694
wandb:      eval/avg_mil_loss 0.45712
wandb:       eval/ensemble_f1 0.74694
wandb:            test/avg_f1 0.78998
wandb:      test/avg_mil_loss 0.43992
wandb:       test/ensemble_f1 0.78998
wandb:           train/avg_f1 0.77914
wandb:      train/ensemble_f1 0.77914
wandb:         train/mil_loss 0.35298
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqaligka
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210126-zqaligka/logs
wandb: Agent Starting Run: eqv9g4ft with config:
wandb: 	actor_learning_rate: 1.3200639050275304e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7372723077505254
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8702574303705812
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210427-eqv9g4ft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eqv9g4ft
wandb: uploading history steps 134-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅██████████▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▃▃▃▃▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▅▅████████▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▅▃▆█▆▅▇▄▆▆▃▇▄▆▄▇▄▄█▃▃▅▂▆▅▅▆▅▅▅▄▄▄▂▅▂▁▂
wandb:      train/ensemble_f1 ▇▂▆▅▄▅▆▅▅▃▄▅▄▅▁▆▄▂▆▅▇▄▁▅▅▅▃▄▄▅▆██▄▃▃▄▃▂▃
wandb:         train/mil_loss ▆▆▄▆▄▄▅▅▅▃▅▅▅▅▂▃▆▄▅▁▄▄▅▄▃▁▆█▅▆▆▂▃▃▅▄▅▃▃▅
wandb:      train/policy_loss ▃▃▃▂▃▄▄▂▂▂▂▃▂▃▂▂▂▅▃▃▁▃▄▂▃▃▁▅█▄█▁▄▄▆▅▆▆▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.2328
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.2408
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.22535
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.88401
wandb:      train/ensemble_f1 0.88401
wandb:         train/mil_loss 0.29215
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eqv9g4ft
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210427-eqv9g4ft/logs
wandb: Agent Starting Run: 0i7la7r2 with config:
wandb: 	actor_learning_rate: 0.0006840505895596642
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9842787529085792
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8482975147384062
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210555-0i7la7r2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0i7la7r2
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▄▅▁▅▃▅▂█▇▃▅▅▂▂▃▁▅▄▃▄▅▆▅▅▂▁▄▅▃▂▅▄▃▇▅▄▅
wandb:      train/ensemble_f1 ▆▄▃▄▅█▅▃▅▄▁▅▄▄▄▆▄▇▃▄▄▂▃▁▃▄▃▅▄▅▂▂▄▃▃▄▄▅▃▄
wandb:         train/mil_loss ▇▄▅▇▅▆▆▅▆▆█▇▇▄▄▇█▅▇▃▅▁▄▇▄▆▄█▆▄▃▄▅▅▇▆▄▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.35091
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.38185
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.91511
wandb:      test/avg_mil_loss 0.22051
wandb:       test/ensemble_f1 0.91511
wandb:           train/avg_f1 0.8533
wandb:      train/ensemble_f1 0.8533
wandb:         train/mil_loss 0.26544
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0i7la7r2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210555-0i7la7r2/logs
wandb: Agent Starting Run: r2kdjnn5 with config:
wandb: 	actor_learning_rate: 4.586471437740661e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1781865722952839
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32541492887229495
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210657-r2kdjnn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r2kdjnn5
wandb: uploading history steps 454-478, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ▁▃▂▂▃▄▇▇▇▇██
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇████▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▃▄▄▅▅▅▆▅▆▆▆█▇▇▇█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆███████▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁▂▂▂▂▃▄▃▄▂▄▄▄▄▄▆▆▆▅▅▆▄▆▄▆▅▇▆▆▇██▇▇██
wandb:      train/ensemble_f1 ▁▁▂▂▁▂▁▁▂▂▃▂▃▄▄▄▅▃▆▄▄▄▅▅▅▆▆▅▅▆▆▅▅▆█▆▇▇▆█
wandb:         train/mil_loss ▃▁▂▇▁▅▇▅▃▃▃▅▄▅▃▅▂▃▃▅▄▃▄▆▅▆▅▃▃▅▅▆▄▂▆█▆█▇▇
wandb:      train/policy_loss ███████████████████▁████████▄███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 2.57467
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 2.77709
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.4188
wandb:      test/avg_mil_loss 3.18336
wandb:       test/ensemble_f1 0.4188
wandb:           train/avg_f1 0.47696
wandb:      train/ensemble_f1 0.47696
wandb:         train/mil_loss 2.16786
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r2kdjnn5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210657-r2kdjnn5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iwrrjojo with config:
wandb: 	actor_learning_rate: 0.002861968958124448
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5789885360696785
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1970283597728869
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211154-iwrrjojo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iwrrjojo
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▃▅▃▁▁▃▄▅▇▅▆▆█▂▇▆▇▆▄▄▆▁▇▇█▅▄▃▆▇▃▄▄▅▄▅▄▇
wandb:      train/ensemble_f1 ▇▆▅▃▅▆▆▅▄▁▇▆▆█▅▆▆▆▃▄█▄▆▁▄▇█▆▄▃▅▅▃▅▃▄▇▇▅▇
wandb:         train/mil_loss ▆▅▅▆▆▆█▆▇▂▅▇█▂▂▆▄▄▃▇▅▄▁▅▂▂▂▇▄▆▆▂▆▁▅▆▃▄▅▆
wandb:      train/policy_loss ▄▅▃▆▄▆▄▂▄▄▃▅▇▆▂▇▃█▅▅▄▂▄▇▆▂▇▅▄▃▅█▇▃▆▁▄▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▃▄▄▂▄▄▅▃▅▇▇▄▄▂▇▁▇▇▇▅█▅▂▇▇▃▇▅▅▃▅▆▇▅▇▃▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57835
wandb: best/eval_avg_mil_loss 2.5618
wandb:  best/eval_ensemble_f1 0.57835
wandb:            eval/avg_f1 0.57835
wandb:      eval/avg_mil_loss 2.51253
wandb:       eval/ensemble_f1 0.57835
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 3.31541
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.60933
wandb:      train/ensemble_f1 0.60933
wandb:         train/mil_loss 1.67449
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iwrrjojo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211154-iwrrjojo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7jqn90iz with config:
wandb: 	actor_learning_rate: 0.00015678111200126575
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.463211643788474
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.295427190204948
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211305-7jqn90iz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jqn90iz
wandb: uploading history steps 80-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▅▄▄▄▃▄▄▄▄▄▃▂▂▂▁▁▁▁▁▁▁▂▃▃▃▄▄▃▃▃▃▄▄▄▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▅▁▃▅▇▆█▅▅▄▆▃▃▃▄▄▆▃▆▂▃▅▇▇▃█▃▃▃▄▆▄▄▅▇▅▅
wandb:      train/ensemble_f1 ▅█▁▃▄▄▂▆▅▅▁▄▃▃▃▂▃▁▆▅▃▆▂▃▄▃▃▄▄▂▂▆▃▆▄▃▅▇▃▃
wandb:         train/mil_loss ▃▄▂▄▅▄▄▃▄▄▄▄▄▅█▅▄▃▃▂▁▂▄▄▃▄▄▆▂▅▃▄▅▃▃▅▄▄▅▅
wandb:      train/policy_loss ▄▅▂▃▃▆▅█▆▃▂▁▃▂▇▃▂▅▆▇▇▇▅▅▆▅▆▅▂▅█▅▅▅▅▅▅▃▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▅█▆▆█▆▅▆▅▂▃▁▃▅▆▇▅▇▃▅▇█▂▅▆▂▆▅▅▅▅▅▃▃▅▇▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.36259
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.36103
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18028
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88149
wandb:      train/ensemble_f1 0.88149
wandb:         train/mil_loss 0.33259
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jqn90iz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211305-7jqn90iz/logs
wandb: Agent Starting Run: gkgorh8y with config:
wandb: 	actor_learning_rate: 0.0006906815108395184
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4892133029448683
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.434223619533327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211411-gkgorh8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gkgorh8y
wandb: uploading history steps 81-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▆▇▆▆▆▅▆▇▆▅▅▆▆▆▆▆▆▆▇▇▆▆▆▆▅▅▅▅▄▃▃▃▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▄▃▅▅▄▆▅▂▄▇▄▅▄▇▃▆▄█▅▃▃▃▇▇▃▅▃▂▅▄▅▅▄▅▁▂▅
wandb:      train/ensemble_f1 ▁▄▄▃▄▄▂▅▃▂▇▂▄▆▄▅▂▅█▂▇▆▂▂▅▄▂▄▅▆▇▄▃▃▆▁▁▅▅▅
wandb:         train/mil_loss ▇▂▃▅▄▄▄▅▃█▄▅▄▄▁▄▅▆▇█▄▆▃▅▃▆▃▄▅▄▆▅▄▇▆▆▆▄▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.34652
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.34333
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.19451
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.88163
wandb:      train/ensemble_f1 0.88163
wandb:         train/mil_loss 0.29295
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gkgorh8y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211411-gkgorh8y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8p5jesti with config:
wandb: 	actor_learning_rate: 0.0015583869104621078
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6805863743095639
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4713199942619321
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211523-8p5jesti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8p5jesti
wandb: uploading history steps 239-259, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆█
wandb: best/eval_avg_mil_loss █▇▄▁▃
wandb:  best/eval_ensemble_f1 ▁▄▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▆▆▆▅████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▄▄▄▄▄▄▃▃▃▃▃▃▂▂▁▁▁▁▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▆▄▄▁▄▄▇▄▅▅▃▃▄▃▅▂▅█▅▃█▅▄▃▆▄▄▆▄▅▅▅█▆▄█▆▃
wandb:      train/ensemble_f1 ▃▄▄▄▃▁▂▂▃▄▄▇▅▃▄▅▃▄▃▇▂▃▆▅▂▅▆▄▆▅▇▅▅▅▅▆█▇▄▃
wandb:         train/mil_loss ▄▆▇▅▄█▁▄█▄▄▄▄▃▆▃▆▃▅▄▃▃▄▂▆▇▂▃▅▄▆▄▆▇▄▂▆▆▇▂
wandb:      train/policy_loss ███████████████████████▅▆▅▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄██▄▄▄▄▄▄▄▄▄▄▄▄▄▁▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 4.376
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 4.33832
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 5.18162
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.50828
wandb:      train/ensemble_f1 0.50828
wandb:         train/mil_loss 2.07183
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8p5jesti
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211523-8p5jesti/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7muu7sqk with config:
wandb: 	actor_learning_rate: 0.002269486819434176
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4970975425288313
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8270078614782834
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211803-7muu7sqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7muu7sqk
wandb: uploading history steps 131-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▃▃▅▄▄▆▄▃▆▃▅▇█▅▃▄▅▂▅▅▅▂▄▃▃▁▁▅▄▆▅▄▅▃▃▆▆
wandb:      train/ensemble_f1 ▄▄▅▆▅▇▆█▅▄▅▄▄▅▇▆▇▇▆█▅▆▆▁▇▃▅█▇▅▁▇▅▄▁▆█▄█▅
wandb:         train/mil_loss ▃▅▅▁▄▂▃▁▅▅▆▃▂▅▃▃▂▆▄▂▃▆▅█▄▄▂▃▄▆▄▆▃▅▂▇▄▂▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 4.33528
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54814
wandb:      eval/avg_mil_loss 4.30392
wandb:       eval/ensemble_f1 0.54814
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 4.96474
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.52987
wandb:      train/ensemble_f1 0.52987
wandb:         train/mil_loss 1.77845
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7muu7sqk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211803-7muu7sqk/logs
wandb: Agent Starting Run: hla37w9v with config:
wandb: 	actor_learning_rate: 0.00101790334631701
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1741858686032517
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5297548622856019
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_211927-hla37w9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/peyzdy6e
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hla37w9v
wandb: uploading history steps 108-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▃▃▃▃▃▃▃▃▃▆█▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▆█▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▃▃▆▆▆▆███▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▁▃▄▂▅▃▅▅▃▄▃▂▇▆▆▅▇▅▅█▅▅▄▆▃▇▄▅▄▇▅▅▂▂▃▄▅▅
wandb:      train/ensemble_f1 ▁▂▂▂▄▄▅▃▂▅▂▄▃▅▃▆▅▅▄▂▄▄▄▄▇▄▆█▂▂▅▂▂▅▆▃▂▃▆▄
wandb:         train/mil_loss ▄▇▅█▅▆▅▃▇▆▅▅▃█▄▇▂▄▇▆▄▃▇▄▇▅▄██▄▇▄▇▅▁▄▅▇▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▄▅█▇█▅██▃▃▃▁▂▂▁▁▂▂▁▂▂▁▃▂▁▁▂▁▂▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.36549
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.84998
wandb:      eval/avg_mil_loss 0.35897
wandb:       eval/ensemble_f1 0.84998
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.32133
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.86496
wandb:      train/ensemble_f1 0.86496
wandb:         train/mil_loss 0.35239
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hla37w9v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_211927-hla37w9v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: vobe7mmj with config:
wandb: 	actor_learning_rate: 0.004011608899061401
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.936073100947418
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4604202044405844
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_212106-vobe7mmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vobe7mmj
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 766-788, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▃▂▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▃▂▅▅▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▂▁▂▁▂▂▁▃▃▃▃▄▄▄▄▅▆▅▆▆▅▆▆▆▆▆█▇█▇▇▇█████
wandb:      train/ensemble_f1 ▁▂▁▂▂▃▃▂▂▃▃▃▃▄▄▄▃▅▅▅▅▄▅▅▆▆▆▆▆▆▇▇█▇▇▇▇▇▇█
wandb:         train/mil_loss ▅▄▇▃▂▃▃█▄▆▅▆▂▂▅▁▃▂▅▃▄▁▂▅▄▄▁▂▂▂▄▆▃▂▁▂▁▃▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▂▂▂▄▄▄▄▄▄▄▄▄▄▄▄██▆▄▄▄▄▄▄▄▄▁▃█████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████▁█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72678
wandb: best/eval_avg_mil_loss 0.49268
wandb:  best/eval_ensemble_f1 0.72678
wandb:            eval/avg_f1 0.72678
wandb:      eval/avg_mil_loss 0.46783
wandb:       eval/ensemble_f1 0.72678
wandb:            test/avg_f1 0.62795
wandb:      test/avg_mil_loss 0.56286
wandb:       test/ensemble_f1 0.62795
wandb:           train/avg_f1 0.68137
wandb:      train/ensemble_f1 0.68137
wandb:         train/mil_loss 0.25071
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vobe7mmj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_212106-vobe7mmj/logs
wandb: Agent Starting Run: m1247wns with config:
wandb: 	actor_learning_rate: 0.00821839590493796
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.319407413295579
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.555861630866514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_212855-m1247wns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1247wns
wandb: uploading history steps 418-439, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss █▆▅▅▅▄▄▄▃▃▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▅▆▅▆▆▆▇▇▇█▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▄▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▂▂▃▁▁▂▃▃▂▄▃▃▄▄▄▄▄▄▅▅▅▅▆▆▅▆▆██▇██▇█▇▇
wandb:      train/ensemble_f1 ▁▁▂▁▂▂▂▂▁▁▂▃▂▃▃▃▄▃▃▄▄▅▄▆▅▆▆▅▇▆▆▆▆█▆▆████
wandb:         train/mil_loss ▅▁█▇▆█▆▆▆█▇▇▅▃▄▆▃▆▇▇▄▄▅▅▄▅▅▇▄▃▄▅▅▆▅▄▄▆▅▃
wandb:      train/policy_loss █████████████████▅███████████▁██████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▅▂▂▂▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56342
wandb: best/eval_avg_mil_loss 1.38486
wandb:  best/eval_ensemble_f1 0.56342
wandb:            eval/avg_f1 0.56234
wandb:      eval/avg_mil_loss 1.32941
wandb:       eval/ensemble_f1 0.56234
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 1.66873
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.56651
wandb:      train/ensemble_f1 0.56651
wandb:         train/mil_loss 0.95363
wandb:      train/policy_loss 0.35246
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.35246
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1247wns
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_212855-m1247wns/logs
wandb: Agent Starting Run: tdfsndwy with config:
wandb: 	actor_learning_rate: 0.003216570348905468
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9261050328795676
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47423946368132097
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_213313-tdfsndwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tdfsndwy
wandb: uploading wandb-summary.json
wandb: uploading history steps 487-500, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ▆██▇▆▅▃▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▂▁▁▂▃▃▄▄▄▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆██████
wandb:      eval/avg_mil_loss ▆██▇▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▄▄▄▄▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▁▄▂▂▂▃▂▂▁▃▄▄▄▄▅▅▅▅▅▅▆▆▅▅▅▆▅▆▇▆▆▇█▆▆█
wandb:      train/ensemble_f1 ▂▂▂▁▁▂▃▁▃▄▄▄▄▅▄▅▇▆▇▄▆▅▅▆▅▆▄▇▆▅▆▇▆█▅▆▇▇▆▆
wandb:         train/mil_loss ▆▅█▅▃▄▄▃▂▃▄▅▃▆▄▆▅▄▅▅▂▁▄▄▃▄▃▄▄▃▅▄▂▅▅▄▁▄▄▄
wandb:      train/policy_loss █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.2884
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.28379
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.29626
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.8475
wandb:      train/ensemble_f1 0.8475
wandb:         train/mil_loss 0.22271
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tdfsndwy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_213313-tdfsndwy/logs
wandb: Agent Starting Run: g7vafxnr with config:
wandb: 	actor_learning_rate: 0.002797456390319635
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.911218914321074
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5204584516618229
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_213812-g7vafxnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7vafxnr
wandb: uploading history steps 257-258, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▃▃▁▃▃▃▃▃▃▄▄▄▂▃▃▄▃▃▆▅▅▄▆▆▃▆▆▇▅▆▆▆▆▅▆▅█
wandb:      train/ensemble_f1 ▄▃▄▃▄▃▃▃▁▃▅▄▃▅▅▅▃▅▆▄▄▆▆▆▅▇▇▇▆▇█▆▇▇▇█▅█▆▇
wandb:         train/mil_loss ▁▄▁▂▁▄▆▃▃▁▄▁▄▁▃▁▄▄▂▄▁▄▁▆▁▁▁▁▁▄▁▂▃▃▆█▁▃▁▇
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃██▆█▆██▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▆██▆█▆▆███▆█▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40782
wandb: best/eval_avg_mil_loss 2.15826
wandb:  best/eval_ensemble_f1 0.40782
wandb:            eval/avg_f1 0.40782
wandb:      eval/avg_mil_loss 2.10954
wandb:       eval/ensemble_f1 0.40782
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 2.72893
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.43088
wandb:      train/ensemble_f1 0.43088
wandb:         train/mil_loss 0.83207
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7vafxnr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_213812-g7vafxnr/logs
wandb: Agent Starting Run: mj9r7vc5 with config:
wandb: 	actor_learning_rate: 0.00023528089769515664
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0891954783829837
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18486399621406824
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214047-mj9r7vc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mj9r7vc5
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▆▆▆▆▆▆▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▁▄▅▅▅▇▄▃▆▄▂▃▆▅▄▅▆▃▇▃▄█▅▆▄▆▅▆▆▄▇▄▂▅▄▅▇
wandb:      train/ensemble_f1 ▅▇▅▄▆▄▅▄▅▅▅▁▄▃▃▃▄█▂▅▅▆▅▆▅▇▅█▄▅▃▄▄▆▄▄▇▃▂▇
wandb:         train/mil_loss ▃▇▄▄▄▃▄▆▄▅▆▆▆▄▄▁▄▁█▄▁▅▄▆▃▁▇▃▅▆▂▅▃▇▄▅▄▆▄▅
wandb:      train/policy_loss █▅▄▁▁▁▁▁▁▁▅▅▄▄▅▁▁▄▁█▁▁▁▁▁█▂▄█▁█▅▁▅▁▂▁▁▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▁▁▁▁▁▁▁▁▅▁▅█▅▄▄▁▅▁▅▁▁▅▁▂▄█▄█▅▁█▅▅▂▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.26433
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.26236
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.15735
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.92118
wandb:      train/ensemble_f1 0.92118
wandb:         train/mil_loss 0.21117
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mj9r7vc5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214047-mj9r7vc5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4xzxil9p with config:
wandb: 	actor_learning_rate: 0.002852450474582184
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31888912083880483
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7771550814127799
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214213-4xzxil9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4xzxil9p
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄█▅▅▇█▆▃▆▅▆▆▅▆▅▃▆▆▄▅▇▄▅▅▄█▅▅▇▄▄▅▁▆▇▄▃▆▇
wandb:      train/ensemble_f1 ▄▇▃▅▇▃▆▅▅▂▂▅▅▃▂▃▂▆▄▅▃▄▅▆▅▆▄▅▃▄▆▁█▅▄▅▅▃▁▆
wandb:         train/mil_loss ▄▁▃▃▄▃▂▃▅█▅▅▆▅▅▇▁▃▁▂▄▅▂▄▄▂▆▃▁▁▂▅▃▅▃▁▄▃▃▁
wandb:      train/policy_loss ▁▆▄▃▅▅▅▆▃█▃▆▅▆▁▂▄▄▆█▄▆▄▄▄▆▂▄▃▅▄▆▃▃▄▅▄▁▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▅▅██▅▅▇▇▅▆▄▅▄▅▄▇▅▆▇▅▅▄▅▄▄▁▇▆▅▅▇▄▅█▅▅▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.30485
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.29092
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.08217
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.92307
wandb:      train/ensemble_f1 0.92307
wandb:         train/mil_loss 0.2218
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4xzxil9p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214213-4xzxil9p/logs
wandb: Agent Starting Run: cl7plkxa with config:
wandb: 	actor_learning_rate: 2.4175813861639084e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6721783788958952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5263430356952868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214320-cl7plkxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cl7plkxa
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▅▃▃▄▄▄▄▄▄▄▄▃▃▃▂▂▁▃▃▃▃▂▂▅▅▅▅▅▅▅▄████▇
wandb:       eval/ensemble_f1 █████████▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂█▁▃▆▆▅▃▃▂▂▇▃▂▅▄▅▄▄▃▇▆▆▄▃▃▅▆▆▄▅▃▄▄▅▃▂▅▅
wandb:      train/ensemble_f1 ▇▁▅▅▄▁▇▅█▅▅▃▆▂▅▅▅█▆▇▃▆▅▅█▆▆▇▇█▄▄▅▆▄▄▅▅▁▂
wandb:         train/mil_loss ▆▃▄▇▅▅▆▇▂▇█▆▁▅▄▄▃▁▄▄▃▅▃▅▆▃▃▂▁▃▂▆▅▂▁▅▅▆▄▇
wandb:      train/policy_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▄▅▁▆▇▄▅█▅█▃▅▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6875
wandb: best/eval_avg_mil_loss 0.76166
wandb:  best/eval_ensemble_f1 0.6875
wandb:            eval/avg_f1 0.66018
wandb:      eval/avg_mil_loss 0.76646
wandb:       eval/ensemble_f1 0.66018
wandb:            test/avg_f1 0.75845
wandb:      test/avg_mil_loss 0.59346
wandb:       test/ensemble_f1 0.75845
wandb:           train/avg_f1 0.73553
wandb:      train/ensemble_f1 0.73553
wandb:         train/mil_loss 0.25754
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cl7plkxa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214320-cl7plkxa/logs
wandb: Agent Starting Run: 1x2hy0sd with config:
wandb: 	actor_learning_rate: 0.0008088095368308631
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.40192810319986727
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2379246352206047
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214427-1x2hy0sd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1x2hy0sd
wandb: uploading history steps 234-246, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ▇▅▃█▆▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▄▄▄▂▂▂▂▂▂▂▇▇▇▇█████████████████████
wandb:      eval/avg_mil_loss ▇▇▅▃▄▄██████████████▆▆▆▆▆▆▁▂▂▁▁▁▁▁▁▁▁▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▂▂▄▂▂▂▂▂▂▂▂▂▅▅▅▇▇▇▇▅▅▅███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▁▃▆▇▆▄▄▂▆▆▆▄▅▃▄▆▆▃▆▇▆▃▃▅▆▇▇▆▄▅▅█▅▄▇▇▇
wandb:      train/ensemble_f1 ▅▁▄▂▄▂▂▃▇▄▃▂▁▅█▄▅█▄▇▄▅▇▆▅█▆▇▇▇▆▅██▃▄▅▅▆▇
wandb:         train/mil_loss ▄▅▇▄█▆▄▅▄▆▇▄▆▄▆▄▃▄▂▃▃▅▃▁▃▇▂▅▂▃▃▄▅▃▅▄▃▁▃▄
wandb:      train/policy_loss ▄▃▆▅██▇█▄█▇▄▅▁▄▃▃▃▁▅▆▆▄▆▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.26117
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.26639
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.88946
wandb:      test/avg_mil_loss 0.22691
wandb:       test/ensemble_f1 0.88946
wandb:           train/avg_f1 0.89609
wandb:      train/ensemble_f1 0.89609
wandb:         train/mil_loss 0.26938
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1x2hy0sd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214427-1x2hy0sd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: irq2tm6h with config:
wandb: 	actor_learning_rate: 0.0010040381846092464
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5290466345632027
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.506853372215928
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214704-irq2tm6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/irq2tm6h
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▅▁▄▂▆▄▄▅▅▁▂▄▅▄▄▃▆▄▄▅▄▄▁▁▆▂▃▅▄█▅▁▅█▆▅▃
wandb:      train/ensemble_f1 ▃▆▅▆▄▄▆▃▅▅▆▅▇▁▃▁▄▃▆▄▁▁▂▆▅▃▅▆▅▄█▃▅▂▁▄█▄▆▇
wandb:         train/mil_loss ▄█▃▅▄▂▁▃▅▃▃▆▆▄▆▂▅▆▅▃▃▆▃▅▂▄▅▆▅▅▄▆▄▄▅▂█▄▁▂
wandb:      train/policy_loss ▆▅▅▃▄▄▄▄▆▅▄▇▄▅▇▂▆▄▄█▄█▄▄▃▄▇▄▅▅▃▂▂▅▄▄▁▄▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▄▅▄▄▅▅▆▄▃▆▂▇▇▅▄▃▄▃▂█▄▄▃▇▄▄▂▁▅▁▄▄▅▁▄▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.36357
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.357
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.1509
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.90435
wandb:      train/ensemble_f1 0.90435
wandb:         train/mil_loss 0.27193
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/irq2tm6h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214704-irq2tm6h/logs
wandb: Agent Starting Run: yij1hhok with config:
wandb: 	actor_learning_rate: 3.438104014656934e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.40390114065389826
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9761444086157692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214811-yij1hhok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yij1hhok
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅█▄▅▆▇▁▃▄▅▃▄▅▄▆▆▇▆▇▅▅▆▇▆▆▆█▄▄▆▁▇▆▆▆▆▄█
wandb:      train/ensemble_f1 ▄▅▇▄▆▅▆▄▄▄▄▅▂▄▂▇▅▅▅▅▅▄▄▅▆▅▄▆▅▄▁▃▅▅▅▅█▃▄▇
wandb:         train/mil_loss ▅▄▆▆▃▄▁▄▄▃▁▆▃▄▄▄▄▆▄▅▇▄▃▄▅▅▅▃▃▂▄█▃▃▄▃▅▄▆▃
wandb:      train/policy_loss ▇▅▁▃▅▂▄▂▄▂▄▃▃▇▆██▅▃▃▄▅▁▄▄▄▅▄▅▅▄▅▃▄▇▂▃█▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▂▅▅▂▃▂▅▂▇▆▃██▂▂▅▂▄▁▃▃▆▅▃▅▄▂▅▇▄▇▅▅▂█▅▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.24168
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.2519
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.15336
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.92617
wandb:      train/ensemble_f1 0.92617
wandb:         train/mil_loss 0.2666
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yij1hhok
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214811-yij1hhok/logs
wandb: Agent Starting Run: 7i7n9f61 with config:
wandb: 	actor_learning_rate: 0.002566786409338648
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6344607497987144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9796660506784364
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_214918-7i7n9f61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i7n9f61
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▆▇▇▇▇▆████████████████████████████
wandb:       eval/ensemble_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▂▇▄▃▁▂▅▆▂▄▅▄▄▅▇▄▄▅▃▅▅▆▄▆▅▇▆▇▅▃▄▇▆▅▄█▂
wandb:      train/ensemble_f1 ▅▄▃▁▅█▄▄▂▅▆▂▃▅▃▅▄▃▅▅▂▅▄▅▄▄▇▆▅▆▅▄▄▆▆▄▆█▄▁
wandb:         train/mil_loss ▄▅▃▇▇▄▇█▅▆▆▅▆▁▅▃▆▄▅▅▄▆▃▆█▇▃▅▇▆▅▆▆▄▇▅▆▆▆▆
wandb:      train/policy_loss ▁▅▅▅▅▄▃▄▆▄▁▅▁▄▃▃█▆▄▁▅▄▆▄▆▆█▃▄▃▁▆▄█▄█▆█▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▆▄▅▁▄▄▆▃▁▆▄▂▆▅▄▅▁▅▆▂▅▄█▁▅▄▇▄▇▄▄▄▇▄▇▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84962
wandb: best/eval_avg_mil_loss 0.37048
wandb:  best/eval_ensemble_f1 0.84962
wandb:            eval/avg_f1 0.83974
wandb:      eval/avg_mil_loss 0.38105
wandb:       eval/ensemble_f1 0.83974
wandb:            test/avg_f1 0.92677
wandb:      test/avg_mil_loss 0.16521
wandb:       test/ensemble_f1 0.92677
wandb:           train/avg_f1 0.88862
wandb:      train/ensemble_f1 0.88862
wandb:         train/mil_loss 0.26893
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i7n9f61
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_214918-7i7n9f61/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8v0u5mo6 with config:
wandb: 	actor_learning_rate: 0.00016232111867059196
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.25464944749406404
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6395804485618294
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215101-8v0u5mo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8v0u5mo6
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▄▄▄▄▄▃▅▃▅▅▄▄▄▄▄▄▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▂▂▂▂▅▄██▅▅▅▁▄▁▄▄▂▂▃▃▄▄▄▅▂▆▆▅▅▂▄▄▅▆▆▆▆
wandb:      train/ensemble_f1 ▄▆▂▂▄▃▃▄▄▅▅▃▇▃▆▆▅▅▆▃▃█▅▄▂▄▁▅▆▇▅▄█▁▄▅▇▇▆▇
wandb:         train/mil_loss ▇█▄▅▅▃▆▅▄▇▃▅▃▅▅▄▅▃▁█▃▅▃▄▄▃▆▅▄▂▇▄▃▄▅▅▃▆▆▁
wandb:      train/policy_loss ▂▄▄▄▆▆▂▄▁▆▄▄▁▅█▅▆▆▃▃▆▁▆▅▆▁▆▆▆▂█▇█▆▆▆▄▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▄█▄▆▆▄▄▂▆█▄▆▆▄█▂▄█▄▄█▆▆▁▄▄▆▂▃██▁█▄█▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.33331
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.31968
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.9375
wandb:      test/avg_mil_loss 0.12175
wandb:       test/ensemble_f1 0.9375
wandb:           train/avg_f1 0.92748
wandb:      train/ensemble_f1 0.92748
wandb:         train/mil_loss 0.19431
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8v0u5mo6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215101-8v0u5mo6/logs
wandb: Agent Starting Run: lmwupssn with config:
wandb: 	actor_learning_rate: 0.005753697879167157
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8674833568902972
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7903707610250527
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215208-lmwupssn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lmwupssn
wandb: uploading history steps 104-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇█
wandb: best/eval_avg_mil_loss █▆▂▁▁
wandb:  best/eval_ensemble_f1 ▁▄▆▇█
wandb:            eval/avg_f1 ▁▁▆▆▆▆██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▆▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▆▆▆▆▆▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▁▁▅▅▇▇█▇▇▇▆▇▆▅▆▆▇▇▇▆▆█▆█▆▇▆▇▇█▅▇▆▆█▇▇
wandb:      train/ensemble_f1 ▁▂▃▂▂▆█▇▆▇▆█▇▇▆▆▅▇▇▇▇▇███▇▇█▅▇▇▇▇█▆▆▆▆▆▇
wandb:         train/mil_loss ▆▄▅▄▅▂▄█▄▄▄▃▃▃▄▂▅▁▂▃▄▂▁▄▃▃▂▄▃▂▃▂▃▁▄▁▂▂▂▃
wandb:      train/policy_loss ▇█▇█▅▅▅▅▅▂▁▂▁▅▅▁▃▂▄▂▄▁▁▁▁▄▁▂▅▄▁▄▂▄▃▁▂▁▁▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▅█▁▄▄▄▇▇██▁▂▁▁▄▄▄▄▂▁▄▄▂▁▂▄▁▂▂▁▄▁▃▁▁▂▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.39796
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.82998
wandb:      eval/avg_mil_loss 0.43337
wandb:       eval/ensemble_f1 0.82998
wandb:            test/avg_f1 0.84926
wandb:      test/avg_mil_loss 0.2595
wandb:       test/ensemble_f1 0.84926
wandb:           train/avg_f1 0.86619
wandb:      train/ensemble_f1 0.86619
wandb:         train/mil_loss 0.26662
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lmwupssn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215208-lmwupssn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ekcwehph with config:
wandb: 	actor_learning_rate: 4.33116021804286e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10613613327683258
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9051710052539046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215336-ekcwehph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ekcwehph
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇████▇▇▆▆▆▆▆▆▆▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▅▅▂▇▂▄▅▄▄▃█▆▃▅▇▄▅▇▄█▄▅▇▆▅▄▆▅▃▃▅▃▇▄▅▇▄▁
wandb:      train/ensemble_f1 ▅▁▆▅▄▄▄▁▃▇▃▃▄▇▄▄▄▄█▃▄▄▃▅▃▇▅▄▅▃▅▅▃▇▆▄▇▄▇▁
wandb:         train/mil_loss ▆▄▆▆▅▅▂█▆▇▆▅▂▃█▅▇▅▅▃▄▄▅▂▃▆▅▆▁▄▇▃▆▄▄█▃▄▄▁
wandb:      train/policy_loss ▄▁▇▄▂▄▁▁▁▄▂▁▁█▁▁▄▁▄▄▁▁▄▁▁▄▁▄▁▇▄▄▄▂▄▇▄▁▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▁▇▂▂█▁▁▇▁▇▂▇▁▇▇▁▁▇▁▁▁▁▇▁█▁▁▁▁▇▁▂▇▁▇▁▁▁▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.30567
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.27125
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.13481
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.89027
wandb:      train/ensemble_f1 0.89027
wandb:         train/mil_loss 0.2087
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ekcwehph
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215336-ekcwehph/logs
wandb: Agent Starting Run: yhf9erfy with config:
wandb: 	actor_learning_rate: 0.00022077218872834816
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.026570294271644035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5529724308048106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215444-yhf9erfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yhf9erfy
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▅▄▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▂▄▆▅▇█▃▅▃▂▆▂▂▅▃▆▅▄▅▅▃▇▄▁▄▅▄▅▅▄▄▅▄▅▇▂▅▄
wandb:      train/ensemble_f1 ▄▁▁▃▄▃▅▂▇█▄▃▅▅▆▂▄▆▃▄▅▆▄▃▄▅▄▅▆▆▄▃▃▆▄▅▇▄▇▃
wandb:         train/mil_loss ▇▅▇▇▄▆▇▇▆▆▅▃▄▅▆▁▇█▄▇▅▅▁▇▆▇▅▄▄▅▂▅▇▇▂▄▅▃▄▄
wandb:      train/policy_loss ▁▁█▁▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁█▁▁▁█▁██▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁█▁▁▁█▁▁▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.39919
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.34799
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.13872
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.91238
wandb:      train/ensemble_f1 0.91238
wandb:         train/mil_loss 0.22418
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yhf9erfy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215444-yhf9erfy/logs
wandb: Agent Starting Run: smpkx42u with config:
wandb: 	actor_learning_rate: 8.962356321466481e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8336272667297494
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8810763803148339
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215551-smpkx42u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smpkx42u
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▆▃▇▄█▂▆▁▅▄▂▅▅▆▅▄▂▃▅▄▆▇▁▅▅▆▃▅▄▆▄▆▅▃▃▃▅
wandb:      train/ensemble_f1 ▆█▅▆▃▆▅▃▅▅▇▂▆▇▂▄▆▃▄▆▅▂▆▅▆▆▃▅▅▅▃▃▅▅▃▃▆▁▆▆
wandb:         train/mil_loss ▄▃▂▄▅▃▄▅▅▄▄▁▄▄█▃▇▄▃▄▅▆▁▃▄▃▄▃▄▆▄▅▅▁▇▄▅▄▄▅
wandb:      train/policy_loss ▆▃▃▅▃█▅▆█████▃█▆▆▃█▁▆▃█▆▁▆▆▆██▆▆▅█▃▅██▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▇█▇▇▆▇██▃█▃▁█▃▃▆▆▁█▁▃▆█▅█▃▆▅██▇▆▅█▆▆▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.37392
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.38971
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.14391
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.90231
wandb:      train/ensemble_f1 0.90231
wandb:         train/mil_loss 0.24941
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smpkx42u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215551-smpkx42u/logs
wandb: Agent Starting Run: 8y13d0a6 with config:
wandb: 	actor_learning_rate: 0.001711160728503288
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5750654212836566
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13735180512738088
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215658-8y13d0a6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8y13d0a6
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▅▅▄▄▅▄▃▂▁▅▅▅▄▄▅▆▅▄▅▆▆▆▇▅▅▆▄▃▂▃▃▃▄▄▇█▇▆▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▅▄▅▅▅▆█▃▇▇▄▅▁▄▃▁▅▄▆▃▁▅▆▅▃▇▆▅▄▁▁▆▅▂▂█▆
wandb:      train/ensemble_f1 ▆▅▄▄▄▅▅▅▇▅▆▅▆▅█▆▁▇▆▅▅▄▄▄▅▄▄▅▆▆█▅▂▆▅▅▆▁▄▃
wandb:         train/mil_loss ▆▃▅▆▃▃█▂▅▁▇▄▄▂▄▄▅▆▆█▅▃▃▄▄▆▂▅▆▄▄▄▆▄▁▅▅▄▆▄
wandb:      train/policy_loss ▅▂▄▇▆▄▂▆▆▆▁▂▅▂▅▂▅▆▄▄▂▅▅█▄▂▃▃▅▂▇▅▇▂▆▅▂▅▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅██▄▄▃▄▅▅▁▄▇▅▇▇▅▃▆▆▂▅▆▇▅▄▅▅▄▄▄▅▇▅▇▃▄▄▆▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.30879
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.30988
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.08463
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.93054
wandb:      train/ensemble_f1 0.93054
wandb:         train/mil_loss 0.22896
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8y13d0a6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215658-8y13d0a6/logs
wandb: Agent Starting Run: 7ak66us9 with config:
wandb: 	actor_learning_rate: 0.00504502746829721
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22016175945371508
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.680851578379488
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215806-7ak66us9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ak66us9
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▇▄▅▅▃▄▂▅▂▆▆▄▅▇▄▅▄▆▅▄█▄▆▆▆▅▄█▁▂▄▅▅▅▄▄▃
wandb:      train/ensemble_f1 ▅▆▇▄▅▅▅▂▆▄▆█▄▆▅▄▅▅▅▆▆▅▆▅█▄▄▄▅▆▁▄▇▅▆▄▅▃▄▃
wandb:         train/mil_loss ▇▁▅▃▆█▅▆▂▄▄▅▃▃▇▅▇▇▄▆▄▅█▅█▇▄▄▆▃▅▅▄▃█▃▃▁▃▅
wandb:      train/policy_loss ▅▅█▁▂▁▁▁▂▄▄▅▄▂▁▂▄▂▄▆▅▂▄▄▅▅▁▂▃▅▂▁▄▁▄▄▅▂▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▁▃▆▆▃▁▃▃█▃▆▁▆█▆▆█▆▃▁██▆▁▂▁▆▃▃▁▃▁██▂▃▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.25227
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.25727
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.92943
wandb:      test/avg_mil_loss 0.18934
wandb:       test/ensemble_f1 0.92943
wandb:           train/avg_f1 0.90749
wandb:      train/ensemble_f1 0.90749
wandb:         train/mil_loss 0.22693
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ak66us9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215806-7ak66us9/logs
wandb: Agent Starting Run: suciae7f with config:
wandb: 	actor_learning_rate: 0.0005713165974465009
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42788954060724527
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8657197580851888
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_215913-suciae7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/suciae7f
wandb: uploading history steps 104-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▄▄▄▆▆█▆▆▆▆▆▆▆▆▆▅▅▅▅▅▃▃▃▃▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▃▁▂▂▂▃▅█▅▅▅▄▄▄▃▃▂▂▃▃▃▃▃▄▄▄▄▄▅▇▇▇▇█
wandb:       eval/ensemble_f1 █████████▆▃▃▆▆▆▆███████▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▁▃▅▃▃▂▂▄▄▃▄██▅▅▅▃█▅▅▆▅▅▆▆▅▆▅▅▆▆▅▂▄▃▆▅
wandb:      train/ensemble_f1 ▃▂▄▃▁▄▃▂▃▁▅▂▄▆▃▄▂▇▅▆▆▄█▅▆▅▆▅▆▇▅▄▇▆▅▃▄▄▅▆
wandb:         train/mil_loss ▅▅▁▃▃▃▂▄▃▅▅▂▃█▃▃▆▃▆▃▃▄▂▃▄▃▂▁▃▂▂▄▃▁▂▂▂▂▂▃
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.22836
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.25712
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.83994
wandb:      test/avg_mil_loss 0.31929
wandb:       test/ensemble_f1 0.83994
wandb:           train/avg_f1 0.88484
wandb:      train/ensemble_f1 0.88484
wandb:         train/mil_loss 0.27865
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/suciae7f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_215913-suciae7f/logs
wandb: Agent Starting Run: adgopfu7 with config:
wandb: 	actor_learning_rate: 0.0004547278280565612
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20015046504180323
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13076051851242343
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_220025-adgopfu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/adgopfu7
wandb: uploading history steps 156-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████
wandb:      eval/avg_mil_loss ▅▅▅▅▅▆▆▆▆▆▆▅▅▅▄██▅▅▅▅▅▅▂▂██▇▇▇▇▄▄▄▄▃▃▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▂▅▄▃▁▅▃▄▄▃▆▁▄▅▇▆▄▃▄▆▅▆▄▆▅█▅▆▇▇▆▅▇▆▅▄▆▅
wandb:      train/ensemble_f1 ▇▅▅▄▄▆▆▃▅▆▅█▁▃▄▅▂▆▄▃▇▆▆▆▅▆▅▆▇▇▅▆▇▅▇▅▄▇▅▂
wandb:         train/mil_loss ▇▄▄▆▄▂█▄▂▂▃▇▂▂▆▅▂▂▅▃▄▅▂▃▃▅▄▆▅▄▅▁▃▄▂▅▃▂▅▄
wandb:      train/policy_loss ██▅▅▇▅▇█▅▅▆▇▆▇▅▂▂██▅██▇▇▁▃▁▁▂▄▂▁▂▂▂▂▂▂▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87981
wandb: best/eval_avg_mil_loss 0.34293
wandb:  best/eval_ensemble_f1 0.87981
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.34052
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.14372
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.91997
wandb:      train/ensemble_f1 0.91997
wandb:         train/mil_loss 0.19031
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/adgopfu7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_220025-adgopfu7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1oekfz23 with config:
wandb: 	actor_learning_rate: 0.007784243128545381
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4150634924301071
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13927432103315884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_220210-1oekfz23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1oekfz23
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▂▃▃▂▃▃▃▃▃▃▃▃▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▁▇▃▆▅▇▇█▄▅▇▆▄▆▃▆▆▅▄▅▅▆▆▇▄█▇█▅▅▄▅▄█▆▃▆
wandb:      train/ensemble_f1 ▄▄▄▁▇▆▆▃▇▅▇▇▄▆█▄▅▇▄▇▇▇▄▆▆█▇▇█▇▅▄▅██▄▇▆▃▆
wandb:         train/mil_loss ▆▆▃▅▅▄▆▃▆▃▅▄▄█▆▅▁▄▇█▅▆▃▅▃▃▆▇▄▂▄▄▃▆█▄▃▇▁▆
wandb:      train/policy_loss ▁▂▄▇▄▄▇▂▅▄▄▄▄▄▂▅▄▂▇▇▂▇▄▅▄▅▅▅▄▇█▄▇▂▇▄▅▄▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▅▃▆▄▅▅█▅▄▅▃▆▄▅▄█▅▄▃▆██▆▃▅▆▆▆█▁▆█▄▆▅▆▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.21037
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.23113
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.89936
wandb:      test/avg_mil_loss 0.2249
wandb:       test/ensemble_f1 0.89936
wandb:           train/avg_f1 0.90605
wandb:      train/ensemble_f1 0.90605
wandb:         train/mil_loss 0.23049
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1oekfz23
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_220210-1oekfz23/logs
wandb: Agent Starting Run: hcy09c3s with config:
wandb: 	actor_learning_rate: 0.0001262926697569712
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8971319576032366
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9340566308877908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_220318-hcy09c3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcy09c3s
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▃▃▃▃▃▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▂█▆▂▆▅▄▄▁▆▄▆▇▆▅▂▃▇▄▅▇▅▃▆▆▄▂▂▁▄▄▄▅▅▇▅▆▇
wandb:      train/ensemble_f1 ▄▆▅▃▅▇▆▆▇▇▆▆▅▄▄▄▇▅█▂▆▆▅▆▂▄▄▃▂▄▅▄▇▃▅▅▆▅▁▅
wandb:         train/mil_loss ▃▆▆▂█▅█▃▄▅▅▄▄▅▃▄▅▇▃▂▃▅▅▃▅▄▃▅▄▃▃▂▅▁▃▅▃▃▄▁
wandb:      train/policy_loss █▇████▆▇▇██▃▁▁▄▁▁▅▃▃▃▁▁▃▁▁▃▄▄▁▃▁▁▃▃▃▃▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆████▇▇▆▆▆█▁▁▁▄▁▁▁▅▃▁▁▃▁▄▁▁▃▁▁▁▃▁▁▃▃▃▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.38639
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.40829
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11296
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91423
wandb:      train/ensemble_f1 0.91423
wandb:         train/mil_loss 0.19863
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcy09c3s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_220318-hcy09c3s/logs
wandb: Agent Starting Run: jq3ps0xb with config:
wandb: 	actor_learning_rate: 5.205894409469685e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.473330686505716
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17165918274476422
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_220425-jq3ps0xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jq3ps0xb
wandb: uploading history steps 387-399, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▆▆▅▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▃▃▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▃▃▄▄▄▅▅▄▄▄▄▄▄▄▄▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▃▂▃▄▄▅▅▄▅▅▆▅▆▅▆▇▅▆▅▆▆▇▇▇▅▅▆█▆▇▇▇▇█▇▇█
wandb:      train/ensemble_f1 ▁▁▂▂▂▃▄▄▄▃▄▅▅▄▄▇▅▆▆▅▃▄▆▇▆▆▇▅▅▇▆▆▇▇█▆▇█▆▇
wandb:         train/mil_loss ▇▆▆▇█▅▆▇▄▅▄▄▄▃▅▃▄▃▄▂▃▃▄▃▃▁▂▃▂▂▂▅▂▃▂▁▂▂▂▂
wandb:      train/policy_loss ██▂██████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████▁███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.26851
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.26256
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.24313
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88854
wandb:      train/ensemble_f1 0.88854
wandb:         train/mil_loss 0.25692
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jq3ps0xb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_220425-jq3ps0xb/logs
wandb: Agent Starting Run: czplmybo with config:
wandb: 	actor_learning_rate: 0.0053904599541055595
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7947317449437954
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9277851857268044
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_220823-czplmybo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czplmybo
wandb: uploading history steps 232-238, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁████▁▁▁▁▁▁▁▁▁▁████████▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▆▆▅▁▃▃▅▅▅▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████▁▁▁▁▁▁▁▁████▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▃▃▅▅▄▂▁▄▅▃▄▅▃▄▅▇▄▅▆▅▅▆▆▇▆▆▆▇▆▆▆▇█▇▆▆▅▅
wandb:      train/ensemble_f1 ▅▁▃▂▄▃▃▃▄▂▃▂▄▁▄▆▅▅▇▄▆▆▆▅▇▆▆▆█▆▆▇▇█▆█▇▅▆▇
wandb:         train/mil_loss ▄▅▆▄▆▄▂▄▇█▃▄▆▅▅▅▄▄▃▃▄▅▂▅▅▄▃▃▄▄▄▁▄▄▅▁▄▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂▂▂▂▂▂▆▃▃█▄▃▁▅▅▂▄▃▄▄▅▂▂▂▂▂▄▃▃▃▅▃▅▄▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.23006
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.9
wandb:      eval/avg_mil_loss 0.23118
wandb:       eval/ensemble_f1 0.9
wandb:            test/avg_f1 0.92914
wandb:      test/avg_mil_loss 0.23709
wandb:       test/ensemble_f1 0.92914
wandb:           train/avg_f1 0.89874
wandb:      train/ensemble_f1 0.89874
wandb:         train/mil_loss 0.20187
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czplmybo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_220823-czplmybo/logs
wandb: Agent Starting Run: kasr7zjn with config:
wandb: 	actor_learning_rate: 0.0004853151886505057
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5348891345656545
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9964722116875124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_221048-kasr7zjn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kasr7zjn
wandb: uploading summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▃▆█
wandb: best/eval_avg_mil_loss ▇█▇▇▂▁
wandb:  best/eval_ensemble_f1 ▁▁▁▃▆█
wandb:            eval/avg_f1 ▁▃▃▃▃▃▃▃▃▃▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▆██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▄▅▄▅▆▄▃▅▅▃▂▅▄▆▃▁▄▂▇▄▆▄▄▆▆▆▇▅▅▆▇▆▅▅▅▆█▇
wandb:      train/ensemble_f1 ▁▃▂▅▅▅▄▄▃▂▅▂▄▂▃▃▅▃▄▂▄▃▁▆▃▇▄▄▆▆▅▇▅▇█▆▇▆▇▆
wandb:         train/mil_loss ▅▅▇▄█▇▆▄▆▃▅▇▆▄▆▅▄▆▄▅▅▄▃▄▃▅▆▃▁▆▆▅▁▇▅▅▃▃▅▇
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁██▃████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.28346
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.26917
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.25763
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.89374
wandb:      train/ensemble_f1 0.89374
wandb:         train/mil_loss 0.29717
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kasr7zjn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_221048-kasr7zjn/logs
wandb: Agent Starting Run: j2avjdqd with config:
wandb: 	actor_learning_rate: 4.3797015061457304e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7631448081871572
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35300346354615597
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_221225-j2avjdqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2avjdqd
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▅▅▆▆▆▆▆▇▇▇▇▇██████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▃▃▁▄▂▃▃▅▃▅▂▅▃▄▅▃▃▂▂▇▆▅▃▃▃█▂▃▃▂▄▄▅▃▄▄▆
wandb:      train/ensemble_f1 ▃▅▃▁▆▁█▂▃▃▃▃▄▃▆▅▃▄▃▂▅▆█▆▅▃▃█▆▄▄▅▄▃▃▇▁▃▇▂
wandb:         train/mil_loss █▅█▅▂▅▅▇▇▄▅▇▁▆▄▃▆▆▂▂▄▆▆▄▅▃▄▇▂▆█▃▁▆▆▄▂▄▄▄
wandb:      train/policy_loss ▆▆▃▃█▁▆▄▆▁▆▃▂▃▂▁▃▆▁▁█▆▁▁▆▃▁▆▄▂▆▃▃▃▁▃█▃▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▃▂▃▅▄▁█▂▅▇▅▁▃▅▃▁▁▄▅▅▃▇▅▃▅▃▅▃▆▃▃▃▆▅▅▃▃▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.25436
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.27926
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.13296
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.90457
wandb:      train/ensemble_f1 0.90457
wandb:         train/mil_loss 0.22456
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2avjdqd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_221225-j2avjdqd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w4ls2ilr with config:
wandb: 	actor_learning_rate: 0.0002557443891158153
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09587731800210132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.010339581428288835
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_221338-w4ls2ilr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w4ls2ilr
wandb: uploading history steps 286-305, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▅▄▄▃▃▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▅▅▆▆▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▄▄▅▆▆▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▃▄▄▄▄▄▃▃▃▃▃▄▃▄▃▄▄▄▄▅▅▅▄▅▅▅▄▅▆▅▇▆▅▆▇█
wandb:      train/ensemble_f1 ▂▁▁▂▂▃▂▃▂▃▄▅▅▄▅▄▅▄▅▄▅▅▅▅▅▅▆▄▆▅▅▅▅▄▇▆▆▆▇█
wandb:         train/mil_loss ▆█▆█▅▅▅▅▄▆▃▄▆▄▄▅▆▅▆▅▄▄▅▆▂▄▅▅▅▃▃▄▅▃▄▄▄▁▃▁
wandb:      train/policy_loss ▃▃▃▃▃▃▃▂▁█▆▆▅▃▃▇██▇▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▆████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55587
wandb: best/eval_avg_mil_loss 1.7272
wandb:  best/eval_ensemble_f1 0.55587
wandb:            eval/avg_f1 0.55587
wandb:      eval/avg_mil_loss 1.60582
wandb:       eval/ensemble_f1 0.55587
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.19471
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.56755
wandb:      train/ensemble_f1 0.56755
wandb:         train/mil_loss 1.40763
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sage-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w4ls2ilr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_221338-w4ls2ilr/logs
wandb: Agent Starting Run: hdnk9tk6 with config:
wandb: 	actor_learning_rate: 0.0013040719368423704
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8437570416646345
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2809710285875697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_221639-hdnk9tk6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdnk9tk6
wandb: uploading history steps 310-331, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▆▄▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▃▄▄▄▅▅▅▅▅▇▇█▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▆▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▄▄▄▄▄▃▃▃▃▄▅▅▅▅▅▅▅▆▇▇▇███▇█▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▄▂▃▄▃▃▄▄▄▄▅▄▇▆▄▄▆▇▆▄▅▅▅▇▇▆▆██▆▅▅▇▆▅▇▆▆
wandb:      train/ensemble_f1 ▁▃▁▁▃▄▃▄▃▃▂▅▃▅▂▅▆▃▃▇▅▇▄▅▄▄▅▄▅▄▆▅▅▅▆▆▅█▄▇
wandb:         train/mil_loss ▅█▃▅▆▃▃▂▃▆▄▃▃▃▄▁▂▃▂▃▃▂▄▃▂▇▂▃▃▄▂▄▁▃▄▄▅▃▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86841
wandb: best/eval_avg_mil_loss 0.34503
wandb:  best/eval_ensemble_f1 0.86841
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.32987
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.82
wandb:      test/avg_mil_loss 0.40206
wandb:       test/ensemble_f1 0.82
wandb:           train/avg_f1 0.84632
wandb:      train/ensemble_f1 0.84632
wandb:         train/mil_loss 0.27408
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdnk9tk6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_221639-hdnk9tk6/logs
wandb: Agent Starting Run: i1xpzp1o with config:
wandb: 	actor_learning_rate: 1.167848230983164e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5033006431916153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4775050728417898
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222000-i1xpzp1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i1xpzp1o
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▃▃▃▄▄▄▄▅▅▅▅▅▄▄▄▄▅▅▅▅▅▅▇████████▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▅▂▆▆▂▄▃▆▁▂▃▄▄▂▄▄▅▄▅▃▆▂▃▆▄▄▅█▆▂▄▁▆▃▁▃▄
wandb:      train/ensemble_f1 ▄▆▆▅▄▄▅▅▃▃█▃▂█▃▄▅▃▆▅▇▆▇▅█▆▆▆▅▇▇█▃▆▅▂▅▄▁▆
wandb:         train/mil_loss ▇▅▄▃▂▄▃▂▅▄▅▃▄▄▇▅▅▄▅▇▆▄▅▆▄▃▅▅▁▅▄▄▇▅▅▃▅█▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.3687
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.37182
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.13193
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.90443
wandb:      train/ensemble_f1 0.90443
wandb:         train/mil_loss 0.21944
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i1xpzp1o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222000-i1xpzp1o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: azsv3z5o with config:
wandb: 	actor_learning_rate: 0.00018590945517597251
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6129607299629726
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6623727566472883
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222113-azsv3z5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/azsv3z5o
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁████████████████████▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▃▄▄▄▃▃▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇██████
wandb:       eval/ensemble_f1 ████████████▁███████████████████████▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▂▅▅▅▅▆▃▇▆▄▃▅▆▃▃▄▅▇▅▃▅▂▁▄▃▄▂▆▂▂▅▃▅▃▄█▅
wandb:      train/ensemble_f1 ▃▆▅▅▆▅▇▃▄▆▆▅▄▂▄▄▂█▁▄▃▇▄▅▄▆▄▆▃▄▁▅▃▄▂▄▆▆▄▁
wandb:         train/mil_loss ▃▃▃▄▂▃▃▄▆▁▄▂▂▂▂▁▅▃▁▃▅▂▃▂█▄▄▂▃▄▅▃▁▄▅▄▂▄▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85978
wandb: best/eval_avg_mil_loss 0.34652
wandb:  best/eval_ensemble_f1 0.85978
wandb:            eval/avg_f1 0.84926
wandb:      eval/avg_mil_loss 0.35383
wandb:       eval/ensemble_f1 0.84926
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13951
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.90832
wandb:      train/ensemble_f1 0.90832
wandb:         train/mil_loss 0.21821
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/azsv3z5o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222113-azsv3z5o/logs
wandb: Agent Starting Run: i9xfy5kg with config:
wandb: 	actor_learning_rate: 1.1674741652998992e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6992317757480392
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4856579481799046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222221-i9xfy5kg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9xfy5kg
wandb: uploading history steps 155-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▂▆▄▆▂▅▁▄█▃▁▂▂▅▇▁▂█▃▄▃▇█▆▅▆▆▅▅▄▄▅▅▆▆▃
wandb:      train/ensemble_f1 ▂▃▅▂▄▁▂▃▄▄▂▃▃▅▂▁▃▂▅▄▃▁▅▅▄▆▃▃▅█▇▅▃▅▆▅▆▃▃▂
wandb:         train/mil_loss ▂▆▅▆▅▇▄▇▃▃▄▅▃▄▁▃▂▄▃▄▅▅█▅▃▂▅▅▃▂▄▄▄▃▁▃▂▃▂▂
wandb:      train/policy_loss ▅▄▆▃▂▄▃▅▂▆█▁▆▂██▅▂█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▁▁▃▃▆▁▇▆▁▆▃█▆▃▃▇▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59294
wandb: best/eval_avg_mil_loss 1.3955
wandb:  best/eval_ensemble_f1 0.59294
wandb:            eval/avg_f1 0.59294
wandb:      eval/avg_mil_loss 1.36054
wandb:       eval/ensemble_f1 0.59294
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 1.75888
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.5481
wandb:      train/ensemble_f1 0.5481
wandb:         train/mil_loss 0.34292
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9xfy5kg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222221-i9xfy5kg/logs
wandb: Agent Starting Run: czi0eal2 with config:
wandb: 	actor_learning_rate: 0.0004532000337526252
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04389311137989671
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5482210896833979
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222409-czi0eal2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czi0eal2
wandb: uploading history steps 104-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆▆▄▁▃▆▆█▆▆▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁█▆█▇▆▄▄▄▅▅▄▄▄▄▄▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃
wandb:       eval/ensemble_f1 ▇▅▁▁▂▄▇███▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▇▄▂▃▃▆▅▂▃▂▅▃▂▄▄▄▅▇▅▃▃▆▆▅▅▁▅▄▆▅▄▆▅▃▆▄▆▅
wandb:      train/ensemble_f1 ▆▄█▃▅▂▅▂▂▂▂▂▄▂▂▃▆▄▄▂▄▄▄▄▁▄▄▄▃▄▄▃▄▅▄▅▄▃▄▅
wandb:         train/mil_loss ▁▆▆▃▅▃▄▆▅▆▄█▆█▄▄▇▇▇▅▇▄▃▄█▆▄▂▄▄▄▆▇▁▂▄▄▄▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁███▅███████▄█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.39031
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.83974
wandb:      eval/avg_mil_loss 0.37529
wandb:       eval/ensemble_f1 0.83974
wandb:            test/avg_f1 0.84986
wandb:      test/avg_mil_loss 0.30087
wandb:       test/ensemble_f1 0.84986
wandb:           train/avg_f1 0.86647
wandb:      train/ensemble_f1 0.86647
wandb:         train/mil_loss 0.30484
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czi0eal2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222409-czi0eal2/logs
wandb: Agent Starting Run: sx8tfxc7 with config:
wandb: 	actor_learning_rate: 0.004620177689898673
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24723248100569883
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4373208808310639
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222528-sx8tfxc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sx8tfxc7
wandb: uploading history steps 104-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇▇█
wandb: best/eval_avg_mil_loss █▆▁▁▂
wandb:  best/eval_ensemble_f1 ▁▄▇▇█
wandb:            eval/avg_f1 ▆▅▇▇█▄▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▅▅▅▂▂▁▄▅▅▅▅▅▅▅███▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅
wandb:       eval/ensemble_f1 ▆▆▆▆▅███▇▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▇▄▆▄▃▂▂▁▁▁▁▁▂▁▁▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂
wandb:      train/ensemble_f1 ██▇▆▅▄▃▂▂▂▂▂▂▁▁▁▂▁▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/mil_loss ▃▂▃▄▂▂▁▄▄▅▅█▄▄▄▆▄▆▄▅▅▆▆▂▃▄▅▄▅▇▅▄▆▅▃▂▅▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.41639
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.55587
wandb:      eval/avg_mil_loss 0.63819
wandb:       eval/ensemble_f1 0.55587
wandb:            test/avg_f1 0.75845
wandb:      test/avg_mil_loss 0.47337
wandb:       test/ensemble_f1 0.75845
wandb:           train/avg_f1 0.53992
wandb:      train/ensemble_f1 0.53992
wandb:         train/mil_loss 0.6069
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sx8tfxc7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222528-sx8tfxc7/logs
wandb: Agent Starting Run: e242sy4n with config:
wandb: 	actor_learning_rate: 0.0015229181965375148
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3351713292716575
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3897384295500108
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222640-e242sy4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e242sy4n
wandb: uploading history steps 155-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▄▆▃▅▆▅▅▄▁▆▂▅▇▅██▆▃▅▇▅▇▄▇▃▅▆▅▅▆▅▅▇▅▆▆█
wandb:      train/ensemble_f1 ▂▆▆▃▃▆▆▃▃▃▁▅▆▃▅▄▂▇▄▄█▃▂▅▅▄▇▆▃▇▆▅▄▅▄▄▇▄▆▇
wandb:         train/mil_loss ▆▆▅█▇▆▆▅█▄▆▇▅▆▄▆▅▆▂▃▁▇▆▄▅▃▃▆▄▆▆▃▆▆▃▅▇▆▆▄
wandb:      train/policy_loss ▄▁▃▃▃▄▄▂█▁▂▂▂▅▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▂▁▄▁▃▅▁█▁▂▁▁▁▁▁▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.24496
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.25381
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.17843
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.93249
wandb:      train/ensemble_f1 0.93249
wandb:         train/mil_loss 0.19867
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e242sy4n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222640-e242sy4n/logs
wandb: Agent Starting Run: 7eo2atpg with config:
wandb: 	actor_learning_rate: 3.634253369908836e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6732817799231177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8358935796753042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222824-7eo2atpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7eo2atpg
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▄▄▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄█▇▅▅▅▅▇▆▇▄▄▇▄▄▅▅▅▅▇▂▅▃▅▆▆▁▆▆▅▆▃▄▄▃▄▃▅
wandb:      train/ensemble_f1 ▄▄▄▇▃▅▃▁▆▄▄▅▄▆▇█▇▄▅▆▆▅▄▁▃▆▄▅▆▃▆▆▅▆▄▅▂▆▂▃
wandb:         train/mil_loss ▂▅▄▅▅▄█▄▇▆▄▅▃▅▃▃▄▃▂▃▃▁▃▄▅▂▃▄▂▂▄▃▄▄▄▁▃▃▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.25697
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.2634
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.15775
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.91874
wandb:      train/ensemble_f1 0.91874
wandb:         train/mil_loss 0.24144
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7eo2atpg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222824-7eo2atpg/logs
wandb: Agent Starting Run: 3hiu0h5f with config:
wandb: 	actor_learning_rate: 8.302739097581084e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6226974552457186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5537631900149692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_222931-3hiu0h5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hiu0h5f
wandb: uploading history steps 130-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▄▆▄▃▁▄▆▄▃▅▄▅▃▂▆▅▄█▆▆▅▃▄▆▆▄▃▅▆▆▂█▆▃▇▇▆
wandb:      train/ensemble_f1 ▃▄▃▃▄▂▄▃▃▄▅▃▄▆▆▆▄▅▃▄▂▇▂▆▅▇▆▇▅▅▅▅▅▇▁▅▅█▅▅
wandb:         train/mil_loss ▄▄▆▃▅▁▃▄▅▆▂█▃▂▄▄▇▅▄▃▃▄▅▁▅▄▅▂▆▅▅▄▄▄▄▇▄▆▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 1.59025
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 1.5445
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.00259
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.60949
wandb:      train/ensemble_f1 0.60949
wandb:         train/mil_loss 0.62262
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hiu0h5f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_222931-3hiu0h5f/logs
wandb: Agent Starting Run: 9n0ae3pb with config:
wandb: 	actor_learning_rate: 0.003864136805998892
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4742188000314145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6435944019852493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223104-9n0ae3pb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9n0ae3pb
wandb: uploading history steps 104-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅████████▅▅▅▂▂▂▂▂▂▄▂▂▁▂▂▂▂▂▂▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▆▆▇▆▆▅▅▄▄▃▂▂▆▆▆███▇▇▆▅▅▅▄▅▅▄▅▄▄▄▄▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅█████████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▆▂▄▆▆▂▄▆▅▄█▂▇▃▆▁▄▂▅▅▃▁▃▄▃▄▅▇▆▄▅█▇█▇█▃▅
wandb:      train/ensemble_f1 ▄▆▅▄▁▅▃▅▇▃▅▅▇█▆▄▁▄▄▁▁▅▃▁▃▅▁▇▆▇▇▆▃██▇▇▅▅▇
wandb:         train/mil_loss ▆▂▅▂▅▆▅▃▃▆▄▆▃▅▅▄▄▆▄▄▄▁▃▃▅▄▃█▃▁▂▃▃▅▄▇▃█▃▇
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████▁█████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57924
wandb: best/eval_avg_mil_loss 1.29301
wandb:  best/eval_ensemble_f1 0.57924
wandb:            eval/avg_f1 0.56342
wandb:      eval/avg_mil_loss 1.24207
wandb:       eval/ensemble_f1 0.56342
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 1.55744
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.54428
wandb:      train/ensemble_f1 0.54428
wandb:         train/mil_loss 0.50787
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9n0ae3pb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223104-9n0ae3pb/logs
wandb: Agent Starting Run: zsdv6tlz with config:
wandb: 	actor_learning_rate: 1.973685061562344e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4164585169254494
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14073100381665415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223217-zsdv6tlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zsdv6tlz
wandb: uploading history steps 155-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss ▄█▇▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▃▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▄▄▆▆▆███████████████▄▆
wandb:      eval/avg_mil_loss ▇▆▇▇█████▄▄▄▅▅▅▃▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄
wandb:       eval/ensemble_f1 ▃▃▃▃▃▁▁▁▁▁▃▃▃▃▆▆█████████████████▃▃▆▆▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▄▃▃▂▅▂▄▃▃▅▃▆▅▄▃▆▆▄▁▄▄▂▆▄▅▅▆█▇▆▅▅▅▅▄▄
wandb:      train/ensemble_f1 ▁▃▄▃▄▃▂▃▄▂▄▅▄▄▅▆▄▅▄▄▅▆▇▅▅█▅▅▇▅▄▆▃▆▅▅▆▆▇▄
wandb:         train/mil_loss ▂▇█▇▁▂▂▂▄▅▇▁▆█▂▅▃▃▃▂▂▄▅▃▆▃▁▇▃▂▃▃▃▄▂▄▅▃▃▂
wandb:      train/policy_loss █▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85949
wandb: best/eval_avg_mil_loss 0.37127
wandb:  best/eval_ensemble_f1 0.85949
wandb:            eval/avg_f1 0.83942
wandb:      eval/avg_mil_loss 0.37893
wandb:       eval/ensemble_f1 0.83942
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.16095
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.89249
wandb:      train/ensemble_f1 0.89249
wandb:         train/mil_loss 0.21191
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zsdv6tlz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223217-zsdv6tlz/logs
wandb: Agent Starting Run: 9kvt1v03 with config:
wandb: 	actor_learning_rate: 0.0001973431380441609
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3402270523976805
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0850147452433293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223405-9kvt1v03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kvt1v03
wandb: uploading history steps 181-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▇█
wandb: best/eval_avg_mil_loss █▇█▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▄▂▂▄▄▅▅▇▇▇▇▇████▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▇▇▇▇▇▇▅▆▆▅▅▅▅▅▅▅▅▅▅▆▄▄▄▄▄▄▃▃▃▁▁▁▁▁▁▃▄▄██
wandb:       eval/ensemble_f1 ▁▁▂▂▂▄▂▂▂▄▅▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▁▂▄▃▅▆▆▃▂▅▇▄▅▃▅▃▄▃▂▂█▄▅▆▆▇▆▆▅▅▇▅▆▇▇▄▇▄
wandb:      train/ensemble_f1 ▅▃▄▁▂▃▃▅▃▅▅▂▄▂▅▄▄▅▃▂▅▇▅▄▅▅▆▄▅▆▇█▅▄▆▆▇▆▄▄
wandb:         train/mil_loss ▇▄▃▅▆▃▃▅▅▅▄█▆▆▆▆▇▄▂▄▃▄▅▃▄▃▃▄▅▄▂▂▁▄▃▁▃▃▂▅
wandb:      train/policy_loss ▅▅▅▅▅▅▅█▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▁▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▇▆▃▄▄▄▄▄▄▄▄▄▃▃▂▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.21747
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.22838
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.90956
wandb:      test/avg_mil_loss 0.22529
wandb:       test/ensemble_f1 0.90956
wandb:           train/avg_f1 0.89984
wandb:      train/ensemble_f1 0.89984
wandb:         train/mil_loss 0.28873
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kvt1v03
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223405-9kvt1v03/logs
wandb: Agent Starting Run: hchdr417 with config:
wandb: 	actor_learning_rate: 0.00015906379732139424
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5375498415503029
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9180485563327688
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223609-hchdr417
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hchdr417
wandb: uploading history steps 77-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▃▃▄███▇▇▇▇▇▇▇▇▇▆▆▇▆▅▅▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▇▃▇▄▃▄▄▄▃▆▄▆▅▆▅▂▄▆▄▅▃▄▇█▃▅▆▇▇▇▆▇▆▄▅█▁
wandb:      train/ensemble_f1 ▆▆▇▆▆▆▇▅▅▆▅█▆▇▄▅▇▇▆▆▄▅▅▄▄▅▇█▅▇▃▁▅▇▇▇▆▇▆▃
wandb:         train/mil_loss ▄▄▅▆▅▅▅▄▅▃▅▆▄▅▄▃▄▅▆▄▄▄▃▆▅▁▅▅▂▅▄▃▅█▅▅▆▄▃▅
wandb:      train/policy_loss ▆▅▄▅▅▅█▇▇▅▅▄▅▅▂▁▅▅▇▆▄▇▄▄▅▅▃▆▅▄▄▁▅▄▆▆▄▂▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▆█▂▆▅▄▆▅█▇▂▅▁█▄▅▅▅▅▄▅▅▇▄▇▅▂▄▃▇▂▄▄▅▇▅█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.3731
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.37269
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.10621
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.88929
wandb:      train/ensemble_f1 0.88929
wandb:         train/mil_loss 0.2697
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hchdr417
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223609-hchdr417/logs
wandb: Agent Starting Run: ttkp7mu3 with config:
wandb: 	actor_learning_rate: 2.8013482175441685e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7756699682894136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7254903466109531
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223716-ttkp7mu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttkp7mu3
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▅▇▆▆▃▆▃▇▆▇▇▆▃▅▆█▇▅▆▂▅▅▆▄▃▇▆▂▅▆▂▆▃▄▆▂▁
wandb:      train/ensemble_f1 ▄▃▃▇▄▄▆▆█▄▆▆▇▆▂▄▃▅▆▆▆▃▃▆▄▆▁▄▅▆▆▅▆▂▄▄▆▅▃▇
wandb:         train/mil_loss ▂▆▂▂▁▄▄▃▂▄▄▄█▆▃▆▃▄▅▃▄▄▂▃▂▄▃▄▂▄▁▂▄▄▃▄▅▃▃▄
wandb:      train/policy_loss ▄█▅▆█▆▃▆▅▄▆▆█▆▆▄▅█▆▂█▁██▄▆▆▁▃▆▄██▄▁▅▆▆▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▅███▂▆▆▆▅▆▅▆▆▇▆▆▂█▂▃██▅▁▇█▆▅▆▆█▆▅█▆▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.40721
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.42118
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.13155
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.91277
wandb:      train/ensemble_f1 0.91277
wandb:         train/mil_loss 0.24964
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttkp7mu3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223716-ttkp7mu3/logs
wandb: Agent Starting Run: k8i3c0hr with config:
wandb: 	actor_learning_rate: 1.2998033090466112e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8640930938518285
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31700166620161097
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223823-k8i3c0hr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8i3c0hr
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▅▆▆▆▆▆▆▅▅▆▆▅▅▅▅▅▅▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▁▂▅▄▄▁▄▃▅▃▄▅▃▄▃▄▅▅▃▂▃▃▄▁▄▆▃▃█▄▄▄▂▆▆▇▇▃
wandb:      train/ensemble_f1 ▇▄▄▃▁▆▅▃▃▃▄▃▃▄▆▄▅▄▃▄▅▄▅▅▅▃▄▄▁▃█▆▄▅▃▅▅▁▆▆
wandb:         train/mil_loss ▅▄▆▅▄▇▆▁▅▃▃▁▄▃▁▁▃▄▄▁▄▃▁▁▁▁▁▅▃▃▆▁█▃▃▁▆▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.86299
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.79777
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 2.44354
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.34867
wandb:      train/ensemble_f1 0.34867
wandb:         train/mil_loss 0.46859
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8i3c0hr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223823-k8i3c0hr/logs
wandb: Agent Starting Run: vc2znb9n with config:
wandb: 	actor_learning_rate: 1.1013001695097988e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22537029816119203
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24669980839629
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_223931-vc2znb9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vc2znb9n
wandb: uploading history steps 155-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▇▆▅▄▄▅▇▄▅▅▄▆▁▆▆█▇▃▆▆▄▃▇▅▇▅▇▅▆▅▅▅▅▃▇▆▅
wandb:      train/ensemble_f1 ▅▆▄▂▅▆▁▇▃▄▄▄▃▃▆▅▅▅▅▃▄▆▄▄▄▃▃▆▃▆▃██▄▄▅▄▅▆▇
wandb:         train/mil_loss ▅▅▆▃▇▆▅▅▂▅▄▄▇▆█▅▄▅▄▄▅▅▁▁▇▃▂▄▇▅▆▄▄▃▄▃▆▅▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56342
wandb: best/eval_avg_mil_loss 1.55767
wandb:  best/eval_ensemble_f1 0.56342
wandb:            eval/avg_f1 0.56342
wandb:      eval/avg_mil_loss 1.5159
wandb:       eval/ensemble_f1 0.56342
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.75984
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.55902
wandb:      train/ensemble_f1 0.55902
wandb:         train/mil_loss 0.89525
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vc2znb9n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_223931-vc2znb9n/logs
wandb: Agent Starting Run: 7rsshu9g with config:
wandb: 	actor_learning_rate: 0.002093152961121561
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7826415976808084
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18584035362605467
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224109-7rsshu9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rsshu9g
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▂▆▅▃▆▆▆█▁▅▇▇▃▅▆▄▅▅▂▁▄▄▆▅▆▄▆▄▇▃▆▄▃▄▄▄▃
wandb:      train/ensemble_f1 ▂▄▃▄▃▃▅▅▇▄▄▆▆▅▄▄▁▅▂▄▄▃▄▃▄▄█▅▄▃▄▁▄▂▃▄▅▂▃▂
wandb:         train/mil_loss ▅▃▄▄▃▁▆▃▅▂▆▃█▄▃▆▃▂▁▄▂▄▄▃▃▂▁▄▄▃▅▂▅▂▅▁▅▅▃▆
wandb:      train/policy_loss ███████████████████████████▁████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▃▂▁▃▁▁▂▃▄▂▄▂▃▃▁▂▂▂▂▁▄▁▂█▆▅▆▅▆▆▅▅█▆▅▆██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.2694
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.29162
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.08577
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.91559
wandb:      train/ensemble_f1 0.91559
wandb:         train/mil_loss 0.22472
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rsshu9g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224109-7rsshu9g/logs
wandb: Agent Starting Run: lti72hbd with config:
wandb: 	actor_learning_rate: 2.916899256822292e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.018939887873474892
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14102828211823126
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224216-lti72hbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lti72hbd
wandb: uploading history steps 153-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss ▁███
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▄▄▄▄▄▃▁▁▁▁▃▃▃▃▃▃▃▃▃▅▆█████████▆▆▆▆▆▅▅▅▅▃
wandb:      eval/avg_mil_loss ▁▁▁▂▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▆███████████████
wandb:       eval/ensemble_f1 ▄▄▄▄▃▁▁▁▁▁▃▃▃▃▃▅▅███████▆▆▆▆▆▆▅▅▅▅▅▅▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▂▁▂▃▅▅▄▄▅▄▃▄▄▃▆▆▄▄▃▃▅▆▆▄▅▅▅▃▆▅█▅▄▃▄▆▇█
wandb:      train/ensemble_f1 ▃▁▂▂▂▅▆▅▄▃▄▅▆▃▄▄▃▆▁▅▃▄▃▅▆▆▆▆▄▅▄▄▄▄▇▅▅▅▆█
wandb:         train/mil_loss ▄▄▄▅▄▅▅▃▄▅▅█▄▅▅▃▃▄▅▃▆▃▃▄▅▄▁▃▄▃▃▂▄▂▄▁▅▄▂▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▆▆▆▆█▇██▆▆▆▆▆▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▁▂▁▁▂▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.30296
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.85994
wandb:      eval/avg_mil_loss 0.32823
wandb:       eval/ensemble_f1 0.85994
wandb:            test/avg_f1 0.85949
wandb:      test/avg_mil_loss 0.26436
wandb:       test/ensemble_f1 0.85949
wandb:           train/avg_f1 0.85609
wandb:      train/ensemble_f1 0.85609
wandb:         train/mil_loss 0.27417
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lti72hbd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224216-lti72hbd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: j1qj134b with config:
wandb: 	actor_learning_rate: 2.2011093846478856e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3396831404095013
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5020177379219057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224543-j1qj134b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j1qj134b
wandb: uploading history steps 79-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▇▅▄▄▄▄▄▅▁▁▃▄▂▃▃▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇███
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▁▅▇▅▄▅▁▅▆▄▄▆▁▅▄▄▆▄▇█▃▂▇▆▆▇▅▅█▇▇▅▆▆▃█▅▄
wandb:      train/ensemble_f1 ▃▄▅▃▆▁▇▄▂▅▄▅▃▄▃▁▅▂▃▅▃▃▅▄▅▄▄▇▃▅▃█▄▄▂▄▁▄▅▅
wandb:         train/mil_loss ▃▄▃▆▂▅▃▄▆▅▆▅▃▄▃▄▄▃▁▁▄▂▃▅▄▃▃▄▂▅▂▃▁█▃▄▄▃▂▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▅▅▄▄█▃▃▄▅▄▆▅▁▂▂▄▅█▁██▅▃▅▆▄▇▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.28623
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.28749
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.12577
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.9075
wandb:      train/ensemble_f1 0.9075
wandb:         train/mil_loss 0.19811
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j1qj134b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224543-j1qj134b/logs
wandb: Agent Starting Run: 6s0ehyr3 with config:
wandb: 	actor_learning_rate: 3.9170545733778954e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.987207448718413
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35706703551278984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224649-6s0ehyr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s0ehyr3
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▆▆▆▆▆████▇▇▆▅▅▅▅▅▅▁▁
wandb:       eval/ensemble_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▄▃▂▁▃▄▅▄▃▄▆▃▃▅▅▆▄▄▄▃▅▂▅▅▅▇▅▆▃▆▆█▅█▇▆▅
wandb:      train/ensemble_f1 ▄▅▄▃▃▄▁▂▄▁▄▅▃▄▅▆▃▃▅▅▄▄▅▅▆▆▇▆▆▄▆▆▇█▆▇▇▅▅▆
wandb:         train/mil_loss ▂▂▁▂▂▃▃▄▂▃▃▃█▃▂▂▂▇▆▂▃▂▃▁▁▃▃▁▃▂▄▆▂▂▂▄▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60114
wandb: best/eval_avg_mil_loss 1.13516
wandb:  best/eval_ensemble_f1 0.60114
wandb:            eval/avg_f1 0.59294
wandb:      eval/avg_mil_loss 1.0838
wandb:       eval/ensemble_f1 0.59294
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 1.33243
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.64152
wandb:      train/ensemble_f1 0.64152
wandb:         train/mil_loss 0.22442
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s0ehyr3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224649-6s0ehyr3/logs
wandb: Agent Starting Run: 3h9mbw6e with config:
wandb: 	actor_learning_rate: 1.2777274808822625e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7548513991256365
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3595651713993714
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224757-3h9mbw6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3h9mbw6e
wandb: uploading history steps 128-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅█▅▆▅▇▃▃▅▄▆▆▂▅▃▅▃█▅▃▃▅▃▃▄▄▅▄▅▁▅▃▅▃▂▂▄▄▃
wandb:      train/ensemble_f1 ▄▂▃▃▅▁▄█▄▄▆▄▆▆▇▆▄▆▄▅▆▃▃▂▄▄▅▄▂▆▆▅▃▄▆▆▁▄▆▄
wandb:         train/mil_loss ▄▄▆▆▂▇▄▃▄▅▄▂▅▄▃▆▄▆▆▄▇█▃▅▄▄▆▁▄▆▃▆▅▅▇▅▃▃▆▂
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.33856
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.35082
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.1298
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.89474
wandb:      train/ensemble_f1 0.89474
wandb:         train/mil_loss 0.2047
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3h9mbw6e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224757-3h9mbw6e/logs
wandb: Agent Starting Run: 7ceuy06h with config:
wandb: 	actor_learning_rate: 7.089638592406508e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5212773437803606
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9948529143870752
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_224929-7ceuy06h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ceuy06h
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:      eval/avg_mil_loss ▂▂▁▁▄▅▁▁▁▁▁█▄▅▄▄▄▄▄▄▄▄▄▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▃▄▅▅▁▃▄▄▆▂▆▄▆▆▃▁▅▄▇▄█▆▇▄█▄▇▆▆▄▆▅▃▇▆▅▅
wandb:      train/ensemble_f1 ▄▄▁▂▄▃▅▅▃▅▄▃▅▄▆▅▇▆▅▄▅█▄▄▇▆▇▆▇▄▇▅▇▆▅▇▅▇▆▆
wandb:         train/mil_loss ▃▆▂▄▅▆▂▄▇▄▂█▇▄▃▆▄▅▄▃▄▁▄▄▂▁▅▁▂▂▆▄▆▅█▅▂▂▅▄
wandb:      train/policy_loss ▆▅▅▆▅▆▁▆▃▆▄▂▅▃▆▆▄█▆▆▆▃▆█▆▄▄▄▃▄█▆█▆▆▆█▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▃▄▃▄▅▃▅▆▃▃▅▃▆▂▃▂▂▇▄▂▄▃▃▃▃▃▁▄█▆▅▄▄▂▆▇▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86999
wandb: best/eval_avg_mil_loss 0.32468
wandb:  best/eval_ensemble_f1 0.86999
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.32867
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.17626
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.89759
wandb:      train/ensemble_f1 0.89759
wandb:         train/mil_loss 0.21389
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ceuy06h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_224929-7ceuy06h/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4kmi71xo with config:
wandb: 	actor_learning_rate: 2.8543678230718303e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9805250749697612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9124774993329235
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_225057-4kmi71xo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/em95c2f6
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4kmi71xo
wandb: uploading history steps 78-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▅▅█▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ██████████▅▅▅▅▅█▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇█▅▃▇▆▄▂█▆▇▆▇▆▁▃▇▆▃▇▆▄▃▄▆▄█▆▅▅▆▁▆▅▅▄▃▅
wandb:      train/ensemble_f1 ▃▆▅▆▃▄▆▄▆▄▅█▂▆▁▆▅▅▄▄▃▃▃▅▅▄▅▄▁▃▃▆▄▄▅▄▅▄▅▃
wandb:         train/mil_loss ▅▆▃▆▄▅▅▃▄▅▅▂▄▄▇▄▃▆▃▆▄▃▆▃▇▃█▃▄▆▄▆▅▆▄▃▃▄▂▁
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅█▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.29134
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.33026
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.0996
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.90674
wandb:      train/ensemble_f1 0.90674
wandb:         train/mil_loss 0.26602
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4kmi71xo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_225057-4kmi71xo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
