wandb: Agent Starting Run: nvg02vk4 with config:
wandb: 	actor_learning_rate: 0.00047045252144145366
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4636207075467834
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6714661362872967
wandb: Agent Starting Run: c5siz7x7 with config:
wandb: 	actor_learning_rate: 7.019223960144275e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8490203621009447
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5577619859003348
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Agent Starting Run: ilwyscwu with config:
wandb: 	actor_learning_rate: 0.0005050929643752785
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16755552269644358
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07545636872079209
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-c5siz7x7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5siz7x7
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-nvg02vk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nvg02vk4
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-ilwyscwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilwyscwu
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: ERROR Error while calling W&B API: Invalid sweep config: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.52.127.3:43336->10.55.247.53:80: read: connection reset by peer (<Response [400]>)
wandb: ERROR Invalid sweep config: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.52.127.3:43336->10.55.247.53:80: read: connection reset by peer
Traceback (most recent call last):
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/lib/retry.py", line 134, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 398, in execute
    return self.client.execute(*args, **kwargs)  # type: ignore
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/lib/gql_request.py", line 59, in execute
    request.raise_for_status()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/run_rlmil.py", line 716, in <module>
    sweep_id = wandb.sweep(args.sweep_config, entity=args.wandb_entity, project=args.wandb_project)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/wandb_sweep.py", line 86, in sweep
    sweep_id, warnings = api.upsert_sweep(sweep, prior_runs=prior_runs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/apis/internal.py", line 137, in upsert_sweep
    return self.api.upsert_sweep(*args, **kwargs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/apis/normalize.py", line 65, in wrapper
    raise err
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 3391, in upsert_sweep
    raise e
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 3385, in upsert_sweep
    response = self.gql(
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 370, in gql
    ret = self._retry_gql(
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/sdk/lib/retry.py", line 150, in __call__
    retry_timedelta_triggered = check_retry_fn(e)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/util.py", line 867, in no_retry_4xx
    raise UsageError(body["errors"][0]["message"])
wandb.errors.errors.UsageError: Invalid sweep config: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.52.127.3:43336->10.55.247.53:80: read: connection reset by peer
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▁▆▄▅▅▅▆▆▇▄▅▇▄▅▅█▄█▇▆▅▃▄▅▆▅▆▆▆█▅▆▄▆▅▄▆
wandb:      train/ensemble_f1 ▁█▁▂▅▃▃▂▅▇▃▃▂▆▄▂▆▅▇▆▃█▄▅▄▄▃▆▆▅▃▂▂▃▅▅▅▅▅▅
wandb:         train/mil_loss ▃▅▅▄▄▄▄▁▂▅▄▄▆█▃▆▃▇▆▄▄▄▅▃▆▆▆▅▃▃▄▄▂▃▅▄▆▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.27838
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.26591
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.23807
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.90496
wandb:      train/ensemble_f1 0.90496
wandb:         train/mil_loss 0.26165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilwyscwu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-ilwyscwu/logs
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▅▁▂▃▂▄▄▄▇▄▃▂▃▅▁▃▃▄▅▃▄▅▇▃▄▅▅▇▅█▇▆▆▇▄▇▄
wandb:      train/ensemble_f1 ▃▅▆▄▄▅▄▃▄▁▁▃▄▃▃▄▆▃▃▅▃▇▂▆▅▄▄▆▃▅▇█▅█▅█▆▅█▇
wandb:         train/mil_loss ▆▅▇▆▆▂▆▆▁▅▄▆▇▅▇▇▆▄▃▆▆▃▅▄▅▅▆▄▆▃▅▄▄▄▃▆▆▅██
wandb:      train/policy_loss ▂▅▄▄▃▅▄█▂▃█▃▅▄▃▂▄▃▄▄▆▂▃█▆▄▁▄▄▅▅▂▆▄▃▁▄▃▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▂▃▅▃▄▅▅█▂█▅▃▃▃▄▅▅▄▂▆▄▃▃█▄▅▄█▅▇▅▂▂▃▂▃▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 5.41637
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.1664
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 6.21535
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34044
wandb:      train/ensemble_f1 0.34044
wandb:         train/mil_loss 2.26375
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nvg02vk4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-nvg02vk4/logs
wandb: Agent Starting Run: 4ombshpd with config:
wandb: 	actor_learning_rate: 3.403192340919118e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5983838593282456
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.706583054140564
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁████
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇█████
wandb:       eval/ensemble_f1 █████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▅▆█▅▆▄▇▂▆▄▃▄▃▃▅▆▆▆▆▅▆▄▇█▆▆▇▃▄▄▄▅▁▄▆▅▅
wandb:      train/ensemble_f1 ▇▆▄▅▅▇▅▄▇▃▄▄▇▄▅▃▆▆▇▅▅▁▅▆▅█▆▅▆▇▅▅▅▅▅▄▄▇▆▆
wandb:         train/mil_loss ▅▅▆▇█▄▃▇▂▇▂▅█▃▇▅▆▄▇▅▄▆▂▃▅▅▅▆█▇▁▅▃▂▆▅▃▁▄▅
wandb:      train/policy_loss ████████████████████████████████████▁███
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████▆█████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.26497
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.2863
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.11412
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.89737
wandb:      train/ensemble_f1 0.89737
wandb:         train/mil_loss 0.24548
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c5siz7x7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-c5siz7x7/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182233-4ombshpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ombshpd
wandb: Agent Starting Run: sww5gajw with config:
wandb: 	actor_learning_rate: 0.00017185275926193054
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5434743948978952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04129226738003522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182236-sww5gajw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sww5gajw
wandb: Agent Starting Run: sqk27nhp with config:
wandb: 	actor_learning_rate: 0.009259557581269574
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4136007450357021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2546473727748053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182238-sqk27nhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sqk27nhp
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇████████▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▄▁█▇▅▄▅▅▂▆▅▁█▆▇▇▇▄▆▂▅▆▆▇▇█▁▅▅▅▅▄▁▅▄▅▅▇
wandb:      train/ensemble_f1 ▃▇█▆▆▃▄▃▄▄▅▃▅▄▅▂▁▇▅▇▂▆▆▅▂▅█▆▆▆▇▅▅▅▆█▅▄▄▄
wandb:         train/mil_loss ▂▄▇▄▅▄▂▆▆▂█▅▃▁▄▃█▄▅▁▅▆▅▇▁▅▅▄▃▂▃▃▂▅▄▇▅▅▇▄
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▂▄▅▃▂▄▄▄▅▄▁▅█▅▅▅▅▇▂▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.26855
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.27708
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.93799
wandb:      test/avg_mil_loss 0.2501
wandb:       test/ensemble_f1 0.93799
wandb:           train/avg_f1 0.89938
wandb:      train/ensemble_f1 0.89938
wandb:         train/mil_loss 0.29156
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sww5gajw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182236-sww5gajw/logs
wandb: Agent Starting Run: q8bkf433 with config:
wandb: 	actor_learning_rate: 0.00013458424817427514
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5592916532181524
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07524116209660303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182419-q8bkf433
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8bkf433
wandb: uploading history steps 129-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▆█▆▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▃▃▆▆█████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▇▇▇▇█▃▃▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▆▆██████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▆▂▅▃▄▅▃▆▄█▅▇▄▅▆▃▄▄▇▅▂▅▄▃▇▅▅▄▃▅▆▁▅▃▃▇▄
wandb:      train/ensemble_f1 ▅▂▁▂▇▃▆▂▂▄▇▁▃▅▇▄▅▃▁▄▆▅▂▅▇▃▄▅▃▄▇▃█▂▆▄▃▆▂▃
wandb:         train/mil_loss ▃▃▅▆▃▄▅▃▄▄▆▃▇▄▃▂▅▄▃▄▃▅▄▄▃▅▇▁▄▄▄▄▆▅▄▄█▇▄▅
wandb:      train/policy_loss ▇▆█▇▇▃▇▁▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87981
wandb: best/eval_avg_mil_loss 0.28232
wandb:  best/eval_ensemble_f1 0.87981
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.2808
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.15981
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.89189
wandb:      train/ensemble_f1 0.89189
wandb:         train/mil_loss 0.25283
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ombshpd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182233-4ombshpd/logs
wandb: Agent Starting Run: 6n31y9wu with config:
wandb: 	actor_learning_rate: 0.00979587731157785
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4166706466174023
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2713240917792056
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182443-6n31y9wu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6n31y9wu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:      eval/avg_mil_loss ▂▂▂▂▁▁▁▄▇███▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▆▅▄▇▆▅▁▅▆▄▇▆▆▄▅▇▅▄█▄▇▆▄▇▆▄▄▆▇▅▅▆▅▆▆▄▆▅
wandb:      train/ensemble_f1 ▅▅▆▆▇▂▄▄▆▇▆▁▄▄▆▅▆▃█▅▄▇▄▃▇▅▅▄▄▆▇▇▄▅▆▇▃▆▇▅
wandb:         train/mil_loss ▅▄▅▃▃▁▆▆▄▄▇▄▅▄▅▆▆▅█▇▇▄▆▆▅▅▅▃▇▅▅▆▄▅▄▄▄▂▅▆
wandb:      train/policy_loss ▃▃▃▃▃▃▆▄▇▂▄▆▆▄▇▁▇▄▇▄▂▂▆▅▆▂▄▅▄▇▅▄▄▇█▅▄▅▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▄▄▅▃▇▂▅▅▄▂▄▁▇▃▄▂▂▆█▃▂▄▄▅▇▄▄▄▃█▃▅▅▂▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.2786
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.27422
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11039
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.91449
wandb:      train/ensemble_f1 0.91449
wandb:         train/mil_loss 0.28085
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6n31y9wu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182443-6n31y9wu/logs
wandb: Agent Starting Run: q9u8mz0o with config:
wandb: 	actor_learning_rate: 0.0005517938465979201
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10596652598730172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04787227166365138
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182641-q9u8mz0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q9u8mz0o
wandb: uploading history steps 252-268, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▅▅▅▅▄▄▅▅▄▄▄▄▃▃▃▃▂▃▃▃▃▂▃▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▄▄▆▅▆▅▆▅▄▄▅▆▆▄▆▅▇▅▅█▄▆▆▄▇▁▃▂▃▄▅▆▃█▇▆▅
wandb:      train/ensemble_f1 ▃▁▄▅▆▆▆▆▂▅▄▅▅▄▄▅▇▅▄▅▇▆▅▆▃█▅▃▅▇▆▄▆▅▅▄▆█▄▃
wandb:         train/mil_loss ▄▆█▅▄▅▄▄█▆▆▇▃▄▆▄▅▅▅▅▄▆▃▁▂▄▄▂▅▄▃▇▄▃▄▅▂▂▃▁
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▄▃▄▄▆▄▇▅▄▄▅▆▆▅▅▅▇▄▄▃▂▃█▃▅▁▆▆█▅▂▄▇█▇▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.24788
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.23996
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.12174
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.92
wandb:      train/ensemble_f1 0.92
wandb:         train/mil_loss 0.21598
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sqk27nhp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182238-sqk27nhp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9t34ekzn with config:
wandb: 	actor_learning_rate: 1.704242867205448e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5390438834980553
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5390828702642653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182715-9t34ekzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9t34ekzn
wandb: uploading history steps 208-213, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▆▄▄▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▃▃▃▃▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇█████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▄▅▄▅▄▅▅▅▆▅▄▄▅▄▄▆▆▆▆▆▇▅▆▅▇▇▇▆██▇█▇▆█▇▅█
wandb:      train/ensemble_f1 ▃▃▁▄▆▃▃▃▁▃▄▄▃▅▄▄▅▃▃▆▇▆▅▅▄▆█▅▄▅▆▅▄▇▆▅▄▆▅█
wandb:         train/mil_loss ▃▅█▅▄▃▂▃▂▃▂▁▂▂▂▂▂▂▃▂▁▂▁▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.46356
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.81818
wandb:      eval/avg_mil_loss 0.40439
wandb:       eval/ensemble_f1 0.81818
wandb:            test/avg_f1 0.80998
wandb:      test/avg_mil_loss 0.709
wandb:       test/ensemble_f1 0.80998
wandb:           train/avg_f1 0.82062
wandb:      train/ensemble_f1 0.82062
wandb:         train/mil_loss 0.39579
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8bkf433
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182419-q8bkf433/logs
wandb: Agent Starting Run: 1evp4v2x with config:
wandb: 	actor_learning_rate: 0.0002365228885020095
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8992444509317942
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0018222122179009093
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182745-1evp4v2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1evp4v2x
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▄████▅▅▅▅▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▆▅▅▅▅▅▅▅▃▃▃▃▂▂▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁█▆▆▆▆▆▆▃▃▃▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▁▂▂▄▄▃▃▂▄▅▅▄▆▅▆▅▅▅▇▅▇▄▃▆▆▅█▅█▆▇█▇▇▇▇
wandb:      train/ensemble_f1 ▂▃▂▁▂▂▃▄▃▅▅▅▄▄▄▆▅▆▆▆▅▅▅▆▆▆▆▆▆▆█▆▇██▇▇▅▇▇
wandb:         train/mil_loss ▆█▄▄▆▆▄▆▄▅▄▅▂▃▂▄▃▃▃▃▃▂▄▃▂▃▃▂▄▂▃▂▂▂▃▃▂▂▁▁
wandb:      train/policy_loss █▆▅▁▅▅▅▅▅▅▅▅▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.33393
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.88999
wandb:      eval/avg_mil_loss 0.2622
wandb:       eval/ensemble_f1 0.88999
wandb:            test/avg_f1 0.86936
wandb:      test/avg_mil_loss 0.40675
wandb:       test/ensemble_f1 0.86936
wandb:           train/avg_f1 0.90735
wandb:      train/ensemble_f1 0.90735
wandb:         train/mil_loss 0.27155
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q9u8mz0o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182641-q9u8mz0o/logs
wandb: Agent Starting Run: jdudz0jn with config:
wandb: 	actor_learning_rate: 0.0003713658853829334
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.029536321683237055
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02121670078563276
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182826-jdudz0jn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdudz0jn
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▅▅▅▅▅▅▁▁██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ██▇▇▇▅▆▆▆▅▄▄▄▄▅▅▁▅▅▇▆▆▆▅▅▅▅▅▅▅▄▃▃▃▃▃▃▃▃▄
wandb:       eval/ensemble_f1 █▅▅▅▅▅▅▅▅▅▅▁██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▁▆▄▇▂▅▅▆▇▆▇▆▅▄▇▆▄▇▆▃▅▆▆▇▄█▆▂▆▅▄▇▄▅▇▆▆▃
wandb:      train/ensemble_f1 ▅▅▅▄▅▅▅▆▄▄▄▅▆▅▆▆▅▃▅▅▆▄▆█▅▃▂▅▅▄▆▄▅▄▆▄▄▁▃▅
wandb:         train/mil_loss ▁▅▄▃▂▅▄▆▁▅▂▃▁▄▅▂▅▅█▃▆▄▃▂▂▅▂▅▃▃▂▂▄▄▆▂▄▅▃▅
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.27829
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.26539
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.29124
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.89854
wandb:      train/ensemble_f1 0.89854
wandb:         train/mil_loss 0.30153
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1evp4v2x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182745-1evp4v2x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bocbam0t with config:
wandb: 	actor_learning_rate: 1.3151143869349104e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8265657213730148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013594263318400523
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182937-bocbam0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bocbam0t
wandb: uploading history steps 141-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▁▁▁▁▁▅▅███████████████▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▁▁▁▁▁▅▅▅▅█████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▂▃▃▁▅▄▃▃▄▃█▇▅▆▇▃▅▂▂▄▆▃▄▇▅▅▅▃▅▄▆▅▅▄▅▃▄
wandb:      train/ensemble_f1 ▂▃▁▁▄▅▅▃▃▁▃█▆▅▅▅▃▂▂▅▂▆▄▆█▂▅▅▅▆▂▃▆▄▂▃▇▅▃▃
wandb:         train/mil_loss █▃█▇▇▇▄▃▆▄█▆▅▄▇▇▄▄▂▁▅▇▅▅▆▄▆▄▄▅▆▄▆▃▃▅▆▄█▂
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.23078
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.24095
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94939
wandb:      test/avg_mil_loss 0.25874
wandb:       test/ensemble_f1 0.94939
wandb:           train/avg_f1 0.91738
wandb:      train/ensemble_f1 0.91738
wandb:         train/mil_loss 0.20613
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9t34ekzn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182715-9t34ekzn/logs
wandb: Agent Starting Run: 6ix5attj with config:
wandb: 	actor_learning_rate: 0.002961581887885622
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9443786602903856
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13490341635541692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182951-6ix5attj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ix5attj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████████████▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:       eval/ensemble_f1 █████████████████████████████████████▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▁▆▆▄▄▃▄▆▇▅▄▃▃▄▇▅▆▆▅▆▄▆▆▆▅▅▄█▆▆▇▅▇▇▃▅▇
wandb:      train/ensemble_f1 ▅▃▁▃▄▃▅▃▅▅▅▄▃▄▇▅▅▆▆▄▆▄▇▄▆▃▅█▅▄▆▅▇▃▇▃▇█▅▇
wandb:         train/mil_loss ▂▅▁▂▄▄▃▃▇▅▃▃▃▄▄▃▂▃▃▄▁▃▃▃▁▅█▆▅▄▂▁▃▄▄▅▄▂▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86988
wandb: best/eval_avg_mil_loss 0.24487
wandb:  best/eval_ensemble_f1 0.86988
wandb:            eval/avg_f1 0.85978
wandb:      eval/avg_mil_loss 0.24995
wandb:       eval/ensemble_f1 0.85978
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.31476
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.90875
wandb:      train/ensemble_f1 0.90875
wandb:         train/mil_loss 0.2604
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdudz0jn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182826-jdudz0jn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vhe407vm with config:
wandb: 	actor_learning_rate: 0.00016415871693836433
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0855396755662049
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04517046749050324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183014-vhe407vm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhe407vm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████
wandb:      eval/avg_mil_loss ▅▇▄▄▄██▇▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▁▁▃▃▁▁▂▂▁▁▂▃▂▂▂▂▂▂▃▂▂▃▂▃▃▃▃▃▃▃▂▃▃▃▃▃▄▃
wandb:      train/ensemble_f1 ▁▂▅▆▅▂▃▂▃▃▃▂▃▃▄▃▃▄▂▃▂▃▅▄▄▅▆▆▆▆▂▄█▆▇▂▄▄▆▅
wandb:         train/mil_loss ▃▃▂▃▃▄▄▁▇▅▂▆▂▅▃▄▅▃▃█▁▅▃▆▃▂▁▂▃▇▃▅▂▃▄▅▄▄█▂
wandb:      train/policy_loss █▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 1.62496
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 2.35282
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 2.18206
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.38207
wandb:      train/ensemble_f1 0.38207
wandb:         train/mil_loss 0.24011
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ix5attj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182951-6ix5attj/logs
wandb: Agent Starting Run: isegzeg2 with config:
wandb: 	actor_learning_rate: 3.172450522527415e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7095374322896598
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4985900939008332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183134-isegzeg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/isegzeg2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅█████████████████████▅▅▅▅▅▂▂▂
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▅▅▅▅███████████████████▅▅▅▅▅▅▅▅▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▂▂▆▁▄▂▃▅▄▅▄▆▄▆▆▅▆▄▄▃▅▂▆▆▅▄▆▆▆▃▇▇▅█▅▇▇
wandb:      train/ensemble_f1 ▅▄▂▄▂▆▁▂▅▂▄▄▄▅▄▇▄▆▄█▇▄▇▆▅▄▇▄█▆▅▆▅█▇▆▅▆▇▆
wandb:         train/mil_loss ▂▇▇▅▃▃▇▂▄▃▄▃▅▃▄█▄▂▇▄▄▅▆▅▆▄▃▁▂▃▂▃▃▃▃▂▅▁▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▁▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66933
wandb: best/eval_avg_mil_loss 1.50375
wandb:  best/eval_ensemble_f1 0.66933
wandb:            eval/avg_f1 0.648
wandb:      eval/avg_mil_loss 1.38681
wandb:       eval/ensemble_f1 0.648
wandb:            test/avg_f1 0.68467
wandb:      test/avg_mil_loss 1.46107
wandb:       test/ensemble_f1 0.68467
wandb:           train/avg_f1 0.71986
wandb:      train/ensemble_f1 0.71986
wandb:         train/mil_loss 0.31649
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bocbam0t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182937-bocbam0t/logs
wandb: Agent Starting Run: 3dzey3c6 with config:
wandb: 	actor_learning_rate: 0.0020105550166637618
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8404236488291682
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.004015851304791984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183147-3dzey3c6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dzey3c6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▅█▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▇▄▂▅▄▄▃▄▃▄▃▃▄▃▁▅▂▁▅▃▄▄▄▇▄▃▆▃▄▄▄▃▄▅▅█▅▄
wandb:      train/ensemble_f1 ▁▇▄▆▂▄▄▄▄▃▃▃▂▃▄▃▂▁▄▆█▂▃▄▄▃▄▃▃▃▃▃▂▅▄▇▂▅▂▄
wandb:         train/mil_loss ▅▆▆▄▇█▆▅▅▆▆▄▇▃█▇▂▇▃▃▆▆▄▆▃▄▄▃▃▃▄▄▆▃▆▂▂▁▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 2.41845
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 2.28391
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.85894
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.53468
wandb:      train/ensemble_f1 0.53468
wandb:         train/mil_loss 1.64521
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhe407vm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183014-vhe407vm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pil0dq7q with config:
wandb: 	actor_learning_rate: 0.002286026575782111
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4469599488745035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3281745563396905
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183203-pil0dq7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pil0dq7q
wandb: uploading history steps 96-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁██████████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▄▅▅▂▃▃▄▅▅▅▆▆▆▆▆▇███▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▃▃▃▄▄▆▄▅▃▆▄▁▂▆▂▃▂▅▇▅▇▇▆▃▄▇▁▅▅▃█▅▄▅▅▄▃
wandb:      train/ensemble_f1 ▄█▅▃▂▅▆▇▇▅▄▆▄▁▆▅▆▆▄▂▅▅▂▅▆▃▅█▄▇▃▃▄▄▅▅▅█▅▅
wandb:         train/mil_loss ▄▇▆██▄▆▆▆▃█▃▇▅▂█▃▆▄▇▄▅▃▅▄▂▄▃▆▆▃▆▄▃▄▆▃▄▁▃
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.30163
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.31661
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.147
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.88105
wandb:      train/ensemble_f1 0.88105
wandb:         train/mil_loss 0.22728
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/isegzeg2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183134-isegzeg2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1wvpprsw with config:
wandb: 	actor_learning_rate: 0.009464177537116416
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1448173524087496
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3692475691378494
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁▁█▁███████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▃▄▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:       eval/ensemble_f1 ▁▁▁███▁█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆██▃▆▇▅▁▇▄▅▄▅▄▁▄▄▂▄▃▂▄▄▁▅▆▄▃▃▄▄▅▅▄▂▇▃▄▅
wandb:      train/ensemble_f1 █▇▇█▃▇█▆▇▆▅▅▃▄▃▃▁▃▄▂▂▄▃▅▁▂▁▅▄▆▅▂▆▄▃▅▅▄▇▁
wandb:         train/mil_loss ▄▂▅▅▄▄▇▃█▄▅▄▃▅▄▅▅▅▄▇▂▆▃▃▂▃▄▃▄▄▄▂▅▁▆▅▃▇▅▆
wandb:      train/policy_loss ▂███████▄▄▃▇▁▂▆▃▂▂▄▅▆▂▃▄▃▁▄▄▅▁▆▁▄▁▁▃▃▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87995
wandb: best/eval_avg_mil_loss 0.23245
wandb:  best/eval_ensemble_f1 0.87995
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.27855
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.48399
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.8909
wandb:      train/ensemble_f1 0.8909
wandb:         train/mil_loss 0.28991
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dzey3c6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183147-3dzey3c6/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183339-1wvpprsw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1wvpprsw
wandb: Agent Starting Run: m7wi98tp with config:
wandb: 	actor_learning_rate: 0.0006438951289223016
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6961576752192097
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.032733402506014087
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183341-m7wi98tp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m7wi98tp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇█
wandb: best/eval_avg_mil_loss █▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▄▆▇█
wandb:            eval/avg_f1 ▁▁▄▆████████████████████████████████████
wandb:      eval/avg_mil_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▅▅▇▅▆▆▆▇▇▄▅▅▆▅▅▆▅▅▅▇▆▅▆▆▇▅▆▆▅█▆▆▆▆▇▇▆▆
wandb:      train/ensemble_f1 ▁▅▅▆▆▆▇▇▆▆▇▇▆▆▆▆▇█▆▆█▆▆▅▆▅▇▆▇▆▇▆█▇▇█▆▇▇▆
wandb:         train/mil_loss █▅▃▆▃▃▆▄▂▆▄▄▄▃▄▄▄▄▅▆▄▃▃▄▄▄▄▄▄▁▅▃▅▂▅▅▄▅▄▃
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.26687
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.26981
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.46468
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.8849
wandb:      train/ensemble_f1 0.8849
wandb:         train/mil_loss 0.25436
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pil0dq7q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183203-pil0dq7q/logs
wandb: Agent Starting Run: lh5ezj7v with config:
wandb: 	actor_learning_rate: 0.008217211389133115
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7043015432503503
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26545246985328497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183347-lh5ezj7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh5ezj7v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▃▃▃▂▂▁▁▆▆▆▆▇▇██▂▂▂▂▂▂▂▂▃▅▃▃▃▃▃▃▃▃▃▅▃▃▃▃
wandb:       eval/ensemble_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▅▆▅▄▆▃▅▆▂▄▁▆▄▇▇▂▆▅▆▃▆█▆▇▆▅▅█▅▅▃▅█▄█▆▅
wandb:      train/ensemble_f1 ▁▂▄▅▄▅▃▃▆▆▅▃▇▆▅▅▃▇▂▅▆▄▅▅█▇▆▇▆▆▅▄▃▅▄▅▆▅▇▇
wandb:         train/mil_loss █▅▃▂▄▃▅▅▅▆▃▇▄▂▄▃▅▁▃▇▄▃▃▆▄▁▁▄▆▅▄▅▄▁▄▇▅▄▆▄
wandb:      train/policy_loss ▇▇█▇██▇▇▇▂▂▂▃▂▂▂▂▂▁▃▂▂▁▂▂▂▁▂▂▃▃▂▂▂▂▃▃▁▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▇▇███▇▂▂▃▂▃▃▂▁▂▂▂▂▁▂▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▂▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93998
wandb: best/eval_avg_mil_loss 0.16427
wandb:  best/eval_ensemble_f1 0.93998
wandb:            eval/avg_f1 0.92994
wandb:      eval/avg_mil_loss 0.16231
wandb:       eval/ensemble_f1 0.92994
wandb:            test/avg_f1 0.93912
wandb:      test/avg_mil_loss 0.13131
wandb:       test/ensemble_f1 0.93912
wandb:           train/avg_f1 0.91234
wandb:      train/ensemble_f1 0.91234
wandb:         train/mil_loss 0.23725
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1wvpprsw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183339-1wvpprsw/logs
wandb: Agent Starting Run: 2n1nwjj0 with config:
wandb: 	actor_learning_rate: 1.7064128979530623e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7385651729141035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8914798399789822
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183522-2n1nwjj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2n1nwjj0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▇▇█████▇▇▆▆▅▆▅▆▆▆▆▅▄▄▃▅▄▄▄▃▄▃▃▃▁▁▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▄▂▆▅▅▄▄▅▄▅▅▃▆▆▅▅▅▅▇▅▅▅▁▅▆▅▆▆▄▇▅▆▄▇▅▄▄█
wandb:      train/ensemble_f1 ▆▂▄▄▄▅▅▇▅▆▄▇▅▆▆▂▅█▆▁█▄▆▇▅▆▇▆▇▅▆▄▅▆█▃▆▆▂▂
wandb:         train/mil_loss ▃▁▆▃▅▃▃▃▄▅▂▅▄▃▄▆▇▆█▁▂▇▄▂▅▆▅▅▃▄▂▃▆▅▄▆▄▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.39049
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.38793
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.12802
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.85584
wandb:      train/ensemble_f1 0.85584
wandb:         train/mil_loss 0.27731
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh5ezj7v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183347-lh5ezj7v/logs
wandb: Agent Starting Run: 9qj1tet4 with config:
wandb: 	actor_learning_rate: 2.238904533071781e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1351015422218882
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3021957085912803
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183530-9qj1tet4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9qj1tet4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▃▁▆
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁████████▄▄▄▄▄▄▄▄███████████████
wandb:      eval/avg_mil_loss ███▇▇▆▅▅▂▇▃▃▂▁▁▂▂▂▂▁▁▁▁▁▁▂▄▃▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁█████████▄▄▄▄▄▄▄▄▄████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃▅█▁▅▅▆▃▅▅▆▃▃█▃▇▆██▇▅█▆▄█▅▇█▇█▃▇▆▅▅█▅▂
wandb:      train/ensemble_f1 ▃▄▃▄▃▅▁▂▅▆▆▂▃▅▅▂▇█▇▄▅▆█▇█▆▄▄▆▅▆▇▆▆▇▇▇▅█▂
wandb:         train/mil_loss ▅▆█▅▃▆▃▆▄▅▄▃▅▂▂▄█▄▂▄▄▃▄▃▁▂▃▂▄▁▄▅▃▄▂▅▃▃▂▃
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.23435
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.23018
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.4834
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.88744
wandb:      train/ensemble_f1 0.88744
wandb:         train/mil_loss 0.27974
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m7wi98tp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183341-m7wi98tp/logs
wandb: Agent Starting Run: uetzw9qi with config:
wandb: 	actor_learning_rate: 1.6432612047827382e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0808986197421081
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01834035139848933
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183550-uetzw9qi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uetzw9qi
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▄▄▃▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▆▅▃▂▂▆▄▃▂▇▆▃▅▆▆▅▄▁▃▆▂▇▇▄▁▆▂█▃▅▂▃▂▄▆▆▄▃
wandb:      train/ensemble_f1 ▃▃▅▄▄▅▄▃▄▁▃▆▂▆▆▄▇▃▄▇█▅▅▆▄▅▅▄▃▁▅▃▄▄▂▅▂▁▃▃
wandb:         train/mil_loss ▄▅▃▃▂▅▄▅▆▆▅▆▂▁▇▇▄▆▅▆▆▄▅█▅▄▅▃▆▄▄▅▇▇▆▅▁▇█▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85978
wandb: best/eval_avg_mil_loss 0.31209
wandb:  best/eval_ensemble_f1 0.85978
wandb:            eval/avg_f1 0.85978
wandb:      eval/avg_mil_loss 0.30991
wandb:       eval/ensemble_f1 0.85978
wandb:            test/avg_f1 0.92839
wandb:      test/avg_mil_loss 0.3536
wandb:       test/ensemble_f1 0.92839
wandb:           train/avg_f1 0.87482
wandb:      train/ensemble_f1 0.87482
wandb:         train/mil_loss 0.29561
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uetzw9qi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183550-uetzw9qi/logs
wandb: Agent Starting Run: awlzoza3 with config:
wandb: 	actor_learning_rate: 0.0003134112404017628
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06128546391336254
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00037413126213137193
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183734-awlzoza3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awlzoza3
wandb: uploading history steps 125-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ██▇▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▅▆▆▆▄▄▄▄▄██████████████████████████████
wandb:      eval/avg_mil_loss ██▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▂▂▄▆▂▂▇▁▆▆▄▅▄▇▃▅▇▅▄█▃▂▇▅▄▆▆▃▇▆▇▆▆█▄▆▆
wandb:      train/ensemble_f1 ▁▄▄▃▄▂▅▆▃▂█▆▃▆▅▄▆▄▇▆█▇▄▄▇▅▄▅▆▆▆▇▇▄▅▅█▆▅▅
wandb:         train/mil_loss ▅▆█▅▃▃▃▄▄▄▃▃▄▃▂▃▃▃▃▂▃▄▂▂▂▃▁▂▅▂▂▄▂▃▂▂▃▃▂▄
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 1.72501
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 1.56982
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.57555
wandb:      test/avg_mil_loss 1.79346
wandb:       test/ensemble_f1 0.57555
wandb:           train/avg_f1 0.64893
wandb:      train/ensemble_f1 0.64893
wandb:         train/mil_loss 1.13656
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9qj1tet4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183530-9qj1tet4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rtt387se with config:
wandb: 	actor_learning_rate: 0.00036643959552655074
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5000469466097529
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20528494959486032
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183756-rtt387se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rtt387se
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆██
wandb: best/eval_avg_mil_loss █▅▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆██
wandb:            eval/avg_f1 ▁▁▁▁▃▅███████████████▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▅████████████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▄▃▂▃▆▆▃▅▆▄▆▄▄▆▆▃▅▅▇▄▇▆▅▆▃▃▅█▆▄▆▇▆▇▄▂█
wandb:      train/ensemble_f1 ▃▃▄▁▃▄▂▃▄▅▇▇▅▆▇▇▅▇▄▇▅▅▅▆▆▅▆▆▄▆▄▄█▅▅▆▅▅▅▆
wandb:         train/mil_loss ▄▇▆▄▄▃▄▅▅▃▂▄█▃▂▃▄▄▃▃▁▅▂▂▄▄▄▂▂▁▅▂▃▇▅▄▄▃▃▂
wandb:      train/policy_loss ▂▃▅▅▅▄▃▃▃▄▃▁▅▃▆▂▂▂█▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▂▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▄▃▃▃▅▅▄▂▃▂▄▁▃▃▂█▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▅▇▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.17642
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.89996
wandb:      eval/avg_mil_loss 0.17664
wandb:       eval/ensemble_f1 0.89996
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.19021
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.89119
wandb:      train/ensemble_f1 0.89119
wandb:         train/mil_loss 0.21017
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2n1nwjj0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183522-2n1nwjj0/logs
wandb: Agent Starting Run: 82g48knv with config:
wandb: 	actor_learning_rate: 0.00016229989737707765
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3245744939211338
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8531822334191042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183844-82g48knv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82g48knv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▁▁▃▃▃████████████████████████▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃█████████████████████▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▃▆▄▂▃▆▃▆▃▅▆▆▅▃▃▄▅▄▄▃▁▅▃█▃▅▅▂▃▇▅▄▃▂▅▃▅
wandb:      train/ensemble_f1 ▅▇▇▆▇▆▅▅▂▅▄▅▂▄▄▃▂▂▂▁▂▃▁█▁▅▃▂▃▇▃▂▅▃▅▂▃▃▃▂
wandb:         train/mil_loss ▅▇▆▆▂█▅▄▅▂▂▄▂▅▄▄▂▃▄▂▁▂▂▂▄▃▃▄▁▆▄▄▇▂▂▄▃▆▃▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▁▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88
wandb: best/eval_avg_mil_loss 0.27914
wandb:  best/eval_ensemble_f1 0.88
wandb:            eval/avg_f1 0.86999
wandb:      eval/avg_mil_loss 0.26249
wandb:       eval/ensemble_f1 0.86999
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.2756
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.87616
wandb:      train/ensemble_f1 0.87616
wandb:         train/mil_loss 0.28184
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awlzoza3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183734-awlzoza3/logs
wandb: Agent Starting Run: rgws5u31 with config:
wandb: 	actor_learning_rate: 0.00010679404182573335
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15439843488403693
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0017256730481686189
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183928-rgws5u31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rgws5u31
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▇█
wandb: best/eval_avg_mil_loss ▆█▅▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅▆▇█
wandb:            eval/avg_f1 ▁▃▃▅▅██▆▆▆▆▆▆▆▆▆██████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █▇▆▆▅▄▃▃▃▂▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▅▅▅▇████▇▇▇▇▇▇▇▇██████████████▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▄▂▃▆▃▄▆▆▇▇▇▆▅▇▇▆▅▇█▅▄█▆▆▆▄▄▅▄▇▃▃▃▄▆█▆
wandb:      train/ensemble_f1 ▃▁▄▄▇▄▆▄▅▄▆▅▆▇▇▆▇▇▇▇▇█▇▇▆▆▆▆▆▆▄▆▇▆▇▆▅▄▄▄
wandb:         train/mil_loss █▅▇▅▂▃▅▃▅▄▄▂▄▄▄▂▄▃▄▄▄▁▃▃▁▃▄▄▃▃▄▃▃▃▄▅▃▁▄▃
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▁▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.23888
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.2293
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.91919
wandb:      test/avg_mil_loss 0.17607
wandb:       test/ensemble_f1 0.91919
wandb:           train/avg_f1 0.88972
wandb:      train/ensemble_f1 0.88972
wandb:         train/mil_loss 0.2288
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82g48knv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183844-82g48knv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mdbzbffq with config:
wandb: 	actor_learning_rate: 0.0003655678894800294
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.016051531183535084
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.388922187630138
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184049-mdbzbffq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdbzbffq
wandb: uploading history steps 252-255, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▁▁▁▁▅▅███▅▅▅██▅██████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▅▅▅▅▅██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆█▆▅▅▅▃▅▁▂▆▁▆▃▄▇▄▅▆▆▅▃▇▃▆▅▆▅▄█▄▄▆▇▃▄▆▆
wandb:      train/ensemble_f1 ▄▂▃▆▆▅▁▄▃▄█▅▁▂▅▂▃▅▅▄▄▆▄▃▄▁█▄▃▂▂▅▄▃▃▆▃▃▆▄
wandb:         train/mil_loss ▄▃▆▇▄▆▅▅▇▄█▆▂█▆▂▄▄▇▅▆▅▅█▅▅▅█▃▅▆▆▃▄▃▅▄▇▁▅
wandb:      train/policy_loss ██████████████████████████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆█▆▅▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86936
wandb: best/eval_avg_mil_loss 0.27126
wandb:  best/eval_ensemble_f1 0.86936
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.27096
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.14084
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.88378
wandb:      train/ensemble_f1 0.88378
wandb:         train/mil_loss 0.26749
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rtt387se
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183756-rtt387se/logs
wandb: Agent Starting Run: 9xrd4h5e with config:
wandb: 	actor_learning_rate: 0.0020400824049292255
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5547016641606843
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10188818689762937
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184204-9xrd4h5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xrd4h5e
wandb: uploading history steps 159-167, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆██
wandb: best/eval_avg_mil_loss █▃█▇▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆██
wandb:            eval/avg_f1 ▁▁▁▁▆▆▆▆▆▆▆███▆█████████████████████████
wandb:      eval/avg_mil_loss ▇▇▇▇▅▇█▇▇▇▆▆▆▆▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▆▆▆▆▄▄▆▆▆▆▆███▆▆█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▅▇▅▂▄▅▅▆▂▆▁▆▂▅▆▇▇▅█▆▆▅▄▅▇▅▇▅▇▇▆▇█▅▅▅▅▆
wandb:      train/ensemble_f1 ▄▁▄▆▆▅▇▆▅▅▆▆▆▄▇▆▆▆▆▆▇▇▆█▇▇▆█▇▇▇▇▆▇█▆▇▇▇▇
wandb:         train/mil_loss █▅▄▄▄▃▅▃▅▃▃▄▄▄▃▆▅▂▄▃▃▅▃▂▃▅▂▄▄▆▄▃▂▃▃▅▂▄▃▁
wandb:      train/policy_loss ▇█▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁███▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.20283
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.17773
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.09174
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.92844
wandb:      train/ensemble_f1 0.92844
wandb:         train/mil_loss 0.21825
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdbzbffq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184049-mdbzbffq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pcwtpund with config:
wandb: 	actor_learning_rate: 0.005911515614684662
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.048469709547896866
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01222910824750778
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184340-pcwtpund
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pcwtpund
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▁▁▃▆▆▆▆▆▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▃▂▆▄▃▄▅▆▃▄▆▄▅▇▄▄▅▃▅▇▂▃▆▅▇▁▄▅▃▅▃▆▄▃▇▃█
wandb:      train/ensemble_f1 ▇▅▃▅▃▅▃▄▅▅▆▄▆▅▄▄█▆▄▅▆█▃▇▁▃▆▄▆▃▅▄▄▄▂▄▇▆▅▄
wandb:         train/mil_loss ▄▇▄▇▆▁█▆▅▆▃▄▄▃▄▅▅▃▇█▆▅▄▅▆▄▃▆▅▄▆▆▄▆▆▄▆▅▄▂
wandb:      train/policy_loss ▃█▂▃▅▃▅▄▁▅▃▂▃▄▆▃▂▂▃▄▄▄▃▃▄▄▃▂▄▄▃▂▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▄▄▁▅█▇▇▅█▅▅▆▄▃▅▇▅▄▅▄▇▄▄▅▂▆▅▃▆▆▄▃▅▅█▅▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.31735
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.31759
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.13795
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.89162
wandb:      train/ensemble_f1 0.89162
wandb:         train/mil_loss 0.2219
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earnest-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xrd4h5e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184204-9xrd4h5e/logs
wandb: Agent Starting Run: tbdttntb with config:
wandb: 	actor_learning_rate: 0.0007990501153231543
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18948061514997228
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17459772080779667
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184347-tbdttntb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tbdttntb
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss █▇▇▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▂▃▄▄▄▅▅▆▇▇▇▇▇▇▇▇█▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▁▂▄▄▄▄▅▇▇▇▇▇▇▇▇██▇▇▇▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▃▃▄▄▅▆▆▇▇▇▇▇█▇▇████████▇█▇█████████
wandb:      train/ensemble_f1 ▁▂▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇██▇████▇████████▇
wandb:         train/mil_loss ▇█▇▇▆▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▁▂▂▁▂▂▂▁
wandb:      train/policy_loss ▃▁▃█▃▃▄▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▄▇▄▄▄▄▂▄▄▇▁▄█▄▂▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.364
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.3547
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.90793
wandb:      test/avg_mil_loss 0.35714
wandb:       test/ensemble_f1 0.90793
wandb:           train/avg_f1 0.83622
wandb:      train/ensemble_f1 0.83622
wandb:         train/mil_loss 0.42799
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rgws5u31
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183928-rgws5u31/logs
wandb: Agent Starting Run: v5pctyja with config:
wandb: 	actor_learning_rate: 0.006239157161209585
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2883294038536235
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03145187740756217
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184555-v5pctyja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v5pctyja
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-40yrhus9'
wandb: uploading history steps 252-263, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss █▇▃▁
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▁▁▁▆▃▃▁▁▃▆▃▃▃▃▃▃▃▆▆▆▆▆██████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▅▆▅▄▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▁▁▁▁▃▃▃▆▃▃▃▃▃▃▃▃▃▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▄▅▇▅▅▅▆▅▇▆▇█▇█▆▅▆▄▃▄▄▆▆▅██▄▆▆▆▆▅▂▄▆▄▃
wandb:      train/ensemble_f1 ▄▂▂▁▂▄▅▄▆▆▄▅▅▅▃▃▄▆▅▅▃▄▅▅▆▃▄▄▃▅▂▄▅▄▄▆▄█▂▄
wandb:         train/mil_loss ▇█▅▆▃▅▇▆▄▄▃▅▄▃▂▃▅▃▃▄▅▄▄▄▄▂▃▃▅▂▂▂▃▁▁▅▃▄▄▁
wandb:      train/policy_loss █▇██▇▇███▇██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.18624
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.18168
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.96931
wandb:      test/avg_mil_loss 0.11555
wandb:       test/ensemble_f1 0.96931
wandb:           train/avg_f1 0.91248
wandb:      train/ensemble_f1 0.91248
wandb:         train/mil_loss 0.18494
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pcwtpund
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184340-pcwtpund/logs
wandb: Agent Starting Run: qu6k9h3w with config:
wandb: 	actor_learning_rate: 1.1608562917788144e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02306393335746426
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.811444964151884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184758-qu6k9h3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu6k9h3w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss █▇▇▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇█████▇▇▇▇▇█████
wandb:      eval/avg_mil_loss ███▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▃▃▃▃▆▆▇▆▆▆▆▆▆▆▇█▇▇▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▃▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇██▇▇██▇▇▇▇▇██████
wandb:      train/ensemble_f1 ▁▁▂▃▃▄▄▄▅▄▅▅▅▅▅▆▅▆▆▆▇▇█▇▇██▇▇▇▇█▇▇██▇███
wandb:         train/mil_loss █▆▇▆▆▅▄▄▃▄▄▃▄▄▄▄▄▃▃▃▂▂▃▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▂▁
wandb:      train/policy_loss ▅▅▅█▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▂▂▂▂▂▂▂▂▂▂▂▆▂▂▂▂▆▅▂▄▂█▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.2851
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.27133
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.89899
wandb:      test/avg_mil_loss 0.29902
wandb:       test/ensemble_f1 0.89899
wandb:           train/avg_f1 0.88121
wandb:      train/ensemble_f1 0.88121
wandb:         train/mil_loss 0.28813
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tbdttntb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184347-tbdttntb/logs
wandb: Agent Starting Run: jue27xby with config:
wandb: 	actor_learning_rate: 0.00573084389536948
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6517663933598828
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2163169608467106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184833-jue27xby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jue27xby
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁██▇█▇█▇█▇▇▇██▇█▇██▇████▇████████▇███▇█▇
wandb:      train/ensemble_f1 ▁▇█▇▇▇▇▇█▇█▇▇█▇▇▇▇▇███▇▇████▇████▇▇███▇▇
wandb:         train/mil_loss ▆▅▅▆▆▄▆▂▆▆▅▄▃▄▂▂▅▄▃▆█▅▇▄▆▆▂▅▂▇▆▄▄▆▅▅▄▃▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.26909
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.25953
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19324
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.86992
wandb:      train/ensemble_f1 0.86992
wandb:         train/mil_loss 0.2849
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v5pctyja
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184555-v5pctyja/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4cr74v5c with config:
wandb: 	actor_learning_rate: 0.007606242686595071
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08915072918859346
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.035607839851171
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184930-4cr74v5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cr74v5c
wandb: uploading history steps 95-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▁▁▁██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂██▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▇▇▇█▆▇▇█▆▆▆▇▆▇▆▇▇▇▆▇▆▇▇▇▇▆▇▆▇▇▇█▆▇▇▆█▇
wandb:      train/ensemble_f1 ▁▁▇▇▇▇▇▆▇▇▆▆▆▇▆▇▆▆▆▇▇▆▇▇▆▅▆▆▅▆▇▇▇▇█▇▆▇▆▇
wandb:         train/mil_loss ▇█▃▂▂▂▂▃▂▂▃▃▃▂▂▂▃▃▂▃▃▁▃▂▁▃▃▂▃▃▃▃▂▂▁▂▂▃▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.3614
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.36416
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.13086
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.88927
wandb:      train/ensemble_f1 0.88927
wandb:         train/mil_loss 0.25871
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jue27xby
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184833-jue27xby/logs
wandb: Agent Starting Run: ept4hlky with config:
wandb: 	actor_learning_rate: 2.4952014998336504e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.48532514857989906
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5715859212598966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185022-ept4hlky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ept4hlky
wandb: uploading history steps 205-212, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▇▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▅███████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▁▁▁▁▅▅▅▅▅███████████████▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▁▂▄▄▂▄▃▃▆▅▄▆▅▅▄▄▄▃▆▆▆▄▇▅▆▆▇▅▆█▃▆█▆▆▆▆█
wandb:      train/ensemble_f1 ▃▁▁▄▂▂▁▄▄▂▅▄▂▆▃▃▆▇▂▄▅▆▆▆▄▅▇▇▆▅▆▆▆▆▅▆▃▆█▅
wandb:         train/mil_loss ▆██▇▇▇█▇▆▆▅▆▆▆▆▄▅▅▄▅▄▄▅▃▅▄▃▄▅▅▄▃▄▃▃▁▂▄▃▂
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅█▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57924
wandb: best/eval_avg_mil_loss 1.68258
wandb:  best/eval_ensemble_f1 0.57924
wandb:            eval/avg_f1 0.55587
wandb:      eval/avg_mil_loss 1.51493
wandb:       eval/ensemble_f1 0.55587
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 1.85008
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.59686
wandb:      train/ensemble_f1 0.59686
wandb:         train/mil_loss 1.03891
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu6k9h3w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184758-qu6k9h3w/logs
wandb: Agent Starting Run: 5h1zryyw with config:
wandb: 	actor_learning_rate: 0.0009507599071571712
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28445503742401734
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5798429237572293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185125-5h1zryyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5h1zryyw
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▅▁▃▄▄▄▆▇▅▄▅▅▄▃▅▅▅█▃▆▄▅▇▆▄▆▆▆▆▅▆▄▅▆▆▆▇
wandb:      train/ensemble_f1 ▃▇▂▃▄▁▅▅▃▃▄▄▅▄▅█▅▂▅▆█▆▃▇▆▇▅▇▆▆█▆▇▆▅▅▄▆▇▆
wandb:         train/mil_loss ▆▄▅▅▄█▄▃▃▆▄▅▆▆█▃▆▄▇▄▅▂▄▅▇▆▂▅▁▁▄▄▂▃▂▃▄▄▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76881
wandb: best/eval_avg_mil_loss 1.06626
wandb:  best/eval_ensemble_f1 0.76881
wandb:            eval/avg_f1 0.76881
wandb:      eval/avg_mil_loss 0.95425
wandb:       eval/ensemble_f1 0.76881
wandb:            test/avg_f1 0.63689
wandb:      test/avg_mil_loss 1.35198
wandb:       test/ensemble_f1 0.63689
wandb:           train/avg_f1 0.72915
wandb:      train/ensemble_f1 0.72915
wandb:         train/mil_loss 0.69659
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5h1zryyw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185125-5h1zryyw/logs
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▁▁▁▁▁▃▁▁▃▃▃▃▅▅▅▆▆▆▆▆▆▆█████████████████
wandb:      eval/avg_mil_loss ▇▇▇█▇▇▇▇▆▆▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▅▅▆▆▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▁▁▂▃▆▂▅▄▆▆▇▄▃▇▄▄▄▄▅▄▄▆▆▅▄▄▅▇▆█▅▃▆▆▄▅▅
wandb:      train/ensemble_f1 ▃▅▁▁▁▂▃▂▂▄▆▄▄▄▃▄▄▄▆▄▂▆▅▆▅▅▆▆▆▅▄▅▅▅█▆▅▃▄▄
wandb:         train/mil_loss ▅▆▃▃▄▅▄▂▆▅▃▄▄▆▅▅▄▅▄▄▃█▄▅▆▃▄▃▁▂▅▄▂▄▃▁▃▂▄▅
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.24543
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.23316
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.20009
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88617
wandb:      train/ensemble_f1 0.88617
wandb:         train/mil_loss 0.31191
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cr74v5c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184930-4cr74v5c/logs
wandb: Agent Starting Run: bzacx49o with config:
wandb: 	actor_learning_rate: 0.001866592088367636
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02292994553103256
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2304374013098479
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185309-bzacx49o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bzacx49o
wandb: Agent Starting Run: n2kcivsf with config:
wandb: 	actor_learning_rate: 0.001710092791167156
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31943393433172995
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0019546651688138184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185314-n2kcivsf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n2kcivsf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▆█
wandb: best/eval_avg_mil_loss ██▇▅▁▂
wandb:  best/eval_ensemble_f1 ▁▃▅▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▃▅▅▅▄▄▅▃▃▃▃▅▅▅▅▅▆█████▆▆▆▆▆▆▆▆▆▆▆▆██
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▄▄▄▆▆▆▃▃▃▃▃▃▃▅▅▅▅▅█████▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▃▃▁▄▃▂▂▄▂▃▄▄▅▃▄▂▄▄▃▆▅▄▅▆▆▇▅█▆▆▅▆▇▇▆▇█
wandb:      train/ensemble_f1 ▃▂▁▂▂▂▂▂▁▂▂▃▂▁▃▃▂▂▂▄▅▃▃▄▄▆▅▅▆▆▅█▄▆▅▆▆▇▆▆
wandb:         train/mil_loss ▅▇█▇▁▅▅▅▄▆▄▆▄▂▅▅▃▅▃▅▄▃▅▃▅▂▃▂▂▂▅▂▁▄▃▁▃▅▁▃
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59066
wandb: best/eval_avg_mil_loss 1.57995
wandb:  best/eval_ensemble_f1 0.59066
wandb:            eval/avg_f1 0.59066
wandb:      eval/avg_mil_loss 0.93105
wandb:       eval/ensemble_f1 0.59066
wandb:            test/avg_f1 0.58822
wandb:      test/avg_mil_loss 1.83663
wandb:       test/ensemble_f1 0.58822
wandb:           train/avg_f1 0.71836
wandb:      train/ensemble_f1 0.71836
wandb:         train/mil_loss 0.66138
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ept4hlky
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185022-ept4hlky/logs
wandb: Agent Starting Run: yn54p0xj with config:
wandb: 	actor_learning_rate: 4.370142960486107e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7458621531767877
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3059449607492546
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185429-yn54p0xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yn54p0xj
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ███▇▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▁▁▁▅▅▅▅▅▅▅▅▅█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▄▂▅█▄▅▆▆▅▅▅▇▆▄▆▃▃▆▄▄▆▆▂▅▄▅▇▅▂▄▄▄▄▅▇▂▂▄
wandb:      train/ensemble_f1 ▅▂▃▃█▄▂▄▅▂▄▄▄▆▆▃▄▇▂▅▃▅▁▄▂▅▄▅▄▁▃▅▂▃▃▇▄▂▃▅
wandb:         train/mil_loss ▅▄▃▃▂▃█▄▄▁▂▃▆▆▄▄▆▁▃▅▃▂▄▃▃▂▃▄▄▁▂▁▃▃▃▅▂▄▅▄
wandb:      train/policy_loss █▇▇█▇█▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▇███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.20437
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.18632
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.97947
wandb:      test/avg_mil_loss 0.10758
wandb:       test/ensemble_f1 0.97947
wandb:           train/avg_f1 0.9225
wandb:      train/ensemble_f1 0.9225
wandb:         train/mil_loss 0.19946
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bzacx49o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185309-bzacx49o/logs
wandb: Agent Starting Run: ibwh5h8n with config:
wandb: 	actor_learning_rate: 9.502913389520212e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5600951199812361
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8875803601333069
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185610-ibwh5h8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibwh5h8n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▄▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁███████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▅▇▅▅▃▆▁▆▇▄▅▅▃▅▁▃▆▅▄▅▄▄▄▇▄▂▅█▅▁▁▆▄▃▄▇▃
wandb:      train/ensemble_f1 ▅█▁▆▅▆▆▄▂▆▆▃█▄▃▄▆▄█▄▇▇▆▅▅▄▆▆█▆█▆▆▅▅▆▄▅▇▆
wandb:         train/mil_loss ▃▄▂▃▃▄▁▅▅▅█▅▄▄▄▆▃▄▃▅▄▄▃▅▃▃▅▄▃▃▄▃▄▅▄▄▃▂▂▃
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54044
wandb: best/eval_avg_mil_loss 2.18849
wandb:  best/eval_ensemble_f1 0.54044
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 2.13448
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 2.55907
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.58751
wandb:      train/ensemble_f1 0.58751
wandb:         train/mil_loss 0.61462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yn54p0xj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185429-yn54p0xj/logs
wandb: Agent Starting Run: w2okb9m3 with config:
wandb: 	actor_learning_rate: 0.008421488858505442
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4233399617006074
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3501725313628653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185624-w2okb9m3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w2okb9m3
wandb: uploading history steps 283-298, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▇▇█
wandb: best/eval_avg_mil_loss █▂▂▁▁▁▁▂▂▅
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▆▇▇▇▇▇▇▇█▇▇██████████
wandb:      eval/avg_mil_loss █▆▆▆▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▄▄▆▅▆▇▇▇▇▇▇▇▇███▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▅▄▅▅▅▅▅▆▅▆▆▆▆▅█▆█▇▇██▇
wandb:      train/ensemble_f1 ▃▁▁▁▂▃▂▃▃▄▃▄▅▄▄▅▄▆▅▅▅▆▇▇▆▆▇▇▇▇▇█▆▇█▇█▇▇▇
wandb:         train/mil_loss ▇▆▇█▅▅▆▂▃▃▃▃▂▃▁▃▃▃▂▂▂▃▂▃▂▂▂▂▂▂▃▃▃▄▃▅▃▄▄▄
wandb:      train/policy_loss ▆▆▁▅▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▂▆▆▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▇▇▁▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▃▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54044
wandb: best/eval_avg_mil_loss 2.68756
wandb:  best/eval_ensemble_f1 0.54044
wandb:            eval/avg_f1 0.53276
wandb:      eval/avg_mil_loss 2.78169
wandb:       eval/ensemble_f1 0.53276
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.06027
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.59136
wandb:      train/ensemble_f1 0.59136
wandb:         train/mil_loss 1.47303
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run visionary-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n2kcivsf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185314-n2kcivsf/logs
wandb: Agent Starting Run: el375mai with config:
wandb: 	actor_learning_rate: 0.000699490643054073
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8314141019056324
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08179119201411034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185803-el375mai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/el375mai
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▁▁▁▁▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▃▄▅▇▇▇▆▄▆██▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▆▇█▄▆▄▆▇▄▁▄▃▅▄▅▇▄▆▆▃▅█▄▇▅▆▆▅▇▇▄▆▆▆▇▇▅
wandb:      train/ensemble_f1 ▇█▆██▆▆▆▄▅▄▆▅▆▅▃▂▄▅▄▆▃▃▆▆▄▅▁▆▆▄▁▅▄▇▇▅▆▃▅
wandb:         train/mil_loss ▄▃▄▂▃▄▇▅▃▂▃▇▅▃▄█▄▇▅▄▅▆▃▅▅▅▄▁▄▇▄▃▆▁▅▂▅▃▆▅
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.31879
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.30746
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.20575
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.891
wandb:      train/ensemble_f1 0.891
wandb:         train/mil_loss 0.2995
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w2okb9m3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185624-w2okb9m3/logs
wandb: Agent Starting Run: qmbhr2tt with config:
wandb: 	actor_learning_rate: 0.00035046638261449327
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2651747247010735
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4212618563819067
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185808-qmbhr2tt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmbhr2tt
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▇▆▆▄▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▃▃▃▃▃▄▄▄▄▄▅▆▆▆▆▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▅▅▄▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▁▁▁▁▁▂▃▃▄▄▅▆▆▇▇▇██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▄▃▅▃▅▆▅▅▆▆▅▆▇▇▆▅▆▆▆▆▇▇▆▆▇▇▆▆███▇▇▇▇█▇
wandb:      train/ensemble_f1 ▁▁▃▂▂▄▅▅▅▄▅▅▆▇▅▆▆▇▆▆▆▇▆▆▇▆█▆▅▆▇▆▇▆▆▆▆▆▇▇
wandb:         train/mil_loss ▇▄▅█▄▅▄▅▃▄▂▂▄▃▄▃▃▃▃▄▄▂▃▃▃▄▃▂▂▂▃▃▂▂▃▃▂▃▁▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▆▁▆▄▄▄▄▇▂▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.23785
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.90999
wandb:      eval/avg_mil_loss 0.22133
wandb:       eval/ensemble_f1 0.90999
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.26525
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88874
wandb:      train/ensemble_f1 0.88874
wandb:         train/mil_loss 0.27209
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibwh5h8n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185610-ibwh5h8n/logs
wandb: Agent Starting Run: 3hevngqz with config:
wandb: 	actor_learning_rate: 0.008503740776059301
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17682270497730757
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1571206640626286
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185916-3hevngqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hevngqz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▆▄▃▅▃▄▅▃▁▅▅▅▆▄▅▃▅▂▁▆▆▇▆▆▄▄█▆▆▆▇▃▇▆▅▇▇
wandb:      train/ensemble_f1 ▃▃▃▆▂▆▄▄▁▃▆▄▃▅▄▅▅▃█▆▅▅▅▆▆▆▆▆▆▄▄█▆▆▅▅▇▆▇▇
wandb:         train/mil_loss ▃▃▄▅█▆▅▃█▆▃▅▂▃▆▅▃▂▃▄▅▂▃▅▂▄▃▂▃▂▆▇▃▁▄▃▅▅▄▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.30914
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.84878
wandb:      eval/avg_mil_loss 0.25729
wandb:       eval/ensemble_f1 0.84878
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.14572
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.91307
wandb:      train/ensemble_f1 0.91307
wandb:         train/mil_loss 0.3107
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmbhr2tt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185808-qmbhr2tt/logs
wandb: Agent Starting Run: 0o13ci6y with config:
wandb: 	actor_learning_rate: 1.2908063157294526e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3136108520325269
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.924513220183391
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185952-0o13ci6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o13ci6y
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss █▅▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▃▇▆▇▆▆▇▆▇█▇▇▇▆▇▆▇▇█▆▆▆▇▆▆▅▆▆▆▆▇▆▅▆▇▆
wandb:      train/ensemble_f1 ▂▁▁▁▂▇▇▆▆▅▆█▆▇▆▇▇▆▇█▆▇▇▇▇▇▆▆▇▅▇▆▆▆▇▆▆▆▆▆
wandb:         train/mil_loss ▅█▅▆▂▆▅▄▇▆▇▃▅▃▅▃▄▄▇▅▅▅▆▅▅▄▅▄▆▄▅▄▆▃▃▅▆▄▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.26684
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.23457
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.87879
wandb:      test/avg_mil_loss 0.28536
wandb:       test/ensemble_f1 0.87879
wandb:           train/avg_f1 0.88734
wandb:      train/ensemble_f1 0.88734
wandb:         train/mil_loss 0.30856
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/el375mai
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185803-el375mai/logs
wandb: Agent Starting Run: shyr17np with config:
wandb: 	actor_learning_rate: 0.008779929631972798
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.26393362427618683
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05689927465429012
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190002-shyr17np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/shyr17np
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██████████▁▁█▁▁█████████▁▁▁▁▁▁▁█████████
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▅▆▆▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████▁▁▁▁███████▁▁▁▁▁▁▁▁▁██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▂▂▅▅▃▂▄▃▃▃▅▆█▄▂▃▄▃▂▄▃▄▆█▅▅▃▆▆▃▄▇▆▄▆▄▆
wandb:      train/ensemble_f1 ▃▃▃▄▁▅▃▆▄▄▄▂▄▆▆▆█▄█▄▆▅▆▃▅▄▆▄█▅▃▅▆▇▅▆▅▆▅▇
wandb:         train/mil_loss ▄▅▅▅▃▅▆▆▅▆▅█▆▃▃▅▅▁▄▄▅▄▄▃▄▅▄▅▆▅▅▃▃▅▄▂▃▃▄▄
wandb:      train/policy_loss █▆▇▇▆▆▅▇▇▇▇▅▆▆▇▆▆▇▄▆▇▇▇██▆▆▆▇▆▇▆▆▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▅▅▆▅▆▆▅▇▅▇▅▁▆▆▅▅▇▆▅▇▆▅▆▅█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.24251
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.21381
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.13912
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.91242
wandb:      train/ensemble_f1 0.91242
wandb:         train/mil_loss 0.23366
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3hevngqz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185916-3hevngqz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: izv2jm58 with config:
wandb: 	actor_learning_rate: 0.0002562032951401931
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02365181145588202
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13504743712022085
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190148-izv2jm58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izv2jm58
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▇▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆███████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▆▆▆▆▆▆▆▆▆▆▆██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▃▄▆▁▃▃▂▃▂▂▃▄▄▄▆▃▃▂▃▄▂▄▄▅▅▃▅▄▄▅▄▅▃▇▅█▆
wandb:      train/ensemble_f1 ▄▅▄▆▂▆▄▅▃▄▄▆▅▆▄▆▆▆▄▅▇▅▄▇▄▆▁▅▂▅▆▅▇▇▇▅▆▆▅█
wandb:         train/mil_loss ▅▄▆▆▅▆▄▄▄▄▅▄▆▅██▁▃▅▂▆▃▂▃▂▄▆▂▃▆▃▂▄▂▅▄▄▄▇▃
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.33299
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.30289
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.1233
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.8963
wandb:      train/ensemble_f1 0.8963
wandb:         train/mil_loss 0.27312
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o13ci6y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185952-0o13ci6y/logs
wandb: Agent Starting Run: wr49kq8e with config:
wandb: 	actor_learning_rate: 0.00031158640285722293
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7155597977823144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07268948943799947
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190250-wr49kq8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wr49kq8e
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▂▁▁▄▃▃▄▄▅▅▅▆▆▆▇▇▇█████████████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▇▇▄▆▅▇▄▅▆▄▆▆▇▄▅▇▄▃▆█▂▅▄▇▃▆▄▄▅▃▁▄▂▃▂▄▅
wandb:      train/ensemble_f1 ▄▄▂▆▆▆▃▄▄▅▅▄▄▃▆▁▆▂▂▄█▆▅▆▅▃▅▅▃▆▁▅▃▃▆▃▁▂▄▃
wandb:         train/mil_loss ▄▁▃▂▄▅▅▄▅▂▅▄▅▄▅▃▄▃▄▆▅▆▅▄▅▅▂█▄▄▁▂▇▂▅▄▃▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.29072
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.30605
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.12494
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.88278
wandb:      train/ensemble_f1 0.88278
wandb:         train/mil_loss 0.2512
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wr49kq8e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190250-wr49kq8e/logs
wandb: Agent Starting Run: ppwfg12y with config:
wandb: 	actor_learning_rate: 0.0009946333798264003
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9230239010262674
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3770894890643307
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190434-ppwfg12y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ppwfg12y
wandb: uploading history steps 364-372, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇███
wandb: best/eval_avg_mil_loss █▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆██████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇████▇▇
wandb:      train/ensemble_f1 ▁▇▇▇▇██▇▇█▇▇▇▇▇█▇█▇█▇█▇▇▇█▇▇███▇█████▇██
wandb:         train/mil_loss ▆▄▆▄▅▅▁▄▆█▃▂▃▂▂▃█▄▃▃▂▃▅▃▄▃▁▂▄▃▂▅▂▂▂▃▂▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████▁██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.25571
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.25157
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19397
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88796
wandb:      train/ensemble_f1 0.88796
wandb:         train/mil_loss 0.28172
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/shyr17np
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190002-shyr17np/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: atee0wvh with config:
wandb: 	actor_learning_rate: 0.00011154121710743112
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.029906936827268304
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13558557880175792
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190608-atee0wvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atee0wvh
wandb: uploading history steps 156-164, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▅▅▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▄▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb:      eval/avg_mil_loss ██████▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▄▅▅▆▅▆▆▇▆▆▅▇▇█▇▆▆█▇▅▇▇▇▅█▆▅▇▅▇▇▇▆▆█▆▆
wandb:      train/ensemble_f1 ▃▂▃▁▂▁▃▅▇▅▅▆▇▆▇▇▆▆▇█▇▇▆▆▇▅▆▇▆▇▇█▆▆▆▆▅▆▆▆
wandb:         train/mil_loss ▇█▂▃▄▅▆▂▂▇▅▃▅▂▃▃▄▅▃▄▄▃▂▂▃▃▄▂▃▅▃▄▄▅▃▄▃▃▄▁
wandb:      train/policy_loss ██▁█▂▃▁▁▂▅▁▂▁▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77422
wandb: best/eval_avg_mil_loss 0.52614
wandb:  best/eval_ensemble_f1 0.77422
wandb:            eval/avg_f1 0.77422
wandb:      eval/avg_mil_loss 0.50527
wandb:       eval/ensemble_f1 0.77422
wandb:            test/avg_f1 0.74877
wandb:      test/avg_mil_loss 0.82355
wandb:       test/ensemble_f1 0.74877
wandb:           train/avg_f1 0.76452
wandb:      train/ensemble_f1 0.76452
wandb:         train/mil_loss 0.25863
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ppwfg12y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190434-ppwfg12y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3msrw66t with config:
wandb: 	actor_learning_rate: 0.0003253594707859665
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6581658377627253
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48405880730198225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190725-3msrw66t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3msrw66t
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▄▄▅▆▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▆▅▄▄▄▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▄▄▅▆▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▃▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▃▂▃▄▂▃▄▃▄▄▅▅▄▅▄▅▅▆▆▆▅▆▆▇▇▇▆▇▇█▇▇▇▇█▇▇
wandb:      train/ensemble_f1 ▁▂▂▂▃▃▄▄▃▄▅▅▄▆▅▅▆▅▅▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇▇▇█▇▇
wandb:         train/mil_loss █▆▆▅▄▅▅▄▄▅▄▄▄▄▄▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▁
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67825
wandb: best/eval_avg_mil_loss 1.08961
wandb:  best/eval_ensemble_f1 0.67825
wandb:            eval/avg_f1 0.66372
wandb:      eval/avg_mil_loss 0.96464
wandb:       eval/ensemble_f1 0.66372
wandb:            test/avg_f1 0.69562
wandb:      test/avg_mil_loss 1.23699
wandb:       test/ensemble_f1 0.69562
wandb:           train/avg_f1 0.75826
wandb:      train/ensemble_f1 0.75826
wandb:         train/mil_loss 0.58492
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izv2jm58
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190148-izv2jm58/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ywmwkk00 with config:
wandb: 	actor_learning_rate: 1.6211387910237993e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9736545595060616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7959393759610278
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190819-ywmwkk00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ywmwkk00
wandb: uploading history steps 141-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▅▇██
wandb: best/eval_avg_mil_loss █▇▇▆▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▅▇██
wandb:            eval/avg_f1 ▁▁▂▄▅▅▅▅▅▅▅▅▇▇▇██████▇▇▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss ██▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▅▅▅▅▅▅▅▇▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▃▃▁▃▂▄▂▅▄▃▄▅▅▅▆▅▅▅▅▆▆▅▆▅▇▆▆▆▆▆▆▆▇▅█▇▇
wandb:      train/ensemble_f1 ▁▁▂▂▃▂▅▃▄▄▄▄▄▅▅▅▅▆▅▄▅▆▆▆▆▇▅▇▅▆▅▇▇▆█▅▅▅▆█
wandb:         train/mil_loss ▇█▆▄▅▃▄▇▅▅▅▄▆▅▄▂▄▁▄▆▄▃▄▇▃▂▂▄▄▂▅▄▃▂▄▄▂▂▂▂
wandb:      train/policy_loss ▁█▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▅▂▂▂▂▂▂▂▂▃▁▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88
wandb: best/eval_avg_mil_loss 0.31498
wandb:  best/eval_ensemble_f1 0.88
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.29628
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.332
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.87369
wandb:      train/ensemble_f1 0.87369
wandb:         train/mil_loss 0.3387
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atee0wvh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190608-atee0wvh/logs
wandb: Agent Starting Run: roqg33tm with config:
wandb: 	actor_learning_rate: 0.007596635568286769
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9999991373592044
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0263847299885116
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190838-roqg33tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/roqg33tm
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇█████▇████████
wandb:       eval/ensemble_f1 ██████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▅▅▇▆▄▆▆▇▄▄▆▆▇▃▆▄▄▂▄▄▂▃▁▄▃▃▁▃▅▇▃▂▅▂▂▅▆▃
wandb:      train/ensemble_f1 ▇█▅▇▆▆▄▆▇▄▆▇▂▂▁▆▃▅▆▄▄▅▄▃▅▄▄▄▂▃▅▄▅▇▂▂▅▅▂▃
wandb:         train/mil_loss ▇▂▅▂▆▃▃▂▂▆▃█▅▃▄▂▃▄▄▂▂▂▁▆▂▂█▅▁▂▂▄▄▁▅▁▁▆▂▂
wandb:      train/policy_loss █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.32777
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.8164
wandb:      eval/avg_mil_loss 0.37125
wandb:       eval/ensemble_f1 0.8164
wandb:            test/avg_f1 0.91511
wandb:      test/avg_mil_loss 0.18315
wandb:       test/ensemble_f1 0.91511
wandb:           train/avg_f1 0.84572
wandb:      train/ensemble_f1 0.84572
wandb:         train/mil_loss 0.26211
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/roqg33tm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190838-roqg33tm/logs
wandb: Agent Starting Run: z2gw7c5q with config:
wandb: 	actor_learning_rate: 0.00018250912579094545
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6492218573386273
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0018960065112040292
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▄▄▄▄▄▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▅▅▅▅▄▄▄▄▄▂▂▂▂▂▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▆▇▇▇▆▆▆▆▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▄▄▄▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▄▄▂▂▇▅▇▄▄▃▅▆▄▇▇▅▅▆▅▄▃▅▆▅█▃▃█▇▄▇▅▄▅▃▅▃
wandb:      train/ensemble_f1 ▄▁▄▅▃▆▃▄▅▅▅▅▇▆▆▆▅▅▆▆▄▄▆█▆▇▆▆▃▄▄▅▄▄▅▇▅▄▅▄
wandb:         train/mil_loss ▇▂▃▇▆▅▄▅▄▆▅▁▄█▆▅▃▆▄▅▄▅▄█▆▅▆▆▅▅▆▅▅▄▅▃▇▁▄▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.96
wandb: best/eval_avg_mil_loss 0.14084
wandb:  best/eval_ensemble_f1 0.96
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.15127
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.94939
wandb:      test/avg_mil_loss 0.16052
wandb:       test/ensemble_f1 0.94939
wandb:           train/avg_f1 0.90108
wandb:      train/ensemble_f1 0.90108
wandb:         train/mil_loss 0.23933
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191022-z2gw7c5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🚀 View run dazzling-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ywmwkk00
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2gw7c5q
wandb: Find logs at: ./wandb/run-20250529_190819-ywmwkk00/logs
wandb: Agent Starting Run: h47tekm1 with config:
wandb: 	actor_learning_rate: 0.008775295240113381
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0026936735079371443
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2777458072463347
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191027-h47tekm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h47tekm1
wandb: uploading history steps 222-236, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁█▅▄
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▃▃▁▃▁▃▃▅▅▅▅▅▅▆▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▃▂▇█▇▇▇▇▇▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▃▃▃▃▁▃▃▃▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▄▄▅▅▅▂▁▅▃▄▄▄▆▇▆█▄▇▄▅▅▆▃▆▆▄▅▆▇▆▅█▃▇▄▅▅
wandb:      train/ensemble_f1 ▄▁▃▂▄▁▁▃▄▂▂▂▃▄▂█▃▅▄▄▄▂▂▂▄▆▇▂▁▄▆█▄▇▇▇▃▄▂▃
wandb:         train/mil_loss ▄▆▅▇▄▄▄▇█▃█▄▁▃▅▄▄▆▇▂▂▁▁▂▅▃▅▄▄▃▃▃▃▃▅█▄▃▂▅
wandb:      train/policy_loss ████▁████▄██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.38632
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.82985
wandb:      eval/avg_mil_loss 0.38342
wandb:       eval/ensemble_f1 0.82985
wandb:            test/avg_f1 0.90793
wandb:      test/avg_mil_loss 0.24156
wandb:       test/ensemble_f1 0.90793
wandb:           train/avg_f1 0.86364
wandb:      train/ensemble_f1 0.86364
wandb:         train/mil_loss 0.28459
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3msrw66t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190725-3msrw66t/logs
wandb: Agent Starting Run: rq9931yo with config:
wandb: 	actor_learning_rate: 0.007877247534803594
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24704517247177493
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6370204903647292
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191113-rq9931yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rq9931yo
wandb: uploading history steps 110-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▁▂▂
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁████▅▅▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▇▇▆▆▆▆▆▇▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁█████▅▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▂▅▂▅▅▅▂▃▁▃▄▃▃▄▂▂▁▅▄▂▅▃▅▄▄▄▅▂▄▄▅▃▂█▇█▇▅
wandb:      train/ensemble_f1 ▃▃▃▃▅▄▅▄▆▃▄▂▅▄▄▄▃▆▄▅▂▅▁▁▆▅▄▅▄▃▄▅▅▅▄▆▇▇█▇
wandb:         train/mil_loss ▃▅▃▅█▄▆▁▆▄▅▅▅▅▆█▇▄▆▂▃▆▅▅▃▃▃▆▅▁▆▄▄▃▃▄▆▄▃▃
wandb:      train/policy_loss █████▇████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▇███▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.27877
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.23824
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.06732
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.94621
wandb:      train/ensemble_f1 0.94621
wandb:         train/mil_loss 0.18506
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h47tekm1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191027-h47tekm1/logs
wandb: Agent Starting Run: or0kssua with config:
wandb: 	actor_learning_rate: 4.242284146021872e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9811468977297888
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9703092642106784
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191231-or0kssua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/or0kssua
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▁▅█
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▂▂▁▁▅▅▅▅▅▅█▅▅▅▅▅▅▅▅████████▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▄▇████▇▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄
wandb:       eval/ensemble_f1 ▅▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅██▅▅▅█████████▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▁▁▃▃▃▂▄▄▂▂▅▄▅▅▄▄▅▅▄▄▅▆▃▃▅▄▅▄▅▆▆▄▆▅▅█▅▇
wandb:      train/ensemble_f1 ▅▂▄▃▁▃▂▁▂▃▄▄▄▂▃▄▄▅▆▃▅▅▃▄▄▆▅▄▄▄▅▆▆▄▅█▄▅▆▅
wandb:         train/mil_loss ▂▂▅▁▇▃▆▄▇▅▅▆▅▄▂▇▇▃▇▃▄▂▆▅▆▂▁▅▇▃█▅▆▃▅▇▄▅▅▄
wandb:      train/policy_loss ▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6397
wandb: best/eval_avg_mil_loss 2.17685
wandb:  best/eval_ensemble_f1 0.6397
wandb:            eval/avg_f1 0.63108
wandb:      eval/avg_mil_loss 2.09728
wandb:       eval/ensemble_f1 0.63108
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 3.03285
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.69044
wandb:      train/ensemble_f1 0.69044
wandb:         train/mil_loss 0.69925
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2gw7c5q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191022-z2gw7c5q/logs
wandb: Agent Starting Run: 538uhlg6 with config:
wandb: 	actor_learning_rate: 0.00011110758430303456
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4112111931273707
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06933238722797386
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191301-538uhlg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/538uhlg6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▇▇▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▃▃▃▃▃▃▃▃▃▄▄▄
wandb:      eval/avg_mil_loss ▃▃▃▃▃▄▅▄████▇▇▇▇▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███▆▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▃▃▃▃▃▃▃▃▃▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▄▄▄▃▄▄▅▅▅▆█▇▂▂▄▄▅▃▃▄▃▂▃▃▁▆▃▅▆▄▃▂▄▂▅▄▆
wandb:      train/ensemble_f1 ▅▇▃▄▄▅▅▄▅█▃▇▇▄▇▆▄▃▄▆▇▃▂▃▄▄▇▅▃▂▃▃▃▁▆▁▄▄▂▄
wandb:         train/mil_loss ▅▃▅▅▅█▄▂▅▂▆▅▃▃▃▃▃▄▁▃▃▅▄▃▄▄▃▃▃▄▆▄▂▄▃▅▄▆▄▂
wandb:      train/policy_loss ▆▆▆▆▆▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.33311
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.83974
wandb:      eval/avg_mil_loss 0.30632
wandb:       eval/ensemble_f1 0.83974
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.25145
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.8986
wandb:      train/ensemble_f1 0.8986
wandb:         train/mil_loss 0.21219
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/or0kssua
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191231-or0kssua/logs
wandb: Agent Starting Run: phll6ks8 with config:
wandb: 	actor_learning_rate: 1.0271237329595663e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8227122359081125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7142563984414361
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191415-phll6ks8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phll6ks8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▃▄▄▄▅▅▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▃▃▄▄▄▅▅▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▃▄▆▆▇█████████████████████▇▇▇▇▇█████
wandb:      eval/avg_mil_loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▄▅▇▇▇██████████████████████████▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▆▆▇▇▇▇▇██▇█████▇██▇█▇▇███▇█▇█▇█▇▇▇█▇█
wandb:      train/ensemble_f1 ▁▁▁▃▄▇▇▇█▇██▇█▇█▇██▇████▇█▇███████▇▇▇█▇▇
wandb:         train/mil_loss █▂▂▁▁▂▁▁▂▁▁▁▁▁▁▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁
wandb:      train/policy_loss ▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▁▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74796
wandb: best/eval_avg_mil_loss 0.85912
wandb:  best/eval_ensemble_f1 0.74796
wandb:            eval/avg_f1 0.72669
wandb:      eval/avg_mil_loss 0.80957
wandb:       eval/ensemble_f1 0.72669
wandb:            test/avg_f1 0.83974
wandb:      test/avg_mil_loss 0.61386
wandb:       test/ensemble_f1 0.83974
wandb:           train/avg_f1 0.79133
wandb:      train/ensemble_f1 0.79133
wandb:         train/mil_loss 0.45724
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rq9931yo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191113-rq9931yo/logs
wandb: Agent Starting Run: u07e6s6i with config:
wandb: 	actor_learning_rate: 0.00013691853133190058
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.26877156742890884
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8922221580386753
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191435-u07e6s6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u07e6s6i
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇▇▇▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▇▇█████████████████████████████████
wandb:       eval/ensemble_f1 ██▇▇▄▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▇▅▄▃▂▁▂▃▂▃▂▃▃▃▃▃▃▃▄▄▃▃▂▄▄▄▃▄▃▅▄▄▂▅▄▂▃
wandb:      train/ensemble_f1 ▇██▄▅▁▁▂▂▂▃▂▂▁▂▃▃▂▃▂▃▃▂▄▃▂▃▃▂▄▄▄▃▃▃▂▂▃▃▅
wandb:         train/mil_loss ▂▁▁▂▃▇▆▆▇▇▇▅▄▅▄▄▇▆█▇▅▅▄▇▅▅▆▆▆▄▅▇▇▆▆▄▇▆▆▅
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88
wandb: best/eval_avg_mil_loss 0.24236
wandb:  best/eval_ensemble_f1 0.88
wandb:            eval/avg_f1 0.79871
wandb:      eval/avg_mil_loss 1.34717
wandb:       eval/ensemble_f1 0.79871
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.64414
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.8485
wandb:      train/ensemble_f1 0.8485
wandb:         train/mil_loss 0.76442
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/538uhlg6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191301-538uhlg6/logs
wandb: Agent Starting Run: mdx3mbvn with config:
wandb: 	actor_learning_rate: 0.00018511385175786903
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9754903399272968
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4719553214608222
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191445-mdx3mbvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdx3mbvn
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▄▆▄▇▄▆▆▄▅▇▅▃▂▅▅▄▇▃█▆▁▅▄▇▆▇▆▄▄▃▁▇▅▃▅▅▂
wandb:      train/ensemble_f1 ▂▄▆▄▄▂▃▄▇▆▁▅▅▃▄▅▃▄▅▃▅▄▂▄█▅█▄▄▆▄▆▅▆▆▃▁▆▄▂
wandb:         train/mil_loss ▄▅██▃▆▆▃▄▇▆▄▆▅▁▃▆▆▄▃▅▅▅▅▆▄▅▁▃▂▄▆▄▅▂▆▅▅▅▅
wandb:      train/policy_loss ███████████████▃▃▃▂▁▃▄▃▃▂▂▂▂▂▃▂▁▃▃▃▃▃▅▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▄▅▄▂▂▁▂▃▄▃▁▂█▂▄▂▄▄▂▃▃▂▄▃▄▄▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79167
wandb: best/eval_avg_mil_loss 0.95031
wandb:  best/eval_ensemble_f1 0.79167
wandb:            eval/avg_f1 0.78214
wandb:      eval/avg_mil_loss 0.85607
wandb:       eval/ensemble_f1 0.78214
wandb:            test/avg_f1 0.60067
wandb:      test/avg_mil_loss 1.38152
wandb:       test/ensemble_f1 0.60067
wandb:           train/avg_f1 0.68659
wandb:      train/ensemble_f1 0.68659
wandb:         train/mil_loss 0.35285
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comfy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phll6ks8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191415-phll6ks8/logs
wandb: Agent Starting Run: zt9yb5rl with config:
wandb: 	actor_learning_rate: 5.0207112309806585e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7409098175604295
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9522434955981908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191559-zt9yb5rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zt9yb5rl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▆▄▄▂▃▆▆▃▅▃▄▃▄▄▂▃▄▁▇▅▅▆▇▃▅▆▆▄▆▄▄▃█▃▅▄▄
wandb:      train/ensemble_f1 ▆▅█▅▄▅█▃▅▅▄▅▄▁▇▄▂▄▅▅▆▅▅▆▇▄▅▂▆▄▂▅▄▅█▄▁▇▄▅
wandb:         train/mil_loss █▅█▄▆▅▃▅▆█▄▄▅▄▆▂▅▂▆▅▅▆▂▃▆▃▆▃▄█▄▄▁▅▆▆▇▂▄▄
wandb:      train/policy_loss ▄▇▇▄▅█▅▄▆▃▃▇▃▃▄▄▆▁▃▂▆▄▄▄▁▅▃█▇▇▅▅▃▅█▂▅█▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▅▅▅█▇▆▆▇▄▇▄▄▄▅▇▅▅▄▄▇▅▅▄▆▇▅▅▄█▆▇▁▄█▇▇▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.2901
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.27487
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.10617
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.89491
wandb:      train/ensemble_f1 0.89491
wandb:         train/mil_loss 0.26666
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u07e6s6i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191435-u07e6s6i/logs
wandb: Agent Starting Run: h07yjgyc with config:
wandb: 	actor_learning_rate: 1.6591217076546145e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08946284008141125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6065584300092698
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191618-h07yjgyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h07yjgyc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▆▇▆▇▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▁▂▃▆▄▄▅█▂▆▅▂▃▅▄▂▆▅▃▃▃▂▁▂▃▄▂▂▄▄▅▂▂▂▅▃▄▃
wandb:      train/ensemble_f1 ▅▅▁▂▂▆▆▇▇▆▃█▆▇▅█▄▂█▄▄▃▃▄▄▂▇▂▂▂▄▄▃▆▃▄▄▂▇▃
wandb:         train/mil_loss ▆▅▆▅▄▅█▅▅▇█▆▆▅▇▅▆▅▅▆█▆▂▃▇▁▁▃▅▄▇▇▆▃▄▅▅▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▂▂▁▁▁▁▁▁▁▁▁▂▂▁▁▂▂▂▁▂▁▂▂▁▂▁▁▁▁▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.2186
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.88946
wandb:      eval/avg_mil_loss 0.23176
wandb:       eval/ensemble_f1 0.88946
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.21652
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.89276
wandb:      train/ensemble_f1 0.89276
wandb:         train/mil_loss 0.31312
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdx3mbvn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191445-mdx3mbvn/logs
wandb: Agent Starting Run: vw4t0gbi with config:
wandb: 	actor_learning_rate: 1.874560896183517e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09937926909938222
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47670525958605847
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191630-vw4t0gbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vw4t0gbi
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅████▅▅
wandb:      eval/avg_mil_loss ▇▇▆▆▆▄▃▁▁▇▇▇▆▅▅▄▄▃▃▃█▇▇▇▇▇▆██▇▇▇▇▆▇▆▆▆▆▅
wandb:       eval/ensemble_f1 ███▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▅▅██▆▅▆▆▄▄▄▁▄▆▃▇▁▇▅▅▄▇▅▅▅▂▁▂▇▅▅▂▅▅▇▅▅▄
wandb:      train/ensemble_f1 ▄█▆▄▅▁▅▁▅▁▄▄▃▅▂▄▅▅▅▄▂▃▅▄▄▁▄▄▂▄▄▄▃▃▄▅▄▃▃▂
wandb:         train/mil_loss ▅▃▅▄▄▄▇▂▄▄█▆▃▄▁▂▃▃▃▃▃▇▃▅▃▇▄▃▃▇▆▄▂▅▃▃▄▄▄▄
wandb:      train/policy_loss █▂▃▄▃▄▄▃▄▂▄▃▅▆▅▁▃▄▂▄▄▅▃▂▆▄▄▅▂▄▇██████▂▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7348
wandb: best/eval_avg_mil_loss 0.87998
wandb:  best/eval_ensemble_f1 0.7348
wandb:            eval/avg_f1 0.72379
wandb:      eval/avg_mil_loss 0.86972
wandb:       eval/ensemble_f1 0.72379
wandb:            test/avg_f1 0.73906
wandb:      test/avg_mil_loss 0.94591
wandb:       test/ensemble_f1 0.73906
wandb:           train/avg_f1 0.75071
wandb:      train/ensemble_f1 0.75071
wandb:         train/mil_loss 0.30996
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zt9yb5rl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191559-zt9yb5rl/logs
wandb: Agent Starting Run: 40hqapnj with config:
wandb: 	actor_learning_rate: 0.001224426658922414
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2459926141567954
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6223201434625037
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191742-40hqapnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40hqapnj
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▆▆▆██████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▅▅▅▅▅▅▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▆▆▆▆▆██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▅▃▅▆▆▃▅▆▃▆▇▆▄▆▅▆▆▃▄▇▁▆▆█▅█▆▇▇▄▅▇▇▅▅▇▄
wandb:      train/ensemble_f1 ▄▄▅▃▄▃▇▅▇▅▆▄▅▃▇▇▃▆▄▆▆▅▄▄▅▆▇▇▇▄▁█▇▆▅▅▇▃▆▄
wandb:         train/mil_loss ▅▄▃▄▅▄▆▅▄▆▄▇▄▃▅▄▄▂█▃▅▃▄▅▂▂▅▂▃▃▂▄▅▆▃▃▃▅▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87923
wandb: best/eval_avg_mil_loss 0.27703
wandb:  best/eval_ensemble_f1 0.87923
wandb:            eval/avg_f1 0.87923
wandb:      eval/avg_mil_loss 0.26766
wandb:       eval/ensemble_f1 0.87923
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19777
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.91325
wandb:      train/ensemble_f1 0.91325
wandb:         train/mil_loss 0.2774
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vw4t0gbi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191630-vw4t0gbi/logs
wandb: Agent Starting Run: d0j8n7ps with config:
wandb: 	actor_learning_rate: 0.002067670882039256
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1105633055615618
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8404480466589974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191839-d0j8n7ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d0j8n7ps
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▃▆▆▆▆▆▆▆▆██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▄▄▄▄▄▄▄▃▃▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▄▄▄▄▄███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▂▃▅▃▁▃▄▃▄▅▄▃▄▃▅▅▆▆▅▄▃▃▆▄▅▄█▃▆▁▅▃▃▄▆▄▄
wandb:      train/ensemble_f1 ▅▅▄▄▄▆▄▁▇▅▃▃▃▄▇▃█▅▇▆▆▇▇▃▄▄▄▃▆▅█▅█▇▅▄█▆▅▇
wandb:         train/mil_loss ▇▂▄▃▅▅█▂▇▅█▄▆▄▃▃▄▅▇▅▂▂▅▄▄▅▄▃▆▅▄▁▃▄▅▆▂▃▃▁
wandb:      train/policy_loss ▇███▇▇▆▆▅█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.24889
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.23121
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.21619
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.9198
wandb:      train/ensemble_f1 0.9198
wandb:         train/mil_loss 0.18875
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h07yjgyc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191618-h07yjgyc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nw40y6xq with config:
wandb: 	actor_learning_rate: 0.0024861563400296253
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5082193963636877
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25270966519597937
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191919-nw40y6xq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nw40y6xq
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇█▇▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▅▄▃▅▄▇▆▃▄▃▄▅▂▂▃▃▆█▄▆▄▆▄▄▅▆▇▅▃▃▆▇▆▄▃▅▁▄
wandb:      train/ensemble_f1 ▃▃▅▄▄▄▄▄▄▆▅▄▅▅▅▂▆▇▃▆█▄▄▅▄▅▃▃▇▅▇▆▆▆▆▄▁▁▆▅
wandb:         train/mil_loss ▅▇▄▄▄▄▄▁▄▅▅▆▅█▅▆▅▄▆▂▅▅▃▅▇▅▄▄▅▄▃▅▂▆▆▄█▇▅▅
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.22693
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.19342
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.09595
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.92841
wandb:      train/ensemble_f1 0.92841
wandb:         train/mil_loss 0.22897
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40hqapnj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191742-40hqapnj/logs
wandb: Agent Starting Run: opc7iwl0 with config:
wandb: 	actor_learning_rate: 4.0241354888563215e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.52612138892722
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3808996332756419
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191931-opc7iwl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opc7iwl0
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▅▇█▇▅▂▅▄▆▇▂▆▆█▅▃█▅▅▆▃▆▇▆▇▄▁▄▇▆▄▆▄▇▄▅▄
wandb:      train/ensemble_f1 ▆▃▇▇▆▄▇▅▅▇▄▂▆▇▅▆▄█▅▄▃▄▆▇▆▄▁▆▇▆▂▄▆▇▄▅▅▄▆▅
wandb:         train/mil_loss ▂▅▅▃▃▄▆▇▆▃▄▃▇▅▂▃▅█▁▅▄▁▂▄▄▄▅▅▃▅▂▄▆▅▃▅▃▃▅▄
wandb:      train/policy_loss █▃▂▄▄▁▆█▄▁▅▅▅▆▁▂▁▆▄▁▄▆▁▃▄▇▆▅▅▃▁▁▁▁▃▄▁▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▇▅▄▂▇▁▂▅▆▇▁▃▄▅▅▇▃▂▆█▂▇▆▄▅▅▂█▂▂▃▄▇▄▅▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.30647
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.28212
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.12239
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.89533
wandb:      train/ensemble_f1 0.89533
wandb:         train/mil_loss 0.29726
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nw40y6xq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191919-nw40y6xq/logs
wandb: Agent Starting Run: qx3mzx4w with config:
wandb: 	actor_learning_rate: 0.00012627513370033302
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.028385970264928395
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7690041354069084
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192103-qx3mzx4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qx3mzx4w
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁███████████████████████████████████████
wandb:      eval/avg_mil_loss █▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁███████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▁▇▄▆▅▄▃▄▆▅▆▅▅▇▆▃▆▇█▅▃█▆▆▄▅▆▃▃▆▅▆▆▆▅▅▆
wandb:      train/ensemble_f1 ▅▂▃▁▂▃▂▅▃▃▄▄▄▃▃▅▆▆▆▃▅▂█▅▆▆▃▅▅▆▇▆▆▆▅▂▃▆▄▆
wandb:         train/mil_loss ▁▆█▁▆▇▅▂▃▄▅▃▇▅▂▄▆▇▄▇▅▅▆▄▆▃▃▅▁▇▃▃█▆▂▅▃▃▄▂
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86701
wandb: best/eval_avg_mil_loss 0.50715
wandb:  best/eval_ensemble_f1 0.86701
wandb:            eval/avg_f1 0.86701
wandb:      eval/avg_mil_loss 0.43567
wandb:       eval/ensemble_f1 0.86701
wandb:            test/avg_f1 0.74796
wandb:      test/avg_mil_loss 0.66957
wandb:       test/ensemble_f1 0.74796
wandb:           train/avg_f1 0.80216
wandb:      train/ensemble_f1 0.80216
wandb:         train/mil_loss 0.35243
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opc7iwl0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191931-opc7iwl0/logs
wandb: Agent Starting Run: zs8rdrjk with config:
wandb: 	actor_learning_rate: 2.2376023020228756e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8310855048500835
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0405212908990531
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192115-zs8rdrjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zs8rdrjk
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ███▇▇▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▃▃▅▅▇▆▇▆▅▅▅▇▅▅▅▅▇▅▆▅▆▆▇▇▅▇▄▅▅▆▅█▅▅▇▆▇
wandb:      train/ensemble_f1 ▃▁▃▁▄▆▅▆▅▇▇▄▇▄▅▆█▅▅▅▇█▇█▇█▅▄▆▆▆▇▇▇▅▆▇█▆▆
wandb:         train/mil_loss █▆▄▅▄▃▃▃▄▂▃▃▂▂▃▃▂▂▃▃▄▃▃▃▂▃▁▃▂▁▃▂▁▁▂▂▂▂▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92994
wandb: best/eval_avg_mil_loss 0.24258
wandb:  best/eval_ensemble_f1 0.92994
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.21525
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.33701
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.90354
wandb:      train/ensemble_f1 0.90354
wandb:         train/mil_loss 0.25619
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qx3mzx4w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192103-qx3mzx4w/logs
wandb: Agent Starting Run: zj1wy564 with config:
wandb: 	actor_learning_rate: 0.004760963800122452
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.218978856481166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17792514320100572
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192247-zj1wy564
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zj1wy564
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆▆▇▇▇▇████
wandb: best/eval_avg_mil_loss █▂▂▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▆▆▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:      eval/avg_mil_loss ████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▇▇▇▇▇█▇█▇▇██▇█▇██▇█▇██▇████████▇██████
wandb:      train/ensemble_f1 ▁▁▁█▇▇▇▇▇█▇██▇▇██▇▇▇▇████▇██▇█▇█████████
wandb:         train/mil_loss ██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.24275
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.24008
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.18739
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.89865
wandb:      train/ensemble_f1 0.89865
wandb:         train/mil_loss 0.32662
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d0j8n7ps
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191839-d0j8n7ps/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ebsl6g2f with config:
wandb: 	actor_learning_rate: 0.0007024992411475998
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17214672181600676
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4300442394994686
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192322-ebsl6g2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebsl6g2f
wandb: uploading history steps 314-326, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▃▃▃▃▃▃▅▅▃▃▃▃▃▃▅▆▆▆▆▆▆▆▆▆▆▆▆███████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▃▆▆▆▆▆▆▆▆▆▆██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▁▂▃▄▃▅▅▅▄▃▃▆▅▃▇▅▄▅▆▄▇▇▇▆▅▄▇▇▅▅▇▆▅▇▆▇▆█
wandb:      train/ensemble_f1 ▄▂▁▂▃▂▃▃▅▄▄▅▆▆▅▅▄▅▅▄▅▅▆▃█▆▃▅▇▆▆▅▅▇▅▅▄▅▆▆
wandb:         train/mil_loss ▆▃▂▅▅▇▂▂█▇▂▁▆▆▅▃▇▆█▇▂▂▃▂█▄▁▆▂▃▅▅▇▃▄▅▄▄▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▇▅█▁▁█▆▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▅▆█▁▁█▆█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56363
wandb: best/eval_avg_mil_loss 1.88646
wandb:  best/eval_ensemble_f1 0.56363
wandb:            eval/avg_f1 0.56363
wandb:      eval/avg_mil_loss 1.80002
wandb:       eval/ensemble_f1 0.56363
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.19964
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.50983
wandb:      train/ensemble_f1 0.50983
wandb:         train/mil_loss 0.56792
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zs8rdrjk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192115-zs8rdrjk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u5joafqb with config:
wandb: 	actor_learning_rate: 0.000275571893685754
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11943568969555383
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7221012278961679
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192640-u5joafqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u5joafqb
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▇▆▃▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▃▇▇▇▇▇▇▇▇▇██████████████████████████
wandb:      eval/avg_mil_loss ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▇▇▇▇▇▇▇▇▇█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▆▇▇██▇▇▇▇▇▇▇██▇█▇▇█████▇█▇█▇███▇▇█▇███
wandb:      train/ensemble_f1 ▁▁▁▁▇▇▇▇▇██▇▇██████▇▇█▇███▇▇███▇███▇████
wandb:         train/mil_loss █▅▃▄▄▄▃▃▄▄▅▃▃▃▂▁▃▃▃▂▃▄▂▂▃▁▃▃▃▄▃▂▁▄▁▂▃▁▃▄
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▆█▇█▇▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.24863
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.24363
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.35338
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.89618
wandb:      train/ensemble_f1 0.89618
wandb:         train/mil_loss 0.32236
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zj1wy564
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192247-zj1wy564/logs
wandb: uploading history steps 307-318, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▆▇▇▇▇▇▇██████████████
wandb:      eval/avg_mil_loss █▇▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▅▅▅▆▆▆▆▇▇▇▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▂▂▃▅▅▅▅▅▆▆▆▇▇▇█▇▇█▇▇█▇██▇███████████
wandb:      train/ensemble_f1 ▁▂▂▃▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇█▇▇▇█▇▇███▇
wandb:         train/mil_loss █▅▆▄▄▄▄▃▄▃▃▂▃▂▂▂▁▂▂▂▂▂▁▂▁▁▁▂▂▁▂▂▁▂▁▁▂▂▁▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▆▁▅▄▆▄▄▄▄▄▂▄▄█▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▅▄▄▄▆▄▁▄▄▄▄▁▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.39143
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.38163
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.90845
wandb:      test/avg_mil_loss 0.36072
wandb:       test/ensemble_f1 0.90845
wandb:           train/avg_f1 0.86228
wandb:      train/ensemble_f1 0.86228
wandb:         train/mil_loss 0.4008
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebsl6g2f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192322-ebsl6g2f/logs
wandb: uploading history steps 109-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▇▆▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▁▁▁▄▁██▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▇▇▇▆▇▇▅▃▃▃▁▁▁▁▁▁▃▃▂▃▂▂▂▃▆▆▆▇▇▆▇▇▇▇█▇▇██▇
wandb:       eval/ensemble_f1 ▃▃▃▃▃▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▆▅▅▅▂▁▂▁▄▂▅▄▃▄▃▄▅▇▅▃▄▄▂▃▅▅▄▃▄█▅▇▇▆▆▆▄
wandb:      train/ensemble_f1 ▅▅▆▅▃▅▄▃▁▂▅▅▇▅▅▄▅▆▄▄▆▅▃▄▄▄▆▅▆█▇▅▇▅▆▆▇█▇▅
wandb:         train/mil_loss ▂▃▂▆▄▅▇▅█▇▂▅▃▅▃▇▃▄▅▂▆▄▂▃▃▄▂▂▄▆▄▅▃▂▁▃▄▁▃▂
wandb:      train/policy_loss ▂▂▂▂▅▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92999
wandb: best/eval_avg_mil_loss 0.16726
wandb:  best/eval_ensemble_f1 0.92999
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.18354
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.90956
wandb:      test/avg_mil_loss 0.32491
wandb:       test/ensemble_f1 0.90956
wandb:           train/avg_f1 0.89099
wandb:      train/ensemble_f1 0.89099
wandb:         train/mil_loss 0.21872
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u5joafqb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192640-u5joafqb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: e8sqanuj with config:
wandb: 	actor_learning_rate: 0.006470247473507775
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4645760884965283
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3901905798174856
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192838-e8sqanuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e8sqanuj
wandb: Agent Starting Run: 6tlnipov with config:
wandb: 	actor_learning_rate: 0.00026358190904221193
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.35202032108023995
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4295104513940502
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192839-6tlnipov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6tlnipov
wandb: Job received.
wandb: Agent Starting Run: znztpxl2 with config:
wandb: 	actor_learning_rate: 3.348524043709248e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6546061586487975
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5893935917238348
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192844-znztpxl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znztpxl2
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▆▄▇▄▄▅▁▅▃▃▆▆▇▃▃▄▄▄▄█▂▂▅▁▃▆▆▅▄▆▄█▄▇▄▃▄▄
wandb:      train/ensemble_f1 ▂▇▆▂▆▃▃▃▃▅▅▃█▅▄▅▄▂▆▅▆▅▆▆▃▅▅▇▂▂▁▅▅▄▆▃▃▃▃▄
wandb:         train/mil_loss ▃▂▄▄▄▂▃▃▅▆▅▄▁▅█▃▅▅▃▄▄▃▄▅▅▄▂▄▃▄▄▃▄▃▂▄▅▅▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54762
wandb: best/eval_avg_mil_loss 5.06708
wandb:  best/eval_ensemble_f1 0.54762
wandb:            eval/avg_f1 0.54762
wandb:      eval/avg_mil_loss 4.91524
wandb:       eval/ensemble_f1 0.54762
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 5.7365
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.56363
wandb:      train/ensemble_f1 0.56363
wandb:         train/mil_loss 2.67756
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e8sqanuj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192838-e8sqanuj/logs
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇█▇██▇▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███▂▂▂▂▂▂▂▁▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅▂▅▅▂▇▄▇▇▅▄▄▇▅▄▄▁▃▆▅▃▄▆▄▆█▆▂▆▂▆▅▄▃▁▄▃▁
wandb:      train/ensemble_f1 ▄▆▂▄▆▂▅█▅▂▄▃▄▃▄▅▄▄▂▁▆▅▃▅▄▄▅▄▆▆▄▄▅▇▅▃▃▄▅▁
wandb:         train/mil_loss ▆▃▁▆▄▆▆▂▃█▅▃▇█▃▃▆▅▆▅▄▃▃▄▆▄▆▄▄▄▂▆█▄▂▂▅▇▁▄
wandb:      train/policy_loss ▆▃▃▂▆▃▃█▃▂▄▆▃▄▇▃▄▅▃▃▂▆▆▅▇▃▆▄▅▃▅▃▅▄▅▃▁▆▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆█▄▄▅▄▃▄▄▄▇▁▇▄▃▇▄▄▃▅▆▅▂▇▇▆▇▄▄▅▄▅▄▃▄▅▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.17016
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.91987
wandb:      eval/avg_mil_loss 0.16252
wandb:       eval/ensemble_f1 0.91987
wandb:            test/avg_f1 0.94914
wandb:      test/avg_mil_loss 0.09462
wandb:       test/ensemble_f1 0.94914
wandb:           train/avg_f1 0.91124
wandb:      train/ensemble_f1 0.91124
wandb:         train/mil_loss 0.20556
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6tlnipov
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192839-6tlnipov/logs
wandb: Agent Starting Run: uzz3nw1l with config:
wandb: 	actor_learning_rate: 0.0014807450235813065
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02786387639422294
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1287832247108598
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193022-uzz3nw1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uzz3nw1l
wandb: Agent Starting Run: zjeykf16 with config:
wandb: 	actor_learning_rate: 0.0004758668335499984
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.526054309636565
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5871252994956826
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193023-zjeykf16
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjeykf16
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▁▃▃▄▄▄▄▅▄▄▄▅▄▅▃▄▅▅▆▆▆▆▆▆▆▇▇▇██████████
wandb:       eval/ensemble_f1 ████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▅▂▄▆▅▅▆▄▇█▄▆▁▆▂▇▂▅▅▅▁▄▃▄▅▄▆▄▆▂▆▃▄▆▁▆▃
wandb:      train/ensemble_f1 ▄▅▄▅▂▆▄▅▅▅▃▂▄▅▄▆▁▂▃▆▅▃█▃▃▄▅▃▂▅▃▄▅▁▄▂▆▄▄▃
wandb:         train/mil_loss ▅▆▇▁▄▅▆▆▆▇▅▂▇▂█▅▅▆▅▇▄▂▂▁▂▂▂▁▄▅▂▅▅▆▅▅▄▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.23309
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.2373
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.94885
wandb:      test/avg_mil_loss 0.16662
wandb:       test/ensemble_f1 0.94885
wandb:           train/avg_f1 0.9174
wandb:      train/ensemble_f1 0.9174
wandb:         train/mil_loss 0.21829
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjeykf16
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193023-zjeykf16/logs
wandb: Agent Starting Run: gl9tagba with config:
wandb: 	actor_learning_rate: 1.250146439454924e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.21009932795400457
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07137895928258053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193206-gl9tagba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gl9tagba
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▃▇█
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆███████████████▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▃▃▇▇█▄▄▄▆▅▅▆▄▄▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▁▁▁▃▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▆███████████████████▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▆▆▅▅▅▄▆▇▅▇▅▆▄▄▆▅▆▂▇▅▆▅▇▇▅▇▅▆▄▄▅▇▆▅▂▇█
wandb:      train/ensemble_f1 ▄▄▁▃▆▆▅▇▆▅▅▇▇▇▇▇▆▇▅▄▇▇▆▅▅▆▇▆▆▅▆▆▇▆▅▆█▅▆█
wandb:         train/mil_loss ▅▄▃█▃▄█▆▆▄▂▄▃▃▅▂▄▅▄▃▄▆▃▆▆▂▃▃▂▂▆▅▆▂▄▁▅▄▂▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅█▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.31149
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.87957
wandb:      eval/avg_mil_loss 0.30885
wandb:       eval/ensemble_f1 0.87957
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.17607
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.93249
wandb:      train/ensemble_f1 0.93249
wandb:         train/mil_loss 0.22793
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gl9tagba
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193206-gl9tagba/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1z5ft6yy with config:
wandb: 	actor_learning_rate: 6.734235841189313e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.040551297978276946
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6774306753957645
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193442-1z5ft6yy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1z5ft6yy
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅▆█
wandb: best/eval_avg_mil_loss █▆▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅▆█
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▅▅▅▃▃▃▃▃▃▃▃▃▃▅▅▅▆▆▆▆▆▆▆▆▆▆███████
wandb:      eval/avg_mil_loss ██▇▇▇▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▅▅▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▂▃▅▄▂▁▄▄▅▆▅▄▇▅▆▃▆▅▃▅▆▆▅█▅▃▅▅▅▄▅▇▅▇▃▅▄
wandb:      train/ensemble_f1 ▃▂▆▂▁▄▃▄▃▄▆▆▅▄▄▆▃▅▅▅█▆▅▇▇▆▇█▇▆▇▇▄▆▃▇▆▃▆▄
wandb:         train/mil_loss ▆▄▆▇▅▃▄▆▃▄▄▂▆▇▅▁█▃▃▆▇▃▄▄▂▃▁▄▃▆▅▄▁▇▅▄▃▆▃▆
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.20009
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.19524
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.20996
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.91495
wandb:      train/ensemble_f1 0.91495
wandb:         train/mil_loss 0.26633
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uzz3nw1l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193022-uzz3nw1l/logs
wandb: Agent Starting Run: kv98rmhu with config:
wandb: 	actor_learning_rate: 0.0010897035582248193
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.36545554211297027
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17077691237618742
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193532-kv98rmhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kv98rmhu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss ██▇▆▆▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▃▃▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▃▄▄▄▄▅▄▃▅▅▅▄▄▄▅▅▅▄▆▅▄▅▆▆▅▅▇▆█▆█▆▇▇▆█▇
wandb:      train/ensemble_f1 ▂▂▁▁▄▅▄▄▃▃▃▃▃▄▅▅▇▆▅▃▅▆▆▅▅▄▅▆▇▇▆▇▇█▇▇▇▇█▇
wandb:         train/mil_loss ▇▅▅▅▆▅▅▄▅▃▅▇▇▅▅█▄▁▅▅▃▆▄▃▃▂▄▄▄▅▅▃▅▅▃▄▅▆▂▄
wandb:      train/policy_loss ▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 2.33124
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 2.25846
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 2.68506
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.49349
wandb:      train/ensemble_f1 0.49349
wandb:         train/mil_loss 0.95225
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znztpxl2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192844-znztpxl2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b6rcpkrj with config:
wandb: 	actor_learning_rate: 0.009709337231643246
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5699704931060353
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08782792022883001
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193624-b6rcpkrj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b6rcpkrj
wandb: uploading history steps 159-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▆▆▇█
wandb: best/eval_avg_mil_loss █▇▇▄▃▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▆▆▇█
wandb:            eval/avg_f1 ▁▁▃▃▃▃▃▄▄▄▇█████████▇▇▇▇▇███████▇▆▆▆▆▇▇▇
wandb:      eval/avg_mil_loss █▇▇▆▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▃▃▄▄▄▇▇███████▇▇▇▇███████▇▆▆▆▆▆▆▆▆▆▆▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▂▃▂▂▂▄▃▃▁▃▅▅▄▅▆▅▅█▆▆▆▇▆▆▇▆▆▆▆▅▆▆▅▇██▇
wandb:      train/ensemble_f1 ▃▁▃▄▄▃▃▂▃▃▄▂▅▇▄▄▅▆▆▆▆▅█▅▇▆▆▇▆▇▆▅▇▇▆▆▅▇▆▇
wandb:         train/mil_loss █▆▆▇▅▆▇▆▄▅▄▄▅▅▄▄▃▃▃▁▃▂▃▃▃▂▂▁▃▂▂▂▁▂▁▃▁▃▂▂
wandb:      train/policy_loss ▃▃▃▃▁▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91997
wandb: best/eval_avg_mil_loss 0.22072
wandb:  best/eval_ensemble_f1 0.91997
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.22189
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.22744
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.90371
wandb:      train/ensemble_f1 0.90371
wandb:         train/mil_loss 0.22341
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1z5ft6yy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193442-1z5ft6yy/logs
wandb: Agent Starting Run: j6vx901u with config:
wandb: 	actor_learning_rate: 2.857731854828749e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5799487042620005
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.055683762540413184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193718-j6vx901u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6vx901u
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅█
wandb: best/eval_avg_mil_loss ▁▁▁█
wandb:  best/eval_ensemble_f1 ▁▂▅█
wandb:            eval/avg_f1 ▆▆▇▄▃▂▁▁▁▁▄▅▅▅▅▅▆▆▆▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▂▃▄▆████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆
wandb:       eval/ensemble_f1 ▆▆▃▂▂▂▁▁▁▁▃▄▅▅▅▅▅▅▅▆▆▆▆██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅██▂▂▃▁▄▂▂▂▄▂▄▄▄▄▃▅▄▃▄▅▄▄▅▄▄▅▆▅▅▅▇▅▆▆▆▆▆
wandb:      train/ensemble_f1 ▇▇█▄▄▂▂▁▁▃▃▁▄▃▂▂▃▁▄▅▄▅▄▅▄▅▄▆▆▄▆▇▇▆▆▆▆▆▅▅
wandb:         train/mil_loss ▂▁▁▂▅▆▆▇█▇▅▆▆▇▇▆▇▇▅▃▃▅▄▅▅▄█▅█▄▄▇▄▆▄▇▅▅▃▇
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▁█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7426
wandb: best/eval_avg_mil_loss 3.24754
wandb:  best/eval_ensemble_f1 0.7426
wandb:            eval/avg_f1 0.73604
wandb:      eval/avg_mil_loss 3.02334
wandb:       eval/ensemble_f1 0.73604
wandb:            test/avg_f1 0.56267
wandb:      test/avg_mil_loss 5.107
wandb:       test/ensemble_f1 0.56267
wandb:           train/avg_f1 0.63554
wandb:      train/ensemble_f1 0.63554
wandb:         train/mil_loss 2.46113
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kv98rmhu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193532-kv98rmhu/logs
wandb: Agent Starting Run: tuyvauja with config:
wandb: 	actor_learning_rate: 0.0004775685298659634
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.013152601073706085
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38288691404334974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193853-tuyvauja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tuyvauja
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▁▁▂▂▃▃▁▂▃▃▂▂▃▃▄▄▄▄▅▇▄▇▇█▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂█▅▇▅▅▆▄▄▄▂▇▆▃▅▅▆▆▇▅█▃▅▆▄▄▁▄▄▇▄▂▄▃▅▃▅▃▇
wandb:      train/ensemble_f1 ▄▄▁▄▃▅▅▄▄▃▃▅▇▆▂▄▃█▅▂▄▅▆▄▂▅▄▃▄▃▄▃▂▃▅▅▃▄▃▇
wandb:         train/mil_loss ▄▃▁█▆▆▄▄▆▂▅▇▇▆▇▅▆▅▅▅█▅▅█▂▅▃▃▆▅▇▅▄▁█▂▃▃▂▄
wandb:      train/policy_loss ▃▄▄▅▄▂▂▄▁▃▄▄▄▆█▅▃▅▂▅▄▆▄▇▆▅▄▅▅▄▅▂▂▇▃▄▆▅▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅█▆▄▆▅▆▂▄▄▄▄▇▇▅▇▁▃▅▄▆▅▆▅▇▆▅▆▅█▇▄▄▄▄█▆▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87957
wandb: best/eval_avg_mil_loss 0.2516
wandb:  best/eval_ensemble_f1 0.87957
wandb:            eval/avg_f1 0.86936
wandb:      eval/avg_mil_loss 0.25436
wandb:       eval/ensemble_f1 0.86936
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.1578
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.92697
wandb:      train/ensemble_f1 0.92697
wandb:         train/mil_loss 0.25332
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6vx901u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193718-j6vx901u/logs
wandb: Agent Starting Run: 7vhxxmu6 with config:
wandb: 	actor_learning_rate: 4.7986869998315866e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2628085399663799
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03468193824235133
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193901-7vhxxmu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vhxxmu6
wandb: uploading history steps 191-202, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▂▄▂▅▅▄▇▅▇▄▂▃▄▄██▆▆█▅▄▅▅▇▂▁█▅▆▆▇▇▆▃▅█▅
wandb:      train/ensemble_f1 ▂▄▅▂▃▇▄▅▄▄▅▇▂▆▆▄▄▅▄▇▄▅▄▅▄▁▆▆▄█▆▄▆▅▅▄▅▃▇▅
wandb:         train/mil_loss ▄▃▅█▅▃▄▆▄▇▇▆▆▁▅▅▃▆▆▆▄█▆▆▃▅▂▄▄▅▆▅▁▆▃▂▄▄▃▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▅█▇▄▁▇▄▅▅▇▇▄▅▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▇▄▆▅▁▃█▅▄▆▇▄▆▆▇▇▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.28682
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.28109
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.12076
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.87846
wandb:      train/ensemble_f1 0.87846
wandb:         train/mil_loss 0.22819
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b6rcpkrj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193624-b6rcpkrj/logs
wandb: Agent Starting Run: 3ficrzwt with config:
wandb: 	actor_learning_rate: 0.000611622464739731
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5002498490024683
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9174393544461504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193941-3ficrzwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ficrzwt
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▁▁▂
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▅█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ██▇▇█▇▇▇▇▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▆██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▁▃▂▂▄▄▄▅▇▇▅▆▆▇█▆▆▇▆▇▆▇▆▆▇▆▇▆▇▆█▇▆▇▆▆▆
wandb:      train/ensemble_f1 ▁▁▁▃▄▄▅▆▄▇▅▃▇▆▅▅▅▆▆▆▆▆▅▅▇▆▅▅▅▅▅▆▆▇▇▆▅▅█▇
wandb:         train/mil_loss ▇▆▆█▆▄▄▅▃▂▃▂▂▁▁▂▁▃▃▂▁▂▃▃▅▃▁▁▃▂▁▂▃▁▂▂▃▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.24204
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.23248
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.43709
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.90125
wandb:      train/ensemble_f1 0.90125
wandb:         train/mil_loss 0.2284
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tuyvauja
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193853-tuyvauja/logs
wandb: Agent Starting Run: vxr57ufc with config:
wandb: 	actor_learning_rate: 0.0006904663404146032
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9990758025157648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04559727682278858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194053-vxr57ufc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vxr57ufc
wandb: uploading history steps 126-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss █▄▂▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 ▁▁▁▁▅███▅███▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▆▆▅▅▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▁
wandb:       eval/ensemble_f1 ▁▁▁▁████▅▅████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▄▂▅▆▃▂▃▅▅▃▆▄▄▄▅▃▅▅▆▃▄▄▆▃▄▅▆█▅▇▆▅▇▇█▆
wandb:      train/ensemble_f1 ▄▂▂▆▅▆▅▂▂▆▄▃▄▇▅▅▁▆▃▅▃▂▄▄▅▃▅▇▆▇▇▆▇▆▆█▇▆▇▆
wandb:         train/mil_loss ▇██▅▆▇▆▇▇▆█▇▄▅▅▄▄▄▅▄▆▆▄▁▅▃▅▂▄▅▇▃▅▄▆▆▆▇▄▄
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄█▁▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94
wandb: best/eval_avg_mil_loss 0.16711
wandb:  best/eval_ensemble_f1 0.94
wandb:            eval/avg_f1 0.91997
wandb:      eval/avg_mil_loss 0.16598
wandb:       eval/ensemble_f1 0.91997
wandb:            test/avg_f1 0.9089
wandb:      test/avg_mil_loss 0.17655
wandb:       test/ensemble_f1 0.9089
wandb:           train/avg_f1 0.91735
wandb:      train/ensemble_f1 0.91735
wandb:         train/mil_loss 0.23018
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vhxxmu6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193901-7vhxxmu6/logs
wandb: Agent Starting Run: 3jkvmisd with config:
wandb: 	actor_learning_rate: 3.65751026520346e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24873063380284344
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9887099210124928
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194115-3jkvmisd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jkvmisd
wandb: uploading output.log; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅█▆▃▅▅▇▆▅▇▆▆▅▆▄▅▆▆▅▄▂▆▆▅▃▆▅▅▆▅▄▆▆▂▆▁▅
wandb:      train/ensemble_f1 ▄▅▅▅▅▄▅▄▆▃▅▆█▅▅▅▅▃▆▄▆▅▅▅▅▅▆▄▅▄▅▅▃▅▆▂▅▆▁▅
wandb:         train/mil_loss ▁▄▄▂▅▃▆▄▆▃▅▃▃▆▃▄█▅▄▄▅▆▅▄▇▇▄▄█▃▂▂▆▄▅▄▇▇▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.29782
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.28133
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11763
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.90179
wandb:      train/ensemble_f1 0.90179
wandb:         train/mil_loss 0.26753
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ficrzwt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193941-3ficrzwt/logs
wandb: Agent Starting Run: wa5esj7u with config:
wandb: 	actor_learning_rate: 0.0005004089260158463
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29171175608442523
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10814897333240424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194124-wa5esj7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wa5esj7u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▅▁█
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▄▄▄▄▄▄██▂▁▅▅▅▄▄▄▄▄▄▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▅▅▅▄▄█▇▆▆▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▆█▁▄▂▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▃▁▅▁▅▄▂▄▅▅▅▄▃▆▅▅▄▇▇▇▅▅▆▄▅██▆▅▇▆▅▇▆▇█▇
wandb:      train/ensemble_f1 ▅▂▂▁▂▄▄▁▃▂▄▆▅▅▅▄▃█▅▆▄▆▇▇▇▅▇▆▅▆▇▅██▆█▅▇▆▇
wandb:         train/mil_loss ▄▆▄▄█▄▅▅▃▇▄▁▄▁▂▅▃▂▂▂▁▃▅▃▅▅▃▅▄▂▄▃▅▂▄▅▃▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▂▁▅▅▅▅▅▅█▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72917
wandb: best/eval_avg_mil_loss 0.98228
wandb:  best/eval_ensemble_f1 0.72917
wandb:            eval/avg_f1 0.70332
wandb:      eval/avg_mil_loss 0.78933
wandb:       eval/ensemble_f1 0.70332
wandb:            test/avg_f1 0.77921
wandb:      test/avg_mil_loss 1.12002
wandb:       test/ensemble_f1 0.77921
wandb:           train/avg_f1 0.8107
wandb:      train/ensemble_f1 0.8107
wandb:         train/mil_loss 0.30894
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vxr57ufc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194053-vxr57ufc/logs
wandb: Agent Starting Run: ke1k3wyw with config:
wandb: 	actor_learning_rate: 2.6668322898159328e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.01654640742714375
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25847604526404777
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194247-ke1k3wyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ke1k3wyw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅███████████████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▄▅▁▇▃▇▂▃▂▂▅▆▅▅▁▅▄▇▇▃▅▇▃▄▅▃▅▆▄▄▅▇▄█▅▇▆▆
wandb:      train/ensemble_f1 ▄▄▂▅▁▃▅▃▄▇▃▅▆▄▄▅▅▅▂▁▄▄▄▄▅▃▅▅▅▃▅▆▃▄▅▄▇▄▃█
wandb:         train/mil_loss ▆▆▆▆█▅▄▄▄▄▃▃▄▃▅▃▇▄▃▂▃▃▁▄▃▂▄▄▄▅▃▅▃▃▄▅▆▄▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.35795
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.33739
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.13199
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.90977
wandb:      train/ensemble_f1 0.90977
wandb:         train/mil_loss 0.32315
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wa5esj7u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194124-wa5esj7u/logs
wandb: Agent Starting Run: 7ppu1j62 with config:
wandb: 	actor_learning_rate: 0.0036798144416769576
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12014105315041534
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04891707418914437
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194502-7ppu1j62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ppu1j62
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▁▁▁▁▅▅▅▅▅▅▅▅▅▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▂▆▂▆▇▆▆▄▆▅▄█▄▅▄▄█▅▃▄▄▆▂▃▅▄▆▅▅▆▇▄▅▅▄▇▁
wandb:      train/ensemble_f1 ▄▁▅▅▄▃▆▆▅▃▅█▃▆▇▅█▅▆▅▃▅▆▆▁▆▆▁▃▇█▂▄▆▅▅▂▅▆▁
wandb:         train/mil_loss ▆█▅▇▅▄▂▆▂▄▆▄▄█▂▂▃▅▆▄█▅▆▃▄▅▄▂▃▅▁▅▅▆▂▅▃▃▃▁
wandb:      train/policy_loss ▇▇███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.21454
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.20409
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.95895
wandb:      test/avg_mil_loss 0.21971
wandb:       test/ensemble_f1 0.95895
wandb:           train/avg_f1 0.90625
wandb:      train/ensemble_f1 0.90625
wandb:         train/mil_loss 0.30441
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ke1k3wyw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194247-ke1k3wyw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d51p0osv with config:
wandb: 	actor_learning_rate: 8.412180917516931e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.016607570321683363
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3779843739903178
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194604-d51p0osv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d51p0osv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▇▇▇▅▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▃▃▆▅▅▆▅▅▅▅▆▆▇▇▇▇███████████▇▇▇▇▇▇▇▇▇▇█
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███████████▇▇▇▆▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▂▄▄▅▄▄▄▆▆▅▆▆▆▇▅▆▆▆▆▇▇▆▆▆▇▆▆█▆▇▇▇▇▇▆▆
wandb:      train/ensemble_f1 ▁▃▂▂▃▄▃▄▃▅▅▆▆▅▅▇▅▆▆▆▅▆▆▅▆▆▆▅▆▇▇▇▆▇██▆▅▆▆
wandb:         train/mil_loss ▅█▆▇▆█▇▆▄▆▅▅▆▄▅▄▅▅▄▅▁▃▃▃▅▄▃▄▃▃▂▂▃▂▂▂▁▂▂▂
wandb:      train/policy_loss █████████████▁█▄████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60114
wandb: best/eval_avg_mil_loss 1.66224
wandb:  best/eval_ensemble_f1 0.60114
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 1.53266
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 1.9357
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.56159
wandb:      train/ensemble_f1 0.56159
wandb:         train/mil_loss 1.01392
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jkvmisd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194115-3jkvmisd/logs
wandb: Agent Starting Run: zawf35u0 with config:
wandb: 	actor_learning_rate: 0.00014804772597136915
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8790298017521168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7999421231275897
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194610-zawf35u0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zawf35u0
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-4wtkfmd8'
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▂▂
wandb:       eval/ensemble_f1 ██████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▄▅▁▃▄▄▆▄▃▄▂▅▄▇▁▃▁▅▂▁▅▅▃▁▄▃▄▅▆▅▅▇▅▂▆█▅
wandb:      train/ensemble_f1 ▆▃▄▆▃▁▄▅▃▅▂▅▅█▅█▃▁▆▂▆▄█▃▇▆▆▃▄▁▂▂▆▇▅▆▆▄▇▅
wandb:         train/mil_loss ▆▄▆█▆▄▇▆▅▃▅▅▅▆▅▇▅▄▆▄▄▄▅▃▄▅▅▆▄▅▁▅▄▅▆▅▅▄▄▃
wandb:      train/policy_loss ██▇██▇▇███▇████████▇███████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▇█▇████▇████████████▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 3.54654
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 3.27074
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 4.25006
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.58631
wandb:      train/ensemble_f1 0.58631
wandb:         train/mil_loss 2.27497
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d51p0osv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194604-d51p0osv/logs
wandb: Agent Starting Run: kk3vkice with config:
wandb: 	actor_learning_rate: 0.007646597536532182
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4578962857549863
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.688516015113374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194743-kk3vkice
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk3vkice
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▁▆▃▃▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▄▆▁▃▂▅▃▄▃▂▃▃▄▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▆▇▆▆▆▇▇███
wandb:       eval/ensemble_f1 ███▁▁▃▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▃▇▅▆▅█▇▃▄▅▅▂▂▅█▇▂▂▅▅▄▄▄▁▅▂██▄▄▇▄▃▁▅▅▇▃
wandb:      train/ensemble_f1 █▆▅▆▆▄▆▅▂▆▄▆▄▅▇▂▅▆▅▅▃▄▅▄▆▅▃▅▅▁▃▅▆▃▅▆▄▄▃▄
wandb:         train/mil_loss ▅█▄▄▄▂▅▃▃▅▅▄▃▃▄▂▃▂▃▃▂▄▂▁▄▄▃▂▁▂▄▃▃▄▃▃▂▂▃▄
wandb:      train/policy_loss ▃▃▁▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.21408
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.87995
wandb:      eval/avg_mil_loss 0.22313
wandb:       eval/ensemble_f1 0.87995
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.12171
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.89595
wandb:      train/ensemble_f1 0.89595
wandb:         train/mil_loss 0.23711
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zawf35u0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194610-zawf35u0/logs
wandb: Agent Starting Run: vkjqri1g with config:
wandb: 	actor_learning_rate: 0.004907712161076753
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7634879958137506
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9670243820125068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194754-vkjqri1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkjqri1g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▆▆█
wandb: best/eval_avg_mil_loss ▇▁▆▆██
wandb:  best/eval_ensemble_f1 ▁▆▆▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▆▅▃▃▃▃▃▃▃▅▆▆▆▆▆▆█▆▆▆▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▅▄▃▂▂▁▃█▆▇▆▇▆▆▆▅▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▅▆▆▆▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆██▆▆▆▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅█▃▆▃▄▂▁▁▃▁▃▂▁▃▂▃▃▄▂▂▄▄▂▁▄▄▃▄▄▄▄▄▂▄▅▃▄
wandb:      train/ensemble_f1 ▁▄▅▆▆█▆▄█▄▃▅▃▄▄▃▃▃▅▅▄▄▃▄▃▅▄▅▆▃▅▅▆▄▇▄▅▅▃▄
wandb:         train/mil_loss ▂▅▂▁▃▃▅▂▇▆█▄▅▇▃▂▁▅▅▅▇▄▅▅▄▅▂▅▄▅▄▃▄█▃▄▅▆▂▂
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.30459
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.29679
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.22986
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.88375
wandb:      train/ensemble_f1 0.88375
wandb:         train/mil_loss 0.244
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ppu1j62
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194502-7ppu1j62/logs
wandb: Agent Starting Run: ltmtdbop with config:
wandb: 	actor_learning_rate: 0.000312650392250889
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.578329056046577
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.058388111149414224
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194829-ltmtdbop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ltmtdbop
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▁▄████▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁
wandb:      eval/avg_mil_loss █▅▄▃▃▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▄▄▄▄█████▅▅▅▅▅▅▅▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▄▂▁▄▄▃▃▅▂▃▃▅▂▆▇▃▃▇▄▃▅▅▅▃▅▇▄▄▅▄▄█▇▆▅▇▇
wandb:      train/ensemble_f1 ▄▄▃▄▁▂▃▂▄▃▁▃▃▄▂▅▃▃▆▃▅▅▇▅▆█▂▃▄▆▇▇▆▅▅▆▆▅▆▇
wandb:         train/mil_loss ▆▅▅▅▅▆▆▄▃▇█▆▅▂▅▃▅▄▂▅▄▃▄▃▂▄▃▄▆▅▁▃▄▅█▆▄▄▂▄
wandb:      train/policy_loss ▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▆▅▅████▂▃▂▃▁▃▁▂▂▂▂▂▂▂▃▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89936
wandb: best/eval_avg_mil_loss 0.21092
wandb:  best/eval_ensemble_f1 0.89936
wandb:            eval/avg_f1 0.87981
wandb:      eval/avg_mil_loss 0.19525
wandb:       eval/ensemble_f1 0.87981
wandb:            test/avg_f1 0.84
wandb:      test/avg_mil_loss 0.55804
wandb:       test/ensemble_f1 0.84
wandb:           train/avg_f1 0.87311
wandb:      train/ensemble_f1 0.87311
wandb:         train/mil_loss 0.25855
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkjqri1g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194754-vkjqri1g/logs
wandb: uploading history steps 127-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆██
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▆██
wandb:            eval/avg_f1 ▂▂▂▂▂▂▂▂▂▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▂▂▂▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▁▁▁███████████████████▇█████████████
wandb:      train/ensemble_f1 ▁▁▁▂▂▁▁▂▁▁▄█▇███████████▇█▇███▇█████████
wandb:         train/mil_loss ▇▆▇▇▆█▆▇▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.26082
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.27334
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.95866
wandb:      test/avg_mil_loss 0.19051
wandb:       test/ensemble_f1 0.95866
wandb:           train/avg_f1 0.84947
wandb:      train/ensemble_f1 0.84947
wandb:         train/mil_loss 0.32896
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk3vkice
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194743-kk3vkice/logs
wandb: Agent Starting Run: 3ycje1qp with config:
wandb: 	actor_learning_rate: 2.3475654598623876e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5622780096207396
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5791580911687285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194953-3ycje1qp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ycje1qp
wandb: Agent Starting Run: ok2fhi4y with config:
wandb: 	actor_learning_rate: 7.511952802734342e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.976480158538834
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6231328608491484
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194957-ok2fhi4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ok2fhi4y
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▄▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▅▆▅▅▇▅▄▆▅▆▆▅▅▃▅▄▃▁▇▅▆▅█▇▄▆▅▆▄▇▇▅▅▃▆▆▆
wandb:      train/ensemble_f1 ▅▅▃▅▇▅▇▅▄▄▆▅▅▃▆▇▅▄▃▃▃▅▁▅▅▆▅▆▄▆█▇▄█▆▆▇▇▆▆
wandb:         train/mil_loss ▃▄▃▃▃▄▅▆▄▄▇▅▅▄▆▆▆▁▃▂▃▄▄▃▄█▄▃▇▄▄▃▃▄▂▅▃▆▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.30236
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.28753
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11819
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.90307
wandb:      train/ensemble_f1 0.90307
wandb:         train/mil_loss 0.27249
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ltmtdbop
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194829-ltmtdbop/logs
wandb: Agent Starting Run: p9owskjc with config:
wandb: 	actor_learning_rate: 3.873831656062951e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3938397678778297
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9724635459596416
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195013-p9owskjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9owskjc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▄▄▅▅▁▁▄▂▆▃▃▅▃▅▅▆▆▃▅▅▇▅▃▃▅▆▇▄▅▄▅▄▅▆▆▇▇▅
wandb:      train/ensemble_f1 ▄▆▅▇▇▇▄▄▅▄▃▆▁▅▄▄▃▅▅▆▅▄▅▄▇▇▆▆▆▅▄█▄▄▇▇██▆▆
wandb:         train/mil_loss ▃▆▃▅▅▄▆▁▃▆▂▄▃▄▅▅▄▄▄▅▃▅▅▄▂█▃▃▅▄▄▄▁▆▅▅▂▃▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.23346
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.24278
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.94851
wandb:      test/avg_mil_loss 0.09344
wandb:       test/ensemble_f1 0.94851
wandb:           train/avg_f1 0.90875
wandb:      train/ensemble_f1 0.90875
wandb:         train/mil_loss 0.24726
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ycje1qp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194953-3ycje1qp/logs
wandb: Agent Starting Run: hadjofxw with config:
wandb: 	actor_learning_rate: 6.332767227101925e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17625735870737969
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8068821357488463
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195137-hadjofxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hadjofxw
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▁▄▅▄▂▄▄▄▃▆▄▆▅▄▆▅▇▇▅▅▄▄▅▄▆█▆▆▅▅▅▅▇▅▇▅▇
wandb:      train/ensemble_f1 ▃▄▁▂▆▄▂▄▄▃▄▆▅▄▄▇▅▅▅▅▆█▆▆▆▅▅▅▆▅▆▅▆▇▄▇▅▅▅▅
wandb:         train/mil_loss ▄█▅▄▄▇▅▅▇▆▆▂▇▃▁▅▇▆▅▂▄▆▅▄▃▆▂▅▃▃▁▇▂▇▅▆▃▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42241
wandb: best/eval_avg_mil_loss 2.89641
wandb:  best/eval_ensemble_f1 0.42241
wandb:            eval/avg_f1 0.42241
wandb:      eval/avg_mil_loss 2.73922
wandb:       eval/ensemble_f1 0.42241
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 3.32871
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.46492
wandb:      train/ensemble_f1 0.46492
wandb:         train/mil_loss 1.55556
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9owskjc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195013-p9owskjc/logs
wandb: Agent Starting Run: 95asf5vf with config:
wandb: 	actor_learning_rate: 5.439872449071029e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9056113563601904
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9207314297408802
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195156-95asf5vf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95asf5vf
wandb: uploading history steps 95-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁█████████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁█████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▇▄▆▆▇▆▄▅▄▆▃▅▇▆▅▆▃▇▁▄█▅▄▆▇▅▄▅▆▁▄▅▂▅▄▇▅
wandb:      train/ensemble_f1 ▃▄▄▅▆▅▃▄▄▇▆▅▁▆▄▄▅▄▂▅▄▆▅▅█▄▃▄▂▃▄▃▂▆▄▄▁▄▄▄
wandb:         train/mil_loss ▄▇▆▅▄▅▄▃▄▁▃▃▆▅▅▇▅▃▆▃▅▄▅▃▅▅▃▅█▅▄▂▁▅▆▆▄█▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.23016
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.21443
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.17403
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.91494
wandb:      train/ensemble_f1 0.91494
wandb:         train/mil_loss 0.23931
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hadjofxw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195137-hadjofxw/logs
wandb: Agent Starting Run: dvjyboj1 with config:
wandb: 	actor_learning_rate: 8.663654747260874e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6023394291993066
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13279896984981232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195326-dvjyboj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dvjyboj1
wandb: uploading history steps 218-224, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆█
wandb: best/eval_avg_mil_loss ▄█▆▅▁
wandb:  best/eval_ensemble_f1 ▁▂▄▆█
wandb:            eval/avg_f1 ▂▂▂▁▁▃▃▃▅▅▆▆▆▆▆▆▆▆▆▆▆███████████████████
wandb:      eval/avg_mil_loss ▄▄▄▆███▇▇▇▇▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▁▁▁▁▃▃▅▅▅▅▆▆▆▆▆█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▁▂▃▁▁▂▂▃▁▂▄▄▂▂▂▁▄▂▄▅▄▆▅▆▅▄▄▃▄▄▆▄█▆▅▆▆▅
wandb:      train/ensemble_f1 ▅▂▂▂▃▂▂▃▃▃▄▆▅▇▃▄▃▁▆▃▅▄▆█▅█▄▅▅▆▆▆▆▇▆▇▇▇▆▇
wandb:         train/mil_loss ▂▂▅▂▂▄▂█▂▂▂▂▂▄▁▁▂▂▄▇▂▃▂▃▂▄▂▄▂▂█▃▂▂▁▂█▂▂▂
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 4.72857
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 4.68707
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 5.53426
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.44747
wandb:      train/ensemble_f1 0.44747
wandb:         train/mil_loss 0.29227
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ok2fhi4y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194957-ok2fhi4y/logs
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ████████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▆▆▄▅▇▁▇▅▆▆▅█▄▅▆▄▅▄▅▅▄▃▅▃▇▃▅▅▇▅▄▄▅▆▆▆▅▂
wandb:      train/ensemble_f1 ▄▅▅▇▅▇▅▅▃▆▆▅▆▆▄█▄▅▅▆▅▃▅▄██▁▅▄▄▇▃▅▄▄▆▆▅▄▄
wandb:         train/mil_loss ▃▄█▂▅▅▆▃▅▅▄▄▂▆▃▁▅▄▅▄▄▂▄▄▃▇▅▆▇▄▄▃▃▆▂▁▆▄▄▃
wandb:      train/policy_loss ██████████████████████████████████████▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.28985
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.32842
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.11545
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.87723
wandb:      train/ensemble_f1 0.87723
wandb:         train/mil_loss 0.24844
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95asf5vf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195156-95asf5vf/logs
wandb: Agent Starting Run: bna1ar62 with config:
wandb: 	actor_learning_rate: 2.964502659562407e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9189289110823542
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04459459375468022
wandb: Agent Starting Run: cu5i2wdm with config:
wandb: 	actor_learning_rate: 0.0007773179912646426
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6950803579555918
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6739549633600951
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195339-bna1ar62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bna1ar62
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195340-cu5i2wdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cu5i2wdm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▅▆█▇▆▅▇▆▅█▇▃▆▃▂▃▄▃▄█▃▁▄▃▆▆▄▃▅▁▃▆▁▅▄█▄▇
wandb:      train/ensemble_f1 ▄▅▄▆▆▅▅▆▇▅█▆▇▆▃▄▃▅▆▂▁▃▅▅▄▃▄▅▄▁▄▄▇▄▅▆▃▂▁▃
wandb:         train/mil_loss ▅▅▅▃▃▂▂▂█▄▃▆▂▂▃▅▃▅▅▆▃▄▅▅▅▅▄▂▅▃▅▃▃▁▁▄▃▄▃▂
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.31905
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.36603
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.96888
wandb:      test/avg_mil_loss 0.10419
wandb:       test/ensemble_f1 0.96888
wandb:           train/avg_f1 0.87523
wandb:      train/ensemble_f1 0.87523
wandb:         train/mil_loss 0.23432
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bna1ar62
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195339-bna1ar62/logs
wandb: Agent Starting Run: w05ouqom with config:
wandb: 	actor_learning_rate: 0.0005326834806710656
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7299850889120901
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5247117298132044
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195524-w05ouqom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w05ouqom
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-9nyqnpo8'
wandb: uploading history steps 187-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▆▆▅▄▃▃▃▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇▇███████████████▇▇▇▇▇████
wandb:      eval/avg_mil_loss █▇▆▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████████████▇▇▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▂▅▄▄▄▄▆▆▆▆▆▇▆█▅▅▇▆▆▆▇▇▆█▆▇█▇█▇▇▇▇▇█▇▇
wandb:      train/ensemble_f1 ▂▁▃▃▂▃▄▅▅▇▄▆▆▆▆▇▆▆▅▆▇▇▇▇▇▆▆▇▇▇▇█▇▆█▆▇█▆▇
wandb:         train/mil_loss ██▅▅▅▄▅▃▄▆▅▆▄▄▃▅▃▂▄▃▄▁▃▅▃▄▃▆▃▃▄▃▄▃▅▁▃▂▃▄
wandb:      train/policy_loss ▄▄▄▂▄▄▂▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁████▅██████▁██████████████████████▃██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.23477
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.90992
wandb:      eval/avg_mil_loss 0.22452
wandb:       eval/ensemble_f1 0.90992
wandb:            test/avg_f1 0.91883
wandb:      test/avg_mil_loss 0.25276
wandb:       test/ensemble_f1 0.91883
wandb:           train/avg_f1 0.88988
wandb:      train/ensemble_f1 0.88988
wandb:         train/mil_loss 0.26712
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dvjyboj1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195326-dvjyboj1/logs
wandb: Agent Starting Run: l7ocawzc with config:
wandb: 	actor_learning_rate: 0.00712667989206157
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17574266078747858
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9113423248801408
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195642-l7ocawzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l7ocawzc
wandb: uploading history steps 125-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁███████████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▅▅▅▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁███████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▁▄▃▅▂▃▆▅▅▅▆▃▄▅▅▅▅▇▇▄▇▅▃█▆▅▅▃█▅▄▅▅▄▆▃▃▃
wandb:      train/ensemble_f1 ▂▄▄▃▇▄▃▄▁▅▅▃▅▃▁▃▅▂▅▅▇▄▃▅▄▃▃▄█▄▇▄▃█▄▄▄▄▆▄
wandb:         train/mil_loss ▃▆▅▃█▃▅▅▃▄▆▄▆▄▃▄▄▇▄▄▅▃▃▄▂▃▅▅▅▃▅▆▂▄▁▃▅▃▃▄
wandb:      train/policy_loss ▁▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76887
wandb: best/eval_avg_mil_loss 0.67835
wandb:  best/eval_ensemble_f1 0.76887
wandb:            eval/avg_f1 0.76887
wandb:      eval/avg_mil_loss 0.64807
wandb:       eval/ensemble_f1 0.76887
wandb:            test/avg_f1 0.79968
wandb:      test/avg_mil_loss 0.74926
wandb:       test/ensemble_f1 0.79968
wandb:           train/avg_f1 0.78673
wandb:      train/ensemble_f1 0.78673
wandb:         train/mil_loss 0.31122
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w05ouqom
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195524-w05ouqom/logs
wandb: Agent Starting Run: 3kay9y3g with config:
wandb: 	actor_learning_rate: 2.9521415149510083e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7003543805604158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8496444300166388
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195738-3kay9y3g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3kay9y3g
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▆▆▇▇▇████▆█▇▆▇▇▅▅▅▇▅▇▅▅▃▅▅▃▃▅▅▅▅▁▂▂▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▂▆▃▄▅▁▃▄▃▃▄▁▅▄▂▃▃▄▃▄▅▆▃▄▇▃▄▃▅▃▇▃▂▄█▃▂▁
wandb:      train/ensemble_f1 ▅▆█▂▄▅▃▃▄▄▃▅▄▆▅▂▅▄▄▁▆▆▄▄▂▇▃▃▄▅▇▄▄▁▄▄▄▇▅▄
wandb:         train/mil_loss ▅▅▃▂▃▄▃▆▅▅▂▄▂▆▆▄▅▅▅▄▄▅▇▅▄▆▅▅▅█▅▅▃▂▁▄▃▄▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.24421
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.23688
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.87879
wandb:      test/avg_mil_loss 0.3373
wandb:       test/ensemble_f1 0.87879
wandb:           train/avg_f1 0.90743
wandb:      train/ensemble_f1 0.90743
wandb:         train/mil_loss 0.23794
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l7ocawzc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195642-l7ocawzc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qw2mtt4k with config:
wandb: 	actor_learning_rate: 0.003006549785816237
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8406141493084964
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8218541157753982
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195853-qw2mtt4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qw2mtt4k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss ▁▃██
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▃█▆▆▃▆███████▆▆▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▂▁▃▃█████▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▃▁▆▆▃▆▆▆▄▄█████▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇█▅▆▄▄▄▄▁▄▅▅▂▃▄▄▄▄▄▄▄▅▂▄▁▃▄▄▃▃▄▄▄▃▃▃▄▄▅
wandb:      train/ensemble_f1 █▅▅▇▅▃▃▃▃▂▃▂▄▄▄▄▄▃▄▃▃▂▄▃▄▄▄▁▁▃▃▃▃▂▅▂▃▃▄▂
wandb:         train/mil_loss ▇▁▆▇▄▆▃▇▆▆▃█▆▂▃▆▅▄▆▂▃▄▂▄▄▆▅▆▄▅▅▃▄▄▂▃▄▄▃▅
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅██████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88
wandb: best/eval_avg_mil_loss 0.39364
wandb:  best/eval_ensemble_f1 0.88
wandb:            eval/avg_f1 0.84986
wandb:      eval/avg_mil_loss 0.3885
wandb:       eval/ensemble_f1 0.84986
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.27497
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.86992
wandb:      train/ensemble_f1 0.86992
wandb:         train/mil_loss 0.24867
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qw2mtt4k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195853-qw2mtt4k/logs
wandb: Agent Starting Run: y1x766lo with config:
wandb: 	actor_learning_rate: 0.0005746141002792541
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7513629641164006
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6892098209305952
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200106-y1x766lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1x766lo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss █▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▂▁▁▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇██████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▃▃▃▄▄▄▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁▁▂▂▂▃▃▃▄▅▅▅▆▆▇▇▇▇▇▇██▇█████▇█▇█▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▁▂▂▃▂▂▃▂▃▃▃▄▄▅▄▄▅▅▆▆▆▆▇▇█████▇▇██▇▇█▇▇
wandb:         train/mil_loss █▆█▃▃▇▅▇▅▆▃▂▂▂▃▃▁▂▆▅▄▃▂▃▂▄▁▂▂▃▃▆▃▃▃▄▅▃▅▄
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇█▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79798
wandb: best/eval_avg_mil_loss 0.53086
wandb:  best/eval_ensemble_f1 0.79798
wandb:            eval/avg_f1 0.76718
wandb:      eval/avg_mil_loss 0.49359
wandb:       eval/ensemble_f1 0.76718
wandb:            test/avg_f1 0.76942
wandb:      test/avg_mil_loss 0.5362
wandb:       test/ensemble_f1 0.76942
wandb:           train/avg_f1 0.724
wandb:      train/ensemble_f1 0.724
wandb:         train/mil_loss 0.40719
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cu5i2wdm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195340-cu5i2wdm/logs
wandb: Agent Starting Run: lavx6j4y with config:
wandb: 	actor_learning_rate: 0.00299689889029548
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7525474793414433
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7262694629783558
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200233-lavx6j4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lavx6j4y
wandb: uploading history steps 394-396, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▅▅▅▅▄▄▄▃▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▃▃▃▃▅▅▅▅▅▅▅▆▇▆▆▆▇▇▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▃▃▆▅▅▅▅▆▅▅▅▆▇▇▇▇▇▇▆▇█▆█▇▇▇▆▇▇▆▇▆▇▇▇▆▇
wandb:      train/ensemble_f1 ▂▂▁▅▄▄▅▅▆▅▇▆▇▆▆▆▇▆▆▆▇▆▇▇▇▇▇█▇▆▆▇▇▆▅▇▆▇█▇
wandb:         train/mil_loss ▆▃▇▆▆▅▆▃▆▂▅▂▄▆▄▄█▅▄▇▃▂▄▅█▅▁▃▇▇██▅▅▃▇▄▅▄▆
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁▃████████████████████▇███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86999
wandb: best/eval_avg_mil_loss 0.39559
wandb:  best/eval_ensemble_f1 0.86999
wandb:            eval/avg_f1 0.86988
wandb:      eval/avg_mil_loss 0.38875
wandb:       eval/ensemble_f1 0.86988
wandb:            test/avg_f1 0.87923
wandb:      test/avg_mil_loss 0.27465
wandb:       test/ensemble_f1 0.87923
wandb:           train/avg_f1 0.85748
wandb:      train/ensemble_f1 0.85748
wandb:         train/mil_loss 0.27184
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3kay9y3g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195738-3kay9y3g/logs
wandb: Agent Starting Run: wigxxn9r with config:
wandb: 	actor_learning_rate: 0.0011487725458643116
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.020218781760386717
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5075256322303976
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200401-wigxxn9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wigxxn9r
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▅▃▂▅▅▆▅▆▆▃▁▆▃▄▅▃▇▄▃▄▄▅▅█▃▅▄▅▄▂▅▂▇▄▇▂▄▇
wandb:      train/ensemble_f1 ▄▂▄▂▆▄▅▇▁▆▄▅▇▄▄▅▄▅▄▄▄█▄▅▆▅▅▇▅▃█▆▅█▄▄▃▆▅▃
wandb:         train/mil_loss ▆▅▄▄▁▃▃▅▄▂▃▄▆▅▃▅▅▃▃▄▃▃▄▄▃▄▆▄█▂▅▄▄▃▄▅▄▄▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.26659
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.28474
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.92609
wandb:      test/avg_mil_loss 0.19893
wandb:       test/ensemble_f1 0.92609
wandb:           train/avg_f1 0.85044
wandb:      train/ensemble_f1 0.85044
wandb:         train/mil_loss 0.32188
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lavx6j4y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200233-lavx6j4y/logs
wandb: Agent Starting Run: e9il7d7w with config:
wandb: 	actor_learning_rate: 0.00032635218037565096
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5606639463544283
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9710114230327032
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200416-e9il7d7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9il7d7w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss ▁██
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▆▆▆▆▁████▆▆▆▆▆▆▅▅▅▅▅▃▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▁▁▁▅▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:       eval/ensemble_f1 ▅▅▅▇█▅▇▇▇▇▅▅▅▅▅▅▅▅▅▃▃▁▁▁▁▁▁▁▃▃▃▃▃▃▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▁▃▂▁▂▄▂▃▁▂▂▃▂▅▂▂▃▅▇▄▅▆▆▄▂▃▅▄▅▄▆▄▆█▅▇▄
wandb:      train/ensemble_f1 ▂▂▇▃▂▃▃▁▅▅▁▂▅▃▃▄▃▃▃▅▂▃▅▇▄▃▃█▅▄▆▄▆▅▂▇▆▇▆▅
wandb:         train/mil_loss ▂▃▄▁▁▅▅▆▇▅▅▇███▇▇▅▇▆▄▆▅▆▇▅▆▄▅▅▅▆▆▆▄▄▅▄▅▄
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.48589
wandb: best/eval_avg_mil_loss 2.43004
wandb:  best/eval_ensemble_f1 0.48589
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.29305
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 2.85647
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.45362
wandb:      train/ensemble_f1 0.45362
wandb:         train/mil_loss 1.82664
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wigxxn9r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200401-wigxxn9r/logs
wandb: Agent Starting Run: 71gdxzrz with config:
wandb: 	actor_learning_rate: 0.0037364832264729538
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.47717785029495385
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9662650990034768
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▅▅▅▆▆▆▆▇██
wandb: best/eval_avg_mil_loss ███▇▆▆▅▅▄▄▃▃▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▅▅▅▆▆▆▆▇██
wandb:            eval/avg_f1 ▁▂▁▂▂▃▃▃▄▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▆▆▆▆▆▇▇▇▇▇
wandb:      eval/avg_mil_loss ▆▇▇▇█▆▆▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▁▁▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▆▆▆▆▆▆▆▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▃▃▄▄▅▅▅▅▆▅▅▆▆▆▇█▇▇▇▇▆▇██▇▇▆▇▆▇▆▇█▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▃▂▃▅▄▄▆▄▅▅▆▇▆▇█▇▇▇▇▆▇▇▇▇▇▅▆▆▆▇▇▇▇▆▆█▇▇
wandb:         train/mil_loss ▆█▃▄▆▆▃▅▅▅▃▂▅▃▄▃▃▅▃▃▃▁▂▂▄▂▂▄▃▄▄▃▃▃▂▄▄▃▄▂
wandb:      train/policy_loss █▁█████████████████████████████████▂████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▆▆▆▆▆▆▆▆▆▆▆▆▂▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75
wandb: best/eval_avg_mil_loss 0.68118
wandb:  best/eval_ensemble_f1 0.75
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.6921
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.6624
wandb:      test/avg_mil_loss 0.56975
wandb:       test/ensemble_f1 0.6624
wandb:           train/avg_f1 0.67385
wandb:      train/ensemble_f1 0.67385
wandb:         train/mil_loss 0.33131
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1x766lo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200106-y1x766lo/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200550-71gdxzrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71gdxzrz
wandb: Agent Starting Run: qkmm5d5h with config:
wandb: 	actor_learning_rate: 0.001467259604569596
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.32376821224714547
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.912509383729652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200603-qkmm5d5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkmm5d5h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▇▃▃▁██▅▁▂▆▅▅▃▄▆▃▂▄▄█▄▇▃▆▇▂▇▇▂▁▁▄▄▆▆▃▆
wandb:      train/ensemble_f1 ▅▃▃▆▂▅▄█▁▃▄▅▃▄▄▇▃▃▃▄▅▃▄▅▂▇▇▂▄▁▄▁▃▂▆▂▁▆▄▅
wandb:         train/mil_loss █▆▅▂▄▇▆▆▂▄▄▃▂▄▄▂▃▅▂▁▅▃▃▄▂▃▃▁▂▂▂▄▄▄▂▂▁▂▂▃
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88972
wandb: best/eval_avg_mil_loss 0.22841
wandb:  best/eval_ensemble_f1 0.88972
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.23704
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.9179
wandb:      test/avg_mil_loss 0.40655
wandb:       test/ensemble_f1 0.9179
wandb:           train/avg_f1 0.9162
wandb:      train/ensemble_f1 0.9162
wandb:         train/mil_loss 0.33325
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9il7d7w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200416-e9il7d7w/logs
wandb: Agent Starting Run: v0whbmbb with config:
wandb: 	actor_learning_rate: 2.4438886693879828e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2216878839976737
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8765752563711147
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200626-v0whbmbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v0whbmbb
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▁▁▁██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ████▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▁▃▂▄▁▃▅▇▄▆▇▅▅▄▆▇▇▇▆▇▆▄▇▇▅▆▅▅▃▄█▅▅▇▇▇▇█
wandb:      train/ensemble_f1 ▁▃▃▃▂▃▅▄▃▆▆▅▄▅▅▆▅▆▆▆▆▇▆▄▄▇▇▆▆▇▅▅▅▅▇▆▃█▅▆
wandb:         train/mil_loss █▅▇▆▄▃▆▅▇█▂▅▇▆▄█▅▄▃▇█▆▄▇▇▃▆▄▁▅▄▄▆▆▇▃▅▆▆▄
wandb:      train/policy_loss ▇█▄▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.25128
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.88972
wandb:      eval/avg_mil_loss 0.21842
wandb:       eval/ensemble_f1 0.88972
wandb:            test/avg_f1 0.97933
wandb:      test/avg_mil_loss 0.07772
wandb:       test/ensemble_f1 0.97933
wandb:           train/avg_f1 0.935
wandb:      train/ensemble_f1 0.935
wandb:         train/mil_loss 0.20581
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkmm5d5h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200603-qkmm5d5h/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nvou870s with config:
wandb: 	actor_learning_rate: 0.003284318350692618
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1624066098388377
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7808006305712034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200805-nvou870s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nvou870s
wandb: uploading history steps 141-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇█
wandb: best/eval_avg_mil_loss ▁▆█▇▇▇
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▅▅▇█████▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▄▄▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄██████████▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▃▃▁▃▃▃▃▃▄▄▅▅███▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▁▂▂▂▃▄▃▃▄▃▅▄▅▆▆▆▅▆▅▇▇▆▆▆▇▆█▇▇▇██▇███▇
wandb:      train/ensemble_f1 ▁▁▁▁▃▃▂▃▃▃▄▃▃▃▄▅▆▄▆▅▅▆▅▆▆▅▆▇▆▆▇▆▇▇▆██▆▇█
wandb:         train/mil_loss ▇▆▂▆▃▃▆▅▇▃▁▆▂▃▃▂▆▄▅▄▄▄▆▅▃▅▄▆▅▄▃▅▅▆▃▃▆▄▆█
wandb:      train/policy_loss ▅▅▅▅▅▅█▅▅▅▅▄▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 1.90725
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.53276
wandb:      eval/avg_mil_loss 2.12596
wandb:       eval/ensemble_f1 0.53276
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 2.19448
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.60915
wandb:      train/ensemble_f1 0.60915
wandb:         train/mil_loss 1.51801
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v0whbmbb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200626-v0whbmbb/logs
wandb: Agent Starting Run: npdstmtt with config:
wandb: 	actor_learning_rate: 0.0008281862604685957
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41927587128915456
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.972571373802504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200901-npdstmtt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/npdstmtt
wandb: uploading history steps 223-233, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss ▅▅█▇▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆██████████████
wandb:      eval/avg_mil_loss ▆████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▃▃▂▅▃▆▄▄▃▄▄▄▆▅▅▆▅▆▅▄▆█▅▇▄▅▆▅▆▇▅▇▅▆▆▅
wandb:      train/ensemble_f1 ▁▂▄▃▃▃▆▄▃▃▅▃▅▄▆▆▄▆▅▅█▇▄▄▅█▆▇▅▅▇▆▄▄▅█▆▆▅▅
wandb:         train/mil_loss ▄▄█▅█▃█▂▂▁▃▇▇▅▃▄▃▆▅▅▅▄▅▃▄▃▄▅▅▅▆▃▅▄▆▄▆▄▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇▇▆█▆▆▃█▃▃▆▆▃▅▂▁▆▃▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53119
wandb: best/eval_avg_mil_loss 2.41633
wandb:  best/eval_ensemble_f1 0.53119
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 2.28719
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.46524
wandb:      test/avg_mil_loss 2.7743
wandb:       test/ensemble_f1 0.46524
wandb:           train/avg_f1 0.50647
wandb:      train/ensemble_f1 0.50647
wandb:         train/mil_loss 0.96663
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71gdxzrz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200550-71gdxzrz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3ngfng8k with config:
wandb: 	actor_learning_rate: 4.2575708545829815e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8369696591628021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6771374411223979
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200942-3ngfng8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ngfng8k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁███▅▅▅███████████████████████████████
wandb:      eval/avg_mil_loss ██▅▄▃▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁█▅▅▅▅████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆▂▂▁▄▄▅▅▅▃▅▇▄▄▄▅▁▄▃▂▆▅▄▅█▄▆▄▆▇▂▆▅▆▅▅▄▅
wandb:      train/ensemble_f1 ▅▆▄▄▄▃▂▇▄▅▃▁▂▁▂▂▁▁▆▂▄▃▂█▄▆▇▄▆▁▅▄▅▅▅▂▅▅▇▄
wandb:         train/mil_loss ▂▃▂▂▆█▅▃▃▃▄▅▃▇▃▃▅▅▂▂▃▁▃▆▃▁▃▄▃▆▃▂▄▅▂▄▅▂▂▂
wandb:      train/policy_loss ▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇██▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.25603
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.22554
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.94914
wandb:      test/avg_mil_loss 0.20113
wandb:       test/ensemble_f1 0.94914
wandb:           train/avg_f1 0.90998
wandb:      train/ensemble_f1 0.90998
wandb:         train/mil_loss 0.23185
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nvou870s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200805-nvou870s/logs
wandb: Agent Starting Run: lwozepn5 with config:
wandb: 	actor_learning_rate: 0.005523715611580281
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5992383972493951
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32990924860029236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200955-lwozepn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lwozepn5
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▄▄▅▇▇▇▇▇▇▇▇▇▇▅▂▂▁▁▄▃▃▃▄▇▇▇▇██▇▄▄▃▂▂▃▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▄▇▅▆▅▃▅▆▇▄▁▃▇▄▄▄▄▅▄▄▂▇▆▅▆▃▆▅▅▅█▅▆▁▃▆▆
wandb:      train/ensemble_f1 ██▄▃▅▆▄▃▇▆▆▄▆▇▅▆▂▄▆▄▃▄▄▅▄▃▃▃▅▄▅▄█▅▂▆▁▅▆▆
wandb:         train/mil_loss ▇▄▇▅█▅▅▃█▄▃▅▁▃▅▆▄▄▃▂▄▃▄▄▄▆▃▅▅▄▃▅▃▃▅▃▅▄▂▅
wandb:      train/policy_loss ▂▃▄▆▁▂▃▅▃▂▅▂▄▅▆▇▆▆▁▃▂▆▄▂▂▂▅▄▂▂▄▃▅▂▆▃█▆▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▂▇▅▄▂▁▆▃▅▆▆▇▆█▆▃▁▇▅▂▃▃▄▄▄▅▁▆▅▄▇▃▆█▅▆▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83897
wandb: best/eval_avg_mil_loss 0.34649
wandb:  best/eval_ensemble_f1 0.83897
wandb:            eval/avg_f1 0.83897
wandb:      eval/avg_mil_loss 0.34641
wandb:       eval/ensemble_f1 0.83897
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.16691
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.8997
wandb:      train/ensemble_f1 0.8997
wandb:         train/mil_loss 0.27146
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lwozepn5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200955-lwozepn5/logs
wandb: Agent Starting Run: rs2xna2x with config:
wandb: 	actor_learning_rate: 1.586136741842327e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3192742073539012
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2571777720950075
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201138-rs2xna2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rs2xna2x
wandb: uploading history steps 175-190, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▆▆▅▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▁▁▂▅▂▂▄▂▃▂▂▄▃▄▄▄▄▆▇▄▅▃▆▅▇█▆▇▇▅▄▄▄▆▆█▅▄
wandb:      train/ensemble_f1 ▂▁▄▃▄▅▄▂▅▄▂▇▂▄▄▅▅▅▅▃▅▄▆▄▆▄▇█▇▄▅▆▃▅▅▇▆▅█▆
wandb:         train/mil_loss ▄▅▆▄▄▇█▇▄▄▇▅▅▂▆▅▂▄▅▁▃▅▃▄▂▅▄▄▄▅▃▆▇▅▅▅▄▂▂█
wandb:      train/policy_loss ▄▄▃▃▅▄▅▁▆▅▁█▃▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▄▃▄▃▁▄▄▄▄█▄▁▂▃▃▇▃█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52381
wandb: best/eval_avg_mil_loss 4.39793
wandb:  best/eval_ensemble_f1 0.52381
wandb:            eval/avg_f1 0.52381
wandb:      eval/avg_mil_loss 4.2467
wandb:       eval/ensemble_f1 0.52381
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 5.29642
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.52608
wandb:      train/ensemble_f1 0.52608
wandb:         train/mil_loss 1.90212
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/npdstmtt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200901-npdstmtt/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n0u1eel2 with config:
wandb: 	actor_learning_rate: 0.0015894163729866183
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1897421472711679
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4226412898237517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201218-n0u1eel2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n0u1eel2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇██▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▂▁▂▁▁▁▇▇▇▆▇▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▁▆▇▅▇▆█▄▄▃▆▃▃▄▄▃▇▅▄▃▆▅▆▃▄▅▅▇▇▄▇▆▇▅▆▄█▅
wandb:      train/ensemble_f1 ▅▁▃▃▆▇▅▆▂▁█▆▅▄▇▅▇▆▅█▆▅▆▄▅▆█▆▆▅▇▅▅▅▅▇▆▅▆▆
wandb:         train/mil_loss ▆▆▇▂▁▅▄▇▂█▃▃▃▃▄▄▅▆▄▂▃▁▅▅▄▂▄▃▄▂▃▇▁▆▄▃▅▂▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55587
wandb: best/eval_avg_mil_loss 2.04844
wandb:  best/eval_ensemble_f1 0.55587
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 2.08006
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.48003
wandb:      test/avg_mil_loss 2.49119
wandb:       test/ensemble_f1 0.48003
wandb:           train/avg_f1 0.59012
wandb:      train/ensemble_f1 0.59012
wandb:         train/mil_loss 0.50193
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ngfng8k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200942-3ngfng8k/logs
wandb: Agent Starting Run: kesdtqgt with config:
wandb: 	actor_learning_rate: 4.735134826575935e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15988874844653933
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07466579910511728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201300-kesdtqgt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kesdtqgt
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▁▁▁▅▅▅▅███████████████████████████████
wandb:      eval/avg_mil_loss ███▇▆▆▆▁▁▄▃▃▃▃▃▃▂▂▂▂▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▄▄▄
wandb:       eval/ensemble_f1 ▅▅▁▁▁▁▅▅▅▅██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▅▄▅▂▃▃█▃█▆▃▁▃▆▄▆▃▅▆▄▄▆▅▇▅▅▄▄▆▂▄▄▄▁▄▇▅▅
wandb:      train/ensemble_f1 ▅▅▇▅▄▄▄▆█▄▄▆▃▄▃▄▅▅▄▆▁▁▅▃▃▄▁▆▄▆▂▆▄▆▆▅▅▅▇▄
wandb:         train/mil_loss ▃▇▂▄▃▃▇▅▃▄▅▁▄█▆▄▆▅▆▅███▆▅▆▃▇▂▄▁▄▇▅▁▆▅▃▆▆
wandb:      train/policy_loss ███▁█████████▅██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89964
wandb: best/eval_avg_mil_loss 0.24086
wandb:  best/eval_ensemble_f1 0.89964
wandb:            eval/avg_f1 0.89964
wandb:      eval/avg_mil_loss 0.24195
wandb:       eval/ensemble_f1 0.89964
wandb:            test/avg_f1 0.9796
wandb:      test/avg_mil_loss 0.10768
wandb:       test/ensemble_f1 0.9796
wandb:           train/avg_f1 0.94118
wandb:      train/ensemble_f1 0.94118
wandb:         train/mil_loss 0.22515
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rs2xna2x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201138-rs2xna2x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4cey5b5e with config:
wandb: 	actor_learning_rate: 2.959725809822576e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.059739396536408695
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6755113461904265
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201353-4cey5b5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cey5b5e
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▄▁▄▅▇▆▆▃▅▇▇▄▅█▆▆▆▅▆▃▃▆█▇█▄▆█▆▅▇▇▆▆▅▆▅▄
wandb:      train/ensemble_f1 ▁▆▅▇▄▄▇▆▆▆▃▅▅▇▄▆▇▆▄▆▅▅▇▇▆█▆▄▆▇▄▃▅▅▆▅▆▅▅▄
wandb:         train/mil_loss ▄▇▅▄▆▅▂▅▄▆▂▇▅▅▄▄▆▁▆▇▅▄▂▅▅▄▅▄▅▄▂█▂▆▃█▅▃▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▇▆▆█▇▄▅▆▅▆▇▆▅▇▅▇▇▆▅▆▇▄▆▂▆▆▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86894
wandb: best/eval_avg_mil_loss 0.26683
wandb:  best/eval_ensemble_f1 0.86894
wandb:            eval/avg_f1 0.86894
wandb:      eval/avg_mil_loss 0.25012
wandb:       eval/ensemble_f1 0.86894
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.18064
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.90315
wandb:      train/ensemble_f1 0.90315
wandb:         train/mil_loss 0.2902
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n0u1eel2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201218-n0u1eel2/logs
wandb: Agent Starting Run: uyrm11at with config:
wandb: 	actor_learning_rate: 4.234909857201405e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.43057887800268113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03033131473410111
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201426-uyrm11at
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uyrm11at
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▅▄▄▄▄▄▅▄▄▃▃▃▃▃▃▂▂▁▁▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▄▅▄▇▅▄▃▅▃▄▅▂▆▅▁▄▃▆█▇▃▅▄▇▄▄▇▂▅▆▃▅▅▄▃▄▂▂
wandb:      train/ensemble_f1 ▂▅▄▁▅▅▄▁▇▂▃▄▇▅█▁▆▃▇▃▃▂▅▇▅▃▅▃▂▄▃▅▄▂▂▅▂▃▆▅
wandb:         train/mil_loss ▄▄█▅▆▄▄▃▄▆█▁▆▅▃▆▆▆▁█▁▇▆▅▆▄▄▆▆▅▅▄▄▄▅▃▄▁▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.2606
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.25572
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.93695
wandb:      test/avg_mil_loss 0.21172
wandb:       test/ensemble_f1 0.93695
wandb:           train/avg_f1 0.859
wandb:      train/ensemble_f1 0.859
wandb:         train/mil_loss 0.31878
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uyrm11at
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201426-uyrm11at/logs
wandb: Agent Starting Run: uboqxtf0 with config:
wandb: 	actor_learning_rate: 0.007647896712305269
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.861383285888343
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5670712647174535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201610-uboqxtf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uboqxtf0
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-fy_nms5j'
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅▆▆▇▇▇█
wandb: best/eval_avg_mil_loss █▇▇▇▆▆▅▄▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅▆▆▇▇▇█
wandb:            eval/avg_f1 ▁▁▃▃▅▆▇▇▇▇▇▅▆▆▇▇▇▇▇▇▇▇███▇▇▇█▇▇▇▇▇▇▆▆▆▆▆
wandb:      eval/avg_mil_loss █▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂▃▃▃▃▃▃▃▃▄▄
wandb:       eval/ensemble_f1 ▁▁▂▂▃▅▅▆▆▆▇▇▇▆▆▆▆▇▇▇██▇█▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▃▃▄▂▃▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇█▇███▇████▇▇█▆
wandb:      train/ensemble_f1 ▁▂▂▃▄▆▄▅▄▅▅▆▇▅▅▇█▇▆█▆▆█▆▇▆▇▆▇▇▆█▇▇▇▇▇▇▇▇
wandb:         train/mil_loss █▆▄▅▄▅▅▄▄▄▃▄▃▃▃▃▂▃▃▃▃▂▄▃▃▂▂▂▂▂▃▁▂▃▂▂▂▂▂▂
wandb:      train/policy_loss ▅▁█▃█████████████████████▄██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▆▃▆▆█▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89996
wandb: best/eval_avg_mil_loss 0.30312
wandb:  best/eval_ensemble_f1 0.89996
wandb:            eval/avg_f1 0.86967
wandb:      eval/avg_mil_loss 0.33195
wandb:       eval/ensemble_f1 0.86967
wandb:            test/avg_f1 0.9288
wandb:      test/avg_mil_loss 0.30708
wandb:       test/ensemble_f1 0.9288
wandb:           train/avg_f1 0.87767
wandb:      train/ensemble_f1 0.87767
wandb:         train/mil_loss 0.28447
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kesdtqgt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201300-kesdtqgt/logs
wandb: Agent Starting Run: h5ntmo4e with config:
wandb: 	actor_learning_rate: 0.008758179340355532
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8293364870758086
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9567699960119675
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201652-h5ntmo4e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ntmo4e
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▁▁▅▆▄▃▅▆▅▃▂▄▄▂▄▇▄▅▄▅▃▇▅▅▅▂▄▅▅███▄▆▅▄▄▆
wandb:      train/ensemble_f1 ▂▃▁▁▇▄▆▄▄▅▄▄▄▃▅▆▆▅▂▄▄▃▅▄▃▄▂▄▃▆▃▅▅█▅▆▁▅▃▆
wandb:         train/mil_loss ▆█▅▆▅▅▇▂▄▅▄▄▁▅▃▅▆▅▅▄▆▇▂▅▅▄▅▄▅▄▃▂▃▁▇▆▄▃▆▃
wandb:      train/policy_loss █▄▄▁▃▃▅▅▃▅▆▃▆▁▁▁▁▁▅▃▅▃▁▅▅▁▅█▅▃▁▅▅▃▁▃▆▃▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▆▆▄▃▅▃▃▁▃▁▄▃█▁▁▁▅▁▁▄▃▆▃▅▃▃▅▄▅▃▃▁▄▆▃▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82985
wandb: best/eval_avg_mil_loss 0.43934
wandb:  best/eval_ensemble_f1 0.82985
wandb:            eval/avg_f1 0.82985
wandb:      eval/avg_mil_loss 0.4175
wandb:       eval/ensemble_f1 0.82985
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.37552
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.84873
wandb:      train/ensemble_f1 0.84873
wandb:         train/mil_loss 0.29998
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cey5b5e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201353-4cey5b5e/logs
wandb: Agent Starting Run: 0b28wcme with config:
wandb: 	actor_learning_rate: 3.20533086900108e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7005991011629892
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5253114125926475
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201715-0b28wcme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0b28wcme
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁███████████████████████████████████████
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▂▂▂▂▂▁▂▁▂▂▁▂▂▂▁▂▁▂▂▂▁▂▂▂▂▂▃▂▂▂▁▂▂▂▂▂▂▂
wandb:      train/ensemble_f1 ██▂▂▂▂▃▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▃▂▂▂▂▂▁▂▂▃
wandb:         train/mil_loss ▁▁▂█▅▄▆▅▃▄▆▅▇▆▆▅▅▇▃▆▅▃▅▄▅▂▂▃▄▃▄▆▅▄▃▂▇▆▆▅
wandb:      train/policy_loss ▅▅▅▅▅▁█▄▄▆▃▄▆▄▆█▅▄▆▅▄▅▄▆▆▄▅▄▆▄▂▃▃▄▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.31381
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 2.81836
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.94813
wandb:      test/avg_mil_loss 0.19629
wandb:       test/ensemble_f1 0.94813
wandb:           train/avg_f1 0.55387
wandb:      train/ensemble_f1 0.55387
wandb:         train/mil_loss 0.61054
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uboqxtf0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201610-uboqxtf0/logs
wandb: Agent Starting Run: 8j6r92w3 with config:
wandb: 	actor_learning_rate: 0.0001125550384096369
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7757121417268786
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11191158830994984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201754-8j6r92w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8j6r92w3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:       eval/ensemble_f1 ▆▆█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▇█▂▃▆▇▅▅▄▅▆▆▇▄▆▃█▅▃▄▃▄▇▅▄▄▄▅▆▅▄▄▂▃▄▆▃▁
wandb:      train/ensemble_f1 ▁▅█▆▇▅▅▅▆▆▇▅▅▅█▂██▄▄▃▄▅▇▇▆▅▂▄▅▆▅▄▄▁▃▄▆▃▅
wandb:         train/mil_loss ▄▅▂▄▅▄▆▃▅▄▃▇▅▆▃▇▇█▂▃▆▆▄▇▃▇█▄▃▃▃▁▂▃▆▂▃▅▂▁
wandb:      train/policy_loss ██▁▂▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92
wandb: best/eval_avg_mil_loss 0.17188
wandb:  best/eval_ensemble_f1 0.92
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.27545
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.22022
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.86893
wandb:      train/ensemble_f1 0.86893
wandb:         train/mil_loss 0.23166
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ntmo4e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201652-h5ntmo4e/logs
wandb: Agent Starting Run: dimyzf3p with config:
wandb: 	actor_learning_rate: 1.6093292511316713e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7261636213189517
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8617549527856506
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201841-dimyzf3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dimyzf3p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃█▆▂▄▂▁▄▂▁▆▃▄▆▅▂▃▄▇▅▇▂▃▆▄▃▃▅▅▄▂▅▂▁▃▃▄▄
wandb:      train/ensemble_f1 ▆▆▆▅▆▇▁▄▃▄▁▅▄▃▄▃▆▅█▂▃▇▂▅▁▄▁▃▄▆▅▄▄▆▂▇▅▂▃▃
wandb:         train/mil_loss ▅▄▅▆▅█▄▄▄▂▄▅▃▆▅▇▄▅▄▅▅▃▃▄▅▄▄▄▁▅▃▄▄▄▆▅▄▅▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.27991
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.30222
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.92609
wandb:      test/avg_mil_loss 0.19527
wandb:       test/ensemble_f1 0.92609
wandb:           train/avg_f1 0.86925
wandb:      train/ensemble_f1 0.86925
wandb:         train/mil_loss 0.3182
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8j6r92w3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201754-8j6r92w3/logs
wandb: Agent Starting Run: k3tgxygm with config:
wandb: 	actor_learning_rate: 0.00020814279899890076
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24311786439346883
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.003989507724500796
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201937-k3tgxygm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k3tgxygm
wandb: uploading history steps 109-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▅▅████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▅▅███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▁▇▅▅▃▅▅▃▄▄█▄▆▅▅▇█▅▆▄▃▅▇▄▅▅▅▃█▇▆▄▄█▄▆█
wandb:      train/ensemble_f1 ▃▁▄▅▅▅▅▅▁▇▅▅▂█▄▇▄█▅▆▄▇▃▆▅▃▆█▆▆▆▃▇▇█▄▆▇▆▆
wandb:         train/mil_loss ▅▄▃▆█▅▅▇▅▂▇▆▅▇▅█▆▄▆▅▅▄▇▃▄▆▃▅▄▄▄▁▄▅▃▃▄▆▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁▆▅████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7933
wandb: best/eval_avg_mil_loss 0.57094
wandb:  best/eval_ensemble_f1 0.7933
wandb:            eval/avg_f1 0.7933
wandb:      eval/avg_mil_loss 0.47679
wandb:       eval/ensemble_f1 0.7933
wandb:            test/avg_f1 0.67159
wandb:      test/avg_mil_loss 1.02585
wandb:       test/ensemble_f1 0.67159
wandb:           train/avg_f1 0.77247
wandb:      train/ensemble_f1 0.77247
wandb:         train/mil_loss 0.34112
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dimyzf3p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201841-dimyzf3p/logs
wandb: Agent Starting Run: q19ou2us with config:
wandb: 	actor_learning_rate: 0.0030851345335356425
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09712722656398154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5583569830142747
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202045-q19ou2us
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q19ou2us
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-lcwyz253'
wandb: uploading history steps 140-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁▁▁███████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▃▁▃▁▂▃▄▃▄▄▄▄▄▂▃▃▄▅▄▄▇▅▄▄▅▅▅▆▂▅▅▅▄▄▅▄█
wandb:      train/ensemble_f1 ▂▂▃▂▃▃▃▃▂▁▄▃▄▄▅▅▅▄▅▃▄▄▃▆▅▆█▆▆▄▆▄▆▅▂▄▇▅▆▄
wandb:         train/mil_loss ▄▇▅▆▇█▄▆▁▇▃▄▁▄▅▇▄▆▂▆▁▅▆▃▃▅▆▄▅▅▄▂▅▃▄▃▂▇▇▅
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51433
wandb: best/eval_avg_mil_loss 4.47337
wandb:  best/eval_ensemble_f1 0.51433
wandb:            eval/avg_f1 0.51433
wandb:      eval/avg_mil_loss 4.32048
wandb:       eval/ensemble_f1 0.51433
wandb:            test/avg_f1 0.45012
wandb:      test/avg_mil_loss 5.0885
wandb:       test/ensemble_f1 0.45012
wandb:           train/avg_f1 0.53534
wandb:      train/ensemble_f1 0.53534
wandb:         train/mil_loss 2.68543
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k3tgxygm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201937-k3tgxygm/logs
wandb: Agent Starting Run: tvhhixiy with config:
wandb: 	actor_learning_rate: 0.0005848895463581591
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2413541076596627
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17514697492693954
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202202-tvhhixiy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvhhixiy
wandb: uploading history steps 109-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▇█
wandb: best/eval_avg_mil_loss ██▇▇▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▇█
wandb:            eval/avg_f1 ▁▁▁▂▃▇▇█████████████████████████████████
wandb:      eval/avg_mil_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▇▇██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▁▂▃██▇▇███▇██████████▇████████▇█████
wandb:      train/ensemble_f1 ▁▂▁▁▃█▇▇█▇████████████████████████▇█████
wandb:         train/mil_loss ██▇█▇▅▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86967
wandb: best/eval_avg_mil_loss 0.35265
wandb:  best/eval_ensemble_f1 0.86967
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 0.25784
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.17619
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.89989
wandb:      train/ensemble_f1 0.89989
wandb:         train/mil_loss 0.23127
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q19ou2us
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202045-q19ou2us/logs
wandb: Agent Starting Run: 9kts72lz with config:
wandb: 	actor_learning_rate: 1.4775370844316786e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1963565260347991
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2704837233547237
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202239-9kts72lz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kts72lz
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃
wandb:      eval/avg_mil_loss ▁▃▅▅▆▇▇▇▇██████████████████████▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █▅▅▃▃▃▃▄▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆███▇▅▅▅▅▁▃▁▁▁▃▂▂▂▂▅▂▃▃▃▂▃▄▄▂▃▃▃▂▃▃▂▄▃▄▃
wandb:      train/ensemble_f1 ▆███▇▇▇▇▅▅▄▂▂▃▁▂▃▄▂▄▄▂▂▃▅▂▄▃▂▄▁▂▂▃▃▃▃▄▃▃
wandb:         train/mil_loss ▃▁▂▅▄▆▅▅▆▄▃▇▆▅▅▇▅▅▆▄▇▁▆▆█▅▄▅▄▄▅▂▅▅▆▆▃▄▄▅
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 3.28006
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.50715
wandb:      eval/avg_mil_loss 4.36528
wandb:       eval/ensemble_f1 0.50715
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 4.29797
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.49123
wandb:      train/ensemble_f1 0.49123
wandb:         train/mil_loss 2.37437
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvhhixiy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202202-tvhhixiy/logs
wandb: Agent Starting Run: 98fcwgx4 with config:
wandb: 	actor_learning_rate: 1.854039712570084e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9021154549626124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4727390862349674
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202346-98fcwgx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/98fcwgx4
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▆▆▆▃▃▃▃▃▃▃▃▃▃▃▁▁▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▃▃▃▅▅▄▄▄▄▃▃▃▃▂▂▂▁▄▄▄
wandb:       eval/ensemble_f1 ███████████████████▆▆▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▅▆▆▇▅▇▇▇▆▇▇▄▅▄▄▆█▅▆▆▄▁▅▅▄▆▃▅▆▅▄▅▅▄▆▄▆
wandb:      train/ensemble_f1 ▂▄▅▇▇▅▇▇▃▅▄▄▅▅▅▃▆▆▃▄█▄▅▂▄▃▅▅▁▂▆▇▂▃▄▆▆▁▇▅
wandb:         train/mil_loss ▂▄▃▄▅▃▃▁▁▄▁▆▇▃▃▃▁▂█▇▅▂▂▄▂▃▂▄▁▆▂▂▃▂▄▅▄▁▂▅
wandb:      train/policy_loss ██████████████████████████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁███████▂█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78897
wandb: best/eval_avg_mil_loss 0.74527
wandb:  best/eval_ensemble_f1 0.78897
wandb:            eval/avg_f1 0.76942
wandb:      eval/avg_mil_loss 0.72535
wandb:       eval/ensemble_f1 0.76942
wandb:            test/avg_f1 0.85949
wandb:      test/avg_mil_loss 0.51973
wandb:       test/ensemble_f1 0.85949
wandb:           train/avg_f1 0.8256
wandb:      train/ensemble_f1 0.8256
wandb:         train/mil_loss 0.4195
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9kts72lz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202239-9kts72lz/logs
wandb: Agent Starting Run: 64yq160l with config:
wandb: 	actor_learning_rate: 0.0005324877509345869
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5232307852316853
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4637774374855812
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202423-64yq160l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/64yq160l
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁███████████████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▂
wandb:       eval/ensemble_f1 ▁▁▁█████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▆▆▅▄▄▆▂▅▅▃▃▄▄▅▅▃▄▄▆▆▃▆▅▆▅▅▇▅▆▇▇▇█▇▇▁▅▇
wandb:      train/ensemble_f1 ▇▅▅▄▅▆▆▆▅▅▇▅▇▆▄▇▆▆▇▆▆▇▅▇▆▆█▅▆▇██▇▇▅▁▇▅▄▅
wandb:         train/mil_loss ▅▆▄▂▅▄▅▇▅▅▆▄▅▄▁▃▃▄▃▄▄▃▆▆▂▃▅█▆▅▄▆▃▅▄▂▃▃▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 2.48361
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 2.37591
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 3.16138
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.60271
wandb:      train/ensemble_f1 0.60271
wandb:         train/mil_loss 0.27999
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/98fcwgx4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202346-98fcwgx4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nspxykqa with config:
wandb: 	actor_learning_rate: 8.426804220471421e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6013955489881305
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4343301343511652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202544-nspxykqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nspxykqa
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▃▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss █▆▆▆▅▄▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▃▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▃▃▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇████▇██████
wandb:      train/ensemble_f1 ▁▃▂▃▃▄▄▄▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇████████
wandb:         train/mil_loss █▅▅▆▃▄▄▃▃▃▁▃▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▂▁
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8899
wandb: best/eval_avg_mil_loss 0.31876
wandb:  best/eval_ensemble_f1 0.8899
wandb:            eval/avg_f1 0.8899
wandb:      eval/avg_mil_loss 0.3132
wandb:       eval/ensemble_f1 0.8899
wandb:            test/avg_f1 0.87957
wandb:      test/avg_mil_loss 0.30722
wandb:       test/ensemble_f1 0.87957
wandb:           train/avg_f1 0.86114
wandb:      train/ensemble_f1 0.86114
wandb:         train/mil_loss 0.26436
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0b28wcme
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201715-0b28wcme/logs
wandb: Agent Starting Run: y1lfpnrh with config:
wandb: 	actor_learning_rate: 2.464173586750556e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7971469065341505
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6893857962080546
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202628-y1lfpnrh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1lfpnrh
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅▅▅▅▅▅██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▃▃▁▄▃▄▄▃▁▄▅▄▄▆▆▅▅▄▅▅▆▅▇▆▅▄█▄▅▃▄▇▄▅▇▆▇
wandb:      train/ensemble_f1 ▄▂▅▃▂▂▁▃▄▂▅▅▄▆▇▆▆▆▅▄▄▄▅█▇▅▅▅▄▄▆▄▅▄▆▇██▅▇
wandb:         train/mil_loss ▁▃▅▃▅▄▄▄▃▅▁▃▆▃▅▄▅▃▂▄▂█▃▅▄▃▃▆▃▁▆▂▄▁▆▃▃▃▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▂▃▄▅▁▅▄▆▄▅▅▆▅▂▃▄▅▄▄▆▆▄▄▇▄▄▅▄█▃▄▄▃▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 2.52694
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.37446
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 2.96383
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.45137
wandb:      train/ensemble_f1 0.45137
wandb:         train/mil_loss 1.02228
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/64yq160l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202423-64yq160l/logs
wandb: Agent Starting Run: 2pnqq9lz with config:
wandb: 	actor_learning_rate: 0.00014690845204785283
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7958558495899359
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17528611410284278
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202643-2pnqq9lz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2pnqq9lz
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▅▆▇▇▇▇▇██████▇▆▆▆▆▆▆▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▅▅▂▄▄▂▄▄▁▂▄▄▂▃▃▅▄▂▆▃▄▅▃▃▅▂▃▃▄▃▃█▃▅▅▅
wandb:      train/ensemble_f1 ▄▃▃▂▅▃▄▁▃▁▄▄▃▁▅▂▃▂▃▃▃▁▅▃▄▂▅▁▃▅▄▃▃▃▄▂▃█▂▂
wandb:         train/mil_loss ▇▃▅▆▆▇▄▄▅▄▆▄▅▄▅▆▅▆▆▁▁▅▆▃▆▂▅▆▄▃▆▆▆▄▇▅▅█▇▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.28807
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.29315
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.92609
wandb:      test/avg_mil_loss 0.18787
wandb:       test/ensemble_f1 0.92609
wandb:           train/avg_f1 0.86261
wandb:      train/ensemble_f1 0.86261
wandb:         train/mil_loss 0.28777
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nspxykqa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202544-nspxykqa/logs
wandb: Agent Starting Run: 9l4ljxn4 with config:
wandb: 	actor_learning_rate: 0.0004811000861705787
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8324176630972007
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14153229906243914
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202727-9l4ljxn4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9l4ljxn4
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇██████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▇▂█▄▅▅▄▃▆▃▅▄▁▂▄▅▃▄▂▆▅▅▂▅▆▂▅▁▇▄▅▃▃▄▄▂▄
wandb:      train/ensemble_f1 ▅█▆▄▆▂▆▅▄▃▅▅▄▅▃▆▅▃▄▆▅▅▄▆▅▆▆▃▆▃▅▆▅▂▁▄▅▃▁▄
wandb:         train/mil_loss ▅▅▃▇▄▃▄▄▄▆▆▅▇▃▂▆▄▅▃▃▂▄▄▁▄▁█▃▆▆▃▇▂▄▄▄▃▄▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.32343
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.34411
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.12778
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88455
wandb:      train/ensemble_f1 0.88455
wandb:         train/mil_loss 0.2601
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2pnqq9lz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202643-2pnqq9lz/logs
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▅▂█▄▁▇▃▅▆▆▅▇▅▆▄█▇▆▅▇▃▄▄█▆▅▃▄▆▆▄▂▄▅▄▆▄
wandb:      train/ensemble_f1 ▄▅▄▄▅▄▅▄▃▁▆▄▅▆▅▄█▄▄▆▄▃▆▃▅▅▆▄▃▂▃▄▅▄▃▇▄▁▄▃
wandb:         train/mil_loss ▆▃█▆▅▃▅▄▇▄▇▃▇▃█▄▅▇▅▁▃▄▅▃▄▂▄▂▄▄▅▇▄▅▆▆▃▄▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.22603
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.23205
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.9179
wandb:      test/avg_mil_loss 0.18929
wandb:       test/ensemble_f1 0.9179
wandb:           train/avg_f1 0.90125
wandb:      train/ensemble_f1 0.90125
wandb:         train/mil_loss 0.27147
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1lfpnrh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202628-y1lfpnrh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: 3ko9yc45 with config:
wandb: 	actor_learning_rate: 0.00011831008941571262
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3822287650498257
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4101610792204656
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202832-3ko9yc45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ko9yc45
wandb: Job received.
wandb: Agent Starting Run: epqi3mva with config:
wandb: 	actor_learning_rate: 0.004310745551810898
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5885224811893616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00564363371736798
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202838-epqi3mva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/epqi3mva
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▇█
wandb: best/eval_avg_mil_loss █▆▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁████▅▃▃▃▃▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇████▅▁▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▂▂▂▂▂▂▂▂▂▁█▇▇▇▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▃▃▃▇▄▄▄▄▅▅▄▆▅▄▂▅▄▅▁▁▄▃▂▆▄▅▂▄▃▅▄▅▃▅▅▁█
wandb:      train/ensemble_f1 ▄▅▄▄▇▄▄██▄▆▃▅▄▄▄▅▇▃▆▃▇▄▆▄▃▆▂▅▂▁▂▃▅▃▅▅▆▂▄
wandb:         train/mil_loss █▃▃▃▃▆▅▃▅▂▃▅▂▅▄▂▃▄▄▄▁▅▄▂▁▂▃▅▃▂▃▄▃▃▃▃▅▂▃▆
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90992
wandb: best/eval_avg_mil_loss 0.21647
wandb:  best/eval_ensemble_f1 0.90992
wandb:            eval/avg_f1 0.8591
wandb:      eval/avg_mil_loss 0.23837
wandb:       eval/ensemble_f1 0.8591
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.23288
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.85569
wandb:      train/ensemble_f1 0.85569
wandb:         train/mil_loss 0.34139
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9l4ljxn4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202727-9l4ljxn4/logs
wandb: Agent Starting Run: 14qckkl4 with config:
wandb: 	actor_learning_rate: 1.3796440822144251e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.743034888659713
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.023848192224414477
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202932-14qckkl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14qckkl4
wandb: uploading history steps 96-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁█▇▆▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▄▂▂▄▃▄▂▅▄▂▃▅█▇▅▆▁▃▄▆▆▄▄▅▂▃▃▄▂█▁▃▄▅▇▆▂▄
wandb:      train/ensemble_f1 ▄▆▅▁▂▄▅▃▆▃▃▄▅▁▅▃▂▇▇▅▅▇▄▇▄▄▆▅▄▅▇█▂▅▅▅▇▆▆▄
wandb:         train/mil_loss ▇▄▄▅▆▄▄▇▆█▅▄▅▇▅▆▅▃▇▆▅▂▇▃▁▅▆▄█▆▅▅▃▄▇▁▅▃▆▁
wandb:      train/policy_loss ▄▁▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91987
wandb: best/eval_avg_mil_loss 0.17954
wandb:  best/eval_ensemble_f1 0.91987
wandb:            eval/avg_f1 0.90977
wandb:      eval/avg_mil_loss 0.19885
wandb:       eval/ensemble_f1 0.90977
wandb:            test/avg_f1 0.9388
wandb:      test/avg_mil_loss 0.14103
wandb:       test/ensemble_f1 0.9388
wandb:           train/avg_f1 0.92556
wandb:      train/ensemble_f1 0.92556
wandb:         train/mil_loss 0.19225
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ko9yc45
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202832-3ko9yc45/logs
wandb: Agent Starting Run: ibq99fjv with config:
wandb: 	actor_learning_rate: 0.004014190757230655
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22520966529905573
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8007077455008633
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203016-ibq99fjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibq99fjv
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▄▃▅▄▅▆▂▃▆▅▂▄▄▅▃▄▄▅▆▃▂▅▄▁▄▄▅▂▅▇▄▃▅▃▅▃▁▃
wandb:      train/ensemble_f1 █▅▅▃▆▆▅▅▅▆▇▆▆▆▄▄▅▄▅▅▄▄▆▅▅▃▅▇▅▁▆▇▆▅▆▄▃▃▅▄
wandb:         train/mil_loss ▇▂▆▄▅█▃▅▃▇▆▄▄▇▂▂▅▄▄▁▂▄▆▄▄▅▅▅▆▄▂▂▃▂▂▄▂▄▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.23786
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.25506
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.95833
wandb:      test/avg_mil_loss 0.19555
wandb:       test/ensemble_f1 0.95833
wandb:           train/avg_f1 0.88202
wandb:      train/ensemble_f1 0.88202
wandb:         train/mil_loss 0.30006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14qckkl4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202932-14qckkl4/logs
wandb: Agent Starting Run: wv9e8kth with config:
wandb: 	actor_learning_rate: 1.8032701626265418e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.061522334517334576
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5020761892610295
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203115-wv9e8kth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wv9e8kth
wandb: uploading history steps 171-178, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▁▆▄
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▃▃▃▃▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ██▇▇▇▆███████▇▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▆▆▆▆▆▆▆██████████▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▅▃▆▃▃▆▂▂▁▂▃▃▅▄▄▄▆▄▄▅▃▅▂▃▄▇▄▇█▇▅▆▆▆▆▄▅
wandb:      train/ensemble_f1 ▄▂▂▃▄▇▄▆▃▄▄▂▅▂▃▁▄▃▄▃▄▃▃▆▆▄▃▇▆▄▆▆▆▇▅██▇▇▇
wandb:         train/mil_loss ▅▄▅▅▃▃▆█▆▄▅▇█▄▅▃▄▁▇▅█▅▂▆▃▆▅▆▅▇▄▅▃▃▇▂▁▄▃▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▄▆▆▄▄▆▆▆▅▄▅▅▅▄▄▄▅▇▅▄█▄▃▃▁▇▃▇▄▃▃▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▇▅▇▆▇▄▆▇▂▄▃▂▆▁▆▃▂▇▅▃▃▅▃▄▄▃▄▄█▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 2.86719
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.46082
wandb:      eval/avg_mil_loss 2.73223
wandb:       eval/ensemble_f1 0.46082
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 3.30972
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.43467
wandb:      train/ensemble_f1 0.43467
wandb:         train/mil_loss 1.03731
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/epqi3mva
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202838-epqi3mva/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g3p0ttjd with config:
wandb: 	actor_learning_rate: 0.00092205996648856
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42368993942930855
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8741681803027758
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203145-g3p0ttjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/76ppa1fz
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3p0ttjd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▆▇▇▅▅▁▁▁▂▂▃▃▃▃▅▅▅▅▆▆▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▃▂▂▄▄▆▆▆▆███▇▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 █████▆▆▆▆▆▅▅▅▃▃▁▃▃▄▅▅▅▅▅▅▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▆▇▇▆█▇▇▆▅▅▄▃▃▃▂▃▁▂▂▁▃▂▃▂▃▂▂▃▃▃▃▃▄▃▄▃▃
wandb:      train/ensemble_f1 ██▇▇█▆▆▆▆▄▄▃▂▃▁▃▂▂▄▃▂▃▃▂▂▃▄▂▃▃▃▂▃▃▄▄▃▄▄▃
wandb:         train/mil_loss ▃▃▃▁▂▂▃▂▂▃▅▄▄▆▆▇█▇▆▄▅▅▆▇▆▆▃▅▅▆▅▅▄▆▅▅▅▆▅▅
wandb:      train/policy_loss ▃▃▃▃▃▁▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▂▃▄▃█▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▂▆█████▁██████████████████████▇██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88946
wandb: best/eval_avg_mil_loss 0.24657
wandb:  best/eval_ensemble_f1 0.88946
wandb:            eval/avg_f1 0.86
wandb:      eval/avg_mil_loss 0.30755
wandb:       eval/ensemble_f1 0.86
wandb:            test/avg_f1 0.96911
wandb:      test/avg_mil_loss 0.08291
wandb:       test/ensemble_f1 0.96911
wandb:           train/avg_f1 0.84
wandb:      train/ensemble_f1 0.84
wandb:         train/mil_loss 0.30194
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ibq99fjv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203016-ibq99fjv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zq0rtevh with config:
wandb: 	actor_learning_rate: 0.0007381188267418054
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.26226223703785057
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.385514829110705
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203205-zq0rtevh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/4visk13r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zq0rtevh
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▅▄▄▃▅▅▄▄▃▂▂██▇▇▇▇▆▆▆▅▅▅▄▃▃▃▃▃▂▂▂▁▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁█████████████▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▂▂▂▄▅▃▄▂▃▃▅▄▄▃▃▆▂▄▄▅▂▆█▅▄▃▄▃█▅▃▂▇▄▃▂▅
wandb:      train/ensemble_f1 ▂▂▃▁▃▄▃▅▄▃▄▆▄▃▅▆▄▄▅▄▃▄▆▆▄▅▆▄▅▆█▃▆▅▄▂▃▄▅▅
wandb:         train/mil_loss ▇█▇██▆▇█▄▆▅▆▇▄▇▇▅▇▆▇▆▅▅▄▆▆▅▄▁█▅▇▃▆▄▄▇▄▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55587
wandb: best/eval_avg_mil_loss 3.37942
wandb:  best/eval_ensemble_f1 0.55587
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 3.32106
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.50868
wandb:      test/avg_mil_loss 4.09624
wandb:       test/ensemble_f1 0.50868
wandb:           train/avg_f1 0.57072
wandb:      train/ensemble_f1 0.57072
wandb:         train/mil_loss 2.19891
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wv9e8kth
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203115-wv9e8kth/logs
wandb: Agent Starting Run: pckdsvhz with config:
wandb: 	actor_learning_rate: 3.3735882904057415e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7535646700585316
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9678482613063476
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203324-pckdsvhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pckdsvhz
wandb: uploading history steps 109-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆███
wandb: best/eval_avg_mil_loss █▅▃▃▁
wandb:  best/eval_ensemble_f1 ▁▆███
wandb:            eval/avg_f1 ▁▆██████████████████████████████████████
wandb:      eval/avg_mil_loss █▅▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁█████████████████▁█████████▁▁▁██████▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▇▆▆▆▆▆▆▆▆▇▆▆▆▇█▆▇▇▇█▇██▇▇▆▇▇██▇▇▇▇███
wandb:      train/ensemble_f1 ▁▆▆▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇██▇████▇█▇█▇████▇██▇█
wandb:         train/mil_loss █▆▄▄▃▂▅▃▄▅▃▃▄▃▂▂▃▃▂▃▃▂▂▂▂▄▁▁▃▂▃▁▃▂▃▂▄▄▁▃
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90999
wandb: best/eval_avg_mil_loss 0.24603
wandb:  best/eval_ensemble_f1 0.90999
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.23066
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.8891
wandb:      test/avg_mil_loss 0.35673
wandb:       test/ensemble_f1 0.8891
wandb:           train/avg_f1 0.90368
wandb:      train/ensemble_f1 0.90368
wandb:         train/mil_loss 0.25171
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3p0ttjd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203145-g3p0ttjd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077262/pymp-zwy7wm7q'
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇█████
wandb:       eval/ensemble_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▅▃▇█▆▄▅█▅▆▃▄▁▄█▄▅▄▅▅▄▇▆▇▆▆▆▆▇▇▅▂▂▅▆▆▇▃
wandb:      train/ensemble_f1 ▆▁▂▆▆▃▆▆▁▆▂▄▃▄▃▂▄▅▅▂▃▃▃▆▃▇▆▃▅▄▅▅▂▂▆▇▅▄▃█
wandb:         train/mil_loss ▂▂▅█▅▄▄▇▂▅▆▅▃▆▇▄▄▅▅▆▅▆▄▆▆▃▆▅▁▅▅▄▄▄▄▆▂▅▆▅
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84816
wandb: best/eval_avg_mil_loss 0.26042
wandb:  best/eval_ensemble_f1 0.84816
wandb:            eval/avg_f1 0.83766
wandb:      eval/avg_mil_loss 0.28291
wandb:       eval/ensemble_f1 0.83766
wandb:            test/avg_f1 0.94769
wandb:      test/avg_mil_loss 0.18732
wandb:       test/ensemble_f1 0.94769
wandb:           train/avg_f1 0.8526
wandb:      train/ensemble_f1 0.8526
wandb:         train/mil_loss 0.31329
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pckdsvhz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203324-pckdsvhz/logs
wandb: Agent Starting Run: 7ixz1av0 with config:
wandb: 	actor_learning_rate: 0.00022464267631039104
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7129682606188924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4353701969834588
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203503-7ixz1av0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/sutx5a0d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ixz1av0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅████████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▃▂▃▇▁▆▄▅▃▄▅▆▃▅█▄▄▂▃▃▇▄▆▆▄▆▆█▁▅█▇▅▃█▆▅
wandb:      train/ensemble_f1 ▄▃▃▂▂▃▅▄▂▄▃▅▃▁█▄▂▃▃▆▁▃▆▅▅▃▅▂▃▅▃▅▅▃▅▇▄▆▅▄
wandb:         train/mil_loss ▇▄▇▆▇▂▅▃▆▂▃▆▅█▄▂▅▄▇▄▄▇▆▂▁▃▄▇▆▇▆▇▆▂▃▄▇▄▄▁
wandb:      train/policy_loss █▆▆▆▆█▆█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁████▅██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89984
wandb: best/eval_avg_mil_loss 0.23901
wandb:  best/eval_ensemble_f1 0.89984
wandb:            eval/avg_f1 0.89984
wandb:      eval/avg_mil_loss 0.2188
wandb:       eval/ensemble_f1 0.89984
wandb:            test/avg_f1 0.92792
wandb:      test/avg_mil_loss 0.17272
wandb:       test/ensemble_f1 0.92792
wandb:           train/avg_f1 0.91247
wandb:      train/ensemble_f1 0.91247
wandb:         train/mil_loss 0.2086
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zq0rtevh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203205-zq0rtevh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▅▅▂▄▃▆█▅▅▅▄▄▄▆▃▃▇▃▆▃▆▁▆▇▆▆▄▄▅▄▄▇▅▅█▃▆▅
wandb:      train/ensemble_f1 ▅▅▅▇██▆▅▆▅▅▅█▆▅▂▆▆▇▂▁▅▇▆▅▄▆▄▆▄▅▅▂▃█▅▃▆▃▅
wandb:         train/mil_loss ▅▄▅▆▄▄▄▄▅▄▅▃▃▅▆▂▆▁▂▅▅▇▁▄▃▂▄▆▄▃█▄▅▃▃▄▃▂▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.27968
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.82708
wandb:      eval/avg_mil_loss 0.29433
wandb:       eval/ensemble_f1 0.82708
wandb:            test/avg_f1 0.904
wandb:      test/avg_mil_loss 0.19783
wandb:       test/ensemble_f1 0.904
wandb:           train/avg_f1 0.85889
wandb:      train/ensemble_f1 0.85889
wandb:         train/mil_loss 0.30947
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7ixz1av0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203503-7ixz1av0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
