wandb: Agent Starting Run: dxu7nlen with config:
wandb: 	actor_learning_rate: 1.0114903462943684e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.204954865807938
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6809698594551483
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041100-dxu7nlen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxu7nlen
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 135-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ████▁▁▁▁▁▁▁███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▄▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █████▁▁▁██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▅▃█▄▃▅▃▄▃▅▂▄▆▄▂▃▅▁▆▆▅▄▂▅▅▅▁▇▁▃▆▂▅▄▄▃▃
wandb:      train/ensemble_f1 ▄▁▅▅▄▆▁▅▅▅▅▆▂▄▅▄▄▇▇▇▆▅▄▆▅▅▁▆▄█▄▇▅█▅▅▃▆▅▄
wandb:         train/mil_loss ▆▇▆▄▃▅▅▅▂▆▄▆▇▄▄█▁▅▅▃▂▄▂▄▄▃▃▃▂▄▃▃▂▂▅▂▃▄▅▄
wandb:      train/policy_loss ▅▅▆▆█▅▆▄▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91161
wandb: best/eval_avg_mil_loss 0.26532
wandb:  best/eval_ensemble_f1 0.91161
wandb:            eval/avg_f1 0.90799
wandb:      eval/avg_mil_loss 0.25994
wandb:       eval/ensemble_f1 0.90799
wandb:            test/avg_f1 0.93026
wandb:      test/avg_mil_loss 0.18622
wandb:       test/ensemble_f1 0.93026
wandb:           train/avg_f1 0.89204
wandb:      train/ensemble_f1 0.89204
wandb:         train/mil_loss 0.23608
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxu7nlen
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041100-dxu7nlen/logs
wandb: Agent Starting Run: kwnk4sv0 with config:
wandb: 	actor_learning_rate: 0.001643926624859414
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08825444999186682
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17878115525502203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041304-kwnk4sv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwnk4sv0
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▃▁▃▃▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▆████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██▆▃▁▂▂▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▁▁▂▃▂▁▃▃▃▂▃▃▃▃▃▄▄▄▃▃▄▄▄▃▄▄▃▅▄▃▃▄▃▃▄▄▄▃
wandb:      train/ensemble_f1 ▇█▁▃▃▂▄▂▃▄▃▃▄▃▄▃▃▃▄▄▃▄▄▃▃▄▄▃▃▄▄▄▄▄▃▄▄▅▄▄
wandb:         train/mil_loss ▁▂▄▇██▇▇▇▆▆█▆▇▆▆▇▇▅▅▆▇▆▇▆▆▇▇▇▆▄▇▇▄▅▆▇▅▅▆
wandb:      train/policy_loss ▄▄▄▆▁▄▄▄▄▄▇▄▄▄▄▄▄▄▆▄▄▄▄▃▄▄▃▄▄▄▃█▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████▆███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6142
wandb: best/eval_avg_mil_loss 1.08827
wandb:  best/eval_ensemble_f1 0.6142
wandb:            eval/avg_f1 0.52544
wandb:      eval/avg_mil_loss 2.03657
wandb:       eval/ensemble_f1 0.52544
wandb:            test/avg_f1 0.58151
wandb:      test/avg_mil_loss 1.08223
wandb:       test/ensemble_f1 0.58151
wandb:           train/avg_f1 0.52288
wandb:      train/ensemble_f1 0.52288
wandb:         train/mil_loss 1.74676
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwnk4sv0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041304-kwnk4sv0/logs
wandb: Agent Starting Run: o6auwq0w with config:
wandb: 	actor_learning_rate: 0.0012435827663524468
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7351287970299747
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.283535765885111
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041426-o6auwq0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o6auwq0w
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▇▅▄▂▃▃▁▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆███████
wandb:       eval/ensemble_f1 ████████████████▇▇▃▃▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▇▆█▆▆▇███▅▇▇█▅▄▅▆▄▅▅▃▄▃▂▃▃▂▂▂▃▃▃▄▃▂▁▃
wandb:      train/ensemble_f1 ▇▆▆▇▆█▆█▆██▆█▇▆▄▄▄▅▃▂▃▂▂▁▃▂▂▃▃▃▃▃▄▂▂▂▃▁▃
wandb:         train/mil_loss ▄▄▄▆█▄▄▆▆▇▄▃▆▅▅▇▆▅▆▇▅█▅▇▁▄▄▇▆▅▃▅▄▅▇▇▄█▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75694
wandb: best/eval_avg_mil_loss 1.00698
wandb:  best/eval_ensemble_f1 0.75694
wandb:            eval/avg_f1 0.72463
wandb:      eval/avg_mil_loss 1.25448
wandb:       eval/ensemble_f1 0.72463
wandb:            test/avg_f1 0.75531
wandb:      test/avg_mil_loss 0.62107
wandb:       test/ensemble_f1 0.75531
wandb:           train/avg_f1 0.7309
wandb:      train/ensemble_f1 0.7309
wandb:         train/mil_loss 0.41697
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o6auwq0w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041426-o6auwq0w/logs
wandb: Agent Starting Run: zpgn4sb8 with config:
wandb: 	actor_learning_rate: 1.0967546482720011e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22156747185289127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7535308522815813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041549-zpgn4sb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zpgn4sb8
wandb: uploading history steps 200-219, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▅▅▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▂▂▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆███████████████
wandb:      eval/avg_mil_loss ██▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▃▂▂▂▂▂▅▅▅▆▆▆▆▆▆▆▆███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▅▂▂▅▄▃▁▇█▇▅▂▃▆▅▆▇▆█▅▄▄▄▃▅▅▅▅▁▆▄▇▃▄▅▄▆
wandb:      train/ensemble_f1 ▃▃▅▂▄▄▇▁▄▆▅▅▅▆▅▆▆▅█▃▅▆▇▇▇▃▇▃▅▆▄▇▆▇▄█▆▆▄▄
wandb:         train/mil_loss ▄▆█▆▅▇▄▄▆▄▅▂▅▃▂▄▅▅▃▃▁▄▅▆▆▄▄▃▃▄▄▄▄▄▃▃▇▄▄▄
wandb:      train/policy_loss █▆▇█▇▄▄▄▁▂▁▂▁▂▃▃▂▂▂▂▇█▇█▆▆▇█▇▆▇▇█▇█▇▆▆▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.24343
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.92573
wandb:      eval/avg_mil_loss 0.23449
wandb:       eval/ensemble_f1 0.92573
wandb:            test/avg_f1 0.93052
wandb:      test/avg_mil_loss 0.16641
wandb:       test/ensemble_f1 0.93052
wandb:           train/avg_f1 0.91814
wandb:      train/ensemble_f1 0.91814
wandb:         train/mil_loss 0.24285
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zpgn4sb8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041549-zpgn4sb8/logs
wandb: Agent Starting Run: 8xbwpsjp with config:
wandb: 	actor_learning_rate: 1.2922591358175116e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7142994087259202
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9176233457316456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041839-8xbwpsjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8xbwpsjp
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 219-237, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ██▅▅▅▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▂▂▂▄▄▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▅▅▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▄▄▄▄▄▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▃▁▆▄▅▂▃▇▇▄▃▆▄▄▄▂▄▅▇▇▅▆▆▆█▇▃▃▆▄▄█▅▃▄▆▆
wandb:      train/ensemble_f1 ▁▆▅▄▃▁▅▄▃▂▁▅▅▄▃▃▃▂▂▄▃▃▇▆▄▂▃▂▄▃██▃▃▃▃▅▅▃▅
wandb:         train/mil_loss ▄▇▆▇▅▁▁▄▄▃▂█▅▄▄▅▇▅▄▇▅▆▅▄▃▆▃█▇▅▃▆▅▃▆▅▄▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.2981
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.29225
wandb:       eval/ensemble_f1 0.90667
wandb:            test/avg_f1 0.93824
wandb:      test/avg_mil_loss 0.15967
wandb:       test/ensemble_f1 0.93824
wandb:           train/avg_f1 0.91704
wandb:      train/ensemble_f1 0.91704
wandb:         train/mil_loss 0.23331
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8xbwpsjp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041839-8xbwpsjp/logs
wandb: Agent Starting Run: 06zq01mf with config:
wandb: 	actor_learning_rate: 1.0102689780941506e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06253849164866898
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.918274256922424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042145-06zq01mf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06zq01mf
wandb: uploading history steps 141-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▅▅▅▅▃▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▃▄▅▅▅▆▅▇▆▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▆▅▄▄▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▄▄▅▅▆▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▃▁▂▃▁▄▃▃▄▄▅▅▄▅▄▄▅█▆▆▆▅▄▅▇▅▅▆▄▆█▇▅▅▇▆▇
wandb:      train/ensemble_f1 ▃▃▅▁▁▁▄▄▂▄▄▃▄▃▂▆▅▅▄▄▄▆▆▆▆▆▆▇▆▄▄▆▇▆█▇▅▆▅█
wandb:         train/mil_loss █▄▆▆▆▄▆█▅▆▅▃▄▇▅▃▃▅▄▃▇▃▂▄▁▅▁▃▂▃▂▄▂▄▃▄▃▄▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄█▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92587
wandb: best/eval_avg_mil_loss 0.26431
wandb:  best/eval_ensemble_f1 0.92587
wandb:            eval/avg_f1 0.9186
wandb:      eval/avg_mil_loss 0.24787
wandb:       eval/ensemble_f1 0.9186
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.14668
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.92705
wandb:      train/ensemble_f1 0.92705
wandb:         train/mil_loss 0.23003
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06zq01mf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042145-06zq01mf/logs
wandb: Agent Starting Run: rragbcmv with config:
wandb: 	actor_learning_rate: 1.1235134032961316e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.32555706610367385
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9137348093319848
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042349-rragbcmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rragbcmv
wandb: uploading output.log; uploading config.yaml; uploading history steps 218-237, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▅▆▆▇█
wandb: best/eval_avg_mil_loss ██▅▅▄▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▄▄▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▁▁▂▅▆▅▅▆▆▆▆▆▆▆▆▇▇▇█████████████▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▄▆▃▆▅▄▃▆▄▆▄▆▅▅▅▆▆▇▇▇█▇▇▇▅▅█▆█▆▅▆▇▆▇▇
wandb:      train/ensemble_f1 ▃▁▂▄▃▃▃▃▃▄▃▃▅▅▃▅▅▅▅▅▅▅▅▆▅▇▆▅▅▇█▇▇▅█▅▄▅▆▆
wandb:         train/mil_loss █▅▅▄▇▅▃▅██▄▇▃▅█▇▇▇▄▅▆▃▇▄▄▅▁▆▂▄▃▂▂▃▄▅▆▁▂▂
wandb:      train/policy_loss ▆█▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.25984
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.91069
wandb:      eval/avg_mil_loss 0.25336
wandb:       eval/ensemble_f1 0.91069
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.15607
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.9148
wandb:      train/ensemble_f1 0.9148
wandb:         train/mil_loss 0.24765
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rragbcmv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042349-rragbcmv/logs
wandb: Agent Starting Run: ookan6i0 with config:
wandb: 	actor_learning_rate: 1.0310912831235431e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9702177089617744
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4006044068965934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042655-ookan6i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ookan6i0
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▆▇██▅▇█▅▅▅▅▅▄▄▄▄▃▃▄▄▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▃▂
wandb:       eval/ensemble_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▂▆▅▅▃▄▆▃▄▆▇▅▇▆▆▆▆▅▅▇▇▇▃▄▆▅▁▅▃▄▃▄▄▅▃█▆
wandb:      train/ensemble_f1 ▂▆▅▁▄▆▄▅▃▄▄▇▅▆▇▄▆▅▇▅▆▆▆▅▃▆▅▇▇▇▆▅▅▁▅▃▅▃█▂
wandb:         train/mil_loss ▇▄▆▇▅▇▆▇▇▇▆▅▆▇▅▆▄▆▆▅▆█▅▇▇▅▄▄▅▆▇▇▁▅▇▆▆▃█▄
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89197
wandb: best/eval_avg_mil_loss 0.32496
wandb:  best/eval_ensemble_f1 0.89197
wandb:            eval/avg_f1 0.88836
wandb:      eval/avg_mil_loss 0.32298
wandb:       eval/ensemble_f1 0.88836
wandb:            test/avg_f1 0.89191
wandb:      test/avg_mil_loss 0.19586
wandb:       test/ensemble_f1 0.89191
wandb:           train/avg_f1 0.86855
wandb:      train/ensemble_f1 0.86855
wandb:         train/mil_loss 0.23437
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ookan6i0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042655-ookan6i0/logs
wandb: Agent Starting Run: jibc7qtg with config:
wandb: 	actor_learning_rate: 1.504083241293814e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9779118914537164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8732238912952998
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042817-jibc7qtg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jibc7qtg
wandb: uploading history steps 237-248, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▃▆▆▃▃▃▃▆▆▆█████████████▆▆
wandb:      eval/avg_mil_loss █▆▆▆▅▅▅▅▅▅▄▄▃▃▃▂▃▃▃▂▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▆▆▃▆▆▆▆████████████▆██▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▃▄█▃▂▃▃▁▅▅▃▂▅▅▃▃▅▃▃▂▂▂▅▃▄▃▃▅▁▂▁▃▄▅▂▅▃
wandb:      train/ensemble_f1 █▅▆▄▅▄▅▇▆▁▄▄▃▆▁▅▃▅▄▄▅▅▅▄▄█▅▇▇█▃▅▅▇▅▃▇▃▁▄
wandb:         train/mil_loss ▃▃▄▂▂▄▂▃▃▂▄▃▅▅▅▅▄▄▃▄▄▄▃▅▄▁▂▃▇▇▃▇▁▃█▃▂▅▄▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▁▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▂▇█▅▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87885
wandb: best/eval_avg_mil_loss 0.3933
wandb:  best/eval_ensemble_f1 0.87885
wandb:            eval/avg_f1 0.87488
wandb:      eval/avg_mil_loss 0.39389
wandb:       eval/ensemble_f1 0.87488
wandb:            test/avg_f1 0.91375
wandb:      test/avg_mil_loss 0.20599
wandb:       test/ensemble_f1 0.91375
wandb:           train/avg_f1 0.8743
wandb:      train/ensemble_f1 0.8743
wandb:         train/mil_loss 0.23348
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jibc7qtg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042817-jibc7qtg/logs
wandb: Agent Starting Run: povf5srx with config:
wandb: 	actor_learning_rate: 1.1817055879539398e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5370994159631421
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7359418409861416
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043134-povf5srx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/povf5srx
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄██████████████▄▄█▄████████████▄▄▄▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇███▇▇▇▇▇▇▇▇▆▆▄▅▅▄▃▃▄▅▄▄▄▂▂▂▂▂▃▅▅▄▃▃▃▃▁
wandb:       eval/ensemble_f1 ▄█████████████▄▄▄█▄▄██████████▄██▄▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▄▇▇▅▄▅▁▇▅▅▃▃▃▅▁▆▅▅▄▅▆▄▇▄▅▄▄█▁▁▅▆▄▄▅▄▆▃
wandb:      train/ensemble_f1 ▅█▅▄▄▇▄▅▁▅▃▄▂▃▃▄▇▆▄▃▄▇█▁▄▄▅▄█▃▂▂▅▅▄▄▁▄▆▃
wandb:         train/mil_loss ▆▅▁▅▅▄▅▅▆▅▆▆▆▅█▅▅▄▆▄▅▅▅▅▇▅▇▄▅▅▄▅▅▆▆▅▅▇▄▇
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90687
wandb: best/eval_avg_mil_loss 0.26897
wandb:  best/eval_ensemble_f1 0.90687
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.26747
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.91566
wandb:      test/avg_mil_loss 0.22989
wandb:       test/ensemble_f1 0.91566
wandb:           train/avg_f1 0.90537
wandb:      train/ensemble_f1 0.90537
wandb:         train/mil_loss 0.24732
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/povf5srx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043134-povf5srx/logs
wandb: Agent Starting Run: myptdkmp with config:
wandb: 	actor_learning_rate: 1.0830927743659824e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28321651881377197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.76496568609366
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043257-myptdkmp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myptdkmp
wandb: uploading wandb-summary.json; uploading config.yaml; uploading history steps 141-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▇▇█
wandb: best/eval_avg_mil_loss █▇▄▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅▇▇█
wandb:            eval/avg_f1 ▁▁▂▂▅▇▇▇▇▅▅██████▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▅▅▇▇▇▇▇▅▇████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▃▅▄▅▄▄▅▅▅▅▅▅▆▆▅▅▆█▆▅█▄▅▄▄▇▅▄▄▆▄▄▅▅▅▆▆
wandb:      train/ensemble_f1 ▃▂▁▃▄▂▂▅▄▂▄▅▄▄▄█▅▅▇▅▃▆▄▆██▅▃▆▇▄▅▆▅▆▆▆▅▇▅
wandb:         train/mil_loss ▅▇▅█▅▅▅▃▃▃▄▃▅▃▅▃▄▄▄▂▅▃▃▄▂▃▃▅▄▃▃▄▅▂▂▃▃▁▄▅
wandb:      train/policy_loss ██████▂█████▁███████▇███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁████████████▇████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.28326
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.91087
wandb:      eval/avg_mil_loss 0.26652
wandb:       eval/ensemble_f1 0.91087
wandb:            test/avg_f1 0.92679
wandb:      test/avg_mil_loss 0.17098
wandb:       test/ensemble_f1 0.92679
wandb:           train/avg_f1 0.91767
wandb:      train/ensemble_f1 0.91767
wandb:         train/mil_loss 0.22019
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myptdkmp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043257-myptdkmp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v5csqir1 with config:
wandb: 	actor_learning_rate: 1.0277385459265208e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8519965235063525
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.610178647750973
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043510-v5csqir1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v5csqir1
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▅▁▄▄█▄▄▄▄▄▄▄▄▄▄▄███████▄██████████████
wandb:      eval/avg_mil_loss █▇▇▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ███▂▂▁▁█▁▁▁▇▁▁▁▁▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▂▄▄▆▃▁▃▄▄▃▅▆█▅▅▄▄▆▅▅▅▆▇▄▅▅▄▇█▅▄█▃▇▄█▄▄
wandb:      train/ensemble_f1 ▄▃▂▄▄▃▅▆▄▃▃▁▃▃▄▆▇▄▅▇▆▅▅▄▅▅▅▅▃▅▇▄▅█▅▆▇▅▆▇
wandb:         train/mil_loss ▄▅▆▅▅█▃▃▆▂▃▇▂▅▅▆▄▄▅▇▄▂▆▂▇▄▇▅▅▄▇▁█▅▆▄█▄▂▇
wandb:      train/policy_loss ▃▃▃▁▆█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89737
wandb: best/eval_avg_mil_loss 0.31211
wandb:  best/eval_ensemble_f1 0.89737
wandb:            eval/avg_f1 0.89688
wandb:      eval/avg_mil_loss 0.29572
wandb:       eval/ensemble_f1 0.89688
wandb:            test/avg_f1 0.88427
wandb:      test/avg_mil_loss 0.33956
wandb:       test/ensemble_f1 0.88427
wandb:           train/avg_f1 0.90731
wandb:      train/ensemble_f1 0.90731
wandb:         train/mil_loss 0.25375
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v5csqir1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043510-v5csqir1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: di10hayz with config:
wandb: 	actor_learning_rate: 1.07990375793405e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8914671988840384
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0586546636383225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043644-di10hayz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/di10hayz
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▄▄▄▄▂▂▃▃▂▁▁▁▂▂▁▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▄▁▃▆▅▅▄▄▅▄▆▄▄▄▄▇▃▃▆▄▇▄▃▃▃▅▇▄▅▇▅▆█▂▄▇▆
wandb:      train/ensemble_f1 ▂▅▂▃▅▂▄▄▂▅▂▄▁▃▃▄▂▅▄▃▄▃▃▂▂▆▃▆▅▃▄▇▄▄▂▄▆▄▁█
wandb:         train/mil_loss ▁▂▃▂▂▂▁▂▂▂▄▆▁▃▂▂▄▄▄▅▂▃█▃▃▃▁▂▂▁▆▇▅▄▄▆▄▃▇▄
wandb:      train/policy_loss ▇█▆▇▇▇▃▇▇▆▇▃▆▁▇▆▆▆▆▆▅▆▇▇▇▇▆▆▃▄▄▇▆▇▆▆▇▃▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▅▇▅▇▇▇▁▆▅▂▆▇▅▆▆▇▅▇█▇▇█▄▆▅▇▆▅▆▇▆▆▆▇▇▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.48369
wandb: best/eval_avg_mil_loss 2.25027
wandb:  best/eval_ensemble_f1 0.48369
wandb:            eval/avg_f1 0.48369
wandb:      eval/avg_mil_loss 2.21352
wandb:       eval/ensemble_f1 0.48369
wandb:            test/avg_f1 0.4134
wandb:      test/avg_mil_loss 2.17574
wandb:       test/ensemble_f1 0.4134
wandb:           train/avg_f1 0.46789
wandb:      train/ensemble_f1 0.46789
wandb:         train/mil_loss 0.42053
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/di10hayz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043644-di10hayz/logs
wandb: Agent Starting Run: qfrqrqg2 with config:
wandb: 	actor_learning_rate: 0.0010694820153216251
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9922382541130744
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9827918144366394
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043806-qfrqrqg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qfrqrqg2
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▁▁▁▃▃▃▂▁▂▃▁▂▁▁▁▂▃▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▄▂▃▅▁▃▂▃▂▂▄▆▄▄▄▃▇▃▅▄█▄▂▃▅▃▅▅▅▃▅▅▅▅▃▃▄
wandb:      train/ensemble_f1 ▂▂▂▄▅▃▃▄▂▂▅▂▂█▅▄▄▃▃▄▃▄▇▃█▅▂▄▅▅▅▃▅▁▅▃▅▁▄▂
wandb:         train/mil_loss ▅▅▃▃▅▁▄█▃▁▅▃▃▂▅▃▃▃▆▇▄▅▆▃▂▄▄▄▅▅▂▄▂▂▃▃▃▃▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8669
wandb: best/eval_avg_mil_loss 0.39104
wandb:  best/eval_ensemble_f1 0.8669
wandb:            eval/avg_f1 0.8669
wandb:      eval/avg_mil_loss 0.38405
wandb:       eval/ensemble_f1 0.8669
wandb:            test/avg_f1 0.90591
wandb:      test/avg_mil_loss 0.20598
wandb:       test/ensemble_f1 0.90591
wandb:           train/avg_f1 0.87741
wandb:      train/ensemble_f1 0.87741
wandb:         train/mil_loss 0.2423
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qfrqrqg2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043806-qfrqrqg2/logs
wandb: Agent Starting Run: 9py6xi07 with config:
wandb: 	actor_learning_rate: 0.00012801346719614628
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5114700145993256
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9924056819081865
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043929-9py6xi07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9py6xi07
wandb: uploading history steps 219-226, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ██▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▂▂▄▅▅▅▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▆
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▂▅▅▅▅▅▅▅▇▇▇▇▇▇██████▇▇▇▇▇▇▇▇▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▄▆▄▂▄▅▅▄▁▄▅▆▂▄▄▇▇▆▇▄▇▆▇▃▅▅▇▂▄▄█▂▅▅▆▇▄█
wandb:      train/ensemble_f1 ▄▃▁▄▃▄▃▄▅▃▅▅▄▃▄▅▅▃▅▆▃▅▄▆▄█▄▅▅▅▅▇▄▁▇▄▄▅▅▄
wandb:         train/mil_loss ▆▄▆▆▇▅▁▃▄▃▆▇▆▄▃▂▆▃█▃▆▅▆▄▄▁▃▃▅▆▆▃▂▆▃▃▃▄▂▂
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▁▄▁▃▃▃▆▆▃▃█▃▆▁▃▃▃▃▃▃▃▃▃▃▃▃▅▄▂▃▁▅█▄▂▇▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60462
wandb: best/eval_avg_mil_loss 2.02224
wandb:  best/eval_ensemble_f1 0.60462
wandb:            eval/avg_f1 0.59671
wandb:      eval/avg_mil_loss 1.94133
wandb:       eval/ensemble_f1 0.59671
wandb:            test/avg_f1 0.52769
wandb:      test/avg_mil_loss 1.95509
wandb:       test/ensemble_f1 0.52769
wandb:           train/avg_f1 0.58966
wandb:      train/ensemble_f1 0.58966
wandb:         train/mil_loss 0.68174
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9py6xi07
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043929-9py6xi07/logs
wandb: Agent Starting Run: 63f51ksr with config:
wandb: 	actor_learning_rate: 0.009005130053390919
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9733944491351316
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8124877908177535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044225-63f51ksr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63f51ksr
wandb: uploading config.yaml
wandb: uploading history steps 99-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▁▂▅▇███████████████████████████████████
wandb:      eval/avg_mil_loss █▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▁▆▆▇███████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▅▁▅▇▆▇▇▇▇▇▇▇▆▇▆▆▇▆▇▆█▇▆▇▆▆▆▇▆▆▇▆▆▇▇▆▇▆
wandb:      train/ensemble_f1 ▁▃▃▄▆▆▇▇█▆█▆▇▇▇▆▇▇▆▇▅█▆▇█▆▇▇▇█▇▇▆▆▆▇█▅▇█
wandb:         train/mil_loss ▇▇▇▅▆▆▃▇▆▇▅▄▆▇▃▄▆▆▄▆▅▇▄█▇▄▂█▃▆█▁▅▂▅▄▃▆▅▄
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.3314
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.32545
wandb:       eval/ensemble_f1 0.9105
wandb:            test/avg_f1 0.93824
wandb:      test/avg_mil_loss 0.15851
wandb:       test/ensemble_f1 0.93824
wandb:           train/avg_f1 0.90772
wandb:      train/ensemble_f1 0.90772
wandb:         train/mil_loss 0.22014
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63f51ksr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044225-63f51ksr/logs
wandb: Agent Starting Run: 04rqxgzs with config:
wandb: 	actor_learning_rate: 1.646497353898182e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9892216309055636
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5491283254567313
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044358-04rqxgzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/04rqxgzs
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▁▁▁▅▅▆▆▆▅█▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▅▇▃▆▆▂▇▇▄▅█▇▇▇▆▆▅▅▄▅▄▅▆▄▅▄▆▂▆▄▁▅▅▅▆▇▄▇
wandb:      train/ensemble_f1 ▅▅▆▆▄▆▅▄▅█▅▄▄▆▅▆▅▇█▆▄▆█▅▅▄▅▅▁▅▅▅▄▆▆▆▄▅▅▅
wandb:         train/mil_loss ▅▃▁▁▃▅▂▃▆█▅▃▂▄▅▅▅▅▆▆▃▃▇▄▄▄▅▁▅▅▂▄▄▇▄▅▄▄▇▄
wandb:      train/policy_loss ████████▇█▇████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▇███▇████████▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80985
wandb: best/eval_avg_mil_loss 0.57974
wandb:  best/eval_ensemble_f1 0.80985
wandb:            eval/avg_f1 0.80613
wandb:      eval/avg_mil_loss 0.59002
wandb:       eval/ensemble_f1 0.80613
wandb:            test/avg_f1 0.83391
wandb:      test/avg_mil_loss 0.32937
wandb:       test/ensemble_f1 0.83391
wandb:           train/avg_f1 0.81199
wandb:      train/ensemble_f1 0.81199
wandb:         train/mil_loss 0.23819
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/04rqxgzs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044358-04rqxgzs/logs
wandb: Agent Starting Run: fo5887xu with config:
wandb: 	actor_learning_rate: 1.0233309382978902e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7691050998905964
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8327822650160791
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044520-fo5887xu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo5887xu
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 177-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▇█
wandb: best/eval_avg_mil_loss ██▆▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▃▃▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▇▇▆▆▆▅▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▃▅▅▅▅▆▅▅▅▆▆▆▆▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▂▂▄▁▄▃▄▄▃▂▆▄▆▂▅▅▇▂▃▃▆▆▅█▇▆▆▄▇▄▅▄▇▃▅▄▆▅
wandb:      train/ensemble_f1 ▄▁▅▁▃▂█▃▂▅▄▃▃▆▇▄▂▄▄▅▇▅▅▆▅▄▅▆█▆▇▆▅▅▆▅▅▅▇▇
wandb:         train/mil_loss ▇▄▅▃█▃▃▆▄▂▆▅▄▄▂▅▆▆▅▃▄▄▃▅▁▄▃▃▆▇▃▃▆▄▃▃▅▂▆▄
wandb:      train/policy_loss ▆▁▃▃▃▃▃▃▃▃▅▇▆▅▅▃▃▃▃█▅▆▆▆█▆▄▆▄▆▄▇▇▄▅▇▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84651
wandb: best/eval_avg_mil_loss 0.3658
wandb:  best/eval_ensemble_f1 0.84651
wandb:            eval/avg_f1 0.84642
wandb:      eval/avg_mil_loss 0.35984
wandb:       eval/ensemble_f1 0.84642
wandb:            test/avg_f1 0.88476
wandb:      test/avg_mil_loss 0.26963
wandb:       test/ensemble_f1 0.88476
wandb:           train/avg_f1 0.85009
wandb:      train/ensemble_f1 0.85009
wandb:         train/mil_loss 0.21999
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo5887xu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044520-fo5887xu/logs
wandb: Agent Starting Run: h7mdqi6r with config:
wandb: 	actor_learning_rate: 0.0046367941588376736
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9898355523787764
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9844903979308562
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044751-h7mdqi6r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h7mdqi6r
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ██████████▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▂▄▅▆▆▇▇▇▇▇▇██████████████████████
wandb:       eval/ensemble_f1 ███████▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █████████▇▇▆▆▅▂▁▂▂▁▂▂▂▂▂▂▁▂▂▁▁▂▂▁▂▁▁▁▁▂▂
wandb:      train/ensemble_f1 ▇████▇▇▇▆▅▄▃▂▂▂▂▁▁▂▁▂▂▂▂▁▂▁▂▁▂▂▁▂▂▂▁▁▂▁▁
wandb:         train/mil_loss ▄▃▃▃▃▄▃▄▂▃▄▂▂▆▃▅▃▃▃▂▅▃▃▂▃▅█▁█▅▂▄▂▇█▅▃▃▄▃
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▂▁▁▁▁▁▅▁▅▅█▁▁▅▁▁▁▁▂▂▁▁▁▁▁▁▂▁▂▁▁▁▁▂▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9046
wandb: best/eval_avg_mil_loss 0.26403
wandb:  best/eval_ensemble_f1 0.9046
wandb:            eval/avg_f1 0.65824
wandb:      eval/avg_mil_loss 1.0367
wandb:       eval/ensemble_f1 0.65824
wandb:            test/avg_f1 0.9247
wandb:      test/avg_mil_loss 0.16849
wandb:       test/ensemble_f1 0.9247
wandb:           train/avg_f1 0.68572
wandb:      train/ensemble_f1 0.68572
wandb:         train/mil_loss 0.22786
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h7mdqi6r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044751-h7mdqi6r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wk761was with config:
wandb: 	actor_learning_rate: 0.005645500776993351
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9466820018861332
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6442361094469843
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044939-wk761was
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wk761was
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 99-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▂▁█████████▇▇▇▆▆▆
wandb:       eval/ensemble_f1 ▁▁▁████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▇▃▆▃▅▅▄▄▄▅▅▁▄▆▅▃▄▅▄▅▃▂█▆▂▅▅▅▃▃▄▂▂▃▆▅▁▂
wandb:      train/ensemble_f1 ▃▄▁▃▆▆▄█▆▄▅▅▆▂▃▅▅▆▆▃▄▄▆▅▃▃▂▅▆▂▅▃▆▄▅▁▂▆▂▅
wandb:         train/mil_loss ▅▄▂█▁▅▂▃▅▂▄▂▄▇▁█▁▅▄█▇▆▂▅▅▁▂▇▂▂▂▂▇▂▄▂▂▆▂▄
wandb:      train/policy_loss ▂█▂▁▂▁▃▂▂▁▁▃▂▃▁▃▂▂▃▂████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55905
wandb: best/eval_avg_mil_loss 2.30177
wandb:  best/eval_ensemble_f1 0.55905
wandb:            eval/avg_f1 0.55396
wandb:      eval/avg_mil_loss 2.3097
wandb:       eval/ensemble_f1 0.55396
wandb:            test/avg_f1 0.5207
wandb:      test/avg_mil_loss 2.13728
wandb:       test/ensemble_f1 0.5207
wandb:           train/avg_f1 0.54441
wandb:      train/ensemble_f1 0.54441
wandb:         train/mil_loss 0.2273
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wk761was
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044939-wk761was/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wtqywozr with config:
wandb: 	actor_learning_rate: 1.48607212013605e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12082999266687512
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8123261051645565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045135-wtqywozr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wtqywozr
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆██
wandb: best/eval_avg_mil_loss █▇▆▅▅▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆██
wandb:            eval/avg_f1 ▁▃▃████▆▆▆▆▆███▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▄▄███████▆▆▆▆███▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▅█▇▅▆▅▅▃▅▄██▇▇▆▅▅▃▆▅▃▁▄▂▇▅▃▅▇▆▃▄▇▅▄▄▅▅
wandb:      train/ensemble_f1 ▃▄▄▆▅█▄▄▄▅▆▂▃▅▂▃▂▄▄▃█▂▂▂▄▁▄▇▆▁▂▁▁▅▂▃▂▃▃▃
wandb:         train/mil_loss █▂▃▄▅▅▄▄▃▂▂▂▃▄█▃▁▂▄▅▂▄▅▂▂▁▅▃▃▃▁▃▂▇▁▃▃▂▃▄
wandb:      train/policy_loss ▆▆▆▆▁▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.25944
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.91873
wandb:      eval/avg_mil_loss 0.25003
wandb:       eval/ensemble_f1 0.91873
wandb:            test/avg_f1 0.93494
wandb:      test/avg_mil_loss 0.13546
wandb:       test/ensemble_f1 0.93494
wandb:           train/avg_f1 0.91735
wandb:      train/ensemble_f1 0.91735
wandb:         train/mil_loss 0.21863
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wtqywozr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045135-wtqywozr/logs
wandb: Agent Starting Run: t148p9ml with config:
wandb: 	actor_learning_rate: 1.3652878583352012e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6705198861181516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6558077746320655
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045349-t148p9ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t148p9ml
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 652-669, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇█▇▇███████████████
wandb:      eval/avg_mil_loss ████▇▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▃▃▃▄▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▂▃▄▄▄▄▅▅▅▆▄▆▇▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▆▇████
wandb:      train/ensemble_f1 ▁▂▂▂▃▃▃▃▃▄▄▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▆▇▇▇▆▆█▇▇▆▇▇▇█
wandb:         train/mil_loss ▇▇▇█▆▆▇▆▃▁▆▄▃▅▆▄▁▅▅▂▂▄▄▅▆▃▃▃▅▆▃▄▃▄▅▅▄▃▃▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▁▄▃█▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▄▃▃▁▂▃▅▆▃▃▆▇▅▃▃▃▃▃▃▂▁▃▃▃▃▃▄▇▆█▆▄▄▇▄▁▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89688
wandb: best/eval_avg_mil_loss 0.31963
wandb:  best/eval_ensemble_f1 0.89688
wandb:            eval/avg_f1 0.89312
wandb:      eval/avg_mil_loss 0.31718
wandb:       eval/ensemble_f1 0.89312
wandb:            test/avg_f1 0.90939
wandb:      test/avg_mil_loss 0.3259
wandb:       test/ensemble_f1 0.90939
wandb:           train/avg_f1 0.90452
wandb:      train/ensemble_f1 0.90452
wandb:         train/mil_loss 0.22682
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t148p9ml
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045349-t148p9ml/logs
wandb: Agent Starting Run: fdu7cl8n with config:
wandb: 	actor_learning_rate: 1.1215585257514003e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.010123338558281623
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5750431473321109
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050224-fdu7cl8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdu7cl8n
wandb: uploading history steps 502-517, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▆▆▆▇▇▆▄▄▄▄▄▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▂▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇██████████
wandb:      eval/avg_mil_loss ██▇▇▆▇▇▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▃▄▅▅▅▅▅▅▅▅▇▇▇▇▇▆▇▇▇▇▇▇▇▇██████▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▃▃▃▃▃▃▅▅▅▅▄▆▄▆▆▅▇▅▅▅▆▅▆▅▆█▆▆█▆▆▆▇▇▅▃▇
wandb:      train/ensemble_f1 ▁▂▁▄▃▃▃▃▃▅▅▅▃▆▃▅▅▅▄▄▄▄▆▅▆▃▇▆▅▄▆▄█▇▆▆▅▇▆▄
wandb:         train/mil_loss ▆█▇▇▇▇▅▆▇█▅▆▄▅▄▇▅▆▄▅▅▆▅▅▃▇▅▅▆▁▄▃▅▃▄▄▄▄▂▄
wandb:      train/policy_loss ██████████████████████████▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59001
wandb: best/eval_avg_mil_loss 2.34673
wandb:  best/eval_ensemble_f1 0.59001
wandb:            eval/avg_f1 0.58507
wandb:      eval/avg_mil_loss 2.2921
wandb:       eval/ensemble_f1 0.58507
wandb:            test/avg_f1 0.5461
wandb:      test/avg_mil_loss 2.22983
wandb:       test/ensemble_f1 0.5461
wandb:           train/avg_f1 0.55602
wandb:      train/ensemble_f1 0.55602
wandb:         train/mil_loss 2.05253
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdu7cl8n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050224-fdu7cl8n/logs
wandb: Agent Starting Run: cn3beoa9 with config:
wandb: 	actor_learning_rate: 1.110081127611705e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1809054607242596
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9006991075523514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050856-cn3beoa9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cn3beoa9
wandb: uploading history steps 240-257, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss █▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▆▆▆▃▃▃▃▃▃██████████▆▆▄▄▄
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▆▆▆▆▆▃▃▃▆██████████▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▅▆▅▃▇▅▃▅▅▁▆▂▅▆█▆▄▇▆█▆▆▂█▇▃▆▆▄▄▄▅▅▆▆▇▇▄
wandb:      train/ensemble_f1 ▅▇▄▅▅▄▅▃▆▄▅▃▁▅▇▆▅▇▄▄▆▇▅▇▅▅▆█▅█▆▄▄▅▅▆▅▆▆▅
wandb:         train/mil_loss ▄▅▇▆▃▃▆▇▇▂▆▄▅▆▆▅▄▃▃█▂█▃▂▁▆▁▆▆▆▅▂▇▂▅▂▄▂▂▁
wandb:      train/policy_loss ▃▂▂▃▃▁▂▂▇▇██▃▁▂▃▃▄▂▂▃▃▁▃▂▇▇▇█▇█▇██▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.30017
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.91845
wandb:      eval/avg_mil_loss 0.27274
wandb:       eval/ensemble_f1 0.91845
wandb:            test/avg_f1 0.93026
wandb:      test/avg_mil_loss 0.15473
wandb:       test/ensemble_f1 0.93026
wandb:           train/avg_f1 0.92634
wandb:      train/ensemble_f1 0.92634
wandb:         train/mil_loss 0.20865
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cn3beoa9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050856-cn3beoa9/logs
wandb: Agent Starting Run: si55kgm3 with config:
wandb: 	actor_learning_rate: 1.0861361220902236e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5319034993883724
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.890494239851359
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051217-si55kgm3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/si55kgm3
wandb: uploading history steps 219-224, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▇▇▆▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▂▃▄▄▅▄▆▄▅█▄▅▄▅▅▅▂▁▃▅█▃▇▅▇▅▅▄▅▅▅▅▆▇▇▇▅▅
wandb:      train/ensemble_f1 ▂▂▁▂▃▄▃▄▄▄█▂▅▃▃▄▄▄▅▆▄▂▃▃▆▇▃▄▄▆▆▅▅▅▅▇▅▆▄▄
wandb:         train/mil_loss ▄▃▄▅▅▄▅▅▂▇▅▃▄▁▃▃▄▃▆▂▅▂▄▃▄▅▄▄▅▅▁▂▂▄▄▄▂█▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89772
wandb: best/eval_avg_mil_loss 0.43319
wandb:  best/eval_ensemble_f1 0.89772
wandb:            eval/avg_f1 0.89772
wandb:      eval/avg_mil_loss 0.42864
wandb:       eval/ensemble_f1 0.89772
wandb:            test/avg_f1 0.8992
wandb:      test/avg_mil_loss 0.20442
wandb:       test/ensemble_f1 0.8992
wandb:           train/avg_f1 0.89619
wandb:      train/ensemble_f1 0.89619
wandb:         train/mil_loss 0.25973
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/si55kgm3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051217-si55kgm3/logs
wandb: Agent Starting Run: 07dpl8m9 with config:
wandb: 	actor_learning_rate: 2.683316075023677e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1097129561180472
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9422992449546423
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051512-07dpl8m9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/07dpl8m9
wandb: uploading wandb-summary.json
wandb: uploading history steps 463-480, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss ██▇▇▄▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▃▄▄▄▄▄▅▅▅▅▅▅▄▅▆▆▆▆▆▆▇▇███████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▃▃▃▃▅▅▅▅▅▃▃▅▅▅▅▆▆▆▆▆▆▆▆▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▃▂▁▇▃▅▃▄▅▅▅▅▄▆▄▁▅▄▅▇▄▅▅▅▇▃▆▆▆▆▇█▅▆▇▆▆
wandb:      train/ensemble_f1 ▂▂▂▃▂▅▅▃▄▃▃▅▆▁▃▄▆▅▆▅▆▇▇▆▆█▆▆██▇▇▆▆▇▅▇▇▆▆
wandb:         train/mil_loss ▅▅▇██▅▅▆▅▆▄▇▅▅▆▃▂▅▃▅▃▆▃▅▄▅▅▃▃▅▆▃▄▃▃▁▃▃▂▆
wandb:      train/policy_loss ▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.25499
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92937
wandb:      eval/avg_mil_loss 0.24732
wandb:       eval/ensemble_f1 0.92937
wandb:            test/avg_f1 0.92307
wandb:      test/avg_mil_loss 0.15679
wandb:       test/ensemble_f1 0.92307
wandb:           train/avg_f1 0.91871
wandb:      train/ensemble_f1 0.91871
wandb:         train/mil_loss 0.22818
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/07dpl8m9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051512-07dpl8m9/logs
wandb: Agent Starting Run: to0y35bb with config:
wandb: 	actor_learning_rate: 1.2380304400304024e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.434148091054507
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5980541029633224
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052117-to0y35bb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to0y35bb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄██████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▄▃▃▃▄▄▅▅▅▅▅▅▅████████████████▇▇▇▇▇
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▂▆█▁▆▅█▇▅▄▅▅▇▆▆▇█▆▄▅▅▂▃▇▃▂▆▄▆▆▇▅▆▅▆▇▅▅
wandb:      train/ensemble_f1 ▅▃█▅█▇▅█▄▄█▇▆▆▇▇▄▅▅▅▅▅▅▆▇▆▆▃▁▆▅▅▇▅▆▇▅▇▅▅
wandb:         train/mil_loss ▅▃▃▇▄▄▆▃▇▅▂▃▄▂▃▄▃▄▄▇▅▅▃▆▄▄▂▁▄██▆▄▂▅▅▂▄▄▃
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90236
wandb: best/eval_avg_mil_loss 0.29287
wandb:  best/eval_ensemble_f1 0.90236
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.29417
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.91072
wandb:      test/avg_mil_loss 0.25914
wandb:       test/ensemble_f1 0.91072
wandb:           train/avg_f1 0.8902
wandb:      train/ensemble_f1 0.8902
wandb:         train/mil_loss 0.24855
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to0y35bb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052117-to0y35bb/logs
wandb: Agent Starting Run: 0dknk1f8 with config:
wandb: 	actor_learning_rate: 1.1497777490157e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8557580398142077
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9949309696810748
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052239-0dknk1f8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0dknk1f8
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▆▆▃▄▃▇▅▆▅▇▅▁▅▄▃▅▄▇▅▃▄█▅▄▄▆▄▆▅▆▃▃▇▅▃▅▄
wandb:      train/ensemble_f1 ▆▃▁▅▆▄▇▆▅▃▇▄▃▄▃▄▅▃▆▄▅▄▁█▃▃▆▆▃▅▄▇▂▆▄▇▇▆▅▅
wandb:         train/mil_loss ▄▄▄▁▄▇▆▃▃▂▃▂▇▆▇▄▅▄▁▂▅▆▅█▃▃▄▄▂▅▄▄▄▆▃▂▆▇▃▄
wandb:      train/policy_loss ▇▆▄▆▇▅▇▇▇▄▄█▅▆▇▅▄▅▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄█▅▇▇▄▇█▇▇▆▄▇▅▇▄▃▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90325
wandb: best/eval_avg_mil_loss 0.24454
wandb:  best/eval_ensemble_f1 0.90325
wandb:            eval/avg_f1 0.89942
wandb:      eval/avg_mil_loss 0.24154
wandb:       eval/ensemble_f1 0.89942
wandb:            test/avg_f1 0.92679
wandb:      test/avg_mil_loss 0.21148
wandb:       test/ensemble_f1 0.92679
wandb:           train/avg_f1 0.91401
wandb:      train/ensemble_f1 0.91401
wandb:         train/mil_loss 0.2167
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0dknk1f8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052239-0dknk1f8/logs
wandb: Agent Starting Run: pai32si3 with config:
wandb: 	actor_learning_rate: 1.759129980676593e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6407671996524547
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46966399330015907
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052402-pai32si3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pai32si3
wandb: uploading history steps 179-187, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss ██▃▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▁▃▃▃▃▃▃▃▃▃▆▆▆▆█▆▆▆██████████████████████
wandb:      eval/avg_mil_loss ▇██▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▄▄███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▆▆▃▄▇▁▅▅▇▂▇▃▃▆▅▃▄▃▆▆▅▄██▇▅▄▅▂▅▂▆▂▄▇▃▅
wandb:      train/ensemble_f1 ▅▅▅▅▃▆▆▃▅▃▁▆▆█▇▆▅▃▄▃▃▄▆▄▆▂▄▄▅▇▅▄▇▄▂▄▆▆▅▆
wandb:         train/mil_loss ▇▄▆▂▅█▂▇▁▅▅▆▆▇▄▄▃▅▅▆▃▂▆▇▆▂▅▂▅▇▄▇▄▄▆▄▆▃▅▄
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▁▃▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88674
wandb: best/eval_avg_mil_loss 0.36557
wandb:  best/eval_ensemble_f1 0.88674
wandb:            eval/avg_f1 0.88674
wandb:      eval/avg_mil_loss 0.35191
wandb:       eval/ensemble_f1 0.88674
wandb:            test/avg_f1 0.90552
wandb:      test/avg_mil_loss 0.24267
wandb:       test/ensemble_f1 0.90552
wandb:           train/avg_f1 0.8806
wandb:      train/ensemble_f1 0.8806
wandb:         train/mil_loss 0.26912
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pai32si3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052402-pai32si3/logs
wandb: Agent Starting Run: riclhxif with config:
wandb: 	actor_learning_rate: 0.00020591218029722769
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9972921799087432
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9377536719104916
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052626-riclhxif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/riclhxif
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 217-227, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss ▁▂█▇▅
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▃▃▃▃▃▃▃▅▆▆▆▆▆▆███████████████████
wandb:      eval/avg_mil_loss ▁▁▂▅█████▇▇▇▇▇▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▁
wandb:       eval/ensemble_f1 ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▆▆▆▆▆▆██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▁▆▇▃▆▅▃▄▄█▇▇▇▆▇▅▂▄▆▇▇▆▅▄█▆▆▇▇▅▆█▆▅█▇▅█
wandb:      train/ensemble_f1 ▆▂█▇▂▅▁▃▄▅▂▂▅▃▇▅▇▇▆▆▇▆▅▇▆▅▆▄▇▅█▃▅▂▃▇█▅▆▄
wandb:         train/mil_loss ▂▂▃▂▃▃▂▂▂▃▂▂▂█▂▃▂▂▂▁▂▂▃▂▃█▂▂▁▁▃▁▂▂▂▂▂▂▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40633
wandb: best/eval_avg_mil_loss 3.5449
wandb:  best/eval_ensemble_f1 0.40633
wandb:            eval/avg_f1 0.40633
wandb:      eval/avg_mil_loss 3.52487
wandb:       eval/ensemble_f1 0.40633
wandb:            test/avg_f1 0.37829
wandb:      test/avg_mil_loss 3.59424
wandb:       test/ensemble_f1 0.37829
wandb:           train/avg_f1 0.40526
wandb:      train/ensemble_f1 0.40526
wandb:         train/mil_loss 0.20632
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run woven-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/riclhxif
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052626-riclhxif/logs
wandb: Agent Starting Run: co1nxq7c with config:
wandb: 	actor_learning_rate: 2.4781265548868e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3385219303334688
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7022444603547876
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052927-co1nxq7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/co1nxq7c
wandb: uploading history steps 339-347, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▅▄▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▂▂▂▂▃▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▂▂▂▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▁▄▄▄▄▃▄▅▃▄▄▅▄▄▄▄▅▄▅▅▇▆▂▄▆▄▆▆▄▃▆▅▄▅█▇▄
wandb:      train/ensemble_f1 ▁▃▁▃▃▂▂▄▃▄▃▄▃▅▄▅▄▄▅▆▅▅▅▄▅▆▅▄▅▃▅▄▅▄▄▆▄▄█▆
wandb:         train/mil_loss ▅▅█▆▅▄▄▃▆▃▅▆█▄▄▄▄▄▄▄▃▄▁▆▄▆▃▁▆▃▅█▆▃▂▃█▅▅▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▇██▆▇▄▂▄▃▃▄▂▅▃▂▄▄▂▄▁▃▃▄▂▄▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.33216
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.91414
wandb:      eval/avg_mil_loss 0.32064
wandb:       eval/ensemble_f1 0.91414
wandb:            test/avg_f1 0.93401
wandb:      test/avg_mil_loss 0.16117
wandb:       test/ensemble_f1 0.93401
wandb:           train/avg_f1 0.89095
wandb:      train/ensemble_f1 0.89095
wandb:         train/mil_loss 0.27853
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/co1nxq7c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052927-co1nxq7c/logs
wandb: Agent Starting Run: 49j8nhhf with config:
wandb: 	actor_learning_rate: 3.601964110300853e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.47809831221820864
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5399269736410361
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053354-49j8nhhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49j8nhhf
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▅▅▅▅▅▅▅█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▇▇▇▇█▇▆▄▃▃▃▃▁▁█▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃
wandb:       eval/ensemble_f1 ███▅▅▅▅▅▅▅▅▅██▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▁▇▆▅▂▆▄▃▆▂▃▇▃▆▃▄▂▃▄▅▃▄▂▅▅▂▆▄▇▅▁▅▆▅█▅▁▂
wandb:      train/ensemble_f1 ▆▅▄▆▅▅▆▅▅▄▇▆▂█▅▄▅▄▂▅▆▆▁▃▇▅▅▂█▇▄▆▆▇▆▆▅▅▂▃
wandb:         train/mil_loss ▇▅▃▃▅▆█▁▄▄▆▆▅▅▃▂▅▂▃▆▆▆▄▅▂▄▇▅▅▃▅▅▅▅▄▃▆▆▄▄
wandb:      train/policy_loss ▃▃▃▃▃▃▅▄▃▃▃▃█▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▄▃▃▃▃▃▃█▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89602
wandb: best/eval_avg_mil_loss 0.32975
wandb:  best/eval_ensemble_f1 0.89602
wandb:            eval/avg_f1 0.88836
wandb:      eval/avg_mil_loss 0.32851
wandb:       eval/ensemble_f1 0.88836
wandb:            test/avg_f1 0.91879
wandb:      test/avg_mil_loss 0.20435
wandb:       test/ensemble_f1 0.91879
wandb:           train/avg_f1 0.89746
wandb:      train/ensemble_f1 0.89746
wandb:         train/mil_loss 0.24583
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49j8nhhf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053354-49j8nhhf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3na3umzq with config:
wandb: 	actor_learning_rate: 2.341120267058831e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5532044856344336
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6453076660784507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053526-3na3umzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3na3umzq
wandb: uploading history steps 180-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss █▇▃▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▁▁▄▄▄▄▄▄▄▄▄▅▇▇▇▇▅▅▅▄▄▇▇███▇▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▅▅▅▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▄▄▄▄▄▄▄▄▇▇▇▇▅▅▄▇██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▂▁▃▅▄▂▄▃▃▃▄▅▄▄▂▆▃▄▄▄▄▄▅▅▃▅▄▂▃▄▄▅▃▅▄▂█
wandb:      train/ensemble_f1 ▄▄▂▃▁▃▃▃▂▂▂▄▄▆▄▄▄▄▅▃▆▇▄▄▃▄▄▆▆▄▃▃▃█▅▆▇▄▆▅
wandb:         train/mil_loss ▄▂▆▅▆▄▄▇▄▁▁▃▆▄▅▄▃▅▁▅▃▅▆▅▂▂▆▁▃▄▃▄▃▅▄▅▂▂▂█
wandb:      train/policy_loss ▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45063
wandb: best/eval_avg_mil_loss 2.97402
wandb:  best/eval_ensemble_f1 0.45063
wandb:            eval/avg_f1 0.43828
wandb:      eval/avg_mil_loss 2.90016
wandb:       eval/ensemble_f1 0.43828
wandb:            test/avg_f1 0.40767
wandb:      test/avg_mil_loss 3.22417
wandb:       test/ensemble_f1 0.40767
wandb:           train/avg_f1 0.43391
wandb:      train/ensemble_f1 0.43391
wandb:         train/mil_loss 1.14041
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3na3umzq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053526-3na3umzq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vteybuyc with config:
wandb: 	actor_learning_rate: 0.00010346924549853884
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9372298436370252
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7516352808479236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053810-vteybuyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vteybuyc
wandb: uploading wandb-summary.json
wandb: uploading history steps 238-251, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄███████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▄▅▄█▇▆▃▇▁▄▅▃▃▅▅▂▅▂▅▅▆▅▄▄▆▅▄▃▃▂▅▃▆▃▆▄▂
wandb:      train/ensemble_f1 ▄▄▃▄▅▂▃▄▅▇▃▄▇▄▅▆▁▅▁▂▂▅▅█▄▄▅▄▆▇▄▇▅▅▃▃▆▆▆▇
wandb:         train/mil_loss ▂▁▅▃▂▇▇▃▅█▄▅▆▃▅▄▁▃▃▄▂▄▂▁▅▃▂▅▄▅▃▆▃▂▃▃▂▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇████▆▇▇▆▆▆▇▆▆█▇▆▇▆▇▆▆▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇▆▇▇▄▆▇█▆▇▆▆▆▇█▅█▇▆▆██▇▇▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85757
wandb: best/eval_avg_mil_loss 0.74722
wandb:  best/eval_ensemble_f1 0.85757
wandb:            eval/avg_f1 0.85757
wandb:      eval/avg_mil_loss 0.74088
wandb:       eval/ensemble_f1 0.85757
wandb:            test/avg_f1 0.84231
wandb:      test/avg_mil_loss 0.44148
wandb:       test/ensemble_f1 0.84231
wandb:           train/avg_f1 0.85364
wandb:      train/ensemble_f1 0.85364
wandb:         train/mil_loss 0.27508
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vteybuyc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053810-vteybuyc/logs
wandb: Agent Starting Run: 4k6kitjs with config:
wandb: 	actor_learning_rate: 0.002218118520541559
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.389384143156874
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3812426022583174
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054126-4k6kitjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4k6kitjs
wandb: uploading history steps 140-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▁▄▂
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▆▆▆█████████▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆
wandb:      eval/avg_mil_loss ▇▇▇▇██████▇▇▇▇▆▆▆▆▆▆▆▆▅▄▄▄▄▃▃▃▃▂▁▁▁▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▆████████████▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▂▅▅▄▂▃▂▄▃▂▃▂▄▁▄▃▃▅▂▆▄▅▃▃▃▅▅▄▄▄▅▃█▄▅▆▆
wandb:      train/ensemble_f1 ▄▆▆▁▂▃▃▅▄▄▃▂▄▂▆▅▆▅▅▃▇▅▆▄▄▄▃▆▆█▇▆▄▅▆▅▇█▅▅
wandb:         train/mil_loss ▁▅▄▅█▂▆▆▇▄▆▅▄▅▄▄▂▅▅▇▅▄▃▅▅▄▂▄▅▄▆▆▅▄▄▂▃▁▄▅
wandb:      train/policy_loss ▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▅███████████████████████████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.39309
wandb: best/eval_avg_mil_loss 3.52379
wandb:  best/eval_ensemble_f1 0.39309
wandb:            eval/avg_f1 0.38637
wandb:      eval/avg_mil_loss 3.46361
wandb:       eval/ensemble_f1 0.38637
wandb:            test/avg_f1 0.3538
wandb:      test/avg_mil_loss 3.67098
wandb:       test/ensemble_f1 0.3538
wandb:           train/avg_f1 0.40288
wandb:      train/ensemble_f1 0.40288
wandb:         train/mil_loss 1.95533
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4k6kitjs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054126-4k6kitjs/logs
wandb: Agent Starting Run: yl14tj09 with config:
wandb: 	actor_learning_rate: 1.1522154717248955e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.909880775101431
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9949433907419544
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054319-yl14tj09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yl14tj09
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▅▅▅▆▆▆▇▆▆▆▆▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▆▆▆▅▂▄▅█▄▆▆▅█▄▄▇▅▆▂█▇▇▃▄▄▆▅▅▇▅▇▅▇▆▆▃▄▁
wandb:      train/ensemble_f1 ▁▃▆▆▅▁▃▄▇▆▄▃▆█▆▇▂▇▂▃▄▄▆▄▅█▇▄▃▇▃▄▆▃▃▅▄▅▂▃
wandb:         train/mil_loss ▂▅▃▄▁▅▂▃▆▅▅▂▃▂▅█▅▅▃▂▅▅▃▃▄▇▃▃▁▃▅▃▃▄▄▂▃▃▄▃
wandb:      train/policy_loss ▅▇▅▅█▇▅▇▅▇▁█▇▂███▅█▄▇▇▅▅▄▅█▇▄██▇▇▅▄▅█▄▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▆█▅▅▆█▆█▆▁▁█▆▅▃▅█▆█▅▆▆▃▅█▃▆██▃▆▆▆█▅█▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90646
wandb: best/eval_avg_mil_loss 0.27835
wandb:  best/eval_ensemble_f1 0.90646
wandb:            eval/avg_f1 0.90646
wandb:      eval/avg_mil_loss 0.28177
wandb:       eval/ensemble_f1 0.90646
wandb:            test/avg_f1 0.92999
wandb:      test/avg_mil_loss 0.16127
wandb:       test/ensemble_f1 0.92999
wandb:           train/avg_f1 0.88453
wandb:      train/ensemble_f1 0.88453
wandb:         train/mil_loss 0.22705
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yl14tj09
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054319-yl14tj09/logs
wandb: Agent Starting Run: b02j3djn with config:
wandb: 	actor_learning_rate: 0.002372699549042328
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6189557856512661
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05024227967333439
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054442-b02j3djn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b02j3djn
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▄▄▁▂
wandb:  best/eval_ensemble_f1 ▁▅▅▆▇▇█
wandb:            eval/avg_f1 ▄▄▆▆▅▁▂▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▇▇▇▂▁█▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▄▄▆▆█▁▃▄▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▇▅▅▅▆▄▃▄▄▆▅▃▅▄▆▅▆▆▅▅▅▇▅▆▆▄▅▆▄▆▅▅▄▆▄█▆▇
wandb:      train/ensemble_f1 ▁▇▇█▆▅▆▄▆▅▅▇▆▄▆▅▆▆▇▅▆▆▇▆▆▆▆▅▇▆█▇▇▆▆▇▇█▆█
wandb:         train/mil_loss ▆▄█▇▃▄▇▂▃▄▃▃▄▂▅▅▆▃▄▂▃▃▁▄▃▄▁▂▅▁▂▃▃▃▄▂▄▂▃▂
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇█▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.27595
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.26582
wandb:       eval/ensemble_f1 0.90667
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.18527
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.92206
wandb:      train/ensemble_f1 0.92206
wandb:         train/mil_loss 0.21948
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b02j3djn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054442-b02j3djn/logs
wandb: Agent Starting Run: s8fxpq1c with config:
wandb: 	actor_learning_rate: 0.007795224776704186
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22444831501680595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07703543112546885
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054626-s8fxpq1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s8fxpq1c
wandb: uploading history steps 301-305, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▅▄▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▆▆▆▆▆▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▅▅▅▆▆▆▆▆▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▄▃▁▃▄▁▃▃▃▃▃▂▅▃▅▂▅▄▅▃▄▃▅▄▃▆▄▄█▅██▇▇▃▁▇
wandb:      train/ensemble_f1 ▆▃▆▅▃▅▁▄▇▂▄▅▅▆▄▅▄▃▅▄▆▅▆▅▄▅▇▆▅▄▄▁▄▅▇▆▆▅█▇
wandb:         train/mil_loss ▆▅▆▆▅█▅█▅▃▅▆▄▅▆▂▄▆▅▅▄▄▃▅▅▃▁▃▂▂▃▄▂▃▅▅▃▂▃▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▆▆▁▁▄▄▄▄▄▄▁▁▂▂▂▂▂▃▃▂▃▃▁▂▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.33536
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.91414
wandb:      eval/avg_mil_loss 0.31844
wandb:       eval/ensemble_f1 0.91414
wandb:            test/avg_f1 0.93401
wandb:      test/avg_mil_loss 0.16899
wandb:       test/ensemble_f1 0.93401
wandb:           train/avg_f1 0.90611
wandb:      train/ensemble_f1 0.90611
wandb:         train/mil_loss 0.25427
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s8fxpq1c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054626-s8fxpq1c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sb1otal9 with config:
wandb: 	actor_learning_rate: 0.0012613243589685902
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6729823593546722
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8165294653465666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055030-sb1otal9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sb1otal9
wandb: uploading history steps 100-120, summary; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▇
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:      eval/avg_mil_loss ▂▂▂▁▁▂▂▆▆▇███████████▇▇▇████████████████
wandb:       eval/ensemble_f1 ▁▁▁█████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▅▂▅▄▄▇▆▁▁▅▆▅▅▂▆▅▄▅▅▆▃▃▄▇▇▄▄▅▅▅▄▅▃▄█▄▃
wandb:      train/ensemble_f1 ▁█▄▄▅▃▅▅▅▄▅▇▄▅▃▇▃▄▅▅▅▅▆▅▅▆▆▆▆▇▅▅▇▃█▆▇▄█▄
wandb:         train/mil_loss ▂▅▆▄██▅▅▅▅▃█▅▅▄▂▅▄▅▂▆▃▅██▄▆▄▆▆▄▁▆▃▂▃▅▄▇▂
wandb:      train/policy_loss █▆▅▆▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▂█▇▇█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.25196
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.25766
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.92191
wandb:      test/avg_mil_loss 0.20267
wandb:       test/ensemble_f1 0.92191
wandb:           train/avg_f1 0.89497
wandb:      train/ensemble_f1 0.89497
wandb:         train/mil_loss 0.22171
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sb1otal9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055030-sb1otal9/logs
wandb: Agent Starting Run: nc9qx5b1 with config:
wandb: 	actor_learning_rate: 0.007429455216922029
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2820396149123059
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8281366356554788
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055207-nc9qx5b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nc9qx5b1
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁███████████████████████████████████████
wandb:       eval/ensemble_f1 ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▆▆▅▆▄▆▆▃▇▇▅█▆▆▆▆▇▇▆▄▅▆▇▇▇▅▇█▆█▇▅▇▆▆▅██
wandb:      train/ensemble_f1 █▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂
wandb:         train/mil_loss ▁▆█▆▆▆█▆▇▆▅▅▇▅▆▅▇▅▆█▆▇▆▆▇▇▅▇▅▇▇▇▇▇▇▅▇▆█▇
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68864
wandb: best/eval_avg_mil_loss 0.69896
wandb:  best/eval_ensemble_f1 0.68864
wandb:            eval/avg_f1 0.37271
wandb:      eval/avg_mil_loss 3.15664
wandb:       eval/ensemble_f1 0.37271
wandb:            test/avg_f1 0.65428
wandb:      test/avg_mil_loss 0.9195
wandb:       test/ensemble_f1 0.65428
wandb:           train/avg_f1 0.38149
wandb:      train/ensemble_f1 0.38149
wandb:         train/mil_loss 2.29938
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nc9qx5b1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055207-nc9qx5b1/logs
wandb: Agent Starting Run: 1j5hxqa9 with config:
wandb: 	actor_learning_rate: 0.003982390557890211
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8616828851751287
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08917833764448124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055330-1j5hxqa9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1j5hxqa9
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▅▆██▇▇▇▆▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁▁▂▃▆▃▇▃▃▂▃▄▃▅▄▂▅▄▅▆▄▄▄▄▃▃▄█▃▄▂▂▃▂▂▂▃▅▃
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▆▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.33592
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.3445
wandb:      eval/avg_mil_loss 3.4442
wandb:       eval/ensemble_f1 0.3445
wandb:            test/avg_f1 0.83364
wandb:      test/avg_mil_loss 0.4709
wandb:       test/ensemble_f1 0.83364
wandb:           train/avg_f1 0.37144
wandb:      train/ensemble_f1 0.37144
wandb:         train/mil_loss 0.53847
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1j5hxqa9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055330-1j5hxqa9/logs
wandb: Agent Starting Run: tvu9ro7c with config:
wandb: 	actor_learning_rate: 0.008757060702732846
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6137150023072053
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8586373193139732
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055453-tvu9ro7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvu9ro7c
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss ███▅▄▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▇▇████████████
wandb:      eval/avg_mil_loss █▇███▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▅▅▅▅▅▅▅▅▅▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▄▁▃▅▂▄▅▇▃▃▅▄▅▄▃▅▇▄▅▆█▇▅▅▇▄▅▄▃▅▇▅▇▅▅▄▄▆
wandb:      train/ensemble_f1 ▄▆▃▆▅▆▃▅▁▆▅▄▂▆▅█▅▇▃▆▆▅▆▅█▇▅▇▆▄▅▆▄▂▄▇▅▆▆▆
wandb:         train/mil_loss ▁▂▂▄▂▂▂▅▃▆▄▅▃█▂▂▅▄▅▅▁▃▄▂▇▄▂▄▃▆▁▃▅▄▃▅▆▃▁▅
wandb:      train/policy_loss ▆▅▅▅▅▅█▆▁█▇▂▅▄▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▃▃▄▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▄▄▄▄▂▅▅▅█▃▃▃▃█▄▄▄▄▄▄▄▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89847
wandb: best/eval_avg_mil_loss 0.37882
wandb:  best/eval_ensemble_f1 0.89847
wandb:            eval/avg_f1 0.89847
wandb:      eval/avg_mil_loss 0.36717
wandb:       eval/ensemble_f1 0.89847
wandb:            test/avg_f1 0.90964
wandb:      test/avg_mil_loss 0.24232
wandb:       test/ensemble_f1 0.90964
wandb:           train/avg_f1 0.87745
wandb:      train/ensemble_f1 0.87745
wandb:         train/mil_loss 0.26261
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvu9ro7c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055453-tvu9ro7c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6ehhjx9c with config:
wandb: 	actor_learning_rate: 3.9708656830966976e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.992530776929655
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15564545329453983
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055956-6ehhjx9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ehhjx9c
wandb: uploading history steps 218-236, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▅▆█
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▄▄▄▆▇▇▇▇██▆▆▆▅▆▆▆▇▇▇▇▆▇█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▅▆▃█▇▆▆▄▂▆▅▆▂▇▅▅▄▄▅▇█▅▆▄▇▆█▁▅▃▆▅█▆▅▅▅▄
wandb:      train/ensemble_f1 ▁▁▄▅▅▄▄▅▃▄▄▃▄▄▄▃▅▃▃▃▄▆▁█▄▄▄▂▅▃▆▂▃▂▅▅▆▂▁▁
wandb:         train/mil_loss ▃▁▄▄▂▃▅▄▂▆▃▁▅▆▇▅▆█▆▃▄▂▂▅█▃▅▂▃▄▂▂▁▃▂▁▅▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▄▄▁▁▁▁▁▁▁▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▁▁▁▁▁▁▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90623
wandb: best/eval_avg_mil_loss 0.27761
wandb:  best/eval_ensemble_f1 0.90623
wandb:            eval/avg_f1 0.90623
wandb:      eval/avg_mil_loss 0.27831
wandb:       eval/ensemble_f1 0.90623
wandb:            test/avg_f1 0.89963
wandb:      test/avg_mil_loss 0.24837
wandb:       test/ensemble_f1 0.89963
wandb:           train/avg_f1 0.88988
wandb:      train/ensemble_f1 0.88988
wandb:         train/mil_loss 0.24844
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ehhjx9c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055956-6ehhjx9c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: z1ei91v5 with config:
wandb: 	actor_learning_rate: 0.00015840658507960663
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.428712164770952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.938130837681218
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060329-z1ei91v5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z1ei91v5
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅█████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅█████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▂▃▂▁▂▂▄▆▄▄▅▄▄▇▆▅▇▆▆█▃▄▅▇▇▆▅▅▄▇▅▇▆▆▄▆▅▇
wandb:      train/ensemble_f1 ▆▃▂▃▁▄▂▁▂▁▄▅▇▇▇▆▁▆▄▃▅▄▆▁▆█▇▇▄██▇▆▅▇▆▇▇▇▆
wandb:         train/mil_loss ▆▇▃▁▃▇▃▃▂▃▃▃▄▅▅▂▄▅▃▇█▃▅▅▁▆▃▄▅▄▅▃▅▄▄▄▃▆▃▄
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38637
wandb: best/eval_avg_mil_loss 3.42866
wandb:  best/eval_ensemble_f1 0.38637
wandb:            eval/avg_f1 0.37958
wandb:      eval/avg_mil_loss 3.29884
wandb:       eval/ensemble_f1 0.37958
wandb:            test/avg_f1 0.3538
wandb:      test/avg_mil_loss 3.52706
wandb:       test/ensemble_f1 0.3538
wandb:           train/avg_f1 0.40132
wandb:      train/ensemble_f1 0.40132
wandb:         train/mil_loss 1.95181
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z1ei91v5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060329-z1ei91v5/logs
wandb: Agent Starting Run: qnqixojb with config:
wandb: 	actor_learning_rate: 4.653019408397937e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5544831060345448
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5898429506753909
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060514-qnqixojb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qnqixojb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ████▇▇▇▆▆▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▂▂▃▃▃▂▃▃▄▃▄▃▄▄▃▄▅▅▅▅▅▅▆▇▇▆▇▇▆█▆▇█▇▇▇
wandb:      train/ensemble_f1 ▁▁▁▁▁▂▃▂▂▂▃▃▃▄▃▄▄▃▄▃▄▄▄▅▅▅▅▅▆▆▇▆▇▇▇▆▇█▇█
wandb:         train/mil_loss ▄▃▅▄▆█▂▅▁▂▃▅▄▁▄▃▅▄▅▃▄▃▃▁▃▃▄▄▂▃▃▂▂▃▄▃▅▃▂▅
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57108
wandb: best/eval_avg_mil_loss 1.56637
wandb:  best/eval_ensemble_f1 0.57108
wandb:            eval/avg_f1 0.57108
wandb:      eval/avg_mil_loss 1.54602
wandb:       eval/ensemble_f1 0.57108
wandb:            test/avg_f1 0.51659
wandb:      test/avg_mil_loss 1.5307
wandb:       test/ensemble_f1 0.51659
wandb:           train/avg_f1 0.57362
wandb:      train/ensemble_f1 0.57362
wandb:         train/mil_loss 0.67674
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qnqixojb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060514-qnqixojb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ohi27b4m with config:
wandb: 	actor_learning_rate: 0.00018114617252038012
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20119598373249747
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46317823334677954
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061532-ohi27b4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ohi27b4m
wandb: uploading history steps 176-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅███████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▃▁▃▂▄▃▆▄▆▁▂▅▁▅▆▃▄█▇▃▄▆▇▇▄▅▁▆▇▇▅▁▅▄▆▆▃
wandb:      train/ensemble_f1 ▃▂▄▃▃▃▂▃▁▃▄▅▅▁▄▃▂▃▃▄▅▇▆█▅▄▆▆▇▆▄▆▇█▇▆▇▅▃▅
wandb:         train/mil_loss ▄▃▃▇▂▄▅█▃▃▄▄▅▁▃▅▅▆▃▁▂▆▃▅▄▃▃▂▃▁▂▂▆▃▂▂▃▃▄▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▂▂█▆████▇█▆██▇▆██▇█▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▂▁▆▆▆▇▇▆▇▆██▆▆▅█▇█▆█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91796
wandb: best/eval_avg_mil_loss 0.3097
wandb:  best/eval_ensemble_f1 0.91796
wandb:            eval/avg_f1 0.91796
wandb:      eval/avg_mil_loss 0.28895
wandb:       eval/ensemble_f1 0.91796
wandb:            test/avg_f1 0.94199
wandb:      test/avg_mil_loss 0.16305
wandb:       test/ensemble_f1 0.94199
wandb:           train/avg_f1 0.90286
wandb:      train/ensemble_f1 0.90286
wandb:         train/mil_loss 0.22334
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ohi27b4m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061532-ohi27b4m/logs
wandb: Agent Starting Run: tl2ptmua with config:
wandb: 	actor_learning_rate: 7.610283456667476e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05397013668105621
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14794356460400593
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061807-tl2ptmua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tl2ptmua
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▄▄▄▄▁▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆██████████████████
wandb:      eval/avg_mil_loss ▇█▇▆▅▄▄▄▅▅▄▄▄▃▃▃▃▂▂▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▆▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▄▅▄▆▂▅▅▅▁█▄▅▄▃▅▆▄▄▂▄▅▂▅▃█▄▂▃▂▂▂▄▃▅▃▃▄▂
wandb:      train/ensemble_f1 ▃▄▃▅█▂▅▅▅▆▃▂▃▅▃▂▄▂▃▅▄▃▃▂▂▄▄▁▃▄▅▃▄▆▃▂▆▅▃▄
wandb:         train/mil_loss ▅▄▃▂▂▃█▅▂▄▂▄▄▄▃▄▂▂▂▄▁▃▅▄▂▃▃▃▂▄▂▃▃▃▄▄▄▅▁▃
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▆▁▆▃▆▃▃▆▁▁▃▃▁▆▃█▃▆▃▃▃▃▁▃▁▃▃▄▃▁▃▁▁▁▁█▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.27174
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.91414
wandb:      eval/avg_mil_loss 0.27295
wandb:       eval/ensemble_f1 0.91414
wandb:            test/avg_f1 0.93076
wandb:      test/avg_mil_loss 0.2022
wandb:       test/ensemble_f1 0.93076
wandb:           train/avg_f1 0.89565
wandb:      train/ensemble_f1 0.89565
wandb:         train/mil_loss 0.25302
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comfy-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tl2ptmua
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061807-tl2ptmua/logs
wandb: Agent Starting Run: p0rxe088 with config:
wandb: 	actor_learning_rate: 0.001415122741457854
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17914120448684068
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9954489713724872
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062046-p0rxe088
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0rxe088
wandb: uploading history steps 100-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████▆▆▆▅▅▄▅▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▃▃▃▃▅▆▇▇▇████▇████████████████████
wandb:       eval/ensemble_f1 █████▆▆▆▆▅▅▅▅▅▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇█▇█▇█▇█▇▆▅▅▅▅▅▅▅▅▃▃▂▂▁▁▂▁▁▂▁▂▂▂▁▁▂▁▁▂▁
wandb:      train/ensemble_f1 ▇███▇█▆▆▅▆▆▅▅▅▅▃▂▂▂▁▁▂▂▁▂▂▁▁▂▂▁▂▂▁▂▂▁▂▂▁
wandb:         train/mil_loss ▁▁▁▂▁▁▁▁▄▃▂▃▃▃▄▄▅▆▆▅▅▇▆▆▆▇▆▇▆▅▇▆▆▆▆█▇▅██
wandb:      train/policy_loss ████████▇▇███████▁███████████▇███████▄██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▆████████████████▇▃██▅███▁██████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76045
wandb: best/eval_avg_mil_loss 1.06694
wandb:  best/eval_ensemble_f1 0.76045
wandb:            eval/avg_f1 0.55905
wandb:      eval/avg_mil_loss 1.72247
wandb:       eval/ensemble_f1 0.55905
wandb:            test/avg_f1 0.76277
wandb:      test/avg_mil_loss 0.6013
wandb:       test/ensemble_f1 0.76277
wandb:           train/avg_f1 0.54115
wandb:      train/ensemble_f1 0.54115
wandb:         train/mil_loss 1.43119
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run serene-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0rxe088
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062046-p0rxe088/logs
wandb: Agent Starting Run: 7md6x1ha with config:
wandb: 	actor_learning_rate: 0.00018394815166026689
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13425115652633757
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3776518543334024
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062209-7md6x1ha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7md6x1ha
wandb: uploading wandb-summary.json
wandb: uploading history steps 363-377, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ██▆▆▆▆▅▅▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▂▁▁▂▂▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▁▁▁▃▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▃▂▃▃▄▁▂▅▃▄▁▃▄▆▄▄▆▃▄▆▆▄▃█▅▆▆▄▇█▇▇▆▇▆▄█
wandb:      train/ensemble_f1 ▅▄▄▄▁▂▃▂▃▄▃▃▅▄▂▃▅▃▆▅▇▆▆▆▄▃▅▆▅▇▆▇▇▆▆███▆▇
wandb:         train/mil_loss ▇█▇▇█▆▅█▇▇▃▅▆█▇▆▄▃▆▃▄▄▄▁▄▅▃▂▂▅▃▃▄▃▄▂▄▃▁▃
wandb:      train/policy_loss ██████▁███████████▄█████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91009
wandb: best/eval_avg_mil_loss 0.29839
wandb:  best/eval_ensemble_f1 0.91009
wandb:            eval/avg_f1 0.91009
wandb:      eval/avg_mil_loss 0.27774
wandb:       eval/ensemble_f1 0.91009
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.18468
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.90732
wandb:      train/ensemble_f1 0.90732
wandb:         train/mil_loss 0.23459
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7md6x1ha
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062209-7md6x1ha/logs
wandb: Agent Starting Run: n7qantef with config:
wandb: 	actor_learning_rate: 0.0001383152095560556
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0899018015283366
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8424557106162961
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062659-n7qantef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/hc1avi8a
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n7qantef
wandb: uploading history steps 182-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▅▆█
wandb: best/eval_avg_mil_loss █▆▆▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▁▁▅▅▅▆▆▆██████▅▅▅▅▅▅▅▅▅▅▅▃▃▃▃▅
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▁▁▁▅▅▆▆▆▆▆███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃▄▃▂▇▃▁▃▆▄▄▂▇▆▂▆▂▁▅▆▃▅▆▃▆▆▅▄▃▆█▆▇▇▇▆▆█
wandb:      train/ensemble_f1 ▂▁▃▃▄▆▃▅█▆▂▄▇▄▄▅▃▅▃▆▄▆▇▅▅▅█▄▄▅▆▇▇██▃▆▇▆█
wandb:         train/mil_loss ▆▄▄▅▆▃▃▄▄▆▄▄▄▆▆▅▄▁▄▅▁▅▆▃▅▅▂▄▅▃▂▃▁▅▃█▃▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.29004
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.91104
wandb:      eval/avg_mil_loss 0.26649
wandb:       eval/ensemble_f1 0.91104
wandb:            test/avg_f1 0.94199
wandb:      test/avg_mil_loss 0.14924
wandb:       test/ensemble_f1 0.94199
wandb:           train/avg_f1 0.91404
wandb:      train/ensemble_f1 0.91404
wandb:         train/mil_loss 0.21275
wandb:      train/policy_loss 0.00373
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.00373
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n7qantef
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062659-n7qantef/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: mvm2ffb7 with config:
wandb: 	actor_learning_rate: 0.009381586255978848
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.976272735324908
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32860506787078136
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062939-mvm2ffb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mvm2ffb7
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▄▄▅▅▅▅▆▆▅▅▃▅▄▄▃▂▁▁▂▃▄▃▃▃▃▃▂▃▂▃▂▂▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▂▄▆▂▇▇█▅▄▆▄▆▅▆▇▆▆▄▆▅▅▇▆▆▁▇▇▃▇▄▅▅▅▄▃▆▇▄
wandb:      train/ensemble_f1 ▄▇▆▅▄▄▅▆█▆▇▆▃█▆▃▃▆▃▅▅▄▄▆▆▅▇▆▇▁▄▇▇▃▆▂▅▄▄▆
wandb:         train/mil_loss ▁▆▂▃▅▂▂▅▂▄▂▃▂▃▃▃▄▄▄▂▃▅█▃▂▄▂▆▃▁▃▃▃▃▂▆▃▃▄▆
wandb:      train/policy_loss ▁▁▄▄█▁▁▁▁█▁▁▄▁▄▁▄▁▄▄▄▄▄▄▄▁▁█▅▁▁▄▁▁▁▄▁▄▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▄▄▁▄█▁▁▁▁▁▄▄▁▁▁▄▁▁▄▁▄▄▁█▁▁▁▁▁▁▁▁▄▁▁▁▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88642
wandb: best/eval_avg_mil_loss 0.34907
wandb:  best/eval_ensemble_f1 0.88642
wandb:            eval/avg_f1 0.88642
wandb:      eval/avg_mil_loss 0.34755
wandb:       eval/ensemble_f1 0.88642
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.20962
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.86877
wandb:      train/ensemble_f1 0.86877
wandb:         train/mil_loss 0.26076
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mvm2ffb7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062939-mvm2ffb7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: edac543f with config:
wandb: 	actor_learning_rate: 0.0006469556903757206
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8998554349435409
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6554229844923035
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063125-edac543f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/edac543f
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▅▅▅▅▆▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▄▄▃▃▃▃▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▅▅▅▅▆▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▆█████▇▇███
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇██▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▂▁▁▁▂▁▄▄▃▃▂▃▂▄▅▄▂▅▅▅▇▃▇▄▄▆▅▅▆▅▆▇▅▅▇█▇▆
wandb:      train/ensemble_f1 ▂▁▃▃▂▂▃▃▃▄▃▃▄▄▄▃▃▄▃▄▅▅▅▅▅▇▅▅▆▅▅▅▄█▆▆▇▇▆▇
wandb:         train/mil_loss ▆▃▂▄▄▄▄█▃▆▅▄▄▂▅▂▅▂▄▂▂▄▅▇▇▂▁▇▃▂▂▂▃▅▄▄▄▄▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78188
wandb: best/eval_avg_mil_loss 0.77
wandb:  best/eval_ensemble_f1 0.78188
wandb:            eval/avg_f1 0.77871
wandb:      eval/avg_mil_loss 0.74366
wandb:       eval/ensemble_f1 0.77871
wandb:            test/avg_f1 0.70726
wandb:      test/avg_mil_loss 0.73805
wandb:       test/ensemble_f1 0.70726
wandb:           train/avg_f1 0.77634
wandb:      train/ensemble_f1 0.77634
wandb:         train/mil_loss 0.2692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/edac543f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063125-edac543f/logs
wandb: Agent Starting Run: 80chtfj2 with config:
wandb: 	actor_learning_rate: 1.299751913136627e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.86837033772927
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33475092859168787
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063829-80chtfj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80chtfj2
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████▁▁▁▁▁▁██▁▁
wandb:      eval/avg_mil_loss █▆▇▇▇▆▆▅▄▂▁▂▃▁▂▅▅▅▅▆▅▅▅▄▃▄▃▃▂▂▃▃▂▁▁▁▂▃▃▃
wandb:       eval/ensemble_f1 ████████████████████████████████▁▁▁▁▁███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▃▄▇▅▃▃▃▄▆▆▆▃▁▄▆▅▅▄▅▅▃█▂▄▆▄▃▆▃▃▂▇▅▄▂▄▅▄
wandb:      train/ensemble_f1 ▃▅▄▃▃▃▆▅▃▄▄▂▅▁▅▅▃▃▅▃▆▄▅▅▅▃▃▃▅▆▄▇▄▅█▇▄▅▅▁
wandb:         train/mil_loss ▆▄▄▆▆▄▅▄▃▃▅▁▆▂▄▇▆▄█▇▃▆▅▇▅▅▅▃▆▂▆▄▅▃▅▄▂▃▃▅
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▁▄█▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████████████▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.28337
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.92209
wandb:      eval/avg_mil_loss 0.28213
wandb:       eval/ensemble_f1 0.92209
wandb:            test/avg_f1 0.93052
wandb:      test/avg_mil_loss 0.14194
wandb:       test/ensemble_f1 0.93052
wandb:           train/avg_f1 0.91376
wandb:      train/ensemble_f1 0.91376
wandb:         train/mil_loss 0.2473
wandb:      train/policy_loss -0.05242
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.05242
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80chtfj2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063829-80chtfj2/logs
wandb: Agent Starting Run: 7bibdkiz with config:
wandb: 	actor_learning_rate: 0.0019536521018894133
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.34865003751422763
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.335392306232963
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063951-7bibdkiz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7bibdkiz
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅▇██
wandb: best/eval_avg_mil_loss █▂▂▁▁▂
wandb:  best/eval_ensemble_f1 ▁▁▅▇██
wandb:            eval/avg_f1 ▆▆▆▆▆▃▅█▇▃▂▂▂▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▄▄▄
wandb:      eval/avg_mil_loss ▅▅▅▅█▁▁▂▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▇▇▇▇▁▅▇█▆▆▆▅▅▅▅▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▆▇▁▃▆▇██▇▇▆▆▇▇▆▇▆▆▆▆▆▆▇▆▇▆▅▇▆▇▇▆▇▇▇▆▇
wandb:      train/ensemble_f1 ▇▇▆▇▁█▇▆▆▆▅▆▇▇▇▆▆▆▇▆▆▅▆▆▆▆▆▆▆▆▇▆▆▆▇▆▅▇▆▇
wandb:         train/mil_loss ▄▄▅█▄▁▂▂▃▄▄▂▃▅▃▃▃▃▄▄▂▃▂▃▄▃▄▃▃▄▂▃▂▄▂▂▃▃▃▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▁▆▆▆▆▆▆▆▆▆▃▆█▆▅▆▁▃▆▆▂▆▆▆▆▆▆▆▂▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72619
wandb: best/eval_avg_mil_loss 0.70625
wandb:  best/eval_ensemble_f1 0.72619
wandb:            eval/avg_f1 0.68627
wandb:      eval/avg_mil_loss 0.79336
wandb:       eval/ensemble_f1 0.68627
wandb:            test/avg_f1 0.74046
wandb:      test/avg_mil_loss 0.67295
wandb:       test/ensemble_f1 0.74046
wandb:           train/avg_f1 0.71503
wandb:      train/ensemble_f1 0.71503
wandb:         train/mil_loss 0.6125
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7bibdkiz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063951-7bibdkiz/logs
wandb: Agent Starting Run: raa9r09n with config:
wandb: 	actor_learning_rate: 0.0007899066922090116
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06567867438182451
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6368111785333205
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064130-raa9r09n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/raa9r09n
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▇▇▇▅▆▅▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▃▁▂▂▃▃▃▄▆▇▇▇▇██▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 █▇▇▇▇▆▅▆▅▄▃▃▃▃▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▇▇▇▄▄▃▃▃▄▃▂▂▃▂▃▃▂▂▂▁▁▂▂▃▂▄▄▃▃▃▃▃▄▄▅▅▅▅
wandb:      train/ensemble_f1 ▅██▆▆▅▄▃▃▄▁▂▂▂▃▂▂▂▁▁▁▃▄▃▃▃▁▄▃▃▃▃▄▅▅▅▄▅▆▅
wandb:         train/mil_loss ▅▂▁▄▃▄▃▂▃▅██▇▇▇▆▆▇▇▇▅▄▆▄▇▄▅▅▃▆▄▄▄▃▅▃▄▄▅▁
wandb:      train/policy_loss █▄▆█████▄██▁██████▇████▅████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▆▆▆▆▆▅▃▆▂▆▅▆▁▄▆▆▆▆▆▆▄▆▆▃▆▆█▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71226
wandb: best/eval_avg_mil_loss 0.73821
wandb:  best/eval_ensemble_f1 0.71226
wandb:            eval/avg_f1 0.59499
wandb:      eval/avg_mil_loss 0.84468
wandb:       eval/ensemble_f1 0.59499
wandb:            test/avg_f1 0.69262
wandb:      test/avg_mil_loss 0.76621
wandb:       test/ensemble_f1 0.69262
wandb:           train/avg_f1 0.64313
wandb:      train/ensemble_f1 0.64313
wandb:         train/mil_loss 0.67607
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/raa9r09n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064130-raa9r09n/logs
wandb: Agent Starting Run: j76xlu84 with config:
wandb: 	actor_learning_rate: 1.3026418950728622e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8515907678564831
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22232787044691915
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064253-j76xlu84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j76xlu84
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁▁████████████████████▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▆▆▅▅███▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▃▃▃▃▃▂▁▁▁▁▂▂▂▂▁
wandb:       eval/ensemble_f1 ███████████▁▁▁▁▁▁███████████████████▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▆█▇▆█▅▆▇▃▅▇█▇▆▃▂▄▇▅▇▄▅▆▅▁▅▄▂▁▅▅▃▆▅▃▇▅
wandb:      train/ensemble_f1 ▅▄▅█▅▆▄▅▃▄▆▆▇▃▆▂▅▅▆▆▃▄▅▄▁▄▁▄▄▄▄▃▆▅▄▅▃▅▂▄
wandb:         train/mil_loss ▆▅▅▃▂▅▄▃▃▃▆▆▄▂▄▆▂▇▄▅▅▅▆▆▃▂▁█▃▅▄▃▆▃▃▆▅▁▂▂
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▄▂▁▅▄███████████████████▂▃▄▃▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50076
wandb: best/eval_avg_mil_loss 2.79614
wandb:  best/eval_ensemble_f1 0.50076
wandb:            eval/avg_f1 0.49512
wandb:      eval/avg_mil_loss 2.75492
wandb:       eval/ensemble_f1 0.49512
wandb:            test/avg_f1 0.45739
wandb:      test/avg_mil_loss 2.9827
wandb:       test/ensemble_f1 0.45739
wandb:           train/avg_f1 0.4894
wandb:      train/ensemble_f1 0.4894
wandb:         train/mil_loss 0.35611
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j76xlu84
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064253-j76xlu84/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: if9iz6tu with config:
wandb: 	actor_learning_rate: 0.0058493157888068435
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6294739993847002
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9735579053116324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064426-if9iz6tu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/if9iz6tu
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▃▃▃▆▆▆▆▆██████████████████████████████
wandb:      eval/avg_mil_loss ▁█████████████████████████████▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▁▂▃▂▄▂▄▆▆▃▁▅▃█▄▄▃▅▃▆▆▅▄▇▅▅▃▆▅▃▇▄▆▅▆▆▄▄▇█
wandb:         train/mil_loss ▁▁▄▆▇▃▆▅▄▃▆▅▅█▆▇▅▇▆▃▅▆▅▄▅▆▄▃▃▆▄▆▄▄▄▅▄▅▇▄
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▃▁▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90063
wandb: best/eval_avg_mil_loss 0.29855
wandb:  best/eval_ensemble_f1 0.90063
wandb:            eval/avg_f1 0.33725
wandb:      eval/avg_mil_loss 3.16097
wandb:       eval/ensemble_f1 0.33725
wandb:            test/avg_f1 0.91646
wandb:      test/avg_mil_loss 0.22124
wandb:       test/ensemble_f1 0.91646
wandb:           train/avg_f1 0.34566
wandb:      train/ensemble_f1 0.34566
wandb:         train/mil_loss 1.08714
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/if9iz6tu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064426-if9iz6tu/logs
wandb: Agent Starting Run: 00mv3173 with config:
wandb: 	actor_learning_rate: 4.333646013841993e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8256688536921103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9221741740641112
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064548-00mv3173
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00mv3173
wandb: uploading history steps 549-558, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▃▃▂▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████▇█████████
wandb:      eval/avg_mil_loss ███▇▆▄▄▄▄▃▃▃▃▃▂▂▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▂▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▃▃▄▄▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇█████▇▇██▇███████
wandb:      train/ensemble_f1 ▁▂▄▄▄▄▄▅▆▆▆▆▆▇▇▇▆▇▇▇▇█▇███▇███████▇█████
wandb:         train/mil_loss █▄█▆▆▅▅▅▄▆█▄▆▆▆▆▄▆▁▃▂▂▁▆▂▃▄▄▅▅▃▁▅▄▆▆▁▅▃▃
wandb:      train/policy_loss ▄▄▄▄▅▄▅▂▄▄▆█▄▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▁▄▃▂▄▄▄▄▃▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄█▄▄▄▄▄▄▆▄▅▄▄▄▄▄▁▄▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8791
wandb: best/eval_avg_mil_loss 0.35225
wandb:  best/eval_ensemble_f1 0.8791
wandb:            eval/avg_f1 0.87549
wandb:      eval/avg_mil_loss 0.36588
wandb:       eval/ensemble_f1 0.87549
wandb:            test/avg_f1 0.8553
wandb:      test/avg_mil_loss 0.34229
wandb:       test/ensemble_f1 0.8553
wandb:           train/avg_f1 0.86712
wandb:      train/ensemble_f1 0.86712
wandb:         train/mil_loss 0.25376
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/00mv3173
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064548-00mv3173/logs
wandb: Agent Starting Run: xvxviqnc with config:
wandb: 	actor_learning_rate: 1.4162734678118185e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13073380289645287
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.970540666301429
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065302-xvxviqnc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xvxviqnc
wandb: uploading wandb-summary.json
wandb: uploading history steps 140-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄██████▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▁▁▁▅▆▆▆▆▆▆▆▆▇▇████████▆▇▇▇██▇█▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█████▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▂▁▇▄▇▇▄▅▇▂▅▄▆▄▆▄▇▅▄▆▃▄▇▆█▄▄▄▅▅▃▇▃▂▄▂▃▂
wandb:      train/ensemble_f1 ▃▄▂▄▂▇▄▄█▄▄▃▄▆▇▆▅█▇▄▇▆▂▇▄▁█▆▆▄▆▄▅▄▇▅▄▄▅▄
wandb:         train/mil_loss ▅▃▅▄▄▃▁▅▃▃▄▃▃▄▄▄▄▂▃▄▅▄▄▄▄▁▃▅▃▅▅▂▃█▄▄▄▃▇▄
wandb:      train/policy_loss ████████████████████▃▁▃▂████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████▁▁▂███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88139
wandb: best/eval_avg_mil_loss 0.30716
wandb:  best/eval_ensemble_f1 0.88139
wandb:            eval/avg_f1 0.8742
wandb:      eval/avg_mil_loss 0.30862
wandb:       eval/ensemble_f1 0.8742
wandb:            test/avg_f1 0.90768
wandb:      test/avg_mil_loss 0.18945
wandb:       test/ensemble_f1 0.90768
wandb:           train/avg_f1 0.89654
wandb:      train/ensemble_f1 0.89654
wandb:         train/mil_loss 0.23495
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xvxviqnc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065302-xvxviqnc/logs
wandb: Agent Starting Run: j6kqs8nq with config:
wandb: 	actor_learning_rate: 8.883821734016779e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.987122546107262
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8246250418958243
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065506-j6kqs8nq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6kqs8nq
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▅▆▇▆▆▆▆▆▆▇▇▇▇█▇██▆▇▆▇▇▇▆▆▇▆▅▄▄▄▃▃▅▄▄▄▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▃▅▂▄▅▅▃▅▂▅▁▃▅▆▇▁▃▂▄▂▆▃▃▄▄▅▅▇▅▅▃█▅▅▃▃▂
wandb:      train/ensemble_f1 ▅▅▃▅▄▄▅▅▃▅▂▄▅█▅▅▅▅▇▃▃█▄▆▅▁▃▃▄▇▃▄▆▆▄▅▅▃▆▄
wandb:         train/mil_loss ▇▂▄▂▆▅▄▆▄▅▄▃▂▅▄▃▂▅█▂▄▅▆▄▂▄▃▄▅▆▃▅▃▁▄▄▃▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.25229
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.91845
wandb:      eval/avg_mil_loss 0.2517
wandb:       eval/ensemble_f1 0.91845
wandb:            test/avg_f1 0.92333
wandb:      test/avg_mil_loss 0.16886
wandb:       test/ensemble_f1 0.92333
wandb:           train/avg_f1 0.90586
wandb:      train/ensemble_f1 0.90586
wandb:         train/mil_loss 0.24865
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6kqs8nq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065506-j6kqs8nq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 37ndo7bv with config:
wandb: 	actor_learning_rate: 0.0001746088869314812
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29433966964387714
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4728496529368511
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065702-37ndo7bv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ndo7bv
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 238-256, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ▃▃██▇▇▆▆▄▄▁▂▂
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▄▃▁▂▃▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▃▄█▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▁
wandb:       eval/ensemble_f1 ▃▂▁▂▂▃▃▃▃▄▅▅▇▆▆▆▆▆▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▁▁▃▅▃▅▅▅▆▆▆▆▅▅▆▇▅▆▆▅▆█▅▅▅▆▃▆▄▅▅▄▅▄▅▅▃
wandb:      train/ensemble_f1 ▁▃▄▃▃▄▅▅▅▆▇▇▇▄▅▇▄█▆▆▆▇▆▆▆▇▇▆▆▇▆▅▅▆▇▆▅▇▅▅
wandb:         train/mil_loss ▃▅▇█▄▁▄▄▃▂▁▁▂▄▃▅▄▂▅▂▂▃▄▂▅▄▃▃▃▅▅▃▄▄▆▂▄▄▄▆
wandb:      train/policy_loss ▃▃▃▃▅▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▄█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▁█▄▄▅▁▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88606
wandb: best/eval_avg_mil_loss 0.37834
wandb:  best/eval_ensemble_f1 0.88606
wandb:            eval/avg_f1 0.87525
wandb:      eval/avg_mil_loss 0.3566
wandb:       eval/ensemble_f1 0.87525
wandb:            test/avg_f1 0.90211
wandb:      test/avg_mil_loss 0.25374
wandb:       test/ensemble_f1 0.90211
wandb:           train/avg_f1 0.84924
wandb:      train/ensemble_f1 0.84924
wandb:         train/mil_loss 0.38416
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ndo7bv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065702-37ndo7bv/logs
wandb: Agent Starting Run: cuisdbyl with config:
wandb: 	actor_learning_rate: 5.980342745363423e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.565061864657068
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03605253653233642
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070023-cuisdbyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cuisdbyl
wandb: uploading history steps 374-378, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▇▄▄▃▂▁▁▂
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▂▃▁▁▂▄▄▄▄▃▃▄▄▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▆▇▇▇█▇
wandb:      eval/avg_mil_loss █████▅▄▄▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▂▁▁▁▃▃▄▄▃▃▄▄▄▄▅▅▅▅▅▆▆▇▆▆▆▇▇▇▇█▆▇▇▇▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▅▃▃▂▅▃▂▃▆▃▃▅▂▅▆▃▁▄▃▄▃▅▄▄▅▅▄▄▆▆▆▄▆▆▄▂▂█
wandb:      train/ensemble_f1 ▄▂▄▆▁▅▆▇▆▇▆▅▅▅▄▄▁▄▆▇▄▇▅▅▂▆▆██▇▆▆█▇▅█▆▅▆▇
wandb:         train/mil_loss ▄▄▄▆▄▃▄▄▄▃█▃▃▄▅▄▂▃▃▂█▄▃▃▄▆▃▅▂▆▇▅▂▃▄▂▃▂▄▁
wandb:      train/policy_loss █████▄███████████████████████▅██████▁███
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▁▄▁▄▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89384
wandb: best/eval_avg_mil_loss 0.41074
wandb:  best/eval_ensemble_f1 0.89384
wandb:            eval/avg_f1 0.89014
wandb:      eval/avg_mil_loss 0.39441
wandb:       eval/ensemble_f1 0.89014
wandb:            test/avg_f1 0.8804
wandb:      test/avg_mil_loss 0.29371
wandb:       test/ensemble_f1 0.8804
wandb:           train/avg_f1 0.88262
wandb:      train/ensemble_f1 0.88262
wandb:         train/mil_loss 0.28851
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cuisdbyl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070023-cuisdbyl/logs
wandb: Agent Starting Run: ll5f1vaa with config:
wandb: 	actor_learning_rate: 0.0069416374101848085
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.309400836743158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.690244555338937
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070517-ll5f1vaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll5f1vaa
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▅████████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆
wandb:       eval/ensemble_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▆▅▅▅▅▆▄▇▅▄▆█▃█▆▄▃▃▃▅▅▃▁▃▃▃▄▅▂▅▅▂▅▄▃▅▃
wandb:      train/ensemble_f1 ▇▅▅▄▆▅▆▆▅█▃▇█▅█▇▄▄▂▂▄▄▅▄▃▃▅▃▆▅▃▂▁▅▇▆▃▃▃▃
wandb:         train/mil_loss ▅▃▁▄▇▁▅▁▄▄▆▄▃█▃▅▆█▇▇▄▃▅▆▇▅▃▄▅▆▄▄▃▄▅▃▆▅█▂
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3225
wandb: best/eval_avg_mil_loss 3.81385
wandb:  best/eval_ensemble_f1 0.3225
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 3.99972
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29704
wandb:      test/avg_mil_loss 4.09523
wandb:       test/ensemble_f1 0.29704
wandb:           train/avg_f1 0.33211
wandb:      train/ensemble_f1 0.33211
wandb:         train/mil_loss 1.93582
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll5f1vaa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070517-ll5f1vaa/logs
wandb: Agent Starting Run: c2c8zbr3 with config:
wandb: 	actor_learning_rate: 1.867151689153355e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5334083993408915
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5219363172474545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070639-c2c8zbr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c2c8zbr3
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▇█
wandb: best/eval_avg_mil_loss ▅▃▁█▄
wandb:  best/eval_ensemble_f1 ▁▃▅▇█
wandb:            eval/avg_f1 ▅▇▆▇█▆▄▄▄▅▅▆▅▃▃▅▅▅▅▅▄▄▄▃▄▄▄▄▄▃▄▃▃▂▂▂▂▂▁▂
wandb:      eval/avg_mil_loss ▆▅▇▆▆▇█████▇▇▆▆▆▅▄▆▆▁▁▁▂▂▂▂▂▁▂▂▂▃▃▃▂▃▃▃▂
wandb:       eval/ensemble_f1 ▅▆▇▇█▅▅▄▄▄▅▅▅▅▅▃▃▅▅▅▄▃▃▃▄▄▄▃▂▂▂▂▂▂▂▁▃▂▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆█▆█▅▅▄▇▅▄█▆▆▄▃▃▄▂▃▃▄▆▄▆▇▂▄▇▃▃▅▅▁▃▄▃▆▄
wandb:      train/ensemble_f1 ▄█▆██▅█▇▅█▇▇▇▆▅▇▆▅▄▆▂▃▅▃▆▃▄▃▅▄▂▄▄▄▄▅▅▁▇▃
wandb:         train/mil_loss ▄▆▆▁▆▅▆▇▅▆▄▆▃▄▇█▆▇▄▄▂▂▆▇▄▃▅▅▅▂▃▅▅▆▂▃█▃▃▇
wandb:      train/policy_loss ▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▁▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅█▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55816
wandb: best/eval_avg_mil_loss 1.42418
wandb:  best/eval_ensemble_f1 0.55816
wandb:            eval/avg_f1 0.52985
wandb:      eval/avg_mil_loss 1.36765
wandb:       eval/ensemble_f1 0.52985
wandb:            test/avg_f1 0.51774
wandb:      test/avg_mil_loss 1.4498
wandb:       test/ensemble_f1 0.51774
wandb:           train/avg_f1 0.50937
wandb:      train/ensemble_f1 0.50937
wandb:         train/mil_loss 0.67676
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c2c8zbr3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070639-c2c8zbr3/logs
wandb: Agent Starting Run: fbw6vqrl with config:
wandb: 	actor_learning_rate: 7.848469140487444e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9742220868567064
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0154457762251603
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070817-fbw6vqrl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fbw6vqrl
wandb: uploading history steps 118-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▅▄▄▄▄▄▄▄▄▃▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▄▄▄▂▂▄▅▃▇▆▂▄▄▅▁▆▃▄▅▆▂▅▁▃▂▄▂▁▅▇▃▁▅▆▁▂▆▅
wandb:      train/ensemble_f1 ▇▂▃█▃▅▅▃▄▇▅▄▁▄▃▃▄▃▄▃▅▁▅▃▂▃▅▅▃▂▄▅▃▄▃▆▅▂▄▅
wandb:         train/mil_loss ▃▁▄▁▂▁▁▁▁▃▁▁▃▃▁▁▄▃▁▁▃▁▁▁▃▄▂▁▆▆▁▂▁▁▁▁█▄▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3445
wandb: best/eval_avg_mil_loss 3.99918
wandb:  best/eval_ensemble_f1 0.3445
wandb:            eval/avg_f1 0.3445
wandb:      eval/avg_mil_loss 3.96665
wandb:       eval/ensemble_f1 0.3445
wandb:            test/avg_f1 0.29704
wandb:      test/avg_mil_loss 4.51363
wandb:       test/ensemble_f1 0.29704
wandb:           train/avg_f1 0.33197
wandb:      train/ensemble_f1 0.33197
wandb:         train/mil_loss 0.24133
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fbw6vqrl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070817-fbw6vqrl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9513lg0d with config:
wandb: 	actor_learning_rate: 0.000485358621476388
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4729901099463628
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9486411772594122
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071016-9513lg0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9513lg0d
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▇▆▁▂▄▅▅▅▆▇▇▇▇▆▇▇███▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:      eval/avg_mil_loss ▂▂▄▇█▆▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃
wandb:       eval/ensemble_f1 █▇▆▆▁▁▂▄▅▅▅▅▆▆▇▆▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▄▁▂▃▃▄▅▅▆▆▅▆▆▆▆▇▆▇▇▇▆▇▆█▇▆█▇▆██▇▇▇█▆▇█
wandb:      train/ensemble_f1 ▆▇▆▄▃▁▂▃▂▂▅▄▃▄▅▄▅▅▄▅▄▆▅▆▆▆▆▇▆▇▆▆▇▆▆▇▇▆▆█
wandb:         train/mil_loss ▅▃▂▃██▆▇▅▃▄▅▄▆▂▅▂▄▅▃▄▄▂▄▂▃▃▃▄▃▂▃▃▂▂▂▃▁▄▃
wandb:      train/policy_loss ▆▆█▅▆▆▆▆▆▆▄▆▆▆▆▆▅▇▆▆▆▆▆▂▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▄▄▃▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▅▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87212
wandb: best/eval_avg_mil_loss 0.31168
wandb:  best/eval_ensemble_f1 0.87212
wandb:            eval/avg_f1 0.86776
wandb:      eval/avg_mil_loss 0.32583
wandb:       eval/ensemble_f1 0.86776
wandb:            test/avg_f1 0.86321
wandb:      test/avg_mil_loss 0.31832
wandb:       test/ensemble_f1 0.86321
wandb:           train/avg_f1 0.88035
wandb:      train/ensemble_f1 0.88035
wandb:         train/mil_loss 0.26295
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9513lg0d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071016-9513lg0d/logs
wandb: Agent Starting Run: ts7aobi3 with config:
wandb: 	actor_learning_rate: 0.00010237802063138598
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6159932299053581
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4756023983647357
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071139-ts7aobi3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ts7aobi3
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▇▄▄▄▂▇▂▆▂▆▇▇▆▆▆▄▆▆▄▄▁▄▇▅▅▄▂█▃▅▄▃▆▄▄▆▃▃
wandb:      train/ensemble_f1 ▆▄▆▄▆▆▃▆▃▆▆▆▇▅▄▆▇▄▅▃▅▇▅▄▂▃▇▅▁▅▄▅█▅▂▂▇▅▃▃
wandb:         train/mil_loss ▆▂█▆█▃▆▅▅▃▇▆▅▄▄▄▄▄▄▅▂▄▆▄▄▃▇▃▂▃▅▃▁▅▇▃▄▃▃▅
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89983
wandb: best/eval_avg_mil_loss 0.3041
wandb:  best/eval_ensemble_f1 0.89983
wandb:            eval/avg_f1 0.89983
wandb:      eval/avg_mil_loss 0.30495
wandb:       eval/ensemble_f1 0.89983
wandb:            test/avg_f1 0.897
wandb:      test/avg_mil_loss 0.19916
wandb:       test/ensemble_f1 0.897
wandb:           train/avg_f1 0.90358
wandb:      train/ensemble_f1 0.90358
wandb:         train/mil_loss 0.23782
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ts7aobi3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071139-ts7aobi3/logs
wandb: Agent Starting Run: 6c8jjk25 with config:
wandb: 	actor_learning_rate: 0.004226422774615335
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12333153078873972
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7126483380489005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071322-6c8jjk25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6c8jjk25
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▃▃▃▃▂▂▂▂▁▁▁▂▂▂▄▅▅▄▅▇▇▇▇███▇▇▇▇████████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▆▅▆▅▁▄▆▅▇▄▆▁▂▆▄▆▆█▄▄▃▄▆▅▃▆▆▃▆▃▆▇▅▂▇▅▆
wandb:      train/ensemble_f1 ▅▅▄▅▄▆▃▁▄▅▆▆▁▅▇▄▅▄▅▄▂▅▃▂▄▅▅▄▅▁▆▄▃▅▆▂▃▅▃█
wandb:         train/mil_loss ▂▅▅▄▁▅▄▅▄▅▃▂▄▂█▃▃▄▂▆▆▂█▄▄▂▃▆▇▄▆▃▅▂▃▄▅▃▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92223
wandb: best/eval_avg_mil_loss 0.26305
wandb:  best/eval_ensemble_f1 0.92223
wandb:            eval/avg_f1 0.92223
wandb:      eval/avg_mil_loss 0.26354
wandb:       eval/ensemble_f1 0.92223
wandb:            test/avg_f1 0.931
wandb:      test/avg_mil_loss 0.14958
wandb:       test/ensemble_f1 0.931
wandb:           train/avg_f1 0.9242
wandb:      train/ensemble_f1 0.9242
wandb:         train/mil_loss 0.2029
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6c8jjk25
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071322-6c8jjk25/logs
wandb: Agent Starting Run: xlmaw58a with config:
wandb: 	actor_learning_rate: 0.004407431143804045
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7205070555314501
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.90790281215203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071446-xlmaw58a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlmaw58a
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▇█████████████████████████████████████
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 █▂▃▃▂▂▂▂▂▂▁▂▁▁▂▂▂▂▁▂▂▂▂▂▁▁▂▂▂▂▂▂▃▂▂▂▂▂▂▃
wandb:         train/mil_loss ▂▁▅▅▇▅▆▄▃▇▆▅▆▅▃▇▅▆▅▃▄▄▆▂▅▅▅▁█▄█▅▄▂▅▄▅▅▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7544
wandb: best/eval_avg_mil_loss 0.8158
wandb:  best/eval_ensemble_f1 0.7544
wandb:            eval/avg_f1 0.3225
wandb:      eval/avg_mil_loss 3.39972
wandb:       eval/ensemble_f1 0.3225
wandb:            test/avg_f1 0.7138
wandb:      test/avg_mil_loss 0.86853
wandb:       test/ensemble_f1 0.7138
wandb:           train/avg_f1 0.34831
wandb:      train/ensemble_f1 0.34831
wandb:         train/mil_loss 1.42886
wandb:      train/policy_loss 0.19705
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.19705
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlmaw58a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071446-xlmaw58a/logs
wandb: Agent Starting Run: ue5ayqr3 with config:
wandb: 	actor_learning_rate: 2.37143505938188e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8216683207953849
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.651330665033844
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071608-ue5ayqr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue5ayqr3
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇▄▄▃▂▂▃▃▃▁▁▂▂▂▂▂▂▂▂▃▃▃▃▂▂▂▂▃▃▂▂▂▂▂▂▃▃▃▂
wandb:      eval/avg_mil_loss ▁▄▇▇█▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▅▅▅▅▅▅▄▄▄▄▄▄▅▅▅
wandb:       eval/ensemble_f1 █▆▃▃▄▃▄▄▄▃▁▁▂▂▂▂▂▂▂▃▄▄▄▄▄▂▂▃▄▄▃▃▃▂▂▄▄▃▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▂▁▄▂▃▅▄▂▃▄▄▃▅▆▃█▅▂▄▃▄▃▃▃▆▄▃▃▃▂▂▂▄▃▂▁▂▁
wandb:      train/ensemble_f1 ▇▆█▂▂▁▅▅▆▄▄▄▅▆▂▅▃▅▆▆▃▆▇▃▇▄▄▄▇▃▅▅▃▅▃▃▅▃▃▁
wandb:         train/mil_loss ▆▂▃▃▃▄▅▅▃▂▃▄▅▃▄▄▃▆▄▂▃▃█▄▂▃▂▄▂▅▆▄▁▃▃▂▁▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▂▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76277
wandb: best/eval_avg_mil_loss 0.64075
wandb:  best/eval_ensemble_f1 0.76277
wandb:            eval/avg_f1 0.73261
wandb:      eval/avg_mil_loss 0.6784
wandb:       eval/ensemble_f1 0.73261
wandb:            test/avg_f1 0.74071
wandb:      test/avg_mil_loss 0.65533
wandb:       test/ensemble_f1 0.74071
wandb:           train/avg_f1 0.71874
wandb:      train/ensemble_f1 0.71874
wandb:         train/mil_loss 0.30341
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue5ayqr3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071608-ue5ayqr3/logs
wandb: Agent Starting Run: evifssb3 with config:
wandb: 	actor_learning_rate: 0.0007390902706136965
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18309198821760908
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3186021267531144
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071731-evifssb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/evifssb3
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▄▇▇██████████████████████████████▇▇▇▇▇
wandb:       eval/ensemble_f1 ███▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▂▁▁▂▁▁▂▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂▂▁▁▂▂▂
wandb:      train/ensemble_f1 █▃▅▄▃▃▄▄▃▃▄▂▅▄▃▂▃▂▅▄▅▂▄▃▃▆▅▄▅▃▂▂▃▂▄▄▂▁▂▂
wandb:         train/mil_loss ▁▁▄▆▅▆▇▆██▆▇███▆▆█▇▇▇██▆▇▇▆▇█▇▇▇▇▇▆█▆▅▇▇
wandb:      train/policy_loss ▃▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▅█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87212
wandb: best/eval_avg_mil_loss 0.24917
wandb:  best/eval_ensemble_f1 0.87212
wandb:            eval/avg_f1 0.32992
wandb:      eval/avg_mil_loss 2.69751
wandb:       eval/ensemble_f1 0.32992
wandb:            test/avg_f1 0.84103
wandb:      test/avg_mil_loss 0.2892
wandb:       test/ensemble_f1 0.84103
wandb:           train/avg_f1 0.34119
wandb:      train/ensemble_f1 0.34119
wandb:         train/mil_loss 2.21878
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/evifssb3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071731-evifssb3/logs
wandb: Agent Starting Run: 4iq6vsnh with config:
wandb: 	actor_learning_rate: 0.0018218835095968255
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.025472564616232707
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22142764144352375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071854-4iq6vsnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4iq6vsnh
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▄▂▄▆▆▇▇▃▇▆▁▄▄▅▄▅▆▆▂▃█▄▄▇▆▂▇▆▁▄▁▇▄▂▃▃▅▅
wandb:      train/ensemble_f1 ▆▆▆▅▃▆▄▇▅▅▇▂▁▇▂▄▆▅▆▆▇▄█▅▅▇▇▂▆▅▆▅▂▇▆▇▃▄▃▅
wandb:         train/mil_loss ▇▇█▆▃▅▂▁▁▆▆▅▁▆▃▃█▄▂▇▇▂▇▃▄▅▄▅▅█▇▃▄▄▆▂▄▃▁▅
wandb:      train/policy_loss ▁▁▁▁▄███▄▁▄▄▁▄▁▁▁▁▁▁▄█▁▄▁▁▁▁▁▄▅▄▁▁▄▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▄▁▁▁██▄▁▁▁▁▁▁▁▁▁▁▁▁█▁▄▁▁▁▁▁▁▁▁▄▁▁▁▁▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 4.00019
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 3.67674
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 4.33587
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33455
wandb:      train/ensemble_f1 0.33455
wandb:         train/mil_loss 3.48131
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4iq6vsnh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071854-4iq6vsnh/logs
wandb: Agent Starting Run: w80ygwic with config:
wandb: 	actor_learning_rate: 0.00041626740824154447
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.238180336784101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7174992306376335
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072017-w80ygwic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w80ygwic
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▅▅▃▃▅▃▅▃▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▅▅▅▃▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▆▆▄▃▄▄▆▅▇▆▅▄▄▄█▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃
wandb:       eval/ensemble_f1 █▆▆▅▅▆▄▆▃▁▃▃▃▃▃▄▄▄▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▂▃▄▃▄▇▃▃▂▆▂▄█▁▃▁▃▄▄▃▅▃▄▇▅▅▄▄▂▇▄▆▆▃▆▅▄▆
wandb:      train/ensemble_f1 ▂▂▄▃▂▁▃▇▇▅▄▄▄▃▄▂▁▄▃▄▃▂▃▅▅▅▅▆▅▄▃▄▂▂█▅▂▅▄▄
wandb:         train/mil_loss ▁▃▁▄▂▅▄▇▂▅▅▅▇▆▆▄█▅▄▃▅▅▃▆▂▆▄▅▄▃▂▄▂▄▅▂▄▂▃▂
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.26995
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.90646
wandb:      eval/avg_mil_loss 0.27951
wandb:       eval/ensemble_f1 0.90646
wandb:            test/avg_f1 0.92625
wandb:      test/avg_mil_loss 0.15081
wandb:       test/ensemble_f1 0.92625
wandb:           train/avg_f1 0.91362
wandb:      train/ensemble_f1 0.91362
wandb:         train/mil_loss 0.21112
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w80ygwic
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072017-w80ygwic/logs
wandb: Agent Starting Run: idpdn4x3 with config:
wandb: 	actor_learning_rate: 5.943724572075136e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18007396300446377
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4972258993974683
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072140-idpdn4x3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/idpdn4x3
wandb: uploading history steps 118-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▅▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▃▆█▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▁▃▆▆▅▂▄▇▃▄▄▄▁▅▆▂▅▂█▅▄▄▆▆▆▂▄▄▃█▄▄▅▅▅▂▂
wandb:      train/ensemble_f1 ▄▅▁▃▅▃▆▆▇▆▅▆▄▅▆▇▃▆█▄▅▆▄▂▆▂▇▄▃▅▄▇▅▅▄▆▂▅▇▃
wandb:         train/mil_loss ▁▂▆▃█▅▂▅▄▂▃▂▂▅▅▂█▃▃▃▃▂▂▅▁▅▃▄▃▆▃▅▅▇▁▃▅▃▃▂
wandb:      train/policy_loss ▄▄▄▁▄▄▄▃▅▄▄▄▄▄▄▄▄▄▄▄▄▄▆█▄▄▄▄▄▄▄▄▄▄▄▃▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▆▅▅▅▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93351
wandb: best/eval_avg_mil_loss 0.23439
wandb:  best/eval_ensemble_f1 0.93351
wandb:            eval/avg_f1 0.92261
wandb:      eval/avg_mil_loss 0.22776
wandb:       eval/ensemble_f1 0.92261
wandb:            test/avg_f1 0.92729
wandb:      test/avg_mil_loss 0.14458
wandb:       test/ensemble_f1 0.92729
wandb:           train/avg_f1 0.9177
wandb:      train/ensemble_f1 0.9177
wandb:         train/mil_loss 0.19538
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/idpdn4x3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072140-idpdn4x3/logs
wandb: Agent Starting Run: nrxbgg9q with config:
wandb: 	actor_learning_rate: 0.00025956931179083216
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6551060634725786
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4515664731936331
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072318-nrxbgg9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nrxbgg9q
wandb: uploading wandb-summary.json
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄███████▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄█████████▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▃▇▅▁▇▅▃▅▄▃▃▅█▂▄▄▅▅▃▇▄▆▅█▆▆▇▆▅▄▄█▆▆▅▅▃
wandb:      train/ensemble_f1 ▅▃▅▅▄▄▁▂▄▃▃▅█▄▄▇▄▆▃▅▅▇▄▅▆▆█▅▆▄▆▆▃▆▇▆▄▇▄▆
wandb:         train/mil_loss █▃▃▃▃▃▃▄▅▃▃▂▃▁▄▅▁▃▃▄▂▄▂▂▅▃▁▅▄▂▄▂▄▂▂▃▃▃▅▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅▅▅█▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.2926
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.9183
wandb:      eval/avg_mil_loss 0.28171
wandb:       eval/ensemble_f1 0.9183
wandb:            test/avg_f1 0.93052
wandb:      test/avg_mil_loss 0.14961
wandb:       test/ensemble_f1 0.93052
wandb:           train/avg_f1 0.91426
wandb:      train/ensemble_f1 0.91426
wandb:         train/mil_loss 0.23361
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nrxbgg9q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072318-nrxbgg9q/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sxwho0l9 with config:
wandb: 	actor_learning_rate: 6.793257598913032e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1423043215274837
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6367160566938129
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072502-sxwho0l9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sxwho0l9
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 238-242, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▄▄▄▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▂▃▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇██████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▃▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇███████▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▅▅▅▄▄▇▃▄▄▃▄▃▄▅▂▅▅▂▆▄█▃▇▄▄▆▅▄▂▂▅▄▆▆▃▅▅
wandb:      train/ensemble_f1 ▂▃▃▆▁▃▃▅▄▆▃▅▂▆▆▆▇▆▆▆▄▂▅▇▃▇▃▇█▆▅▅▅▆▆▆▆▄▃▅
wandb:         train/mil_loss █▄▇▄▅▃▅▃▄▂▆▄▃▂▄▃▆▅▃▃▂▃▄▂▅▁▅▄▃▆▄▃▄▃▄▄▄▅▄▂
wandb:      train/policy_loss ███████▆████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94069
wandb: best/eval_avg_mil_loss 0.24277
wandb:  best/eval_ensemble_f1 0.94069
wandb:            eval/avg_f1 0.9334
wandb:      eval/avg_mil_loss 0.24193
wandb:       eval/ensemble_f1 0.9334
wandb:            test/avg_f1 0.9422
wandb:      test/avg_mil_loss 0.14719
wandb:       test/ensemble_f1 0.9422
wandb:           train/avg_f1 0.91172
wandb:      train/ensemble_f1 0.91172
wandb:         train/mil_loss 0.18656
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sxwho0l9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072502-sxwho0l9/logs
wandb: Agent Starting Run: 44y5t0bv with config:
wandb: 	actor_learning_rate: 2.1169295122461662e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.840077584199985
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44681670217064706
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072813-44y5t0bv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/44y5t0bv
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇█████
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▅▆▆▆▆▆▆▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▃▃▃▄▄▂▃▄▂▃▄▃▃▄▅▃▅▅▅▆▅▆▄▅▅▅▆▆▇▆▆▇▆▆█▆
wandb:      train/ensemble_f1 ▃▂▁▁▃▃▂▃▂▂▂▂▃▄▄▃▄▄▅▅▄▄▅▅▆▅▆▆▆▅▆▅▆▇▆█▇▇█▇
wandb:         train/mil_loss ▄▄▆▆█▆▅▆▆▂▇▃▅▁▂▃▃▄▂▅▄▇▂▃▆▃▃▃▄▃▄▄▃▄▁▄▆▃▅▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84301
wandb: best/eval_avg_mil_loss 0.33199
wandb:  best/eval_ensemble_f1 0.84301
wandb:            eval/avg_f1 0.83938
wandb:      eval/avg_mil_loss 0.31897
wandb:       eval/ensemble_f1 0.83938
wandb:            test/avg_f1 0.8782
wandb:      test/avg_mil_loss 0.25788
wandb:       test/ensemble_f1 0.8782
wandb:           train/avg_f1 0.85508
wandb:      train/ensemble_f1 0.85508
wandb:         train/mil_loss 0.23675
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/44y5t0bv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072813-44y5t0bv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9xslpxrv with config:
wandb: 	actor_learning_rate: 1.1463632123877636e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8923055862397034
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39070023444341273
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073842-9xslpxrv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xslpxrv
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁█▁▁█████████████▁███▁▁▁▁▁██▁▁▁█▁▁█████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▅▄▄▅▄▃▃▂▃▃▃▃▄▄▃▃▃▃▄▃▃▃▃▃▂▂▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁█▁▁███████████████████▁▁▁█▁██▁████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃▄▁▄▅▄▃▅▂▆▆▃▂▄▆▄▅▅▅▆▅▃▂▂▃▇▄▄▅▆▂▄▃▆▆▅▃█
wandb:      train/ensemble_f1 ▇▄▅▆▂▃▆▄▃▆▁▃▃▆▇▇▆▂▅▆▆▇▇█▆▃▄▄▃█▆▂▆▄▂▂▇▇▄▅
wandb:         train/mil_loss ▁▃▄▃▃▄▄▄▄▂▅▄▃▅▄▅▃▅▃▁▄▅▂▃▂▂▃▃▃▄▃▄▃▃▄▃█▃▃▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅▄▅▃▅▅▅▅█▅▅█▆▁▅▂▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃▃▃▃▃▁▃▇█▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.30797
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.91813
wandb:      eval/avg_mil_loss 0.30623
wandb:       eval/ensemble_f1 0.91813
wandb:            test/avg_f1 0.93052
wandb:      test/avg_mil_loss 0.14732
wandb:       test/ensemble_f1 0.93052
wandb:           train/avg_f1 0.91203
wandb:      train/ensemble_f1 0.91203
wandb:         train/mil_loss 0.24374
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xslpxrv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073842-9xslpxrv/logs
wandb: Agent Starting Run: xlej0yol with config:
wandb: 	actor_learning_rate: 0.00011059990201919534
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2740498022457717
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6089410422232958
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074101-xlej0yol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlej0yol
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆▆▆▆▅▆▆▆▆▆██▅▅▅▅▅▅▅▅▅▅▅▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▁▁▂▂▂▃▃▄▄▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅███▇▇▆▆▆▆▆
wandb:       eval/ensemble_f1 ▆▆▆█▆█▅▅▅▅▅▆▆▆▆▆▆▆▆▆██▆▄▄▄▄▄▄▄▄▃▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▇▆▄▆▇█▄▇▇▄▄▅▃▆▄▆▅▆▄▅▅▆▇▄▅▇▄▇▅█▄▅▅▅▆▄▇▁
wandb:      train/ensemble_f1 ▇▅▃▇▃▃▂▁▄▅▁▅▆▂▆▅▅▅▂▃█▄▄▃▄▅▃▁▇▃▁█▄▂▄▇█▄▂▄
wandb:         train/mil_loss ▁▂▃▆▇▃▂▅▅▄▅▃▄▇▆▆▂█▄▅▄▅▄▆▆▅▄▆▃▅▁▅▄▄▆▅▄▄▇▃
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8903
wandb: best/eval_avg_mil_loss 0.34443
wandb:  best/eval_ensemble_f1 0.8903
wandb:            eval/avg_f1 0.87559
wandb:      eval/avg_mil_loss 0.3996
wandb:       eval/ensemble_f1 0.87559
wandb:            test/avg_f1 0.88343
wandb:      test/avg_mil_loss 0.25944
wandb:       test/ensemble_f1 0.88343
wandb:           train/avg_f1 0.88657
wandb:      train/ensemble_f1 0.88657
wandb:         train/mil_loss 0.33617
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlej0yol
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074101-xlej0yol/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uegeo1tt with config:
wandb: 	actor_learning_rate: 0.003869517702705698
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05716825111181045
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7586327144117483
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074238-uegeo1tt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uegeo1tt
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 98-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▇▆▆▅▅▄▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▃▃▃▃▄▅▇▇▇████████████████████████████
wandb:       eval/ensemble_f1 ██▇▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▇▆▆▅▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ███▆▆▅▄▄▃▂▂▁▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁▂▃▃▃▃▄▆▆██▆█▇▆▇▇█▇▇▇▇▇▇▇▆▇▇▇▇███▇▇█▇▇▆
wandb:      train/policy_loss ▅▅▅▅▅▅▄▅▅▅▅▅▅▅█▅▅▅▁▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▃▅▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▇▆▃▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▃▆▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89036
wandb: best/eval_avg_mil_loss 0.35706
wandb:  best/eval_ensemble_f1 0.89036
wandb:            eval/avg_f1 0.37829
wandb:      eval/avg_mil_loss 1.77443
wandb:       eval/ensemble_f1 0.37829
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.21605
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.42555
wandb:      train/ensemble_f1 0.42555
wandb:         train/mil_loss 1.62695
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uegeo1tt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074238-uegeo1tt/logs
wandb: Agent Starting Run: 3u70f52h with config:
wandb: 	actor_learning_rate: 1.0277697022924969e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3628666389067603
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5351418261424412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074405-3u70f52h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3u70f52h
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁██
wandb: best/eval_avg_mil_loss ▁▂▂█
wandb:  best/eval_ensemble_f1 ▁▁██
wandb:            eval/avg_f1 ▇▇█▇▇▅▅▆▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:      eval/avg_mil_loss ▁▁▃▃▃▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇███
wandb:       eval/ensemble_f1 ▇▇▇▆▅▆▇▇▇▇▇█▇▇▇▆▆▆▆▆▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▃▅▃▇▇▅▅▆▃▅▆▆▆▅▆▄▃▄▂▄▄▃▄▁▃▃▄▆▄▃▂▁▂▃▃▃▃▅
wandb:      train/ensemble_f1 ▇▇▄▅▅▄█▄▃▄▇▅▅▃▃▄▅▆▅▅▃▅▅▄▁▄▄▆▄▄▄▆▄▆▃▃▅▄▃▂
wandb:         train/mil_loss ▂▂▁▃▄▄▃▄▄▃▄▃▆▄▃▃▃▅▄▅▆▂▂▅▅▄▆▆▂▄▅▃▅▆▅▅▄▅▆█
wandb:      train/policy_loss ▄▄▄▄▁▄▄▅▄▄▄▄▄▄▄█▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄█▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84306
wandb: best/eval_avg_mil_loss 0.6642
wandb:  best/eval_ensemble_f1 0.84306
wandb:            eval/avg_f1 0.79927
wandb:      eval/avg_mil_loss 0.79322
wandb:       eval/ensemble_f1 0.79927
wandb:            test/avg_f1 0.80164
wandb:      test/avg_mil_loss 0.70845
wandb:       test/ensemble_f1 0.80164
wandb:           train/avg_f1 0.81073
wandb:      train/ensemble_f1 0.81073
wandb:         train/mil_loss 0.72829
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3u70f52h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074405-3u70f52h/logs
wandb: Agent Starting Run: 1he275cr with config:
wandb: 	actor_learning_rate: 0.00010597530198033088
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6492658622966077
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5398458316213678
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074558-1he275cr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1he275cr
wandb: uploading history steps 119-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▅██████████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▅▅▅█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▄▂▃▁▂▄▁▅█▅▄▄▄▅▂▅▇▃▁▁▄▄▂▄▂▅▃▃▃▅▇▂▁▅▅▂▂
wandb:      train/ensemble_f1 ▅▃▇▅▅█▇▆█▄▆▄▆▄▆▇▇▇▆▆▆▆█▅▅▇▁▇▅▃▄▆▇▆▇▃▅▅▅▄
wandb:         train/mil_loss ▅▄▆▆▆▅▁▄▇▄▆▆▆▅▆▇▆▅▆▃▆▅▂▆▅▄▆▄▇▆▆▇▆▇▆█▄▅▆▇
wandb:      train/policy_loss ▁▁▁▁▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▁▅▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89963
wandb: best/eval_avg_mil_loss 0.31145
wandb:  best/eval_ensemble_f1 0.89963
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.30852
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.904
wandb:      test/avg_mil_loss 0.20675
wandb:       test/ensemble_f1 0.904
wandb:           train/avg_f1 0.90807
wandb:      train/ensemble_f1 0.90807
wandb:         train/mil_loss 0.22763
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1he275cr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074558-1he275cr/logs
wandb: Agent Starting Run: 87dkaa1h with config:
wandb: 	actor_learning_rate: 1.1308520843658004e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7390656142201767
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39684008257069914
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074742-87dkaa1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87dkaa1h
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 99-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▃▃█████████▆▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ███▇▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▁▁▁▁▁▁▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▆█████████▆▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▁▄▄▁▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▄▆▆▄▅▃▃▄▇▂▃▁▆▆▃▇▃▅▅▄▆▅▃█▇▃▇▄▄▃▇▄▇▅▃█▃
wandb:      train/ensemble_f1 ▁▁▅▃▃▃▇█▅▂▇▁▂▄▂▅▅▂▄▂▃▄▄▄▂▅▅▄▆▄▄▂▆▃▅▅▂▂▇▃
wandb:         train/mil_loss ▃▆▃▇▅▃▅▄▃█▅▂▁▆▆▂▁▆▂▅▄▄▂▅▆▅▅▃▃▂▄▅▃▄▄▄▃▄▃▅
wandb:      train/policy_loss ▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▁▇▇█▇▇▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.29303
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.28231
wandb:       eval/ensemble_f1 0.90667
wandb:            test/avg_f1 0.91817
wandb:      test/avg_mil_loss 0.16845
wandb:       test/ensemble_f1 0.91817
wandb:           train/avg_f1 0.91513
wandb:      train/ensemble_f1 0.91513
wandb:         train/mil_loss 0.25985
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87dkaa1h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074742-87dkaa1h/logs
wandb: Agent Starting Run: 5a9eej4z with config:
wandb: 	actor_learning_rate: 6.377087279932197e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.533121077750493
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05950057011100529
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074915-5a9eej4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5a9eej4z
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 197-214, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▁▄▅█
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▃▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆██▆▆▆█▆▆████████▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▁▂▂▃▄▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃███████
wandb:       eval/ensemble_f1 ▁▃▄▄▄▄▄▄▄▄▄▄▄▆▆▆████▆▆▆█▆▆█████████████▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▄▂▄▁▃▅▃▂▄▃▁▄▅▁▆▅▃▃▄▆▅▄▇▃▂▂▄█▄▃▆▃▅▅▃▆▇
wandb:      train/ensemble_f1 ▄▇▄▇▅█▄▁▄▃▂▇▅▅▅▆▂▄▃▅▅▆█▆▂▆▅▆▆▃▆▆▄▃▆▃█▄▁▄
wandb:         train/mil_loss ▃▄▃▄▂▃▅▆▅▄▂▃▂▄▄▂▃▆▁▄▄▅▁▃▃▅▄█▅▃▄▄▃▁▂▅▂▅▃▆
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▇█▇▃▅▆▂▄▅▃▆▃▂▆▁▇▃▆▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90283
wandb: best/eval_avg_mil_loss 0.26319
wandb:  best/eval_ensemble_f1 0.90283
wandb:            eval/avg_f1 0.8992
wandb:      eval/avg_mil_loss 0.27601
wandb:       eval/ensemble_f1 0.8992
wandb:            test/avg_f1 0.90735
wandb:      test/avg_mil_loss 0.19701
wandb:       test/ensemble_f1 0.90735
wandb:           train/avg_f1 0.9009
wandb:      train/ensemble_f1 0.9009
wandb:         train/mil_loss 0.21517
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5a9eej4z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074915-5a9eej4z/logs
wandb: Agent Starting Run: zkp360d2 with config:
wandb: 	actor_learning_rate: 0.0003060077164526865
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.40609255519381415
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8387820693143399
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075205-zkp360d2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkp360d2
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▅▁▁▁▁▅███▅▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▆▆▆▆▆▅▅███▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁
wandb:       eval/ensemble_f1 ██████▅▅▅▅▅▁▁▁▁███▅▅▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▆▄▅▂▄▃▁▃▅▇▃▂▅▁▅█▅▄▅▇▆▂▅▄█▅▄▅▇▂▇▅▆▅▆▅▄
wandb:      train/ensemble_f1 ▃▅▂▄▄▅▄▂▅▄▄▄▁▄▃▂▅▆▅▄▅▇▆▂▅█▅▄█▆▇▃▅▆▅▅▄▄█▄
wandb:         train/mil_loss ▃▇▄▅▅▅▄▅▅▅█▅▅▆▄▅▂▄█▃▅▁▄█▅▅▁▁▇▆▃▅▄▆▄▄▂▅▅▄
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52285
wandb: best/eval_avg_mil_loss 2.59353
wandb:  best/eval_ensemble_f1 0.52285
wandb:            eval/avg_f1 0.52005
wandb:      eval/avg_mil_loss 2.45523
wandb:       eval/ensemble_f1 0.52005
wandb:            test/avg_f1 0.48822
wandb:      test/avg_mil_loss 2.64227
wandb:       test/ensemble_f1 0.48822
wandb:           train/avg_f1 0.52796
wandb:      train/ensemble_f1 0.52796
wandb:         train/mil_loss 1.34149
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkp360d2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075205-zkp360d2/logs
wandb: Agent Starting Run: rva0dnsn with config:
wandb: 	actor_learning_rate: 0.0014869173855459753
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.044457887499192994
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3011396325779503
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075328-rva0dnsn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rva0dnsn
wandb: uploading history steps 235-246, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▅▄▃▃▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▁▃▄▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇▇▇▇▇▇▆▅▅
wandb:      eval/avg_mil_loss ██▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████▇▇▇▇▇▇▇▇▇▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▁▃▅▆▅▆▇▆▆▇▆▆▆▇▆▅▇▆▆▆▅▆▅▆▆▇▆▆▇▆▇▇█▇▇▆▇
wandb:      train/ensemble_f1 ▁▁▁▁▁▆█▇▇█▇▇▇▇▇▆▇▆▇▆▇▆▇▆▆▆▆▆█▇▆▇▇▆█▆▇▅▇▇
wandb:         train/mil_loss ▇██▅▃▃▂▃▂▃▂▂▂▃▁▄▃▃▂▂▂▂▂▂▃▂▂▂▁▄▁▂▂▂▃▁▂▂▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87898
wandb: best/eval_avg_mil_loss 0.37308
wandb:  best/eval_ensemble_f1 0.87898
wandb:            eval/avg_f1 0.86095
wandb:      eval/avg_mil_loss 0.39884
wandb:       eval/ensemble_f1 0.86095
wandb:            test/avg_f1 0.90548
wandb:      test/avg_mil_loss 0.17559
wandb:       test/ensemble_f1 0.90548
wandb:           train/avg_f1 0.89498
wandb:      train/ensemble_f1 0.89498
wandb:         train/mil_loss 0.23828
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rva0dnsn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075328-rva0dnsn/logs
wandb: Agent Starting Run: eul49m87 with config:
wandb: 	actor_learning_rate: 0.0001780827105300934
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28984714512588605
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19317703355861904
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075644-eul49m87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eul49m87
wandb: uploading history steps 99-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▅▅▅▅▅▆▆█▅▃▃▃▃▃▃▆▃▃▃▆█▆█████▆▆▆▆▆▃▃▃▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▆▁▁█▇██▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▅▆▃▅▃▅▆▆▃▃▅▅▆▆████▆▆▆▆▆▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▇▂▂▂▄▂▂▁▄▃▂▃▂▃▁▂▄▄▅▅▃▄▅▅▅▄▃▅▆▇▅▅█▃▅▄▅
wandb:      train/ensemble_f1 ▅▄▇▇▃▅▃▅▃▂▂▁▂▄▄▄▂▃▅▄▆▆▃▃▅▆▅▃█▅█▅▆▇▄█▅▅▆▅
wandb:         train/mil_loss ▅▃▄█▅▆▅▄▇▅▅▆▄▅▂▄▂▄▁▄▅▁▅▄▄▄▄▂▄▄▆▇▆▇▆▃▄▄▆▅
wandb:      train/policy_loss ▄▄▄▄▄▃▄▄▄▄▄▄▁▄▄▄▄▄█▄▁▇▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▁▄▄▄▆▄▄▅▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▃▄▄▄▄▄▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90396
wandb: best/eval_avg_mil_loss 0.27386
wandb:  best/eval_ensemble_f1 0.90396
wandb:            eval/avg_f1 0.8924
wandb:      eval/avg_mil_loss 0.2909
wandb:       eval/ensemble_f1 0.8924
wandb:            test/avg_f1 0.88704
wandb:      test/avg_mil_loss 0.20019
wandb:       test/ensemble_f1 0.88704
wandb:           train/avg_f1 0.8994
wandb:      train/ensemble_f1 0.8994
wandb:         train/mil_loss 0.26214
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eul49m87
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075644-eul49m87/logs
wandb: Agent Starting Run: dc81i0yc with config:
wandb: 	actor_learning_rate: 0.009276321753529463
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8653508243099296
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5293358508847114
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075818-dc81i0yc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dc81i0yc
wandb: uploading history steps 98-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁███
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁███
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁███████████████████████████████████████
wandb:      train/ensemble_f1 ▁▁▁▁▁███████████████████████████████████
wandb:         train/mil_loss ▇▃▄█▁▂▁▁▁▁▁▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▂▂▂▁▂▁
wandb:      train/policy_loss ▅▄▁▂▂▂▃▃▃▃▆▆▅▇▅▆▆▆▄▇▅▆▇▆▇▆▆▆▆▆▅▆▆▆▇▄█▅▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▁▂▆▂▃▃▅▆█▆▆▆▆▇▇▆▇▆▆▇▆▆█▆▆▃▆█▃▇▆▆▄▇▆▆█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91778
wandb: best/eval_avg_mil_loss 0.2759
wandb:  best/eval_ensemble_f1 0.91778
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.28113
wandb:       eval/ensemble_f1 0.9105
wandb:            test/avg_f1 0.91538
wandb:      test/avg_mil_loss 0.2125
wandb:       test/ensemble_f1 0.91538
wandb:           train/avg_f1 0.91311
wandb:      train/ensemble_f1 0.91311
wandb:         train/mil_loss 0.20762
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dc81i0yc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075818-dc81i0yc/logs
wandb: Agent Starting Run: 5mhftu2e with config:
wandb: 	actor_learning_rate: 3.6363996173185503e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7573615869206441
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32418786768997554
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075951-5mhftu2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5mhftu2e
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▇▆▆▇▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▂▅▆▃▆▄▄▅▃▁▅▅▃▃▆▄▄█▄▁▅█▃▄▇▆▅▄▂▄▂▆▅▆▅▅▄▅
wandb:      train/ensemble_f1 ▆▃▅▅▅▃▆█▂▄▇▂▅▅▅▃▆▁▅▆▄▆▁▇▃▅▆▇▆█▅▇▅▅▃▃▄▅▃▅
wandb:         train/mil_loss ▄▆▄▆▅▅▇▁▅▄▄▄▃▄▄▄▆▄▄▇▃▃▅▅▃▆▅▄▂▃▃▅▄▁▅▆█▂▄▃
wandb:      train/policy_loss ▇▁▂▇▄▁▄▂▂▄▅▁▅▄▂▄▄▂▃▅▅▆▅▁▂▃▅▂▄▄▅▁▄▄▅▄▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▇▆▇▃▄▂▄▃▅▇▆▂▆▆▇▄▃▆▆▆▇▆▆▆▄▆▆▄█▅▄▂▂▆▄▆▆█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90049
wandb: best/eval_avg_mil_loss 0.2866
wandb:  best/eval_ensemble_f1 0.90049
wandb:            eval/avg_f1 0.90049
wandb:      eval/avg_mil_loss 0.29059
wandb:       eval/ensemble_f1 0.90049
wandb:            test/avg_f1 0.89763
wandb:      test/avg_mil_loss 0.20524
wandb:       test/ensemble_f1 0.89763
wandb:           train/avg_f1 0.91641
wandb:      train/ensemble_f1 0.91641
wandb:         train/mil_loss 0.21362
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5mhftu2e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075951-5mhftu2e/logs
wandb: Agent Starting Run: slqfcn4r with config:
wandb: 	actor_learning_rate: 1.1892007675627058e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3144155840304642
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8460982370937666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080113-slqfcn4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/slqfcn4r
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 375-389, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss █▆▆▅█▆█▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▁▁▂▂
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▇▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss ██▇▆▆█▇█▇▇▇▇▇▇▆▆▆▆▅▅▄▄▃▃▄▃▃▃▃▃▄▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▃▄▄▄▅▄▄▅▆▅▆▆▆▆▅▇▇▇▇▆▇▇▇▇▇██▅██▆█▅▇▇▆▇
wandb:      train/ensemble_f1 ▁▂▁▁▂▄▃▄▆▅▄▃▄▅▅▆▅▅▆▆▇▆▇▆█▆▇▇█▇▇▇▇▇▆▇▇██▇
wandb:         train/mil_loss ▄▆▇▅█▅▅▅▆▄▁▃▆▇▃▆▅▄▄▃▅▁▅▅▅▃▂▇▄▃▄▃▆▄▇▆▄▃█▂
wandb:      train/policy_loss ▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▄▄▄█▄▄▄▄▄▁▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▂▃▃▃▃▃█▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.5174
wandb: best/eval_avg_mil_loss 3.15672
wandb:  best/eval_ensemble_f1 0.5174
wandb:            eval/avg_f1 0.50635
wandb:      eval/avg_mil_loss 3.00599
wandb:       eval/ensemble_f1 0.50635
wandb:            test/avg_f1 0.4781
wandb:      test/avg_mil_loss 3.09003
wandb:       test/ensemble_f1 0.4781
wandb:           train/avg_f1 0.49004
wandb:      train/ensemble_f1 0.49004
wandb:         train/mil_loss 1.90767
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/slqfcn4r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080113-slqfcn4r/logs
wandb: Agent Starting Run: 5nhpthqs with config:
wandb: 	actor_learning_rate: 1.0996033759193143e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8461932745612251
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7733147689121582
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080617-5nhpthqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5nhpthqs
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▂
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▁▂▃▃▂▂▃▃▃▄▃▄▄▄▅▆▆▅▆▆▇▆▇▇▇█▇▇▇█▇▇▇██▇█
wandb:      train/ensemble_f1 ▁▂▁▂▃▃▂▃▂▃▃▃▃▄▄▄▄▄▄▆▅▅▅▅▅▅▆▆▆▆▇▇▇▆▆▇▇▇█▇
wandb:         train/mil_loss ▂▃█▃▃▅▄▃█▄▄▃▃▁▂▃▁▄▃▄▄▄▅▅▃▃▃▃▄▄▃▃▃▃▂▃▃▃▄▃
wandb:      train/policy_loss ██████████▅██████████▁████▄█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69712
wandb: best/eval_avg_mil_loss 0.78683
wandb:  best/eval_ensemble_f1 0.69712
wandb:            eval/avg_f1 0.69712
wandb:      eval/avg_mil_loss 0.77428
wandb:       eval/ensemble_f1 0.69712
wandb:            test/avg_f1 0.69065
wandb:      test/avg_mil_loss 0.66393
wandb:       test/ensemble_f1 0.69065
wandb:           train/avg_f1 0.72411
wandb:      train/ensemble_f1 0.72411
wandb:         train/mil_loss 0.32491
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5nhpthqs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080617-5nhpthqs/logs
wandb: Agent Starting Run: qmikh7lg with config:
wandb: 	actor_learning_rate: 0.0001143357879387288
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5281227201037612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6756926523032142
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081640-qmikh7lg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmikh7lg
wandb: uploading history steps 785-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss ██▇▇▇▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▁▂▂▂▃▄▄▄▄▄▄▅▅▅▅▆▇▇▇▇▇▇▇▇▇██████████████
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▃▃▄▄▄▅▄▅▅▆▆▆▆▇▆▇▇▇▇▇█▇█▇█▇▇█▇█▇██████
wandb:      train/ensemble_f1 ▁▂▂▃▃▄▃▄▄▄▅▄▄▅▅▅▆▅▇▇▆▆▇▇▇▇▇▇▇▇▇███▇█████
wandb:         train/mil_loss ▇▇▆█▅▅▄▅▅▄▄▄▃▄▃▃▄▄▃▃▃▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▁▁
wandb:      train/policy_loss ▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84671
wandb: best/eval_avg_mil_loss 0.34552
wandb:  best/eval_ensemble_f1 0.84671
wandb:            eval/avg_f1 0.84306
wandb:      eval/avg_mil_loss 0.34153
wandb:       eval/ensemble_f1 0.84306
wandb:            test/avg_f1 0.8668
wandb:      test/avg_mil_loss 0.27817
wandb:       test/ensemble_f1 0.8668
wandb:           train/avg_f1 0.8675
wandb:      train/ensemble_f1 0.8675
wandb:         train/mil_loss 0.31952
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmikh7lg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081640-qmikh7lg/logs
wandb: Agent Starting Run: fnwnz6zl with config:
wandb: 	actor_learning_rate: 0.00013873965570758266
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04451325325437705
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7855431415434724
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082658-fnwnz6zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fnwnz6zl
wandb: uploading history steps 495-497, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▃▂▂▁▂▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▆▆▇▇▆▇▇▇█████████▇▇█
wandb:      eval/avg_mil_loss █▇▇██████▇▆▆▆▅▅▅▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▂▂▁▁▂▃▄▄▄▄▅▅▄▅▅▄▄▄▅▇▇▇▇▇▇█▇▇▇██████▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▂▃▃▄▄▄▄▅▅▄▄▆▅▅▆▆▅▆▆▆▇▇▆▇▇▆▇▇▇▇▇█████
wandb:      train/ensemble_f1 ▁▁▁▂▂▂▂▂▁▃▄▃▃▃▅▅▆▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇
wandb:         train/mil_loss ██▇██▆▆▆▇▆▆▅▄▅▅▄▄▅▃▃▃▃▃▃▂▃▂▂▃▂▃▂▂▂▁▂▁▂▁▁
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▁▅▅█▅▅▅▅▅▄▅▅▅▅▆▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86095
wandb: best/eval_avg_mil_loss 0.42501
wandb:  best/eval_ensemble_f1 0.86095
wandb:            eval/avg_f1 0.85323
wandb:      eval/avg_mil_loss 0.35605
wandb:       eval/ensemble_f1 0.85323
wandb:            test/avg_f1 0.85472
wandb:      test/avg_mil_loss 0.25128
wandb:       test/ensemble_f1 0.85472
wandb:           train/avg_f1 0.87122
wandb:      train/ensemble_f1 0.87122
wandb:         train/mil_loss 0.27229
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fnwnz6zl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082658-fnwnz6zl/logs
wandb: Agent Starting Run: czxwzcl9 with config:
wandb: 	actor_learning_rate: 0.00045053133266667454
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29539904267539785
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3640518350969961
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083320-czxwzcl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czxwzcl9
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▇▅▂▁▃▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▁▂▅▆▇█▆▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 █▅▁▁▃▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▅▂▁▁▄▄▅▆█▇▇▇█▇▇▇█▇▇▇▇▇█▇█▇▇▇▆▇▇▇▆▇▇▆▇▇
wandb:      train/ensemble_f1 █▄▁▁▁▅▅▇▇▆▆▇▇▇▇▇█▇▇▇█▇█▆▇▇▇▆▆▆▇▆█▆▆▆▆▆▆▆
wandb:         train/mil_loss ▁▁█▄▃▃▂▃▂▁▂▁▂▃▃▂▁▁▄▁▃▂▃▂▁▁▂▂▂▃▄▂▃▃▄▂▃▃▂▃
wandb:      train/policy_loss ▇▆▅▇▃▅▅▅▃█▃▁▃▅▅▅▅▅▅▅▄▄▁▅▅▅▅▅█▆▇▅▅▅▃▇▇▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8924
wandb: best/eval_avg_mil_loss 0.36528
wandb:  best/eval_ensemble_f1 0.8924
wandb:            eval/avg_f1 0.8354
wandb:      eval/avg_mil_loss 0.45628
wandb:       eval/ensemble_f1 0.8354
wandb:            test/avg_f1 0.86804
wandb:      test/avg_mil_loss 0.29746
wandb:       test/ensemble_f1 0.86804
wandb:           train/avg_f1 0.84281
wandb:      train/ensemble_f1 0.84281
wandb:         train/mil_loss 0.39226
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czxwzcl9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083320-czxwzcl9/logs
wandb: Agent Starting Run: ftvz9g3s with config:
wandb: 	actor_learning_rate: 2.395899301730781e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8001442631953068
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32176517962296836
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083443-ftvz9g3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ftvz9g3s
wandb: uploading history steps 157-176, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▆█▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▁▃▃▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆████████████████████
wandb:      eval/avg_mil_loss ▆▆█▇█▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▁▁▁▁▁▁▁▃▃▂▂▂▂▂▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▆▁▃▆▄▂▅▃▅▂▅▃▃▂▄▅█▂▄▁▆▇▆▆▆▅▆▆▇▇▄▅▇▄▇▃▄
wandb:      train/ensemble_f1 ▃▅▅▆▅▃▃▄▆▇▅▇▅▅▄▆▇▇▆▃▂▁▄▅▂▆▅█▆▇▆▃▅▄▃▆▆▇▇▄
wandb:         train/mil_loss ▇▄▄▄▅▄▃▆▅▄▄▄▆▇▂▄▇█▅▆▇▁▆▇▇▅▄▃▄▅▆▅▃▄▃█▃▄▄▃
wandb:      train/policy_loss ▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91211
wandb: best/eval_avg_mil_loss 0.26816
wandb:  best/eval_ensemble_f1 0.91211
wandb:            eval/avg_f1 0.91211
wandb:      eval/avg_mil_loss 0.26665
wandb:       eval/ensemble_f1 0.91211
wandb:            test/avg_f1 0.86631
wandb:      test/avg_mil_loss 0.22352
wandb:       test/ensemble_f1 0.86631
wandb:           train/avg_f1 0.89833
wandb:      train/ensemble_f1 0.89833
wandb:         train/mil_loss 0.21792
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ftvz9g3s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083443-ftvz9g3s/logs
wandb: Agent Starting Run: y61osuoq with config:
wandb: 	actor_learning_rate: 5.133838356698561e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3394641666901719
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30239240538491396
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083703-y61osuoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y61osuoq
wandb: uploading history steps 198-206, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅██████▅▅▅▅▅▁▁▁▁▅▅▅▅▅
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆███▇▇▆▆▆▅▆▆▅▅▅▅▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅█████▅▅▅▅▅▁▁▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▁▄▂▃▁▂█▄▃▂▅▃▅▃▂▂▅▆▅▅▂▄▅▅▃▄▅▄▆▅▆▃▃▇▂▆▅
wandb:      train/ensemble_f1 ▂▁▂▁▂▂▂▃▂▁▄▂▅▁▂▃▂▂▃▅▅▃▄▁▄▂▃▂▄▁▁▂▂▄█▆▃▄▄▅
wandb:         train/mil_loss ▃▇▄▆▅█▅▆▅▄▅▆▅▃▄▅▅▃▄▆▁▇▄▃▂▃▄▂▃▅▅▅▆▄▅▃▂▅▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.33725
wandb: best/eval_avg_mil_loss 2.72744
wandb:  best/eval_ensemble_f1 0.33725
wandb:            eval/avg_f1 0.32992
wandb:      eval/avg_mil_loss 2.50825
wandb:       eval/ensemble_f1 0.32992
wandb:            test/avg_f1 0.29704
wandb:      test/avg_mil_loss 2.97552
wandb:       test/ensemble_f1 0.29704
wandb:           train/avg_f1 0.3496
wandb:      train/ensemble_f1 0.3496
wandb:         train/mil_loss 1.77326
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y61osuoq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083703-y61osuoq/logs
wandb: Agent Starting Run: t0zrqepz with config:
wandb: 	actor_learning_rate: 0.002583225903686933
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28609209962950954
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09121416254601644
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083942-t0zrqepz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t0zrqepz
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▄▆▆▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁▁▁▂▁▂▂▂▂▁
wandb:      eval/avg_mil_loss ▁▅▄▁▂▄▄▅▅▅█▇▇▇▇▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██▄▅▆▃▄▆▄▅▄▄▄▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▇█▆▆▅▅▆▅▅▅▄▄▄▃▃▃▃▃▅▄▄▄▃▄▄▃▄▃▃▄▁▄▃▃▄▄▃▄
wandb:      train/ensemble_f1 ▆█▇▆▆▆▅▅▅▅▄▄▅▄▅▃▄▄▄▄▄▃▃▄▄▃▂▃▄▃▄▄▁▄▄▃▄▃▃▄
wandb:         train/mil_loss ▂▃▁▃▁▂▃▃▃▃▂▃▃▆▄▆▆▅▆▄▆▆▅▅▂▅▃▄▆▇▄▄▅▆▆▆▅█▅▅
wandb:      train/policy_loss ▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▇▂▃▅▅▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▁▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄▂█▃▄▄▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90283
wandb: best/eval_avg_mil_loss 0.329
wandb:  best/eval_ensemble_f1 0.90283
wandb:            eval/avg_f1 0.86514
wandb:      eval/avg_mil_loss 0.36966
wandb:       eval/ensemble_f1 0.86514
wandb:            test/avg_f1 0.92222
wandb:      test/avg_mil_loss 0.15771
wandb:       test/ensemble_f1 0.92222
wandb:           train/avg_f1 0.86679
wandb:      train/ensemble_f1 0.86679
wandb:         train/mil_loss 0.30021
wandb:      train/policy_loss 0.13886
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.13886
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run visionary-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t0zrqepz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083942-t0zrqepz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yg7fbe48 with config:
wandb: 	actor_learning_rate: 0.0022560347069245164
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8911571923069989
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9981199966251778
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084113-yg7fbe48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yg7fbe48
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▅▃▃▄▄▆▁▄▅▆▄▅▃▅▃▅▅▁▃▄▅▅█▅▃▃▆█▇▆▅▅▇█▄█▃▄
wandb:      train/ensemble_f1 ▂▅▄▂▃▄▃▁▁▄▃▄▁▃▃▂▄▃▃▄▄▆▃▅▄█▃▄▆▂▅▃█▆▅▅▄▅▄▃
wandb:         train/mil_loss ▃▂▄▂▁▃▂▂▃▃▄▃▃▅▄▂▂▆▂▄▁▄▁▂▅▃▂▄▃▃█▆▁▃▃▃▄▆▂▂
wandb:      train/policy_loss █▅▇▇▆▇▅▆██▅▆▇▅▆▅▆█▆█▄▅██▅▇▆▇▇▄▁▂▄▇▆▇▆▄▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇▆▇▅▇█▅█▇▆▇▅▆▇▅▇▅▆▆█▇▅▄████▅▇▆▇▅▁▆▆▇▅▅▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45671
wandb: best/eval_avg_mil_loss 2.20324
wandb:  best/eval_ensemble_f1 0.45671
wandb:            eval/avg_f1 0.45671
wandb:      eval/avg_mil_loss 2.08916
wandb:       eval/ensemble_f1 0.45671
wandb:            test/avg_f1 0.41015
wandb:      test/avg_mil_loss 1.93402
wandb:       test/ensemble_f1 0.41015
wandb:           train/avg_f1 0.46175
wandb:      train/ensemble_f1 0.46175
wandb:         train/mil_loss 0.30038
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yg7fbe48
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084113-yg7fbe48/logs
wandb: Agent Starting Run: tx2ydux2 with config:
wandb: 	actor_learning_rate: 3.4806900730869914e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14233068406425875
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21762244159459643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084239-tx2ydux2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tx2ydux2
wandb: uploading history steps 496-503, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ▇██▇▇▇█▇█▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▆▆▆▇▇▇████████
wandb:      eval/avg_mil_loss ████▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▅▇▆▆▆▆▇▇▇▇██▇▇█▇██▇█▇▇█▇
wandb:      train/ensemble_f1 ▁▁▁▁▂▃▃▃▃▄▄▄▅▅▅▆▆▆▅▅▆▆▆▆▆▇▇▇▇█▇█▇█▇▇██▇█
wandb:         train/mil_loss ▇█▅▄▆▆▅▆▇▇▆▅▅▇▅▄▅▆▅▄▅▃▆▅▄▃▂▁▃▃▄▄▄▄▆▅▃▄▄▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▇███████▁█▇███▃███▃▅████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59001
wandb: best/eval_avg_mil_loss 2.60922
wandb:  best/eval_ensemble_f1 0.59001
wandb:            eval/avg_f1 0.57709
wandb:      eval/avg_mil_loss 2.63176
wandb:       eval/ensemble_f1 0.57709
wandb:            test/avg_f1 0.52433
wandb:      test/avg_mil_loss 2.56676
wandb:       test/ensemble_f1 0.52433
wandb:           train/avg_f1 0.5714
wandb:      train/ensemble_f1 0.5714
wandb:         train/mil_loss 2.16947
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tx2ydux2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084239-tx2ydux2/logs
wandb: Agent Starting Run: 2se1v6od with config:
wandb: 	actor_learning_rate: 6.167092205480345e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5436237768954985
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2353528175466192
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084906-2se1v6od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/wtj6rs0m
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2se1v6od
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 197-212, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅█████████████████████████
wandb:      eval/avg_mil_loss █▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▄▃▅▄▃▃▄▂▃▄▅▅▄▄▄▅▅▅▅▄▂▅▄▅▆▆▆▆▆▅▅▆▆▅█▅▃
wandb:      train/ensemble_f1 ▃▄▃▁▄▃▅▆▆▄▄▄▄▆▅▅▅▅▅▆▅▆▄▅▆▄▇▆▆▆▅▅▅▇██▆▅▄▇
wandb:         train/mil_loss ▃▄▆▄▅▆▁▄▄▂▆▆▅▄▂▅▅▅▅▂▅▂▄▆█▆▅▄▆▄▆▃▅▄▅▃▃▆▇▄
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▃▄▂▇▆▂▇▃▇█▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.28933
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.28022
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.91375
wandb:      test/avg_mil_loss 0.17535
wandb:       test/ensemble_f1 0.91375
wandb:           train/avg_f1 0.90981
wandb:      train/ensemble_f1 0.90981
wandb:         train/mil_loss 0.21678
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2se1v6od
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084906-2se1v6od/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: e2s6sraq with config:
wandb: 	actor_learning_rate: 0.00011004123340183138
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08700220566100114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6082818302870199
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085207-e2s6sraq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2s6sraq
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█
wandb: best/eval_avg_mil_loss █▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▃▄▃▄▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▁▂▂▂▄▄▄▄▄▄▄▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▃▃▃▃▃▃▅▅▃▄▅▄▆▄▅▅▆▆▆▇▇▆▅▇▇▆▇▇▆█▇▇█▇▇██
wandb:      train/ensemble_f1 ▁▃▃▂▄▅▃▅▅▅▄▅▄▅▃▆▇▆▆▅▆▆▆▇▆▆▇▇▆▇▇▆▆▇▇▇▇▇█▇
wandb:         train/mil_loss ▆█▇█▆▆▆▅▆▇█▄▇▇▅▄▄▄▄▅▆▄▇▅▅▃▅▂▁▅▄▄▂▁▄▃▂▃▄▃
wandb:      train/policy_loss ▁▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55467
wandb: best/eval_avg_mil_loss 3.78057
wandb:  best/eval_ensemble_f1 0.55467
wandb:            eval/avg_f1 0.54657
wandb:      eval/avg_mil_loss 3.50932
wandb:       eval/ensemble_f1 0.54657
wandb:            test/avg_f1 0.50804
wandb:      test/avg_mil_loss 3.59942
wandb:       test/ensemble_f1 0.50804
wandb:           train/avg_f1 0.54699
wandb:      train/ensemble_f1 0.54699
wandb:         train/mil_loss 2.76504
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2s6sraq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085207-e2s6sraq/logs
wandb: Agent Starting Run: 0yfmmd05 with config:
wandb: 	actor_learning_rate: 0.0009442470007207848
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42289082564052727
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5810826298527643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085737-0yfmmd05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yfmmd05
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁▁▁▁█████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▅▅▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▇▂▃▅▁▃▅▂▇▃▃▇▅▇▇▇▁▅▅▇▃▄▆▅▇▇▃▆▅▅▅█▇▇█▅▇▆
wandb:      train/ensemble_f1 ▄▅▁▃▂▄▄▆▄▅▄▄▅▆▇▇▅▇▆▄█▇▄▅▅▆█▇▇▄▆▆▃▅▅█▆▄▃▆
wandb:         train/mil_loss ▃▇▇▇▇▇▃▆▆▄▇▆▅▇▄▆▇▇▇▅▃▄▃▇▅█▆▁▅▂▆▄▆█▂▃▇▂▄▃
wandb:      train/policy_loss ███████████████████▁███▄████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▇████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.24716
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.24688
wandb:       eval/ensemble_f1 0.90667
wandb:            test/avg_f1 0.91538
wandb:      test/avg_mil_loss 0.17288
wandb:       test/ensemble_f1 0.91538
wandb:           train/avg_f1 0.91683
wandb:      train/ensemble_f1 0.91683
wandb:         train/mil_loss 0.22213
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yfmmd05
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085737-0yfmmd05/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5dmebi90 with config:
wandb: 	actor_learning_rate: 0.0014520751459680915
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08685195273298496
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9065429721521764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090030-5dmebi90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5dmebi90
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆▇█
wandb: best/eval_avg_mil_loss █▅▃▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▄▄▃▅▄▄▆▆▇▇████████████████████████████
wandb:      eval/avg_mil_loss █▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▄▄▄▄▅▅▅▅▄▄▆▆▇█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▆▄▃█▅▆▅▅▅▅▄▆▃▄▇▅▇▁█▅▅▇▄▅▆▇▂▄▁▅▄▃▂▆▄▇▆▅
wandb:      train/ensemble_f1 ▂▁▅▆▆▄▅█▅▅▃▄▄▅▇▁▃▆▆▅▄▂▅█▄▄▂▅▁▁█▃█▆▃▃▆▅▅▆
wandb:         train/mil_loss ▆█▄▃▄▃▄▄▄▃▃▅▂▄▂▃▂▃▅▃▂▁▁▃▃▂▄▂▃▃▃▃▃▂▂▃▄▂▃▃
wandb:      train/policy_loss ████████▁████▆██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.23902
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.92573
wandb:      eval/avg_mil_loss 0.23261
wandb:       eval/ensemble_f1 0.92573
wandb:            test/avg_f1 0.91936
wandb:      test/avg_mil_loss 0.16835
wandb:       test/ensemble_f1 0.91936
wandb:           train/avg_f1 0.91401
wandb:      train/ensemble_f1 0.91401
wandb:         train/mil_loss 0.20577
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5dmebi90
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090030-5dmebi90/logs
wandb: Agent Starting Run: 0h4fpui5 with config:
wandb: 	actor_learning_rate: 0.001968333300376804
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9852348627651554
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0523077297907506
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090228-0h4fpui5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0h4fpui5
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▆▅▅▃▅▆▆▅▁▄▃▄▅▇▇▅▆▆▄▇▃▃▄▅▃▄▄▃▅▂▄▇█▁▃█
wandb:      train/ensemble_f1 ▃▅▆▅▃▃▃▅▅▄▃▅▅▇▄▄▄▆▄▅▂▁▂█▂▄▄▃▃▁▄▃▅▅▂▇▄▁▃▇
wandb:         train/mil_loss ▁▂█▄▁▁▁▁▂▁▁▁▂▁▄▂▁▁▁▄▇▂▁▁▁▁▁▁▁▂▂▄▂▂▁▂▄▄▁▂
wandb:      train/policy_loss █▄█████▄▄█▅█▄███▄██▄▁█████▄██▄███▄█▄███▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▄█▄█████▄█▄▅███▄██▄▁███▄██▄██▄████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65581
wandb: best/eval_avg_mil_loss 3.9727
wandb:  best/eval_ensemble_f1 0.65581
wandb:            eval/avg_f1 0.65581
wandb:      eval/avg_mil_loss 3.93252
wandb:       eval/ensemble_f1 0.65581
wandb:            test/avg_f1 0.60413
wandb:      test/avg_mil_loss 3.60481
wandb:       test/ensemble_f1 0.60413
wandb:           train/avg_f1 0.66271
wandb:      train/ensemble_f1 0.66271
wandb:         train/mil_loss 0.23843
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0h4fpui5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090228-0h4fpui5/logs
wandb: Agent Starting Run: 3kx2ge7d with config:
wandb: 	actor_learning_rate: 0.0092779381772767
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41407567629318154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.442803307042872
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090350-3kx2ge7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3kx2ge7d
wandb: uploading history steps 157-172, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆████
wandb: best/eval_avg_mil_loss █▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▆████
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ███▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▇▇▇▇▇▇▇███▇██████████████▇████████████
wandb:      train/ensemble_f1 ▁▁▁▂▁█▇███▇██████████████▇██████████████
wandb:         train/mil_loss ▇▅██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ███▇██████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▅▅▅▄▃▂▃▇█▇▇▃▃▁▄▁▃▂▂▂▃▃▃▂▄▂▁▁▃▂▃▃▂▂▅▃▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.22201
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92937
wandb:      eval/avg_mil_loss 0.2148
wandb:       eval/ensemble_f1 0.92937
wandb:            test/avg_f1 0.93426
wandb:      test/avg_mil_loss 0.14637
wandb:       test/ensemble_f1 0.93426
wandb:           train/avg_f1 0.92942
wandb:      train/ensemble_f1 0.92942
wandb:         train/mil_loss 0.22895
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3kx2ge7d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090350-3kx2ge7d/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qqqwvgmf with config:
wandb: 	actor_learning_rate: 0.00435422434053335
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4098724404600065
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5190225020682168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090616-qqqwvgmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qqqwvgmf
wandb: uploading history steps 136-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█████
wandb: best/eval_avg_mil_loss █▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁█████
wandb:            eval/avg_f1 ▁▂▄▄▄▅▅▅▇▇██████████████████████████████
wandb:      eval/avg_mil_loss ▇█▇▇▇▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▁▂▂▄▄▄▄▄▄▅▅▅▇▇█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▇▃▃▅▄▅▃▅▆▅▅▅▁▅▄▅▅▄▅▁▅▄▂▅▆▅▃▅▅▇▄▇▇▇▄▅▆
wandb:      train/ensemble_f1 ▄▁▄▆▆▄▄▃▄▂█▄▅▅▄▂▆▆▄▆▅▅▅▆▇▅▃▅▅▅▇▅▆▅▇█▇▅▇▅
wandb:         train/mil_loss ▄▃▃▅▂▃▄▃▄▄▂▅▄▅▆▇▃▃▃▄▄█▃▄▄▅▄▄▇▄▂▄▆▅▅▅▅▅▄▁
wandb:      train/policy_loss ██▅██▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁█▄████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.22417
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92937
wandb:      eval/avg_mil_loss 0.21674
wandb:       eval/ensemble_f1 0.92937
wandb:            test/avg_f1 0.93426
wandb:      test/avg_mil_loss 0.1562
wandb:       test/ensemble_f1 0.93426
wandb:           train/avg_f1 0.92498
wandb:      train/ensemble_f1 0.92498
wandb:         train/mil_loss 0.20323
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qqqwvgmf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090616-qqqwvgmf/logs
wandb: Agent Starting Run: la2axhuz with config:
wandb: 	actor_learning_rate: 0.004777787862571269
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24844366545762864
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8497779420986996
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090815-la2axhuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/la2axhuz
wandb: uploading history steps 137-156, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss ▁▁▁█
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▁▁▁▄▄▄▃▃▅▅▆▆▆███████████████████████████
wandb:      eval/avg_mil_loss ▁▁▆▆▅██▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▄▄▃▅▅▅▆█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▄▆▅▆▆▆▆▆▅▄▅▄▇▇▅▁▃▃▃▃▅▅▆▅▄▄▆▅▄▆▄▂▃▄▅▆█
wandb:      train/ensemble_f1 ▂▅▃▃▂▇▇▇▆█▆▃▆▃▆▆▆▂▁▄▆█▃▄▄█▅▇▄▃▆▄▇▄▆▆▄▅▆▄
wandb:         train/mil_loss ▅▄▅▇█▃▃▄▆▆▅▅▁▁▂▃▅▆▃▇▇▂▃▆▄▅▁▄▆▂▄▄▆▂▃▄▃▇▃▃
wandb:      train/policy_loss ▄▄▄▄▄▄█▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▁▄▄█▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.23395
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.92573
wandb:      eval/avg_mil_loss 0.23022
wandb:       eval/ensemble_f1 0.92573
wandb:            test/avg_f1 0.92307
wandb:      test/avg_mil_loss 0.16473
wandb:       test/ensemble_f1 0.92307
wandb:           train/avg_f1 0.93006
wandb:      train/ensemble_f1 0.93006
wandb:         train/mil_loss 0.21673
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/la2axhuz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090815-la2axhuz/logs
wandb: Agent Starting Run: megiqxsk with config:
wandb: 	actor_learning_rate: 0.0022569946163765145
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5575732025007365
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8400697977839454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091019-megiqxsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/megiqxsk
wandb: uploading history steps 195-213, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▁▁▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆████▆██████████████
wandb:      eval/avg_mil_loss █▆▆▆▅▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆███████████████▆████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▁▂▃▅▅▅▆▅▄▃▂▇▅▆▂▂▂▄▄▄▇▆▄▇▇▅▆▂▇▄▂▇▄▇▇▅▅█
wandb:      train/ensemble_f1 ▃▃▂▂▆▄▇▄▆▃▂▂▅▄▃▅▅▇▁▅▃▅▄▅▅█▃▇▆▄▅▄▄▆▆▅█▇▆▃
wandb:         train/mil_loss ▅▆▇▃▄▇▆▆▅▅▆▆▅▇▅▃▆█▄▇▇█▁▅▆▇▅█▄▇▅▆▄▄▆▄▅▅▅▆
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▅▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.22555
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.92558
wandb:      eval/avg_mil_loss 0.22458
wandb:       eval/ensemble_f1 0.92558
wandb:            test/avg_f1 0.92679
wandb:      test/avg_mil_loss 0.15687
wandb:       test/ensemble_f1 0.92679
wandb:           train/avg_f1 0.91301
wandb:      train/ensemble_f1 0.91301
wandb:         train/mil_loss 0.2195
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/megiqxsk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091019-megiqxsk/logs
wandb: Agent Starting Run: evemvy05 with config:
wandb: 	actor_learning_rate: 0.009090743319861531
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.044315116470910354
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9788658861399376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091310-evemvy05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/evemvy05
wandb: uploading history steps 177-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇▇▇█
wandb: best/eval_avg_mil_loss ██▅▄▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇▇▇█
wandb:            eval/avg_f1 ▁▁▂▁▁▁▁▁▁▁▁▂▂▅▅▅▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▅▅▆█▇▇▆▆▆▆▅▅▅▅▄▃▂▂▂▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▄▇▅▅▇▅▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▄▁▃▃▄▄▃▄▆▅▆▆▆▅▃▇▅▄▆▇▆▆▆▆▆▇█▆▅▆▇▅▇▆▆▇█▆
wandb:      train/ensemble_f1 ▁▃▃▂▁▂▃▃▆▁▂▅▄▃▄▄▆▃▅▄▇▄▅▅▅▄▅▆▄▆█▆▃▄▅▆▇▆▅▅
wandb:         train/mil_loss ▄▂▆▃█▃▄▅▃▄▄▅▃▂▄▄▂▂▅▃▃▂▁▂▂▂▂▁▂▁▃▂▂▃▃▂▁▂▂▁
wandb:      train/policy_loss ▃▇▃▃▃▃▃▃▃▃▁▃▂▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▆▃▃▃▃▃▃▃▃▃▁▃▃▃▃▂▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.20711
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.92587
wandb:      eval/avg_mil_loss 0.20738
wandb:       eval/ensemble_f1 0.92587
wandb:            test/avg_f1 0.94596
wandb:      test/avg_mil_loss 0.13121
wandb:       test/ensemble_f1 0.94596
wandb:           train/avg_f1 0.927
wandb:      train/ensemble_f1 0.927
wandb:         train/mil_loss 0.23379
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/evemvy05
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091310-evemvy05/logs
wandb: Agent Starting Run: hk58v5lk with config:
wandb: 	actor_learning_rate: 0.00915470190859504
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5192303588926626
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7429951960756245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091545-hk58v5lk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hk58v5lk
wandb: uploading history steps 98-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████████▅▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █████████▅▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███████████▅▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      train/ensemble_f1 ████████▅▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/mil_loss ▁▁▁▁▁▁▁▁▁▁▁▄▅▆▇▅▆▅▆▇▅▇▅▅▄▇▆▄▄█▄▃▄▅▄▆▆▅▄▅
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▁▃▃▃▃▃▃▃▂▂▃▃▃▃▃▃█▃▃▂▃█▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▃█▅▅▅▁▅▂▅▅▄▅▅▅▅▅▄▅▅▅▅▅▅▇▅▅▅▅▅▇▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90725
wandb: best/eval_avg_mil_loss 0.29938
wandb:  best/eval_ensemble_f1 0.90725
wandb:            eval/avg_f1 0.47464
wandb:      eval/avg_mil_loss 5.03634
wandb:       eval/ensemble_f1 0.47464
wandb:            test/avg_f1 0.91936
wandb:      test/avg_mil_loss 0.15204
wandb:       test/ensemble_f1 0.91936
wandb:           train/avg_f1 0.48149
wandb:      train/ensemble_f1 0.48149
wandb:         train/mil_loss 2.27224
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hk58v5lk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091545-hk58v5lk/logs
wandb: Agent Starting Run: flxktnhx with config:
wandb: 	actor_learning_rate: 0.0001459025554912655
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18750409195028772
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8685894576705228
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091713-flxktnhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flxktnhx
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▆▆▇▆▆▆▆▆▆▆▆▆▆▇█████████▇▇▇▇▇█████████▇
wandb:      eval/avg_mil_loss █▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▆▆▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇████▇▇█████████▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▄▆▄▄▆▄▁▅▃▄▄▂▃▄▆▇█▁▆▅█▅▅▅▅▆▅▃▅▆▆▅▆▅▅▇▅
wandb:      train/ensemble_f1 ▁▄▆▄▆▄▅▃▃▅▃▅▅▄▆▄▇▅▄▅█▂▆▅▅▄▄▄▅▅▅▅▃▅▅▅▆▆▅▃
wandb:         train/mil_loss ▇█▆▄▅▇▄▇▂▅▂▄▅▃▄▅▅▆▅▂▃▇▄▃▃▄▄▃▃▄▄▄▂▄▄▁▄▅▂▅
wandb:      train/policy_loss ▇▇█▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁██████████████████▅████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.21407
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.21312
wandb:       eval/ensemble_f1 0.9105
wandb:            test/avg_f1 0.93426
wandb:      test/avg_mil_loss 0.16455
wandb:       test/ensemble_f1 0.93426
wandb:           train/avg_f1 0.92174
wandb:      train/ensemble_f1 0.92174
wandb:         train/mil_loss 0.21207
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flxktnhx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091713-flxktnhx/logs
wandb: Agent Starting Run: ytpi3te1 with config:
wandb: 	actor_learning_rate: 4.45214723505455e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6947296635207405
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8875759802070281
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091954-ytpi3te1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ytpi3te1
wandb: uploading history steps 137-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆█
wandb: best/eval_avg_mil_loss █▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▃▆█
wandb:            eval/avg_f1 ▃▁▁▁▁▃▃▃▅▅▅▅▆▆██████████████████████████
wandb:      eval/avg_mil_loss ██▇▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▅▆▆▆███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▃▃▃▅▂▃▅▆▅▇▆▅▃▅▇▃▃▄▇▅▅▃▇▆█▅█▅▅▅▁▅▅▄▄▅▅
wandb:      train/ensemble_f1 ▃▄▂▁▃▄▄▄▇▃▅▅▅█▆▄▅▇▅▅▅▃▃▄▆█▆▆█▃▅▇▆▇▆▆▆▄▆▅
wandb:         train/mil_loss ▅▇▄▇▄▆▆▆▄▄▆▆▅▄▁▃▁▇▃██▃▅▃▂▂▄▁█▅▁▅▃▂▅▆▅▂▆▂
wandb:      train/policy_loss ▃█▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▁██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8828
wandb: best/eval_avg_mil_loss 0.29618
wandb:  best/eval_ensemble_f1 0.8828
wandb:            eval/avg_f1 0.8828
wandb:      eval/avg_mil_loss 0.28566
wandb:       eval/ensemble_f1 0.8828
wandb:            test/avg_f1 0.90964
wandb:      test/avg_mil_loss 0.18753
wandb:       test/ensemble_f1 0.90964
wandb:           train/avg_f1 0.88692
wandb:      train/ensemble_f1 0.88692
wandb:         train/mil_loss 0.24414
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ytpi3te1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091954-ytpi3te1/logs
wandb: Agent Starting Run: j212f3q6 with config:
wandb: 	actor_learning_rate: 0.00033065408978037665
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5971834911540508
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6481695348244576
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092147-j212f3q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j212f3q6
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███████████▇▇▇▇▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▅▁▃▃▁▄▅▃▄▁▃▂▇▆▅▃▃▇▆▅▅▂▆▅▄▅▆▄▃▆▄▆▄▇▅█▃
wandb:      train/ensemble_f1 ▄▅▂▃▂▅▁▅▃▃▄▅▆▄▁▆▄▅▃▃▅▅▂▆▆▅▅▃█▄▆▆▆▄▄▇▅▇▅▆
wandb:         train/mil_loss ▄▅▁▃█▄▄▃▄▃▅▆▃▄▅▄▄▃▃▄▃▁▂▆▂▆▄▄▄▄▃▄▄▃▄▅▄▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53362
wandb: best/eval_avg_mil_loss 5.63687
wandb:  best/eval_ensemble_f1 0.53362
wandb:            eval/avg_f1 0.53362
wandb:      eval/avg_mil_loss 4.97937
wandb:       eval/ensemble_f1 0.53362
wandb:            test/avg_f1 0.48318
wandb:      test/avg_mil_loss 5.36002
wandb:       test/ensemble_f1 0.48318
wandb:           train/avg_f1 0.5601
wandb:      train/ensemble_f1 0.5601
wandb:         train/mil_loss 2.31416
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j212f3q6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092147-j212f3q6/logs
wandb: Agent Starting Run: prj2nqbc with config:
wandb: 	actor_learning_rate: 0.00014624973217668925
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.324881735498072
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14653838418499232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092311-prj2nqbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/prj2nqbc
wandb: uploading history steps 138-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▆▇█
wandb: best/eval_avg_mil_loss █▇▆▅▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▆▆▆▆▆▆▇▇▇▇█████████████████████████
wandb:      eval/avg_mil_loss ████▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▆▆▇▇▇▇▇▇████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▁▁▃▄▆▃▅▃▄▆▄▇▆▅▆█▆▅▅▄▅▃▅▅▆▃▅▄▆▅▅▅▃▆▄▅▅
wandb:      train/ensemble_f1 ▄▃▁▂▂▄▅▆▄▆█▆▇▃▃▆▅▅▇▇▅▆▇▃▇▇▆▃█▆▅▆▅▅▆▅▄▆▅▆
wandb:         train/mil_loss █▆▄▄▆▄▄▆▄▇▂▅▆▂▅▅▆▂▄▇▂▄▃▅▇▄▆▂▆▅▂▂▃▃▃▁▅▂▂▄
wandb:      train/policy_loss ▄▄▄█▄▁▁▃▇█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁███▃█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.639
wandb: best/eval_avg_mil_loss 4.39521
wandb:  best/eval_ensemble_f1 0.639
wandb:            eval/avg_f1 0.639
wandb:      eval/avg_mil_loss 4.14884
wandb:       eval/ensemble_f1 0.639
wandb:            test/avg_f1 0.57914
wandb:      test/avg_mil_loss 4.0818
wandb:       test/ensemble_f1 0.57914
wandb:           train/avg_f1 0.62853
wandb:      train/ensemble_f1 0.62853
wandb:         train/mil_loss 2.49577
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/prj2nqbc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092311-prj2nqbc/logs
wandb: Agent Starting Run: n5o09k3z with config:
wandb: 	actor_learning_rate: 1.115613626555624e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08901225064889906
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.533512601959771
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092510-n5o09k3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n5o09k3z
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄███
wandb: best/eval_avg_mil_loss █▄▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▁▄███
wandb:            eval/avg_f1 ▁▁▁▁▁▁▄███▅▅▅▅█▅▅▅▅▅▅▅▅▅▅███▅███████████
wandb:      eval/avg_mil_loss █▇▇▆▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▃▃▁▁████▆▆▆▆▆▆▆▆███▆▆▆▆██▆██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▁▂▁▅▂▅▆▅█▃▆▂▅▆▆▃▅▅▄▆▄▄▃▆▆▆▇▆▇▃▅▅▆▆▇▃▇▅
wandb:      train/ensemble_f1 ▂▆▁▂▅▇▅▄▆▄▅▅▂▇▆▅▆▃▂▄▅▃▅▅▄▆▅▆▃█▃▅▇▅▅▄▆▃▄▇
wandb:         train/mil_loss ▄▄█▆▁▅▁▄▂▃▂▅▄▂▂▃▃▃▃▅▃▃▁▃▂▃▃▃▃▂▄▃▂▄▃▁▄▂▂▁
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▄▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.21592
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.92209
wandb:      eval/avg_mil_loss 0.21428
wandb:       eval/ensemble_f1 0.92209
wandb:            test/avg_f1 0.92704
wandb:      test/avg_mil_loss 0.17246
wandb:       test/ensemble_f1 0.92704
wandb:           train/avg_f1 0.90923
wandb:      train/ensemble_f1 0.90923
wandb:         train/mil_loss 0.23232
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n5o09k3z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092510-n5o09k3z/logs
wandb: Agent Starting Run: lfykpiv0 with config:
wandb: 	actor_learning_rate: 0.008613213138052385
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9236384439025792
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7894998678327503
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092806-lfykpiv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lfykpiv0
wandb: uploading history steps 193-206, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆████████▆▆▆▆▆▆▆▅▅▅▆▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▆▆▆▅▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▁▄▅▄▄▆▃▄▆▄▆█▃▃▄▇▆▄▄▇▆▅▅▅▃▄▆▃▅▆▄▆▇▅▅▄▆▃
wandb:      train/ensemble_f1 ▅▅▁▄▅▇▅▄▃▅▃▅▅▅▆▅▅▆▅▅▅▇▄▇▆▅▆▄▄▅▅▆▆▆█▆▄▅▄▇
wandb:         train/mil_loss ▂▄▅█▄▂▂▅▇▃▂▅▃▂▆▃▁▃▂▆▃▃▅▃▃▄▄▃▄▆▃▄▇▃▄▅▃▃▅▄
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████▁█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88316
wandb: best/eval_avg_mil_loss 0.50208
wandb:  best/eval_ensemble_f1 0.88316
wandb:            eval/avg_f1 0.86844
wandb:      eval/avg_mil_loss 0.48131
wandb:       eval/ensemble_f1 0.86844
wandb:            test/avg_f1 0.87348
wandb:      test/avg_mil_loss 0.48449
wandb:       test/ensemble_f1 0.87348
wandb:           train/avg_f1 0.84646
wandb:      train/ensemble_f1 0.84646
wandb:         train/mil_loss 0.26282
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lfykpiv0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092806-lfykpiv0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: md6enkti with config:
wandb: 	actor_learning_rate: 0.0005370621159270172
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4366436783230475
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4455537680121068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093104-md6enkti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/md6enkti
wandb: uploading history steps 157-173, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▄▄▄▄▄▅▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇███
wandb:      eval/avg_mil_loss █▄▆▆▅▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▆▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆██▆██▆▆▆▆▆▆▆▆▆███▆██▆██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▄▂▃▂▄▄▂▄▃▅▁▃▃▅▅▃▅▃▂▄█▃▇▂▃▃▂▄▃▅▃▆▄▃▃▃▁
wandb:      train/ensemble_f1 ▄▅▅▃▃▅▅▂▂▃▅▅▄▃▆▆▄▆▆▄▇▇▄▆▃█▃▄▇▃▆▃▄▄▄▅▅▅▁▄
wandb:         train/mil_loss ▅▆▃▃▆▅▅█▄▁▅▄▄▆▁▅█▅▄▃▂▅▄▂▃▅▇▆▅▄▃▅▄▄▃▇▃▄▄▅
wandb:      train/policy_loss ▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▆▇▄▄▄█▄▃▄▄▄▄▄▇▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▇▅▄▅▅▅▅▅▆▅▇▅▅▅█▅▅▅▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.23793
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.92177
wandb:      eval/avg_mil_loss 0.23665
wandb:       eval/ensemble_f1 0.92177
wandb:            test/avg_f1 0.91936
wandb:      test/avg_mil_loss 0.16511
wandb:       test/ensemble_f1 0.91936
wandb:           train/avg_f1 0.91854
wandb:      train/ensemble_f1 0.91854
wandb:         train/mil_loss 0.23307
wandb:      train/policy_loss -0.03772
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.03772
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/md6enkti
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093104-md6enkti/logs
wandb: Agent Starting Run: y8nqrdk2 with config:
wandb: 	actor_learning_rate: 0.00011901953965319747
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08409844834044022
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5953882164282909
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093324-y8nqrdk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y8nqrdk2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss █▆▄▄▃▂▂▂▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▃▆▆▆▆▇▇▇▇████▆▇▇▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▆▆▇▇
wandb:      eval/avg_mil_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▁▃▆▇▇▇▇▇█▇█▇▇█▇███████▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▃▆▆▇▄▇█▅▆▄▆█▆▄▆▄▄▄▅▅▄▅▁▃▃▃▂▃▄▃▄▂▅▄▂▃▄▂
wandb:      train/ensemble_f1 ▁▄▄▆▅▆█▇▆▇▇▇▆▇▇▇▆▇▅▆▆▇▆▆▆▅▆▅▅▇▅▄▅▅▇▆▇▆▄▄
wandb:         train/mil_loss ▄▃▄▅▄▄▂▁▂▂▁▂▄▃▄▂▄▅▅▂▄▄▅▅▁▄▅▅▅▃█▃▅▇▅▅▆▆▅▆
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▁▇▆▇▇▇▇▇▇▅▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▁▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82478
wandb: best/eval_avg_mil_loss 0.5275
wandb:  best/eval_ensemble_f1 0.82478
wandb:            eval/avg_f1 0.81367
wandb:      eval/avg_mil_loss 0.7383
wandb:       eval/ensemble_f1 0.81367
wandb:            test/avg_f1 0.82492
wandb:      test/avg_mil_loss 0.41704
wandb:       test/ensemble_f1 0.82492
wandb:           train/avg_f1 0.78703
wandb:      train/ensemble_f1 0.78703
wandb:         train/mil_loss 0.63718
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y8nqrdk2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093324-y8nqrdk2/logs
wandb: Agent Starting Run: uecz0yz8 with config:
wandb: 	actor_learning_rate: 0.00017608697372121753
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19796550106703792
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8651233528420084
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093528-uecz0yz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uecz0yz8
wandb: uploading history steps 334-338, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▅▅▅▆▇█
wandb: best/eval_avg_mil_loss █▆▄▄▄▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▅▅▅▆▇█
wandb:            eval/avg_f1 ▁▂▂▁▁▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▇▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▁▁▄▅▅▅▅▅▆▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▃▃▅▃▅▅▄▄▆▇▆▆▄▇▂▆▂▄▄▃▅▆▆█▆▇▅▄▄▇█▅▆▄█▄▃
wandb:      train/ensemble_f1 ▃▃▁▄▅▅▃▄▃▅▅▇▁▇▅▁▂▇▆▄▅█▅▆▃▃▄▇▃▃▄▄▆▄▆▃▄▄▆▅
wandb:         train/mil_loss ██▇▇▅▄█▄▂▆▅▃▆▆▁▅▆▇▅▃▆▃▂▃▁▂▃▃▂▃▇▆▆▃▄▄▅▄▅▅
wandb:      train/policy_loss ▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9408
wandb: best/eval_avg_mil_loss 0.19955
wandb:  best/eval_ensemble_f1 0.9408
wandb:            eval/avg_f1 0.93704
wandb:      eval/avg_mil_loss 0.20164
wandb:       eval/ensemble_f1 0.93704
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.14175
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.91924
wandb:      train/ensemble_f1 0.91924
wandb:         train/mil_loss 0.21517
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uecz0yz8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093528-uecz0yz8/logs
wandb: Agent Starting Run: 4c814vr6 with config:
wandb: 	actor_learning_rate: 0.0003401673390309176
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8543837513103321
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6825199581166392
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093952-4c814vr6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4c814vr6
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▆▅▅▅▅▄▄▄▃▄▄▄▃▃▃▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▅▅▂▇▆▆▃▆▆▃▁▆▄▄▅█▄▂▃▁▃▅▄▆▅▅▄▃▆▄▃▇▆▅▆▆▆
wandb:      train/ensemble_f1 ▆▅▅▅▇▃▃▄▆▆▆▅▄▅▄▃▂▂▆█▅▂▄▅▅▆▅▄▃▃▄▃▅▄▆▆▆▅▁█
wandb:         train/mil_loss ▃▄▅▄▃▄▁▅▃▄▄▄▅▅▄▃▂▂▂▇▄▅▃▁▃▃▂▁█▆▄▄▂▅▇▂▃▃▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.25718
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.91394
wandb:      eval/avg_mil_loss 0.2448
wandb:       eval/ensemble_f1 0.91394
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.16384
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.90248
wandb:      train/ensemble_f1 0.90248
wandb:         train/mil_loss 0.21911
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4c814vr6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093952-4c814vr6/logs
wandb: Agent Starting Run: 1v9h1zhv with config:
wandb: 	actor_learning_rate: 0.0009019143090247664
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.33074103073004035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34196918635760165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094115-1v9h1zhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1v9h1zhv
wandb: uploading history steps 99-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅█▇▁▂▄▅▆▅▅▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▆▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █▄▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▆▃▁▆▃▅▅▆▇▆▆▆▇██▇▇▇▇██████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▁▂▆▃▆█▆▆▇▆▆▇▇▇▇█▇▇▇▆▆▇▇▇▅▆▆▇█▇█▇▇█▇▇▇
wandb:      train/ensemble_f1 ▄▃▂▁▁▃▃▃▅▄▆▅▅▆▅▆▆▇▇▆▆▅▅▅▆▆▆▅▇▇▆█▇▆▆█▇▇▆▇
wandb:         train/mil_loss ██▅▆▃▄▂▄▄▃▄▃▃▂▄▃▂▂▄▃▃▃▄▂▂▃▄▂▂▃▃▂▃▃▃▂▁▂▃▃
wandb:      train/policy_loss ▄▁▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66266
wandb: best/eval_avg_mil_loss 2.27208
wandb:  best/eval_ensemble_f1 0.66266
wandb:            eval/avg_f1 0.64611
wandb:      eval/avg_mil_loss 1.46192
wandb:       eval/ensemble_f1 0.64611
wandb:            test/avg_f1 0.57156
wandb:      test/avg_mil_loss 1.87095
wandb:       test/ensemble_f1 0.57156
wandb:           train/avg_f1 0.6726
wandb:      train/ensemble_f1 0.6726
wandb:         train/mil_loss 0.86109
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1v9h1zhv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094115-1v9h1zhv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7cqr17jv with config:
wandb: 	actor_learning_rate: 0.00014222122365158534
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.459301887613796
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9522320389556206
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094248-7cqr17jv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7cqr17jv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ▇█▇████▇▇▇▆▆▅▅▅▅▃▂▁▁▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss ▇█▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▁▁▁▁▂▂▂▃▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▄▃▃▄▃▄▅▅▄▅▆▅▅▅▅▅▆▆▅▇▆▆▆▆▆▆▆▇▆▇▆▇█▇▆▇▇
wandb:      train/ensemble_f1 ▃▁▃▁▂▃▄▄▅▄▅▅▅▅▅▅▅▆▅▅▆▆▆▇▅▇▆▆▇█▇▇▇▇▇▇▇▆██
wandb:         train/mil_loss █▂▃▄▄▃▃▆▄▄▃▂▄▁▂▁▄▅▃▆▂▆▂▃▄▄▄▂▄▁▆▃▁▄▆▄▂▂▄▇
wandb:      train/policy_loss ▅▂▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▂▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57004
wandb: best/eval_avg_mil_loss 4.9415
wandb:  best/eval_ensemble_f1 0.57004
wandb:            eval/avg_f1 0.57004
wandb:      eval/avg_mil_loss 4.77733
wandb:       eval/ensemble_f1 0.57004
wandb:            test/avg_f1 0.52905
wandb:      test/avg_mil_loss 4.41931
wandb:       test/ensemble_f1 0.52905
wandb:           train/avg_f1 0.53522
wandb:      train/ensemble_f1 0.53522
wandb:         train/mil_loss 3.06198
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7cqr17jv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094248-7cqr17jv/logs
wandb: Agent Starting Run: 7j8j56z2 with config:
wandb: 	actor_learning_rate: 0.0007492632456805996
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5102713063058432
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6512254296057517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094936-7j8j56z2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7j8j56z2
wandb: uploading history steps 196-212, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆███████
wandb:      eval/avg_mil_loss █▇▆▆▆▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▄▃█▂▅▁▃▆▄▃▄▄▃▄▂▄▄▅▄▅▄▆▄▆▄▆▂▆▂▅▂▃▃▂▅▄▄
wandb:      train/ensemble_f1 ▆▄█▅▅▅▅▂▄▅▄▄▆▄▄▇▅▅▅▅▆▅▅▅▄▅▁▆▃▅▄▅▆▅▄▅▅█▅▆
wandb:         train/mil_loss ▁▅▅▄▂▄▅▅▄▄▃▄▄▇▁▄▄▆▅▄▅▄▁▆▄▅▄▃▆▃▅▂▅▅▃▂▅▅▄█
wandb:      train/policy_loss █████████████████████████████████▁██████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.21663
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.92209
wandb:      eval/avg_mil_loss 0.21622
wandb:       eval/ensemble_f1 0.92209
wandb:            test/avg_f1 0.92307
wandb:      test/avg_mil_loss 0.16978
wandb:       test/ensemble_f1 0.92307
wandb:           train/avg_f1 0.91305
wandb:      train/ensemble_f1 0.91305
wandb:         train/mil_loss 0.2503
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7j8j56z2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094936-7j8j56z2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wqmiec6o with config:
wandb: 	actor_learning_rate: 8.807029061623712e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6129512052784251
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6183174194793901
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095232-wqmiec6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wqmiec6o
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▂▁▃▃▄▅▁▂▃▃▄▅▄▅▅▄▇▂▆▆▇▄▆█▆▅▇▇▃▅▅▃▇▃▄▃▇
wandb:      train/ensemble_f1 ▁▂▁▃▂▃▃▄▁▃▃▃▄▅▄▅▅▄▆▄▆▆▆▇▇▆▅█▇▇▅▇▆██▆▆▃██
wandb:         train/mil_loss ▃▃▃▇▃▄▅▆▅▃▆▇▄▄▄▄▃▃▅█▂▄▃▅▅▄▅▃▆▅▂▄▂▃▁▃▇▆▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.26361
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.23061
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.92191
wandb:      test/avg_mil_loss 0.16409
wandb:       test/ensemble_f1 0.92191
wandb:           train/avg_f1 0.92536
wandb:      train/ensemble_f1 0.92536
wandb:         train/mil_loss 0.21647
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wqmiec6o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095232-wqmiec6o/logs
wandb: Agent Starting Run: tzccsapg with config:
wandb: 	actor_learning_rate: 0.0012286757131572466
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6253977375659733
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6333664643303516
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095355-tzccsapg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzccsapg
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████▁▁▁███████████████▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █████████████▁▁████████████████▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▅▅▅▅▁▃▃█▅▄▃▄▄▁▄▅▇▆▅▇▆▅▁▆▄▅▃▆▇▆▃▄▃▆█▄▆
wandb:      train/ensemble_f1 ▅▆▅▅▄▅▃▃▄▄▆▅▃█▆▅▄▃▁▁█▄▃▅█▇▆▆▄▅▄▇▅▃█▄▃▃█▄
wandb:         train/mil_loss ▄▃▅▃▆▂▇▂▅▄▃▅▂▄▅▅▅▇█▄█▄▃▂▄▃▆▄▂▃▃▁▄▆▅▃▄▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.26661
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.23768
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.92191
wandb:      test/avg_mil_loss 0.16458
wandb:       test/ensemble_f1 0.92191
wandb:           train/avg_f1 0.91203
wandb:      train/ensemble_f1 0.91203
wandb:         train/mil_loss 0.21342
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzccsapg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095355-tzccsapg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2s1i2kct with config:
wandb: 	actor_learning_rate: 0.006703590009623594
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09788373648651684
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5725771763625632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095528-2s1i2kct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s1i2kct
wandb: uploading history steps 177-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss ▇▆█▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▁▁▁▅▅▅▅▅▅▅▅▅███████▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▇▇▇▇▇▆███▇▇▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▅▅▅▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅███████▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▃▄▁▅▄▄▄▃▅▃▁▂▅▁▃▃▂▅▇▂▃▃▃▅▃▂▃▄▅▄▅█▄▆▄▇▄▅
wandb:      train/ensemble_f1 ▄▆▇▅▁▄▇▁▄▁▅▂▂▅▆▄▆▃▅▄▅▇▅▄▄▃█▆▂▅▄▃▃▆▅▆▃█▅▅
wandb:         train/mil_loss ▁▇▅█▅▆▅▅▇▆▃▅█▇▇▃▄▄▅▄▃▄▂▄▄▂▆▆▄▄▅▆▅▄▆▅▅▃▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88686
wandb: best/eval_avg_mil_loss 1.07888
wandb:  best/eval_ensemble_f1 0.88686
wandb:            eval/avg_f1 0.88321
wandb:      eval/avg_mil_loss 1.00756
wandb:       eval/ensemble_f1 0.88321
wandb:            test/avg_f1 0.87756
wandb:      test/avg_mil_loss 1.00735
wandb:       test/ensemble_f1 0.87756
wandb:           train/avg_f1 0.8735
wandb:      train/ensemble_f1 0.8735
wandb:         train/mil_loss 0.99546
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s1i2kct
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095528-2s1i2kct/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t3q3iw3f with config:
wandb: 	actor_learning_rate: 3.931953766765137e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7130575895357815
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30773025925854125
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095830-t3q3iw3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t3q3iw3f
wandb: uploading history steps 272-276, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇█████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▄▅▆▅▆▆▇▆▇█▆▇▆▅▇▆▆▅▅█▆▆▇▇▇▆▇▆▆▇▆██▅▅▇█
wandb:      train/ensemble_f1 ▂▂▄▁▄▃▆▄▄▆▇▆▆▇▇▅▅▆▆▆▅▆▅▇▆█▅▃▆▆▇▇█▆▇▆▇▇▆▆
wandb:         train/mil_loss ▅█▅▃▅█▇▆▂▃▄▁▂▄▃▃▅▅▂▅▂▅▂▆▃▁▂▄▁▃▅▂▁▃▅▁▄▄▃▂
wandb:      train/policy_loss █▄▄▆▄▁▂▂▃▂▅▅▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▄█▅▆▆▆▅▃▁▃▃▁▂▂▄▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6142
wandb: best/eval_avg_mil_loss 5.28983
wandb:  best/eval_ensemble_f1 0.6142
wandb:            eval/avg_f1 0.6142
wandb:      eval/avg_mil_loss 5.18707
wandb:       eval/ensemble_f1 0.6142
wandb:            test/avg_f1 0.55678
wandb:      test/avg_mil_loss 5.0244
wandb:       test/ensemble_f1 0.55678
wandb:           train/avg_f1 0.62912
wandb:      train/ensemble_f1 0.62912
wandb:         train/mil_loss 0.76399
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t3q3iw3f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095830-t3q3iw3f/logs
wandb: Agent Starting Run: eyyk6wvf with config:
wandb: 	actor_learning_rate: 0.0001372051111107924
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9420696016217532
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9594831062556722
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100208-eyyk6wvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eyyk6wvf
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▆▅▆▆▇▆▆▅▃▃▂▃▂▃▃▃▂▂▂▂▁▂▂▃▃▂▂▂▃▃▂▃▃▄▄▄▂▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▄▁▆▇▃▆▁▄▅█▅▅▆▃▃▅▄▄▄▄▁▆▆▃▅▅▄█▆▃▄▅▄▆▆▆▅
wandb:      train/ensemble_f1 ▅▄▂▃▁▅▆▅▄▆▄▄▃▅▁▅▄▃▄▃▃▅▂▃▃▂▄▂█▇▃▄▄▅▃▅▅▄▆▄
wandb:         train/mil_loss ▃▆▅▅▄▆▅▅▅▆▇▄▇▃▃▃▃▂▃▄▄█▃▄▂▃▄▅▄▇▄▅▂▅▅▄▅▃▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.25801
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.91394
wandb:      eval/avg_mil_loss 0.25342
wandb:       eval/ensemble_f1 0.91394
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.1552
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.90517
wandb:      train/ensemble_f1 0.90517
wandb:         train/mil_loss 0.22293
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eyyk6wvf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100208-eyyk6wvf/logs
wandb: Agent Starting Run: h390ffel with config:
wandb: 	actor_learning_rate: 0.0020925997897088752
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5349237378418158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49380920072415513
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100335-h390ffel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h390ffel
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▆▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▂▄▄▄▄▅▅▅▅▅▅▅▇▇▇▇███████████████▇▇▇▇▇▇█
wandb:      eval/avg_mil_loss ██▇▇▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▃▃▃▃▆▆▆▆▆██████████████▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▇▃▆▅▄▆▆▆▁▇▄▆█▅▄▃█▅▇▄▅▄▄▄▃▄▆▇▄▃▂▅▇▆▃▄▅
wandb:      train/ensemble_f1 ▄▃▂▇▄▅▇▂▃▆▂▆▄▃▅▅▅▄█▄▆▅▅▃▄▅▆▂▆▃▁▃█▆▇▆▇▆▆▅
wandb:         train/mil_loss ▅▇▅▅▂▃▄▂▄▅▅▃▂▅▄▁▁▃█▃▅▃▃▃▃▅▅▅▅▂▄▇▄▃▄▄▂▆▂▂
wandb:      train/policy_loss ▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.22342
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92937
wandb:      eval/avg_mil_loss 0.22296
wandb:       eval/ensemble_f1 0.92937
wandb:            test/avg_f1 0.92679
wandb:      test/avg_mil_loss 0.15684
wandb:       test/ensemble_f1 0.92679
wandb:           train/avg_f1 0.91313
wandb:      train/ensemble_f1 0.91313
wandb:         train/mil_loss 0.19491
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h390ffel
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100335-h390ffel/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: liv0sa5t with config:
wandb: 	actor_learning_rate: 0.0012698207263670126
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2888343219047129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4815182618742795
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100611-liv0sa5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/liv0sa5t
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▇▇██
wandb: best/eval_avg_mil_loss █▅▄▃▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆▇▇██
wandb:            eval/avg_f1 ▁▁▅▆▆▇▇▆▆▆▇▇▇▇▇▇████████████████████████
wandb:      eval/avg_mil_loss ████▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▆▆▇▇▆▆▇▇▇▇▇▇██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▂▄██▆▄▇▅▅▅▅▆▅▅▄▅▇▇▇▆▆▄▆▅▆▆▇▆▅▄▅▆▆▅▅▅▅
wandb:      train/ensemble_f1 ▂▁▃▆▆▆▄▄▅▆▆▅▅▃▆▆▇▇▅▄▆▇▇█▇▇▇▄▇▇▆▆▄▄██▇▆▆▅
wandb:         train/mil_loss ▇▆█▄█▆▅▄▃▄▃▃▂▄▃▁▄▂▁▄▂▃▃▁▂▃▃▁▂▄▁▂▃▃▂▂▂▃▃▂
wandb:      train/policy_loss ▅▅▅▃▅▅▃▁▂▅▄▅▅▅▅▅▅▅▅▅▅▅▅▇▅▅▅▆█▇▇▇▇█▇██▇█▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▂▄▃▁▄▄▄▄▄▄▄▄▄▄█▇▄▄█▇█▆▇▆▆█▆▇▇▇▇▆▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.23778
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.9334
wandb:      eval/avg_mil_loss 0.23627
wandb:       eval/ensemble_f1 0.9334
wandb:            test/avg_f1 0.91566
wandb:      test/avg_mil_loss 0.17417
wandb:       test/ensemble_f1 0.91566
wandb:           train/avg_f1 0.91399
wandb:      train/ensemble_f1 0.91399
wandb:         train/mil_loss 0.2078
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/liv0sa5t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100611-liv0sa5t/logs
wandb: Agent Starting Run: jqzbq3aw with config:
wandb: 	actor_learning_rate: 0.0006963577268423418
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5187562621820666
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2732569100260276
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100830-jqzbq3aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqzbq3aw
wandb: uploading history steps 156-170, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▇█
wandb: best/eval_avg_mil_loss █▆▅▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▄▄▄▄▄▄▅▅▇▇▇▇████████████████████████
wandb:      eval/avg_mil_loss █▇▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃▁▁▃▃▃▃▂▃▅▃▅▆▃▃▅▂▅▃▄▄▃▃▄▂▄▃▃█▆▆▃▆▅▅▄▄▃
wandb:      train/ensemble_f1 ▁▃▁▃▂▃▃▅▃▃▆▄▄▃▆▄▃▄▅▅▄▃▅▄▃▅▃▂▃▃█▂▆▆▃▆▃▅▄▃
wandb:         train/mil_loss ▄▄▄▄▅▅▃▂▃▄▅▆▆▂▇▂▃▄▅▄▂▄▄▃▁▄▃▅▅▄▄▆▅▃▄▄█▄▄▄
wandb:      train/policy_loss ▂▃▅▃▅█▇▃▅▇▃▆▃▃▅▃▄▄▂▃▁▆▃▃▃▂▃▅▄▄▁▅▁▂▃▁▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▆▅▄█▄▄▇▅▄▃▄▃▄▃▃▅▃▅▃▂▂▃▄▁▃▂▃▂▁▆▃▃▁▂▄▃▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.22426
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92937
wandb:      eval/avg_mil_loss 0.21928
wandb:       eval/ensemble_f1 0.92937
wandb:            test/avg_f1 0.93801
wandb:      test/avg_mil_loss 0.14177
wandb:       test/ensemble_f1 0.93801
wandb:           train/avg_f1 0.91457
wandb:      train/ensemble_f1 0.91457
wandb:         train/mil_loss 0.21494
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqzbq3aw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100830-jqzbq3aw/logs
wandb: Agent Starting Run: 5s4izhvc with config:
wandb: 	actor_learning_rate: 4.168218252553381e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05782011902153006
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9872099648735206
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101050-5s4izhvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5s4izhvc
wandb: uploading history steps 237-253, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▇██
wandb: best/eval_avg_mil_loss █▄▃▃▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▂▂▄▇▇▇▇▇█████▇▇██████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▄▇▇▇▇▇███████▆▆▇▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▄▅▄▆▄▆▄▄▆▅▄▄▂▅▄▁█▃▆▅▅▄▃▅▄▁▂█▆▆▆▆█▄▄▆▇▅
wandb:      train/ensemble_f1 ▁▃▁▆▅▄▆▇▄█▃▇▆▅▆▅▂▆▅▆▆▅▄▃▅▄▃▂▄▄▃▅▅▃▃▅▅▅▃▅
wandb:         train/mil_loss █▃▆█▅▃▅▆▁▄▃▃▂▅▄▂▁▄▂▂▂▄▄▃▂▃▃▃▅▂▂▄▄▅▂▁▂▂▁▃
wandb:      train/policy_loss ▄▄▄▁▁▁▁▁▁▁▁▂▂▄▄▄▄▄▄▄▄▄▄▇██▇████▇▇██████▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.2066
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.9334
wandb:      eval/avg_mil_loss 0.20523
wandb:       eval/ensemble_f1 0.9334
wandb:            test/avg_f1 0.93472
wandb:      test/avg_mil_loss 0.15113
wandb:       test/ensemble_f1 0.93472
wandb:           train/avg_f1 0.92052
wandb:      train/ensemble_f1 0.92052
wandb:         train/mil_loss 0.19864
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5s4izhvc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101050-5s4izhvc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f4o9nh29 with config:
wandb: 	actor_learning_rate: 2.1438350567629495e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07849472430387339
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.517131566748403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101425-f4o9nh29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4o9nh29
wandb: uploading history steps 158-162, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆██
wandb: best/eval_avg_mil_loss █▄▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▅▆▆▆█▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▆▅▅▅▅▅▃▃▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▆▆█▆▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▄▇▃▄▅▄▆▇▆▇▅▄▅▄▂▄▅▃▆▅▄▄█▆▇▃▅▃▃▆▆▇▃▆▄▄▇▄
wandb:      train/ensemble_f1 ▃▁▄▆▅▃▅▆▇▇█▄▄▅▆▁▅▅▂▅▅▆▄▃▆▄▆▆▂▃▅▄▄▅▇▄▆▇▇▅
wandb:         train/mil_loss ▆▃▅▆▇▄▄▆█▇▁▄▆▃▇▅▆▇▅▃▅▇▄▄▅▅▅▆▄▃▅▆▄▇▅▆▃█▆▄
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▁▃▃▃█▃▁▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄█▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.24133
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.92587
wandb:      eval/avg_mil_loss 0.23238
wandb:       eval/ensemble_f1 0.92587
wandb:            test/avg_f1 0.91105
wandb:      test/avg_mil_loss 0.15967
wandb:       test/ensemble_f1 0.91105
wandb:           train/avg_f1 0.907
wandb:      train/ensemble_f1 0.907
wandb:         train/mil_loss 0.2337
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4o9nh29
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101425-f4o9nh29/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p7fzcu2v with config:
wandb: 	actor_learning_rate: 0.0001697570500267249
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9842545835326294
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09441670285787174
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101642-p7fzcu2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p7fzcu2v
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇████▇▇▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▁▃▅▂▃▂▅▃▃▄▅█▁▄▆▄▄▆▃▆▅▄▂▆▄▅▄▂▁▄▅▃▅▅█▂▃
wandb:      train/ensemble_f1 ▄▄▄▅▂▃▆▄▂▄▃▂▅▆▂█▃▁▅▃▆▄▅▃▄▅▄▅▅▇▆▁▂▄█▄▆█▄▃
wandb:         train/mil_loss ▂▄▄▄▆▃▃▃▄▅▆▃▂▆▆▃▄▄▄▃▁▅▅▆▄▃▅▄█▄▆▆▅▃▅█▅▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89149
wandb: best/eval_avg_mil_loss 0.27787
wandb:  best/eval_ensemble_f1 0.89149
wandb:            eval/avg_f1 0.89149
wandb:      eval/avg_mil_loss 0.27401
wandb:       eval/ensemble_f1 0.89149
wandb:            test/avg_f1 0.91848
wandb:      test/avg_mil_loss 0.18995
wandb:       test/ensemble_f1 0.91848
wandb:           train/avg_f1 0.88529
wandb:      train/ensemble_f1 0.88529
wandb:         train/mil_loss 0.22859
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p7fzcu2v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101642-p7fzcu2v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zkzdqudb with config:
wandb: 	actor_learning_rate: 5.029120041299253e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.859088581924273
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5031201113399584
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101816-zkzdqudb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkzdqudb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:      eval/avg_mil_loss ██▆▅▅▅▅▃▃▃▂▂▂▂▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▂▄▄▄▄▄▁▂▆▅▄▂▂▆▅▃▂▄▄▄▅▂▃▃▃▂▆▆▃▃▂█▂▆▅▄▃
wandb:      train/ensemble_f1 ▂▅▄▄▁▅▄▄▄▅▅▅▅▇▃▄▂▆▅▄▆▅▄▄▅▄▃▃▃▅▄▆▃▄▇█▅▅▆▃
wandb:         train/mil_loss ▆▄▂▂▂▄▄▂▃▅▁▃▄▃▄▃▃▅▂▄▂▁█▂▅▃▅▄▃▄▄▃▃▂▄▃▃▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▅▃▃▅▅▇▄▆▆█▆▇▄▇▇▇▇▇▇▇▂▇▆▅▆▆█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▇▆▇▇▄█▆██▄█▅▇█▇▅▆██▇██▆▃▆█▇▇▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90623
wandb: best/eval_avg_mil_loss 0.3132
wandb:  best/eval_ensemble_f1 0.90623
wandb:            eval/avg_f1 0.90623
wandb:      eval/avg_mil_loss 0.30763
wandb:       eval/ensemble_f1 0.90623
wandb:            test/avg_f1 0.90964
wandb:      test/avg_mil_loss 0.19041
wandb:       test/ensemble_f1 0.90964
wandb:           train/avg_f1 0.89108
wandb:      train/ensemble_f1 0.89108
wandb:         train/mil_loss 0.23143
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkzdqudb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101816-zkzdqudb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: awxhxr6y with config:
wandb: 	actor_learning_rate: 0.004748892548011538
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10792592740744278
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.727881716778021
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102018-awxhxr6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awxhxr6y
wandb: uploading history steps 218-219, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅▇█
wandb: best/eval_avg_mil_loss █▇▂▁▁▂
wandb:  best/eval_ensemble_f1 ▁▄▅▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▆▆▆▆▆▆▆▆▃▆▆▆▆█▆▆█▆▆█▆█▆█▆▆▆▆▆▆▆▆▆█
wandb:      eval/avg_mil_loss █▄▃▂▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▁▁▁▁▁▃▁▁▆▆▆▆▆▆▆▆▆▃▆▆▆▆▆█▆▆██▆▆▆▆▆▆██▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▅▂▃▂▃▄▄▄▄▃▆▄█▃▄▅▅▅▇██▄▆▂▅▇▄▅▆█▁▅▅▆▂▂▆
wandb:      train/ensemble_f1 ▁▄▃▄▃▂▄▄▄▄▄▃▂▅▂▂█▅▃▆▄▄▅▂▆▅▆▁▁▃▅▃▅▅▅▁▄▄▂▅
wandb:         train/mil_loss ▄▂▃▄▄▃▅▃▅▄▇▆▆▃▄▅▃▂▄▅▄▆▄▂▅▃▅█▃▁▅▂▃▃▅▂█▅▆▂
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▅▁▇▇▇▇▇▇▇▇▇▇▄▇▅▇█▇▇▇▇▇▇▇▇▇▇▇▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.25226
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.92573
wandb:      eval/avg_mil_loss 0.24671
wandb:       eval/ensemble_f1 0.92573
wandb:            test/avg_f1 0.91594
wandb:      test/avg_mil_loss 0.16894
wandb:       test/ensemble_f1 0.91594
wandb:           train/avg_f1 0.91865
wandb:      train/ensemble_f1 0.91865
wandb:         train/mil_loss 0.21204
wandb:      train/policy_loss 0.27776
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.27776
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awxhxr6y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102018-awxhxr6y/logs
wandb: Agent Starting Run: 93fhvv8n with config:
wandb: 	actor_learning_rate: 0.00017347505109204572
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9980727190162298
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6332181357548218
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102310-93fhvv8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93fhvv8n
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ▁▂▅█
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▁▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▅▄▄▄▅▅▅▅▅▅▅▅▅▆
wandb:      eval/avg_mil_loss ▄▆█▅▅▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▆████▇▄▄▅▅▅▅▅▅▅▅▄▅▅▄▄▄▄▅▅▅▅▅▄▄▅▅▅▅▅▅▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆█▅▅▆▇█▃▅▄▂▇▄▆▄▂▅▅▇▂▂▆▃▄▂▃▄▅▆▅▄▁▅▃▆▆▆▄▅
wandb:      train/ensemble_f1 ▆▆▆▅▇▅▄▄▄▇█▃▄▄▁▇██▄▂▅▅▇▇▁▇▅▆▆▆▅▃▂▇▆▆▇▃▆▃
wandb:         train/mil_loss ▂▃▁▂▂▂▂▁█▂▂▂▂▂▂▂▃▂▁▁▂▂▁▂▃▆▂▂▂▂▂▁▁▁▁▂▂▂▇▁
wandb:      train/policy_loss ▅▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.5174
wandb: best/eval_avg_mil_loss 4.21648
wandb:  best/eval_ensemble_f1 0.5174
wandb:            eval/avg_f1 0.49512
wandb:      eval/avg_mil_loss 3.92045
wandb:       eval/ensemble_f1 0.49512
wandb:            test/avg_f1 0.4781
wandb:      test/avg_mil_loss 3.92937
wandb:       test/ensemble_f1 0.4781
wandb:           train/avg_f1 0.49409
wandb:      train/ensemble_f1 0.49409
wandb:         train/mil_loss 0.20394
wandb:      train/policy_loss -0.01181
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.01181
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93fhvv8n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102310-93fhvv8n/logs
wandb: Agent Starting Run: 2t5j3zl8 with config:
wandb: 	actor_learning_rate: 1.077975385523699e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5528072596147674
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4816199791614084
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102438-2t5j3zl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2t5j3zl8
wandb: uploading history steps 216-221, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▃▃▃▃▃▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃███████████▆█▆██
wandb:      eval/avg_mil_loss ██▆▆▆▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃█████████▆▆▆███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▄▃▅▄▇▄▂▅▅▇▇▅▅▇█▇▆▆▇▅▅▄▅▄▄▇▇▁▇▃▆▅▆▄▄▄▅
wandb:      train/ensemble_f1 ▂▂▁▂▁▃▄▇▆█▅▄▄▃▅▂▄▃▃▅▃▄▂▄▄▄▇▅▄▄▄▄▇▅▅▆▅▅▄▄
wandb:         train/mil_loss ▃▅▅▅▃▃▅▄▅▄▅▃▄▅▅▂▆▂▂█▄▅▄▂▅▄▅▅▁▅▃▄▆▂▄▆▅▃▃▅
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.22512
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.92177
wandb:      eval/avg_mil_loss 0.22232
wandb:       eval/ensemble_f1 0.92177
wandb:            test/avg_f1 0.93401
wandb:      test/avg_mil_loss 0.14546
wandb:       test/ensemble_f1 0.93401
wandb:           train/avg_f1 0.91193
wandb:      train/ensemble_f1 0.91193
wandb:         train/mil_loss 0.2341
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2t5j3zl8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102438-2t5j3zl8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8u1ol45v with config:
wandb: 	actor_learning_rate: 0.0035222573473850287
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22194264597367885
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.386225047073407
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102742-8u1ol45v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8u1ol45v
wandb: uploading history steps 197-217, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▅▇██
wandb: best/eval_avg_mil_loss █▇▄▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▅▇██
wandb:            eval/avg_f1 ▂▂▂▂▂▁▁▁▁▄▄▆▆▆▆▆▆▆▇▇██▇▇▇███████████████
wandb:      eval/avg_mil_loss █▇▆▅▅▄▄▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▁▁▂▃▃▄▄▆▆▆▆▆▇▇▇▇▇▇▇████▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▂▂▂▆▄▃▅▆▆▆▅▄▄▇▇▄▅▅█▅▇▅▅▅▅▅▅▆▅▇▆▅▆▇▆▆█
wandb:      train/ensemble_f1 ▃▂▂▂▂▁▂▃▄▆▃▆▅▆▅▄▅▆▃▄▆▇▆▆▅▆▅▅▅▅▅▅▄▅▅▅▆█▄▆
wandb:         train/mil_loss ▄▅█▇▅▅▄▅▄▆▄▅▄▅▄▄▂▇▅▆▄▂▆▃▅▃▃▅▃▄▃▁▃▃▄▁▄▆▅▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▁██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.20449
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.93328
wandb:      eval/avg_mil_loss 0.2018
wandb:       eval/ensemble_f1 0.93328
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.13562
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.92702
wandb:      train/ensemble_f1 0.92702
wandb:         train/mil_loss 0.22041
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8u1ol45v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102742-8u1ol45v/logs
wandb: Agent Starting Run: 5s5qrutl with config:
wandb: 	actor_learning_rate: 0.00012916090484752757
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.91722327350302
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.565613200525006
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103033-5s5qrutl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5s5qrutl
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▄▇▅▆▁█▆▁█▆▆▅▄▇▅▄▅▆▃▆▃▅▄▇▇█▄▆▅▂▂▃▅▄▄▃▆▅
wandb:      train/ensemble_f1 ▂▄▅▆▇▆▅▂▂█▅▇█▇▇▅▅▅▇▇▄▅▄▇▄▅▅▇▃▄▄▅▃█▄▅▄▇▇▁
wandb:         train/mil_loss ▃▄▅▄▄▆▄▅▄▄▄▄▅▃▄▃▄▆▄▅▆▃▂▄▄▆▇▁▄▄▄▅▃▅▃▅▄█▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.27913
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.91394
wandb:      eval/avg_mil_loss 0.26852
wandb:       eval/ensemble_f1 0.91394
wandb:            test/avg_f1 0.92999
wandb:      test/avg_mil_loss 0.18237
wandb:       test/ensemble_f1 0.92999
wandb:           train/avg_f1 0.89482
wandb:      train/ensemble_f1 0.89482
wandb:         train/mil_loss 0.23083
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5s5qrutl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103033-5s5qrutl/logs
wandb: Agent Starting Run: yifjnl2f with config:
wandb: 	actor_learning_rate: 3.860769540694834e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6845334035190425
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32759123256800005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103200-yifjnl2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yifjnl2f
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇█▅▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▃▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:       eval/ensemble_f1 █▆▇▅▃▁▁▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▅▅▄▃▃▃▃▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▄▁▃▃▄▄▃▃▄▄▅▅▄▄▆▄▄▃▅▄▅▄▄▃▃▅▃▅▄▃▃▅▃▄▃▄▂
wandb:      train/ensemble_f1 █▆▅▄▄▄▃▂▃▄▃▂▄▂▆▄▄▃▄▄▄▃▄▃▃▂▄▄▃▄▃▃▃▃▃▄▂▃▂▁
wandb:         train/mil_loss ▂▁▂▂▃▄▆▄▂▅▅▅▃▄▄▅▄▆▂▄▃▅▃▇▄▄▄█▅▅▄▃▃▃▅▆▄▄▅▄
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90725
wandb: best/eval_avg_mil_loss 0.23066
wandb:  best/eval_ensemble_f1 0.90725
wandb:            eval/avg_f1 0.87943
wandb:      eval/avg_mil_loss 0.59859
wandb:       eval/ensemble_f1 0.87943
wandb:            test/avg_f1 0.90768
wandb:      test/avg_mil_loss 0.19946
wandb:       test/ensemble_f1 0.90768
wandb:           train/avg_f1 0.85139
wandb:      train/ensemble_f1 0.85139
wandb:         train/mil_loss 0.28791
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yifjnl2f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103200-yifjnl2f/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ynd1uh64 with config:
wandb: 	actor_learning_rate: 4.2978864550049695e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8937083370432103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35819702272861376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103333-ynd1uh64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ynd1uh64
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▆▃▆▃▃▃▃▆▆▆▆▆▆████████████████████
wandb:      eval/avg_mil_loss ██▇▅▅▅▅▅▄▅▄▄▄▅▅▅▄▄▄▄▄▄▄▄▄▃▂▂▂▂▁▁▁▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▁▁▁▁▆▃▆▃▃▆▆▆██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▃▄▅▁▇▅▇▅▇▅▇▅▅▄▇▃▅▆▂▅▅▇▆▃▅██▆▄▃▅▄▅▅▇▅▄▄
wandb:      train/ensemble_f1 ▅▄▆▁▆▅▅▇▄▅▆▆▅▂▆▂▅▅▆▆█▇▇▆▄▃▄▆▇▅▃▃█▆▅▇▅▆▇▄
wandb:         train/mil_loss ▃▄▅▆██▆▃█▆▆▄▅▅▅▅▄▆▅▃▇▅▃▄▄▇▇█▅▆▇▅▄▁▅▅█▇▅▆
wandb:      train/policy_loss ▄▄▄▄▁▄▆▄▄▄▄▄█▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▂█████▆▇▅███████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.27865
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.91394
wandb:      eval/avg_mil_loss 0.27659
wandb:       eval/ensemble_f1 0.91394
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.15447
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.89303
wandb:      train/ensemble_f1 0.89303
wandb:         train/mil_loss 0.21841
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ynd1uh64
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103333-ynd1uh64/logs
wandb: Agent Starting Run: 45ljgq66 with config:
wandb: 	actor_learning_rate: 0.0005638773005310382
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2787162217779764
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7279810969763717
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103603-45ljgq66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/45ljgq66
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▆▃▁▁▁▁▂▂▃▃▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████
wandb:      eval/avg_mil_loss █▇▇▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▆▃▁▁▃▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▁▃▄▄▄▅▄▄▄▆▆▄▅▅▅▅▆▆▅▅▅▆▆▆▅▆▆▆▆▅▅▆▅▆▆▆▅▇
wandb:      train/ensemble_f1 ▁▁▄▂▃▅▆▅▆▅▅▇▆▆▆▆▆▆▇▇▆▇▆██▇█▇▆█▇▇▇▇▇▇█▆▇█
wandb:         train/mil_loss ▆▇█▇▇▅▇▅▃▆▅▅▇▇▄▁▅▆▆▅▄▄▄▄▅▃▅▅▅▅▂▇▅▅▂▅▅▆▅▅
wandb:      train/policy_loss █▁██████▂█████████████████▂█▆███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▂▇▇▇▇▇▇▇▇▂▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.4978
wandb: best/eval_avg_mil_loss 3.891
wandb:  best/eval_ensemble_f1 0.4978
wandb:            eval/avg_f1 0.48632
wandb:      eval/avg_mil_loss 3.32717
wandb:       eval/ensemble_f1 0.48632
wandb:            test/avg_f1 0.48318
wandb:      test/avg_mil_loss 3.59384
wandb:       test/ensemble_f1 0.48318
wandb:           train/avg_f1 0.51451
wandb:      train/ensemble_f1 0.51451
wandb:         train/mil_loss 2.35526
wandb:      train/policy_loss -0.09307
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.09307
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/45ljgq66
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103603-45ljgq66/logs
wandb: Agent Starting Run: f2j8zsww with config:
wandb: 	actor_learning_rate: 1.13853612419319e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0913481111902542
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9848957271462644
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103726-f2j8zsww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2j8zsww
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▆▆▇█
wandb: best/eval_avg_mil_loss █▇▅▄▄▄▃▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▃▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇█████████████████▇
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▅▅▆▆▆▆▆▆▆▆▇▇▇████████████████████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▅▁▄▃▆▅▄▄▄▅▁▅▄▅▆▄▃▅▆▇▅▄▃▇█▂▇▇█▅▄▆▃▄▆▅▃
wandb:      train/ensemble_f1 ▂▂▁▇▃▃▂▂▄▁▆▅▇▅▃▅▄▆▂▇▆▇█▅▇▄▆▇▅▆▂▅▆▆█▃█▅▃█
wandb:         train/mil_loss ██▄▄▅▅▆▅▅▅▃▄▅▆▄▄▄▃▁▄▄▅▄▅▅▄▅▅▂▄▅▇▄▅▃▄▆▂▅▃
wandb:      train/policy_loss ▄▄▄▄▂▂▂▁▁▁▄▄▄▄▄▄▄▄▄▄▄█▇██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▇██████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94455
wandb: best/eval_avg_mil_loss 0.2033
wandb:  best/eval_ensemble_f1 0.94455
wandb:            eval/avg_f1 0.9408
wandb:      eval/avg_mil_loss 0.2022
wandb:       eval/ensemble_f1 0.9408
wandb:            test/avg_f1 0.93472
wandb:      test/avg_mil_loss 0.14114
wandb:       test/ensemble_f1 0.93472
wandb:           train/avg_f1 0.92509
wandb:      train/ensemble_f1 0.92509
wandb:         train/mil_loss 0.19554
wandb:      train/policy_loss -0.23572
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.23572
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2j8zsww
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103726-f2j8zsww/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uuj9rvo8 with config:
wandb: 	actor_learning_rate: 7.916158860613548e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5919825818429444
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.212278662261293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104047-uuj9rvo8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uuj9rvo8
wandb: uploading history steps 98-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████▆███▆▆▆▆▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▁▃▃▃▃▃▃
wandb:      eval/avg_mil_loss █▇▇▇▇▆▅▅▅▅▄▄▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▁▁▁▄▄
wandb:       eval/ensemble_f1 ████▆▆▆▆▆▆▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▅▅▅▃██▅▄▆█▇▄▅▅▆▄▃▅▂▅▄▄▆▄▂▆▆▄▄▅▁▆▅▅▅▄▄
wandb:      train/ensemble_f1 ▂▇▅▅▆▆▆▇██▆▅▅▆█▃▄▆▄▁▃▅▅▄▆▄▂▂▆▁▃▃▄▄▅▄▅▃▇▄
wandb:         train/mil_loss ▃▅▄▃▇▅▃▁▄▄▄██▃▄▄▃▅▄▅▅▅▆▆▄▅▆▅▅▆▅▆▆▄▆▃▂▅█▃
wandb:      train/policy_loss ████████████▁███████████████████▃███████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91524
wandb: best/eval_avg_mil_loss 0.25907
wandb:  best/eval_ensemble_f1 0.91524
wandb:            eval/avg_f1 0.90822
wandb:      eval/avg_mil_loss 0.25408
wandb:       eval/ensemble_f1 0.90822
wandb:            test/avg_f1 0.93076
wandb:      test/avg_mil_loss 0.16267
wandb:       test/ensemble_f1 0.93076
wandb:           train/avg_f1 0.89505
wandb:      train/ensemble_f1 0.89505
wandb:         train/mil_loss 0.21857
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uuj9rvo8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104047-uuj9rvo8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5ytqpwr1 with config:
wandb: 	actor_learning_rate: 2.5134045421179205e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9144137617186106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4780336172309867
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104229-5ytqpwr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5ytqpwr1
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▆▅▅▆▆▆▅▅▅▅▄▃▃▁▄▃▂▂▂▁▂▂▁▁▁▂▄▄▄▅▅▅▃▄▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▃▅▅█▆▄▅▅▅▆▅▆▆▅▅▅▃▆▄▄▆▅▄▅▅▄▅▅▅▅▆▄▆▄▅▄▃█
wandb:      train/ensemble_f1 ▂▂▇▅▃▅▆█▄▄▅▃▆▄▄▄▆▅▃▁▄▆▃▄▆▂▅▅▅▆▃▆▄▅▄▃█▆▆▆
wandb:         train/mil_loss ▅▄▃▄▄▄▄▄▂▅▄▄▃▅▅▃▄▁▂▅▃▄█▄▄▂▃▇▃▆▂▃▁▂▄▄▂▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.25062
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.24941
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.93026
wandb:      test/avg_mil_loss 0.1671
wandb:       test/ensemble_f1 0.93026
wandb:           train/avg_f1 0.91573
wandb:      train/ensemble_f1 0.91573
wandb:         train/mil_loss 0.23108
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5ytqpwr1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104229-5ytqpwr1/logs
wandb: Agent Starting Run: p9xm3k76 with config:
wandb: 	actor_learning_rate: 3.436181108219762e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22927413033711608
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5835261836887934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104358-p9xm3k76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9xm3k76
wandb: uploading wandb-summary.json; uploading history steps 314-333, summary
wandb: uploading history steps 314-333, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▆▆▆▆▆▆▆▄▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████▇▇▇▇▇▇▇▇███
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▇▆▅▄▄▄▄▄▃▄▄▄▃▃▂▂▂▂▂▂▁▁▃▄▃▃▃▃▃▃▃▂
wandb:       eval/ensemble_f1 ▁▁▁▂▂▃▃▃▃▃▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████████▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▂▂▁▃▃▄▃▄▄▆▅▇▅▅▆▅▆▆▇▅▅▆▅▇▇▆██▇▆▇▇▆▆▇▇▇
wandb:      train/ensemble_f1 ▁▄▃▂▃▃▄▅▅▆▆▇▆▄▅▄▅▅▆▅▆▅▆▅▅▆▇▅▇▇▆█▇█▇▅▇▇▆█
wandb:         train/mil_loss ▆▃▆█▆▆▆▆▅▆▇▄█▆▆▇▅▅▅▇▆▅▅▇▅▆▄▅█▄▄▄▄▁█▄▆▅▆▆
wandb:      train/policy_loss ▂▂▂▂▇▂▂▂▂█▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▅▂▆█▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▅▃▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54181
wandb: best/eval_avg_mil_loss 4.68004
wandb:  best/eval_ensemble_f1 0.54181
wandb:            eval/avg_f1 0.53362
wandb:      eval/avg_mil_loss 4.74743
wandb:       eval/ensemble_f1 0.53362
wandb:            test/avg_f1 0.50023
wandb:      test/avg_mil_loss 4.33562
wandb:       test/ensemble_f1 0.50023
wandb:           train/avg_f1 0.54392
wandb:      train/ensemble_f1 0.54392
wandb:         train/mil_loss 2.62096
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9xm3k76
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104358-p9xm3k76/logs
wandb: Agent Starting Run: 5x0zxalf with config:
wandb: 	actor_learning_rate: 0.003584016412545241
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05084039634212634
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04805627714218086
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104820-5x0zxalf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x0zxalf
wandb: uploading history steps 119-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆▆█
wandb: best/eval_avg_mil_loss ▁██▄▄▄
wandb:  best/eval_ensemble_f1 ▁▃▆▆▆█
wandb:            eval/avg_f1 ▁▁▆▆▃▃▆▆▆████████████████████████████▆▆▆
wandb:      eval/avg_mil_loss ▁▂▇█▇▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▆▆▆▃▃▆▆▃████████████████████████████▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▅▃▃▅▇▂▆▇▄▄▃▂▃▄▄▆▄▃▄▃▆▄▃▅▁▅▄█▆▃▄█▆▄▇▃▇▃
wandb:      train/ensemble_f1 ▃▄▄▇▄▁▆▁▃▄▃▃▄▂▇▅▅▅▂▅▅▂▃▄▃▃▃█▇▅▃▆▆▆▅▆▅▄▃▃
wandb:         train/mil_loss ▆▃▃▅▄▄▅▃▅▅▄▄▇▄▄▂▆▃▄▇▃▄▆▁▃▅▄▂▄▃▆▄▄▅▄▄█▄▃▃
wandb:      train/policy_loss ▃▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.23434
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.91845
wandb:      eval/avg_mil_loss 0.22947
wandb:       eval/ensemble_f1 0.91845
wandb:            test/avg_f1 0.91936
wandb:      test/avg_mil_loss 0.16794
wandb:       test/ensemble_f1 0.91936
wandb:           train/avg_f1 0.91458
wandb:      train/ensemble_f1 0.91458
wandb:         train/mil_loss 0.22168
wandb:      train/policy_loss 0.20034
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.20034
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x0zxalf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104820-5x0zxalf/logs
wandb: Agent Starting Run: dmvepruk with config:
wandb: 	actor_learning_rate: 5.363579597648388e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3261913451170123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.021967896538594656
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105009-dmvepruk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmvepruk
wandb: uploading history steps 293-294, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▅▅▅▄▄▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇███
wandb:      eval/avg_mil_loss ██▇▇▇▆▅▅▅▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▃▃▃▃▃▃▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▅▁▄▅▄▃▄▃▃▃▅▅▄▄▄▆▅▆▅▅▇▅▆▅▄▆▅▅▆▄▆▅▅▆▃▆█
wandb:      train/ensemble_f1 ▂▂▁▂▅▂▄▃▄▄▆▄▃▅▄▇▅▄▆▆▆▆▆▃▅▆▇▆▅▆█▅▅▅▆▄▆▅▄▆
wandb:         train/mil_loss ▅▅█▆█▄▆▇▅▅▁▄▄▄▄▅▄▄▅▄▅▅▄▃▂▂▄▄▁▅▄▂▃▃▂▄▅▃▂▂
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▁▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9216
wandb: best/eval_avg_mil_loss 0.26352
wandb:  best/eval_ensemble_f1 0.9216
wandb:            eval/avg_f1 0.9216
wandb:      eval/avg_mil_loss 0.254
wandb:       eval/ensemble_f1 0.9216
wandb:            test/avg_f1 0.92191
wandb:      test/avg_mil_loss 0.16403
wandb:       test/ensemble_f1 0.92191
wandb:           train/avg_f1 0.90755
wandb:      train/ensemble_f1 0.90755
wandb:         train/mil_loss 0.22724
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmvepruk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105009-dmvepruk/logs
wandb: Agent Starting Run: 3nsi0utl with config:
wandb: 	actor_learning_rate: 0.0032841828133791415
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18054752996792311
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4244950114671888
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105402-3nsi0utl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v91bcgas
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nsi0utl
wandb: uploading history steps 215-229, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅██████
wandb: best/eval_avg_mil_loss ██▃▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▅██████
wandb:            eval/avg_f1 ▁▁██████████████████████████████████████
wandb:      eval/avg_mil_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▃▃▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁███████████████████████████████████████
wandb:      train/ensemble_f1 ▁▁██████████████████████████████████████
wandb:         train/mil_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ████▇█▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆█▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.20283
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.93328
wandb:      eval/avg_mil_loss 0.19988
wandb:       eval/ensemble_f1 0.93328
wandb:            test/avg_f1 0.9422
wandb:      test/avg_mil_loss 0.1417
wandb:       test/ensemble_f1 0.9422
wandb:           train/avg_f1 0.92488
wandb:      train/ensemble_f1 0.92488
wandb:         train/mil_loss 0.17802
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3nsi0utl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105402-3nsi0utl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 0emkvqv1 with config:
wandb: 	actor_learning_rate: 0.0004010222689691202
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6389653992759518
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.463119288405367
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105721-0emkvqv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0emkvqv1
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 457-470, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ▇███▇▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▃▁▁▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████
wandb:      eval/avg_mil_loss ██▇▇▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▁▁▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▅▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇██▇██
wandb:      train/ensemble_f1 ▄▁▃▄▃▄▃▄▃▄▄▄▅▆▆▅▆▆▅▆▆▇▇▇▇▇▇█▇▆▇▇▇▇▇█▇▇██
wandb:         train/mil_loss █▆█▆▄▅▆▂▅▆▄▇▄▆▅▄▅▃▄▆▅▄▄▄▄▂▃▄▄▄▄▂▄▃▁▅▅▃▄▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▆█▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86844
wandb: best/eval_avg_mil_loss 0.37566
wandb:  best/eval_ensemble_f1 0.86844
wandb:            eval/avg_f1 0.86827
wandb:      eval/avg_mil_loss 0.36425
wandb:       eval/ensemble_f1 0.86827
wandb:            test/avg_f1 0.81611
wandb:      test/avg_mil_loss 0.39264
wandb:       test/ensemble_f1 0.81611
wandb:           train/avg_f1 0.86372
wandb:      train/ensemble_f1 0.86372
wandb:         train/mil_loss 0.28312
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0emkvqv1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105721-0emkvqv1/logs
wandb: Agent Starting Run: cl7h7cls with config:
wandb: 	actor_learning_rate: 1.8304632245578147e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5557291828626325
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.034074430625123275
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110339-cl7h7cls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cl7h7cls
wandb: uploading history steps 274-275, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅███▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▁▁▁▄▁█▄▆▃▄▁▂▅▃▃▃▆▃▄▂▅▇▄▂▃▃▂▇▂▅▃▄▅▆▅▅
wandb:      train/ensemble_f1 ▁▃▆▃▃▄▄▄▅▆▅▅▄▃▅▄▅▅█▅▄▅▆▅▅▆▇▅▃▄▆▄▅▇▅▅▄▃▆▆
wandb:         train/mil_loss ▄▄▅▃▄▂▄▂▂▄▄▇▂▆▄▅▆▄▄▂▂▃█▄▂▄▁▆▃▂▃▆▂▆▅▂▂▂▁▄
wandb:      train/policy_loss ▃▃▃▂▇▆▂▃▆▆▆█▇▃▆▅▄▂▃▄▅▁▂▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▂▅▅▄▄▃▆▂▆▅▆█▄▆▄▇█▄▅▇▁▅▃▆▇▆▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.31616
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.9103
wandb:      eval/avg_mil_loss 0.30481
wandb:       eval/ensemble_f1 0.9103
wandb:            test/avg_f1 0.92222
wandb:      test/avg_mil_loss 0.19618
wandb:       test/ensemble_f1 0.92222
wandb:           train/avg_f1 0.89901
wandb:      train/ensemble_f1 0.89901
wandb:         train/mil_loss 0.24268
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cl7h7cls
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110339-cl7h7cls/logs
wandb: Agent Starting Run: tg4cs4rv with config:
wandb: 	actor_learning_rate: 1.4674618443522132e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5420345237344135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02359908637453567
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110716-tg4cs4rv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tg4cs4rv
wandb: uploading history steps 781-801, summary; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▃▂▂▂▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▁▂▂▃▃▄▄▄▅▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇██
wandb:      train/ensemble_f1 ▁▁▂▂▂▂▃▃▄▃▄▄▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█
wandb:         train/mil_loss ▆█▅██▄▃▃▃▅▃▆▄▆▃▃▂▃▅▃▄▃▁▃▂▃▃▄▁▂▂▂▂▃▁▃▃▂▁▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆█▁▆▆▆▆▆▅▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79022
wandb: best/eval_avg_mil_loss 0.75452
wandb:  best/eval_ensemble_f1 0.79022
wandb:            eval/avg_f1 0.79022
wandb:      eval/avg_mil_loss 0.74384
wandb:       eval/ensemble_f1 0.79022
wandb:            test/avg_f1 0.76277
wandb:      test/avg_mil_loss 0.90005
wandb:       test/ensemble_f1 0.76277
wandb:           train/avg_f1 0.78025
wandb:      train/ensemble_f1 0.78025
wandb:         train/mil_loss 0.5194
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tg4cs4rv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110716-tg4cs4rv/logs
wandb: Agent Starting Run: dfnlz8bs with config:
wandb: 	actor_learning_rate: 5.4352319812543944e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4785239085299215
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00985054428358867
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111735-dfnlz8bs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dfnlz8bs
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▅▅▅▃▃▁▁▁▁▁▁▁▁▃▃▅▅▅▆███████▆▆▆▆▅▅▅▅▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▅▅▃▁▁▁▁▁▁▁▃▃▃▅▅██████████▆▆▆▅▅▅▅▅▅▅▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▃▁▂▄▅▅▂▄▄▂▄▄▄▄▃▃▆▆▂▅▇▅▂▆▄▅▅▆▇▆▄▄█▄▆▅▄
wandb:      train/ensemble_f1 ▁▂▂▁▃▂▃▅▃▃▂▅▂▁▅▄▇▆▅▂▅▄▅▆▅▄▄▅▅▃▄█▂▄▃▄▅▇▄▃
wandb:         train/mil_loss ▅▄█▅▇▄▅▅▇▄▄▄▄▇▂▅▄▇▅▄▄▆▇▅▃▅▅▃▃▇█▄▃▅▅█▁▄▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.37958
wandb: best/eval_avg_mil_loss 3.54945
wandb:  best/eval_ensemble_f1 0.37958
wandb:            eval/avg_f1 0.37271
wandb:      eval/avg_mil_loss 3.46529
wandb:       eval/ensemble_f1 0.37271
wandb:            test/avg_f1 0.3239
wandb:      test/avg_mil_loss 3.54602
wandb:       test/ensemble_f1 0.3239
wandb:           train/avg_f1 0.38299
wandb:      train/ensemble_f1 0.38299
wandb:         train/mil_loss 1.74987
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dfnlz8bs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111735-dfnlz8bs/logs
wandb: Agent Starting Run: l4vmkf5y with config:
wandb: 	actor_learning_rate: 0.000771307156133887
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.469150995460374
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4454064585068467
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111950-l4vmkf5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l4vmkf5y
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▆▅▅▄▃▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▂▃▃▄▄▅▇▇▇▇▇▇▇▇█████████████████████████
wandb:      eval/avg_mil_loss ██▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▃▃▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▁▁▂▂▅▁▃▂▃▃▆▄▂▂▂▇▅▆▅▄██▄▆▅▆▅▇▅▅▅▆▅▄█▆▇
wandb:      train/ensemble_f1 ▄▁▄▄▂▅▄▄▅▃▄▂▆▆▄▅▄▃▆▄▄▆▇▅▅█▅▇▅▇▄▆▄▇█▆▆▆▆▇
wandb:         train/mil_loss ▄█▆▆▇▆▃▅▄▆▄▆▅▆▄▂▃▄▅▆▃▄▃▂▅▂▇▃▃▃▁▅▃▃▆▅▃▁▆▃
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁▃███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88319
wandb: best/eval_avg_mil_loss 0.34207
wandb:  best/eval_ensemble_f1 0.88319
wandb:            eval/avg_f1 0.88319
wandb:      eval/avg_mil_loss 0.32497
wandb:       eval/ensemble_f1 0.88319
wandb:            test/avg_f1 0.85985
wandb:      test/avg_mil_loss 0.23948
wandb:       test/ensemble_f1 0.85985
wandb:           train/avg_f1 0.87547
wandb:      train/ensemble_f1 0.87547
wandb:         train/mil_loss 0.25582
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l4vmkf5y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111950-l4vmkf5y/logs
wandb: Agent Starting Run: 9d35rfu7 with config:
wandb: 	actor_learning_rate: 0.004660473452152099
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2741126318476653
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6890038414115172
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112230-9d35rfu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9d35rfu7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▇▇▇▇▇▇▇███████████
wandb: best/eval_avg_mil_loss █▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆▇▇▇▇▇▇▇███████████
wandb:            eval/avg_f1 ▁▁▂▃▃▃▃▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████▇▇▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃▄▅▂▃▄▁▄▃▂▃▃▅▃▅▅▆▄▅▅▆▅▆▆▆▆▅▄▅▇▅▆▅▆▇▇█▆
wandb:      train/ensemble_f1 ▁▆▇▇▇▇█████▇████████████████████████████
wandb:         train/mil_loss █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▂▁▁▁▁▂▁▁▁▂▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▅▅▅▆▇▇▃▃▃▃█▇▅▄▆▇▆▇▅▇▇▇▅▇▆▃▃▃▃▁▁▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89409
wandb: best/eval_avg_mil_loss 0.33079
wandb:  best/eval_ensemble_f1 0.89409
wandb:            eval/avg_f1 0.88306
wandb:      eval/avg_mil_loss 0.32082
wandb:       eval/ensemble_f1 0.88306
wandb:            test/avg_f1 0.89219
wandb:      test/avg_mil_loss 0.20984
wandb:       test/ensemble_f1 0.89219
wandb:           train/avg_f1 0.87384
wandb:      train/ensemble_f1 0.87384
wandb:         train/mil_loss 0.27493
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9d35rfu7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112230-9d35rfu7/logs
wandb: Agent Starting Run: yevi5pjy with config:
wandb: 	actor_learning_rate: 0.00010347824681447276
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.013254647913894411
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6786661241036376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112713-yevi5pjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yevi5pjy
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▆▆▆▅▅▄▅▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▂▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████
wandb:      eval/avg_mil_loss ██▇▇▆▆▅▅▅▄▄▃▃▃▂▃▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▃▃▃▄▄▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▅▆▆▆▇▆▇▆▇▆▇▆█▆▇▇▇
wandb:      train/ensemble_f1 ▁▁▂▂▂▃▃▄▄▃▄▄▄▅▅▅▆▅▅▅▆▆▆▆▇▆▆▆▇█▆▆▇██▆██▇█
wandb:         train/mil_loss ██▆█▆▅▆▆▅▆▃▆▂▆▆▄▄▄▄▆▂▃▅▄▂▃▅▃▅▃▃▄▃▄▅▃▄▅▃▁
wandb:      train/policy_loss ▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆███▃▃█▆▆▃▄▆▆▆▆▁▂▁▃▃▃▃▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅█▅██▅▅▅▅▅▅▅▅▅██████▁█▅▅▅▅▅▅▅▁▁▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49209
wandb: best/eval_avg_mil_loss 3.08118
wandb:  best/eval_ensemble_f1 0.49209
wandb:            eval/avg_f1 0.48632
wandb:      eval/avg_mil_loss 3.03694
wandb:       eval/ensemble_f1 0.48632
wandb:            test/avg_f1 0.41401
wandb:      test/avg_mil_loss 2.9193
wandb:       test/ensemble_f1 0.41401
wandb:           train/avg_f1 0.48286
wandb:      train/ensemble_f1 0.48286
wandb:         train/mil_loss 2.73915
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yevi5pjy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112713-yevi5pjy/logs
wandb: Agent Starting Run: 4lz3cmfe with config:
wandb: 	actor_learning_rate: 0.0001583576692472315
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3418596812085185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35939063468067567
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113727-4lz3cmfe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lz3cmfe
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████████▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████████████████████████████▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▂▄▂▂▃▃▅▃▂▃▂▂▄▆▂▃▂▃▅▅▃▆▄▄▄▆▂▅▃▅▄█▆▅▆▄▄
wandb:      train/ensemble_f1 ▃▁▄▁▇▁▅▂▂▆▂▄▅▄▄▃▆▂▅█▂▇▄▃▄▆▆▂█▅▅▄▆▇▆▆▇▇▅▆
wandb:         train/mil_loss ▅▅▆▄▃▂▅█▄▅▄▆▄▄▅▂▄▃▅▅▃▃▄▄▃▂▁▄▄▄▃▄▄▄▃▆▃▃▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.39293
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.34115
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.23553
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.89871
wandb:      train/ensemble_f1 0.89871
wandb:         train/mil_loss 0.28062
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lz3cmfe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113727-4lz3cmfe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: noqrc3ob with config:
wandb: 	actor_learning_rate: 3.3207402920229945e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2356820150240463
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5022766570681657
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113928-noqrc3ob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/noqrc3ob
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▅▄▄▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▄▅▅▅▆▆▆▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▄▃▄▅▄▃▄▅▇▅▆▅▆▅▄▆█▆▆▅▇▆▇▅▆▆▇▇▆▆▆█▆▇▇▇
wandb:      train/ensemble_f1 ▂▁▂▃▂▂▃▄▂▄▆▅▇▅▅▇▅▅▇▆▆▆█▇▇▆▇▇▆▇▆▇▇█▇▆▆▇██
wandb:         train/mil_loss ▅▇█▂▄▄▄▆▄▅▃▂▃▃▁▅▄▃▁▄▅▃▃▅▂▃▃▄▄▂▁▁▂▂▂▃▅▄▂▃
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90363
wandb: best/eval_avg_mil_loss 0.32155
wandb:  best/eval_ensemble_f1 0.90363
wandb:            eval/avg_f1 0.89983
wandb:      eval/avg_mil_loss 0.3133
wandb:       eval/ensemble_f1 0.89983
wandb:            test/avg_f1 0.9083
wandb:      test/avg_mil_loss 0.20297
wandb:       test/ensemble_f1 0.9083
wandb:           train/avg_f1 0.8994
wandb:      train/ensemble_f1 0.8994
wandb:         train/mil_loss 0.25662
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/noqrc3ob
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113928-noqrc3ob/logs
wandb: Agent Starting Run: m821y51b with config:
wandb: 	actor_learning_rate: 0.00016254414473784043
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4798191703210224
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11609300824041267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114516-m821y51b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m821y51b
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▃▃▃▄▄▄▅▅▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▇▇▆▆▆▆▄▄▃▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▃▃▃▄▄▄▅▅▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▂▂▃▃▃▃▃▄▄▄▄▄▅▆▇▇▇▇▇▇▇▇▇▇██████████████
wandb:      eval/avg_mil_loss ███▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▁▂▁▂▂▂▃▃▄▃▃▃▃▄▄▅▅▅▄▅▆▆▅▇▅▆▇▇▆▆▆▇█▇▇▇█
wandb:      train/ensemble_f1 ▃▂▁▂▂▃▂▂▁▃▃▃▃▄▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇█▇▆▇▇▆█▇█
wandb:         train/mil_loss ▇▆▅▆█▃▇▆▇▃▅▅▅▄▃▆▄▃▄▅▃▄▃▄▂▃▄▃▃▃▅▁▄▂▅▂▁▂▁▄
wandb:      train/policy_loss ▆▆▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87591
wandb: best/eval_avg_mil_loss 0.31162
wandb:  best/eval_ensemble_f1 0.87591
wandb:            eval/avg_f1 0.86859
wandb:      eval/avg_mil_loss 0.31458
wandb:       eval/ensemble_f1 0.86859
wandb:            test/avg_f1 0.87321
wandb:      test/avg_mil_loss 0.22196
wandb:       test/ensemble_f1 0.87321
wandb:           train/avg_f1 0.87516
wandb:      train/ensemble_f1 0.87516
wandb:         train/mil_loss 0.27165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m821y51b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114516-m821y51b/logs
wandb: Agent Starting Run: e61bkzv7 with config:
wandb: 	actor_learning_rate: 2.5305296148831335e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4965284023402319
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2674937997483281
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115316-e61bkzv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e61bkzv7
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▂▂▁▂▁▂▅▂▂▄▃▃▂▅▆▃▄▂▂▃▂▄▃▄▃▄▆▄▄█▃▃▅▅▂▄▂
wandb:      train/ensemble_f1 ▅▄▄▁▄▆▅▃▃▆▁▄▃▇█▄▅▇▃▄▄▅▄▆▄▅▄▆▆▅▅▆▆▄▄▄███▆
wandb:         train/mil_loss ▅▄▄▅▇▆▃▄▇▅▄▅▆▄▆▃▄▅▄▆▅▂▄▆▅▅▂▃▆▅▃▃▂▇▇▁▄█▆▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90236
wandb: best/eval_avg_mil_loss 0.37279
wandb:  best/eval_ensemble_f1 0.90236
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.32967
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.23161
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.9027
wandb:      train/ensemble_f1 0.9027
wandb:         train/mil_loss 0.29923
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e61bkzv7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115316-e61bkzv7/logs
wandb: Agent Starting Run: lpt6v3on with config:
wandb: 	actor_learning_rate: 0.0021128959275052723
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10066841663040292
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7526354221188576
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115439-lpt6v3on
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lpt6v3on
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▄▃▆▆▇▆▁▁▁▂▂▁▂▁▁▁▂▁▁▂▃▃▄▄▄▅▅▅▄▅▅▅▅▅▆▇▇▇▇
wandb:      eval/avg_mil_loss ▁▅▆▆▅▅▅▇▇████▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄
wandb:       eval/ensemble_f1 █▅▃▂▂▄▅▅▁▁▁▁▂▁▁▁▁▁▁▂▂▂▃▃▄▄▃▄▄▄▄▄▄▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▆▅▄▅▃▁▂▁▃▂▁▂▂▂▂▃▄▄▄▄▃▃▄▅▄▅▄▃▄▅▄▅▄▄▅▅▅▅
wandb:      train/ensemble_f1 █▅▃▃▄▄▃▁▂▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▂▃▃▄▃▄▄▃▄▄▄▄▄▄▄
wandb:         train/mil_loss ▃▃▆▁▅▃▅█▆▆▆▇█▆▇▆█▄▆▅▇▇▆▅▃▄▅▆▅▆▁▅▃▃▆▅▃▆▅▄
wandb:      train/policy_loss ▄▅▅▅▅▅▆▅▅▅▅▅▆▁▅▅▅▅▂▅▄▂▅▄▁█▅▅▅▇▅▅▂▅▃▁▃▅▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▆▁▆▄▄▆▆█▄▅▆▆▆▆▆█▅█▆▅▃▆▄▆▆█▇▆▆▁▆▆▄▇▄▆▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88992
wandb: best/eval_avg_mil_loss 0.30087
wandb:  best/eval_ensemble_f1 0.88992
wandb:            eval/avg_f1 0.85012
wandb:      eval/avg_mil_loss 0.34579
wandb:       eval/ensemble_f1 0.85012
wandb:            test/avg_f1 0.87622
wandb:      test/avg_mil_loss 0.2933
wandb:       test/ensemble_f1 0.87622
wandb:           train/avg_f1 0.84883
wandb:      train/ensemble_f1 0.84883
wandb:         train/mil_loss 0.3595
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lpt6v3on
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115439-lpt6v3on/logs
wandb: Agent Starting Run: gw6wpjin with config:
wandb: 	actor_learning_rate: 0.004662524210515409
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.112776999320773
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31616235769536527
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115602-gw6wpjin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gw6wpjin
wandb: uploading history steps 462-477, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ▁█▇▇▇▆▅▅▅▅▃▃
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▄▄▄▄▄▃▅▅▆▆▆▆▇▆▅▅▅▅▆▆▆▆▇▇▇▇█▇▇▇▇▇▆▇▇▇
wandb:      eval/avg_mil_loss ▁██▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▅▅▅▅▄▃▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▂▃▃▅▃▃▅▄▄▅▄▅▆▅▆▅▅▇█▆▇▆▇▇▇▆▇▆▆▇▇▇▇▆█▇▇
wandb:      train/ensemble_f1 ▃▂▃▃▁▂▂▄▃▃▃▄▄▄▃▄▄▅▄▅▅▅▅▆▅▅▆▆▆▆▇▆▆▇▇▆█▆▆▇
wandb:         train/mil_loss ▂▆▆█▄█▃█▅▇▆▇▁▄▅▃▆▄▃▆▆▇▂▅▅▄▆▆▂▅▄▇▂▄▅▆▂▃▆▃
wandb:      train/policy_loss █████████████████████▁██████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁█████████████▆████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.44816
wandb: best/eval_avg_mil_loss 2.96013
wandb:  best/eval_ensemble_f1 0.44816
wandb:            eval/avg_f1 0.44204
wandb:      eval/avg_mil_loss 2.88922
wandb:       eval/ensemble_f1 0.44204
wandb:            test/avg_f1 0.39945
wandb:      test/avg_mil_loss 2.69108
wandb:       test/ensemble_f1 0.39945
wandb:           train/avg_f1 0.46954
wandb:      train/ensemble_f1 0.46954
wandb:         train/mil_loss 2.13401
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gw6wpjin
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115602-gw6wpjin/logs
wandb: Agent Starting Run: dautrqvz with config:
wandb: 	actor_learning_rate: 0.0010830182745692003
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5284339958140649
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8965377230294155
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120218-dautrqvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dautrqvz
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▃▇▁▆▅▅▅▄▆▅▅▄▃▄▇▅▃▆▆▄▅▅▆▆▅▇▆▅█▇▇▅▆▄▆▇▆▆
wandb:      train/ensemble_f1 ▇▆▂▅▅▃▆▆▄▄▂▇▂▅▃▇▁▆▃▇▅▅▃▄▄▆▇▇▅▄██▆▇▅▅▅▃▅▃
wandb:         train/mil_loss ▄▄▃▄▅▆▃▄▄▅▃▄▂▅█▄▄▁▁▆▆▆▂▃▁▇▅▄▄▅▄▂▂▆▄▃▂▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.37951
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.3381
wandb:       eval/ensemble_f1 0.90599
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.22926
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.89826
wandb:      train/ensemble_f1 0.89826
wandb:         train/mil_loss 0.26373
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dautrqvz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120218-dautrqvz/logs
wandb: Agent Starting Run: b0gca8dg with config:
wandb: 	actor_learning_rate: 5.821257009362428e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1161177568524866
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6173971299514236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120341-b0gca8dg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b0gca8dg
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▂▂▅▅▅▅▅▅▅▅▅▅▅████████▅▅▅▁▁▁▁▁▁▁▁▄▇▇▇▇
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ████▅▅▁▁▁▁▅▅▅▅▅▅▅▅▅▅█████▄▄▁▁▁▁▁▁▁▁▁▁▁▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▄▅▂▅▂▁▆▆▇▄▃▅▄▆▄▆▆▆▄▄▂▆▃▆▅▄▅▆▇▆▇█▃▆▇▃▃
wandb:      train/ensemble_f1 ▃▄▅▁▅▇▆▂▃▂▇▁▃▇▄▅▃▆▅▆▆▅▄▂▄▅▆▄▃▅▇█▇█▇▆▇▄▃▃
wandb:         train/mil_loss █▅▄▂▃▄▅▄▆▅▅▄▂▅▆▂▂▅▄▃▅▂▁▅▃▅▃▃▃▅▁▃▂▂▂▂▄▅▄▄
wandb:      train/policy_loss ▂▂▂▂█▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89657
wandb: best/eval_avg_mil_loss 0.2996
wandb:  best/eval_ensemble_f1 0.89657
wandb:            eval/avg_f1 0.89581
wandb:      eval/avg_mil_loss 0.28832
wandb:       eval/ensemble_f1 0.89581
wandb:            test/avg_f1 0.90156
wandb:      test/avg_mil_loss 0.26699
wandb:       test/ensemble_f1 0.90156
wandb:           train/avg_f1 0.89887
wandb:      train/ensemble_f1 0.89887
wandb:         train/mil_loss 0.26021
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b0gca8dg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120341-b0gca8dg/logs
wandb: Agent Starting Run: vg5ubn3r with config:
wandb: 	actor_learning_rate: 1.79046902907292e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2248550672942664
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5786645203623437
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120507-vg5ubn3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vg5ubn3r
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 178-195, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇████
wandb:            eval/avg_f1 ▁▂▂▂▃▄▄▅▅▇▇▇▇▇▇██████▇▇████▇▇▇▇▇▇▆▆▆▆▆▆▅
wandb:      eval/avg_mil_loss ███▇▆▆▆▆▅▅▅▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▂▅▅▅▅▅▅▆▆▇▇█████████▇▇▇██▇▇▇▇▇▇▇▇▆▇▇▇▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▃▂▃▄▂▃▆▅▆▆▅▅▆▆▇▇▇▇▆▇▆▇█▇▇▆▇▆▆█▆▆▆▆▅▅
wandb:      train/ensemble_f1 ▁▁▁▁▂▃▄▄▃▄▅▄▅▄▅▆▆▆▆▇▅█▆▇▇▇▇▅▇▇█▇███▆▇▇▇▅
wandb:         train/mil_loss █▅▇▇▇▆▄▃▄▃▃▃▄▃▂▄▃▃▃▃▃▂▂▂▁▁▃▁▂▁▁▂▂▁▂▂▂▂▁▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▂▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▅██████████████▁████▄███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80875
wandb: best/eval_avg_mil_loss 0.47153
wandb:  best/eval_ensemble_f1 0.80875
wandb:            eval/avg_f1 0.76134
wandb:      eval/avg_mil_loss 0.58568
wandb:       eval/ensemble_f1 0.76134
wandb:            test/avg_f1 0.78828
wandb:      test/avg_mil_loss 0.59693
wandb:       test/ensemble_f1 0.78828
wandb:           train/avg_f1 0.76783
wandb:      train/ensemble_f1 0.76783
wandb:         train/mil_loss 0.543
wandb:      train/policy_loss 0.01325
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.01325
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vg5ubn3r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120507-vg5ubn3r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: aevg3u2n with config:
wandb: 	actor_learning_rate: 3.071957514310437e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1890262737058368
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3602299647366549
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120809-aevg3u2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aevg3u2n
wandb: uploading history steps 99-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▁▄▄▄█████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▇▆▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁█▇▇▇▇███▇▇▇▇
wandb:       eval/ensemble_f1 ▂▁▁█████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▃▄▄▅▄▂▃▃▄▄▄▇▅▃▅▄▅▃▁▄▄▅▅▄▃▃▅█▃▄▄▂▄▆▅▆▆▅
wandb:      train/ensemble_f1 ▅▁▃▆▄▃▅▁▃▅▄▃▇▃▅▃▄▆▅▇▄▆▆▇▆▄▄▃▅▃▅▇▅▅▇▃█▅▆▃
wandb:         train/mil_loss ▇▃▅█▃▃▄▅▁▅▅▄▄▄▄▂▆▆▂▇▆▃▃▃▇▆▄▃▄▂▂▂▃▄▄▂▂▃▆▄
wandb:      train/policy_loss ██▁████████████████▅████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90344
wandb: best/eval_avg_mil_loss 0.27626
wandb:  best/eval_ensemble_f1 0.90344
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.27948
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.91963
wandb:      test/avg_mil_loss 0.23219
wandb:       test/ensemble_f1 0.91963
wandb:           train/avg_f1 0.91223
wandb:      train/ensemble_f1 0.91223
wandb:         train/mil_loss 0.25863
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aevg3u2n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120809-aevg3u2n/logs
wandb: Agent Starting Run: 4jhl1e8b with config:
wandb: 	actor_learning_rate: 0.008683590301773283
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09900472226012191
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09557868058520846
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120943-4jhl1e8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4jhl1e8b
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▆▆▇▇▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▂▁▁▁▂▃▄▆▇██████████████████████████████
wandb:       eval/ensemble_f1 ▇▇▇██▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▆▆▇▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁
wandb:         train/mil_loss ▁▁▁▁▁▂▄▄▇▇█▇▆█▇▇▇▇▇█▇██▇█▇▇▇▇█▆▆▆▇▇█▇█▆▇
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▇▂███████████████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89897
wandb: best/eval_avg_mil_loss 0.27803
wandb:  best/eval_ensemble_f1 0.89897
wandb:            eval/avg_f1 0.35876
wandb:      eval/avg_mil_loss 3.63746
wandb:       eval/ensemble_f1 0.35876
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.17911
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.36187
wandb:      train/ensemble_f1 0.36187
wandb:         train/mil_loss 2.82664
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4jhl1e8b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120943-4jhl1e8b/logs
wandb: Agent Starting Run: 43vc9p8k with config:
wandb: 	actor_learning_rate: 2.3808552717964157e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.779283101195258
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.974950812355876
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121106-43vc9p8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/43vc9p8k
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▇▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▅▅▆██████████▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █████▇▇▇▇███████▇▇▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▃▃▅▆▆▆▆████████████▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▅▄▂▂▅▅▃▂▂▄▃▃▂▄▄▆▆▂▆▇▇▅█▅▃▄▆▅▆▄▄▆▆██▅▃▅
wandb:      train/ensemble_f1 ▁▄▄▄▃▁▅▃▆▅▅▆▃▃▄▆▅▇▅▆▅▅▅▆▆██▅▄▅▆▇▇▄█▆▇▅▅▆
wandb:         train/mil_loss ▄█▄▅▂▆▁▆▄▂▃▅▇▄▅█▆▇▄▅▆▃▃▅▅▄▄▇▆▇▃█▃▇▄▄▃▄▇▃
wandb:      train/policy_loss ▂▄▄▄▃▂▄▁▂▃▄▄▃▁▃▁▃▃▃▄█▄▆▅▅▅▅▅▅▅▅▅▅▂▂▄▂▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▃▂▂▄▂▄▄▃▂▄▃▂▄▃▃█▇▄▅▅▅▅▅▅▅▅▅▅▅▃▂▃▂▃▃▁▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59364
wandb: best/eval_avg_mil_loss 1.73862
wandb:  best/eval_ensemble_f1 0.59364
wandb:            eval/avg_f1 0.59057
wandb:      eval/avg_mil_loss 1.70161
wandb:       eval/ensemble_f1 0.59057
wandb:            test/avg_f1 0.52905
wandb:      test/avg_mil_loss 1.91844
wandb:       test/ensemble_f1 0.52905
wandb:           train/avg_f1 0.61358
wandb:      train/ensemble_f1 0.61358
wandb:         train/mil_loss 0.52682
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/43vc9p8k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121106-43vc9p8k/logs
wandb: Agent Starting Run: g0an928r with config:
wandb: 	actor_learning_rate: 0.0035210318926398483
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.00271364434320931
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12045993067497374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121406-g0an928r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0an928r
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▅▆▇▇███████████████████████████████████
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▁▂▁▁▂▂▁▂▁▁▁▂▂
wandb:      train/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▁▂▁▁▁▂▂▁▁▁▁▂▁
wandb:         train/mil_loss ▁▂▅▆▆▇█████▇██▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇██▇██▇▇█▇
wandb:      train/policy_loss ▆████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████▁█████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84964
wandb: best/eval_avg_mil_loss 0.4081
wandb:  best/eval_ensemble_f1 0.84964
wandb:            eval/avg_f1 0.37958
wandb:      eval/avg_mil_loss 3.60256
wandb:       eval/ensemble_f1 0.37958
wandb:            test/avg_f1 0.8369
wandb:      test/avg_mil_loss 0.34611
wandb:       test/ensemble_f1 0.8369
wandb:           train/avg_f1 0.37264
wandb:      train/ensemble_f1 0.37264
wandb:         train/mil_loss 3.30778
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0an928r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121406-g0an928r/logs
wandb: Agent Starting Run: f2xk8f1c with config:
wandb: 	actor_learning_rate: 0.009432994793891003
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2105988850387257
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04959012918388373
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121530-f2xk8f1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2xk8f1c
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 99-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▁▁█████████████████████████████████████
wandb:      eval/avg_mil_loss ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁███████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁███████████████████████████████████████
wandb:      train/ensemble_f1 ▁▁██████████████████████████████████████
wandb:         train/mil_loss ▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91009
wandb: best/eval_avg_mil_loss 0.35076
wandb:  best/eval_ensemble_f1 0.91009
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.31178
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.22434
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.90543
wandb:      train/ensemble_f1 0.90543
wandb:         train/mil_loss 0.29719
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2xk8f1c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121530-f2xk8f1c/logs
wandb: Agent Starting Run: isqlb4q7 with config:
wandb: 	actor_learning_rate: 7.540293265478255e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.665299329640653
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6108953146802516
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121657-isqlb4q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/isqlb4q7
wandb: uploading history steps 236-240, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ██▇▆▅▅▅▄▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▂▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▂▂▃▃▃▃▃▅▅▆▇▇▇▇▇▇██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▅▂▁▃▂▃▅▅▆▃▅▂▇▃▅▆▄▄▃▄▅▅▅▄▄▄▇▃▅▆▆▅▆█▅▆▅
wandb:      train/ensemble_f1 ▅▁▂▄▅▄▂▂▄▄▃▅▅▆▄▂▄▇▆▇▆▇▄▅▄▅▄▄▄▄▄▄▅▅█▇▅▆▇▆
wandb:         train/mil_loss ▄█▆▄▇▇▇▃▂▄▅▅▅▃▆▅▆▄▅▁▂▃▁▅▃▃▁▇▂▄▃▃▄▃▃▄▄▅▄▅
wandb:      train/policy_loss ▇▇▁▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁████████████████████████▆█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88319
wandb: best/eval_avg_mil_loss 0.34637
wandb:  best/eval_ensemble_f1 0.88319
wandb:            eval/avg_f1 0.88319
wandb:      eval/avg_mil_loss 0.3337
wandb:       eval/ensemble_f1 0.88319
wandb:            test/avg_f1 0.85985
wandb:      test/avg_mil_loss 0.23708
wandb:       test/ensemble_f1 0.85985
wandb:           train/avg_f1 0.87189
wandb:      train/ensemble_f1 0.87189
wandb:         train/mil_loss 0.26003
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/isqlb4q7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121657-isqlb4q7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6vkxyugz with config:
wandb: 	actor_learning_rate: 5.649031469423299e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7921764825511826
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9764802115225538
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122016-6vkxyugz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6vkxyugz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁███████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▁▅▇▇███████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁█████████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄█▂▃▅▂▁▅▄▅▅▅▅▆▃▄▅▄▄▆▄▄▆▃▆▆▅▆▄▄▅▃▃▅▆▇▇▅
wandb:      train/ensemble_f1 ▅▃▇█▄▂▄▂▄▃▃▁▁▂▇▅▆▃▂▅▅▆▃▃▄▄▂▁▃▇▄▇▄▅▇▃▄▃▃▂
wandb:         train/mil_loss ▄▂▅▄▂▆▁▂▆▄▄▁▇▂▂▃▂▄▃▄▂▄▃▃▂▅▄█▃▃▆▄▅▇▁▃▂▂▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89657
wandb: best/eval_avg_mil_loss 0.28098
wandb:  best/eval_ensemble_f1 0.89657
wandb:            eval/avg_f1 0.89279
wandb:      eval/avg_mil_loss 0.28993
wandb:       eval/ensemble_f1 0.89279
wandb:            test/avg_f1 0.90887
wandb:      test/avg_mil_loss 0.2281
wandb:       test/ensemble_f1 0.90887
wandb:           train/avg_f1 0.89607
wandb:      train/ensemble_f1 0.89607
wandb:         train/mil_loss 0.24795
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6vkxyugz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122016-6vkxyugz/logs
wandb: Agent Starting Run: 3v5jlubt with config:
wandb: 	actor_learning_rate: 0.00046110060038228706
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8716483245213831
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5652051497125974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122144-3v5jlubt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3v5jlubt
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▃▄▃▆▆▅▆▇▇▄▄█▄▇▆▄▆▇▄▆▄▄▇▃▅▄▆▃▆▆▅▇▃▅▁▇▅
wandb:      train/ensemble_f1 ▅▃▃▄▅▅▆▅▅▇▄▃█▁▄▅▅▆▇█▃▆▆▄▇▅▃▆▅▄▄▃▅▃▄▇▅▂▄▆
wandb:         train/mil_loss ▅▆█▃▅▄▁▆▂▄▃▃▄▄▄▃▅▄▂▆▄▃▃▄▄▅▅▅▆▆▂▆▄▅▅▆▄▃▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90236
wandb: best/eval_avg_mil_loss 0.37275
wandb:  best/eval_ensemble_f1 0.90236
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.35283
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.2317
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.88954
wandb:      train/ensemble_f1 0.88954
wandb:         train/mil_loss 0.24014
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3v5jlubt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122144-3v5jlubt/logs
wandb: Agent Starting Run: 5yx1e9hl with config:
wandb: 	actor_learning_rate: 1.5284063620832623e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5641321688905435
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9907216067087814
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122307-5yx1e9hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5yx1e9hl
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ████▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇████████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▄▄▅▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██████████████
wandb:      train/ensemble_f1 ▁▂▂▃▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇█████████████
wandb:         train/mil_loss ▅▅▅▆▇▃▅▅▇▄▇▅▁▅▅▃▃▃▄▄▄▃█▃▄▂▂▄▅▃▄▃▂▃▂▂▅▃▃▃
wandb:      train/policy_loss ▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅█▅▅▅▅▅▅▄▇▅▅▅▁▅▅▅▇▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87838
wandb: best/eval_avg_mil_loss 0.34667
wandb:  best/eval_ensemble_f1 0.87838
wandb:            eval/avg_f1 0.87101
wandb:      eval/avg_mil_loss 0.33818
wandb:       eval/ensemble_f1 0.87101
wandb:            test/avg_f1 0.87982
wandb:      test/avg_mil_loss 0.3146
wandb:       test/ensemble_f1 0.87982
wandb:           train/avg_f1 0.88704
wandb:      train/ensemble_f1 0.88704
wandb:         train/mil_loss 0.27878
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5yx1e9hl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122307-5yx1e9hl/logs
wandb: Agent Starting Run: 603vs9xr with config:
wandb: 	actor_learning_rate: 0.00029128880477663943
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.33768850740637957
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8751016205822936
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122949-603vs9xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/603vs9xr
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▆▅▄▃▃▁▁▁▁▂▃▃▃▃▃▄▄▄▅▅▅▄▄▄▄▃▃▂▂▂▄▃▅▆▆
wandb:      eval/avg_mil_loss ▁▁▁▁▂▃▆▇██████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ███▇▆▅▃▁▁▁▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▄▄▄▃▃▃▂▂▂▃▃▃▄▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▄▅▆▄▅▁▄▃▃▅▁▄▆▄▄▆▆▇█▅▄▄▅▅▅▆▅▆▂▆▆██▇▆▇▃▅
wandb:      train/ensemble_f1 ▄▄▂▆▆▄▄▄▄▃▁▅▁▆▁▄▄▇▅▅▅▄▄▂▅▄▅▆▇▄▅▆▆▃█▆█▅▆▅
wandb:         train/mil_loss ▅▁▁▂▄▅▆▆▅▅▅▃▃▂▃▄▃▆▃▃▄▃▄▄▂▅▄█▃▄▃▃▁▂▃▄▃▄▂▁
wandb:      train/policy_loss ▄▄▄█▄▄▄▄▄▆▄▄▄▄▄▁▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▄▂▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃█▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90799
wandb: best/eval_avg_mil_loss 0.24195
wandb:  best/eval_ensemble_f1 0.90799
wandb:            eval/avg_f1 0.90001
wandb:      eval/avg_mil_loss 0.27728
wandb:       eval/ensemble_f1 0.90001
wandb:            test/avg_f1 0.89036
wandb:      test/avg_mil_loss 0.22548
wandb:       test/ensemble_f1 0.89036
wandb:           train/avg_f1 0.90037
wandb:      train/ensemble_f1 0.90037
wandb:         train/mil_loss 0.22476
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/603vs9xr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122949-603vs9xr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2s95v6nl with config:
wandb: 	actor_learning_rate: 0.00017619530765900892
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3044122282715971
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1503929850942849
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_123121-2s95v6nl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s95v6nl
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ███▆▅▅▁▁▁▃▂
wandb:  best/eval_ensemble_f1 ▁▂▂▄▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██▇▇▇█▇▇▆▆▇▇▆█
wandb:      eval/avg_mil_loss █▆▅▅▅▄▄▅▄▄▃▃▃▂▂▂▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁
wandb:       eval/ensemble_f1 ▁▃▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▆▇▇▇▇▆▆▆▆██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▄▇▇▆▅▆▆▇▇▆▆▆▇▅▅▆▅▆▆▆▆▇▆▇▅▆▅▆▅▅▇▇▇▆█▇
wandb:      train/ensemble_f1 ▁▂▄▅▅▅▇▆▆▄▆▆▇▅▇▆▅▆▆▄▆▅▆▆▅▅▄▅▇▄▅▅▆▆▆▆▅▇█▆
wandb:         train/mil_loss ▆▃▁▆▅▃▇▆▁▆▅▂▄▅▅▅▃▄▆▅▄▅▃▃▅▄▅█▅▇▅▄▇▅▇▆▄▇▇▃
wandb:      train/policy_loss ▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▁▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████████▁████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45671
wandb: best/eval_avg_mil_loss 1.4918
wandb:  best/eval_ensemble_f1 0.45671
wandb:            eval/avg_f1 0.45422
wandb:      eval/avg_mil_loss 1.44619
wandb:       eval/ensemble_f1 0.45422
wandb:            test/avg_f1 0.37595
wandb:      test/avg_mil_loss 1.40289
wandb:       test/ensemble_f1 0.37595
wandb:           train/avg_f1 0.4516
wandb:      train/ensemble_f1 0.4516
wandb:         train/mil_loss 0.82256
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s95v6nl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_123121-2s95v6nl/logs
wandb: Agent Starting Run: jr0faxt1 with config:
wandb: 	actor_learning_rate: 3.207694650449864e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11054685160529808
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.650064379023176
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_123437-jr0faxt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jr0faxt1
wandb: uploading history steps 335-338, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▅███
wandb: best/eval_avg_mil_loss █▆▄▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▄▅███
wandb:            eval/avg_f1 ▃▃▃▃▃▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆█████▆▆▆▆▆▆▆██████▆▆
wandb:      eval/avg_mil_loss █▇▆▆▆▆▆▆▆▆▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▁▁▃▃▅▃▃▃▃▆▆█████████▆▆▆▆▆▆▆██████▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▃▃▁▂▃▃▅▄▄▅▃▆▅▄▄▅▅▅▅▅▄▅▄▅▇▅▄▆▇▆▄▄▆█▆▆
wandb:      train/ensemble_f1 ▂▃▃▁▂▄▃▄▃▄▅▅▄▄▆▄▅▆▅▆▅▆▅▅▅▇█▇▄▄▆▆▅▇▇▇█▅█▆
wandb:         train/mil_loss ██▅▆▅▇▃▅▆▄▆▅▄▄▄▄▅▄▄▃▂▃▃▂▄▂▃▃▂▁▃▂▁▁▃▁▂▄▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9145
wandb: best/eval_avg_mil_loss 0.23555
wandb:  best/eval_ensemble_f1 0.9145
wandb:            eval/avg_f1 0.91087
wandb:      eval/avg_mil_loss 0.22665
wandb:       eval/ensemble_f1 0.91087
wandb:            test/avg_f1 0.93401
wandb:      test/avg_mil_loss 0.15458
wandb:       test/ensemble_f1 0.93401
wandb:           train/avg_f1 0.91711
wandb:      train/ensemble_f1 0.91711
wandb:         train/mil_loss 0.23178
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jr0faxt1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_123437-jr0faxt1/logs
wandb: Agent Starting Run: ewdl5hh0 with config:
wandb: 	actor_learning_rate: 0.00012357892696988963
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17764861739637572
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7789415655262469
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_123900-ewdl5hh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewdl5hh0
wandb: uploading history steps 197-202, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▅▄▄▄▂▁▁▁▁▁▂▂▂▄▄▄▄▄▅▅▅▅▅▇████████████████
wandb:      eval/avg_mil_loss ▇▇██▇█████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁
wandb:       eval/ensemble_f1 ▄▂▁▁▁▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▇███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃▅▅▅▅▅▆▄▆▅▅▄▆▆▆▅▇▅▇▅▅▅▄▅▅▆▆▆▄▆▇▇▆▆▅▁▆█
wandb:      train/ensemble_f1 ▄▂▅▃▆▄▁▄▆█▅▂▄▄▄▇▅▇█▂▆█▆▆▅▃▄▃▅▃▅▆▃▆▄▁▃▅█▇
wandb:         train/mil_loss ▄▅▆▆▆▆▃▃▆▅▄▄▅█▅▇▄▄▄▄▇▃▃▅▄▁▅▆▃▁▄▅▂▃▃▆▅▂▅▃
wandb:      train/policy_loss █▆▁▂▇▆▄▄▄▄▄▄▇▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.24038
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.92644
wandb:      eval/avg_mil_loss 0.22783
wandb:       eval/ensemble_f1 0.92644
wandb:            test/avg_f1 0.90887
wandb:      test/avg_mil_loss 0.1709
wandb:       test/ensemble_f1 0.90887
wandb:           train/avg_f1 0.91045
wandb:      train/ensemble_f1 0.91045
wandb:         train/mil_loss 0.21298
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewdl5hh0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_123900-ewdl5hh0/logs
wandb: Agent Starting Run: yqm1nt9m with config:
wandb: 	actor_learning_rate: 0.002101887564547588
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4885124773914874
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40299945280130833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124141-yqm1nt9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yqm1nt9m
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ███████████████████████████████████████▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▇▃▃▄▄▃▄▃▅▆▄▆▅▆▆▅▆▅▆▄█▇▅▃▅▆▆█▄▆▇█▄█▄▇██
wandb:      train/ensemble_f1 ▇▅▁▃▄▆▄▄▄▃▄▂▅▃▇▅▄▅▅▆▄▄▄▆▄▄▅▁▄▅▇▅▆▇▄▆▆▇▅█
wandb:         train/mil_loss ▇▂▆▄█▁▄▃▇▄▄▄▅▆▆▃█▄▄▅▂▂█▃▆▅▆▄▂▃▃▄▃▆▅▅▃▃▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.36883
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.331
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.22739
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.91011
wandb:      train/ensemble_f1 0.91011
wandb:         train/mil_loss 0.28177
wandb:      train/policy_loss 0.13869
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.13869
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yqm1nt9m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124141-yqm1nt9m/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bebdbzb7 with config:
wandb: 	actor_learning_rate: 0.0030364641957367055
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2826894110845882
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7285469927454327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124336-bebdbzb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bebdbzb7
wandb: uploading history steps 177-182, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▆▇▇███
wandb: best/eval_avg_mil_loss ████▅▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▆▇▇███
wandb:            eval/avg_f1 ▅▅▁▁▅▇██████████████████████████████████
wandb:      eval/avg_mil_loss ▄█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▁▁███████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▁█▇██▇▇██▇▇██▇▇█▇▇█████▇██████████▇███
wandb:      train/ensemble_f1 ▁▁▇████████████▇█████████████▇██▇█▇█████
wandb:         train/mil_loss ▇▆▇█▃▂▂▂▂▁▂▃▂▂▃▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90742
wandb: best/eval_avg_mil_loss 0.28482
wandb:  best/eval_ensemble_f1 0.90742
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.28033
wandb:       eval/ensemble_f1 0.90667
wandb:            test/avg_f1 0.90156
wandb:      test/avg_mil_loss 0.29763
wandb:       test/ensemble_f1 0.90156
wandb:           train/avg_f1 0.89609
wandb:      train/ensemble_f1 0.89609
wandb:         train/mil_loss 0.28482
wandb:      train/policy_loss 0.01638
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.01638
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bebdbzb7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124336-bebdbzb7/logs
wandb: Agent Starting Run: kh8xzznt with config:
wandb: 	actor_learning_rate: 2.562973450699759e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.40093418190145225
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.006361471665084606
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124600-kh8xzznt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kh8xzznt
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▂▃▂▅▂▃▇▃▄▃▂▁▄▆▃█▆▆▃▅▄▇▇▇▆▇▆▅▇▄▆▄█▄▆▄▆
wandb:      train/ensemble_f1 ▄▄▆▅▂▅▁▄▅▄▃▃▃▄▄▆▃▆▄▄▄▅▇▁▇▄▇▇█▅▇█▆▅▇▄▆▄▆▇
wandb:         train/mil_loss ▆▃▆▃▃█▅█▄▄▄▅▇▆▅▇▇▇▆▂▆▅▇▅▇▅▇▆▅▂▁▅▃▃▂▃▅▅▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90236
wandb: best/eval_avg_mil_loss 0.35927
wandb:  best/eval_ensemble_f1 0.90236
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.31413
wandb:       eval/ensemble_f1 0.90236
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.22303
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.90042
wandb:      train/ensemble_f1 0.90042
wandb:         train/mil_loss 0.22893
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kh8xzznt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124600-kh8xzznt/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v6xv27wk with config:
wandb: 	actor_learning_rate: 0.00039474956570600625
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6026235304165649
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.962751347986195
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124733-v6xv27wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v6xv27wk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇██▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▄▄▄▄▄
wandb:      eval/avg_mil_loss ▆▆▅▂▁▃▄▄▅▅▅▅▅▅▄▄▇▇██████████████▇▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ▇▇▇█▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆█▅▃▁▂▄▁▄▁▂▃▂▅▂▄▂▃▄▂▄▆▃▁▃▄▃▅▃▅▅▃▄▃▄▂▃▅
wandb:      train/ensemble_f1 █▆▆▇▅▂▁▃▃▃▂▂▃▂▂▃▃▃▃▃▃▃▃▃▅▄▄▁▂▄▄▃▅▄▃▃▄▂▃▄
wandb:         train/mil_loss ▁▅▄▅▁▅▄▇▇▂▅▆█▆▆▃▇▅▅▅▆▆▇▃▃█▄▄▆▄▃▅█▅▇▃▅▄▄▅
wandb:      train/policy_loss ███████████▂█████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▂██████████████████████████▁█████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45422
wandb: best/eval_avg_mil_loss 2.81215
wandb:  best/eval_ensemble_f1 0.45422
wandb:            eval/avg_f1 0.42334
wandb:      eval/avg_mil_loss 2.86781
wandb:       eval/ensemble_f1 0.42334
wandb:            test/avg_f1 0.40838
wandb:      test/avg_mil_loss 2.9282
wandb:       test/ensemble_f1 0.40838
wandb:           train/avg_f1 0.44588
wandb:      train/ensemble_f1 0.44588
wandb:         train/mil_loss 1.18736
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v6xv27wk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124733-v6xv27wk/logs
wandb: Agent Starting Run: c98qkf1t with config:
wandb: 	actor_learning_rate: 0.0008136064180782451
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8907118916699328
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10568890777957184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124902-c98qkf1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c98qkf1t
wandb: uploading history steps 292-293, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆█████████
wandb:      eval/avg_mil_loss ███▇██▇▇▇▆▅▅▅▅▅▄▄▄▄▄▄▄▄▅▅▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▅▅▅▅▆▆▆▆▆▆▆▆█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▄▄▃▃▄▂▇▃▂▃▃▅▃▄▃▄▄▅█▄▅▅▂▆▄▃▆▅▅▅▆▇▆▇▇▅█
wandb:      train/ensemble_f1 ▂▃▂▃▅▃▅▃▄▄▃▆▃▁▃▃▄▃▆▃▄▃▅▄▄▄▄▄▄▄▅█▅▆▅▅▆▆▆▆
wandb:         train/mil_loss ▄▂▁▃▅▄▁▄▇█▆▄▂▅▅▄▄▃▁▃▄▄▇▂▆▂▂▁▄▆█▃▃▂▄▄▃▇▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.35167
wandb: best/eval_avg_mil_loss 3.42069
wandb:  best/eval_ensemble_f1 0.35167
wandb:            eval/avg_f1 0.35167
wandb:      eval/avg_mil_loss 3.3838
wandb:       eval/ensemble_f1 0.35167
wandb:            test/avg_f1 0.3239
wandb:      test/avg_mil_loss 3.45656
wandb:       test/ensemble_f1 0.3239
wandb:           train/avg_f1 0.37693
wandb:      train/ensemble_f1 0.37693
wandb:         train/mil_loss 0.24692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c98qkf1t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124902-c98qkf1t/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ik0g2l5p with config:
wandb: 	actor_learning_rate: 1.0256982254229517e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15288243348878372
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35599444730492946
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_125310-ik0g2l5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ik0g2l5p
wandb: uploading history steps 569-583, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▃▃▃▃▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████████████▇
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▅▅▅▄▄▄▅▅▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▂▃▃▃▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▁▂▂▃▂▂▁▂▄▄▄▄▃▄▄▅▅▆▆▆▅▆▇▆▇▇▆▇▇█▇▆▇▇▇▇█▇
wandb:      train/ensemble_f1 ▂▁▂▁▁▃▂▃▄▃▃▅▅▄▆▆▆▅▅▅▅▆▇▇▆▆▆▇▇█▆▆▇▇▇▇▇▆█▇
wandb:         train/mil_loss ▅█▃▅▁▇▃▅▄▅▃▇▆█▄▆▁▅▁▅▃▄▅▆▇▆▅█▄▄▄▃▂▅▇▃▇▃▃▃
wandb:      train/policy_loss ▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53362
wandb: best/eval_avg_mil_loss 2.99542
wandb:  best/eval_ensemble_f1 0.53362
wandb:            eval/avg_f1 0.52285
wandb:      eval/avg_mil_loss 2.9513
wandb:       eval/ensemble_f1 0.52285
wandb:            test/avg_f1 0.47577
wandb:      test/avg_mil_loss 2.94946
wandb:       test/ensemble_f1 0.47577
wandb:           train/avg_f1 0.5216
wandb:      train/ensemble_f1 0.5216
wandb:         train/mil_loss 1.8773
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ik0g2l5p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_125310-ik0g2l5p/logs
wandb: Agent Starting Run: hp0jq4ze with config:
wandb: 	actor_learning_rate: 0.0008349308206970376
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8156546071203399
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3231649603884048
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_130044-hp0jq4ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hp0jq4ze
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▄▁▅▄▅▄▃▇█▅▄▃▅▅▅▄▅▄▅▆▅▃▄▆▆▃▅▄▆▂▅▅▃▆▆▅▅
wandb:      train/ensemble_f1 ▃▇▇▄█▄▄▄▄▆▃▃█▄▆▃▇▆▆▅▆▆▅▇▄█▇▁▃▆▇▇▇▃▁▅▇▄▆▇
wandb:         train/mil_loss ▂▅▂▄▃▂▄▅▃▃▄▂▅▄▃▃▃▂▂▂▃▅▆▃▃▂▂█▃▂▄▆▅▁▅▅▄▁▃▂
wandb:      train/policy_loss ▇▆█▇▇▆▇█▅▆▆▆▇▆▃▂▂▃▄▃▃▃▂▄▃▄▃▂▁▂▂▃▄▃▃▂▂▃▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▅▆▇▇▇▆▇▅█▆▇▆▇▃▂▂▄▃▃▂▂▂▃▄▂▄▁▂▅▄▃▂▃▃▂▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90623
wandb: best/eval_avg_mil_loss 0.30216
wandb:  best/eval_ensemble_f1 0.90623
wandb:            eval/avg_f1 0.9026
wandb:      eval/avg_mil_loss 0.28788
wandb:       eval/ensemble_f1 0.9026
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.17512
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.92009
wandb:      train/ensemble_f1 0.92009
wandb:         train/mil_loss 0.2169
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hp0jq4ze
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_130044-hp0jq4ze/logs
wandb: Agent Starting Run: gy52k8jr with config:
wandb: 	actor_learning_rate: 0.005302419100056725
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6031407151719299
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9696298895212446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_130206-gy52k8jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gy52k8jr
wandb: uploading history steps 786-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb: best/eval_avg_mil_loss █▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:            eval/avg_f1 ▁▁▁▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇████████████████████
wandb:      train/ensemble_f1 ▁▁▁▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:         train/mil_loss █▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▅▅▅▆▅▅▅▅▂▁▅▅▅▅▃▇▅▅▃▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87559
wandb: best/eval_avg_mil_loss 0.39288
wandb:  best/eval_ensemble_f1 0.87559
wandb:            eval/avg_f1 0.87177
wandb:      eval/avg_mil_loss 0.39131
wandb:       eval/ensemble_f1 0.87177
wandb:            test/avg_f1 0.86217
wandb:      test/avg_mil_loss 0.31506
wandb:       test/ensemble_f1 0.86217
wandb:           train/avg_f1 0.87305
wandb:      train/ensemble_f1 0.87305
wandb:         train/mil_loss 0.26293
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gy52k8jr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_130206-gy52k8jr/logs
wandb: Agent Starting Run: gufj6kc3 with config:
wandb: 	actor_learning_rate: 0.0008838011777975345
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7722626182034139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3926037191534282
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_131241-gufj6kc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gufj6kc3
wandb: uploading history steps 155-167, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▆▆▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄███████▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▆▅▅▄▄▄▄▄▆▄▇▅▄▅▄▄▅▅▄▆▆▄▆▂▄▄▁▅▇▄▄▆▁▅▄█▆▄
wandb:      train/ensemble_f1 ▆▄▅▆▆▃▃▃▃▃▄▆█▅▄▅▃▄█▅▆▄▄▅▆▁▅▄▅▇▅▇▆▄▇▆▄█▆▆
wandb:         train/mil_loss ▃▅▃█▁▄▄▅▁▃▆▆▃▅▂▃▄▄▂▅▂▃▄▂▇▅▄▆▂▇▄▄▄▃▅▄▅▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅█▂▅▆▄▅▇▆▃▄▃▂▄▅▆▃▃▂▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.295
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.90687
wandb:      eval/avg_mil_loss 0.29021
wandb:       eval/ensemble_f1 0.90687
wandb:            test/avg_f1 0.91879
wandb:      test/avg_mil_loss 0.17932
wandb:       test/ensemble_f1 0.91879
wandb:           train/avg_f1 0.90437
wandb:      train/ensemble_f1 0.90437
wandb:         train/mil_loss 0.23515
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gufj6kc3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_131241-gufj6kc3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 27x2bj30 with config:
wandb: 	actor_learning_rate: 1.255987173739758e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8915195751502359
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34005758359017346
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_131527-27x2bj30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/27x2bj30
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▄▂▆▂▅▆▁▆▇▇▄▃▃▃▆▅▅▃▆▃▃▅▃▅▅▄▆▃▄▄▆▂██▂▃▅
wandb:      train/ensemble_f1 ▂▄▄▅▅▃▆▃▁▁▇▅▄▄▃▅▅▅▅▃▃▁▄▆▅▄▃▃▃▅▄▄▄▅▆▃▄██▃
wandb:         train/mil_loss ▅▄▃▅▇▅▁▂▅▇▅▅▅▅▅▄▃▅█▃▄▂▄▃▃▂▃▂▃▃▇▅▅▆▂▁▅▃▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.39453
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.37394
wandb:       eval/ensemble_f1 0.90599
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.23267
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.89378
wandb:      train/ensemble_f1 0.89378
wandb:         train/mil_loss 0.2043
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/27x2bj30
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_131527-27x2bj30/logs
wandb: Agent Starting Run: od3ypymv with config:
wandb: 	actor_learning_rate: 0.00229327028954309
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.586902374248038
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.039337228718180905
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_131656-od3ypymv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/od3ypymv
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▃▁▄▄▄▆▄▂▄▅▃▅▅▄▄▅▄▄▅▇▅▄▃▆▃▂▂▁▅▄▅▆█▃▄▅▆
wandb:      train/ensemble_f1 ▃▃▂▃▃▄▅▄▂▅▆▄▃▆▄▂▃▄▆▁▄▅█▁▆▆▄▂▁▅▄▄▆█▃▇▄▆▄▅
wandb:         train/mil_loss ▃▃▅▃█▂▅▃▂▃▄▂▆▄▂▄▂▃▅▄▃▂▄▃▁▄▃▃▃▃▃▆▂▂▂▃▂▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.39404
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.35294
wandb:       eval/ensemble_f1 0.90599
wandb:            test/avg_f1 0.90137
wandb:      test/avg_mil_loss 0.23705
wandb:       test/ensemble_f1 0.90137
wandb:           train/avg_f1 0.89731
wandb:      train/ensemble_f1 0.89731
wandb:         train/mil_loss 0.26612
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/od3ypymv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_131656-od3ypymv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ebj9b9x6 with config:
wandb: 	actor_learning_rate: 0.0022659813997055254
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7666965486411691
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7399021002158552
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_131838-ebj9b9x6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebj9b9x6
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁███▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ██▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▃▄▃▃▄▃▄▄▄▄▄▄▃▄▄▄▄▄▄▄
wandb:      train/ensemble_f1 ▁▂▄▃▄▆▅▇█▇█▇▇█▇▇▇▇▇▇▇▇▇▇█▇█▇▇▆▇▇▇███▇███
wandb:         train/mil_loss ▁▁▂▇█▆▇▅▄█▅▄▅▄▄▅▄▇▄▄▃▅▅▇▄▇▅▆▆▆▇▆▇▅▆▅▃▅▃▂
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85711
wandb: best/eval_avg_mil_loss 0.33247
wandb:  best/eval_ensemble_f1 0.85711
wandb:            eval/avg_f1 0.54884
wandb:      eval/avg_mil_loss 2.36862
wandb:       eval/ensemble_f1 0.54884
wandb:            test/avg_f1 0.88427
wandb:      test/avg_mil_loss 0.29471
wandb:       test/ensemble_f1 0.88427
wandb:           train/avg_f1 0.58476
wandb:      train/ensemble_f1 0.58476
wandb:         train/mil_loss 0.56229
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ebj9b9x6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_131838-ebj9b9x6/logs
wandb: Agent Starting Run: d1is0ic4 with config:
wandb: 	actor_learning_rate: 0.00014979388509746977
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4595602663807169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6090800193025789
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132005-d1is0ic4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d1is0ic4
wandb: uploading history steps 285-289, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▄▃▂▃▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▃▃▃▃▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██████████▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▇▆▆▆▅▅▅▄▄▄▄▃▃▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▂▂▂▂
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▅▅▁▃▃▃▄▆▆▄▄▆▇▄▇▄█▅▅▁▄▅▄▂▅▆▅▇▂▄▄▄▅▅▂▁▄▃
wandb:      train/ensemble_f1 ▄▁▄▄▁▅▄▂▅▆▇▂█▇▆▅▇▆▅▂▆▇▅▄▁▃▃▄▅▄▄▁▄▃▄▅▆▄▄▄
wandb:         train/mil_loss ▇▆▇█▆▇▅▃▆▆▃▆▄▃▄▂▅█▃▄▁▄▃▅▆▅▃▆▄▃▆▄▄▇▄▄▅▃▅▆
wandb:      train/policy_loss ▅▆▆▅▂▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▅▅▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▁▁▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.27604
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.92236
wandb:      eval/avg_mil_loss 0.26864
wandb:       eval/ensemble_f1 0.92236
wandb:            test/avg_f1 0.91594
wandb:      test/avg_mil_loss 0.17788
wandb:       test/ensemble_f1 0.91594
wandb:           train/avg_f1 0.91187
wandb:      train/ensemble_f1 0.91187
wandb:         train/mil_loss 0.22397
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d1is0ic4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132005-d1is0ic4/logs
wandb: Agent Starting Run: xpzcn6ln with config:
wandb: 	actor_learning_rate: 0.00019028758617501744
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5769307128842627
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1435377494903568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132358-xpzcn6ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xpzcn6ln
wandb: uploading history steps 115-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ▇█▇▆█▇▆▆▆▆▇▆▆▇▇▇▇▇▅▅▄▃▃▃▅▅▄▅▅▅▄▃▃▄▄▄▄▃▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▄▃▅▄▇▁▃▅▅▃▇▆▅▇▄▃▄▂▆█▄▇▇▂▅▄▅▃▄▂▂▃▅▅▄▄▃
wandb:      train/ensemble_f1 ▅▁▄▄▃▄▆▃▂▁▄▅▃▄▅▄▆▅▂▄▄▃▃▂▅▇▃▆▄▄▂▃▄▅▃▃▄▄▄█
wandb:         train/mil_loss ▄▆▄▄▄▆▄▆▃▅▄▄▄▄▃▅█▄█▁▆▇▄▄▆▄▃▆▄▆▆▂▅▄▅▂▃▃▅▃
wandb:      train/policy_loss ▄▃▅█▁▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▆▁▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3225
wandb: best/eval_avg_mil_loss 1.90783
wandb:  best/eval_ensemble_f1 0.3225
wandb:            eval/avg_f1 0.3225
wandb:      eval/avg_mil_loss 1.90911
wandb:       eval/ensemble_f1 0.3225
wandb:            test/avg_f1 0.29704
wandb:      test/avg_mil_loss 2.00217
wandb:       test/ensemble_f1 0.29704
wandb:           train/avg_f1 0.33917
wandb:      train/ensemble_f1 0.33917
wandb:         train/mil_loss 0.64211
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xpzcn6ln
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132358-xpzcn6ln/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wzj4ja1s with config:
wandb: 	actor_learning_rate: 0.0019936659664828893
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9530685529070616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41573570620605493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132543-wzj4ja1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzj4ja1s
wandb: uploading history steps 305-309, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▂▁▁▃▃
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▂▂▄▄▄▅▅▅▅▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ▆█▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▄▄▄▄▅▅▅▅▅▅▅▅▅▇▇▇█▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▄▃▅▄▁▁▄▁▄▃▄▃▃▃▁▄▃▅▅▅▃▂▄▄█▅▄▇▇██▇▅▄▅▅▃
wandb:      train/ensemble_f1 ▃▂▅▆▄▅▁▅▁▄▄▄▃▂▃▁▅▃▃▅▃▂█▆█▄▆▄▆▄▄▆▄▅▅▅▅▃▄▆
wandb:         train/mil_loss ▁▆▂▄▂▄▄▄▃▂▁▁▂▂▄▆▄▄▁▇▄▄▂▃▂▁▇▂▄▁█▁▂▆▂▁▁▄▅▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅█▇▇▇▇█▇█▆▇█▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.35876
wandb: best/eval_avg_mil_loss 2.93139
wandb:  best/eval_ensemble_f1 0.35876
wandb:            eval/avg_f1 0.35876
wandb:      eval/avg_mil_loss 2.90252
wandb:       eval/ensemble_f1 0.35876
wandb:            test/avg_f1 0.31729
wandb:      test/avg_mil_loss 2.59497
wandb:       test/ensemble_f1 0.31729
wandb:           train/avg_f1 0.36231
wandb:      train/ensemble_f1 0.36231
wandb:         train/mil_loss 0.21269
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzj4ja1s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132543-wzj4ja1s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x4jisham with config:
wandb: 	actor_learning_rate: 3.937654071578275e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.36552632246868866
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8295160436663197
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_133021-x4jisham
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x4jisham
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▆▆▅▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▂▂▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▃▃▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▃▃▃▃▄▄▄▄▄▃▅▃▃▃▄▄▅▃▆▄▅▆▅▆▅▅▅▆▆▆▆▆█▆▆▆
wandb:      train/ensemble_f1 ▅▁▁▆▁▂▄▃▅▄▃▃▃▅▆▄▄▄▄▄▄▅▄▄▅▃▅▅▇▆▅▄▅▆▅██▆▅█
wandb:         train/mil_loss ▅▇█▆▆▇▅▅▅▅▆▅▂▃▃▇▄▁▅▃▆▄▆▄▃▃▄▃▄▄▅▄▆▃▆▃▄▄▄▄
wandb:      train/policy_loss ██████▃██▁█████████▂████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89409
wandb: best/eval_avg_mil_loss 0.32034
wandb:  best/eval_ensemble_f1 0.89409
wandb:            eval/avg_f1 0.89409
wandb:      eval/avg_mil_loss 0.3123
wandb:       eval/ensemble_f1 0.89409
wandb:            test/avg_f1 0.88859
wandb:      test/avg_mil_loss 0.21406
wandb:       test/ensemble_f1 0.88859
wandb:           train/avg_f1 0.86744
wandb:      train/ensemble_f1 0.86744
wandb:         train/mil_loss 0.25695
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x4jisham
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_133021-x4jisham/logs
wandb: Agent Starting Run: r0ect57g with config:
wandb: 	actor_learning_rate: 2.1264973669374543e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7376569096362167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43774923142928546
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_133450-r0ect57g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0ect57g
wandb: uploading history steps 221-229, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▇█
wandb: best/eval_avg_mil_loss █▆▅▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▇█
wandb:            eval/avg_f1 ▂▁▁▁▁▃▃▄▄▅▅▆▆▆▇▇▇▇▇█▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▁▁▁▁▂▃▄▄▄▄▃▄▅▅▅▅▅▇▇▇████▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▃▂▂▃▅▁▄▃▅▄▃▃▃▅▂▇▄▅▆▃▅▃▆▄▅▅▆▅▂▆██▄▆▄█▅
wandb:      train/ensemble_f1 ▃▅▁▅▄▅▇▃▄▂▄▅▄▄▃▇▃▄▇▆▇▆▅▄▃▆▆▇▄▆▄▆▅▆██▇▃▇▆
wandb:         train/mil_loss ▇▆▄▇▆▄▆▄▆▄▄▅▁▃▃▆▆▃▃▄▂▅▆▅█▆▅▅▆▅▅▆▁▄▆▄▃▆▃▇
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90786
wandb: best/eval_avg_mil_loss 0.29443
wandb:  best/eval_ensemble_f1 0.90786
wandb:            eval/avg_f1 0.8964
wandb:      eval/avg_mil_loss 0.28615
wandb:       eval/ensemble_f1 0.8964
wandb:            test/avg_f1 0.90156
wandb:      test/avg_mil_loss 0.28271
wandb:       test/ensemble_f1 0.90156
wandb:           train/avg_f1 0.90264
wandb:      train/ensemble_f1 0.90264
wandb:         train/mil_loss 0.24481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0ect57g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_133450-r0ect57g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w8xl3s9m with config:
wandb: 	actor_learning_rate: 0.0002862316090498688
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9163199557307096
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7990740885828032
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_133843-w8xl3s9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8xl3s9m
wandb: uploading history steps 267-268, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆█
wandb: best/eval_avg_mil_loss █▆▄▃▁
wandb:  best/eval_ensemble_f1 ▁▁▃▆█
wandb:            eval/avg_f1 ▃▃▃▃▁▃▃▃▃▃▃▃▃▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆██████████
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▃▃▃▃▁▁▁▁▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆████████▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▇▃▁▂▄▄▆▅▂▃▆▅▅▄▆▅▄▆▅▇▃▄▆▇▅█▇█▁▅▆▆▅▄▅▆▆▅
wandb:      train/ensemble_f1 ▄▂▂▅▅▂▃▄▅▃▄▄▃▆▄▆▄▄▄▅▄▆▆▃▅▆▅▁▅▄▆▆▆▅▅▆█▅▇█
wandb:         train/mil_loss ▁▃▄▄▃▂▁▅▄▃▃▃▇▅▆▅▇▂▅▄▄▇█▅▄▁▃▆▂▂▆▃▂▆▄▃▅▂█▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▂▁▂▂▁▂▂▁▁▂▄█▇▇▇▇█▇█▇█▇▇██████████▇████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8278
wandb: best/eval_avg_mil_loss 0.53758
wandb:  best/eval_ensemble_f1 0.8278
wandb:            eval/avg_f1 0.82048
wandb:      eval/avg_mil_loss 0.52289
wandb:       eval/ensemble_f1 0.82048
wandb:            test/avg_f1 0.78098
wandb:      test/avg_mil_loss 0.45003
wandb:       test/ensemble_f1 0.78098
wandb:           train/avg_f1 0.78196
wandb:      train/ensemble_f1 0.78196
wandb:         train/mil_loss 0.21924
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8xl3s9m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_133843-w8xl3s9m/logs
wandb: Agent Starting Run: 14d0eo2b with config:
wandb: 	actor_learning_rate: 0.00019817216825700196
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5580631777704504
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3114554639634828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_134220-14d0eo2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14d0eo2b
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▇▄▄▅▅▄▅▇▆▆▁▄▅▅█▆▇▆▇▅▆▇▆▄▇█▅▆▆▅▇▇▇▇▇▇▄▇
wandb:      train/ensemble_f1 ▃▆▅▅▄▃▅▅▅▆▇▅▃▁▄▆▆▃▇▆▄▅▄▅▅▇▆▇▆▇█▅▆▆▆▇▄▆▇▆
wandb:         train/mil_loss ▃▄▂▅▆▄▄▄▅▂▆▄▃█▄▄▅▆▄▄▅▁▂▄█▅▅▁▁▂▃▆▁▃▂▃▂▅▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.38938
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.34795
wandb:       eval/ensemble_f1 0.90599
wandb:            test/avg_f1 0.90552
wandb:      test/avg_mil_loss 0.22003
wandb:       test/ensemble_f1 0.90552
wandb:           train/avg_f1 0.907
wandb:      train/ensemble_f1 0.907
wandb:         train/mil_loss 0.28423
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/14d0eo2b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_134220-14d0eo2b/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 02zs4zzc with config:
wandb: 	actor_learning_rate: 1.3110822560048917e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07611598803303854
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3818132996646616
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_134353-02zs4zzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/02zs4zzc
wandb: uploading history steps 177-182, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▃▃▃▅▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▇▇▅▄▄▄▄▄▄▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▃▃▃▅▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▃▃▃▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇███████████████▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▃▂▅▄▄▄▄▅▅▇▆▅▆▆▇▇▆▆▇▇▇▆▇▇█▆█▇▇█▇▇▇▆█▇█
wandb:      train/ensemble_f1 ▂▁▃▂▃▃▄▅▄▅▆▅▅▅▅▆▅▆▇▇▆▇▇█▆▆▇▇▇▆▇█▇▆▇▆▆▆▆▇
wandb:         train/mil_loss █▆▆▅▅▅▄▂▃▄▂▂▃▄▃▄▂▃▃▂▂▃▃▂▂▃▃▂▂▂▂▁▂▂▃▂▃▁▁▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▁▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89754
wandb: best/eval_avg_mil_loss 0.34561
wandb:  best/eval_ensemble_f1 0.89754
wandb:            eval/avg_f1 0.89004
wandb:      eval/avg_mil_loss 0.29964
wandb:       eval/ensemble_f1 0.89004
wandb:            test/avg_f1 0.91009
wandb:      test/avg_mil_loss 0.26226
wandb:       test/ensemble_f1 0.91009
wandb:           train/avg_f1 0.89314
wandb:      train/ensemble_f1 0.89314
wandb:         train/mil_loss 0.25536
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/02zs4zzc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_134353-02zs4zzc/logs
wandb: Agent Starting Run: znxjd1q6 with config:
wandb: 	actor_learning_rate: 0.00014939988864917154
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16848702039239283
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7761462134733627
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_134618-znxjd1q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/8yyqx08d
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znxjd1q6
wandb: uploading history steps 99-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▅▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▂▄▄▆▆███████████████▄▄▄▄▄▄▄▄▃▃▆▃▃▅▃▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▆▆▆████████████████▆▆▆▄▄▄▄▄▄▄▃▃▆▃▃▃▃▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▂▆▆▃▅▁▅▇▄▆▄▅▆█▄▅▄▆▅▆▅▆▄▇▇▄▆▆▄█▆█▄█▆▅▆▇
wandb:      train/ensemble_f1 ▃▆▃▂▇▅▁▇▅▇▇▄▄▅▅▅▆▆▃▄▆▅▃▄▆▆▇▅▆██▇▆▇▇▆▅▇▆▆
wandb:         train/mil_loss ▅▄▆▃█▄▇▅▃▄▆▃▇▃▃▅▆▆▃▂▃▄▄▅█▂▃▄▃▄▄▃▁▃▁▂▂▂▁▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅█▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91173
wandb: best/eval_avg_mil_loss 0.28476
wandb:  best/eval_ensemble_f1 0.91173
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.26298
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.89066
wandb:      test/avg_mil_loss 0.28251
wandb:       test/ensemble_f1 0.89066
wandb:           train/avg_f1 0.91261
wandb:      train/ensemble_f1 0.91261
wandb:         train/mil_loss 0.25282
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znxjd1q6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_134618-znxjd1q6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
