wandb: Agent Starting Run: 0yc9vqwq with config:
wandb: 	actor_learning_rate: 6.291062752571662e-05
wandb: 	attention_dropout_p: 0.35953906711409
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44035924211942334
wandb: 	temperature: 0.5902833941900287
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041839-0yc9vqwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 129-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄▅▆▇▇█
wandb: best/eval_avg_mil_loss ▁▂▃█▃▆▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▄▅▆▇▇█
wandb:            eval/avg_f1 ▇█▆▃▅▄▆▃▃█▆▂▆▇▄▄▇▃▅▆▇▁▅▄▆▃▅█▆▃▄▆▄▄▄▂▄▄▃▅
wandb:      eval/avg_mil_loss ▂█▃▅▂▂▆▄▅▂▄▂▁▄▆▄▂▆▄▄▅▄▅▁▃▂▅▁▅▄▅▅▅▅▅▇▄▄▆▂
wandb:       eval/ensemble_f1 ▄▅▅▃▆▄▄▄▅▃▇▄█▆▅▆▇▆▃▆▄▅▄▃▄▃▁▆█▃▅▁▃▄▆▄▃▃▃▄
wandb:           train/avg_f1 ▄▅▄▆▄▄▅▅▄▆▄▇▆█▆▅▂▅▃▆▃▄▂▄▃▃▄▃▄▃▃▃▄▃▄▃▂▃▁▅
wandb:      train/ensemble_f1 ▆▄▅▄▇▂▅▅▆▄▇▆▆▇▁▁█▄▅▁▆▃▃▅▅▂▅▂▃▃▃▃▂▄▂▂▃▅▁▆
wandb:         train/mil_loss ▆▆▄▇▅▇▆▄▅▅█▅▇▄▅▆▇▅▆▄▅▅▅▄▄▄▁▁▄▅▅▄▄▂▆▂▄▄▅▂
wandb:      train/policy_loss ▆▇▆▆▆▆▆▆▆▆▆▆▁▆▅▆█▆▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆█▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91524
wandb: best/eval_avg_mil_loss 0.26847
wandb:  best/eval_ensemble_f1 0.91524
wandb:            eval/avg_f1 0.88281
wandb:      eval/avg_mil_loss 0.42302
wandb:       eval/ensemble_f1 0.88281
wandb:           train/avg_f1 0.86567
wandb:      train/ensemble_f1 0.86567
wandb:         train/mil_loss 0.25463
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041839-0yc9vqwq/logs
wandb: ERROR Run 0yc9vqwq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: an72l9ma with config:
wandb: 	actor_learning_rate: 1.1125310993939654e-06
wandb: 	attention_dropout_p: 0.04370361774402004
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26249674594713335
wandb: 	temperature: 9.650019794208673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042033-an72l9ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▄▄▅█▇▅▅▃▁▂▂█▆▃▄▅▆▄▅▄▅▆▇▅▇▃▃▂▅▄▇▃▃▄▅▅▅▄▆▅
wandb:      eval/avg_mil_loss ▆▂▆▅▅▅▃▃▄▄▃█▅▃▄▄▄▃▅▄▄▂▂▄▁▆▂▄▅▅▃▄█▄▃▃▃▄▄▆
wandb:       eval/ensemble_f1 █▄▇▄▅▂▃▄▅▂▄▃▄▅▄▅▆▅▃▆█▃▆▇▃▄▃▃▄▅▃▄▆▂▃▅▆▃▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃▂▄▅▅▅▅▄▁▄▅▄▅▅▅▃▂▄▄▆▃▂▂█▆▆▄▂▆▆▄▃▃▃▄▅▂▃
wandb:      train/ensemble_f1 █▅▃▃▃▃▅▃▄▄▅▄▅▅▅▅▃▄▃▃▆▃▃▃▁█▆▂▃▃▆▃▃▄▄▅▂▆▅▄
wandb:         train/mil_loss ▇█▃▅▄▆▆▃▄▄▅▃▅▁▃▆▄▇▄▅▅▅▄▆▄▅▄▄▆▆▄▃▅█▄▅▇▄▅▅
wandb:      train/policy_loss ▄▄█▄▄▄▄▄▄▄▄▄▄▄▇▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▅▃▅█▁▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.25666
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.88652
wandb:      eval/avg_mil_loss 0.35512
wandb:       eval/ensemble_f1 0.88652
wandb:            test/avg_f1 0.91226
wandb:      test/avg_mil_loss 0.22796
wandb:       test/ensemble_f1 0.91226
wandb:           train/avg_f1 0.88262
wandb:      train/ensemble_f1 0.88262
wandb:         train/mil_loss 0.2169
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042033-an72l9ma/logs
wandb: Agent Starting Run: 78ut9eu7 with config:
wandb: 	actor_learning_rate: 2.6288586164078054e-06
wandb: 	attention_dropout_p: 0.03528171558985249
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8554459419204408
wandb: 	temperature: 4.0724431285983815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042206-78ut9eu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: uploading wandb-summary.json
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆█
wandb: best/eval_avg_mil_loss ▇▆▅▂▁▅▃█▄
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆█
wandb:            eval/avg_f1 ▅▇▆▇█▄▅▁▃▄▇▄▆▅▇▆▇▇▆▅▆▆▆▇▆▄▇▅▅▇▆▅▂▇▆▄█▆▃▇
wandb:      eval/avg_mil_loss ▄▃▃▃▃▃▃▁▂▅▄▁▂▄▄▄▂█▄▂▃▁▃▃▃▂▃▇▄▄▄▅▅▄▃▃▄▃▂▄
wandb:       eval/ensemble_f1 ▃▂▅▄▄▅▃▃▃▃▂▄▂▄▅▆▇▃▅▃▁▅▅▆▁▃▅▄▆▃▅▆▃▃▅▆▆▅█▂
wandb:           train/avg_f1 ▃▅▄▅▄▅▆▄▆▁▅▄▄▅▄▃▄▅▄▃▅▄▄▃▃▅▅▃▅▅▅▅▆▆▄▅█▄▃▅
wandb:      train/ensemble_f1 ▆▄▃▇▆▅▄▂▅▇▆▆▁▆▂▅█▄▆▇▂▆▅▄▄▇▄▅▅▄▇▃▅█▆▆▇▅▆▆
wandb:         train/mil_loss ▇▆▆██▆▆▇▅▇▅▇▄▄▆▇▆▆▅▄▄▄▄▆▆▃▄▁▄▃▅▄▃▃▃▃▄▃▃▁
wandb:      train/policy_loss ▅▅▅▅█▅▅▅▅▃▅▅▅▅▆▅▅▅▂▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.32327
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.86343
wandb:      eval/avg_mil_loss 0.41759
wandb:       eval/ensemble_f1 0.86343
wandb:           train/avg_f1 0.8833
wandb:      train/ensemble_f1 0.8833
wandb:         train/mil_loss 0.84831
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042206-78ut9eu7/logs
wandb: ERROR Run 78ut9eu7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: t5pg820r with config:
wandb: 	actor_learning_rate: 0.00011500806257085972
wandb: 	attention_dropout_p: 0.20852219208274136
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5510767760005835
wandb: 	temperature: 5.2847969509308115
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042436-t5pg820r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: uploading history steps 119-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃██
wandb: best/eval_avg_mil_loss ▅█▃▁
wandb:  best/eval_ensemble_f1 ▁▃██
wandb:            eval/avg_f1 ▆▆▆▆▄▄▇██▄▄▃▃▄▇▄▂▅▄▃█▅▄▅▁▂▅▄▆▇▁▅▂▄▅▁▁▄▃▅
wandb:      eval/avg_mil_loss ▄▃▄▃▃▆▃▄█▂▄▃▄▇▆▁▇▃█▃▅▆▂▃▄▇▄▅▆▇▆▃▆▂▆▇▆▆▆▅
wandb:       eval/ensemble_f1 ▆▆▅▆▆▄▄▇█▃▅▆▄▄▃▄▄▃▂▂▃▄▃▁▂▅▄▄▄▅▃▄▃▃▂▇▄▂▄▆
wandb:           train/avg_f1 ▇▇▇▆█▅▇▅▇█▇▆▄▅▅▅▂▅▁▃▅▃▅▄▃▅▃▂▅▃▃▄▃▅▅▄▃▃▃▁
wandb:      train/ensemble_f1 █▇█▇▅▇▇▇▅█▆▇▆▄▅▅▅▃▄▃▄▅▂▅▁▃▆▃▄▄▃▅▃▂▂▃▃▄▃▄
wandb:         train/mil_loss ▇█▇▇▇▃▅▆▃▅▇▄▁▁▃▃▂▂▄▅▃▃▃▂▂▁▄▄▄▃▄▄▄▄▆▂▃▄▃▃
wandb:      train/policy_loss ▃▃▃▃▃▃▄▃▃▆▃▅▃▃▅▃█▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▆▅▃▅▅▁▅█▅▅▅▅▅▅▅▅▆▅▅▅▄▅▅▅▅▅▅▅▅▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91203
wandb: best/eval_avg_mil_loss 0.24921
wandb:  best/eval_ensemble_f1 0.91203
wandb:            eval/avg_f1 0.89405
wandb:      eval/avg_mil_loss 0.3178
wandb:       eval/ensemble_f1 0.89405
wandb:           train/avg_f1 0.86448
wandb:      train/ensemble_f1 0.86448
wandb:         train/mil_loss 0.21083
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run woven-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042436-t5pg820r/logs
wandb: ERROR Run t5pg820r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: upg3ueh6 with config:
wandb: 	actor_learning_rate: 1.8125674829039468e-06
wandb: 	attention_dropout_p: 0.07792873795977151
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29278472409294976
wandb: 	temperature: 8.439462172260537
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042700-upg3ueh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upg3ueh6
