wandb: Agent Starting Run: 0yc9vqwq with config:
wandb: 	actor_learning_rate: 6.291062752571662e-05
wandb: 	attention_dropout_p: 0.35953906711409
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44035924211942334
wandb: 	temperature: 0.5902833941900287
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041839-0yc9vqwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 129-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ƒâ–ˆâ–ƒâ–†â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–†â–ƒâ–…â–„â–†â–ƒâ–ƒâ–ˆâ–†â–‚â–†â–‡â–„â–„â–‡â–ƒâ–…â–†â–‡â–â–…â–„â–†â–ƒâ–…â–ˆâ–†â–ƒâ–„â–†â–„â–„â–„â–‚â–„â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–‚â–ˆâ–ƒâ–…â–‚â–‚â–†â–„â–…â–‚â–„â–‚â–â–„â–†â–„â–‚â–†â–„â–„â–…â–„â–…â–â–ƒâ–‚â–…â–â–…â–„â–…â–…â–…â–…â–…â–‡â–„â–„â–†â–‚
wandb:       eval/ensemble_f1 â–„â–…â–…â–ƒâ–†â–„â–„â–„â–…â–ƒâ–‡â–„â–ˆâ–†â–…â–†â–‡â–†â–ƒâ–†â–„â–…â–„â–ƒâ–„â–ƒâ–â–†â–ˆâ–ƒâ–…â–â–ƒâ–„â–†â–„â–ƒâ–ƒâ–ƒâ–„
wandb:           train/avg_f1 â–„â–…â–„â–†â–„â–„â–…â–…â–„â–†â–„â–‡â–†â–ˆâ–†â–…â–‚â–…â–ƒâ–†â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–â–…
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–‡â–‚â–…â–…â–†â–„â–‡â–†â–†â–‡â–â–â–ˆâ–„â–…â–â–†â–ƒâ–ƒâ–…â–…â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–…â–â–†
wandb:         train/mil_loss â–†â–†â–„â–‡â–…â–‡â–†â–„â–…â–…â–ˆâ–…â–‡â–„â–…â–†â–‡â–…â–†â–„â–…â–…â–…â–„â–„â–„â–â–â–„â–…â–…â–„â–„â–‚â–†â–‚â–„â–„â–…â–‚
wandb:      train/policy_loss â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–…â–†â–ˆâ–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91524
wandb: best/eval_avg_mil_loss 0.26847
wandb:  best/eval_ensemble_f1 0.91524
wandb:            eval/avg_f1 0.88281
wandb:      eval/avg_mil_loss 0.42302
wandb:       eval/ensemble_f1 0.88281
wandb:           train/avg_f1 0.86567
wandb:      train/ensemble_f1 0.86567
wandb:         train/mil_loss 0.25463
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run astral-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041839-0yc9vqwq/logs
wandb: ERROR Run 0yc9vqwq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: an72l9ma with config:
wandb: 	actor_learning_rate: 1.1125310993939654e-06
wandb: 	attention_dropout_p: 0.04370361774402004
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26249674594713335
wandb: 	temperature: 9.650019794208673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042033-an72l9ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–„â–„â–…â–ˆâ–‡â–…â–…â–ƒâ–â–‚â–‚â–ˆâ–†â–ƒâ–„â–…â–†â–„â–…â–„â–…â–†â–‡â–…â–‡â–ƒâ–ƒâ–‚â–…â–„â–‡â–ƒâ–ƒâ–„â–…â–…â–…â–„â–†â–…
wandb:      eval/avg_mil_loss â–†â–‚â–†â–…â–…â–…â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–…â–ƒâ–„â–„â–„â–ƒâ–…â–„â–„â–‚â–‚â–„â–â–†â–‚â–„â–…â–…â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–†
wandb:       eval/ensemble_f1 â–ˆâ–„â–‡â–„â–…â–‚â–ƒâ–„â–…â–‚â–„â–ƒâ–„â–…â–„â–…â–†â–…â–ƒâ–†â–ˆâ–ƒâ–†â–‡â–ƒâ–„â–ƒâ–ƒâ–„â–…â–ƒâ–„â–†â–‚â–ƒâ–…â–†â–ƒâ–â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–ƒâ–‚â–„â–…â–…â–…â–…â–„â–â–„â–…â–„â–…â–…â–…â–ƒâ–‚â–„â–„â–†â–ƒâ–‚â–‚â–ˆâ–†â–†â–„â–‚â–†â–†â–„â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–…â–„â–…â–…â–…â–…â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–â–ˆâ–†â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–„â–…â–‚â–†â–…â–„
wandb:         train/mil_loss â–‡â–ˆâ–ƒâ–…â–„â–†â–†â–ƒâ–„â–„â–…â–ƒâ–…â–â–ƒâ–†â–„â–‡â–„â–…â–…â–…â–„â–†â–„â–…â–„â–„â–†â–†â–„â–ƒâ–…â–ˆâ–„â–…â–‡â–„â–…â–…
wandb:      train/policy_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–…â–ƒâ–…â–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.25666
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.88652
wandb:      eval/avg_mil_loss 0.35512
wandb:       eval/ensemble_f1 0.88652
wandb:            test/avg_f1 0.91226
wandb:      test/avg_mil_loss 0.22796
wandb:       test/ensemble_f1 0.91226
wandb:           train/avg_f1 0.88262
wandb:      train/ensemble_f1 0.88262
wandb:         train/mil_loss 0.2169
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run colorful-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042033-an72l9ma/logs
wandb: Agent Starting Run: 78ut9eu7 with config:
wandb: 	actor_learning_rate: 2.6288586164078054e-06
wandb: 	attention_dropout_p: 0.03528171558985249
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8554459419204408
wandb: 	temperature: 4.0724431285983815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042206-78ut9eu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: uploading wandb-summary.json
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–…â–‚â–â–…â–ƒâ–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–‡â–ˆâ–„â–…â–â–ƒâ–„â–‡â–„â–†â–…â–‡â–†â–‡â–‡â–†â–…â–†â–†â–†â–‡â–†â–„â–‡â–…â–…â–‡â–†â–…â–‚â–‡â–†â–„â–ˆâ–†â–ƒâ–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–…â–„â–â–‚â–„â–„â–„â–‚â–ˆâ–„â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‡â–„â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„
wandb:       eval/ensemble_f1 â–ƒâ–‚â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–„â–…â–†â–‡â–ƒâ–…â–ƒâ–â–…â–…â–†â–â–ƒâ–…â–„â–†â–ƒâ–…â–†â–ƒâ–ƒâ–…â–†â–†â–…â–ˆâ–‚
wandb:           train/avg_f1 â–ƒâ–…â–„â–…â–„â–…â–†â–„â–†â–â–…â–„â–„â–…â–„â–ƒâ–„â–…â–„â–ƒâ–…â–„â–„â–ƒâ–ƒâ–…â–…â–ƒâ–…â–…â–…â–…â–†â–†â–„â–…â–ˆâ–„â–ƒâ–…
wandb:      train/ensemble_f1 â–†â–„â–ƒâ–‡â–†â–…â–„â–‚â–…â–‡â–†â–†â–â–†â–‚â–…â–ˆâ–„â–†â–‡â–‚â–†â–…â–„â–„â–‡â–„â–…â–…â–„â–‡â–ƒâ–…â–ˆâ–†â–†â–‡â–…â–†â–†
wandb:         train/mil_loss â–‡â–†â–†â–ˆâ–ˆâ–†â–†â–‡â–…â–‡â–…â–‡â–„â–„â–†â–‡â–†â–†â–…â–„â–„â–„â–„â–†â–†â–ƒâ–„â–â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–
wandb:      train/policy_loss â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–†â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.32327
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.86343
wandb:      eval/avg_mil_loss 0.41759
wandb:       eval/ensemble_f1 0.86343
wandb:           train/avg_f1 0.8833
wandb:      train/ensemble_f1 0.8833
wandb:         train/mil_loss 0.84831
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042206-78ut9eu7/logs
wandb: ERROR Run 78ut9eu7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: t5pg820r with config:
wandb: 	actor_learning_rate: 0.00011500806257085972
wandb: 	attention_dropout_p: 0.20852219208274136
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5510767760005835
wandb: 	temperature: 5.2847969509308115
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042436-t5pg820r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: uploading history steps 119-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–†â–„â–„â–‡â–ˆâ–ˆâ–„â–„â–ƒâ–ƒâ–„â–‡â–„â–‚â–…â–„â–ƒâ–ˆâ–…â–„â–…â–â–‚â–…â–„â–†â–‡â–â–…â–‚â–„â–…â–â–â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–ˆâ–‚â–„â–ƒâ–„â–‡â–†â–â–‡â–ƒâ–ˆâ–ƒâ–…â–†â–‚â–ƒâ–„â–‡â–„â–…â–†â–‡â–†â–ƒâ–†â–‚â–†â–‡â–†â–†â–†â–…
wandb:       eval/ensemble_f1 â–†â–†â–…â–†â–†â–„â–„â–‡â–ˆâ–ƒâ–…â–†â–„â–„â–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–â–‚â–…â–„â–„â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–„â–‚â–„â–†
wandb:           train/avg_f1 â–‡â–‡â–‡â–†â–ˆâ–…â–‡â–…â–‡â–ˆâ–‡â–†â–„â–…â–…â–…â–‚â–…â–â–ƒâ–…â–ƒâ–…â–„â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–ƒâ–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:      train/ensemble_f1 â–ˆâ–‡â–ˆâ–‡â–…â–‡â–‡â–‡â–…â–ˆâ–†â–‡â–†â–„â–…â–…â–…â–ƒâ–„â–ƒâ–„â–…â–‚â–…â–â–ƒâ–†â–ƒâ–„â–„â–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–„
wandb:         train/mil_loss â–‡â–ˆâ–‡â–‡â–‡â–ƒâ–…â–†â–ƒâ–…â–‡â–„â–â–â–ƒâ–ƒâ–‚â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–„â–„â–„â–ƒâ–„â–„â–„â–„â–†â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–ƒâ–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91203
wandb: best/eval_avg_mil_loss 0.24921
wandb:  best/eval_ensemble_f1 0.91203
wandb:            eval/avg_f1 0.89405
wandb:      eval/avg_mil_loss 0.3178
wandb:       eval/ensemble_f1 0.89405
wandb:           train/avg_f1 0.86448
wandb:      train/ensemble_f1 0.86448
wandb:         train/mil_loss 0.21083
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042436-t5pg820r/logs
wandb: ERROR Run t5pg820r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: upg3ueh6 with config:
wandb: 	actor_learning_rate: 1.8125674829039468e-06
wandb: 	attention_dropout_p: 0.07792873795977151
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29278472409294976
wandb: 	temperature: 8.439462172260537
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042700-upg3ueh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upg3ueh6
wandb: uploading history steps 112-131, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–…â–†â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–…â–‚â–ƒâ–„â–„â–‡â–â–†â–„â–†â–…â–…â–„â–ƒâ–…â–„â–†â–†â–†â–„â–ˆâ–ƒâ–‡â–„â–„â–†â–„â–â–†â–ˆâ–†â–‡â–ˆâ–†â–†â–…â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–…â–…â–ˆâ–ƒâ–…â–…â–…â–„â–…â–„â–ƒâ–…â–ƒâ–„â–…â–…â–ˆâ–ˆâ–†â–‚â–ƒâ–ƒâ–ƒâ–†â–‚â–â–‚â–ƒâ–†â–†â–‚â–‚â–ƒâ–†â–„â–…â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–â–…â–…â–…â–„â–„â–„â–†â–â–â–ƒâ–†â–ƒâ–‡â–†â–…â–…â–ƒâ–…â–„â–…â–„â–ˆâ–†â–ƒâ–„â–ƒâ–†â–…â–„â–â–†â–…â–†â–ˆâ–„â–…â–†â–„â–…
wandb:           train/avg_f1 â–…â–ˆâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–„â–ˆâ–‡â–…â–†â–‡â–‡â–ƒâ–†â–ƒâ–†â–…â–‡â–ˆâ–‡â–†â–†â–„â–‡â–†â–…â–„â–…â–„â–„â–†â–†â–â–…
wandb:      train/ensemble_f1 â–ƒâ–â–ˆâ–„â–ƒâ–…â–„â–„â–…â–„â–…â–†â–ˆâ–‡â–„â–‡â–‚â–‡â–…â–†â–†â–…â–‡â–ƒâ–‡â–…â–†â–†â–†â–„â–†â–„â–…â–ƒâ–ˆâ–…â–…â–ˆâ–ˆâ–„
wandb:         train/mil_loss â–ˆâ–†â–‡â–‡â–‡â–ˆâ–‡â–…â–†â–†â–†â–†â–†â–…â–†â–…â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91898
wandb: best/eval_avg_mil_loss 0.24357
wandb:  best/eval_ensemble_f1 0.91898
wandb:            eval/avg_f1 0.88859
wandb:      eval/avg_mil_loss 0.30259
wandb:       eval/ensemble_f1 0.88859
wandb:           train/avg_f1 0.8813
wandb:      train/ensemble_f1 0.8813
wandb:         train/mil_loss 0.33039
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upg3ueh6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042700-upg3ueh6/logs
wandb: ERROR Run upg3ueh6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qgb34jqg with config:
wandb: 	actor_learning_rate: 1.0559514048828589e-06
wandb: 	attention_dropout_p: 0.3345354558380369
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9832337054974918
wandb: 	temperature: 4.500371143067468
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042854-qgb34jqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qgb34jqg
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 93-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–„â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–…â–†â–ƒâ–ƒâ–†â–…â–…â–ƒâ–†â–ˆâ–†â–…â–â–‚â–ƒâ–„â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‡â–†â–‡â–†â–„â–…â–‚â–ƒâ–…â–ƒâ–†â–†â–ƒâ–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–„â–†â–ƒâ–ˆâ–…â–…â–…â–…â–â–†â–‡â–…â–„â–‚â–„â–†â–‡â–ƒâ–„â–„â–…â–‡â–‡â–‡â–†â–…â–‡â–†â–ƒâ–â–…â–ƒâ–‚â–ƒâ–†â–†â–†â–†â–„
wandb:       eval/ensemble_f1 â–â–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–…â–„â–ˆâ–„â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–…â–„â–…â–„â–„â–…â–„â–ƒâ–„â–‚â–‚â–ƒâ–„â–„â–‚â–ƒ
wandb:           train/avg_f1 â–‚â–†â–…â–‡â–†â–†â–„â–ƒâ–ƒâ–‚â–…â–ˆâ–„â–„â–„â–ˆâ–„â–…â–†â–ƒâ–…â–„â–ƒâ–†â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–‚â–…â–„â–…â–…â–ƒâ–â–„â–ƒâ–‚
wandb:      train/ensemble_f1 â–‚â–‡â–†â–…â–„â–‡â–†â–„â–„â–ˆâ–ˆâ–ƒâ–‡â–‡â–„â–†â–†â–‚â–‡â–ƒâ–…â–ƒâ–…â–„â–„â–…â–…â–ƒâ–‚â–…â–…â–…â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–…â–…â–‡â–ˆâ–…â–ƒâ–„â–…â–„â–„â–…â–‡â–…â–‡â–†â–ƒâ–…â–„â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–…â–â–ƒâ–‚â–„â–…â–†â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94464
wandb: best/eval_avg_mil_loss 0.19056
wandb:  best/eval_ensemble_f1 0.94464
wandb:            eval/avg_f1 0.87937
wandb:      eval/avg_mil_loss 0.292
wandb:       eval/ensemble_f1 0.87937
wandb:           train/avg_f1 0.87797
wandb:      train/ensemble_f1 0.87797
wandb:         train/mil_loss 0.21931
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misunderstood-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qgb34jqg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042854-qgb34jqg/logs
wandb: ERROR Run qgb34jqg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: y2asd65g with config:
wandb: 	actor_learning_rate: 0.0004409001634680523
wandb: 	attention_dropout_p: 0.22379582740335088
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41900983165393046
wandb: 	temperature: 0.1731217222389858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043021-y2asd65g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y2asd65g
wandb: uploading history steps 122-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–†â–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–†â–‡â–†â–…â–„â–†â–†â–…â–†â–†â–…â–ˆâ–ˆâ–…â–…â–…â–…â–†â–„â–†â–…â–„â–â–„â–„â–
wandb:      eval/avg_mil_loss â–ƒâ–†â–„â–†â–â–‚â–„â–†â–…â–ˆâ–„â–ƒâ–„â–†â–…â–„â–„â–â–„â–„â–ƒâ–„â–â–‚â–…â–„â–„â–„â–ˆâ–…â–ˆâ–…â–…â–„â–…â–…â–…â–…â–†â–‡
wandb:       eval/ensemble_f1 â–†â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–ˆâ–‡â–†â–„â–ˆâ–…â–‡â–‡â–‡â–„â–†â–†â–ˆâ–†â–…â–‡â–„â–†â–…â–†â–…â–…â–†â–ƒâ–…â–„â–…â–ƒâ–ƒâ–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–‡â–‡â–†â–†â–†â–‡â–‡â–…â–‡â–†â–†â–…â–„â–…â–…â–‡â–†â–„â–…â–ƒâ–…â–„â–ƒâ–…â–…â–…â–‚â–„â–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–‚â–â–‚â–
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–ˆâ–…â–‡â–†â–…â–†â–ˆâ–†â–†â–†â–‡â–†â–„â–†â–…â–…â–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–„â–â–ƒâ–‚â–ƒ
wandb:         train/mil_loss â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–†â–ˆâ–„â–…â–…â–„â–†â–„â–…â–…â–„â–„â–ƒâ–…â–ƒâ–‚â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–ƒâ–â–ƒâ–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–†â–„â–„â–ˆâ–ˆâ–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–†â–‡â–‡â–…â–…â–…â–…â–…â–„â–†â–…â–…â–†â–…â–…â–…â–ˆâ–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91886
wandb: best/eval_avg_mil_loss 0.23464
wandb:  best/eval_ensemble_f1 0.91886
wandb:            eval/avg_f1 0.82836
wandb:      eval/avg_mil_loss 0.38642
wandb:       eval/ensemble_f1 0.82836
wandb:            test/avg_f1 0.8828
wandb:      test/avg_mil_loss 0.24406
wandb:       test/ensemble_f1 0.8828
wandb:           train/avg_f1 0.8432
wandb:      train/ensemble_f1 0.8432
wandb:         train/mil_loss 0.18844
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y2asd65g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043021-y2asd65g/logs
wandb: Agent Starting Run: bnjjk51c with config:
wandb: 	actor_learning_rate: 6.915713872394583e-05
wandb: 	attention_dropout_p: 0.1264486218508976
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0254451952924869
wandb: 	temperature: 1.4183696179718608
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043220-bnjjk51c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bnjjk51c
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–„â–†â–â–‚â–‚â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–†â–…â–†â–…â–â–„â–†â–ƒâ–ƒâ–„â–†â–‡â–„â–‡â–‚â–ˆâ–ƒâ–…â–†â–‚â–„â–ˆâ–ƒâ–†â–…â–ƒâ–„â–„â–…â–â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–…â–†â–„â–ƒâ–„â–ƒâ–‡â–†â–ƒâ–…â–…â–â–„â–„â–â–‚â–‡â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–„â–‚â–ˆâ–†â–„â–‚â–„â–ˆâ–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–‚â–„â–ƒâ–…â–â–„â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–â–„â–…â–ƒâ–„â–ƒâ–„â–…â–†â–†â–‚â–‡â–…â–„â–„â–†â–ƒâ–…â–…â–ƒâ–ƒâ–„â–„â–ˆâ–…â–â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–„â–‚â–„â–ƒâ–…â–„â–…â–â–…â–‚â–…â–ƒâ–„â–†â–„â–†â–‡â–…â–…â–„â–ˆâ–…â–ƒâ–†â–…â–‡â–†â–…â–†â–†â–†â–‡â–ˆâ–‡â–„â–„â–„â–…
wandb:      train/ensemble_f1 â–„â–‡â–„â–‚â–„â–…â–„â–„â–â–…â–„â–…â–ƒâ–„â–„â–†â–…â–†â–…â–…â–ˆâ–…â–‡â–‡â–ƒâ–ƒâ–‡â–†â–…â–„â–†â–…â–†â–‡â–…â–ˆâ–‡â–„â–„â–…
wandb:         train/mil_loss â–â–ƒâ–…â–ƒâ–†â–†â–„â–†â–ˆâ–‚â–…â–…â–„â–„â–…â–…â–‚â–„â–ƒâ–„â–‚â–…â–…â–„â–‚â–„â–ƒâ–ƒâ–„â–â–†â–„â–„â–‚â–‚â–†â–‚â–…â–â–‚
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–ˆâ–‚â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–…â–„â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91556
wandb: best/eval_avg_mil_loss 0.46163
wandb:  best/eval_ensemble_f1 0.91556
wandb:            eval/avg_f1 0.87151
wandb:      eval/avg_mil_loss 0.30742
wandb:       eval/ensemble_f1 0.87151
wandb:            test/avg_f1 0.86934
wandb:      test/avg_mil_loss 0.32714
wandb:       test/ensemble_f1 0.86934
wandb:           train/avg_f1 0.86522
wandb:      train/ensemble_f1 0.86522
wandb:         train/mil_loss 1.89084
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run daily-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bnjjk51c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043220-bnjjk51c/logs
wandb: Agent Starting Run: 9w4xz89a with config:
wandb: 	actor_learning_rate: 0.0002454524259680078
wandb: 	attention_dropout_p: 0.04952620026606441
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01426285814089745
wandb: 	temperature: 0.672784488338598
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043327-9w4xz89a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9w4xz89a
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 75-81, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–†â–‚â–…â–…â–‡â–„â–ƒâ–†â–„â–ƒâ–ˆâ–‡â–†â–‚â–„â–†â–‡â–†â–†â–…â–†â–†â–ƒâ–‚â–…â–‚â–‚â–„â–â–‚â–…â–…â–â–‡â–â–â–†â–…
wandb:      eval/avg_mil_loss â–‡â–ƒâ–„â–…â–…â–ƒâ–…â–‚â–‚â–†â–…â–…â–ˆâ–…â–„â–…â–ƒâ–â–„â–„â–†â–…â–ƒâ–…â–„â–„â–ƒâ–„â–„â–†â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–„â–‡â–…â–„â–‡â–ƒâ–…â–„â–…â–…â–„â–…â–ˆâ–†â–‡â–‡â–†â–ƒâ–…â–‡â–…â–‚â–…â–„â–„â–‡â–â–…â–…â–ƒâ–‡â–†â–…â–‚â–„â–‡â–…â–ƒâ–…
wandb:           train/avg_f1 â–‡â–…â–‡â–…â–…â–‡â–…â–‡â–‡â–ˆâ–†â–…â–ˆâ–†â–†â–†â–†â–„â–†â–…â–‚â–ƒâ–‚â–…â–‚â–„â–‚â–‚â–…â–†â–â–â–ƒâ–‚â–…â–†â–‡â–ˆâ–…â–„
wandb:      train/ensemble_f1 â–„â–ƒâ–…â–„â–ƒâ–„â–ˆâ–…â–ƒâ–†â–…â–ƒâ–†â–†â–„â–…â–„â–…â–„â–„â–…â–„â–‚â–â–â–ƒâ–‚â–„â–…â–„â–â–ƒâ–‚â–ƒâ–„â–…â–†â–†â–„â–…
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–„â–„â–†â–„â–†â–…â–…â–ƒâ–…â–„â–ƒâ–„â–†â–„â–â–‡â–†â–‡â–ˆâ–ƒâ–†â–ƒâ–‡â–‡â–„â–ƒâ–‡â–ƒâ–‚â–ƒâ–…â–†â–„â–„â–‚â–…
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91546
wandb: best/eval_avg_mil_loss 0.29639
wandb:  best/eval_ensemble_f1 0.91546
wandb:            eval/avg_f1 0.89715
wandb:      eval/avg_mil_loss 0.28376
wandb:       eval/ensemble_f1 0.89715
wandb:           train/avg_f1 0.8831
wandb:      train/ensemble_f1 0.8831
wandb:         train/mil_loss 0.3303
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ruby-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9w4xz89a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043327-9w4xz89a/logs
wandb: ERROR Run 9w4xz89a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: opus2oyo with config:
wandb: 	actor_learning_rate: 0.00014389295952577802
wandb: 	attention_dropout_p: 0.3063701596271806
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.544688218241387
wandb: 	temperature: 9.19005055566129
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043441-opus2oyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opus2oyo
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–ˆâ–â–†â–„â–ƒâ–‡â–„â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–„â–†â–‚â–…â–„â–…â–…â–†â–ƒâ–‡â–†â–†â–‚â–†â–‡â–„â–ƒâ–„â–„â–…â–‡â–ƒâ–„â–…â–ˆâ–ˆâ–„â–…â–„â–†â–†â–ƒâ–…â–†â–„â–…â–…â–†
wandb:      eval/avg_mil_loss â–„â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–â–…â–‚â–…â–ƒâ–„â–â–â–…â–ƒâ–â–ƒâ–„â–ƒâ–„â–‚â–‚â–‚â–„â–…â–ƒâ–â–ƒâ–…â–â–â–‚â–‚
wandb:       eval/ensemble_f1 â–‚â–„â–…â–…â–†â–†â–…â–†â–â–†â–…â–†â–‡â–…â–…â–…â–‡â–‡â–„â–‡â–†â–„â–ˆâ–†â–ˆâ–ˆâ–…â–…â–†â–†â–‡â–…â–„â–…â–„â–â–…â–†â–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–„â–†â–…â–„â–„â–ƒâ–…â–„â–ƒâ–†â–…â–ˆâ–…â–ˆâ–…â–ƒâ–„â–‡â–„â–†â–ƒâ–†â–„â–„â–„â–†â–†â–…â–†â–…â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–‚â–†â–â–ƒâ–†â–„â–ˆâ–‚â–ƒâ–†â–†â–‡â–‚â–…â–…â–‚â–‚â–†â–‡â–‡â–‚â–ƒâ–ƒâ–„â–„â–†â–†â–‚â–‡â–‡â–…â–ƒ
wandb:         train/mil_loss â–‡â–ˆâ–‡â–ˆâ–‡â–†â–†â–†â–†â–‡â–…â–†â–…â–…â–†â–„â–†â–ƒâ–‡â–…â–„â–…â–…â–„â–„â–…â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–ˆâ–â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–†â–…â–†â–†â–†â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–„â–‚â–…â–ˆâ–…â–â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–‡â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90344
wandb: best/eval_avg_mil_loss 0.32079
wandb:  best/eval_ensemble_f1 0.90344
wandb:            eval/avg_f1 0.83947
wandb:      eval/avg_mil_loss 0.31739
wandb:       eval/ensemble_f1 0.83947
wandb:            test/avg_f1 0.85481
wandb:      test/avg_mil_loss 0.32832
wandb:       test/ensemble_f1 0.85481
wandb:           train/avg_f1 0.85295
wandb:      train/ensemble_f1 0.85295
wandb:         train/mil_loss 2.03317
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eager-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/opus2oyo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043441-opus2oyo/logs
wandb: Agent Starting Run: 5944t3rz with config:
wandb: 	actor_learning_rate: 3.094461915382063e-06
wandb: 	attention_dropout_p: 0.46123919654742246
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8167147172567719
wandb: 	temperature: 1.279069235919461
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043656-5944t3rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5944t3rz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–†â–‚â–†â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–…â–‡â–„â–…â–…â–…â–†â–†â–‡â–ˆâ–†â–‚â–ˆâ–ˆâ–ƒâ–†â–…â–„â–‡â–…â–„â–‚â–…â–‡â–ƒâ–ƒâ–†â–„â–†â–ˆâ–ˆâ–†â–…â–ƒâ–ƒâ–„â–â–…
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–…â–„â–ƒâ–„â–…â–ƒâ–„â–„â–ƒâ–„â–†â–ˆâ–ˆâ–„â–ƒâ–†â–†â–„â–„â–ƒâ–„â–…â–…â–‡â–„â–„â–…â–ƒâ–…â–ƒâ–„â–â–…â–„â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–†â–‡â–„â–†â–ƒâ–„â–…â–†â–†â–â–ƒâ–„â–ƒâ–ˆâ–‡â–†â–ˆâ–ƒâ–„â–†â–†â–„â–‡â–‡â–…â–„â–‡â–ƒâ–„â–„â–†â–„â–ˆâ–†â–ƒâ–‡â–†â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–…â–…â–ƒâ–…â–‚â–‚â–†â–ƒâ–‚â–â–…â–…â–„â–…â–‚â–â–„â–„â–‚â–„â–…â–ˆâ–‚â–†â–‚â–„â–‡â–…â–„â–ƒâ–‚â–†â–‡â–„â–„â–…â–‡â–…
wandb:      train/ensemble_f1 â–‡â–„â–ƒâ–…â–ƒâ–…â–‚â–†â–‚â–†â–†â–‚â–â–‚â–„â–†â–ƒâ–„â–„â–â–„â–…â–‚â–ˆâ–â–…â–‡â–…â–‚â–‚â–‚â–„â–‚â–„â–†â–„â–…â–‡â–„â–…
wandb:         train/mil_loss â–„â–…â–ƒâ–ƒâ–†â–„â–…â–„â–„â–„â–„â–ƒâ–†â–…â–‚â–ƒâ–…â–‚â–„â–â–‚â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–…â–„â–‚â–â–‚
wandb:      train/policy_loss â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–‚â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.25677
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.88558
wandb:      eval/avg_mil_loss 0.30677
wandb:       eval/ensemble_f1 0.88558
wandb:            test/avg_f1 0.90768
wandb:      test/avg_mil_loss 0.2139
wandb:       test/ensemble_f1 0.90768
wandb:           train/avg_f1 0.88261
wandb:      train/ensemble_f1 0.88261
wandb:         train/mil_loss 0.36129
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5944t3rz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043656-5944t3rz/logs
wandb: Agent Starting Run: 8pd68eb4 with config:
wandb: 	actor_learning_rate: 8.227980911354214e-06
wandb: 	attention_dropout_p: 0.24064869573924164
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7342444141786963
wandb: 	temperature: 5.379231181650482
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043824-8pd68eb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pd68eb4
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‚â–ˆâ–…â–…â–†â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–†â–‚â–„â–…â–„â–…â–„â–ƒâ–†â–†â–„â–„â–‚â–†â–ˆâ–â–„â–„â–„â–â–â–…â–…â–â–‚â–„â–…â–ƒâ–„â–â–†â–‡â–‚â–„â–‡â–ƒâ–ƒâ–ƒâ–…
wandb:      eval/avg_mil_loss â–‚â–„â–„â–…â–ƒâ–…â–„â–ƒâ–‚â–…â–…â–†â–…â–â–„â–†â–ƒâ–ˆâ–‡â–„â–…â–„â–ƒâ–…â–‡â–ˆâ–‡â–„â–„â–„â–…â–„â–…â–†â–†â–…â–…â–†â–„â–…
wandb:       eval/ensemble_f1 â–…â–‡â–‡â–‚â–†â–‡â–†â–‡â–…â–‡â–‚â–‡â–‚â–ƒâ–„â–‡â–†â–‡â–‚â–†â–‚â–„â–‚â–†â–ƒâ–†â–ƒâ–†â–…â–â–„â–ˆâ–‚â–…â–„â–„â–ƒâ–…â–†â–…
wandb:           train/avg_f1 â–‡â–„â–‚â–‡â–„â–‚â–†â–ˆâ–†â–…â–†â–â–‚â–ƒâ–ˆâ–…â–‚â–…â–…â–ƒâ–„â–†â–„â–…â–„â–‡â–†â–…â–â–†â–‡â–…â–â–ƒâ–ƒâ–†â–†â–…â–‚â–‡
wandb:      train/ensemble_f1 â–„â–‚â–†â–‡â–‚â–‚â–‚â–…â–†â–…â–„â–…â–†â–â–‚â–…â–‚â–ƒâ–…â–„â–†â–†â–„â–„â–†â–ƒâ–†â–†â–ˆâ–ˆâ–…â–â–‡â–ƒâ–â–„â–â–†â–†â–ƒ
wandb:         train/mil_loss â–ˆâ–ˆâ–ˆâ–†â–‡â–†â–†â–…â–†â–‡â–†â–†â–…â–„â–†â–…â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–
wandb:      train/policy_loss â–„â–…â–„â–ƒâ–„â–„â–†â–„â–…â–„â–„â–„â–„â–â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–â–â–â–â–ƒâ–â–â–â–â–‚â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91873
wandb: best/eval_avg_mil_loss 0.19847
wandb:  best/eval_ensemble_f1 0.91873
wandb:            eval/avg_f1 0.88859
wandb:      eval/avg_mil_loss 0.30728
wandb:       eval/ensemble_f1 0.88859
wandb:           train/avg_f1 0.89526
wandb:      train/ensemble_f1 0.89526
wandb:         train/mil_loss 0.28467
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wise-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pd68eb4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043824-8pd68eb4/logs
wandb: ERROR Run 8pd68eb4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	size mismatch for task_model.mlp.0.weight: copying a param with shape torch.Size([256, 22]) from checkpoint, the shape in current model is torch.Size([64, 22]).
wandb: ERROR 	size mismatch for task_model.mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
wandb: ERROR 	size mismatch for task_model.mlp.3.weight: copying a param with shape torch.Size([2, 256]) from checkpoint, the shape in current model is torch.Size([2, 64]).
wandb: ERROR 
wandb: Agent Starting Run: 6uji1qns with config:
wandb: 	actor_learning_rate: 6.852896350696967e-06
wandb: 	attention_dropout_p: 0.3815252515349368
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6901246311613068
wandb: 	temperature: 6.095774336702638
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043957-6uji1qns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6uji1qns
wandb: uploading wandb-summary.json
wandb: uploading history steps 146-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–†â–‚â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–„â–†â–†â–„â–†â–‡â–…â–†â–†â–†â–†â–†â–‡â–„â–ƒâ–†â–†â–…â–ˆâ–„â–â–ˆâ–„â–…â–‡â–†â–…â–ƒâ–„â–…â–‡â–†â–…â–„â–†â–…â–†â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–â–‚â–â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–„â–‚â–‡â–ƒâ–…â–†â–„â–„â–„â–„â–ƒâ–ˆâ–ƒâ–ƒâ–â–„â–…â–ƒâ–‚â–…â–ƒâ–…â–…â–„
wandb:       eval/ensemble_f1 â–â–ƒâ–…â–„â–„â–ƒâ–„â–„â–„â–…â–…â–„â–ˆâ–„â–†â–…â–ƒâ–…â–ˆâ–ƒâ–ˆâ–„â–†â–ƒâ–‡â–‚â–‡â–„â–ƒâ–„â–…â–‡â–„â–„â–‡â–„â–†â–‚â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–â–ƒâ–ƒâ–„â–„â–‚â–„â–…â–‡â–„â–â–…â–…â–ƒâ–…â–…â–ƒâ–ƒâ–ˆâ–…â–…â–ƒâ–†â–†â–ˆâ–†â–…â–„â–ƒâ–‡â–…â–†â–…â–†â–…â–‚â–ƒâ–„â–†
wandb:      train/ensemble_f1 â–…â–â–‚â–„â–‚â–‚â–„â–ƒâ–„â–‡â–…â–â–ƒâ–‚â–…â–‚â–„â–„â–†â–†â–‚â–„â–„â–ƒâ–†â–…â–…â–ƒâ–„â–‡â–ˆâ–…â–„â–…â–„â–…â–„â–„â–‚â–†
wandb:         train/mil_loss â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–†â–…â–…â–…â–†â–†â–…â–†â–…â–‡â–‡â–ˆâ–…â–†â–†â–†â–…â–‡â–‡â–‡â–†â–‡â–…â–†â–…â–‡â–…â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.23619
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.87756
wandb:      eval/avg_mil_loss 0.37732
wandb:       eval/ensemble_f1 0.87756
wandb:            test/avg_f1 0.88246
wandb:      test/avg_mil_loss 0.21016
wandb:       test/ensemble_f1 0.88246
wandb:           train/avg_f1 0.8918
wandb:      train/ensemble_f1 0.8918
wandb:         train/mil_loss 1.72701
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6uji1qns
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043957-6uji1qns/logs
wandb: Agent Starting Run: gkrnh9fe with config:
wandb: 	actor_learning_rate: 0.0001003568230083866
wandb: 	attention_dropout_p: 0.14379542034034298
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9416489373849286
wandb: 	temperature: 4.534581204532594
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044211-gkrnh9fe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gkrnh9fe
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 122-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–†â–ˆâ–â–‡
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–†â–â–…â–ƒâ–…â–„â–„â–‚â–…â–†â–ƒâ–„â–‡â–ƒâ–…â–ƒâ–‚â–„â–ˆâ–„â–…â–ƒâ–â–…â–…â–…â–…â–…â–‚â–„â–…â–…â–‚â–â–‡â–ƒâ–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–â–‚â–‡â–…â–‡â–…â–„â–ƒâ–ƒâ–‚â–‚â–‡â–ƒâ–‚â–…â–â–…â–ƒâ–…â–„â–ƒâ–„â–ˆâ–ƒâ–ƒâ–„â–â–‡â–„â–„â–„â–ˆâ–…â–ƒâ–…â–…â–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–…â–…â–ƒâ–†â–„â–â–‡â–ƒâ–„â–‚â–„â–ƒâ–…â–ƒâ–…â–‚â–ƒâ–„â–…â–„â–†â–ƒâ–â–ƒâ–…â–„â–†â–ƒâ–„â–ƒâ–„â–„â–ƒâ–†â–‡â–ƒâ–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–ƒâ–„â–…â–„â–„â–„â–†â–…â–…â–„â–ˆâ–ƒâ–ƒâ–„â–…â–…â–…â–†â–„â–…â–ƒâ–„â–ƒâ–†â–â–…â–…â–…â–…â–†â–†â–…â–…â–‡â–ƒâ–‡â–ˆâ–ƒâ–†
wandb:      train/ensemble_f1 â–â–„â–„â–„â–†â–„â–…â–†â–„â–…â–…â–„â–ƒâ–…â–„â–„â–„â–„â–…â–…â–„â–ƒâ–ˆâ–ƒâ–†â–ƒâ–…â–â–…â–…â–ƒâ–…â–„â–†â–‚â–…â–„â–ƒâ–ƒâ–…
wandb:         train/mil_loss â–„â–†â–…â–‡â–†â–…â–‡â–†â–â–‡â–„â–†â–†â–†â–„â–†â–†â–…â–„â–…â–†â–…â–ˆâ–†â–…â–…â–‡â–…â–†â–†â–…â–„â–…â–…â–…â–…â–†â–„â–ˆâ–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9338
wandb: best/eval_avg_mil_loss 0.26846
wandb:  best/eval_ensemble_f1 0.9338
wandb:            eval/avg_f1 0.89657
wandb:      eval/avg_mil_loss 0.31328
wandb:       eval/ensemble_f1 0.89657
wandb:            test/avg_f1 0.884
wandb:      test/avg_mil_loss 0.2371
wandb:       test/ensemble_f1 0.884
wandb:           train/avg_f1 0.89587
wandb:      train/ensemble_f1 0.89587
wandb:         train/mil_loss 0.21844
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run confused-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gkrnh9fe
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044211-gkrnh9fe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lz2ga32a with config:
wandb: 	actor_learning_rate: 0.0004620503794487003
wandb: 	attention_dropout_p: 0.1313415040301335
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05624128409483808
wandb: 	temperature: 1.748239405417641
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044439-lz2ga32a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lz2ga32a
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‡â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–ˆâ–„â–„â–†â–„â–†â–„â–…â–‡â–ˆâ–…â–…â–…â–‡â–†â–†â–†â–„â–„â–†â–‡â–†â–ƒâ–„â–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„â–…â–†â–â–ƒâ–„
wandb:      eval/avg_mil_loss â–…â–â–ƒâ–„â–…â–…â–„â–„â–„â–…â–ƒâ–…â–ˆâ–ƒâ–…â–‡â–„â–…â–…â–†â–†â–…â–…â–ƒâ–†â–†â–‡â–„â–†â–„â–„â–‡â–‡â–„â–ˆâ–‡â–ˆâ–†â–†â–†
wandb:       eval/ensemble_f1 â–ˆâ–…â–ƒâ–„â–‡â–„â–ƒâ–„â–‚â–ƒâ–…â–†â–„â–†â–ˆâ–‡â–…â–„â–â–†â–ƒâ–ƒâ–ƒâ–…â–‡â–‡â–‚â–„â–â–†â–†â–„â–‚â–ƒâ–…â–ƒâ–†â–ƒâ–„â–ƒ
wandb:           train/avg_f1 â–„â–„â–„â–„â–…â–‚â–‚â–…â–‡â–†â–â–…â–â–ƒâ–‡â–ƒâ–ƒâ–â–†â–ƒâ–ˆâ–â–ƒâ–„â–†â–…â–„â–ƒâ–â–„â–…â–†â–‚â–‚â–ƒâ–„â–‡â–‚â–„â–‡
wandb:      train/ensemble_f1 â–…â–„â–†â–ˆâ–ƒâ–†â–„â–†â–†â–†â–ƒâ–†â–ƒâ–†â–„â–‚â–…â–ƒâ–ˆâ–†â–‚â–„â–‚â–ƒâ–ƒâ–…â–…â–ƒâ–â–†â–…â–…â–‚â–†â–†â–ƒâ–‡â–ƒâ–ƒâ–…
wandb:         train/mil_loss â–ˆâ–…â–„â–‡â–…â–†â–„â–„â–ˆâ–…â–ƒâ–†â–ƒâ–†â–…â–ƒâ–…â–„â–…â–‚â–…â–ƒâ–…â–„â–†â–‚â–…â–…â–…â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–‚â–‚â–ƒ
wandb:      train/policy_loss â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–†â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9186
wandb: best/eval_avg_mil_loss 0.25372
wandb:  best/eval_ensemble_f1 0.9186
wandb:            eval/avg_f1 0.8804
wandb:      eval/avg_mil_loss 0.35227
wandb:       eval/ensemble_f1 0.8804
wandb:           train/avg_f1 0.88638
wandb:      train/ensemble_f1 0.88638
wandb:         train/mil_loss 1.04993
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lz2ga32a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044439-lz2ga32a/logs
wandb: ERROR Run lz2ga32a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 86picw9i with config:
wandb: 	actor_learning_rate: 7.509152130907468e-06
wandb: 	attention_dropout_p: 0.08804634022462171
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.006658138983044348
wandb: 	temperature: 5.993617388371186
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044710-86picw9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86picw9i
wandb: uploading wandb-summary.json
wandb: uploading history steps 92-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–ƒâ–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–„â–†â–„â–†â–ƒâ–â–ƒâ–…â–„â–…â–†â–ƒâ–‡â–ƒâ–â–…â–†â–ƒâ–†â–ƒâ–†â–„â–„â–ƒâ–‚â–„â–‡â–„â–…â–…â–ƒâ–†â–ˆâ–ˆâ–„â–â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–‚â–„â–„â–ƒâ–â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–„â–„â–ƒâ–…â–â–†â–ƒâ–…â–ƒâ–ƒâ–‡â–„â–„â–â–…â–ˆâ–‚â–‚â–„â–…â–‚â–…â–‚â–…â–…â–‚â–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–…â–‚â–‚â–„â–†â–…â–…â–‚â–…â–„â–‚â–„â–…â–‚â–…â–†â–„â–„â–ƒâ–ƒâ–…â–†â–„â–‚â–†â–‚â–ƒâ–‡â–â–†â–ƒâ–‚
wandb:           train/avg_f1 â–‡â–…â–‡â–†â–ƒâ–ˆâ–†â–„â–‚â–‡â–†â–…â–â–ˆâ–…â–ƒâ–‡â–…â–ˆâ–†â–ƒâ–„â–ˆâ–†â–…â–…â–…â–†â–‚â–„â–…â–‚â–…â–†â–„â–‡â–‡â–‚â–ˆâ–…
wandb:      train/ensemble_f1 â–…â–†â–…â–‚â–„â–…â–…â–…â–ƒâ–„â–â–‡â–…â–„â–„â–ƒâ–†â–ˆâ–„â–‡â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–„â–„â–â–‡â–…â–‡â–†â–‚â–†â–‡â–„
wandb:         train/mil_loss â–…â–„â–‡â–†â–…â–†â–ƒâ–ˆâ–†â–…â–ˆâ–†â–ˆâ–„â–‚â–†â–„â–‡â–„â–„â–‡â–†â–…â–‡â–„â–…â–„â–…â–â–…â–…â–‚â–ƒâ–…â–‚â–ƒâ–†â–„â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–â–…â–…â–â–â–â–…â–â–â–ˆâ–…â–…â–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93371
wandb: best/eval_avg_mil_loss 0.23892
wandb:  best/eval_ensemble_f1 0.93371
wandb:            eval/avg_f1 0.88859
wandb:      eval/avg_mil_loss 0.2896
wandb:       eval/ensemble_f1 0.88859
wandb:           train/avg_f1 0.89007
wandb:      train/ensemble_f1 0.89007
wandb:         train/mil_loss 0.2588
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run winter-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86picw9i
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044710-86picw9i/logs
wandb: ERROR Run 86picw9i errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c3392oq0 with config:
wandb: 	actor_learning_rate: 1.866996988213252e-06
wandb: 	attention_dropout_p: 0.22359299528795945
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9062386183423524
wandb: 	temperature: 8.417074913544232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044854-c3392oq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c3392oq0
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–â–‡â–…â–„â–†â–„â–…â–„â–â–„â–„â–„â–ˆâ–…â–ƒâ–‚â–…â–†â–„â–„â–ƒâ–†â–†â–†â–…â–‚â–…â–…â–ƒâ–…â–…â–ƒâ–„â–ƒâ–…â–‡â–ƒâ–ƒâ–„â–„
wandb:      eval/avg_mil_loss â–‚â–ˆâ–‚â–‚â–…â–„â–ƒâ–‚â–„â–„â–…â–ƒâ–‚â–ƒâ–„â–„â–‚â–…â–…â–„â–â–„â–…â–‚â–„â–â–ƒâ–…â–ƒâ–‚â–…â–…â–„â–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–â–‡â–ƒâ–…â–„â–†â–…â–„â–„â–„â–„â–ˆâ–…â–ƒâ–‚â–…â–„â–„â–„â–…â–‡â–‚â–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–„â–…â–‚â–„â–…â–…â–ƒâ–ƒâ–…
wandb:           train/avg_f1 â–…â–ˆâ–†â–ƒâ–â–„â–…â–†â–ˆâ–…â–„â–‡â–…â–‡â–ˆâ–‡â–„â–ƒâ–‡â–„â–†â–…â–‚â–‚â–‚â–„â–ƒâ–‚â–‚â–†â–…â–…â–‚â–…â–…â–†â–…â–ƒâ–ƒâ–„
wandb:      train/ensemble_f1 â–‡â–‡â–„â–ƒâ–â–†â–ˆâ–…â–‡â–…â–‡â–‡â–ƒâ–‡â–‡â–ˆâ–„â–„â–ƒâ–…â–†â–…â–†â–…â–ƒâ–‚â–‚â–„â–„â–ƒâ–„â–‚â–…â–ƒâ–†â–†â–„â–ƒâ–ƒâ–
wandb:         train/mil_loss â–„â–„â–‡â–‡â–‡â–‡â–…â–„â–ƒâ–†â–†â–…â–…â–ˆâ–…â–‡â–…â–†â–†â–ƒâ–„â–ˆâ–…â–ƒâ–„â–„â–„â–ƒâ–„â–†â–‡â–‡â–…â–ƒâ–‚â–…â–â–†â–‡â–„
wandb:      train/policy_loss â–„â–„â–„â–„â–†â–ƒâ–„â–„â–„â–„â–†â–„â–„â–„â–„â–ˆâ–„â–â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–‡â–†â–…â–…â–…â–…â–…â–ˆâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.24768
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.88245
wandb:      eval/avg_mil_loss 0.26583
wandb:       eval/ensemble_f1 0.88245
wandb:           train/avg_f1 0.88767
wandb:      train/ensemble_f1 0.88767
wandb:         train/mil_loss 0.18246
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wandering-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c3392oq0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044854-c3392oq0/logs
wandb: ERROR Run c3392oq0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: emkvrdxk with config:
wandb: 	actor_learning_rate: 1.022795878600108e-06
wandb: 	attention_dropout_p: 0.4972683153927244
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7066211136869142
wandb: 	temperature: 3.661166960617317
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045016-emkvrdxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/emkvrdxk
wandb: uploading history steps 119-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–‡â–‚â–†â–…â–…â–‚â–ƒâ–…â–†â–„â–†â–…â–…â–‚â–†â–ˆâ–„â–ƒâ–‡â–ƒâ–…â–†â–†â–…â–…â–â–…â–ƒâ–„â–‚â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–†â–ƒâ–ˆâ–…â–‡â–â–…â–†â–„â–…â–ƒâ–„â–…â–…â–ƒâ–ƒâ–†â–ƒâ–„â–„â–‚â–‚â–…â–…â–„â–…â–ƒâ–…â–ƒâ–„â–ƒâ–â–ƒâ–‚â–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–ƒâ–â–„â–†â–‚â–„â–…â–„â–‚â–…â–‡â–ˆâ–ƒâ–…â–„â–ˆâ–…â–„â–ƒâ–†â–…â–†â–‚â–„â–…â–†â–†â–ˆâ–ˆâ–†â–‡â–ƒâ–‡â–†â–â–…â–ƒâ–…â–†â–ƒ
wandb:           train/avg_f1 â–ˆâ–‚â–†â–‚â–„â–…â–…â–†â–…â–„â–†â–„â–…â–„â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–‚â–…â–…â–…â–„â–‚â–…â–„â–„â–…â–‡â–â–…â–…â–ƒâ–„â–†
wandb:      train/ensemble_f1 â–„â–…â–„â–†â–ƒâ–…â–…â–„â–‡â–†â–…â–„â–†â–„â–ƒâ–ƒâ–…â–„â–ƒâ–„â–â–‚â–…â–ƒâ–…â–„â–…â–‚â–„â–…â–…â–†â–‡â–„â–‚â–ˆâ–‡â–ƒâ–†â–‡
wandb:         train/mil_loss â–…â–„â–„â–ƒâ–†â–…â–…â–ˆâ–ƒâ–‡â–†â–„â–„â–…â–†â–†â–ƒâ–…â–†â–…â–„â–…â–†â–„â–„â–„â–ƒâ–‡â–…â–…â–ƒâ–ƒâ–„â–„â–„â–ƒâ–‚â–â–‚â–
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.2348
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.8742
wandb:      eval/avg_mil_loss 0.34167
wandb:       eval/ensemble_f1 0.8742
wandb:           train/avg_f1 0.89291
wandb:      train/ensemble_f1 0.89291
wandb:         train/mil_loss 1.40138
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zany-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/emkvrdxk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045016-emkvrdxk/logs
wandb: ERROR Run emkvrdxk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ve8g48mh with config:
wandb: 	actor_learning_rate: 0.00016178370950941626
wandb: 	attention_dropout_p: 0.06802419398899728
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33122802975258503
wandb: 	temperature: 0.0003135861169933918
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045220-ve8g48mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ve8g48mh
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 73-79, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–â–ˆâ–„â–…â–†â–„â–‚â–…â–ˆâ–…â–†â–„â–…â–â–†â–†â–…â–„â–„â–„â–ˆâ–†â–‡â–ˆâ–†â–…â–…â–†â–…â–…â–„â–ˆâ–†â–†â–„â–‚â–„â–ˆâ–…
wandb:      eval/avg_mil_loss â–…â–†â–„â–…â–ˆâ–„â–‡â–ƒâ–†â–„â–…â–†â–‚â–ƒâ–â–ˆâ–…â–…â–ˆâ–ƒâ–‚â–ƒâ–…â–†â–ƒâ–‚â–…â–„â–…â–…â–ƒâ–„â–†â–„â–„â–„â–…â–ˆâ–†â–ƒ
wandb:       eval/ensemble_f1 â–…â–â–„â–ˆâ–„â–ƒâ–„â–„â–…â–„â–…â–†â–…â–†â–„â–„â–…â–„â–…â–†â–†â–„â–„â–„â–„â–‡â–„â–†â–…â–†â–…â–…â–†â–†â–†â–…â–„â–„â–†â–†
wandb:           train/avg_f1 â–‡â–†â–…â–…â–‡â–„â–â–…â–„â–…â–†â–…â–ˆâ–„â–‡â–„â–…â–…â–†â–„â–„â–„â–‡â–ƒâ–†â–†â–†â–†â–„â–ƒâ–„â–ƒâ–ˆâ–…â–‡â–â–…â–…â–…â–ˆ
wandb:      train/ensemble_f1 â–‡â–‡â–†â–…â–…â–ƒâ–…â–â–‚â–…â–†â–‡â–†â–…â–‡â–…â–†â–†â–„â–„â–ƒâ–†â–…â–†â–†â–†â–…â–ƒâ–…â–„â–ˆâ–ˆâ–…â–…â–‡â–â–…â–„â–…â–…
wandb:         train/mil_loss â–‚â–…â–‚â–‚â–‡â–„â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ƒâ–…â–‚â–ƒâ–ƒâ–â–ˆâ–„â–‚â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–â–…â–â–…â–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–…â–â–â–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–…â–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.34521
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.86989
wandb:      eval/avg_mil_loss 0.25711
wandb:       eval/ensemble_f1 0.86989
wandb:           train/avg_f1 0.89493
wandb:      train/ensemble_f1 0.89493
wandb:         train/mil_loss 1.29114
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ve8g48mh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045220-ve8g48mh/logs
wandb: ERROR Run ve8g48mh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: sm4jndxn with config:
wandb: 	actor_learning_rate: 1.1964381064967684e-06
wandb: 	attention_dropout_p: 0.13380866316555912
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6805942510875852
wandb: 	temperature: 0.932871549416654
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045332-sm4jndxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sm4jndxn
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 100-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–â–ƒâ–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–ƒâ–„â–„â–„â–†â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–„â–â–ˆâ–†â–†â–„â–…â–ƒâ–†â–…â–„â–„â–â–ƒâ–„â–†â–„â–…â–„â–â–‚â–„â–†â–‚â–ƒâ–ƒâ–‚
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–‚â–ƒâ–‚â–„â–‚â–„â–„â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–„â–†â–‚â–„â–â–„â–„â–‚â–„â–ˆâ–„â–â–‚â–ƒâ–‚â–…â–‚â–ƒâ–†â–†â–„â–„â–‚
wandb:       eval/ensemble_f1 â–ƒâ–…â–„â–‚â–„â–„â–†â–„â–„â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–â–„â–ˆâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–„â–â–‡â–„â–ƒâ–†â–ƒâ–…â–„â–ƒâ–†â–„â–„â–‚â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ˆâ–‡â–‡â–‡â–â–‡â–‡â–‡â–„â–…â–…â–…â–ƒâ–„â–†â–†â–…â–‚â–‚â–â–†â–‚â–„â–ˆâ–„â–ƒâ–‡â–ˆâ–…â–ƒâ–‚â–‡â–…â–…â–†â–…â–â–ƒ
wandb:      train/ensemble_f1 â–…â–…â–…â–‡â–ˆâ–†â–‡â–†â–„â–‡â–†â–„â–„â–ƒâ–„â–…â–…â–„â–„â–†â–„â–…â–‡â–…â–†â–„â–…â–‚â–ƒâ–…â–†â–ƒâ–„â–†â–ƒâ–„â–†â–„â–„â–
wandb:         train/mil_loss â–ˆâ–†â–…â–„â–ˆâ–†â–„â–‚â–†â–‡â–…â–„â–ƒâ–„â–„â–ƒâ–…â–…â–‡â–„â–ˆâ–â–…â–‡â–…â–…â–…â–„â–‡â–…â–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–ˆâ–â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93025
wandb: best/eval_avg_mil_loss 0.32603
wandb:  best/eval_ensemble_f1 0.93025
wandb:            eval/avg_f1 0.88316
wandb:      eval/avg_mil_loss 0.40419
wandb:       eval/ensemble_f1 0.88316
wandb:            test/avg_f1 0.88642
wandb:      test/avg_mil_loss 0.23084
wandb:       test/ensemble_f1 0.88642
wandb:           train/avg_f1 0.88125
wandb:      train/ensemble_f1 0.88125
wandb:         train/mil_loss 0.24939
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sm4jndxn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045332-sm4jndxn/logs
wandb: Agent Starting Run: r3ibg2o4 with config:
wandb: 	actor_learning_rate: 2.9382889049187977e-06
wandb: 	attention_dropout_p: 0.37047042837944266
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2986288970984661
wandb: 	temperature: 4.642507486805445
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045521-r3ibg2o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3ibg2o4
wandb: uploading wandb-summary.json; uploading history steps 105-122, summary
wandb: uploading history steps 105-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–†â–ˆâ–â–„â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–â–ƒâ–‡â–ˆâ–†â–ˆâ–†â–„â–…â–†â–ˆâ–ƒâ–‡â–…â–‡â–†â–†â–„â–„â–†â–…â–†â–ƒâ–†â–„â–…â–†â–„â–†â–„â–ƒâ–‡â–†â–â–…â–„â–†â–…â–†
wandb:      eval/avg_mil_loss â–ƒâ–…â–…â–„â–‡â–ˆâ–ƒâ–ƒâ–‚â–…â–ƒâ–…â–‚â–„â–‡â–„â–„â–‚â–„â–‚â–ƒâ–ƒâ–„â–†â–ƒâ–„â–†â–ƒâ–„â–â–‚â–„â–„â–ƒâ–‚â–„â–„â–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–â–ƒâ–‡â–ˆâ–†â–†â–„â–…â–…â–ƒâ–ƒâ–…â–ˆâ–ˆâ–‡â–‚â–„â–‡â–‡â–…â–„â–†â–†â–‡â–ˆâ–†â–‡â–ˆâ–†â–„â–…â–‡â–…â–„â–†â–‚â–†â–†
wandb:           train/avg_f1 â–†â–‚â–…â–„â–„â–„â–„â–„â–†â–…â–ƒâ–„â–‚â–„â–ƒâ–…â–…â–„â–†â–„â–ˆâ–„â–†â–†â–…â–„â–…â–…â–‚â–†â–â–ƒâ–â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–…â–„â–†â–‡â–‚â–„â–†â–†â–„â–†â–‡â–†â–…â–„â–…â–‡â–„â–†â–„â–†â–ˆâ–ˆâ–…â–‡â–†â–‡â–…â–‡â–‡â–‡â–„â–†â–â–„â–„â–†â–†â–†â–…â–‡
wandb:         train/mil_loss â–†â–ˆâ–†â–†â–‡â–„â–…â–„â–‡â–…â–…â–‡â–‡â–†â–ƒâ–ƒâ–†â–†â–†â–…â–…â–…â–…â–‡â–ˆâ–…â–†â–†â–ƒâ–…â–â–†â–ƒâ–†â–‡â–ƒâ–‡â–…â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9338
wandb: best/eval_avg_mil_loss 0.28134
wandb:  best/eval_ensemble_f1 0.9338
wandb:            eval/avg_f1 0.91135
wandb:      eval/avg_mil_loss 0.25669
wandb:       eval/ensemble_f1 0.91135
wandb:           train/avg_f1 0.89391
wandb:      train/ensemble_f1 0.89391
wandb:         train/mil_loss 0.25053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run exalted-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3ibg2o4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045521-r3ibg2o4/logs
wandb: ERROR Run r3ibg2o4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hxzi0syz with config:
wandb: 	actor_learning_rate: 2.89732291761935e-05
wandb: 	attention_dropout_p: 0.23048036067173655
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04307743709916034
wandb: 	temperature: 4.31553530437623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045720-hxzi0syz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hxzi0syz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–‡â–ˆâ–„â–†â–ˆâ–„â–ˆâ–„â–†â–…â–…â–†â–‡â–†â–†â–†â–…â–„â–ƒâ–†â–†â–†â–‡â–…â–„â–†â–†â–ˆâ–ƒâ–…â–…â–…â–†â–ƒâ–…â–â–
wandb:      eval/avg_mil_loss â–ƒâ–„â–‚â–†â–ƒâ–…â–…â–…â–ƒâ–ƒâ–…â–â–…â–…â–†â–„â–…â–…â–„â–†â–„â–ƒâ–†â–„â–†â–…â–„â–‡â–‡â–…â–„â–†â–ˆâ–„â–‚â–†â–‡â–ˆâ–‡â–‡
wandb:       eval/ensemble_f1 â–†â–†â–‡â–‡â–…â–…â–‡â–…â–„â–…â–„â–…â–…â–…â–†â–â–„â–…â–…â–ƒâ–„â–‡â–†â–†â–‡â–…â–‚â–„â–‡â–ƒâ–ˆâ–ƒâ–„â–ƒâ–…â–ƒâ–†â–„â–â–‚
wandb:           train/avg_f1 â–†â–†â–†â–†â–†â–‚â–†â–‡â–ˆâ–…â–…â–â–…â–‚â–…â–„â–…â–„â–…â–„â–â–…â–‚â–‚â–ƒâ–„â–‚â–ƒâ–†â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒ
wandb:      train/ensemble_f1 â–†â–†â–‡â–„â–†â–†â–ˆâ–ƒâ–‡â–ƒâ–…â–…â–„â–…â–…â–ˆâ–‡â–„â–…â–…â–…â–…â–…â–…â–„â–†â–…â–„â–…â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–
wandb:         train/mil_loss â–†â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–‡â–†â–†â–…â–…â–†â–ˆâ–†â–…â–…â–„â–„â–…â–…â–…â–…â–ƒâ–„â–†â–ƒâ–ƒâ–„â–…â–ƒâ–…â–ƒâ–…â–„â–„â–ƒâ–„â–ƒâ–
wandb:      train/policy_loss â–„â–„â–†â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–‡â–„â–„â–â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9229
wandb: best/eval_avg_mil_loss 0.23495
wandb:  best/eval_ensemble_f1 0.9229
wandb:            eval/avg_f1 0.84672
wandb:      eval/avg_mil_loss 0.4337
wandb:       eval/ensemble_f1 0.84672
wandb:           train/avg_f1 0.87697
wandb:      train/ensemble_f1 0.87697
wandb:         train/mil_loss 0.21209
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run unique-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hxzi0syz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045720-hxzi0syz/logs
wandb: ERROR Run hxzi0syz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: sdxx4wcz with config:
wandb: 	actor_learning_rate: 0.0003009193329160721
wandb: 	attention_dropout_p: 0.40958415603324505
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32915035627431277
wandb: 	temperature: 8.626963770308206
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045935-sdxx4wcz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sdxx4wcz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…â–â–ƒâ–‚â–†â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–…â–„â–†â–„â–ƒâ–†â–‡â–…â–â–…â–„â–…â–ƒâ–„â–…â–†â–‡â–†â–…â–†â–ˆâ–…â–‚â–‚â–„â–‡â–†â–…â–„â–†â–…â–†â–„â–‡â–„â–…â–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–…â–„â–‚â–ƒâ–…â–„â–ƒâ–‡â–‚â–„â–…â–„â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–…â–‡â–ƒâ–ƒâ–‚â–†â–„â–ˆâ–„â–„â–ƒâ–†â–â–†â–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–…â–‡â–…â–„â–‚â–…â–‡â–‡â–„â–„â–‡â–ˆâ–†â–…â–…â–‡â–‚â–†â–„â–…â–…â–ƒâ–„â–ˆâ–ˆâ–â–‡â–‚â–†â–…â–…â–…â–„â–…â–â–‡â–…â–‚â–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–„â–â–ƒâ–„â–…â–†â–„â–„â–…â–‡â–ƒâ–â–†â–†â–…â–‚â–…â–‡â–ƒâ–…â–…â–„â–…â–…â–ƒâ–…â–ˆâ–„â–†â–…â–„â–…â–…â–ƒâ–„â–„â–…â–…
wandb:      train/ensemble_f1 â–„â–…â–…â–„â–†â–„â–ƒâ–ƒâ–‚â–…â–â–‡â–ƒâ–„â–ˆâ–‡â–‡â–†â–„â–„â–…â–†â–â–…â–‡â–‚â–„â–…â–‡â–„â–†â–…â–…â–„â–„â–ˆâ–„â–„â–„â–†
wandb:         train/mil_loss â–…â–ƒâ–…â–…â–…â–„â–…â–ƒâ–‚â–ˆâ–„â–‡â–„â–„â–„â–‚â–ƒâ–„â–ƒâ–‚â–…â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–ƒâ–„â–â–ƒâ–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–…â–â–…â–…â–ˆâ–â–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–…â–ˆâ–ˆâ–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.24132
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.88619
wandb:      eval/avg_mil_loss 0.37647
wandb:       eval/ensemble_f1 0.88619
wandb:            test/avg_f1 0.92083
wandb:      test/avg_mil_loss 0.19213
wandb:       test/ensemble_f1 0.92083
wandb:           train/avg_f1 0.89762
wandb:      train/ensemble_f1 0.89762
wandb:         train/mil_loss 0.19071
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run light-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sdxx4wcz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045935-sdxx4wcz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0o1a733f with config:
wandb: 	actor_learning_rate: 0.0003133411372288962
wandb: 	attention_dropout_p: 0.05140761383383402
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12632125029739416
wandb: 	temperature: 0.3385730978418311
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050211-0o1a733f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o1a733f
wandb: uploading history steps 107-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–„â–ƒâ–‚â–‚â–ˆâ–„â–…â–‡â–…â–â–ƒâ–„â–ƒâ–‡â–ƒâ–†â–„â–‚â–â–ƒâ–…â–‡â–†â–…â–†â–…â–ƒâ–„â–…â–ˆâ–â–†â–„â–ƒâ–†â–„â–„â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–„â–†â–†â–„â–„â–ƒâ–‡â–‡â–…â–‡â–„â–†â–†â–â–†â–ƒâ–„â–‚â–ƒâ–ˆâ–ƒâ–„â–…â–ƒâ–…â–…â–‚â–„â–ƒâ–„â–„â–†â–ƒâ–â–„â–…â–…
wandb:       eval/ensemble_f1 â–„â–†â–ƒâ–ƒâ–†â–ƒâ–„â–†â–‡â–†â–„â–ƒâ–…â–ƒâ–â–ƒâ–‡â–„â–…â–ƒâ–…â–…â–ƒâ–…â–†â–ƒâ–„â–„â–‚â–‚â–‡â–‡â–…â–„â–„â–„â–ƒâ–„â–ˆâ–‚
wandb:           train/avg_f1 â–„â–‚â–‡â–†â–…â–‚â–ƒâ–…â–ƒâ–…â–„â–…â–â–‚â–…â–…â–†â–…â–ƒâ–‡â–„â–†â–†â–„â–ˆâ–†â–‚â–„â–ƒâ–„â–ƒâ–„â–…â–†â–ƒâ–‚â–„â–…â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–‚â–†â–ˆâ–„â–‚â–ƒâ–„â–ƒâ–„â–‚â–„â–„â–ƒâ–â–â–‚â–…â–„â–‚â–…â–…â–„â–†â–‚â–ƒâ–„â–†â–…â–â–„â–‚â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–…
wandb:         train/mil_loss â–‚â–„â–‡â–†â–‡â–†â–„â–„â–†â–‡â–„â–ˆâ–â–†â–„â–‚â–„â–…â–†â–‚â–†â–ƒâ–†â–„â–‚â–ˆâ–„â–„â–‚â–†â–„â–‚â–…â–†â–ƒâ–…â–„â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93766
wandb: best/eval_avg_mil_loss 0.18848
wandb:  best/eval_ensemble_f1 0.93766
wandb:            eval/avg_f1 0.89384
wandb:      eval/avg_mil_loss 0.44002
wandb:       eval/ensemble_f1 0.89384
wandb:           train/avg_f1 0.88858
wandb:      train/ensemble_f1 0.88858
wandb:         train/mil_loss 0.20392
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dainty-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o1a733f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050211-0o1a733f/logs
wandb: ERROR Run 0o1a733f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ahebiqxd with config:
wandb: 	actor_learning_rate: 0.00013157033201442432
wandb: 	attention_dropout_p: 0.11333383003596686
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03184492454298582
wandb: 	temperature: 4.419082873170228
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050354-ahebiqxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahebiqxd
wandb: uploading history steps 99-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–†â–ˆâ–†â–…â–…â–ƒâ–…â–ƒâ–„â–„â–…â–‚â–„â–…â–…â–â–ƒâ–…â–„â–‚â–…â–…â–‚â–„â–ƒâ–„â–†â–„â–„â–ƒâ–†â–†â–…â–ƒâ–ƒâ–…â–„â–†
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‡â–â–‚â–‚â–…â–ƒâ–„â–ˆâ–„â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–†â–„â–„â–†â–„â–„â–…â–†â–‚â–ƒâ–†â–‚â–„â–‚â–ƒ
wandb:       eval/ensemble_f1 â–†â–†â–„â–â–„â–„â–ˆâ–…â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–…â–…â–‚â–†â–„â–…â–ƒâ–†â–…â–ƒâ–„â–†â–…â–‚â–†â–„â–„â–„â–„â–†â–ˆâ–†â–â–†â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–„â–ˆâ–„â–„â–…â–‡â–…â–ˆâ–ˆâ–„â–„â–‚â–†â–‡â–†â–‡â–†â–…â–†â–„â–…â–ˆâ–„â–…â–ƒâ–‡â–ˆâ–…â–…â–…â–‡â–„â–…â–†â–†â–†â–…â–
wandb:      train/ensemble_f1 â–„â–…â–„â–„â–…â–„â–ƒâ–‡â–†â–…â–†â–ˆâ–…â–ƒâ–…â–ˆâ–„â–‚â–‡â–‡â–†â–…â–†â–†â–†â–…â–„â–…â–ˆâ–…â–ƒâ–…â–„â–†â–…â–†â–†â–…â–…â–
wandb:         train/mil_loss â–ƒâ–…â–…â–…â–ƒâ–ƒâ–„â–…â–…â–…â–…â–…â–„â–„â–‡â–…â–…â–„â–…â–ƒâ–„â–„â–…â–†â–†â–„â–„â–‡â–„â–â–ƒâ–…â–„â–ƒâ–„â–…â–„â–†â–ƒâ–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–ˆâ–…â–â–â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–…â–…â–…â–â–…â–…â–â–…â–…â–…â–ˆâ–â–…â–â–…â–…â–â–…â–ˆâ–…â–ˆâ–…â–…â–…â–ˆâ–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.22078
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.90786
wandb:      eval/avg_mil_loss 0.30061
wandb:       eval/ensemble_f1 0.90786
wandb:            test/avg_f1 0.89036
wandb:      test/avg_mil_loss 0.24385
wandb:       test/ensemble_f1 0.89036
wandb:           train/avg_f1 0.86979
wandb:      train/ensemble_f1 0.86979
wandb:         train/mil_loss 0.26223
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glad-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahebiqxd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050354-ahebiqxd/logs
wandb: Agent Starting Run: lrxk5owb with config:
wandb: 	actor_learning_rate: 0.0005095351393627092
wandb: 	attention_dropout_p: 0.12358024986588428
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8860920621505756
wandb: 	temperature: 5.548725696104739
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050543-lrxk5owb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lrxk5owb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–‚â–â–…â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–…â–‡â–†â–…â–ˆâ–‡â–ˆâ–…â–â–…â–†â–†â–…â–†â–‚â–„â–‡â–‡â–†â–…â–†â–†â–†â–„â–†â–†â–ˆâ–†â–„â–„â–…â–‡â–†â–…â–†â–ˆâ–ˆâ–ˆâ–†
wandb:      eval/avg_mil_loss â–†â–„â–„â–„â–„â–ƒâ–„â–†â–„â–†â–ƒâ–„â–„â–„â–†â–„â–„â–„â–ƒâ–„â–„â–†â–…â–ˆâ–ˆâ–„â–â–ƒâ–†â–…â–…â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–…â–…â–†â–†â–ˆâ–ˆâ–…â–‡â–â–…â–†â–†â–…â–…â–‡â–†â–†â–†â–…â–ˆâ–†â–…â–†â–„â–„â–†â–†â–„â–…â–…â–ˆâ–†â–†â–…â–†â–†â–ˆâ–†â–†
wandb:           train/avg_f1 â–â–…â–ƒâ–â–ƒâ–‡â–…â–…â–„â–ƒâ–‡â–†â–‚â–…â–†â–…â–ƒâ–†â–„â–„â–‡â–…â–â–†â–ˆâ–…â–„â–†â–…â–ƒâ–‡â–ƒâ–‡â–†â–…â–‡â–„â–ƒâ–„â–ˆ
wandb:      train/ensemble_f1 â–‡â–…â–â–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–†â–ƒâ–„â–†â–„â–ƒâ–„â–‚â–†â–ˆâ–ƒâ–„â–ƒâ–‡â–…â–ƒâ–„â–…â–â–„â–…â–„â–…â–„â–…â–ƒâ–†â–†â–ƒâ–†â–„
wandb:         train/mil_loss â–„â–‚â–„â–†â–ƒâ–ˆâ–„â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–…â–„â–„â–‚â–„â–â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–„â–„â–â–ƒâ–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–â–ƒâ–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–â–†â–ƒâ–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92281
wandb: best/eval_avg_mil_loss 0.25706
wandb:  best/eval_ensemble_f1 0.92281
wandb:            eval/avg_f1 0.89312
wandb:      eval/avg_mil_loss 0.32391
wandb:       eval/ensemble_f1 0.89312
wandb:           train/avg_f1 0.90169
wandb:      train/ensemble_f1 0.90169
wandb:         train/mil_loss 0.88008
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lrxk5owb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050543-lrxk5owb/logs
wandb: ERROR Run lrxk5owb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5f44ai80 with config:
wandb: 	actor_learning_rate: 0.000325477408250129
wandb: 	attention_dropout_p: 0.25994503861954
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5371744432008799
wandb: 	temperature: 8.69342629987569
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050710-5f44ai80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5f44ai80
wandb: uploading history steps 112-126, summary; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–…â–â–â–†â–ˆâ–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–‚â–„â–â–„â–ƒâ–†â–†â–…â–„â–‡â–„â–…â–ƒâ–…â–ƒâ–ˆâ–ƒâ–„â–â–†â–‚â–‚â–„â–‚â–†â–„â–„â–„â–ƒâ–†â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–ƒâ–â–†â–…â–†â–ƒâ–…â–„â–ƒâ–â–â–‚â–†â–„â–‚â–ƒâ–„â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–â–…â–‚â–„â–‚â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–‚â–‚â–†â–„â–ƒâ–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–†â–ƒâ–…â–‡â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–‚â–†â–‚â–ƒâ–„â–‚â–ƒâ–†â–ˆâ–…â–„â–ƒâ–ƒâ–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–„â–…â–…â–ˆâ–„â–†â–†â–â–„â–…â–‡â–ƒâ–â–†â–†â–‡â–…â–‡â–„â–„â–ˆâ–†â–†â–…â–„â–„â–…â–…â–‡â–†â–…â–…â–†â–„â–‡â–…â–†â–…â–„
wandb:      train/ensemble_f1 â–ƒâ–…â–„â–…â–†â–„â–…â–„â–ƒâ–…â–…â–„â–â–†â–ƒâ–†â–…â–…â–…â–…â–…â–…â–‡â–ˆâ–…â–„â–…â–„â–„â–‡â–…â–…â–†â–‡â–†â–‡â–…â–†â–…â–‡
wandb:         train/mil_loss â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–…â–ˆâ–„â–…â–…â–†â–„â–ƒâ–…â–†â–„â–†â–…â–„â–†â–‡â–„â–„â–„â–„â–‚â–‚â–ƒâ–‚â–â–ƒâ–‡â–â–ƒâ–â–‚â–„â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–ˆâ–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–ƒâ–…â–…â–…â–…â–…â–‡â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.26531
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.88198
wandb:      eval/avg_mil_loss 0.34829
wandb:       eval/ensemble_f1 0.88198
wandb:            test/avg_f1 0.89399
wandb:      test/avg_mil_loss 0.26064
wandb:       test/ensemble_f1 0.89399
wandb:           train/avg_f1 0.89386
wandb:      train/ensemble_f1 0.89386
wandb:         train/mil_loss 2.23336
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5f44ai80
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050710-5f44ai80/logs
wandb: Agent Starting Run: ieshku8u with config:
wandb: 	actor_learning_rate: 8.256782237222594e-05
wandb: 	attention_dropout_p: 0.21180393724278648
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08653856123697168
wandb: 	temperature: 7.80095062808781
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050930-ieshku8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ieshku8u
wandb: uploading wandb-summary.json
wandb: uploading history steps 104-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–…â–†â–ƒâ–ƒâ–…â–†â–‚â–…â–„â–ˆâ–„â–ˆâ–„â–„â–‡â–„â–„â–…â–ƒâ–‚â–„â–â–„â–ƒâ–„â–ƒâ–…â–‡â–‚â–ˆâ–†â–‚â–…â–â–†â–ƒâ–†â–„â–…â–„
wandb:      eval/avg_mil_loss â–‡â–„â–‚â–†â–‚â–ƒâ–…â–„â–…â–„â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–‚â–â–‡â–‚â–‚â–ƒâ–‚â–‚â–…â–„â–ƒâ–ˆâ–ƒâ–„â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–†
wandb:       eval/ensemble_f1 â–ƒâ–†â–…â–…â–‚â–ƒâ–ˆâ–‡â–„â–‚â–ƒâ–„â–â–ƒâ–†â–…â–„â–‡â–‡â–…â–†â–„â–„â–†â–ƒâ–ƒâ–â–…â–„â–†â–†â–†â–ƒâ–„â–†â–†â–…â–„â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–ƒâ–ƒâ–„â–„â–†â–‡â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ˆâ–†â–‡â–…â–‡â–†â–„â–†â–†â–…â–†â–â–…â–„â–…â–„â–†â–‡â–ˆâ–…â–…â–‡â–‡â–…â–†â–†â–
wandb:      train/ensemble_f1 â–„â–†â–â–ƒâ–ƒâ–‡â–ƒâ–…â–ƒâ–†â–†â–†â–„â–…â–‚â–‡â–„â–…â–†â–†â–†â–†â–…â–ƒâ–†â–…â–…â–„â–†â–†â–†â–…â–…â–ˆâ–†â–„â–‡â–†â–†â–
wandb:         train/mil_loss â–†â–ˆâ–ˆâ–‡â–†â–…â–…â–‡â–…â–ƒâ–„â–†â–‚â–ƒâ–ˆâ–„â–†â–„â–ƒâ–†â–â–…â–ƒâ–„â–ƒâ–…â–â–„â–…â–†â–‚â–„â–‡â–‚â–‚â–…â–†â–ƒâ–‚â–…
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–â–ˆâ–…â–ˆâ–…â–…â–…â–â–ˆâ–ˆâ–…â–…â–…â–ˆâ–ˆâ–…â–â–…â–…â–â–ˆâ–…â–…â–…â–ˆâ–…â–â–…â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93744
wandb: best/eval_avg_mil_loss 0.24685
wandb:  best/eval_ensemble_f1 0.93744
wandb:            eval/avg_f1 0.90063
wandb:      eval/avg_mil_loss 0.37182
wandb:       eval/ensemble_f1 0.90063
wandb:            test/avg_f1 0.93494
wandb:      test/avg_mil_loss 0.1637
wandb:       test/ensemble_f1 0.93494
wandb:           train/avg_f1 0.88401
wandb:      train/ensemble_f1 0.88401
wandb:         train/mil_loss 0.33323
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run skilled-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ieshku8u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050930-ieshku8u/logs
wandb: Agent Starting Run: dxpv9rhf with config:
wandb: 	actor_learning_rate: 5.925720284160694e-05
wandb: 	attention_dropout_p: 0.4609475584589705
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8420633941556339
wandb: 	temperature: 9.73732868844049
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051109-dxpv9rhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxpv9rhf
wandb: uploading history steps 83-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–â–‡â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–„â–†â–†â–„â–„â–‡â–â–ƒâ–…â–ƒâ–ƒâ–‚â–‡â–†â–†â–…â–„â–„â–…â–†â–…â–ƒâ–…â–†â–†â–„â–†â–‚â–…â–ˆâ–‡â–„â–…â–†â–…â–…â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–â–‚â–†â–â–„â–â–ˆâ–ˆâ–â–„â–…â–„â–„â–‚â–‚â–„â–ƒâ–„â–†â–‡â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–…â–„â–‚â–‚â–â–†â–„â–…â–„â–„â–„â–ˆâ–‚
wandb:       eval/ensemble_f1 â–†â–…â–ƒâ–…â–†â–†â–‡â–â–‡â–„â–ƒâ–„â–†â–‚â–‚â–…â–‡â–…â–†â–ƒâ–„â–â–„â–…â–…â–…â–„â–…â–„â–‡â–…â–ˆâ–…â–‡â–„â–„â–ƒâ–…â–„â–„
wandb:           train/avg_f1 â–„â–‡â–‚â–…â–‡â–†â–„â–†â–…â–†â–…â–†â–ƒâ–„â–†â–…â–„â–‚â–…â–…â–‚â–ˆâ–…â–â–†â–…â–‡â–ƒâ–‡â–„â–…â–…â–ƒâ–…â–„â–ƒâ–†â–ƒâ–ˆâ–„
wandb:      train/ensemble_f1 â–‡â–‡â–ˆâ–‡â–…â–…â–†â–‡â–ƒâ–‡â–‡â–…â–†â–‡â–„â–†â–†â–†â–ƒâ–†â–‡â–â–†â–†â–…â–„â–†â–„â–„â–„â–ƒâ–†â–ƒâ–ˆâ–„â–…â–…â–†â–ƒâ–†
wandb:         train/mil_loss â–ˆâ–ƒâ–…â–†â–…â–â–„â–‡â–ƒâ–…â–‡â–„â–†â–ƒâ–„â–‡â–†â–‚â–‚â–†â–ƒâ–†â–‡â–ˆâ–ƒâ–ƒâ–‡â–„â–‡â–„â–‡â–†â–‡â–ƒâ–…â–…â–…â–„â–†â–†
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–„â–†â–ˆâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.26349
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.88631
wandb:      eval/avg_mil_loss 0.30601
wandb:       eval/ensemble_f1 0.88631
wandb:           train/avg_f1 0.89178
wandb:      train/ensemble_f1 0.89178
wandb:         train/mil_loss 0.17716
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smooth-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxpv9rhf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051109-dxpv9rhf/logs
wandb: ERROR Run dxpv9rhf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: yyr0lsqo with config:
wandb: 	actor_learning_rate: 0.0007984255220901918
wandb: 	attention_dropout_p: 0.34310215630972635
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8886710937580262
wandb: 	temperature: 2.6674794847963765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051252-yyr0lsqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yyr0lsqo
wandb: uploading history steps 42-55, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–â–„â–†â–…â–ˆâ–„â–ƒâ–ƒâ–†â–‚â–…â–„â–†â–ˆâ–„â–…â–†â–ƒâ–„â–‚â–„â–„â–„â–ƒâ–ƒâ–„â–…â–‡â–†â–ƒâ–…â–„â–‚â–…â–ˆâ–†â–„â–„â–†â–„
wandb:      eval/avg_mil_loss â–…â–…â–…â–„â–â–…â–…â–ƒâ–‡â–…â–„â–…â–ƒâ–…â–…â–„â–ˆâ–ƒâ–†â–†â–…â–…â–ˆâ–‚â–‡â–„â–ƒâ–†â–‡â–‡â–ƒâ–ƒâ–…â–„â–„â–„â–ƒâ–„â–‡â–ƒ
wandb:       eval/ensemble_f1 â–‚â–â–„â–†â–…â–„â–ƒâ–ƒâ–ƒâ–†â–ƒâ–…â–„â–ˆâ–„â–…â–ƒâ–„â–‚â–‚â–„â–„â–ƒâ–ˆâ–ƒâ–„â–…â–‡â–†â–ƒâ–…â–„â–‚â–…â–…â–‡â–„â–„â–†â–„
wandb:           train/avg_f1 â–„â–…â–„â–ƒâ–ƒâ–…â–„â–†â–„â–„â–‡â–…â–ƒâ–…â–„â–„â–ƒâ–ƒâ–…â–…â–†â–‡â–ˆâ–†â–†â–…â–„â–„â–‚â–‡â–„â–…â–†â–…â–ƒâ–â–ƒâ–‡â–…â–„
wandb:      train/ensemble_f1 â–„â–…â–„â–ƒâ–ƒâ–†â–…â–„â–†â–„â–‡â–…â–ƒâ–…â–†â–ƒâ–ƒâ–…â–…â–…â–‡â–ˆâ–†â–†â–…â–…â–„â–‚â–‡â–…â–…â–†â–…â–ƒâ–â–ƒâ–†â–‡â–…â–„
wandb:         train/mil_loss â–…â–ˆâ–†â–ˆâ–„â–ˆâ–„â–‡â–…â–…â–ˆâ–„â–†â–…â–†â–„â–…â–†â–„â–„â–…â–…â–‡â–„â–ƒâ–„â–ƒâ–…â–„â–…â–…â–ƒâ–â–…â–ƒâ–…â–…â–‡â–†â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.24551
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.89673
wandb:      eval/avg_mil_loss 0.23284
wandb:       eval/ensemble_f1 0.89673
wandb:           train/avg_f1 0.88904
wandb:      train/ensemble_f1 0.88904
wandb:         train/mil_loss 0.23177
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run likely-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yyr0lsqo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051252-yyr0lsqo/logs
wandb: ERROR Run yyr0lsqo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qr8je4x8 with config:
wandb: 	actor_learning_rate: 1.790296783313988e-05
wandb: 	attention_dropout_p: 0.29427925770702557
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1619103076552828
wandb: 	temperature: 5.521226063813235
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051400-qr8je4x8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qr8je4x8
wandb: uploading history steps 50-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–…â–„â–†â–†â–†â–…â–„â–â–†â–…â–…â–‚â–„â–„â–„â–…â–†â–ˆâ–…â–‚â–„â–‡â–†â–‡â–…â–‡â–…â–†â–…â–‚â–†â–…â–ƒâ–†â–…â–…â–…â–†
wandb:      eval/avg_mil_loss â–„â–‡â–‚â–‡â–ƒâ–„â–ƒâ–ˆâ–†â–ƒâ–‚â–…â–‡â–ƒâ–…â–„â–ƒâ–„â–ƒâ–‚â–„â–…â–‚â–â–ƒâ–…â–…â–â–…â–ƒâ–†â–†â–â–ƒâ–†â–„â–…â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–ƒâ–‚â–†â–‡â–†â–…â–†â–‚â–‡â–†â–„â–â–…â–…â–ƒâ–…â–„â–…â–†â–â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–…â–‡â–†â–ƒâ–„â–‡â–†â–ˆ
wandb:           train/avg_f1 â–„â–…â–…â–…â–ƒâ–†â–…â–ƒâ–ˆâ–â–…â–ƒâ–„â–†â–„â–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–…â–…â–ƒâ–ƒâ–„â–…â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–„â–„â–…
wandb:      train/ensemble_f1 â–„â–…â–…â–…â–ƒâ–ˆâ–â–†â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–…â–…â–‡â–â–„â–ƒâ–…â–ƒâ–„â–„â–…â–…â–„â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–…â–„â–ƒâ–…â–„â–„â–…
wandb:         train/mil_loss â–…â–†â–ƒâ–…â–ƒâ–†â–„â–‚â–†â–ˆâ–†â–„â–ƒâ–ˆâ–„â–…â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–…â–…â–‚â–…â–‚â–ƒâ–‚â–…â–‚â–‡â–‚â–ƒâ–â–ƒâ–„â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94837
wandb: best/eval_avg_mil_loss 0.2153
wandb:  best/eval_ensemble_f1 0.94837
wandb:            eval/avg_f1 0.92634
wandb:      eval/avg_mil_loss 0.27122
wandb:       eval/ensemble_f1 0.92634
wandb:           train/avg_f1 0.90453
wandb:      train/ensemble_f1 0.90453
wandb:         train/mil_loss 0.35368
wandb:      train/policy_loss -0.13234
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.13234
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run volcanic-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qr8je4x8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051400-qr8je4x8/logs
wandb: ERROR Run qr8je4x8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jdlmcm53 with config:
wandb: 	actor_learning_rate: 4.255582177553559e-06
wandb: 	attention_dropout_p: 0.372890525849412
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1791435051982737
wandb: 	temperature: 4.216744433189375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051507-jdlmcm53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdlmcm53
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ƒâ–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–â–ƒâ–‚â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–„â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–ƒâ–†â–„â–‚â–‚â–…â–†â–‚â–…â–ƒâ–‡â–…â–„â–„â–†â–ˆâ–…â–„â–…â–‡â–‡â–„â–†â–‚â–…â–†â–†â–‚â–…â–…â–â–‚â–‚â–ƒâ–‚â–„â–„â–ƒ
wandb:      eval/avg_mil_loss â–…â–…â–†â–„â–…â–„â–…â–…â–…â–‚â–…â–ƒâ–ƒâ–…â–†â–â–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–†â–„â–†â–ˆâ–„â–„â–ƒâ–…â–ˆâ–„â–ƒâ–ˆâ–†â–†â–†
wandb:       eval/ensemble_f1 â–„â–„â–„â–…â–ƒâ–ˆâ–ƒâ–†â–‚â–‚â–…â–„â–â–…â–„â–„â–‡â–†â–‡â–„â–ƒâ–…â–„â–ƒâ–…â–‚â–‚â–…â–ƒâ–„â–…â–„â–…â–ƒâ–„â–„â–‚â–‚â–‚â–„
wandb:           train/avg_f1 â–…â–‡â–‡â–†â–†â–ˆâ–†â–„â–†â–…â–„â–‡â–ˆâ–†â–„â–…â–†â–†â–†â–ƒâ–…â–…â–„â–†â–„â–â–…â–†â–ƒâ–„â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–†â–…
wandb:      train/ensemble_f1 â–…â–†â–‡â–…â–…â–ƒâ–…â–ˆâ–…â–…â–‡â–‡â–…â–…â–†â–ƒâ–‡â–…â–„â–…â–â–…â–„â–ƒâ–ƒâ–…â–„â–…â–†â–ƒâ–„â–„â–ƒâ–…â–„â–…â–…â–ƒâ–ƒâ–„
wandb:         train/mil_loss â–‡â–†â–†â–†â–ˆâ–ˆâ–‡â–†â–…â–†â–…â–„â–…â–…â–†â–…â–…â–…â–…â–…â–ƒâ–„â–„â–„â–„â–„â–…â–…â–„â–…â–â–…â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–â–„
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–†â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94499
wandb: best/eval_avg_mil_loss 0.239
wandb:  best/eval_ensemble_f1 0.94499
wandb:            eval/avg_f1 0.90498
wandb:      eval/avg_mil_loss 0.27178
wandb:       eval/ensemble_f1 0.90498
wandb:           train/avg_f1 0.8952
wandb:      train/ensemble_f1 0.8952
wandb:         train/mil_loss 0.21977
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run skilled-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdlmcm53
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051507-jdlmcm53/logs
wandb: ERROR Run jdlmcm53 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: k0tjccjf with config:
wandb: 	actor_learning_rate: 2.9394101612829133e-05
wandb: 	attention_dropout_p: 0.25201742879562855
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7323285584821126
wandb: 	temperature: 8.336652917295943
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051747-k0tjccjf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0tjccjf
wandb: uploading history steps 103-120, summary; uploading wandb-summary.json
wandb: uploading history steps 121-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–‡â–…â–‚â–ƒâ–†â–†â–†â–ƒâ–…â–‚â–ƒâ–‚â–…â–â–„â–„â–â–…â–…â–…â–„â–‚â–…â–‡â–â–‚â–ˆâ–ƒâ–ƒâ–‚â–†â–ƒâ–…â–ƒâ–…â–ƒâ–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–…â–„â–„â–„â–„â–â–‡â–ƒâ–…â–…â–„â–„â–ƒâ–„â–…â–ƒâ–„â–ƒâ–†â–ˆâ–„â–…â–‚â–‚â–„â–ƒâ–„â–…â–…â–„â–…â–…â–„â–†â–„â–‡â–ƒ
wandb:       eval/ensemble_f1 â–‡â–„â–„â–†â–ƒâ–†â–…â–„â–‚â–†â–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–†â–…â–„â–…â–„â–„â–„â–â–…â–…â–‚â–†â–‡â–†â–„â–ƒâ–„â–†â–ƒâ–…â–ƒâ–†â–ˆâ–†
wandb:           train/avg_f1 â–…â–†â–…â–‡â–‡â–‡â–†â–ˆâ–†â–ˆâ–†â–†â–…â–†â–…â–ƒâ–„â–…â–…â–†â–ƒâ–†â–â–„â–…â–…â–„â–†â–…â–ƒâ–„â–„â–‚â–…â–„â–†â–†â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–…â–„â–†â–‡â–„â–‡â–†â–‡â–ˆâ–†â–ƒâ–„â–†â–‡â–…â–„â–â–†â–‡â–†â–‡â–…â–…â–…â–†â–ƒâ–…â–ƒâ–ˆâ–…â–„â–ƒâ–„
wandb:         train/mil_loss â–†â–†â–ˆâ–…â–â–†â–„â–„â–â–ƒâ–…â–„â–…â–‚â–„â–ƒâ–…â–‚â–ƒâ–‚â–„â–„â–†â–„â–„â–…â–ƒâ–„â–„â–…â–„â–„â–„â–ƒâ–„â–‚â–ƒâ–…â–‚â–…
wandb:      train/policy_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ˆâ–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93725
wandb: best/eval_avg_mil_loss 0.1728
wandb:  best/eval_ensemble_f1 0.93725
wandb:            eval/avg_f1 0.91898
wandb:      eval/avg_mil_loss 0.24496
wandb:       eval/ensemble_f1 0.91898
wandb:           train/avg_f1 0.8936
wandb:      train/ensemble_f1 0.8936
wandb:         train/mil_loss 0.28459
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run icy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0tjccjf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051747-k0tjccjf/logs
wandb: ERROR Run k0tjccjf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jd1sifgq with config:
wandb: 	actor_learning_rate: 2.335540986226972e-05
wandb: 	attention_dropout_p: 0.1286680784862908
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 162
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10357738805717263
wandb: 	temperature: 0.06657942494378455
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051941-jd1sifgq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jd1sifgq
wandb: uploading history steps 124-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–‡â–†â–†â–†â–„â–„â–…â–†â–†â–ƒâ–†â–‡â–„â–†â–†â–„â–†â–ˆâ–†â–„â–†â–„â–„â–„â–„â–â–…â–…â–„â–‡â–…â–ƒâ–„â–„â–â–…â–‚â–„
wandb:      eval/avg_mil_loss â–…â–‚â–…â–ƒâ–„â–ƒâ–…â–„â–†â–ƒâ–â–…â–„â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–‡â–…â–ƒâ–…â–…â–…â–…â–†â–„â–†â–„â–†â–‡â–„â–ˆâ–„â–„â–†â–‡â–†â–‡
wandb:       eval/ensemble_f1 â–‡â–†â–…â–†â–†â–…â–‡â–„â–„â–†â–†â–ˆâ–„â–„â–„â–…â–†â–„â–„â–„â–„â–…â–‚â–…â–ƒâ–ƒâ–…â–â–…â–…â–„â–…â–‡â–…â–…â–…â–ƒâ–â–„â–‡
wandb:           train/avg_f1 â–‡â–‡â–„â–…â–‡â–†â–†â–‡â–†â–ˆâ–‡â–†â–‡â–†â–†â–†â–‡â–…â–…â–…â–ˆâ–†â–…â–…â–…â–…â–‡â–…â–†â–„â–„â–†â–ƒâ–†â–ƒâ–‚â–„â–†â–â–„
wandb:      train/ensemble_f1 â–†â–…â–„â–…â–…â–‡â–‡â–…â–…â–ˆâ–†â–‡â–…â–…â–…â–†â–†â–…â–‡â–†â–†â–„â–„â–„â–…â–„â–…â–†â–†â–ƒâ–„â–„â–ƒâ–ƒâ–…â–„â–…â–…â–â–ƒ
wandb:         train/mil_loss â–…â–ˆâ–†â–…â–…â–…â–‡â–†â–„â–„â–†â–…â–…â–„â–„â–ƒâ–„â–†â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–ƒâ–„â–â–‚â–‚â–‚â–â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93361
wandb: best/eval_avg_mil_loss 0.19931
wandb:  best/eval_ensemble_f1 0.93361
wandb:            eval/avg_f1 0.89767
wandb:      eval/avg_mil_loss 0.25717
wandb:       eval/ensemble_f1 0.89767
wandb:           train/avg_f1 0.88576
wandb:      train/ensemble_f1 0.88576
wandb:         train/mil_loss 0.23622
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run playful-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jd1sifgq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051941-jd1sifgq/logs
wandb: ERROR Run jd1sifgq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wch2sjtx with config:
wandb: 	actor_learning_rate: 7.397642087625819e-05
wandb: 	attention_dropout_p: 0.28297057536052483
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7565764447327531
wandb: 	temperature: 3.8716918128963695
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052211-wch2sjtx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wch2sjtx
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–‚â–ƒâ–„â–†â–„â–…â–†â–„â–„â–…â–…â–‡â–…â–„â–†â–†â–…â–‚â–†â–â–ƒâ–†â–†â–ˆâ–…â–…â–†â–ƒâ–‡â–ƒâ–ƒâ–‡â–…â–â–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–‡â–†â–ƒâ–†â–‡â–ƒâ–‚â–ˆâ–‚â–„â–„â–„â–â–…â–„â–…â–ƒâ–‡â–‚â–„â–†â–ƒâ–‚â–…â–‡â–ƒâ–‚â–„â–‚â–‡â–‡â–…â–ƒâ–„â–‡â–‚â–ƒâ–†â–…â–„
wandb:       eval/ensemble_f1 â–…â–†â–…â–‚â–…â–„â–„â–…â–ƒâ–…â–‡â–„â–„â–…â–„â–†â–†â–…â–†â–‚â–„â–†â–ƒâ–…â–…â–†â–„â–ˆâ–„â–ƒâ–„â–…â–‡â–ƒâ–ƒâ–…â–ƒâ–…â–â–„
wandb:           train/avg_f1 â–…â–†â–„â–„â–†â–ƒâ–„â–‡â–ƒâ–†â–„â–„â–…â–ƒâ–…â–„â–„â–ƒâ–ˆâ–…â–‚â–ƒâ–…â–†â–ƒâ–…â–…â–‚â–…â–†â–…â–…â–…â–‡â–„â–â–…â–‚â–…â–‚
wandb:      train/ensemble_f1 â–„â–„â–…â–„â–†â–„â–…â–‡â–†â–…â–…â–…â–…â–‡â–„â–„â–„â–ƒâ–ˆâ–„â–†â–ƒâ–…â–ƒâ–ƒâ–„â–…â–…â–„â–‚â–…â–„â–‚â–…â–‡â–ˆâ–…â–â–‚â–„
wandb:         train/mil_loss â–„â–…â–„â–‚â–‡â–…â–ƒâ–„â–ˆâ–ƒâ–ˆâ–„â–â–ƒâ–…â–‚â–…â–„â–…â–…â–‚â–„â–„â–‚â–‚â–„â–â–„â–â–ƒâ–„â–â–„â–ƒâ–‚â–…â–„â–ƒâ–…â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–†â–…â–…â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93032
wandb: best/eval_avg_mil_loss 0.26859
wandb:  best/eval_ensemble_f1 0.93032
wandb:            eval/avg_f1 0.88992
wandb:      eval/avg_mil_loss 0.28059
wandb:       eval/ensemble_f1 0.88992
wandb:           train/avg_f1 0.87941
wandb:      train/ensemble_f1 0.87941
wandb:         train/mil_loss 0.1983
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wch2sjtx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052211-wch2sjtx/logs
wandb: ERROR Run wch2sjtx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tjotbtg0 with config:
wandb: 	actor_learning_rate: 0.0004594060718657372
wandb: 	attention_dropout_p: 0.20854230779824512
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.057852301719627075
wandb: 	temperature: 4.378795314763131
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052343-tjotbtg0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjotbtg0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–…â–‡â–†â–„â–…â–‡â–„â–‡â–…â–„â–…â–…â–…â–‡â–„â–‡â–†â–‡â–„â–…â–…â–‚â–†â–â–ƒâ–ƒâ–‡â–ƒâ–„â–†â–„â–ˆâ–‡â–ƒâ–…â–‚â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–„â–‚â–‚â–â–â–‚â–„â–‚â–…â–‚â–‚â–…â–ƒâ–â–â–„â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–†â–…â–…â–‡â–„â–ˆâ–„â–ƒâ–„â–‚â–„â–ƒâ–†â–…â–‡â–ƒ
wandb:       eval/ensemble_f1 â–‡â–†â–…â–†â–…â–ƒâ–‡â–ƒâ–ˆâ–„â–„â–…â–ˆâ–†â–†â–ƒâ–ˆâ–‚â–†â–ˆâ–„â–„â–‚â–â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–â–„â–„â–…â–†â–â–†â–†â–…â–‚
wandb:           train/avg_f1 â–‡â–ˆâ–…â–†â–…â–…â–…â–†â–‡â–…â–‡â–ˆâ–â–„â–†â–†â–â–†â–…â–†â–…â–…â–ƒâ–‚â–†â–„â–…â–†â–†â–„â–ƒâ–ƒâ–…â–‚â–„â–‚â–„â–â–ƒâ–‚
wandb:      train/ensemble_f1 â–‡â–…â–†â–ˆâ–†â–‡â–ˆâ–†â–†â–‡â–‡â–ƒâ–…â–ˆâ–†â–…â–„â–†â–†â–…â–†â–†â–†â–ƒâ–…â–†â–‡â–ƒâ–†â–„â–…â–ƒâ–…â–ƒâ–ƒâ–â–„â–ƒâ–„â–ƒ
wandb:         train/mil_loss â–‡â–ˆâ–ƒâ–…â–†â–…â–…â–†â–…â–…â–…â–†â–…â–†â–…â–†â–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–†â–†â–…â–‚â–†â–‚â–„â–…â–ƒâ–â–…â–„â–‚â–…â–‚â–‚â–…
wandb:      train/policy_loss â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92653
wandb: best/eval_avg_mil_loss 0.22549
wandb:  best/eval_ensemble_f1 0.92653
wandb:            eval/avg_f1 0.87218
wandb:      eval/avg_mil_loss 0.30013
wandb:       eval/ensemble_f1 0.87218
wandb:           train/avg_f1 0.87953
wandb:      train/ensemble_f1 0.87953
wandb:         train/mil_loss 0.25247
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run warm-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tjotbtg0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052343-tjotbtg0/logs
wandb: ERROR Run tjotbtg0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: x6c473ej with config:
wandb: 	actor_learning_rate: 0.00015368120197235103
wandb: 	attention_dropout_p: 0.23452439511081904
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0408369405933412
wandb: 	temperature: 6.115067076215411
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052552-x6c473ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x6c473ej
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–„â–ƒâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–‚â–„â–„â–†â–…â–†â–„â–…â–„â–ˆâ–„â–„â–†â–ˆâ–…â–…â–†â–…â–„â–„â–…â–ƒâ–†â–ƒâ–…â–„â–ƒâ–†â–„â–‡â–…â–…â–„â–„â–â–†â–…â–ƒ
wandb:      eval/avg_mil_loss â–‡â–…â–…â–†â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–‚â–‡â–â–‚â–„â–„â–†â–ƒâ–ƒâ–„â–†â–‚â–‡â–…â–â–†â–…â–†â–ƒâ–ƒâ–„â–ƒâ–ˆâ–‡â–„â–‡â–‡â–‡â–„â–ˆ
wandb:       eval/ensemble_f1 â–„â–…â–‚â–„â–„â–…â–„â–†â–†â–„â–…â–ˆâ–…â–†â–†â–…â–…â–†â–…â–ˆâ–„â–„â–„â–…â–ƒâ–„â–†â–ƒâ–ƒâ–…â–…â–ƒâ–†â–„â–ˆâ–…â–„â–„â–â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–ˆâ–ˆâ–ƒâ–…â–„â–‡â–…â–„â–„â–ƒâ–†â–„â–‚â–„â–„â–â–„â–„â–…â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–ƒâ–ˆâ–‚â–„â–ƒâ–…â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–…â–†â–‚â–„â–ˆâ–…â–…â–„â–‡â–„â–ƒâ–„â–„â–ƒâ–†â–„â–…â–â–„â–ƒâ–…â–ƒâ–†â–…â–ƒâ–‚â–‚â–ƒâ–…â–„â–ƒâ–ƒâ–‚â–„â–„â–†â–ƒâ–…â–ƒ
wandb:         train/mil_loss â–‡â–„â–…â–ƒâ–‡â–ƒâ–†â–‡â–†â–†â–„â–„â–†â–‚â–…â–†â–‡â–ˆâ–…â–†â–…â–‡â–†â–†â–„â–…â–…â–„â–„â–†â–„â–ƒâ–ƒâ–„â–ƒâ–…â–…â–ƒâ–â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–â–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–â–…â–ˆâ–…â–â–ˆâ–…â–ˆâ–ˆâ–â–…â–ˆâ–â–ˆâ–…â–…â–â–…â–â–…â–ˆâ–…â–â–…â–…â–â–â–ˆâ–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.255
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.89296
wandb:      eval/avg_mil_loss 0.33469
wandb:       eval/ensemble_f1 0.89296
wandb:            test/avg_f1 0.91594
wandb:      test/avg_mil_loss 0.24592
wandb:       test/ensemble_f1 0.91594
wandb:           train/avg_f1 0.89413
wandb:      train/ensemble_f1 0.89413
wandb:         train/mil_loss 0.34102
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swift-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x6c473ej
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052552-x6c473ej/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1cb5e482 with config:
wandb: 	actor_learning_rate: 0.0001231547552155448
wandb: 	attention_dropout_p: 0.16480834970344127
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0499544467014672
wandb: 	temperature: 4.703243829583058
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052705-1cb5e482
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cb5e482
wandb: uploading history steps 80-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–â–†â–„â–ƒâ–‚â–…â–ƒâ–‚â–…â–ƒâ–‚â–„â–‡â–ˆâ–†â–†â–ƒâ–ƒâ–„â–…â–‡â–…â–‚â–ƒâ–„â–ƒâ–…â–†â–†â–ƒâ–…â–„â–‡â–‡â–ƒâ–‚â–„â–†â–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–‡â–‚â–„â–â–‚â–…â–…â–‡â–„â–„â–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–‚â–„â–ˆâ–ƒâ–‚â–ƒâ–†â–…â–ƒâ–„â–‚â–ƒâ–„â–‡â–†â–ƒâ–‡â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‡â–…â–†â–‚â–†â–†â–„â–…â–‚â–‡â–ƒâ–†â–†â–ƒâ–ˆâ–†â–…â–ƒâ–ƒâ–†â–ˆâ–†â–„â–ƒâ–ˆâ–„â–…â–ƒâ–†â–†â–…â–‡â–‡â–â–ƒâ–‚â–…â–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‚â–‡â–ƒâ–…â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–…â–ˆâ–„â–†â–„â–ˆâ–†â–„â–„â–†â–â–‚â–ˆâ–…â–‡â–†â–…â–…â–…â–†â–„â–…â–ƒâ–ƒâ–ƒâ–†â–†â–„â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–‡â–†â–…â–„â–„â–†â–†â–‡â–†â–†â–…â–…â–ˆâ–„â–ˆâ–„â–ƒâ–‡â–‡â–ˆâ–†â–ˆâ–„â–†â–„â–†â–…â–‡â–…â–â–„â–†â–‡â–‡â–„â–ƒâ–†â–…â–†
wandb:         train/mil_loss â–„â–„â–‡â–…â–‡â–†â–„â–†â–‡â–„â–†â–„â–‡â–†â–‡â–…â–…â–…â–ƒâ–ƒâ–ˆâ–ˆâ–ƒâ–…â–„â–ƒâ–†â–†â–†â–†â–†â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–â–…â–†
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–†â–„â–ˆâ–„â–„â–„â–„â–„â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–‡â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.24398
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.92223
wandb:      eval/avg_mil_loss 0.23268
wandb:       eval/ensemble_f1 0.92223
wandb:            test/avg_f1 0.90521
wandb:      test/avg_mil_loss 0.25045
wandb:       test/ensemble_f1 0.90521
wandb:           train/avg_f1 0.89523
wandb:      train/ensemble_f1 0.89523
wandb:         train/mil_loss 0.46668
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run winter-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cb5e482
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052705-1cb5e482/logs
wandb: Agent Starting Run: d756c8nk with config:
wandb: 	actor_learning_rate: 0.0001370036787979542
wandb: 	attention_dropout_p: 0.0998023843991172
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 61
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.021378549717097628
wandb: 	temperature: 5.715601727035301
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052839-d756c8nk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d756c8nk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–„â–‚â–„â–†â–ƒâ–â–„â–…â–‡â–‚â–†â–…â–†â–‡â–ƒâ–†â–‚â–„â–„â–…â–‡â–†â–†â–ƒâ–…â–ƒâ–ˆâ–‡â–‡â–‡â–…â–„â–…â–„â–†â–‚â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–…â–ƒâ–„â–…â–…â–‚â–‚â–†â–„â–…â–„â–‚â–‚â–â–…â–†â–„â–…â–†â–ƒâ–†â–„â–â–„â–…â–ƒâ–ƒâ–â–‚â–‚â–„â–…â–â–ƒâ–ˆâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–‡â–…â–‡â–„â–†â–†â–ƒâ–‚â–„â–ƒâ–„â–†â–‡â–‚â–†â–â–‡â–„â–†â–„â–ƒâ–„â–…â–‡â–„â–…â–ƒâ–ˆâ–‡â–„â–‡â–‡â–…â–„â–ƒâ–„â–„â–†â–ƒ
wandb:           train/avg_f1 â–„â–…â–ƒâ–„â–‚â–…â–ƒâ–‚â–†â–†â–ˆâ–„â–„â–†â–„â–‡â–â–†â–ƒâ–…â–ƒâ–…â–…â–â–„â–ˆâ–ƒâ–…â–…â–ƒâ–‡â–„â–„â–ƒâ–„â–†â–„â–„â–…â–‡
wandb:      train/ensemble_f1 â–…â–„â–…â–„â–…â–‚â–…â–†â–…â–ƒâ–†â–†â–†â–ˆâ–„â–…â–ƒâ–†â–â–â–…â–†â–ƒâ–…â–…â–„â–‚â–„â–…â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–„â–…â–„â–…â–†
wandb:         train/mil_loss â–…â–‡â–‡â–…â–„â–‡â–ˆâ–ƒâ–ˆâ–ƒâ–„â–„â–†â–‚â–ƒâ–ƒâ–ƒâ–‡â–†â–…â–ˆâ–‚â–„â–„â–…â–‚â–„â–…â–„â–ƒâ–„â–‚â–‚â–„â–â–…â–…â–‚â–„â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.1979
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.89354
wandb:      eval/avg_mil_loss 0.3017
wandb:       eval/ensemble_f1 0.89354
wandb:           train/avg_f1 0.90447
wandb:      train/ensemble_f1 0.90447
wandb:         train/mil_loss 0.27491
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run tough-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d756c8nk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052839-d756c8nk/logs
wandb: ERROR Run d756c8nk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f08s7ws4 with config:
wandb: 	actor_learning_rate: 0.00022177634746077825
wandb: 	attention_dropout_p: 0.1519385247506671
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32512200955055437
wandb: 	temperature: 3.5047643171822407
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052946-f08s7ws4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f08s7ws4
wandb: uploading wandb-summary.json
wandb: uploading history steps 101-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–â–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–â–…â–â–…â–‚â–„â–„â–„â–„â–…â–†â–ƒâ–„â–„â–‚â–…â–…â–†â–ƒâ–ƒâ–„â–ˆâ–…â–ƒâ–„â–†â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–…â–…â–â–ƒâ–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–…â–†â–ƒâ–‚â–‚â–„â–ƒâ–„â–…â–‡â–‚â–„â–ƒâ–„â–…â–‡â–„â–‡â–…â–„â–‚â–ƒâ–‡â–…â–„â–ƒâ–ƒâ–†â–†â–…â–…â–„â–â–†â–ˆâ–„â–†â–„â–‚â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–†â–…â–ƒâ–‚â–‡â–†â–…â–†â–…â–‡â–†â–ˆâ–„â–†â–…â–„â–†â–‡â–†â–†â–…â–‡â–†â–ˆâ–„â–†â–„â–…â–†â–â–„â–…â–„â–‡â–…â–…â–„â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‡â–â–‡â–‡â–†â–ƒâ–‡â–‚â–ƒâ–‡â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–†â–ƒâ–ƒâ–ˆâ–†â–ƒâ–†â–„â–…â–†â–†â–„â–‡â–‡â–†â–†â–†â–†â–„â–ƒ
wandb:      train/ensemble_f1 â–…â–ƒâ–â–‡â–…â–†â–ƒâ–„â–ƒâ–‡â–†â–†â–‡â–†â–†â–…â–‡â–†â–…â–ƒâ–…â–†â–…â–‡â–†â–…â–†â–…â–…â–†â–„â–‡â–„â–…â–ˆâ–„â–†â–…â–†â–†
wandb:         train/mil_loss â–ƒâ–†â–ƒâ–‡â–ˆâ–ƒâ–…â–‡â–†â–…â–†â–‡â–†â–†â–„â–†â–†â–‡â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‡â–…â–…â–†â–…â–ƒâ–†â–„â–ƒâ–†â–„â–†â–„â–â–…â–…â–ˆ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94099
wandb: best/eval_avg_mil_loss 0.32567
wandb:  best/eval_ensemble_f1 0.94099
wandb:            eval/avg_f1 0.89341
wandb:      eval/avg_mil_loss 0.44362
wandb:       eval/ensemble_f1 0.89341
wandb:            test/avg_f1 0.89036
wandb:      test/avg_mil_loss 0.41521
wandb:       test/ensemble_f1 0.89036
wandb:           train/avg_f1 0.88399
wandb:      train/ensemble_f1 0.88399
wandb:         train/mil_loss 0.30707
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fearless-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f08s7ws4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052946-f08s7ws4/logs
wandb: Agent Starting Run: 1cg2gcjq with config:
wandb: 	actor_learning_rate: 7.877087014915887e-05
wandb: 	attention_dropout_p: 0.2510988949124105
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1839484235918325
wandb: 	temperature: 3.567379783551312
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053135-1cg2gcjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cg2gcjq
wandb: uploading history steps 80-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–â–ƒâ–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–…â–…â–ˆ
wandb:            eval/avg_f1 â–†â–…â–„â–ƒâ–…â–‡â–†â–â–†â–…â–…â–‡â–…â–†â–„â–ˆâ–…â–„â–ƒâ–„â–…â–†â–‡â–„â–…â–†â–‡â–…â–…â–‡â–…â–…â–…â–„â–…â–â–‡â–ˆâ–ƒâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–ˆâ–…â–‡â–…â–‡â–…â–„â–ƒâ–ƒâ–ƒâ–‡â–„â–‚â–‡â–ƒâ–…â–„â–„â–‚â–„â–†â–†â–„â–â–ƒâ–†â–ƒâ–‚â–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–†â–‚
wandb:       eval/ensemble_f1 â–†â–…â–„â–„â–†â–†â–„â–‡â–…â–ˆâ–‡â–„â–†â–„â–ƒâ–„â–â–„â–‡â–…â–…â–„â–‡â–„â–„â–…â–„â–„â–…â–„â–†â–…â–†â–…â–…â–‚â–„â–†â–…â–‡
wandb:           train/avg_f1 â–â–‡â–…â–†â–„â–„â–„â–…â–„â–„â–‚â–ƒâ–ˆâ–…â–…â–…â–†â–†â–„â–…â–…â–ƒâ–„â–…â–„â–„â–‡â–ƒâ–‡â–†â–…â–„â–‚â–‡â–…â–†â–…â–…â–ƒâ–†
wandb:      train/ensemble_f1 â–â–â–„â–‡â–ƒâ–…â–ƒâ–‚â–ˆâ–…â–‡â–†â–„â–‡â–†â–„â–…â–„â–„â–‡â–†â–„â–†â–ƒâ–‡â–„â–…â–‚â–…â–‡â–…â–„â–ƒâ–‡â–‡â–…â–†â–…â–‡â–†
wandb:         train/mil_loss â–„â–…â–ƒâ–†â–…â–…â–†â–…â–„â–†â–‚â–†â–‚â–„â–„â–…â–ˆâ–„â–†â–„â–…â–ƒâ–†â–‚â–„â–…â–…â–†â–…â–…â–â–„â–…â–ƒâ–ƒâ–…â–„â–…â–„â–…
wandb:      train/policy_loss â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–ˆâ–…â–†â–ƒâ–â–…â–…â–…â–…â–…â–ƒâ–…â–…â–ƒâ–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90116
wandb: best/eval_avg_mil_loss 0.30391
wandb:  best/eval_ensemble_f1 0.90116
wandb:            eval/avg_f1 0.88642
wandb:      eval/avg_mil_loss 0.29877
wandb:       eval/ensemble_f1 0.88642
wandb:           train/avg_f1 0.86985
wandb:      train/ensemble_f1 0.86985
wandb:         train/mil_loss 3.26744
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ruby-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cg2gcjq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053135-1cg2gcjq/logs
wandb: ERROR Run 1cg2gcjq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jzzk8cf6 with config:
wandb: 	actor_learning_rate: 4.867921162845706e-06
wandb: 	attention_dropout_p: 0.1318030472286474
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08190278584262511
wandb: 	temperature: 4.940519414777996
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053314-jzzk8cf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jzzk8cf6
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 85-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–ˆâ–‡â–„â–„â–†â–„â–ƒâ–â–…â–…â–ƒâ–†â–…â–„â–…â–„â–ƒâ–„â–„â–‡â–†â–…â–‡â–…â–ˆâ–†â–â–ƒâ–„â–…â–…â–†â–…â–…â–„â–„â–„â–„
wandb:      eval/avg_mil_loss â–‚â–‚â–ˆâ–„â–…â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–…â–…â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–…â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–†â–…â–…â–…â–…â–†â–„â–„â–„â–…â–„â–†â–…â–„â–‡â–„â–„â–…â–…â–†â–‡â–†â–†â–‡â–â–…â–„â–ˆâ–†â–‡â–„â–†â–†â–ƒâ–…â–…â–…â–„â–…
wandb:           train/avg_f1 â–â–‚â–„â–‚â–ƒâ–„â–ƒâ–†â–â–…â–…â–ƒâ–„â–„â–…â–‚â–…â–‚â–ƒâ–…â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–„â–„â–†â–â–ˆâ–ƒâ–…â–ƒâ–ƒâ–‚â–…â–ƒâ–…
wandb:      train/ensemble_f1 â–‚â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–†â–‚â–„â–‡â–†â–…â–…â–†â–‡â–„â–…â–„â–„â–‚â–…â–ƒâ–…â–„â–ƒâ–…â–â–…â–‡â–â–†â–…â–ƒâ–ˆâ–†â–ƒâ–‚â–…â–‚
wandb:         train/mil_loss â–‚â–‚â–„â–‚â–…â–…â–…â–ƒâ–ƒâ–†â–…â–ƒâ–‚â–„â–‡â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–…â–„â–„â–†â–ƒâ–†â–…â–ƒâ–â–„â–†â–„â–„â–ƒâ–ƒâ–†â–„â–ˆâ–‡
wandb:      train/policy_loss â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91928
wandb: best/eval_avg_mil_loss 0.29144
wandb:  best/eval_ensemble_f1 0.91928
wandb:            eval/avg_f1 0.88198
wandb:      eval/avg_mil_loss 0.33896
wandb:       eval/ensemble_f1 0.88198
wandb:           train/avg_f1 0.88995
wandb:      train/ensemble_f1 0.88995
wandb:         train/mil_loss 1.05433
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jzzk8cf6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053314-jzzk8cf6/logs
wandb: ERROR Run jzzk8cf6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tvwvxold with config:
wandb: 	actor_learning_rate: 3.926197083652118e-05
wandb: 	attention_dropout_p: 0.27897180394775445
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14982054380568144
wandb: 	temperature: 9.410199434831776
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053442-tvwvxold
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvwvxold
wandb: uploading history steps 148-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–„â–â–‡â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–…â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–ˆâ–…â–‡â–ƒâ–…â–…â–…â–ˆâ–„â–†â–…â–„â–†â–†â–„â–„â–‡â–ˆâ–…â–ƒâ–†â–„â–…â–ƒâ–…â–ƒâ–„â–…â–†â–…â–ƒâ–…â–â–„â–ƒâ–†â–ˆâ–
wandb:      eval/avg_mil_loss â–‚â–ƒâ–‚â–ƒâ–â–‚â–…â–‚â–„â–‚â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–…â–ƒâ–„â–…â–„â–…â–„â–‚â–„â–…â–ƒâ–‡â–†â–†â–…â–‚â–ˆâ–„â–…â–…â–„â–‡â–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–†â–†â–…â–…â–ˆâ–…â–†â–†â–†â–„â–ˆâ–‡â–…â–„â–„â–…â–…â–„â–„â–‡â–‚â–†â–„â–„â–†â–…â–…â–‚â–†â–†â–‡â–†â–†â–ƒâ–ƒâ–†â–â–…
wandb:           train/avg_f1 â–†â–†â–„â–…â–‡â–‡â–…â–„â–‡â–…â–ˆâ–†â–„â–…â–ƒâ–ƒâ–‡â–†â–†â–…â–„â–…â–„â–ƒâ–…â–†â–†â–…â–„â–‚â–„â–ƒâ–‚â–ƒâ–â–„â–„â–â–â–‚
wandb:      train/ensemble_f1 â–‡â–†â–†â–†â–‡â–…â–…â–†â–†â–ˆâ–‡â–…â–ƒâ–†â–„â–„â–‡â–†â–…â–…â–„â–…â–ƒâ–…â–…â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–â–‚
wandb:         train/mil_loss â–†â–…â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–„â–‡â–ˆâ–…â–„â–‡â–ƒâ–‡â–„â–„â–ƒâ–„â–†â–…â–„â–‚â–…â–„â–‚â–ƒâ–â–â–ƒâ–ƒâ–‚â–„â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93351
wandb: best/eval_avg_mil_loss 0.21811
wandb:  best/eval_ensemble_f1 0.93351
wandb:            eval/avg_f1 0.86125
wandb:      eval/avg_mil_loss 0.33871
wandb:       eval/ensemble_f1 0.86125
wandb:           train/avg_f1 0.87329
wandb:      train/ensemble_f1 0.87329
wandb:         train/mil_loss 0.27948
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tvwvxold
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053442-tvwvxold/logs
wandb: ERROR Run tvwvxold errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: uvu8xczv with config:
wandb: 	actor_learning_rate: 0.0009944188009506194
wandb: 	attention_dropout_p: 0.26717824861108885
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 155
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3725142555045408
wandb: 	temperature: 7.468942614011382
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053739-uvu8xczv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvu8xczv
wandb: uploading history steps 127-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–…â–…â–â–‡â–…â–‡â–…â–ˆâ–…â–…â–„â–‡â–ƒâ–ƒâ–…â–‡â–ˆâ–†â–†â–†â–…â–…â–…â–â–†â–…â–ƒâ–ƒâ–‚â–ˆâ–ˆâ–„â–…â–…â–‡â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–†â–…â–‚â–…â–ˆâ–‚â–ƒâ–„â–‚â–‚â–‚â–ƒâ–…â–†â–ƒâ–„â–‚â–ƒâ–†â–â–†â–â–‚â–…â–‡â–â–ƒâ–‚â–„â–ƒâ–†â–…â–„â–â–†â–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–ƒâ–†â–‡â–…â–†â–ƒâ–â–â–â–ˆâ–‡â–„â–ƒâ–â–‚â–‡â–…â–ƒâ–†â–…â–†â–ˆâ–‡â–„â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–„â–‚â–ƒâ–‡
wandb:           train/avg_f1 â–ƒâ–ƒâ–„â–…â–â–‚â–„â–…â–‚â–†â–ƒâ–…â–…â–„â–†â–ƒâ–†â–†â–‡â–„â–†â–…â–„â–…â–…â–ˆâ–„â–â–ƒâ–ƒâ–…â–â–†â–„â–„â–„â–„â–ƒâ–„â–†
wandb:      train/ensemble_f1 â–ƒâ–…â–‚â–‚â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–„â–„â–„â–ƒâ–…â–…â–ƒâ–ˆâ–…â–‡â–„â–ƒâ–„â–â–ƒâ–…â–…â–„â–†â–„â–†â–…â–„â–…â–†â–„
wandb:         train/mil_loss â–‡â–†â–ˆâ–‡â–ˆâ–†â–ƒâ–‡â–†â–„â–†â–†â–…â–†â–…â–†â–…â–…â–„â–„â–„â–…â–„â–„â–„â–†â–„â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93007
wandb: best/eval_avg_mil_loss 0.23037
wandb:  best/eval_ensemble_f1 0.93007
wandb:            eval/avg_f1 0.91886
wandb:      eval/avg_mil_loss 0.30126
wandb:       eval/ensemble_f1 0.91886
wandb:           train/avg_f1 0.89159
wandb:      train/ensemble_f1 0.89159
wandb:         train/mil_loss 0.26489
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pretty-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvu8xczv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053739-uvu8xczv/logs
wandb: ERROR Run uvu8xczv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pfcy10i5 with config:
wandb: 	actor_learning_rate: 4.869107112794649e-06
wandb: 	attention_dropout_p: 0.09597888403813289
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09298410657013868
wandb: 	temperature: 6.47386709449575
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053957-pfcy10i5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pfcy10i5
wandb: uploading history steps 161-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–‡â–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–ˆâ–…â–ƒâ–…â–†â–…â–„â–†â–†â–‚â–†â–†â–„â–†â–„â–ƒâ–…â–…â–ƒâ–†â–ƒâ–â–†â–ƒâ–†â–‚â–ƒâ–ƒâ–‚â–„â–„â–„â–„â–ƒâ–‚â–‡â–‚â–
wandb:      eval/avg_mil_loss â–ƒâ–â–ƒâ–‚â–„â–…â–„â–ƒâ–…â–â–ƒâ–â–‚â–ƒâ–„â–ƒâ–‚â–„â–„â–„â–…â–„â–†â–‚â–„â–†â–‚â–ˆâ–ƒâ–…â–‚â–ƒâ–ƒâ–…â–…â–ƒâ–‚â–†â–…â–…
wandb:       eval/ensemble_f1 â–…â–†â–‡â–…â–‡â–ˆâ–ƒâ–…â–„â–„â–ƒâ–…â–„â–„â–†â–ƒâ–„â–„â–†â–ƒâ–…â–†â–„â–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–‚â–„â–‚â–â–‚â–‡â–„â–â–
wandb:           train/avg_f1 â–…â–ˆâ–‡â–‡â–†â–…â–…â–†â–†â–†â–‡â–‡â–…â–†â–‡â–„â–…â–„â–…â–ƒâ–†â–„â–„â–„â–â–„â–„â–…â–„â–…â–ƒâ–„â–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:      train/ensemble_f1 â–…â–‡â–‡â–ˆâ–ˆâ–†â–†â–…â–…â–†â–ˆâ–†â–…â–…â–†â–ˆâ–‡â–…â–‡â–…â–…â–…â–†â–†â–„â–…â–…â–†â–†â–ƒâ–„â–‚â–†â–„â–„â–â–…â–„â–ƒâ–‚
wandb:         train/mil_loss â–†â–ˆâ–†â–„â–†â–„â–…â–‡â–ƒâ–…â–ƒâ–ˆâ–ƒâ–„â–†â–…â–‚â–…â–„â–„â–‚â–…â–ƒâ–„â–ƒâ–‚â–â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93759
wandb: best/eval_avg_mil_loss 0.24212
wandb:  best/eval_ensemble_f1 0.93759
wandb:            eval/avg_f1 0.85751
wandb:      eval/avg_mil_loss 0.39001
wandb:       eval/ensemble_f1 0.85751
wandb:           train/avg_f1 0.88368
wandb:      train/ensemble_f1 0.88368
wandb:         train/mil_loss 0.21066
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pfcy10i5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053957-pfcy10i5/logs
wandb: ERROR Run pfcy10i5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lxsw02mz with config:
wandb: 	actor_learning_rate: 3.761697161044507e-05
wandb: 	attention_dropout_p: 0.06434157693962017
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15822994779921495
wandb: 	temperature: 0.9298262633577592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054314-lxsw02mz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lxsw02mz
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–…â–„â–‡â–…â–…â–ƒâ–…â–„â–†â–…â–„â–ˆâ–†â–…â–…â–‚â–…â–…â–â–„â–‡â–…â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–„â–‚â–†â–„â–ƒâ–„
wandb:      eval/avg_mil_loss â–„â–…â–‚â–â–â–…â–„â–â–ƒâ–ƒâ–„â–„â–‚â–â–ƒâ–„â–ƒâ–‚â–ˆâ–†â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–‚â–„â–…â–ƒâ–‡â–‡â–‡â–‚â–…â–„â–†â–‡â–†â–‡
wandb:       eval/ensemble_f1 â–ˆâ–‡â–†â–†â–ˆâ–‡â–†â–„â–…â–‡â–†â–„â–†â–„â–…â–†â–…â–â–„â–‡â–„â–ƒâ–„â–ˆâ–†â–ƒâ–‚â–†â–†â–‚â–ƒâ–†â–ƒâ–„â–â–„â–â–‚â–†â–‚
wandb:           train/avg_f1 â–ˆâ–†â–†â–ˆâ–ˆâ–‡â–†â–†â–…â–…â–†â–†â–…â–…â–†â–†â–†â–†â–…â–…â–„â–…â–…â–…â–†â–„â–…â–†â–„â–…â–…â–„â–ƒâ–…â–„â–„â–„â–ƒâ–…â–
wandb:      train/ensemble_f1 â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–†â–…â–‡â–…â–‡â–†â–†â–‡â–…â–…â–…â–…â–†â–…â–…â–„â–‡â–…â–†â–…â–„â–„â–†â–„â–„â–„â–ƒâ–„â–ƒâ–
wandb:         train/mil_loss â–‡â–ˆâ–†â–ˆâ–†â–†â–†â–‡â–‡â–ˆâ–„â–†â–…â–†â–†â–†â–„â–„â–…â–‚â–ƒâ–â–„â–ƒâ–…â–ƒâ–„â–â–‚â–„â–‚â–‚â–ƒâ–ƒâ–â–â–â–ƒâ–ƒâ–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–…â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92987
wandb: best/eval_avg_mil_loss 0.21361
wandb:  best/eval_ensemble_f1 0.92987
wandb:            eval/avg_f1 0.88271
wandb:      eval/avg_mil_loss 0.36079
wandb:       eval/ensemble_f1 0.88271
wandb:           train/avg_f1 0.87724
wandb:      train/ensemble_f1 0.87724
wandb:         train/mil_loss 0.21324
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run gallant-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lxsw02mz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054314-lxsw02mz/logs
wandb: ERROR Run lxsw02mz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: znp4l1e2 with config:
wandb: 	actor_learning_rate: 1.1212091900057902e-05
wandb: 	attention_dropout_p: 0.017087322651275327
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14752848194246548
wandb: 	temperature: 4.384300567935725
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054544-znp4l1e2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znp4l1e2
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–†â–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–†â–„â–‚â–‚â–„â–ˆâ–‚â–†â–†â–…â–†â–ˆâ–â–†â–ƒâ–„â–‚â–„â–…â–â–‚â–â–†â–‡â–…â–…â–„â–ƒâ–‚
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ˆâ–„â–†â–„â–‚â–‚â–ˆâ–„â–†â–ƒâ–‡â–â–…â–â–ƒâ–„â–†â–ˆâ–„â–„â–„â–ƒâ–â–…â–„â–ƒâ–‚â–ƒâ–†â–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–ƒâ–…â–†â–…â–„â–„â–ƒâ–„â–…â–„â–…â–„â–â–…â–†â–ƒâ–†â–„â–„â–ˆâ–ƒâ–…â–†â–ˆâ–‚â–„â–ƒâ–†â–…â–‡â–†â–ƒâ–‚â–†â–†â–ƒâ–…â–†â–„â–ƒ
wandb:           train/avg_f1 â–…â–…â–‡â–…â–ƒâ–†â–†â–„â–„â–…â–ƒâ–†â–â–†â–ƒâ–†â–„â–†â–…â–„â–ƒâ–…â–…â–†â–„â–„â–…â–†â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–‡â–†â–†â–‚â–†â–‡
wandb:      train/ensemble_f1 â–„â–„â–†â–†â–‡â–„â–ƒâ–‚â–†â–â–â–†â–ƒâ–‡â–†â–†â–†â–†â–ƒâ–†â–ˆâ–…â–…â–…â–…â–„â–†â–†â–„â–†â–ˆâ–ˆâ–ƒâ–ƒâ–…â–…â–ˆâ–…â–†â–…
wandb:         train/mil_loss â–†â–…â–†â–…â–ˆâ–‡â–…â–ˆâ–‡â–…â–‡â–…â–‡â–…â–…â–ˆâ–‡â–†â–‡â–†â–ƒâ–†â–‚â–†â–ƒâ–â–…â–‚â–‡â–„â–…â–‚â–…â–…â–…â–ƒâ–„â–ƒâ–†â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.23443
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.87511
wandb:      eval/avg_mil_loss 0.32942
wandb:       eval/ensemble_f1 0.87511
wandb:           train/avg_f1 0.90034
wandb:      train/ensemble_f1 0.90034
wandb:         train/mil_loss 0.44203
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run warm-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/znp4l1e2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054544-znp4l1e2/logs
wandb: ERROR Run znp4l1e2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kpf4c8y8 with config:
wandb: 	actor_learning_rate: 0.00030811795174924566
wandb: 	attention_dropout_p: 0.0685024825061693
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6130961715833939
wandb: 	temperature: 6.163497515172841
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054722-kpf4c8y8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kpf4c8y8
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 83-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–„â–…â–â–‡â–„â–‚â–…â–ƒâ–†â–…â–ƒâ–ˆâ–…â–…â–…â–…â–„â–†â–‡â–…â–…â–…â–‡â–†â–…â–„â–‚â–…â–„â–…â–…â–„â–â–†â–†â–„â–†â–†â–„
wandb:      eval/avg_mil_loss â–„â–„â–…â–ƒâ–†â–ˆâ–†â–ƒâ–…â–ƒâ–‡â–„â–ƒâ–â–‡â–‚â–â–„â–„â–‚â–…â–„â–„â–„â–„â–ƒâ–‚â–â–†â–‚â–…â–ˆâ–ƒâ–„â–‚â–„â–ƒâ–†â–‚â–‚
wandb:       eval/ensemble_f1 â–„â–„â–‚â–â–…â–„â–†â–…â–‡â–…â–†â–ƒâ–„â–…â–…â–ƒâ–†â–…â–„â–…â–…â–‚â–‡â–‡â–‡â–†â–„â–ˆâ–ƒâ–„â–ƒâ–…â–…â–„â–„â–†â–„â–„â–†â–†
wandb:           train/avg_f1 â–…â–†â–ƒâ–„â–„â–…â–…â–…â–â–â–‚â–…â–†â–„â–…â–‚â–‡â–ƒâ–‚â–†â–ƒâ–‚â–‡â–†â–…â–ƒâ–„â–‚â–ƒâ–â–‡â–…â–†â–‚â–†â–„â–ˆâ–‡â–†â–ˆ
wandb:      train/ensemble_f1 â–†â–…â–ƒâ–â–â–„â–…â–„â–„â–„â–†â–‚â–ƒâ–ƒâ–†â–†â–…â–„â–‚â–‡â–†â–ƒâ–„â–ƒâ–‡â–…â–„â–ƒâ–‚â–ƒâ–†â–‚â–‡â–ƒâ–ƒâ–†â–„â–ˆâ–ˆâ–ˆ
wandb:         train/mil_loss â–â–ˆâ–…â–…â–‚â–‚â–…â–‚â–†â–†â–„â–ƒâ–â–„â–‚â–ƒâ–‚â–„â–ƒâ–†â–†â–„â–â–â–…â–…â–ƒâ–„â–„â–ƒâ–â–„â–„â–‚â–†â–‚â–‚â–…â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.34772
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.88606
wandb:      eval/avg_mil_loss 0.27945
wandb:       eval/ensemble_f1 0.88606
wandb:           train/avg_f1 0.89588
wandb:      train/ensemble_f1 0.89588
wandb:         train/mil_loss 3.08648
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kpf4c8y8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054722-kpf4c8y8/logs
wandb: ERROR Run kpf4c8y8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ra5h8x4r with config:
wandb: 	actor_learning_rate: 7.009706718699551e-06
wandb: 	attention_dropout_p: 0.2174677553244423
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 143
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5296094231144065
wandb: 	temperature: 6.05482035670607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054906-ra5h8x4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ra5h8x4r
wandb: uploading history steps 119-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–‚â–†
wandb:  best/eval_ensemble_f1 â–â–„â–„â–„â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–†â–„â–†â–‚â–ƒâ–ƒâ–„â–„â–â–ˆâ–„â–„â–ƒâ–„â–ƒâ–†â–…â–„â–‚â–†â–‡â–…â–‚â–„â–‡â–…â–ƒâ–‡â–†â–‡â–†â–†â–ƒâ–„â–ƒâ–„â–„â–†
wandb:      eval/avg_mil_loss â–‡â–‚â–„â–ƒâ–†â–…â–…â–ˆâ–â–†â–†â–†â–„â–ƒâ–…â–…â–‡â–„â–‡â–‚â–‚â–…â–„â–‡â–â–†â–„â–„â–ˆâ–â–‚â–‡â–â–‡â–â–ƒâ–„â–ƒâ–†â–‡
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–…â–ƒâ–„â–â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–ƒâ–‡â–ƒâ–…â–‡â–…â–ƒâ–‚â–„â–„â–…â–ƒâ–†â–†â–„â–„â–„â–„â–†â–…â–ƒâ–‚â–„â–†
wandb:           train/avg_f1 â–†â–„â–ƒâ–â–ˆâ–‚â–ƒâ–†â–„â–†â–‚â–„â–ƒâ–„â–ƒâ–„â–‚â–„â–‡â–‚â–…â–…â–ƒâ–„â–†â–‚â–ƒâ–ƒâ–‚â–â–…â–‡â–ƒâ–…â–†â–‚â–…â–„â–‚â–…
wandb:      train/ensemble_f1 â–‡â–†â–‚â–ƒâ–†â–ˆâ–‚â–…â–ƒâ–ƒâ–„â–‡â–„â–„â–‚â–„â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–†â–„â–‚â–…â–ƒâ–‚â–…â–†â–‡â–ƒâ–…â–†â–„â–â–‚â–„
wandb:         train/mil_loss â–ƒâ–…â–„â–ˆâ–‡â–†â–„â–ˆâ–…â–†â–…â–‚â–…â–†â–‡â–‡â–ƒâ–‡â–…â–ˆâ–‡â–†â–‡â–…â–…â–„â–‡â–…â–…â–…â–…â–…â–…â–†â–‡â–†â–…â–†â–â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–â–…â–â–â–ˆâ–â–…â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–…â–…â–…â–ˆâ–…â–â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93371
wandb: best/eval_avg_mil_loss 0.26397
wandb:  best/eval_ensemble_f1 0.93371
wandb:            eval/avg_f1 0.91184
wandb:      eval/avg_mil_loss 0.24521
wandb:       eval/ensemble_f1 0.91184
wandb:           train/avg_f1 0.89086
wandb:      train/ensemble_f1 0.89086
wandb:         train/mil_loss 0.23462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run gallant-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ra5h8x4r
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054906-ra5h8x4r/logs
wandb: ERROR Run ra5h8x4r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8cbkhgag with config:
wandb: 	actor_learning_rate: 3.1535021326194034e-05
wandb: 	attention_dropout_p: 0.21775071580558455
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5613615652929883
wandb: 	temperature: 7.781156430299342
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055140-8cbkhgag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8cbkhgag
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–ƒâ–„â–ƒâ–…â–â–‡â–„â–ˆâ–†â–…â–†â–„â–‡â–…â–‡â–†â–„â–‡â–…â–†â–†â–‡â–†â–…â–„â–ƒâ–‡â–ƒâ–ˆâ–…â–‡â–ƒâ–„â–…â–‡â–…â–‡â–„
wandb:      eval/avg_mil_loss â–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–„â–…â–ƒâ–â–‚â–…â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–…â–„â–‚â–„â–…â–‚â–„â–â–„â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–ƒâ–ƒâ–‚â–â–„â–â–…â–„â–„â–„â–ƒâ–†â–…â–…â–„â–…â–…â–ƒâ–†â–ƒâ–†â–‡â–„â–…â–…â–†â–„â–†â–„â–„â–„â–†â–‚â–…â–ˆâ–ƒâ–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–…â–â–„â–„â–‡â–†â–…â–…â–‡â–†â–‡â–†â–„â–…â–…â–‡â–…â–ˆâ–†â–ˆâ–„â–†â–„â–„â–…â–‡â–‡â–„â–…â–†â–„â–…â–„â–†â–…â–†â–†â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–â–â–ƒâ–â–„â–†â–ˆâ–…â–â–†â–„â–†â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–…â–‚â–‚â–…â–‚â–ƒâ–„â–†â–ƒâ–…â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–„â–…
wandb:         train/mil_loss â–ƒâ–‡â–†â–†â–…â–…â–…â–†â–„â–„â–„â–†â–ƒâ–…â–†â–†â–…â–„â–†â–ƒâ–…â–ƒâ–…â–†â–‡â–„â–‡â–ˆâ–…â–…â–â–…â–ƒâ–…â–…â–†â–„â–‡â–…â–‚
wandb:      train/policy_loss â–„â–„â–â–â–„â–â–ˆâ–„â–â–â–„â–„â–â–„â–„â–ˆâ–â–â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–ˆâ–„â–ˆâ–â–„â–„â–„â–ˆâ–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–â–â–„â–ˆâ–ˆâ–„â–â–„â–ˆâ–„â–â–„â–„â–„â–ˆâ–„â–â–„â–„â–â–â–„â–â–„â–„â–ˆâ–„â–ˆâ–â–„â–â–„â–„â–„â–ˆâ–â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94472
wandb: best/eval_avg_mil_loss 0.2219
wandb:  best/eval_ensemble_f1 0.94472
wandb:            eval/avg_f1 0.8964
wandb:      eval/avg_mil_loss 0.316
wandb:       eval/ensemble_f1 0.8964
wandb:            test/avg_f1 0.92251
wandb:      test/avg_mil_loss 0.15153
wandb:       test/ensemble_f1 0.92251
wandb:           train/avg_f1 0.90028
wandb:      train/ensemble_f1 0.90028
wandb:         train/mil_loss 0.29625
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sleek-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8cbkhgag
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055140-8cbkhgag/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 24ted5qj with config:
wandb: 	actor_learning_rate: 0.00012451551491104133
wandb: 	attention_dropout_p: 0.35853697238704224
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2847082627819584
wandb: 	temperature: 2.908259957815178
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055302-24ted5qj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24ted5qj
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 129-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ˆâ–…â–‡â–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–ƒâ–„â–ƒâ–…â–…â–‚â–„â–‡â–‚â–„â–…â–…â–ƒâ–‚â–„â–‚â–„â–ˆâ–„â–…â–†â–…â–„â–…â–„â–ƒâ–…â–„â–„â–‚â–„â–†â–â–…â–„â–…â–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–ƒâ–…â–„â–„â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–„â–‡â–ƒâ–„â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–â–…â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–‚â–ƒâ–ƒâ–ƒâ–‡â–…â–„â–â–…â–‚â–ƒâ–‚â–‚â–„â–‚â–…â–…â–„â–ƒâ–‚â–„â–‚â–‚â–„â–„â–ˆâ–‡â–ˆâ–†â–„â–‚â–…â–ƒâ–„â–…â–ˆâ–…â–„â–…â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–‚â–‚â–‚â–…â–ƒâ–…â–„â–…â–†â–‚â–…â–„â–†â–…â–ƒâ–†â–†â–ˆâ–„â–„â–ƒâ–…â–…â–ƒâ–‚â–â–‡â–…â–…â–ƒâ–ƒâ–†â–„â–†â–…â–‚â–„â–‡â–ƒ
wandb:      train/ensemble_f1 â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–‡â–†â–„â–„â–†â–ƒâ–…â–„â–†â–â–ˆâ–†â–†â–‡â–ˆâ–ƒâ–„â–‡â–„â–‚â–‡â–†â–†â–„â–…â–…â–ƒâ–ƒâ–„â–…â–„
wandb:         train/mil_loss â–ˆâ–…â–†â–†â–†â–†â–„â–…â–†â–‡â–„â–„â–†â–…â–…â–†â–„â–…â–…â–ƒâ–„â–„â–…â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93351
wandb: best/eval_avg_mil_loss 0.15597
wandb:  best/eval_ensemble_f1 0.93351
wandb:            eval/avg_f1 0.88918
wandb:      eval/avg_mil_loss 0.4299
wandb:       eval/ensemble_f1 0.88918
wandb:            test/avg_f1 0.87198
wandb:      test/avg_mil_loss 0.21136
wandb:       test/ensemble_f1 0.87198
wandb:           train/avg_f1 0.88887
wandb:      train/ensemble_f1 0.88887
wandb:         train/mil_loss 1.00101
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24ted5qj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055302-24ted5qj/logs
wandb: Agent Starting Run: zzm1jntq with config:
wandb: 	actor_learning_rate: 0.000736419853994619
wandb: 	attention_dropout_p: 0.3860111006837825
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5971474253857701
wandb: 	temperature: 8.717998535247341
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055501-zzm1jntq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zzm1jntq
wandb: uploading history steps 92-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–…â–„â–†â–‡â–…â–…â–‡â–‡â–†â–„â–‡â–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–„â–…â–†â–„â–ƒâ–ˆâ–†â–„â–„â–…â–„â–„â–†â–…â–„â–„â–
wandb:      eval/avg_mil_loss â–‡â–‚â–…â–‚â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–…â–‚â–â–‚â–†â–„â–ƒâ–ƒâ–‡â–†â–ƒâ–„â–ƒâ–…â–‚â–…â–„â–‚â–ˆâ–‚â–„â–‚â–ƒâ–ƒâ–„â–
wandb:       eval/ensemble_f1 â–ˆâ–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–…â–…â–‡â–†â–†â–†â–†â–†â–…â–‡â–ˆâ–…â–‡â–‡â–‡â–†â–†â–†â–ƒâ–‡â–â–†â–„â–„â–…â–†â–…â–„â–…â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‡â–…â–…â–ˆâ–‡â–‡â–†â–‡â–…â–†â–ˆâ–ƒâ–†â–…â–…â–…â–…â–†â–…â–„â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–‚â–†â–‚â–‚â–ƒâ–â–„â–‚â–â–
wandb:      train/ensemble_f1 â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–…â–…â–‡â–†â–…â–†â–†â–†â–†â–†â–…â–…â–†â–„â–…â–…â–„â–…â–„â–„â–ƒâ–„â–ƒâ–†â–ƒâ–„â–…â–„â–ƒâ–
wandb:         train/mil_loss â–ˆâ–…â–ˆâ–†â–†â–„â–†â–ƒâ–…â–‡â–‡â–…â–„â–‡â–„â–†â–‡â–„â–ƒâ–…â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–…â–ƒâ–„â–…â–‚â–„â–â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–„â–ƒâ–â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–ˆâ–…â–„â–„â–„â–„â–†â–„â–ˆâ–„â–„â–„â–„â–‚â–…â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–†â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.27394
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.82473
wandb:      eval/avg_mil_loss 0.45564
wandb:       eval/ensemble_f1 0.82473
wandb:            test/avg_f1 0.87951
wandb:      test/avg_mil_loss 0.25051
wandb:       test/ensemble_f1 0.87951
wandb:           train/avg_f1 0.85923
wandb:      train/ensemble_f1 0.85923
wandb:         train/mil_loss 0.21013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sunny-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zzm1jntq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055501-zzm1jntq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ffbrp5y4 with config:
wandb: 	actor_learning_rate: 0.00043945480539598513
wandb: 	attention_dropout_p: 0.2667316442555101
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8744467897700423
wandb: 	temperature: 8.433027460377696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055658-ffbrp5y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffbrp5y4
wandb: uploading history steps 105-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–…â–†â–†â–ˆâ–‡â–ˆâ–‚â–‡â–„â–†â–†â–…â–…â–…â–‚â–†â–„â–…â–„â–„â–â–…â–„â–…â–‚â–„â–„â–ƒâ–†â–‡â–ƒâ–†â–…â–ƒâ–„â–„â–†
wandb:      eval/avg_mil_loss â–â–‚â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–â–‚â–„â–‚â–…â–‚â–‚â–„â–„â–ƒâ–„â–‡â–„â–†â–ƒâ–†â–„â–…â–…â–‡â–‡â–„â–‡â–…â–…â–†â–„â–…â–‡â–ˆâ–…â–‚
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ˆâ–„â–ƒâ–†â–…â–„â–ˆâ–‚â–‡â–‡â–„â–†â–‡â–†â–‚â–…â–†â–…â–‡â–…â–„â–‡â–â–…â–†â–…â–ƒâ–„â–â–â–ƒâ–‡â–„â–ƒâ–†â–†â–…â–†
wandb:           train/avg_f1 â–…â–„â–‡â–ƒâ–…â–†â–…â–…â–…â–…â–‡â–„â–ƒâ–ˆâ–‡â–„â–‚â–„â–…â–â–…â–„â–…â–„â–…â–†â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–â–„â–‚â–‡
wandb:      train/ensemble_f1 â–…â–†â–†â–…â–…â–ƒâ–…â–†â–„â–…â–…â–„â–ˆâ–…â–…â–†â–†â–„â–†â–â–…â–‚â–„â–†â–…â–†â–†â–…â–„â–…â–‚â–ƒâ–‚â–ƒâ–„â–„â–‚â–‚â–‚â–…
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–†â–…â–„â–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–
wandb:      train/policy_loss â–‚â–‚â–â–„â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‚â–â–â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.25443
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.90667
wandb:      eval/avg_mil_loss 0.24326
wandb:       eval/ensemble_f1 0.90667
wandb:           train/avg_f1 0.89372
wandb:      train/ensemble_f1 0.89372
wandb:         train/mil_loss 0.2471
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffbrp5y4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055658-ffbrp5y4/logs
wandb: ERROR Run ffbrp5y4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qdvumye3 with config:
wandb: 	actor_learning_rate: 3.818099804278545e-05
wandb: 	attention_dropout_p: 0.4402402566584476
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15643831380972628
wandb: 	temperature: 3.358905246451087
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055901-qdvumye3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qdvumye3
wandb: uploading wandb-summary.json
wandb: uploading history steps 98-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–„â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–‡â–ƒâ–ˆâ–‚â–„â–ƒâ–„â–…â–…â–†â–‡â–…â–†â–ƒâ–„â–„â–â–†â–‚â–ƒâ–ƒâ–…â–â–„â–„â–ƒâ–„â–‚â–…â–†â–â–„â–…â–ƒâ–„â–„â–…â–†
wandb:      eval/avg_mil_loss â–‚â–ˆâ–…â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–†â–†â–‚â–…â–„â–‚â–ƒâ–…â–‚â–ƒâ–ƒâ–‡â–„â–„â–†â–ƒâ–ƒâ–„â–‚â–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–ƒâ–†â–‚â–ƒâ–‚â–ƒâ–…â–ƒâ–ˆâ–‚â–…â–„â–ƒâ–„â–…â–†â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–‚â–â–…â–„â–‡â–â–…â–„â–‚â–„â–†â–‡â–ƒâ–…â–„â–„â–„
wandb:           train/avg_f1 â–‡â–†â–„â–…â–†â–‚â–…â–‡â–„â–â–†â–„â–‚â–‚â–„â–‡â–‚â–†â–†â–†â–‚â–†â–‡â–ƒâ–†â–„â–‡â–ˆâ–‚â–‚â–…â–…â–‡â–„â–‡â–ˆâ–…â–„â–…â–„
wandb:      train/ensemble_f1 â–„â–‡â–„â–ˆâ–‡â–„â–‚â–„â–„â–„â–ƒâ–â–…â–‚â–‚â–‡â–‡â–‚â–†â–‚â–„â–†â–ƒâ–†â–…â–†â–†â–…â–‡â–„â–†â–…â–„â–†â–„â–„â–„â–‚â–„â–„
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–…â–‡â–…â–†â–†â–…â–†â–…â–†â–„â–…â–ƒâ–…â–„â–ƒâ–„â–…â–„â–ƒâ–„â–„â–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚â–„
wandb:      train/policy_loss â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92653
wandb: best/eval_avg_mil_loss 0.35046
wandb:  best/eval_ensemble_f1 0.92653
wandb:            eval/avg_f1 0.90706
wandb:      eval/avg_mil_loss 0.32754
wandb:       eval/ensemble_f1 0.90706
wandb:           train/avg_f1 0.8913
wandb:      train/ensemble_f1 0.8913
wandb:         train/mil_loss 0.27026
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devout-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qdvumye3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055901-qdvumye3/logs
wandb: ERROR Run qdvumye3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: rshhenzm with config:
wandb: 	actor_learning_rate: 2.7828467301200997e-06
wandb: 	attention_dropout_p: 0.29359073144135434
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3276791561718161
wandb: 	temperature: 5.543333841133704
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060034-rshhenzm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rshhenzm
wandb: uploading history steps 94-113; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 114-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–„â–…â–…â–„â–ƒâ–†â–†â–…â–ƒâ–†â–ƒâ–†â–…â–…â–†â–…â–ƒâ–„â–„â–‡â–„â–…â–„â–„â–„â–…â–„â–ƒâ–„â–‚â–â–
wandb:      eval/avg_mil_loss â–ˆâ–„â–…â–†â–†â–ƒâ–„â–â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–‚â–ƒâ–†â–‡â–„â–ƒâ–„â–„â–â–„â–ƒâ–…â–…â–‚â–„â–…â–‡â–ƒâ–‚â–‚â–„â–…â–„â–â–„â–ƒ
wandb:       eval/ensemble_f1 â–†â–…â–ˆâ–†â–ˆâ–†â–„â–„â–„â–…â–…â–ƒâ–„â–„â–†â–‡â–…â–…â–†â–…â–„â–†â–„â–„â–„â–‡â–„â–„â–…â–…â–…â–ƒâ–…â–„â–„â–‚â–…â–†â–â–
wandb:           train/avg_f1 â–†â–ƒâ–†â–„â–„â–…â–ˆâ–„â–†â–†â–…â–„â–†â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–â–…â–…â–…â–â–ƒâ–ƒâ–‚â–…â–ƒâ–â–„â–ƒâ–…â–…â–ƒâ–„â–‚
wandb:      train/ensemble_f1 â–ƒâ–„â–†â–‡â–†â–†â–†â–ƒâ–„â–‡â–â–‚â–„â–ˆâ–…â–„â–†â–ƒâ–…â–‚â–ƒâ–ƒâ–†â–„â–„â–‡â–ƒâ–‚â–…â–‚â–ˆâ–ƒâ–…â–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒ
wandb:         train/mil_loss â–ˆâ–ƒâ–‡â–„â–‚â–„â–„â–‡â–„â–ƒâ–„â–„â–ƒâ–„â–„â–â–„â–„â–…â–†â–ƒâ–†â–†â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–…â–„â–…â–†â–‚â–…â–„â–„â–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.22979
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.86113
wandb:      eval/avg_mil_loss 0.29386
wandb:       eval/ensemble_f1 0.86113
wandb:           train/avg_f1 0.88402
wandb:      train/ensemble_f1 0.88402
wandb:         train/mil_loss 0.19007
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deep-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rshhenzm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060034-rshhenzm/logs
wandb: ERROR Run rshhenzm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jxtooaxo with config:
wandb: 	actor_learning_rate: 6.234510388092679e-06
wandb: 	attention_dropout_p: 0.2799895282235829
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6839511607912218
wandb: 	temperature: 1.7535948249969568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060212-jxtooaxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxtooaxo
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–†â–†â–ƒâ–â–‚â–ƒâ–‚â–…â–„â–…â–„â–‡â–„â–„â–ƒâ–„â–„â–„â–†â–†â–…â–ƒâ–…â–ƒâ–‡â–ˆâ–„â–ƒâ–‚â–ƒâ–†â–ƒâ–†â–„â–„â–ƒâ–‚
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–„â–ƒâ–†â–‡â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–‡â–â–‚â–…â–‚â–…â–„â–ƒâ–…â–ˆâ–†â–†â–ƒâ–„â–…â–„â–ƒâ–‡â–ƒâ–ƒâ–†â–†
wandb:       eval/ensemble_f1 â–…â–†â–‡â–…â–†â–ƒâ–„â–â–…â–…â–…â–‡â–…â–…â–„â–„â–ˆâ–†â–…â–„â–…â–‡â–†â–ƒâ–ˆâ–„â–†â–„â–†â–„â–ˆâ–„â–„â–†â–…â–…â–â–…â–†â–…
wandb:           train/avg_f1 â–…â–‚â–ƒâ–…â–†â–ƒâ–„â–†â–…â–†â–„â–†â–…â–„â–…â–„â–†â–ˆâ–†â–‡â–†â–ˆâ–‡â–‡â–†â–†â–†â–…â–‚â–â–ƒâ–„â–…â–„â–„â–ƒâ–†â–ƒâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–…â–„â–„â–‡â–ˆâ–‚â–„â–…â–…â–„â–…â–…â–‡â–†â–†â–‡â–†â–†â–ˆâ–†â–„â–ˆâ–â–‡â–‚â–†â–†â–†â–„â–ƒâ–…â–‡â–„â–†â–…â–†â–†â–ˆâ–…â–„
wandb:         train/mil_loss â–‡â–ˆâ–‡â–„â–†â–†â–ˆâ–…â–…â–ˆâ–†â–‡â–‡â–…â–…â–ˆâ–ƒâ–‡â–‚â–†â–†â–…â–ƒâ–…â–„â–…â–ˆâ–…â–„â–â–„â–â–„â–ƒâ–ƒâ–†â–…â–„â–„â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92281
wandb: best/eval_avg_mil_loss 0.26948
wandb:  best/eval_ensemble_f1 0.92281
wandb:            eval/avg_f1 0.88139
wandb:      eval/avg_mil_loss 0.40153
wandb:       eval/ensemble_f1 0.88139
wandb:           train/avg_f1 0.88902
wandb:      train/ensemble_f1 0.88902
wandb:         train/mil_loss 3.36955
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run royal-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxtooaxo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060212-jxtooaxo/logs
wandb: ERROR Run jxtooaxo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xv0675s1 with config:
wandb: 	actor_learning_rate: 2.3283845674668228e-06
wandb: 	attention_dropout_p: 0.23459343870485244
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17529272373906302
wandb: 	temperature: 9.521663949149463
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060355-xv0675s1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv0675s1
wandb: uploading history steps 54-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–„â–ƒâ–„â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–„â–‡â–‡â–‡â–â–ˆâ–„â–‡â–ˆâ–‡â–ƒâ–ˆâ–ˆâ–‡â–…â–„â–„â–‡â–„â–ƒâ–ƒâ–…â–†â–†â–†â–ƒâ–…â–‡â–ƒâ–â–„â–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–‡
wandb:      eval/avg_mil_loss â–‡â–„â–…â–…â–â–‡â–„â–„â–‚â–‚â–„â–†â–‚â–…â–‚â–‚â–„â–‚â–‚â–ƒâ–ƒâ–‚â–‡â–â–…â–ƒâ–„â–†â–‚â–‡â–…â–„â–ˆâ–†â–…â–ƒâ–†â–„â–†â–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–‡â–‚â–‡â–ˆâ–„â–‡â–ˆâ–„â–ƒâ–ˆâ–ˆâ–‡â–‡â–â–…â–„â–‡â–ˆâ–†â–‚â–†â–ƒâ–„â–‡â–ƒâ–ƒâ–â–„â–†â–‚â–„â–…â–„â–ƒâ–ƒâ–ƒâ–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–†â–…â–ƒâ–„â–ˆâ–„â–†â–…â–…â–‡â–…â–…â–†â–…â–…â–‡â–…â–‡â–…â–…â–†â–ƒâ–‡â–ƒâ–…â–ƒâ–â–ƒâ–‚â–ƒâ–â–…â–…â–‡â–…â–…â–„â–…
wandb:      train/ensemble_f1 â–†â–†â–ƒâ–†â–‡â–…â–„â–…â–…â–†â–…â–‡â–†â–…â–…â–…â–‡â–…â–†â–†â–ˆâ–ƒâ–„â–†â–ƒâ–…â–â–ƒâ–ƒâ–†â–„â–â–‡â–…â–„â–†â–…â–„â–…â–…
wandb:         train/mil_loss â–†â–†â–ˆâ–…â–…â–ƒâ–†â–ƒâ–‡â–…â–…â–ˆâ–…â–ƒâ–…â–…â–…â–…â–â–ƒâ–‚â–†â–‡â–…â–†â–„â–…â–‡â–ƒâ–„â–…â–„â–„â–‡â–‚â–ƒâ–…â–‡â–†â–…
wandb:      train/policy_loss â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92281
wandb: best/eval_avg_mil_loss 0.24669
wandb:  best/eval_ensemble_f1 0.92281
wandb:            eval/avg_f1 0.9047
wandb:      eval/avg_mil_loss 0.27554
wandb:       eval/ensemble_f1 0.9047
wandb:            test/avg_f1 0.92817
wandb:      test/avg_mil_loss 0.1899
wandb:       test/ensemble_f1 0.92817
wandb:           train/avg_f1 0.89314
wandb:      train/ensemble_f1 0.89314
wandb:         train/mil_loss 0.19999
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv0675s1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060355-xv0675s1/logs
wandb: Agent Starting Run: cwd0wmfr with config:
wandb: 	actor_learning_rate: 1.4073661490018532e-05
wandb: 	attention_dropout_p: 0.3252236525462876
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0240859698138316
wandb: 	temperature: 8.02074493211462
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060458-cwd0wmfr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cwd0wmfr
wandb: uploading wandb-summary.json
wandb: uploading history steps 58-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–…â–†â–†â–†â–…â–…â–†â–„â–…â–…â–…â–„â–…â–„â–†â–ƒâ–‚â–†â–„â–„â–â–…â–„â–‡â–†â–…â–…â–ˆâ–„â–ƒâ–…â–†â–…â–…â–…â–…â–„â–„
wandb:      eval/avg_mil_loss â–‚â–…â–ƒâ–„â–‚â–„â–ƒâ–„â–„â–‚â–ˆâ–ƒâ–†â–„â–‚â–ƒâ–ƒâ–‚â–„â–‚â–‡â–ƒâ–…â–„â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–†â–…â–ƒâ–†â–†â–„â–…â–†â–‡â–…â–„â–ƒâ–…â–†â–„â–ƒâ–‡â–„â–ƒâ–‡â–ƒâ–†â–„â–â–…â–†â–ƒâ–‡â–â–…â–ˆâ–ƒâ–…â–†â–†â–…â–†â–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–†â–…â–…â–â–„â–‡â–‚â–…â–‡â–„â–…â–…â–…â–ˆâ–ƒâ–„â–ƒâ–„â–…â–†â–„â–ƒâ–„â–†â–ƒâ–†â–‚â–„â–„â–‚â–„â–„â–‚â–‚â–ƒâ–â–â–„
wandb:      train/ensemble_f1 â–…â–„â–„â–…â–ˆâ–„â–â–…â–„â–†â–…â–‚â–…â–„â–‡â–…â–…â–…â–ƒâ–ƒâ–„â–„â–…â–„â–„â–â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–ƒâ–â–‚â–…â–„
wandb:         train/mil_loss â–ˆâ–ˆâ–„â–…â–„â–ˆâ–†â–†â–…â–…â–‡â–‡â–„â–…â–†â–„â–…â–„â–…â–ƒâ–†â–†â–ƒâ–†â–â–ƒâ–ˆâ–†â–…â–‚â–†â–ƒâ–ƒâ–†â–‡â–…â–â–†â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–ˆâ–…â–…â–‡â–…â–…â–…â–„â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.25591
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.8903
wandb:      eval/avg_mil_loss 0.31638
wandb:       eval/ensemble_f1 0.8903
wandb:            test/avg_f1 0.90623
wandb:      test/avg_mil_loss 0.18866
wandb:       test/ensemble_f1 0.90623
wandb:           train/avg_f1 0.89178
wandb:      train/ensemble_f1 0.89178
wandb:         train/mil_loss 0.24407
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cwd0wmfr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060458-cwd0wmfr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rgzyr15t with config:
wandb: 	actor_learning_rate: 5.3826085339959755e-06
wandb: 	attention_dropout_p: 0.10761054846192908
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01049306592225696
wandb: 	temperature: 7.592425393578916
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060624-rgzyr15t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rgzyr15t
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–ƒâ–â–ƒâ–„â–…â–†â–†â–‡â–…â–‡â–†â–„â–†â–„â–ˆâ–ƒâ–„â–…â–ƒâ–†â–„â–‡â–…â–ˆâ–ˆâ–ƒâ–…â–„â–â–…â–„â–ˆâ–…â–†â–ƒâ–‚â–†â–…
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–‚â–ƒâ–†â–„â–†â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–…â–ƒâ–…â–ƒâ–„â–‡â–…â–‚â–…â–ˆâ–…â–†â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–‡â–…â–†â–†â–ˆâ–…â–…â–†â–†â–†â–ˆâ–ƒâ–‡â–…â–‡â–…â–†â–†â–„â–‡â–†â–…â–†â–ˆâ–‡â–‡â–ˆâ–„â–‡â–‚â–„â–†â–†â–â–„â–ƒâ–ƒâ–„â–†â–…
wandb:           train/avg_f1 â–‡â–ˆâ–„â–…â–…â–†â–„â–…â–…â–‡â–…â–†â–‚â–„â–†â–…â–†â–†â–ˆâ–„â–„â–†â–â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–…â–†â–ˆâ–…â–„â–…â–…â–„â–ˆâ–„â–
wandb:      train/ensemble_f1 â–„â–„â–…â–‡â–‡â–„â–‚â–…â–†â–„â–„â–‡â–‡â–„â–‡â–„â–ˆâ–„â–…â–…â–…â–†â–†â–‚â–„â–†â–ƒâ–„â–…â–…â–…â–ƒâ–„â–‚â–…â–…â–„â–â–…â–„
wandb:         train/mil_loss â–…â–ˆâ–‡â–ˆâ–…â–ˆâ–†â–†â–†â–…â–†â–…â–†â–‡â–‡â–ƒâ–…â–†â–‡â–‡â–…â–…â–…â–†â–‡â–†â–†â–…â–…â–†â–„â–…â–…â–†â–ˆâ–‡â–…â–ƒâ–…â–
wandb:      train/policy_loss â–†â–ˆâ–†â–†â–ˆâ–†â–†â–‚â–†â–‚â–†â–†â–†â–†â–…â–ƒâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–‡â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–ƒâ–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91135
wandb: best/eval_avg_mil_loss 0.22373
wandb:  best/eval_ensemble_f1 0.91135
wandb:            eval/avg_f1 0.88836
wandb:      eval/avg_mil_loss 0.36578
wandb:       eval/ensemble_f1 0.88836
wandb:           train/avg_f1 0.88928
wandb:      train/ensemble_f1 0.88928
wandb:         train/mil_loss 3.42136
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run major-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rgzyr15t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060624-rgzyr15t/logs
wandb: ERROR Run rgzyr15t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bx9v55e9 with config:
wandb: 	actor_learning_rate: 1.2681738073363836e-05
wandb: 	attention_dropout_p: 0.3802311426951991
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05004118530171264
wandb: 	temperature: 9.173863498277168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060757-bx9v55e9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bx9v55e9
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–â–‚â–ƒâ–„â–„â–…â–„â–â–â–†â–†â–ƒâ–‡â–…â–„â–„â–ˆâ–„â–ƒâ–†â–ƒâ–†â–„â–„â–…â–‚â–†â–„â–‡â–…â–„â–ƒâ–‚
wandb:      eval/avg_mil_loss â–…â–‡â–…â–†â–…â–ƒâ–‡â–…â–ƒâ–„â–ƒâ–ƒâ–…â–…â–ƒâ–‚â–ˆâ–‚â–â–„â–…â–ƒâ–„â–â–„â–â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–„â–ƒâ–ƒâ–…â–‚â–‚
wandb:       eval/ensemble_f1 â–â–ƒâ–ƒâ–‚â–„â–ˆâ–…â–ƒâ–â–‚â–„â–„â–…â–â–†â–â–†â–†â–ƒâ–‡â–„â–„â–ˆâ–„â–„â–†â–ƒâ–†â–„â–ƒâ–…â–‚â–†â–„â–‚â–…â–„â–ƒâ–ƒâ–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–…â–„â–…â–ƒâ–„â–ˆâ–„â–â–…â–…â–…â–…â–„â–ƒâ–â–‚â–†â–„â–‡â–…â–ƒâ–„â–‡â–…â–…â–…â–…â–†â–…â–†â–…â–ƒâ–„â–…â–…â–…â–„â–â–…
wandb:      train/ensemble_f1 â–‚â–…â–„â–…â–ƒâ–„â–ˆâ–†â–â–…â–…â–…â–…â–ƒâ–„â–â–‚â–†â–„â–‡â–ƒâ–…â–ƒâ–„â–‡â–…â–…â–…â–…â–„â–…â–„â–ƒâ–„â–…â–…â–…â–â–ƒâ–…
wandb:         train/mil_loss â–†â–ˆâ–‡â–†â–†â–†â–†â–†â–‡â–†â–†â–…â–†â–‡â–‡â–…â–…â–…â–„â–…â–†â–„â–†â–†â–ƒâ–…â–„â–„â–„â–ƒâ–…â–â–„â–ƒâ–ƒâ–‚â–†â–„â–„â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9229
wandb: best/eval_avg_mil_loss 0.226
wandb:  best/eval_ensemble_f1 0.9229
wandb:            eval/avg_f1 0.87838
wandb:      eval/avg_mil_loss 0.27901
wandb:       eval/ensemble_f1 0.87838
wandb:            test/avg_f1 0.89399
wandb:      test/avg_mil_loss 0.23769
wandb:       test/ensemble_f1 0.89399
wandb:           train/avg_f1 0.88986
wandb:      train/ensemble_f1 0.88986
wandb:         train/mil_loss 1.68196
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run different-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bx9v55e9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060757-bx9v55e9/logs
wandb: Agent Starting Run: iyrctola with config:
wandb: 	actor_learning_rate: 2.16009541842927e-06
wandb: 	attention_dropout_p: 0.48086895253034007
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.015300339289217146
wandb: 	temperature: 8.221115039506921
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060848-iyrctola
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iyrctola
wandb: uploading wandb-summary.json
wandb: uploading history steps 56-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–â–†â–…â–‚â–ƒâ–…â–…â–‚â–…â–„â–‡â–…â–â–‚â–ˆâ–‡â–…â–ƒâ–‚â–†â–ƒâ–†â–‡â–…â–…â–‡â–†â–‚â–†â–ƒâ–‡â–â–…â–ƒâ–ˆâ–…â–ˆâ–†â–†
wandb:      eval/avg_mil_loss â–„â–„â–†â–ƒâ–ƒâ–‚â–‡â–„â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–‚â–ƒâ–…â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–ˆâ–‚â–…â–…â–…â–ƒâ–‚â–…â–„â–„â–„â–‡â–‚â–…â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‡â–„â–‚â–„â–†â–‚â–ƒâ–…â–…â–â–„â–„â–…â–â–ˆâ–‡â–‡â–‚â–‚â–ƒâ–‡â–…â–„â–…â–‡â–†â–‚â–†â–…â–„â–ƒâ–…â–…â–ƒâ–„â–„â–…â–ˆâ–†â–†
wandb:           train/avg_f1 â–ƒâ–†â–ƒâ–…â–‡â–„â–…â–„â–†â–†â–†â–„â–„â–†â–…â–‡â–†â–ƒâ–„â–â–‚â–†â–ˆâ–†â–„â–‡â–†â–‡â–†â–ƒâ–…â–„â–…â–…â–„â–‚â–„â–†â–„â–ƒ
wandb:      train/ensemble_f1 â–…â–‚â–‡â–‚â–‡â–ƒâ–„â–„â–†â–†â–†â–†â–ƒâ–ƒâ–…â–‡â–„â–†â–‚â–†â–â–„â–†â–…â–…â–…â–†â–…â–‚â–†â–„â–…â–…â–â–„â–…â–ƒâ–ˆâ–‚â–ƒ
wandb:         train/mil_loss â–‡â–‡â–ˆâ–†â–…â–‡â–‡â–†â–…â–ˆâ–‡â–†â–†â–†â–‡â–…â–ƒâ–…â–…â–„â–„â–†â–…â–‡â–‡â–…â–…â–‚â–„â–…â–„â–„â–…â–‚â–†â–‚â–‚â–â–â–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91556
wandb: best/eval_avg_mil_loss 0.30025
wandb:  best/eval_ensemble_f1 0.91556
wandb:            eval/avg_f1 0.90396
wandb:      eval/avg_mil_loss 0.2619
wandb:       eval/ensemble_f1 0.90396
wandb:           train/avg_f1 0.89904
wandb:      train/ensemble_f1 0.89904
wandb:         train/mil_loss 0.81899
wandb:      train/policy_loss -0.52927
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.52927
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iyrctola
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060848-iyrctola/logs
wandb: ERROR Run iyrctola errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pl9b98ay with config:
wandb: 	actor_learning_rate: 3.0781798477728526e-06
wandb: 	attention_dropout_p: 0.271549565709879
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09390568320411909
wandb: 	temperature: 8.61919883576473
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060951-pl9b98ay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pl9b98ay
wandb: uploading history steps 55-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–ƒâ–†â–†â–„â–…â–‚â–…â–ƒâ–ƒâ–…â–…â–†â–†â–ˆâ–…â–ˆâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–„â–ƒâ–…â–‡â–„â–‡â–ƒâ–…â–„â–†â–ƒâ–â–‡â–‡
wandb:      eval/avg_mil_loss â–‡â–„â–‚â–ƒâ–…â–ƒâ–…â–…â–ƒâ–„â–…â–„â–„â–ƒâ–ƒâ–…â–ˆâ–ƒâ–‡â–„â–â–†â–…â–‡â–…â–…â–…â–…â–…â–‡â–…â–ƒâ–‡â–„â–†â–ƒâ–…â–‡â–…â–…
wandb:       eval/ensemble_f1 â–…â–„â–ƒâ–†â–†â–„â–ƒâ–‚â–…â–„â–…â–…â–†â–†â–…â–…â–ˆâ–‡â–…â–„â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‡â–„â–ƒâ–…â–…â–†â–„â–ƒâ–…â–„â–†â–ƒâ–â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–…â–â–…â–„â–â–„â–‡â–ƒâ–†â–†â–…â–‚â–‚â–„â–„â–‡â–†â–…â–…â–ˆâ–ƒâ–†â–…â–ˆâ–„â–‚â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–…â–ƒâ–…â–
wandb:      train/ensemble_f1 â–‚â–…â–â–…â–„â–â–…â–‡â–ƒâ–†â–…â–‚â–‚â–„â–…â–ƒâ–‡â–†â–…â–…â–ˆâ–ƒâ–†â–…â–…â–†â–‡â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–…â–…
wandb:         train/mil_loss â–…â–ƒâ–†â–„â–„â–„â–†â–†â–„â–…â–„â–„â–„â–‚â–â–ƒâ–ˆâ–„â–…â–„â–â–…â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–†â–…â–†â–…â–…
wandb:      train/policy_loss â–„â–„â–„â–†â–‚â–„â–ƒâ–„â–„â–„â–„â–„â–‡â–„â–ƒâ–ƒâ–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–†â–ƒâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–‡â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91886
wandb: best/eval_avg_mil_loss 0.25488
wandb:  best/eval_ensemble_f1 0.91886
wandb:            eval/avg_f1 0.91087
wandb:      eval/avg_mil_loss 0.31406
wandb:       eval/ensemble_f1 0.91087
wandb:            test/avg_f1 0.90493
wandb:      test/avg_mil_loss 0.21875
wandb:       test/ensemble_f1 0.90493
wandb:           train/avg_f1 0.87993
wandb:      train/ensemble_f1 0.87993
wandb:         train/mil_loss 0.81005
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pl9b98ay
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060951-pl9b98ay/logs
wandb: Agent Starting Run: caag0wgo with config:
wandb: 	actor_learning_rate: 3.804410492561592e-05
wandb: 	attention_dropout_p: 0.38568371260851864
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3541108608978766
wandb: 	temperature: 9.959081282302996
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061042-caag0wgo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caag0wgo
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–…â–ƒâ–â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–‡â–ˆâ–…â–„â–ƒâ–ƒâ–„â–â–„â–„â–…â–‡â–„â–ƒâ–â–ˆâ–†â–‚â–„â–„â–‚â–ƒâ–‚â–…â–â–…â–…â–„â–‚â–ƒâ–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–„â–â–ƒâ–‚â–„â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–ˆâ–‚â–„â–â–ƒâ–„â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–„â–‚â–‚â–ƒ
wandb:       eval/ensemble_f1 â–‚â–‚â–…â–…â–ƒâ–„â–…â–…â–…â–ƒâ–„â–†â–ƒâ–†â–„â–ˆâ–…â–â–‚â–‡â–…â–…â–…â–‚â–‚â–‚â–„â–†â–†â–‚â–„â–†â–†â–…â–…â–„â–†â–„â–ƒâ–ƒ
wandb:           train/avg_f1 â–â–†â–ˆâ–…â–„â–„â–…â–…â–‡â–…â–…â–†â–†â–‡â–…â–ƒâ–†â–„â–„â–…â–†â–„â–„â–‚â–ˆâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–…â–†â–ƒâ–‚â–…â–â–„â–‚
wandb:      train/ensemble_f1 â–‡â–‚â–†â–‚â–„â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–…â–…â–„â–†â–ˆâ–…â–…â–ƒâ–„â–ˆâ–ƒâ–†â–…â–†â–†â–†â–…â–â–‚â–…â–„â–„â–„â–…â–ƒâ–‚â–ƒ
wandb:         train/mil_loss â–„â–‡â–„â–ƒâ–ƒâ–‚â–†â–ƒâ–…â–…â–„â–‡â–„â–…â–‡â–†â–ˆâ–‡â–„â–…â–…â–„â–‡â–ƒâ–†â–ƒâ–…â–…â–†â–…â–…â–„â–‡â–â–…â–ƒâ–‚â–„â–…â–„
wandb:      train/policy_loss â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.25743
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.88788
wandb:      eval/avg_mil_loss 0.33604
wandb:       eval/ensemble_f1 0.88788
wandb:           train/avg_f1 0.88006
wandb:      train/ensemble_f1 0.88006
wandb:         train/mil_loss 2.71191
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worthy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caag0wgo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061042-caag0wgo/logs
wandb: ERROR Run caag0wgo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l6hrp8wb with config:
wandb: 	actor_learning_rate: 5.703528428177775e-06
wandb: 	attention_dropout_p: 0.2716316121996064
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4076803798939728
wandb: 	temperature: 8.465599282254292
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061205-l6hrp8wb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l6hrp8wb
wandb: uploading history steps 54-62, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–†â–†â–‡â–…â–„â–…â–‡â–‡â–…â–†â–„â–‡â–†â–ˆâ–‚â–‡â–‡â–†â–‡â–ƒâ–„â–„â–†â–‡â–ƒâ–‚â–â–†â–‡â–†â–ƒâ–…â–†â–†â–‡â–â–†â–
wandb:      eval/avg_mil_loss â–ƒâ–‚â–‚â–â–â–„â–‚â–‚â–„â–ƒâ–â–â–ƒâ–ƒâ–†â–â–ƒâ–â–‚â–â–ƒâ–‚â–‡â–‚â–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–„â–â–ˆâ–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–…â–„â–„â–†â–…â–„â–†â–…â–â–ƒâ–„â–ƒâ–ˆâ–†â–…â–…â–…â–…â–‚â–†â–ˆâ–ƒâ–ƒâ–„â–ƒâ–†â–‚â–â–…â–„â–…â–‚â–„â–„â–…â–…â–…â–…â–…â–‚
wandb:           train/avg_f1 â–†â–…â–…â–‚â–…â–…â–‡â–ƒâ–ˆâ–„â–†â–ƒâ–ˆâ–‡â–„â–„â–ƒâ–â–‚â–„â–†â–‚â–‡â–†â–â–„â–‚â–†â–ƒâ–…â–…â–…â–†â–†â–ˆâ–…â–„â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–†â–…â–…â–„â–‚â–†â–†â–‡â–‚â–ƒâ–†â–ƒâ–‡â–ƒâ–†â–„â–„â–†â–…â–‚â–†â–â–„â–‚â–†â–…â–„â–…â–…â–†â–ˆâ–„â–…â–…â–†â–†â–„â–ƒâ–†â–…
wandb:         train/mil_loss â–…â–…â–„â–…â–„â–„â–…â–…â–ˆâ–†â–…â–„â–„â–‡â–„â–ƒâ–†â–ƒâ–„â–‚â–…â–„â–ƒâ–ƒâ–„â–…â–„â–†â–„â–„â–ƒâ–ˆâ–†â–†â–„â–„â–„â–…â–â–ƒ
wandb:      train/policy_loss â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93388
wandb: best/eval_avg_mil_loss 0.23119
wandb:  best/eval_ensemble_f1 0.93388
wandb:            eval/avg_f1 0.87511
wandb:      eval/avg_mil_loss 0.3189
wandb:       eval/ensemble_f1 0.87511
wandb:           train/avg_f1 0.89357
wandb:      train/ensemble_f1 0.89357
wandb:         train/mil_loss 0.23969
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l6hrp8wb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061205-l6hrp8wb/logs
wandb: ERROR Run l6hrp8wb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xo4eqz5z with config:
wandb: 	actor_learning_rate: 7.737873763380963e-05
wandb: 	attention_dropout_p: 0.3729862805926481
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00493919803346865
wandb: 	temperature: 7.765473844394954
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061302-xo4eqz5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xo4eqz5z
wandb: uploading history steps 38-55, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–†â–„â–…â–†â–„â–‡â–…â–†â–ˆâ–…â–†â–†â–‡â–…â–…â–†â–†â–…â–ˆâ–†â–‡â–…â–‡â–†â–†â–„â–†â–â–…â–‡â–†â–†â–‡â–…â–‡â–…â–ˆâ–…â–†â–†
wandb:      eval/avg_mil_loss â–…â–â–…â–‚â–ƒâ–…â–‡â–ƒâ–‚â–ƒâ–‚â–‡â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–…â–…â–ƒâ–‚â–„â–ƒâ–ˆâ–…â–‚â–„â–†â–„â–ƒâ–„â–ƒâ–â–„â–†â–‚â–‡â–ƒ
wandb:       eval/ensemble_f1 â–‡â–†â–„â–…â–†â–‡â–‚â–…â–†â–ˆâ–…â–‡â–†â–…â–…â–†â–…â–†â–ˆâ–†â–…â–‡â–†â–†â–…â–†â–â–…â–‡â–†â–„â–‡â–…â–‡â–‚â–ˆâ–…â–‡â–†â–†
wandb:           train/avg_f1 â–‚â–„â–…â–…â–„â–†â–…â–…â–‚â–‡â–…â–†â–„â–„â–…â–‚â–„â–…â–ƒâ–…â–†â–â–‚â–ˆâ–‡â–‡â–…â–‚â–ƒâ–„â–„â–‚â–„â–ƒâ–ƒâ–„â–‚â–…â–„â–
wandb:      train/ensemble_f1 â–‚â–„â–…â–…â–„â–…â–…â–…â–‚â–‡â–…â–†â–„â–„â–…â–„â–…â–ƒâ–‡â–†â–‚â–ˆâ–‡â–ƒâ–‡â–‡â–…â–‚â–„â–‚â–„â–ƒâ–ƒâ–„â–‚â–‚â–…â–‚â–„â–
wandb:         train/mil_loss â–„â–„â–ƒâ–ƒâ–‡â–ˆâ–…â–†â–‚â–ƒâ–„â–‚â–„â–…â–…â–ˆâ–…â–…â–ƒâ–â–…â–ƒâ–‚â–…â–„â–‚â–„â–â–„â–„â–‚â–„â–ƒâ–„â–â–„â–ƒâ–â–â–…
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–ƒâ–ˆâ–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–‡â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ƒâ–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–‡â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92261
wandb: best/eval_avg_mil_loss 0.25898
wandb:  best/eval_ensemble_f1 0.92261
wandb:            eval/avg_f1 0.89726
wandb:      eval/avg_mil_loss 0.2928
wandb:       eval/ensemble_f1 0.89726
wandb:           train/avg_f1 0.88488
wandb:      train/ensemble_f1 0.88488
wandb:         train/mil_loss 0.2055
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zesty-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xo4eqz5z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061302-xo4eqz5z/logs
wandb: ERROR Run xo4eqz5z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: p3220v7j with config:
wandb: 	actor_learning_rate: 1.805799040518776e-06
wandb: 	attention_dropout_p: 0.24329596990504387
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2541320444467001
wandb: 	temperature: 9.560884516916303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061354-p3220v7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p3220v7j
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 37-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–‚â–â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–„â–ˆ
wandb:            eval/avg_f1 â–„â–…â–„â–…â–â–„â–…â–ƒâ–â–„â–‚â–†â–„â–„â–…â–â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–†â–ƒâ–â–†â–‚â–ˆâ–…â–ƒâ–ƒâ–‡â–ƒâ–…â–…â–…â–ƒâ–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–…â–ˆâ–â–â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–…â–…â–…â–†â–‚â–â–â–‡â–â–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–‚â–…â–…
wandb:       eval/ensemble_f1 â–…â–…â–…â–†â–…â–„â–†â–ƒâ–ƒâ–„â–ƒâ–†â–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–†â–ƒâ–‚â–ƒâ–ˆâ–…â–„â–ƒâ–„â–„â–…â–…â–†â–…â–â–…â–ƒâ–„â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–„â–…â–…â–ƒâ–…â–„â–…â–„â–…â–†â–…â–â–†â–„â–‚â–„â–„â–ƒâ–„â–…â–…â–†â–…â–â–„â–†â–‚â–â–„â–ˆâ–…â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–…
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–…â–ƒâ–ƒâ–…â–„â–…â–ƒâ–…â–†â–…â–†â–„â–‚â–„â–„â–ƒâ–†â–…â–…â–…â–„â–‡â–„â–†â–‚â–â–„â–ˆâ–ƒâ–…â–„â–ƒâ–‚â–‚â–…â–ƒâ–„
wandb:         train/mil_loss â–†â–„â–…â–†â–†â–„â–†â–‡â–†â–†â–…â–‚â–†â–…â–‚â–„â–…â–†â–†â–†â–…â–‚â–ˆâ–†â–ƒâ–‚â–…â–‚â–‚â–†â–â–„â–ƒâ–†â–‡â–‚â–„â–ƒâ–ƒâ–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–‚â–ˆâ–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–‚â–…â–ˆâ–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93395
wandb: best/eval_avg_mil_loss 0.2338
wandb:  best/eval_ensemble_f1 0.93395
wandb:            eval/avg_f1 0.87871
wandb:      eval/avg_mil_loss 0.36854
wandb:       eval/ensemble_f1 0.87871
wandb:            test/avg_f1 0.92428
wandb:      test/avg_mil_loss 0.23182
wandb:       test/ensemble_f1 0.92428
wandb:           train/avg_f1 0.89581
wandb:      train/ensemble_f1 0.89581
wandb:         train/mil_loss 0.19303
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run honest-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p3220v7j
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061354-p3220v7j/logs
wandb: Agent Starting Run: sp2l1ka6 with config:
wandb: 	actor_learning_rate: 1.0154531705018548e-05
wandb: 	attention_dropout_p: 0.3499210349961917
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0028666418258028736
wandb: 	temperature: 9.053604802699144
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061446-sp2l1ka6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sp2l1ka6
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ƒâ–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–…â–ƒâ–„â–‡â–ƒâ–…â–†â–†â–‡â–„â–†â–†â–„â–ƒâ–„â–†â–„â–…â–…â–ƒâ–ƒâ–ˆâ–…â–„â–…â–†â–†â–†â–ˆâ–†â–‡â–†â–ˆâ–…â–…â–„â–…â–â–…
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–„â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–â–…â–„â–‚â–ˆâ–‚â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–…â–„â–…â–…â–‡â–„â–ƒâ–ƒâ–…â–†â–‡â–†â–„â–†â–„â–ƒâ–„â–„â–ƒâ–…â–…â–ƒâ–ƒâ–ˆâ–‚â–„â–ƒâ–…â–†â–ˆâ–‡â–†â–ˆâ–„â–…â–„â–…â–â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–„â–„â–ˆâ–…â–…â–†â–…â–…â–ƒâ–„â–„â–„â–ƒâ–ˆâ–…â–â–ˆâ–†â–…â–ƒâ–‚â–‚â–ƒâ–„â–…â–„â–‚â–‚â–†â–‚â–ƒâ–„â–„â–†â–…â–‚â–ƒâ–‚
wandb:      train/ensemble_f1 â–ƒâ–…â–‡â–‡â–„â–…â–…â–„â–†â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–…â–‚â–ˆâ–†â–…â–ƒâ–‚â–â–ƒâ–…â–…â–„â–‚â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–â–…â–ƒâ–ƒâ–‚
wandb:         train/mil_loss â–„â–†â–†â–…â–ˆâ–‚â–„â–ƒâ–â–„â–ˆâ–„â–ƒâ–„â–„â–†â–„â–…â–…â–‚â–‚â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–…â–‚â–…â–„â–„â–â–…â–…â–â–â–‚â–„
wandb:      train/policy_loss â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–â–„â–„â–‚â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.27008
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.90822
wandb:      eval/avg_mil_loss 0.24322
wandb:       eval/ensemble_f1 0.90822
wandb:            test/avg_f1 0.92061
wandb:      test/avg_mil_loss 0.17584
wandb:       test/ensemble_f1 0.92061
wandb:           train/avg_f1 0.8863
wandb:      train/ensemble_f1 0.8863
wandb:         train/mil_loss 0.2043
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smart-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sp2l1ka6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061446-sp2l1ka6/logs
wandb: Agent Starting Run: 1r7as9oj with config:
wandb: 	actor_learning_rate: 1.1519261567354776e-05
wandb: 	attention_dropout_p: 0.2850953035243475
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17502422730078304
wandb: 	temperature: 9.088902891215564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061543-1r7as9oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1r7as9oj
wandb: uploading wandb-summary.json
wandb: uploading history steps 38-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–‡â–„â–â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–†â–ƒâ–‡â–†â–‡â–‚â–†â–†â–‡â–†â–„â–ƒâ–†â–ƒâ–„â–ƒâ–…â–†â–†â–†â–„â–â–‡â–ˆâ–‡â–…â–„â–ƒâ–„â–†â–†â–†â–…â–†â–ƒâ–†â–†â–‡
wandb:      eval/avg_mil_loss â–ƒâ–‚â–†â–„â–„â–‚â–â–„â–‚â–…â–â–ˆâ–‚â–â–‚â–†â–…â–„â–†â–ƒâ–„â–‚â–ƒâ–„â–†â–…â–â–ƒâ–â–…â–ƒâ–‡â–‡â–„â–ƒâ–‚â–…â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–…â–ƒâ–†â–†â–†â–‚â–…â–â–…â–ƒâ–ƒâ–…â–ˆâ–„â–ƒâ–…â–…â–…â–…â–ƒâ–â–‡â–…â–†â–…â–ƒâ–†â–ƒâ–„â–…â–…â–†â–…â–…â–‚â–…â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–ƒâ–‡â–†â–ƒâ–ˆâ–…â–‡â–†â–‚â–†â–‡â–‚â–„â–†â–‡â–ˆâ–…â–ˆâ–†â–‡â–‡â–…â–ƒâ–†â–…â–â–„â–„â–„â–‡â–„â–…â–†â–ƒâ–†â–†â–„â–†
wandb:      train/ensemble_f1 â–„â–…â–ƒâ–‡â–†â–ƒâ–ˆâ–…â–‡â–†â–†â–‡â–‚â–„â–‚â–†â–‡â–ˆâ–…â–ˆâ–†â–‡â–‡â–…â–ƒâ–†â–…â–â–„â–„â–„â–„â–…â–†â–ˆâ–ƒâ–†â–†â–„â–†
wandb:         train/mil_loss â–ˆâ–…â–â–…â–„â–â–„â–‚â–†â–…â–„â–†â–…â–„â–‡â–„â–…â–„â–„â–†â–‡â–ƒâ–„â–„â–‡â–…â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–…â–ƒâ–†â–†â–„â–‚â–„â–ƒ
wandb:      train/policy_loss â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.38034
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.90478
wandb:      eval/avg_mil_loss 0.29232
wandb:       eval/ensemble_f1 0.90478
wandb:            test/avg_f1 0.89732
wandb:      test/avg_mil_loss 0.2173
wandb:       test/ensemble_f1 0.89732
wandb:           train/avg_f1 0.89635
wandb:      train/ensemble_f1 0.89635
wandb:         train/mil_loss 0.21273
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run visionary-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1r7as9oj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061543-1r7as9oj/logs
wandb: Agent Starting Run: aw2o6wyf with config:
wandb: 	actor_learning_rate: 2.0159503585359495e-06
wandb: 	attention_dropout_p: 0.2700853310851547
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12315227998136412
wandb: 	temperature: 5.957903042044581
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061630-aw2o6wyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw2o6wyf
wandb: uploading wandb-summary.json
wandb: uploading history steps 73-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–‡â–ˆ
wandb:  best/eval_ensemble_f1 â–â–â–†â–ˆ
wandb:            eval/avg_f1 â–„â–„â–ƒâ–†â–†â–„â–„â–‡â–ƒâ–†â–‡â–‡â–†â–†â–„â–ƒâ–…â–ˆâ–†â–…â–‚â–‡â–„â–‡â–„â–…â–ƒâ–…â–…â–„â–„â–„â–â–†â–‚â–†â–ƒâ–‚â–ƒâ–„
wandb:      eval/avg_mil_loss â–‚â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–„â–…â–â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚â–„â–‚â–‚â–‚â–‡â–â–ƒâ–
wandb:       eval/ensemble_f1 â–‡â–…â–†â–ƒâ–‚â–…â–„â–„â–‡â–‚â–ˆâ–ƒâ–ƒâ–†â–„â–„â–†â–…â–…â–‚â–‡â–‡â–ƒâ–â–†â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–…â–…â–ƒâ–…â–‚â–ƒâ–†â–â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–ˆâ–†â–†â–ƒâ–‚â–ˆâ–„â–…â–ƒâ–…â–ƒâ–…â–ƒâ–…â–â–…â–„â–ƒâ–†â–…â–…â–ƒâ–‚â–ƒâ–†â–„â–‡â–‡â–‚â–†â–‚â–ƒâ–ƒâ–ƒâ–†â–â–†â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–…â–†â–…â–…â–†â–‡â–„â–†â–…â–„â–‚â–…â–„â–„â–ƒâ–ˆâ–‚â–„â–…â–…â–„â–ƒâ–…â–„â–„â–…â–‚â–…â–‚â–„â–â–ƒâ–„â–…â–â–â–†â–ƒ
wandb:         train/mil_loss â–ˆâ–…â–…â–‡â–‡â–…â–†â–†â–†â–‡â–†â–…â–†â–‡â–†â–…â–„â–‡â–†â–„â–„â–ˆâ–‚â–…â–ˆâ–„â–ƒâ–â–…â–…â–ƒâ–„â–„â–…â–„â–ƒâ–‚â–ƒâ–‚â–
wandb:      train/policy_loss â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.26389
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.90098
wandb:      eval/avg_mil_loss 0.21614
wandb:       eval/ensemble_f1 0.90098
wandb:            test/avg_f1 0.90623
wandb:      test/avg_mil_loss 0.20256
wandb:       test/ensemble_f1 0.90623
wandb:           train/avg_f1 0.88402
wandb:      train/ensemble_f1 0.88402
wandb:         train/mil_loss 0.18463
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run desert-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw2o6wyf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061630-aw2o6wyf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tpmh8wyj with config:
wandb: 	actor_learning_rate: 2.6449851989575936e-06
wandb: 	attention_dropout_p: 0.34523222295663786
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.082574979520052
wandb: 	temperature: 9.762945871317047
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061757-tpmh8wyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpmh8wyj
wandb: uploading history steps 38-55, summary; uploading wandb-summary.json
wandb: uploading history steps 38-55, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ƒâ–ˆâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–ƒâ–†â–‚â–…â–„â–†â–†â–ƒâ–…â–ˆâ–…â–ƒâ–ˆâ–„â–ƒâ–…â–ƒâ–…â–‚â–†â–‚â–ƒâ–†â–ƒâ–„â–‚â–‚â–‚â–„â–‚â–…â–„â–ƒâ–‚â–ƒâ–â–‚â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–‚â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–â–ƒâ–‚â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‡â–‚â–‚â–‚â–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–†â–‚â–ƒâ–…â–ƒâ–
wandb:       eval/ensemble_f1 â–…â–ƒâ–†â–‚â–…â–„â–†â–…â–…â–…â–…â–ˆâ–…â–ƒâ–ˆâ–ƒâ–…â–ƒâ–…â–†â–‚â–†â–‚â–†â–ƒâ–„â–‚â–‚â–â–‚â–„â–‚â–…â–„â–ƒâ–‚â–ƒâ–â–‚â–…
wandb:           train/avg_f1 â–„â–†â–ƒâ–…â–â–†â–…â–„â–„â–„â–†â–‚â–…â–ˆâ–„â–ƒâ–„â–„â–‚â–…â–…â–„â–ˆâ–„â–‚â–†â–†â–‚â–†â–„â–ƒâ–†â–ƒâ–‚â–ƒâ–…â–…â–…â–…â–‚
wandb:      train/ensemble_f1 â–†â–„â–…â–…â–‚â–…â–…â–…â–„â–„â–‡â–‚â–â–„â–ˆâ–‡â–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–ˆâ–…â–‚â–…â–„â–â–†â–ƒâ–‚â–†â–ƒâ–‚â–‚â–‡â–…â–…â–„â–‚
wandb:         train/mil_loss â–‚â–…â–ƒâ–…â–„â–„â–â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ˆâ–ƒâ–…â–ƒâ–†â–‡â–„â–â–…â–ƒâ–„â–‚â–‚â–„â–„â–‚â–ƒâ–…â–†â–„â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–ˆâ–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–†â–…â–…â–…â–…â–„â–†â–…â–†â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.25462
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.90034
wandb:      eval/avg_mil_loss 0.20521
wandb:       eval/ensemble_f1 0.90034
wandb:           train/avg_f1 0.88125
wandb:      train/ensemble_f1 0.88125
wandb:         train/mil_loss 3.92125
wandb:      train/policy_loss -0.1003
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.1003
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eternal-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpmh8wyj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061757-tpmh8wyj/logs
wandb: ERROR Run tpmh8wyj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: h4y64r2h with config:
wandb: 	actor_learning_rate: 1.402868033822093e-06
wandb: 	attention_dropout_p: 0.11829577224427644
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5775944145838223
wandb: 	temperature: 2.9432986469056397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061849-h4y64r2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h4y64r2h
wandb: uploading history steps 71-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–†â–ƒâ–…â–„â–…â–…â–„â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–â–„â–‚â–„
wandb:      eval/avg_mil_loss â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–‚â–‚â–„â–„â–…â–†â–„â–†â–ƒâ–…â–†â–„â–„â–†â–†â–†â–…â–…â–‡â–…â–†â–„â–‡â–†â–ˆâ–„
wandb:       eval/ensemble_f1 â–…â–ˆâ–‡â–†â–ˆâ–†â–†â–‡â–‡â–†â–…â–‡â–‡â–‡â–†â–‡â–„â–…â–†â–…â–…â–†â–„â–ƒâ–…â–„â–ƒâ–…â–…â–…â–…â–ƒâ–ƒâ–„â–„â–â–„â–„â–‚â–„
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–‡â–…â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–…â–‡â–…â–†â–…â–…â–†â–…â–…â–…â–…â–„â–…â–…â–…â–ƒâ–ƒâ–„â–„â–„â–ƒâ–‚â–‚â–ƒâ–‚â–
wandb:      train/ensemble_f1 â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–†â–‡â–‡â–…â–†â–…â–…â–†â–…â–…â–…â–†â–…â–„â–…â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–
wandb:         train/mil_loss â–ˆâ–‡â–†â–…â–†â–†â–…â–‡â–…â–…â–…â–‡â–ƒâ–†â–ƒâ–„â–…â–…â–ƒâ–„â–…â–„â–…â–†â–„â–…â–ƒâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–â–ƒâ–…â–ƒ
wandb:      train/policy_loss â–„â–†â–…â–†â–„â–†â–‡â–‚â–„â–ˆâ–…â–„â–ƒâ–†â–†â–„â–„â–„â–â–„â–„â–„â–‚â–„â–„â–…â–†â–†â–‡â–†â–†â–„â–„â–†â–„â–„â–„â–„â–‚â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–ƒâ–„â–„â–ˆâ–ƒâ–ƒâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91898
wandb: best/eval_avg_mil_loss 0.23577
wandb:  best/eval_ensemble_f1 0.91898
wandb:            eval/avg_f1 0.86492
wandb:      eval/avg_mil_loss 0.32829
wandb:       eval/ensemble_f1 0.86492
wandb:           train/avg_f1 0.82045
wandb:      train/ensemble_f1 0.82045
wandb:         train/mil_loss 0.19562
wandb:      train/policy_loss 0.0805
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0805
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h4y64r2h
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061849-h4y64r2h/logs
wandb: ERROR Run h4y64r2h errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ypo8ue52 with config:
wandb: 	actor_learning_rate: 2.0879682607719107e-06
wandb: 	attention_dropout_p: 0.15488476303322968
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8786041470517116
wandb: 	temperature: 9.70239165321868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062012-ypo8ue52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ypo8ue52
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ƒâ–â–‚â–‚â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–‚â–ƒâ–‡â–‡â–ˆâ–„â–‚â–„â–ƒâ–ƒâ–„â–„â–†â–ƒâ–„â–†â–„â–‡â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–†â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–â–…â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–‚â–„â–â–…â–‚â–‚â–„â–…â–‡â–‚â–†â–†â–†â–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‡â–…â–ˆâ–…â–„â–„â–…â–…â–†â–…â–‡â–ˆâ–†â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–‡â–…â–‚â–‚â–‡â–ƒâ–ˆâ–„â–‚â–ƒâ–„â–…â–„â–ƒâ–†â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–…â–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–†â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–„â–…â–ˆâ–‡â–…â–‡â–†â–†â–…â–‡â–†â–…â–†â–„â–‡â–‡â–…â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–†â–ƒâ–…â–â–†â–„â–‚â–‚â–ƒâ–„â–„â–â–„â–‚â–„
wandb:      train/ensemble_f1 â–ˆâ–…â–…â–‡â–‡â–‡â–…â–†â–…â–‡â–…â–…â–†â–…â–†â–…â–†â–‡â–†â–ˆâ–…â–„â–ƒâ–ƒâ–„â–„â–…â–„â–‚â–…â–‡â–‚â–„â–ƒâ–‚â–ƒâ–„â–…â–â–‚
wandb:         train/mil_loss â–ˆâ–†â–‡â–…â–‡â–†â–‡â–…â–„â–ƒâ–„â–†â–†â–„â–ƒâ–…â–†â–„â–ˆâ–†â–ƒâ–‚â–…â–â–„â–‚â–ƒâ–‡â–…â–‡â–„â–…â–„â–„â–„â–†â–„â–†â–†â–†
wandb:      train/policy_loss â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92323
wandb: best/eval_avg_mil_loss 0.35125
wandb:  best/eval_ensemble_f1 0.92323
wandb:            eval/avg_f1 0.88316
wandb:      eval/avg_mil_loss 0.27271
wandb:       eval/ensemble_f1 0.88316
wandb:            test/avg_f1 0.85084
wandb:      test/avg_mil_loss 0.33
wandb:       test/ensemble_f1 0.85084
wandb:           train/avg_f1 0.88432
wandb:      train/ensemble_f1 0.88432
wandb:         train/mil_loss 0.18097
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ypo8ue52
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062012-ypo8ue52/logs
wandb: Agent Starting Run: 3a4wigp1 with config:
wandb: 	actor_learning_rate: 1.0297001819174946e-05
wandb: 	attention_dropout_p: 0.391762503467407
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31888789177917176
wandb: 	temperature: 2.2590410174163567
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062140-3a4wigp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3a4wigp1
wandb: uploading history steps 128-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–†â–â–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–„â–ˆâ–‡â–†â–ˆâ–…â–…â–†â–†â–†â–†â–‡â–…â–‡â–†â–…â–ˆâ–…â–„â–‡â–†â–‡â–„â–…â–„â–…â–†â–ƒâ–„â–‚â–„â–„â–ƒâ–‚â–‚â–â–â–‚
wandb:      eval/avg_mil_loss â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–„â–‚â–ƒâ–‚â–â–…â–„â–„â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–…â–ƒâ–„â–†â–…â–…â–‡â–†â–‡â–‡â–†â–ˆâ–†â–‡â–ˆ
wandb:       eval/ensemble_f1 â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–…â–ˆâ–†â–…â–‡â–†â–†â–…â–…â–…â–‡â–„â–†â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚
wandb:           train/avg_f1 â–‡â–†â–‡â–ˆâ–†â–ˆâ–‡â–‡â–†â–‡â–†â–†â–†â–…â–…â–‡â–„â–…â–…â–…â–„â–…â–…â–ƒâ–…â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–â–â–ƒâ–‚
wandb:      train/ensemble_f1 â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†â–ƒâ–…â–„â–ƒâ–…â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–‡â–†â–†â–‡â–‡â–†â–†â–…â–†â–„â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–‡â–…â–…â–…â–…â–„â–…â–‡â–…â–…â–…â–ˆâ–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–ˆâ–†â–…â–â–…â–…â–…â–…â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9186
wandb: best/eval_avg_mil_loss 0.27224
wandb:  best/eval_ensemble_f1 0.9186
wandb:            eval/avg_f1 0.83952
wandb:      eval/avg_mil_loss 0.45458
wandb:       eval/ensemble_f1 0.83952
wandb:           train/avg_f1 0.82869
wandb:      train/ensemble_f1 0.82869
wandb:         train/mil_loss 1.60323
wandb:      train/policy_loss 0.1365
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.1365
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run clear-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3a4wigp1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062140-3a4wigp1/logs
wandb: ERROR Run 3a4wigp1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 68p233j1 with config:
wandb: 	actor_learning_rate: 0.0003689158634652431
wandb: 	attention_dropout_p: 0.4876330717928533
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05214692715107838
wandb: 	temperature: 3.386479136088658
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062450-68p233j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68p233j1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‚â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–„â–…â–…â–†â–„â–ƒâ–…â–…â–„â–â–…â–„â–„â–‚â–ƒâ–ƒâ–ˆâ–…â–…â–ƒâ–‚â–„â–…â–…â–‡â–…â–‚â–„â–†â–„â–‚â–…â–„â–„â–ƒâ–‚â–ƒâ–…
wandb:      eval/avg_mil_loss â–„â–‚â–…â–„â–ˆâ–‚â–‚â–„â–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–‡â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–†â–„â–â–„â–…â–ƒâ–„â–„â–…â–…
wandb:       eval/ensemble_f1 â–ƒâ–„â–…â–‚â–„â–„â–ƒâ–…â–†â–„â–â–…â–„â–„â–…â–ƒâ–ˆâ–…â–‚â–…â–‚â–„â–…â–†â–…â–…â–‚â–…â–†â–„â–…â–„â–‡â–„â–…â–ƒâ–‚â–ƒâ–„â–…
wandb:           train/avg_f1 â–„â–„â–ˆâ–†â–…â–†â–‡â–ˆâ–ƒâ–†â–…â–‡â–„â–†â–…â–‡â–†â–†â–ƒâ–„â–‡â–…â–„â–„â–„â–†â–†â–ˆâ–…â–†â–ƒâ–ƒâ–„â–ƒâ–‡â–ƒâ–„â–ƒâ–„â–
wandb:      train/ensemble_f1 â–„â–„â–ˆâ–†â–…â–†â–ˆâ–„â–†â–‡â–‡â–…â–†â–†â–‡â–†â–„â–ˆâ–„â–„â–…â–„â–„â–…â–„â–†â–†â–ˆâ–ƒâ–…â–‡â–â–ƒâ–„â–…â–‚â–„â–„â–„â–‚
wandb:         train/mil_loss â–ˆâ–„â–…â–†â–…â–„â–ƒâ–†â–„â–…â–†â–„â–…â–‡â–…â–ƒâ–ƒâ–„â–…â–†â–…â–ƒâ–„â–„â–…â–„â–‚â–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–„â–…â–‡
wandb:      train/policy_loss â–…â–…â–†â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–â–ƒâ–…â–…â–…â–ƒâ–…â–†â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–„â–…â–…â–†â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–†â–…â–â–†â–ƒâ–…â–ƒâ–…â–…â–†â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–„â–…â–…â–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93402
wandb: best/eval_avg_mil_loss 0.24659
wandb:  best/eval_ensemble_f1 0.93402
wandb:            eval/avg_f1 0.90498
wandb:      eval/avg_mil_loss 0.29008
wandb:       eval/ensemble_f1 0.90498
wandb:           train/avg_f1 0.876
wandb:      train/ensemble_f1 0.876
wandb:         train/mil_loss 0.23077
wandb:      train/policy_loss 0.77152
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.77152
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dashing-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68p233j1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062450-68p233j1/logs
wandb: ERROR Run 68p233j1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0yl04xv8 with config:
wandb: 	actor_learning_rate: 3.705344422532654e-05
wandb: 	attention_dropout_p: 0.04011388817524275
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20357229942733104
wandb: 	temperature: 7.172225215947245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062542-0yl04xv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yl04xv8
wandb: uploading history steps 101-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–ˆâ–†â–†â–†â–‡â–†â–†â–†â–‡â–…â–„â–‡â–†â–‡â–…â–…â–†â–ƒâ–…â–„â–†â–ƒâ–…â–ƒâ–†â–†â–…â–ƒâ–…â–‡â–ƒâ–ƒâ–„â–â–…â–ƒâ–ƒâ–…â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–…â–„â–ƒâ–ƒâ–â–†â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–„â–ƒâ–„â–ˆâ–„â–„â–…â–„â–ƒâ–„â–„â–‚â–ƒâ–„â–„â–ƒâ–…â–‡â–…â–ƒâ–…â–ƒâ–…â–ˆâ–…â–ƒâ–†
wandb:       eval/ensemble_f1 â–„â–†â–ˆâ–†â–†â–ˆâ–†â–‡â–‡â–‡â–†â–†â–‡â–†â–ƒâ–ˆâ–‡â–…â–…â–†â–â–†â–…â–„â–†â–ƒâ–…â–…â–‡â–‡â–ƒâ–ƒâ–†â–…â–„â–„â–‚â–…â–„â–‚
wandb:           train/avg_f1 â–ˆâ–†â–ˆâ–‡â–‡â–†â–‡â–†â–…â–‡â–ˆâ–†â–…â–†â–ˆâ–†â–‡â–†â–ƒâ–‡â–†â–‡â–‡â–„â–†â–†â–‡â–„â–…â–…â–…â–„â–…â–…â–„â–‚â–„â–†â–„â–
wandb:      train/ensemble_f1 â–‡â–†â–ˆâ–†â–†â–‡â–…â–‡â–†â–„â–†â–„â–…â–…â–…â–…â–„â–…â–…â–†â–†â–„â–†â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–‚â–â–‚â–‚â–„â–ƒ
wandb:         train/mil_loss â–ƒâ–ˆâ–ˆâ–ƒâ–†â–†â–‚â–„â–„â–ƒâ–‡â–…â–„â–„â–ƒâ–†â–„â–„â–ƒâ–ƒâ–‚â–…â–„â–‚â–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–
wandb:      train/policy_loss â–„â–ˆâ–„â–„â–„â–„â–‚â–ˆâ–„â–…â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–†â–„â–„â–„â–„â–‡â–„â–†â–„â–†â–„â–„â–„â–„â–„â–„â–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–„â–„â–„â–„â–„â–„â–‚â–„â–„â–…â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.25719
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.85765
wandb:      eval/avg_mil_loss 0.31736
wandb:       eval/ensemble_f1 0.85765
wandb:           train/avg_f1 0.8603
wandb:      train/ensemble_f1 0.8603
wandb:         train/mil_loss 0.21501
wandb:      train/policy_loss -0.11703
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.11703
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yl04xv8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062542-0yl04xv8/logs
wandb: ERROR Run 0yl04xv8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: w8r1k87f with config:
wandb: 	actor_learning_rate: 1.389017796574796e-06
wandb: 	attention_dropout_p: 0.2656203457080973
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.799406975804411
wandb: 	temperature: 9.689374787847475
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062720-w8r1k87f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8r1k87f
wandb: uploading wandb-summary.json
wandb: uploading history steps 84-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆâ–‡â–…â–â–†
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–‡â–†â–‡â–†â–…â–…â–†â–ƒâ–†â–†â–„â–„â–‡â–„â–ˆâ–„â–„â–‡â–ˆâ–…â–…â–…â–…â–…â–„â–â–…â–‚â–„â–„â–…â–â–…â–…â–…â–‚â–‚
wandb:      eval/avg_mil_loss â–„â–‚â–†â–„â–â–ƒâ–ƒâ–â–„â–ƒâ–†â–‚â–ƒâ–…â–…â–„â–ƒâ–†â–†â–â–…â–ƒâ–â–…â–†â–ˆâ–‡â–†â–„â–†â–ƒâ–„â–„â–ƒâ–…â–â–„â–…â–…â–‡
wandb:       eval/ensemble_f1 â–‡â–†â–ˆâ–†â–ˆâ–…â–†â–‡â–‡â–…â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–†â–„â–„â–†â–…â–„â–„â–‚â–…â–„â–„â–ˆâ–„â–„â–‚â–ƒâ–â–†â–†â–‡â–†â–…â–‚
wandb:           train/avg_f1 â–„â–†â–†â–…â–‡â–…â–„â–…â–…â–…â–ˆâ–„â–ƒâ–…â–‚â–ƒâ–ƒâ–„â–„â–„â–‚â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–â–â–‚â–â–‚
wandb:      train/ensemble_f1 â–„â–†â–…â–†â–‡â–‡â–†â–„â–…â–…â–…â–„â–†â–…â–†â–…â–ˆâ–…â–‚â–…â–ƒâ–…â–ƒâ–„â–â–„â–„â–â–ƒâ–„â–ƒâ–‚â–„â–â–ƒâ–â–ƒâ–â–â–‚
wandb:         train/mil_loss â–…â–„â–†â–†â–‡â–…â–ƒâ–…â–ˆâ–†â–ƒâ–†â–„â–ƒâ–…â–ƒâ–„â–‚â–â–…â–†â–‚â–ƒâ–…â–‡â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–†â–„â–‚â–‚â–…â–…â–â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91943
wandb: best/eval_avg_mil_loss 0.27593
wandb:  best/eval_ensemble_f1 0.91943
wandb:            eval/avg_f1 0.84668
wandb:      eval/avg_mil_loss 0.44682
wandb:       eval/ensemble_f1 0.84668
wandb:           train/avg_f1 0.86685
wandb:      train/ensemble_f1 0.86685
wandb:         train/mil_loss 0.24124
wandb:      train/policy_loss 0.77073
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.77073
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run robust-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8r1k87f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062720-w8r1k87f/logs
wandb: ERROR Run w8r1k87f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6pflodzi with config:
wandb: 	actor_learning_rate: 3.223058242438322e-05
wandb: 	attention_dropout_p: 0.4039506484151494
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 58
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38631857919048695
wandb: 	temperature: 0.8751047632704234
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062918-6pflodzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6pflodzi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–†â–…â–†â–‡â–†â–…â–†â–ƒâ–„â–†â–†â–†â–â–‡â–†â–…â–ƒâ–…â–„â–†â–‡â–†â–‡â–…â–…â–„â–†â–†â–ˆâ–ƒâ–„â–…â–…â–‡â–…â–…â–„â–„
wandb:      eval/avg_mil_loss â–…â–‡â–†â–‚â–…â–†â–ƒâ–‡â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–‡â–…â–†â–…â–ƒâ–„â–†â–…â–†â–‚â–…â–„â–â–ƒâ–ˆâ–‚â–†â–‡â–†â–ƒâ–„â–„â–‚â–„â–†
wandb:       eval/ensemble_f1 â–„â–‚â–ˆâ–‡â–‡â–†â–…â–‡â–„â–†â–‡â–‡â–â–…â–ˆâ–†â–†â–ƒâ–…â–‡â–‡â–‡â–‡â–ˆâ–‡â–…â–‡â–†â–„â–…â–ƒâ–…â–…â–…â–…â–‡â–…â–…â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‡â–…â–‡â–…â–ˆâ–‡â–‡â–…â–„â–…â–…â–…â–‡â–„â–„â–ƒâ–†â–†â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–‚â–„â–…â–„â–ƒâ–‚â–„â–‚â–„â–â–‚â–â–„â–‚
wandb:      train/ensemble_f1 â–„â–‡â–…â–‡â–†â–ˆâ–‡â–‡â–†â–…â–ƒâ–„â–„â–‡â–†â–„â–„â–†â–ƒâ–†â–‚â–„â–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–„â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–
wandb:         train/mil_loss â–ˆâ–ƒâ–…â–‚â–†â–†â–„â–ƒâ–„â–‚â–ƒâ–„â–…â–â–…â–†â–ƒâ–…â–ƒâ–ƒâ–†â–ƒâ–…â–„â–„â–„â–†â–„â–‚â–„â–‚â–â–â–†â–†â–‚â–…â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–‚â–‚â–ƒâ–‚â–‚â–„â–†â–ƒâ–‚â–„â–†â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–†â–‚â–ƒâ–‚â–„â–‚â–†â–â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–„â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91573
wandb: best/eval_avg_mil_loss 0.25875
wandb:  best/eval_ensemble_f1 0.91573
wandb:            eval/avg_f1 0.87206
wandb:      eval/avg_mil_loss 0.33053
wandb:       eval/ensemble_f1 0.87206
wandb:            test/avg_f1 0.88012
wandb:      test/avg_mil_loss 0.26131
wandb:       test/ensemble_f1 0.88012
wandb:           train/avg_f1 0.87254
wandb:      train/ensemble_f1 0.87254
wandb:         train/mil_loss 0.19484
wandb:      train/policy_loss 0.14099
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.14099
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run legendary-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6pflodzi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062918-6pflodzi/logs
wandb: Agent Starting Run: uub846qa with config:
wandb: 	actor_learning_rate: 0.00016033649991883963
wandb: 	attention_dropout_p: 0.39836079674220287
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 155
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28449930297579085
wandb: 	temperature: 2.240531648500763
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063028-uub846qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uub846qa
wandb: uploading history steps 112-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–„â–†â–…â–†â–„â–ˆâ–†â–†â–„â–„â–†â–…â–„â–†â–„â–…â–ƒâ–†â–„â–†â–†â–…â–„â–…â–…â–„â–‚â–„â–â–…â–‚â–â–‚â–ƒâ–‚â–â–â–‚
wandb:      eval/avg_mil_loss â–…â–ƒâ–â–â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–‚â–…â–‚â–„â–†â–…â–ƒâ–‚â–„â–„â–‚â–ƒâ–…â–…â–„â–†â–‡â–†â–…â–…â–…â–„â–ˆâ–†â–…â–‡â–‡
wandb:       eval/ensemble_f1 â–ˆâ–†â–„â–…â–‡â–†â–„â–‡â–†â–„â–„â–†â–†â–‡â–ƒâ–†â–…â–ƒâ–„â–†â–†â–†â–†â–†â–ƒâ–‚â–„â–‚â–†â–‚â–„â–â–‚â–‚â–ƒâ–‚â–‚â–â–â–
wandb:           train/avg_f1 â–…â–†â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–„â–†â–‡â–ˆâ–‡â–ˆâ–†â–†â–…â–†â–‡â–†â–…â–…â–„â–…â–†â–†â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–
wandb:      train/ensemble_f1 â–…â–†â–‡â–†â–‡â–‡â–†â–ˆâ–‡â–‡â–†â–ˆâ–†â–‡â–„â–ˆâ–‡â–‡â–‡â–ˆâ–…â–…â–†â–…â–…â–„â–„â–…â–†â–†â–†â–ƒâ–…â–ƒâ–…â–‚â–„â–‚â–ƒâ–
wandb:         train/mil_loss â–ˆâ–‡â–‡â–ˆâ–†â–†â–ˆâ–†â–‡â–‡â–ˆâ–„â–†â–‡â–„â–‡â–ƒâ–„â–†â–„â–ƒâ–â–…â–„â–ƒâ–„â–„â–ƒâ–†â–„â–‚â–‚â–ƒâ–„â–ƒâ–â–â–‚â–â–
wandb:      train/policy_loss â–„â–„â–ˆâ–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.22773
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.85296
wandb:      eval/avg_mil_loss 0.37278
wandb:       eval/ensemble_f1 0.85296
wandb:           train/avg_f1 0.85516
wandb:      train/ensemble_f1 0.85516
wandb:         train/mil_loss 2.87711
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ruby-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uub846qa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063028-uub846qa/logs
wandb: ERROR Run uub846qa errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v4rfvm8q with config:
wandb: 	actor_learning_rate: 0.0001482107590594552
wandb: 	attention_dropout_p: 0.0735707576507032
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6771944340111713
wandb: 	temperature: 4.4469625409765134
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063243-v4rfvm8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4rfvm8q
wandb: uploading history steps 186-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–ˆâ–‡â–„â–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–…â–†â–ˆâ–‚â–…â–‚â–…â–†â–…â–…â–…â–„â–†â–†â–„â–†â–‡â–…â–„â–ƒâ–ƒâ–…â–†â–„â–†â–…â–â–†â–†â–‡â–„â–†â–ƒâ–†â–†â–…â–„â–„
wandb:      eval/avg_mil_loss â–ˆâ–„â–†â–ƒâ–„â–ƒâ–„â–‚â–â–ƒâ–‚â–†â–†â–…â–…â–…â–†â–‚â–„â–„â–„â–„â–„â–‚â–…â–ƒâ–„â–„â–…â–…â–‚â–„â–…â–…â–„â–…â–„â–…â–„â–„
wandb:       eval/ensemble_f1 â–‚â–„â–…â–‡â–‡â–‡â–‚â–„â–…â–„â–„â–…â–„â–†â–„â–…â–ƒâ–„â–…â–„â–ƒâ–„â–â–ƒâ–†â–†â–ƒâ–ˆâ–…â–†â–„â–…â–‚â–‚â–…â–„â–„â–…â–…â–…
wandb:           train/avg_f1 â–†â–‡â–†â–‚â–ˆâ–†â–…â–…â–‡â–„â–ƒâ–†â–„â–„â–†â–…â–†â–‡â–ƒâ–†â–…â–ƒâ–…â–â–‚â–‚â–‚â–‡â–ƒâ–„â–…â–‡â–â–…â–„â–†â–ˆâ–†â–…â–…
wandb:      train/ensemble_f1 â–…â–‚â–ˆâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–…â–‚â–‡â–ƒâ–ƒâ–…â–…â–…â–‚â–†â–ƒâ–‚â–‚â–…â–†â–…â–„â–‚â–„â–†â–†â–â–ƒâ–„â–…â–„â–…
wandb:         train/mil_loss â–ˆâ–…â–„â–‡â–„â–…â–…â–‡â–…â–…â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–†â–„â–„â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–„â–‚â–…â–…â–â–†â–„â–†â–„â–ƒâ–…â–‚
wandb:      train/policy_loss â–â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.24138
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.87373
wandb:      eval/avg_mil_loss 0.29551
wandb:       eval/ensemble_f1 0.87373
wandb:           train/avg_f1 0.89405
wandb:      train/ensemble_f1 0.89405
wandb:         train/mil_loss 0.2407
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4rfvm8q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063243-v4rfvm8q/logs
wandb: ERROR Run v4rfvm8q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kblduoza with config:
wandb: 	actor_learning_rate: 1.8336827046139213e-06
wandb: 	attention_dropout_p: 0.33144553973648905
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11464995548577615
wandb: 	temperature: 6.203726555885444
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063614-kblduoza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kblduoza
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 54-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–†â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–†â–ƒâ–…â–‡â–„â–ƒâ–†â–‡â–„â–…â–‡â–…â–„â–ƒâ–†â–…â–…â–†â–‚â–ˆâ–ƒâ–ƒâ–‚â–‡â–â–‡â–â–…â–†â–„â–ˆâ–…â–‡â–…â–‚â–†â–â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–„â–ƒâ–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ˆâ–„â–„â–ƒâ–‚â–„â–â–†â–ƒâ–‚â–…â–‚â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–†â–…â–‚â–…â–‡â–„â–ƒâ–†â–‚â–„â–…â–‡â–…â–„â–ƒâ–†â–…â–…â–†â–‚â–ˆâ–ƒâ–ƒâ–†â–â–‡â–â–ˆâ–†â–ˆâ–…â–‡â–…â–†â–‚â–‡â–†â–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–…â–‚â–†â–„â–‚â–ƒâ–†â–„â–‚â–„â–†â–„â–„â–‚â–â–…â–ƒâ–‚â–„â–„â–‚â–„â–„â–ƒâ–ƒâ–…â–†â–…â–†â–„â–„â–„â–ƒâ–ƒâ–„â–ˆâ–…â–ƒ
wandb:      train/ensemble_f1 â–‡â–„â–†â–ƒâ–‡â–†â–„â–ˆâ–‚â–„â–…â–…â–„â–ƒâ–…â–…â–ƒâ–â–‚â–„â–†â–†â–…â–†â–ƒâ–…â–†â–ˆâ–†â–†â–‡â–…â–…â–†â–†â–„â–‡â–…â–‡â–„
wandb:         train/mil_loss â–‡â–…â–‡â–„â–„â–ˆâ–…â–†â–…â–‡â–†â–†â–…â–…â–†â–„â–†â–†â–„â–„â–…â–…â–…â–ƒâ–‚â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–â–ƒâ–â–„
wandb:      train/policy_loss â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91886
wandb: best/eval_avg_mil_loss 0.15201
wandb:  best/eval_ensemble_f1 0.91886
wandb:            eval/avg_f1 0.88606
wandb:      eval/avg_mil_loss 0.37743
wandb:       eval/ensemble_f1 0.88606
wandb:            test/avg_f1 0.90887
wandb:      test/avg_mil_loss 0.18743
wandb:       test/ensemble_f1 0.90887
wandb:           train/avg_f1 0.88834
wandb:      train/ensemble_f1 0.88834
wandb:         train/mil_loss 0.93315
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swift-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kblduoza
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063614-kblduoza/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 25q49u9p with config:
wandb: 	actor_learning_rate: 0.0005665959013635104
wandb: 	attention_dropout_p: 0.10895751177542212
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9824228429058788
wandb: 	temperature: 7.987302139037187
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063716-25q49u9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25q49u9p
wandb: uploading history steps 167-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–‚â–…â–„â–ƒâ–…â–ˆâ–„â–…â–ˆâ–„â–ƒâ–„â–†â–…â–ƒâ–„â–…â–…â–ƒâ–…â–ƒâ–„â–‚â–†â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–
wandb:      eval/avg_mil_loss â–‚â–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–…â–†â–ƒâ–‡â–…â–†â–ƒâ–ƒâ–ˆâ–„â–„â–„â–…â–ƒâ–ƒâ–†â–„â–„â–„â–„â–â–„â–…â–†â–„â–„â–ƒâ–…â–„â–„â–…â–…
wandb:       eval/ensemble_f1 â–†â–„â–‚â–…â–ƒâ–ˆâ–…â–„â–ƒâ–‡â–†â–„â–†â–„â–„â–‡â–†â–…â–„â–…â–„â–ƒâ–†â–„â–…â–…â–‡â–„â–„â–…â–‚â–‡â–‚â–…â–„â–â–ƒâ–„â–…â–
wandb:           train/avg_f1 â–…â–…â–‡â–†â–†â–„â–†â–„â–‡â–…â–†â–…â–‡â–„â–„â–ƒâ–„â–„â–‚â–„â–…â–…â–ˆâ–„â–„â–†â–…â–„â–†â–„â–†â–…â–ƒâ–„â–‚â–…â–‚â–â–‚â–‚
wandb:      train/ensemble_f1 â–‡â–†â–…â–†â–ˆâ–‡â–ˆâ–…â–†â–†â–„â–…â–‡â–†â–…â–‡â–†â–‡â–…â–†â–‡â–„â–‡â–†â–„â–ƒâ–„â–†â–…â–„â–„â–ƒâ–ƒâ–…â–…â–„â–…â–ƒâ–â–…
wandb:         train/mil_loss â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–†â–‡â–†â–†â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.236
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.8648
wandb:      eval/avg_mil_loss 0.36222
wandb:       eval/ensemble_f1 0.8648
wandb:           train/avg_f1 0.87236
wandb:      train/ensemble_f1 0.87236
wandb:         train/mil_loss 1.01195
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run youthful-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25q49u9p
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063716-25q49u9p/logs
wandb: ERROR Run 25q49u9p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lqft7gq8 with config:
wandb: 	actor_learning_rate: 5.405036647935141e-05
wandb: 	attention_dropout_p: 0.4386715922750977
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3037816290396088
wandb: 	temperature: 1.4224872674587652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064002-lqft7gq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqft7gq8
wandb: uploading history steps 68-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–…â–†â–…â–…â–„â–†â–ˆâ–‡â–„â–…â–‚â–†â–ˆâ–…â–…â–â–„â–â–…â–†â–„â–…â–ƒâ–†â–†â–…â–ƒâ–…â–„â–ƒâ–…â–…â–„â–ƒâ–â–„â–‚â–†
wandb:      eval/avg_mil_loss â–ƒâ–‚â–‚â–„â–†â–ƒâ–â–ƒâ–‚â–„â–ƒâ–â–ƒâ–‚â–ˆâ–†â–â–ƒâ–ƒâ–â–‚â–ˆâ–„â–‡â–…â–‚â–…â–ƒâ–„â–…â–ƒâ–…â–…â–„â–ˆâ–„â–…â–„â–„â–†
wandb:       eval/ensemble_f1 â–ˆâ–„â–†â–„â–‡â–…â–„â–…â–…â–„â–†â–‡â–ƒâ–†â–„â–†â–ˆâ–‡â–†â–â–ƒâ–â–„â–…â–†â–„â–…â–ƒâ–†â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–†â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–†â–†â–…â–†â–†â–…â–†â–„â–…â–ƒâ–…â–…â–…â–†â–ƒâ–‚â–â–â–…â–‚â–â–‚â–„â–‚â–ƒ
wandb:      train/ensemble_f1 â–‡â–†â–‡â–‡â–†â–†â–ˆâ–…â–†â–„â–‡â–†â–†â–…â–…â–…â–…â–…â–…â–„â–†â–…â–ƒâ–ƒâ–„â–„â–„â–‚â–„â–„â–„â–„â–…â–„â–„â–„â–â–â–â–‚
wandb:         train/mil_loss â–‡â–„â–ƒâ–…â–…â–ˆâ–…â–†â–‡â–…â–…â–…â–†â–‡â–„â–ƒâ–…â–…â–„â–…â–…â–ƒâ–…â–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–…â–…â–‚â–‚â–â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–‚â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–‚â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–†â–„â–„â–„â–„â–„â–„â–†â–„â–„â–ˆâ–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.22159
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.90861
wandb:      eval/avg_mil_loss 0.32444
wandb:       eval/ensemble_f1 0.90861
wandb:            test/avg_f1 0.90964
wandb:      test/avg_mil_loss 0.22899
wandb:       test/ensemble_f1 0.90964
wandb:           train/avg_f1 0.88171
wandb:      train/ensemble_f1 0.88171
wandb:         train/mil_loss 0.20976
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run trim-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqft7gq8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064002-lqft7gq8/logs
wandb: Agent Starting Run: xn8fk95k with config:
wandb: 	actor_learning_rate: 4.9817694310635225e-06
wandb: 	attention_dropout_p: 0.26796709246993006
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29480004537870375
wandb: 	temperature: 6.077747928495553
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064114-xn8fk95k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xn8fk95k
wandb: uploading wandb-summary.json; uploading history steps 50-67, summary
wandb: uploading history steps 50-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ˆâ–„â–„â–‡â–„â–…â–ƒâ–ƒâ–†â–†â–…â–†â–†â–†â–â–†â–†â–†â–ƒâ–‡â–†â–†â–†â–†â–…â–‡â–‡â–…â–…â–†â–„â–„â–†â–‡â–†â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–…â–ƒâ–…â–ƒâ–†â–„â–ƒâ–ƒâ–„â–†â–„â–„â–‚â–â–‚â–„â–‚â–…â–„â–„â–†â–…â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–â–‡â–…â–„â–‚â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–ƒâ–‡â–„â–…â–ƒâ–…â–ˆâ–…â–‡â–…â–…â–„â–„â–†â–…â–â–…â–…â–…â–†â–…â–…â–„â–…â–†â–†â–†â–„â–„â–„â–…â–„â–…â–†â–…â–…â–‡â–…â–†
wandb:           train/avg_f1 â–…â–„â–â–ƒâ–‚â–ƒâ–…â–ƒâ–„â–ƒâ–…â–†â–…â–ˆâ–†â–‚â–‚â–„â–†â–„â–…â–ˆâ–…â–…â–„â–‚â–â–„â–…â–ƒâ–…â–…â–‚â–†â–ƒâ–ˆâ–†â–ˆâ–†â–…
wandb:      train/ensemble_f1 â–„â–‚â–„â–†â–‚â–„â–…â–…â–…â–„â–…â–…â–†â–…â–ˆâ–ƒâ–†â–…â–â–†â–†â–†â–…â–ƒâ–†â–„â–†â–ƒâ–…â–†â–„â–‡â–‡â–…â–…â–„â–ˆâ–‡â–ˆâ–†
wandb:         train/mil_loss â–‡â–ƒâ–…â–†â–†â–…â–„â–„â–„â–ƒâ–…â–„â–…â–ƒâ–„â–„â–â–„â–„â–„â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–ƒâ–„â–†â–„â–…â–ƒâ–ƒâ–„â–ˆâ–ƒâ–ƒâ–â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94099
wandb: best/eval_avg_mil_loss 0.24717
wandb:  best/eval_ensemble_f1 0.94099
wandb:            eval/avg_f1 0.90758
wandb:      eval/avg_mil_loss 0.32984
wandb:       eval/ensemble_f1 0.90758
wandb:           train/avg_f1 0.89637
wandb:      train/ensemble_f1 0.89637
wandb:         train/mil_loss 0.32625
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xn8fk95k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064114-xn8fk95k/logs
wandb: ERROR Run xn8fk95k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9mb067wy with config:
wandb: 	actor_learning_rate: 2.133198186858992e-05
wandb: 	attention_dropout_p: 0.3319575869697212
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43106988272520175
wandb: 	temperature: 4.7328829330492015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064221-9mb067wy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mb067wy
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–…â–…â–‡â–â–†â–…â–„â–„â–ˆâ–ƒâ–‡â–ƒâ–„â–ƒâ–„â–„â–…â–†â–„â–„â–†â–„â–„â–„â–ƒâ–…â–…â–ƒâ–‚â–…â–â–„â–‚â–ƒâ–‚â–‚â–…â–
wandb:      eval/avg_mil_loss â–…â–â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–‡â–‚â–„â–â–„â–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–…â–„â–†â–â–„â–‚â–â–„â–„â–„â–ƒâ–…â–…â–…â–ƒâ–â–†â–„â–…â–ƒâ–„â–…
wandb:       eval/ensemble_f1 â–‡â–„â–ˆâ–…â–†â–…â–„â–†â–„â–‚â–‡â–ƒâ–‡â–ƒâ–‡â–ˆâ–„â–‚â–…â–ƒâ–â–…â–„â–„â–ƒâ–ƒâ–„â–…â–ƒâ–†â–„â–…â–â–ƒâ–‚â–‚â–„â–ƒâ–…â–‚
wandb:           train/avg_f1 â–„â–†â–†â–†â–ˆâ–…â–ˆâ–†â–†â–…â–†â–†â–†â–ˆâ–†â–†â–…â–†â–…â–†â–„â–„â–…â–„â–ƒâ–…â–„â–…â–„â–†â–„â–‡â–‚â–ƒâ–…â–ƒâ–ƒâ–â–„â–ƒ
wandb:      train/ensemble_f1 â–„â–…â–†â–†â–…â–†â–…â–…â–ˆâ–†â–†â–†â–ˆâ–…â–†â–†â–‡â–…â–…â–†â–…â–†â–„â–„â–…â–‡â–„â–…â–„â–…â–…â–„â–†â–„â–†â–„â–ƒâ–„â–â–‚
wandb:         train/mil_loss â–…â–…â–‡â–ˆâ–„â–…â–…â–…â–…â–„â–†â–…â–†â–‡â–ƒâ–…â–…â–…â–…â–â–ƒâ–ƒâ–‡â–…â–†â–ƒâ–ƒâ–†â–„â–‚â–†â–‚â–…â–„â–…â–â–…â–ƒâ–â–…
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.28349
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.87591
wandb:      eval/avg_mil_loss 0.38873
wandb:       eval/ensemble_f1 0.87591
wandb:           train/avg_f1 0.88184
wandb:      train/ensemble_f1 0.88184
wandb:         train/mil_loss 2.73971
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mb067wy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064221-9mb067wy/logs
wandb: ERROR Run 9mb067wy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4ryj6co7 with config:
wandb: 	actor_learning_rate: 0.00018874105033241852
wandb: 	attention_dropout_p: 0.002527855623222608
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4981255301454741
wandb: 	temperature: 3.700377669722511
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064410-4ryj6co7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ryj6co7
wandb: uploading history steps 105-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–ƒâ–†â–ƒâ–ˆâ–…â–„â–ˆâ–…â–ƒâ–â–ƒâ–â–…â–„â–…â–‡â–ƒâ–‡â–„â–„â–‡â–†â–‡â–‡â–‚â–…â–†â–†â–ƒâ–…â–„â–„â–‡â–„â–†â–‚â–„â–†
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ƒâ–â–„â–‚â–ƒâ–ˆâ–„â–ˆâ–‚â–†â–ƒâ–†â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–‚â–…â–‚â–ƒâ–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–â–ƒâ–‚â–ƒâ–ˆâ–„â–…â–„â–‚â–ˆâ–‚â–„â–„â–…â–‡â–†â–„â–†â–…â–„â–‚â–†â–…â–ƒâ–…â–â–„â–…â–ƒâ–„â–„â–‡â–„â–…â–†â–…â–‚â–ƒâ–‚â–‡
wandb:           train/avg_f1 â–‚â–„â–„â–ƒâ–ƒâ–…â–â–…â–„â–ƒâ–„â–…â–„â–ˆâ–„â–„â–…â–ƒâ–ƒâ–…â–‚â–ˆâ–‚â–ƒâ–„â–‚â–‡â–ˆâ–…â–„â–ˆâ–„â–…â–…â–„â–‡â–‚â–â–†â–†
wandb:      train/ensemble_f1 â–ˆâ–„â–‡â–ƒâ–†â–…â–„â–ƒâ–†â–ˆâ–„â–„â–„â–â–ƒâ–…â–…â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–‡â–„â–ƒâ–…â–…â–‚â–„â–ˆâ–„â–„â–†â–†â–ƒâ–†â–‚â–‡
wandb:         train/mil_loss â–ˆâ–„â–„â–ƒâ–‚â–…â–â–…â–â–ƒâ–„â–â–†â–…â–…â–…â–…â–ƒâ–‚â–†â–„â–†â–†â–‚â–„â–†â–…â–†â–‡â–ƒâ–„â–„â–†â–…â–ƒâ–‚â–…â–ƒâ–…â–…
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91919
wandb: best/eval_avg_mil_loss 0.19711
wandb:  best/eval_ensemble_f1 0.91919
wandb:            eval/avg_f1 0.90832
wandb:      eval/avg_mil_loss 0.29371
wandb:       eval/ensemble_f1 0.90832
wandb:           train/avg_f1 0.89543
wandb:      train/ensemble_f1 0.89543
wandb:         train/mil_loss 0.2848
wandb:      train/policy_loss 0.53082
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.53082
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worldly-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ryj6co7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064410-4ryj6co7/logs
wandb: ERROR Run 4ryj6co7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mx5zsppc with config:
wandb: 	actor_learning_rate: 8.061241658030274e-05
wandb: 	attention_dropout_p: 0.3963362061086197
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6184658237400195
wandb: 	temperature: 4.759491038392765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064548-mx5zsppc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mx5zsppc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–†â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–†â–‡â–ˆâ–…â–‡â–ˆâ–†â–ˆâ–‡â–†â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–ˆâ–…â–†â–†â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–‚â–
wandb:      eval/avg_mil_loss â–‚â–„â–â–„â–ƒâ–ƒâ–†â–‚â–„â–„â–„â–„â–‚â–ƒâ–„â–†â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–†â–„â–†â–†â–ˆâ–†â–‡â–‡â–†
wandb:       eval/ensemble_f1 â–ˆâ–…â–†â–‡â–†â–…â–†â–ˆâ–†â–†â–†â–…â–ƒâ–†â–ˆâ–†â–„â–†â–†â–‡â–ˆâ–†â–‡â–†â–‡â–ƒâ–„â–†â–ƒâ–…â–…â–†â–‚â–‚â–‚â–â–ƒâ–‚â–â–‚
wandb:           train/avg_f1 â–‡â–ˆâ–ˆâ–‡â–†â–†â–‡â–‡â–…â–ˆâ–…â–‡â–ˆâ–ˆâ–…â–‡â–†â–‡â–‡â–†â–‡â–…â–„â–†â–†â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–â–‚
wandb:      train/ensemble_f1 â–‡â–…â–ˆâ–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–†â–…â–†â–†â–‡â–†â–‡â–…â–‡â–†â–…â–…â–…â–…â–…â–…â–„â–„â–…â–‚â–„â–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–â–‚
wandb:         train/mil_loss â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–…â–…â–‡â–†â–…â–†â–…â–…â–…â–†â–„â–„â–†â–ƒâ–‡â–„â–„â–„â–„â–…â–„â–„â–„â–„â–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–„â–„â–„â–ˆâ–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–â–…â–„â–„â–„â–„â–…â–„â–„â–ƒâ–„â–„â–„â–†â–„â–„â–„â–„â–†â–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–…â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–†â–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91148
wandb: best/eval_avg_mil_loss 0.26779
wandb:  best/eval_ensemble_f1 0.91148
wandb:            eval/avg_f1 0.85169
wandb:      eval/avg_mil_loss 0.38187
wandb:       eval/ensemble_f1 0.85169
wandb:           train/avg_f1 0.85362
wandb:      train/ensemble_f1 0.85362
wandb:         train/mil_loss 3.16924
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run giddy-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mx5zsppc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064548-mx5zsppc/logs
wandb: ERROR Run mx5zsppc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1yndyaua with config:
wandb: 	actor_learning_rate: 0.0007189808380906439
wandb: 	attention_dropout_p: 0.4333918711707093
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22092929969272057
wandb: 	temperature: 4.49227324130658
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064803-1yndyaua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1yndyaua
wandb: uploading history steps 66-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‚â–‚â–‡â–ƒâ–†â–„â–„â–ƒâ–ˆâ–„â–…â–†â–„â–…â–‚â–…â–‚â–‚â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–â–‚â–„â–‡â–„â–…â–„â–…â–…â–ƒâ–‚â–‚â–„
wandb:      eval/avg_mil_loss â–‚â–„â–â–â–‚â–ƒâ–ƒâ–ƒâ–â–â–‚â–ƒâ–„â–‚â–ˆâ–†â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚
wandb:       eval/ensemble_f1 â–…â–…â–…â–â–ˆâ–ƒâ–…â–‡â–„â–„â–‚â–„â–†â–†â–„â–…â–‚â–…â–‚â–‚â–ƒâ–…â–…â–ƒâ–ƒâ–†â–ƒâ–„â–‚â–„â–„â–…â–ƒâ–„â–…â–ƒâ–‡â–†â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–„â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–…â–…â–‚â–ƒâ–ˆâ–…â–ƒâ–†â–…â–„â–ƒâ–‡â–…â–†â–…â–â–â–…â–…â–„â–†â–†â–„â–…â–†â–…â–‚â–†â–ƒ
wandb:      train/ensemble_f1 â–…â–„â–…â–ƒâ–†â–„â–„â–„â–…â–ƒâ–†â–ƒâ–…â–…â–…â–ƒâ–…â–„â–ƒâ–ˆâ–†â–‡â–„â–…â–‡â–†â–†â–…â–…â–‚â–„â–…â–â–…â–…â–ƒâ–†â–‚â–„â–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–…â–‡â–…â–…â–…â–„â–†â–†â–„â–†â–„â–„â–…â–‚â–…â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–
wandb:      train/policy_loss â–†â–ˆâ–†â–†â–‡â–†â–†â–†â–„â–†â–†â–â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–ˆâ–†â–†â–†â–†â–†â–„â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.26426
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.90363
wandb:      eval/avg_mil_loss 0.27714
wandb:       eval/ensemble_f1 0.90363
wandb:            test/avg_f1 0.92406
wandb:      test/avg_mil_loss 0.15175
wandb:       test/ensemble_f1 0.92406
wandb:           train/avg_f1 0.88959
wandb:      train/ensemble_f1 0.88959
wandb:         train/mil_loss 0.29091
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1yndyaua
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064803-1yndyaua/logs
wandb: Agent Starting Run: r3uy9i6l with config:
wandb: 	actor_learning_rate: 0.00087479822948516
wandb: 	attention_dropout_p: 0.28756628827081737
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6124750029193072
wandb: 	temperature: 0.5315052789032026
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064911-r3uy9i6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3uy9i6l
wandb: uploading history steps 66-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–…â–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–†â–†â–‡â–‡â–…â–„â–„â–ƒâ–‡â–ˆâ–†â–†â–…â–†â–†â–…â–…â–†â–„â–„â–ƒâ–ˆâ–ˆâ–…â–†â–†â–…â–†â–†â–…â–„â–„â–…â–†â–…â–â–†â–„
wandb:      eval/avg_mil_loss â–†â–‚â–‚â–ˆâ–ƒâ–â–…â–‚â–†â–ƒâ–ƒâ–‚â–‚â–„â–â–„â–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–ƒâ–…â–â–…â–„â–†â–…â–…â–†â–…â–†â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–…â–†â–†â–„â–†â–„â–„â–ƒâ–ƒâ–„â–‡â–…â–…â–†â–…â–ˆâ–…â–‡â–†â–…â–„â–ƒâ–ƒâ–†â–‡â–ˆâ–…â–…â–†â–„â–…â–†â–…â–†â–ƒâ–„â–ƒâ–â–…â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–…â–…â–„â–„â–†â–…â–‡â–ƒâ–„â–…â–‡â–…â–ˆâ–‡â–ƒâ–„â–…â–â–…â–…â–…â–‡â–„â–…â–‡â–‡â–…â–ƒâ–†â–†â–…â–ˆâ–„â–„â–†â–„â–…â–„
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–ƒâ–…â–„â–„â–ƒâ–†â–„â–ƒâ–„â–„â–…â–…â–‡â–ƒâ–„â–…â–â–…â–‡â–†â–…â–‡â–…â–‡â–…â–…â–ƒâ–†â–†â–†â–ˆâ–…â–†â–…â–„â–…â–„
wandb:         train/mil_loss â–†â–†â–…â–ˆâ–†â–ƒâ–‡â–…â–…â–…â–†â–‡â–†â–†â–…â–„â–…â–…â–„â–…â–„â–„â–…â–„â–„â–„â–†â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–„â–†â–„â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–…â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–‡â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.22421
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.88498
wandb:      eval/avg_mil_loss 0.34722
wandb:       eval/ensemble_f1 0.88498
wandb:           train/avg_f1 0.88908
wandb:      train/ensemble_f1 0.88908
wandb:         train/mil_loss 0.57012
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3uy9i6l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064911-r3uy9i6l/logs
wandb: ERROR Run r3uy9i6l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: g4mv6rwy with config:
wandb: 	actor_learning_rate: 0.000546528659309499
wandb: 	attention_dropout_p: 0.15753569804260575
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5702817521623363
wandb: 	temperature: 3.3496803211870985
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065023-g4mv6rwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g4mv6rwy
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–â–…â–ƒâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–†â–‡â–†â–ˆâ–ˆâ–‡â–†â–‡â–†â–‡â–ˆâ–ƒâ–‡â–„â–†â–…â–ˆâ–„â–‡â–…â–ˆâ–ƒâ–…â–‡â–…â–â–ƒâ–…â–†â–‚â–…â–…â–‡â–„â–ƒâ–„â–â–„â–„
wandb:      eval/avg_mil_loss â–‚â–…â–„â–‚â–â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–†â–â–‚â–…â–„â–ƒâ–„â–‡â–†â–„â–…â–…â–„â–‡â–†â–ƒâ–„â–…â–ƒâ–†â–ƒâ–…â–‡â–†â–ˆâ–ƒâ–†â–†
wandb:       eval/ensemble_f1 â–†â–†â–ˆâ–†â–…â–†â–ˆâ–„â–ˆâ–„â–ˆâ–…â–…â–…â–…â–ƒâ–‚â–…â–†â–ƒâ–…â–ˆâ–…â–…â–â–…â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–„
wandb:           train/avg_f1 â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–†â–…â–‡â–‡â–†â–‡â–‡â–…â–…â–†â–†â–…â–†â–…â–…â–…â–†â–„â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–‚â–â–ƒâ–
wandb:      train/ensemble_f1 â–†â–‡â–‡â–ˆâ–ˆâ–…â–‡â–‡â–ˆâ–†â–†â–„â–†â–…â–†â–†â–‡â–„â–„â–…â–„â–„â–„â–‚â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–
wandb:         train/mil_loss â–ˆâ–„â–†â–ˆâ–‚â–…â–„â–…â–†â–ƒâ–ƒâ–„â–‡â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–â–‚â–‚â–â–‚â–‚â–â–‚
wandb:      train/policy_loss â–„â–„â–…â–„â–„â–„â–„â–…â–â–‚â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–ˆâ–„â–„â–„â–„â–…â–„â–„â–…â–„â–„â–â–„â–„â–„â–„â–„â–„â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91565
wandb: best/eval_avg_mil_loss 0.32098
wandb:  best/eval_ensemble_f1 0.91565
wandb:            eval/avg_f1 0.86861
wandb:      eval/avg_mil_loss 0.37256
wandb:       eval/ensemble_f1 0.86861
wandb:           train/avg_f1 0.84755
wandb:      train/ensemble_f1 0.84755
wandb:         train/mil_loss 0.21316
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run peach-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g4mv6rwy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065023-g4mv6rwy/logs
wandb: ERROR Run g4mv6rwy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5wh73pg5 with config:
wandb: 	actor_learning_rate: 0.0001429179496623191
wandb: 	attention_dropout_p: 0.024631935824581452
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49897317115157025
wandb: 	temperature: 2.4021259108065185
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065227-5wh73pg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5wh73pg5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–‡â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–…â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–„â–…â–…â–…â–„â–…â–„â–†â–…â–†â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–‚â–‚â–„â–…â–„â–ƒâ–„â–â–‚
wandb:      eval/avg_mil_loss â–‚â–‚â–â–‚â–ƒâ–â–â–„â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–…â–ƒâ–†â–ˆâ–„â–„â–ƒâ–„â–†â–†â–…â–„â–„
wandb:       eval/ensemble_f1 â–ˆâ–†â–‡â–‡â–ˆâ–‡â–†â–†â–ˆâ–†â–„â–…â–†â–„â–„â–†â–…â–„â–…â–†â–…â–…â–„â–ƒâ–ƒâ–„â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–‚â–„â–‚â–ƒâ–„â–â–ƒ
wandb:           train/avg_f1 â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–…â–†â–…â–†â–„â–…â–„â–…â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–â–ƒ
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–†â–†â–†â–‡â–…â–…â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚
wandb:         train/mil_loss â–‡â–†â–ˆâ–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–â–â–‚â–ƒâ–â–â–ƒ
wandb:      train/policy_loss â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–„â–„â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.916
wandb: best/eval_avg_mil_loss 0.28695
wandb:  best/eval_ensemble_f1 0.916
wandb:            eval/avg_f1 0.79404
wandb:      eval/avg_mil_loss 0.38251
wandb:       eval/ensemble_f1 0.79404
wandb:           train/avg_f1 0.82368
wandb:      train/ensemble_f1 0.82368
wandb:         train/mil_loss 0.18262
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run atomic-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5wh73pg5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065227-5wh73pg5/logs
wandb: ERROR Run 5wh73pg5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 53lnl6tx with config:
wandb: 	actor_learning_rate: 4.066132030459444e-06
wandb: 	attention_dropout_p: 0.2921289056730528
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22859938486168008
wandb: 	temperature: 5.775165052685453
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065503-53lnl6tx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/53lnl6tx
wandb: uploading history steps 83-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–„â–†â–„â–„â–…â–„â–…â–†â–„â–ˆâ–ˆâ–ƒâ–ˆâ–„â–â–†â–„â–„â–…â–…â–„â–„â–…â–ƒâ–ƒâ–â–„â–…â–‚â–ƒâ–‚â–…â–…â–…â–ƒâ–‚â–„â–„
wandb:      eval/avg_mil_loss â–â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–…â–â–„â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ˆâ–„â–…â–„â–†â–…â–„â–ƒâ–ƒâ–…â–„â–…â–…â–‡â–„â–†â–ƒâ–â–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–„â–„â–ˆâ–â–ƒâ–„â–…â–„â–‚â–†â–„â–ˆâ–ˆâ–…â–‚â–…â–„â–â–…â–†â–ƒâ–†â–…â–‚â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–…â–„â–„â–„â–‚â–ˆ
wandb:           train/avg_f1 â–†â–…â–…â–ƒâ–„â–â–ƒâ–‡â–†â–…â–…â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–…â–‚â–ƒâ–„â–‚â–ˆâ–…â–…â–†â–†â–„â–„â–‚â–†â–„â–„â–…â–â–ƒ
wandb:      train/ensemble_f1 â–…â–…â–‚â–‚â–…â–ƒâ–‡â–‡â–†â–ƒâ–ˆâ–‚â–„â–ƒâ–ƒâ–â–„â–‚â–…â–â–ƒâ–‚â–…â–â–„â–„â–…â–ƒâ–‚â–†â–†â–ƒâ–‚â–„â–†â–„â–ƒâ–„â–…â–‡
wandb:         train/mil_loss â–‡â–ˆâ–‡â–„â–…â–„â–ƒâ–…â–ƒâ–…â–„â–„â–„â–„â–â–…â–‚â–‚â–„â–â–„â–â–…â–„â–„â–ƒâ–…â–ƒâ–…â–‚â–â–„â–‚â–ƒâ–ƒâ–…â–„â–†â–‚â–„
wandb:      train/policy_loss â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–‚â–„â–…â–ˆâ–…â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.22457
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.89602
wandb:      eval/avg_mil_loss 0.26539
wandb:       eval/ensemble_f1 0.89602
wandb:           train/avg_f1 0.89062
wandb:      train/ensemble_f1 0.89062
wandb:         train/mil_loss 0.26819
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run confused-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/53lnl6tx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065503-53lnl6tx/logs
wandb: ERROR Run 53lnl6tx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xnsvkeu4 with config:
wandb: 	actor_learning_rate: 3.588740512417314e-06
wandb: 	attention_dropout_p: 0.052795821044947566
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4340924974832274
wandb: 	temperature: 0.45472327442851457
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065646-xnsvkeu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xnsvkeu4
wandb: uploading wandb-summary.json
wandb: uploading history steps 136-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–‚â–‚â–…
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–†â–‡â–†â–â–‚â–ˆâ–†â–‡â–‡â–…â–„â–ˆâ–„â–†â–ˆâ–†â–…â–…â–…â–†â–†â–‚â–ˆâ–ƒâ–†â–…â–…â–…â–ƒâ–‡â–†â–…â–ƒâ–…â–…â–„â–„â–†
wandb:      eval/avg_mil_loss â–ˆâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–†â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–„â–ƒâ–„â–‚â–„â–‚â–ƒâ–ƒâ–„â–„â–‚â–ˆâ–ƒâ–‚â–…â–ƒâ–„â–‚â–…â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–ƒâ–…â–…â–†â–…â–„â–…â–†â–‚â–†â–„â–‡â–†â–ˆâ–ˆâ–‡â–…â–…â–ƒâ–„â–†â–‡â–†â–„â–„â–„â–„â–â–‡â–„â–†â–„â–„â–ƒâ–„â–…â–ƒâ–…â–„
wandb:           train/avg_f1 â–…â–ˆâ–…â–„â–†â–â–‚â–„â–†â–ˆâ–…â–„â–‚â–„â–„â–†â–…â–ˆâ–†â–…â–…â–‚â–ˆâ–‡â–†â–„â–„â–†â–„â–ˆâ–ƒâ–…â–ƒâ–†â–†â–‡â–â–ˆâ–…â–
wandb:      train/ensemble_f1 â–…â–‡â–…â–…â–„â–‚â–†â–…â–ƒâ–…â–„â–…â–…â–ƒâ–„â–…â–ƒâ–‚â–…â–ƒâ–…â–…â–„â–†â–…â–„â–‡â–„â–„â–‡â–„â–ˆâ–…â–â–„â–†â–…â–„â–ƒâ–„
wandb:         train/mil_loss â–…â–„â–†â–†â–‡â–ˆâ–†â–…â–„â–†â–…â–„â–„â–„â–„â–…â–†â–„â–‚â–ƒâ–„â–ƒâ–„â–‚â–„â–„â–‚â–…â–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–†
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–â–„â–ˆâ–â–ˆâ–„â–â–â–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–„â–â–„â–„â–„â–„â–â–„â–„â–„â–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.40107
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.87756
wandb:      eval/avg_mil_loss 0.36202
wandb:       eval/ensemble_f1 0.87756
wandb:           train/avg_f1 0.90373
wandb:      train/ensemble_f1 0.90373
wandb:         train/mil_loss 0.26983
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xnsvkeu4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065646-xnsvkeu4/logs
wandb: ERROR Run xnsvkeu4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r5gxdets with config:
wandb: 	actor_learning_rate: 3.367712139951768e-05
wandb: 	attention_dropout_p: 0.07180354174379128
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47445565430834136
wandb: 	temperature: 2.769044278259104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065911-r5gxdets
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r5gxdets
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–â–…â–ˆâ–‡â–„â–†â–…â–†â–…â–†â–‡â–…â–†â–…â–ƒâ–‡â–†â–„â–†â–„â–…â–…â–†â–†â–„â–„â–ƒâ–‡â–†â–ƒâ–…â–â–‚â–â–†â–…â–â–ƒâ–â–‚
wandb:      eval/avg_mil_loss â–„â–„â–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–„â–ƒâ–„â–ƒâ–†â–„â–…â–…â–…â–…â–„â–…â–…â–†â–…â–ˆâ–†
wandb:       eval/ensemble_f1 â–‚â–…â–‡â–†â–‡â–‡â–„â–ˆâ–„â–„â–ˆâ–„â–„â–†â–„â–…â–†â–†â–…â–†â–„â–…â–†â–ƒâ–„â–‡â–ƒâ–ƒâ–‚â–…â–ƒâ–†â–„â–‚â–â–…â–†â–ƒâ–â–
wandb:           train/avg_f1 â–†â–†â–‡â–†â–…â–†â–†â–†â–ˆâ–†â–ˆâ–…â–‡â–†â–†â–†â–…â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–„â–…â–„â–„â–„â–ƒâ–ƒâ–…â–…â–„â–„â–â–„â–ƒ
wandb:      train/ensemble_f1 â–‡â–†â–†â–…â–†â–†â–ˆâ–…â–†â–…â–†â–ˆâ–…â–†â–„â–‡â–‡â–‡â–†â–…â–‡â–„â–†â–…â–…â–ƒâ–…â–„â–„â–‚â–â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–â–‚
wandb:         train/mil_loss â–†â–ˆâ–…â–ˆâ–†â–ˆâ–‡â–†â–„â–…â–†â–†â–…â–…â–„â–ƒâ–…â–†â–„â–ƒâ–‡â–„â–„â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–„â–ƒâ–â–â–â–‚â–‚
wandb:      train/policy_loss â–ƒâ–â–ƒâ–‚â–ƒâ–„â–ˆâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91919
wandb: best/eval_avg_mil_loss 0.27069
wandb:  best/eval_ensemble_f1 0.91919
wandb:            eval/avg_f1 0.84899
wandb:      eval/avg_mil_loss 0.40225
wandb:       eval/ensemble_f1 0.84899
wandb:           train/avg_f1 0.85801
wandb:      train/ensemble_f1 0.85801
wandb:         train/mil_loss 2.76767
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misty-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r5gxdets
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065911-r5gxdets/logs
wandb: ERROR Run r5gxdets errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: k0ltrhsf with config:
wandb: 	actor_learning_rate: 4.753328532884217e-05
wandb: 	attention_dropout_p: 0.0010293972987228115
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.030341784540562022
wandb: 	temperature: 8.596117233847375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070110-k0ltrhsf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0ltrhsf
wandb: uploading wandb-summary.json
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–…â–‚â–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–‡â–„â–‡â–ƒâ–‡â–†â–„â–ˆâ–…â–‚â–ƒâ–ƒâ–â–ƒâ–â–„â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–‚â–†â–ƒâ–‚â–„â–‚â–‚â–„â–‡â–‚
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„â–ƒâ–‚â–‚â–‚â–„â–‚â–„â–„â–ƒâ–„â–„â–ƒâ–…â–†â–ƒâ–‚â–…â–„â–â–„â–ƒâ–„â–ˆâ–…â–„â–ƒâ–„â–„â–†â–…â–„â–‚
wandb:       eval/ensemble_f1 â–â–‡â–„â–„â–…â–‡â–ƒâ–ˆâ–…â–†â–…â–‚â–ƒâ–…â–‡â–…â–…â–‡â–„â–†â–…â–‚â–â–„â–„â–â–‡â–ƒâ–ˆâ–‚â–ƒâ–…â–‚â–‚â–„â–ƒâ–…â–‡â–‚â–ƒ
wandb:           train/avg_f1 â–‡â–…â–…â–ˆâ–„â–„â–„â–…â–ˆâ–†â–†â–†â–‡â–†â–â–†â–â–„â–†â–„â–â–ƒâ–…â–‡â–„â–„â–‡â–„â–„â–„â–„â–ƒâ–â–‚â–‚â–…â–‚â–ƒâ–‚â–„
wandb:      train/ensemble_f1 â–…â–…â–…â–‡â–‚â–ƒâ–ˆâ–„â–„â–„â–…â–ƒâ–…â–‡â–†â–†â–†â–â–„â–ƒâ–‚â–‚â–†â–…â–…â–…â–â–…â–ƒâ–„â–…â–â–â–„â–…â–…â–‚â–â–‚â–„
wandb:         train/mil_loss â–ˆâ–‡â–‡â–ˆâ–ˆâ–…â–‡â–†â–†â–…â–…â–…â–…â–†â–…â–…â–…â–„â–„â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–â–â–â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–â–†â–„â–…â–„â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91873
wandb: best/eval_avg_mil_loss 0.25035
wandb:  best/eval_ensemble_f1 0.91873
wandb:            eval/avg_f1 0.884
wandb:      eval/avg_mil_loss 0.37904
wandb:       eval/ensemble_f1 0.884
wandb:           train/avg_f1 0.89213
wandb:      train/ensemble_f1 0.89213
wandb:         train/mil_loss 0.68481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k0ltrhsf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070110-k0ltrhsf/logs
wandb: ERROR Run k0ltrhsf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5x93dbhi with config:
wandb: 	actor_learning_rate: 4.762961019084255e-06
wandb: 	attention_dropout_p: 0.40683865221687654
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1051359957106851
wandb: 	temperature: 6.956763474755691
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070314-5x93dbhi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x93dbhi
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–ˆâ–†â–…â–„â–…â–‡â–…â–‡â–†â–…â–†â–†â–â–…â–„â–‡â–ƒâ–†â–â–‡â–†â–†â–…â–‡â–„â–„â–†â–‡â–„â–ƒâ–„â–†â–ˆâ–„â–ˆâ–†â–†â–ƒ
wandb:      eval/avg_mil_loss â–†â–‚â–‚â–ƒâ–â–ƒâ–„â–…â–„â–…â–…â–ƒâ–„â–…â–„â–‡â–„â–…â–„â–†â–†â–„â–„â–„â–ƒâ–‚â–„â–†â–†â–„â–„â–„â–ˆâ–„â–…â–â–…â–„â–ƒâ–†
wandb:       eval/ensemble_f1 â–†â–ˆâ–†â–„â–…â–‚â–ƒâ–„â–„â–…â–„â–„â–„â–‚â–„â–ˆâ–…â–†â–‚â–„â–„â–‚â–†â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–â–‚â–ƒâ–‚â–â–†â–…â–â–â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–‡â–†â–†â–…â–‡â–‡â–ˆâ–…â–†â–‡â–…â–†â–†â–‡â–‡â–†â–†â–ˆâ–…â–„â–‡â–†â–†â–‡â–†â–†â–â–„â–†â–‡â–‡â–‡â–…â–…â–„â–‡â–…â–†
wandb:      train/ensemble_f1 â–…â–†â–†â–…â–†â–„â–…â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–…â–†â–…â–†â–‡â–…â–…â–‡â–†â–†â–„â–‡â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–…â–…â–„â–†
wandb:         train/mil_loss â–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†â–‡â–‡â–ˆâ–…â–†â–…â–…â–†â–†â–†â–†â–‡â–ˆâ–‡â–„â–…â–„â–„â–…â–ƒâ–…â–†â–ƒâ–‚â–â–ƒâ–‚â–„â–„â–ƒ
wandb:      train/policy_loss â–ˆâ–†â–†â–ƒâ–†â–†â–†â–ƒâ–†â–‡â–â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–„â–„â–ƒâ–„â–„â–‚â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.25042
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.9038
wandb:      eval/avg_mil_loss 0.34724
wandb:       eval/ensemble_f1 0.9038
wandb:            test/avg_f1 0.90127
wandb:      test/avg_mil_loss 0.20421
wandb:       test/ensemble_f1 0.90127
wandb:           train/avg_f1 0.89149
wandb:      train/ensemble_f1 0.89149
wandb:         train/mil_loss 0.93293
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run golden-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x93dbhi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070314-5x93dbhi/logs
wandb: Agent Starting Run: s9xwry1t with config:
wandb: 	actor_learning_rate: 5.22023445502798e-06
wandb: 	attention_dropout_p: 0.27384862456296094
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2539147957747846
wandb: 	temperature: 1.0565512741016547
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070442-s9xwry1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9xwry1t
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–‚â–ˆâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–„â–†â–†â–ˆâ–†â–†â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–†â–†â–„â–…â–„â–†â–…â–†â–„â–‡â–ƒâ–„â–ƒâ–„â–„â–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–„â–‡â–†â–‚â–â–â–‚â–‚â–â–‚â–„â–†â–„â–„â–„â–„â–„â–‚â–‚â–ƒâ–‚â–‡â–ƒâ–…â–…â–ƒâ–…â–…â–…â–„â–‡â–ƒâ–ˆâ–„â–ˆâ–„â–…â–ƒâ–‡â–†
wandb:       eval/ensemble_f1 â–‡â–…â–ˆâ–‡â–†â–†â–†â–„â–†â–†â–ˆâ–‡â–…â–ˆâ–†â–‡â–‡â–†â–†â–†â–…â–…â–„â–†â–…â–†â–„â–…â–ƒâ–…â–â–…â–…â–ƒâ–ƒâ–…â–‚â–„â–ƒâ–„
wandb:           train/avg_f1 â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–‡â–†â–‡â–‡â–‡â–‡â–†â–…â–‡â–…â–…â–…â–…â–„â–…â–…â–…â–†â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–
wandb:      train/ensemble_f1 â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–ˆâ–…â–‡â–‡â–†â–‡â–‡â–†â–…â–‡â–†â–‡â–…â–‡â–†â–…â–„â–…â–…â–…â–„â–†â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–
wandb:         train/mil_loss â–„â–ˆâ–…â–ƒâ–…â–ƒâ–„â–„â–„â–†â–ƒâ–ƒâ–…â–…â–„â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–„â–„â–â–ƒâ–â–
wandb:      train/policy_loss â–…â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–‡â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–†â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–…â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92299
wandb: best/eval_avg_mil_loss 0.24564
wandb:  best/eval_ensemble_f1 0.92299
wandb:            eval/avg_f1 0.85027
wandb:      eval/avg_mil_loss 0.34595
wandb:       eval/ensemble_f1 0.85027
wandb:           train/avg_f1 0.83967
wandb:      train/ensemble_f1 0.83967
wandb:         train/mil_loss 0.20898
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9xwry1t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070442-s9xwry1t/logs
wandb: ERROR Run s9xwry1t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: fdgpw3ep with config:
wandb: 	actor_learning_rate: 0.00030969644007180147
wandb: 	attention_dropout_p: 0.31071020934660754
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 72
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2232003580512516
wandb: 	temperature: 1.4329071246005587
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070648-fdgpw3ep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdgpw3ep
wandb: uploading history steps 63-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–ƒâ–„â–â–„â–„â–ˆâ–‚â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–‡â–„â–‚â–ƒâ–ƒâ–„â–ƒâ–†â–†â–„â–„â–„â–‚â–ƒâ–…â–‚â–…â–„â–…â–‚â–„â–…â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–„â–†â–ˆâ–‚â–„â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–…â–†â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–…â–„â–„â–„â–„â–ƒâ–‚â–ƒâ–
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–„â–†â–â–„â–„â–ƒâ–ƒâ–†â–„â–ƒâ–„â–ƒâ–ƒâ–‡â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–„â–…â–…â–ƒâ–…â–‚â–„â–…â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–†â–ƒâ–†â–„â–…â–„â–â–„â–ˆâ–„â–†â–„â–ƒâ–„â–…â–†â–…â–â–†â–…â–ƒâ–ƒâ–ƒâ–…â–†â–ƒâ–…â–ˆâ–†â–ƒâ–â–ƒâ–…â–…â–…â–ƒâ–‚â–‚
wandb:      train/ensemble_f1 â–„â–†â–„â–…â–†â–„â–„â–…â–†â–„â–…â–„â–ƒâ–ˆâ–…â–†â–„â–ƒâ–†â–…â–ƒâ–‚â–„â–†â–„â–…â–â–…â–ˆâ–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–‚â–‚â–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–â–„â–‡â–„â–ƒâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–ƒâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–†â–â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–ˆâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.21024
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.93328
wandb:      eval/avg_mil_loss 0.21024
wandb:       eval/ensemble_f1 0.93328
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.15732
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.89029
wandb:      train/ensemble_f1 0.89029
wandb:         train/mil_loss 0.37173
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run laced-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdgpw3ep
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070648-fdgpw3ep/logs
wandb: Agent Starting Run: f7c6v5bm with config:
wandb: 	actor_learning_rate: 0.0001338369062007317
wandb: 	attention_dropout_p: 0.2814088821392602
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37268504429933613
wandb: 	temperature: 6.816625805592703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070806-f7c6v5bm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f7c6v5bm
wandb: uploading history steps 54-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–‚
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–…â–ƒâ–â–‡â–†â–ˆâ–†â–…â–„â–…â–„â–‡â–„â–‚â–„â–‡â–†â–…â–†â–…â–†â–‡â–†â–…â–…â–„â–„â–†â–†â–ƒâ–†â–„â–…â–‡â–‡â–…â–†
wandb:      eval/avg_mil_loss â–‚â–ƒâ–„â–‚â–‡â–†â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–…â–…â–ƒâ–ƒâ–„â–†â–„â–‚â–‚â–‡â–„â–ƒâ–„â–†â–†â–„â–ƒâ–‚â–â–†
wandb:       eval/ensemble_f1 â–†â–‡â–…â–…â–…â–â–‡â–†â–ˆâ–†â–…â–†â–†â–„â–…â–‡â–†â–„â–…â–‚â–†â–†â–…â–†â–…â–†â–†â–…â–†â–„â–…â–‡â–„â–‚â–†â–†â–…â–‡â–‡â–„
wandb:           train/avg_f1 â–…â–‡â–ˆâ–‡â–…â–…â–„â–„â–†â–ƒâ–†â–…â–…â–…â–„â–…â–…â–ƒâ–â–ƒâ–„â–ƒâ–‚â–ƒâ–†â–†â–„â–‚â–…â–†â–ƒâ–…â–†â–‚â–â–…â–†â–„â–„â–
wandb:      train/ensemble_f1 â–…â–‡â–ƒâ–ˆâ–‡â–„â–…â–„â–†â–‚â–ƒâ–…â–…â–…â–„â–†â–…â–…â–ƒâ–‚â–„â–‚â–‚â–‚â–â–‡â–„â–‚â–„â–…â–‚â–â–…â–„â–…â–…â–†â–ƒâ–„â–…
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–
wandb:      train/policy_loss â–„â–ˆâ–„â–„â–„â–ˆâ–„â–ƒâ–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–…â–„â–…â–…â–„â–„â–„â–†â–â–„â–„â–„â–„â–„â–„â–„â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‡â–„â–„â–…â–„â–…â–„â–…â–„â–„â–†â–â–‡â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.24481
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.88116
wandb:      eval/avg_mil_loss 0.33909
wandb:       eval/ensemble_f1 0.88116
wandb:           train/avg_f1 0.87963
wandb:      train/ensemble_f1 0.87963
wandb:         train/mil_loss 0.68622
wandb:      train/policy_loss 0.10942
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.10942
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f7c6v5bm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070806-f7c6v5bm/logs
wandb: ERROR Run f7c6v5bm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: eb747g57 with config:
wandb: 	actor_learning_rate: 0.0001960987734013094
wandb: 	attention_dropout_p: 0.2496334401642426
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25749613109362857
wandb: 	temperature: 4.629180510033947
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070918-eb747g57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb747g57
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‡â–â–„â–‚â–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–â–„â–†â–„â–„â–…â–…â–…â–…â–ˆâ–…â–‡â–ƒâ–…â–‡â–„â–‡â–…â–„â–†â–‡â–‚â–…â–ƒâ–â–…â–†â–…â–ƒâ–‡â–ƒâ–„â–‚â–…â–„â–†â–„â–ˆâ–…â–„
wandb:      eval/avg_mil_loss â–…â–â–ƒâ–‚â–„â–ƒâ–…â–†â–†â–â–‚â–„â–‚â–ƒâ–‚â–„â–„â–†â–†â–ƒâ–ƒâ–ˆâ–‡â–…â–„â–…â–„â–‚â–‚â–„â–‚â–‚â–…â–â–…â–„â–ƒâ–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–â–…â–„â–ƒâ–„â–…â–„â–ƒâ–†â–†â–ƒâ–„â–†â–ƒâ–…â–„â–‚â–…â–†â–‚â–ƒâ–â–…â–…â–„â–ƒâ–„â–†â–„â–‚â–…â–‚â–…â–„â–ƒâ–ˆâ–„â–â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–…â–ƒâ–…â–…â–‚â–…â–…â–…â–‚â–„â–…â–†â–â–„â–†â–…â–†â–…â–‡â–ƒâ–ˆâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–„â–…â–…â–‚â–„â–ƒâ–†â–‚â–â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–„â–‚â–†â–‡â–„â–‚â–‡â–†â–„â–‡â–†â–â–…â–„â–ˆâ–„â–…â–ƒâ–„â–…â–ˆâ–†â–â–…â–…â–„â–†â–ƒâ–…â–„â–„â–‡â–…â–ƒâ–‚â–â–ƒâ–ƒâ–„
wandb:         train/mil_loss â–‡â–ˆâ–ƒâ–†â–„â–ƒâ–ƒâ–…â–ƒâ–„â–‡â–„â–‚â–„â–ƒâ–‚â–„â–†â–†â–†â–„â–â–…â–†â–ƒâ–‚â–…â–ƒâ–„â–„â–ƒâ–‚â–…â–…â–„â–„â–†â–…â–‡â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–ˆâ–…â–â–â–ˆâ–â–â–…â–â–â–…â–â–ˆâ–â–â–ˆâ–â–…â–â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–…â–â–…â–â–…â–â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92662
wandb: best/eval_avg_mil_loss 0.28502
wandb:  best/eval_ensemble_f1 0.92662
wandb:            eval/avg_f1 0.88642
wandb:      eval/avg_mil_loss 0.26919
wandb:       eval/ensemble_f1 0.88642
wandb:            test/avg_f1 0.90236
wandb:      test/avg_mil_loss 0.2581
wandb:       test/ensemble_f1 0.90236
wandb:           train/avg_f1 0.88721
wandb:      train/ensemble_f1 0.88721
wandb:         train/mil_loss 0.20013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dandy-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb747g57
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070918-eb747g57/logs
wandb: Agent Starting Run: xixczwvx with config:
wandb: 	actor_learning_rate: 1.048378607128682e-05
wandb: 	attention_dropout_p: 0.3951600448853638
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04561006223835962
wandb: 	temperature: 2.4387372864453827
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071116-xixczwvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zoc1c2p7
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xixczwvx
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–„â–‡â–…â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–…â–„â–‡â–†â–ˆâ–„â–„â–…â–…â–…â–…â–ƒâ–ƒâ–‡â–†â–…â–…â–…â–„â–…â–ƒâ–‡â–†â–†â–…â–‡â–…â–„â–…â–…â–„â–„â–â–â–ƒâ–…â–ˆ
wandb:      eval/avg_mil_loss â–„â–†â–‚â–„â–‚â–†â–‚â–…â–†â–‚â–ƒâ–†â–‚â–„â–ˆâ–ƒâ–„â–ƒâ–‚â–…â–ƒâ–ˆâ–‡â–‡â–„â–â–„â–„â–„â–â–…â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–†â–‚
wandb:       eval/ensemble_f1 â–‡â–†â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–†â–…â–†â–†â–‡â–…â–†â–…â–…â–†â–…â–…â–†â–ˆâ–†â–†â–…â–…â–…â–†â–†â–†â–â–…â–†â–…â–†â–…â–…â–„â–„
wandb:           train/avg_f1 â–…â–…â–…â–ˆâ–„â–†â–†â–†â–†â–„â–…â–†â–ƒâ–„â–„â–„â–ƒâ–…â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–„â–ƒâ–„â–â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–
wandb:      train/ensemble_f1 â–…â–…â–ˆâ–‡â–„â–‡â–„â–†â–‡â–†â–†â–†â–†â–†â–„â–…â–ƒâ–„â–…â–†â–ˆâ–…â–‚â–…â–…â–‚â–ƒâ–„â–ƒâ–‚â–…â–â–„â–‚â–„â–â–â–â–„â–‚
wandb:         train/mil_loss â–…â–†â–ˆâ–†â–†â–†â–…â–†â–…â–†â–„â–„â–†â–…â–†â–„â–„â–…â–…â–„â–†â–„â–„â–ƒâ–…â–…â–ƒâ–„â–„â–…â–„â–„â–„â–…â–„â–„â–„â–„â–â–„
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–…â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93032
wandb: best/eval_avg_mil_loss 0.22926
wandb:  best/eval_ensemble_f1 0.93032
wandb:            eval/avg_f1 0.87197
wandb:      eval/avg_mil_loss 0.26509
wandb:       eval/ensemble_f1 0.87197
wandb:           train/avg_f1 0.89256
wandb:      train/ensemble_f1 0.89256
wandb:         train/mil_loss 0.23834
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hearty-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xixczwvx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071116-xixczwvx/logs
wandb: ERROR Run xixczwvx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: z0pp2097 with config:
wandb: 	actor_learning_rate: 0.00014709944718370563
wandb: 	attention_dropout_p: 0.4763025436272121
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9995385860820388
wandb: 	temperature: 2.666252642114378
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071404-z0pp2097
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z0pp2097
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading history steps 70-88, summary
wandb: uploading history steps 70-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–â–…
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–†â–…â–…â–…â–‚â–„â–„â–…â–„â–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–ˆâ–‚â–„â–‚â–…â–…â–„â–…â–…â–…â–…â–ƒâ–†â–…â–†â–ƒâ–ƒâ–„â–ˆâ–…â–…â–…
wandb:      eval/avg_mil_loss â–†â–â–„â–ƒâ–‚â–…â–‡â–ˆâ–ƒâ–ƒâ–†â–ƒâ–â–†â–„â–†â–…â–„â–ˆâ–‚â–‡â–â–‚â–…â–ƒâ–…â–…â–„â–†â–„â–‡â–„â–‚â–„â–ˆâ–†â–ƒâ–…â–…â–…
wandb:       eval/ensemble_f1 â–‡â–†â–ƒâ–†â–ƒâ–â–ƒâ–„â–…â–…â–„â–â–„â–…â–„â–„â–‚â–‚â–ˆâ–ˆâ–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–†â–„â–ƒâ–„â–„â–†â–ƒâ–ƒâ–„â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ˆâ–…â–†â–†â–‡â–„â–„â–ƒâ–ƒâ–…â–ƒâ–â–†â–„â–…â–„â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–ƒâ–‡â–ƒâ–„â–â–‚â–„â–‚â–‚â–…â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–‡â–‚â–ˆâ–‚â–†â–ƒâ–ƒâ–†â–ƒâ–„â–â–ˆâ–„â–„â–ˆâ–†â–…â–„â–ƒâ–„â–„â–„â–‚â–†â–‡â–‚â–„â–…â–…â–„â–ƒâ–„â–„â–‚â–‚â–„â–ƒâ–‚â–„
wandb:         train/mil_loss â–„â–‚â–‚â–…â–„â–‚â–‚â–‡â–ƒâ–„â–…â–‡â–†â–â–†â–ƒâ–ƒâ–ˆâ–‚â–‡â–ƒâ–…â–‚â–„â–â–‚â–ƒâ–…â–†â–ƒâ–‚â–„â–„â–ƒâ–‚â–„â–ƒâ–†â–…â–ƒ
wandb:      train/policy_loss â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94857
wandb: best/eval_avg_mil_loss 0.29201
wandb:  best/eval_ensemble_f1 0.94857
wandb:            eval/avg_f1 0.91565
wandb:      eval/avg_mil_loss 0.32502
wandb:       eval/ensemble_f1 0.91565
wandb:            test/avg_f1 0.92061
wandb:      test/avg_mil_loss 0.17757
wandb:       test/ensemble_f1 0.92061
wandb:           train/avg_f1 0.90319
wandb:      train/ensemble_f1 0.90319
wandb:         train/mil_loss 0.16308
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vibrant-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z0pp2097
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071404-z0pp2097/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nsxzy6me with config:
wandb: 	actor_learning_rate: 7.996887666648481e-06
wandb: 	attention_dropout_p: 0.373279429509775
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3866469187760365
wandb: 	temperature: 9.175031108681358
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071535-nsxzy6me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nsxzy6me
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–‡â–ˆâ–„â–‡â–…â–ƒâ–†â–…â–…â–†â–…â–„â–ƒâ–†â–‚â–†â–ƒâ–ƒâ–†â–„â–‡â–„â–ƒâ–‡â–†â–…â–‡â–…â–„â–â–‡â–„â–‡â–…â–†â–‚â–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–â–â–‚â–…â–†â–ƒâ–ˆâ–ƒâ–‡â–‡â–‚â–„â–„â–†â–ƒâ–‚â–…â–†â–†â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–„â–‚â–ƒâ–‚â–‡â–„â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–‡â–†â–ˆâ–…â–…â–†â–„â–…â–„â–ƒâ–†â–ƒâ–†â–†â–†â–ƒâ–†â–†â–…â–†â–„â–ƒâ–ˆâ–‚â–‡â–…â–„â–…â–â–‡â–„â–‡â–„â–†â–…â–‚â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–â–„â–„â–ƒâ–‚â–ƒâ–†â–‚â–„â–ƒâ–â–„â–„â–…â–„â–„â–„â–…â–„â–†â–ƒâ–…â–…â–…â–…â–…â–ƒâ–†â–†â–ˆâ–„â–‡â–…â–ƒâ–…â–‚â–‡â–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‚â–…â–„â–…â–„â–…â–‡â–†â–„â–…â–…â–†â–…â–…â–…â–…â–„â–â–…â–„â–„â–‡â–‡â–‡â–†â–…â–†â–ˆâ–ˆâ–‡â–†â–ˆâ–‚â–†â–…â–„â–‡â–†
wandb:         train/mil_loss â–†â–…â–‡â–‡â–…â–„â–‡â–‡â–ƒâ–„â–…â–‚â–…â–ƒâ–…â–„â–…â–â–…â–ƒâ–‚â–†â–ˆâ–„â–â–„â–„â–â–‚â–‡â–ƒâ–‡â–„â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–„
wandb:      train/policy_loss â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93025
wandb: best/eval_avg_mil_loss 0.24846
wandb:  best/eval_ensemble_f1 0.93025
wandb:            eval/avg_f1 0.90411
wandb:      eval/avg_mil_loss 0.26974
wandb:       eval/ensemble_f1 0.90411
wandb:            test/avg_f1 0.89897
wandb:      test/avg_mil_loss 0.23355
wandb:       test/ensemble_f1 0.89897
wandb:           train/avg_f1 0.89787
wandb:      train/ensemble_f1 0.89787
wandb:         train/mil_loss 4.56914
wandb:      train/policy_loss 0.52291
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.52291
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run blooming-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nsxzy6me
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071535-nsxzy6me/logs
wandb: Agent Starting Run: gn1qml5d with config:
wandb: 	actor_learning_rate: 0.0005826732002706557
wandb: 	attention_dropout_p: 0.0701003429011402
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9974657760358944
wandb: 	temperature: 5.905445122576953
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071718-gn1qml5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gn1qml5d
wandb: uploading wandb-summary.json
wandb: uploading history steps 76-80, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–…â–„â–ˆâ–…â–†â–†â–‚â–†â–†â–‚â–„â–‡â–ƒâ–…â–ƒâ–…â–â–…â–ƒâ–„â–…â–‚â–ƒâ–„â–…â–…â–„â–‚â–â–†â–…â–„â–â–â–ƒâ–‚â–‚â–„
wandb:      eval/avg_mil_loss â–…â–‚â–ƒâ–„â–†â–…â–‚â–ˆâ–‚â–‡â–‚â–â–„â–ƒâ–„â–„â–†â–â–ƒâ–†â–‡â–„â–‚â–†â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–‚â–…â–‚â–†â–ƒâ–…â–ƒâ–‚â–…
wandb:       eval/ensemble_f1 â–ƒâ–â–‡â–†â–ƒâ–„â–†â–‡â–‡â–‡â–‡â–…â–ƒâ–ˆâ–†â–†â–ƒâ–ƒâ–†â–†â–…â–â–ƒâ–‚â–†â–„â–†â–…â–†â–†â–‡â–…â–†â–…â–ƒâ–‚â–„â–ƒâ–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–‡â–‡â–„â–†â–ˆâ–…â–„â–‡â–†â–‡â–„â–…â–…â–ˆâ–‡â–†â–‡â–‡â–…â–‡â–‡â–‡â–†â–‡â–†â–ˆâ–ƒâ–†â–…â–„â–…â–…â–‡â–†â–â–ƒâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–…â–…â–†â–ƒâ–„â–…â–ˆâ–ˆâ–†â–„â–‚â–„â–„â–‚â–ˆâ–†â–‡â–„â–†â–„â–†â–…â–…â–†â–„â–ƒâ–†â–ƒâ–…â–„â–„â–†â–†â–â–„â–ƒâ–†â–
wandb:         train/mil_loss â–„â–‡â–„â–…â–…â–ƒâ–ƒâ–†â–„â–„â–…â–„â–„â–„â–…â–†â–„â–…â–…â–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–ƒâ–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–…â–â–ƒâ–‚â–ƒâ–
wandb:      train/policy_loss â–…â–â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–‡â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94099
wandb: best/eval_avg_mil_loss 0.2586
wandb:  best/eval_ensemble_f1 0.94099
wandb:            eval/avg_f1 0.90486
wandb:      eval/avg_mil_loss 0.36989
wandb:       eval/ensemble_f1 0.90486
wandb:            test/avg_f1 0.91253
wandb:      test/avg_mil_loss 0.19565
wandb:       test/ensemble_f1 0.91253
wandb:           train/avg_f1 0.88812
wandb:      train/ensemble_f1 0.88812
wandb:         train/mil_loss 0.16323
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hardy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gn1qml5d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071718-gn1qml5d/logs
wandb: Agent Starting Run: yz4dvrc9 with config:
wandb: 	actor_learning_rate: 2.3935504134161713e-06
wandb: 	attention_dropout_p: 0.021412493081727435
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9950683016085384
wandb: 	temperature: 5.330187687051532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071830-yz4dvrc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yz4dvrc9
wandb: uploading history steps 101-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–ƒâ–„â–†â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–…â–ƒâ–„â–†â–‡â–…â–‡â–â–†â–†â–ˆâ–…â–ƒâ–…â–…â–„â–ƒâ–‡â–‚â–„â–‚â–‚â–ƒâ–‡â–
wandb:      eval/avg_mil_loss â–„â–„â–…â–ƒâ–ƒâ–„â–†â–‚â–‚â–„â–‚â–„â–‚â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–„â–ƒâ–ƒâ–„â–†â–‚â–„â–„â–‚â–‚â–
wandb:       eval/ensemble_f1 â–„â–‚â–ƒâ–ƒâ–„â–†â–†â–„â–„â–ƒâ–‚â–†â–â–‚â–ƒâ–ƒâ–†â–†â–ˆâ–ƒâ–‡â–â–„â–ƒâ–„â–„â–„â–ƒâ–‚â–‡â–ƒâ–ƒâ–‚â–„â–„â–‚â–ƒâ–…â–†â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–…â–ƒâ–†â–‡â–‚â–ƒâ–„â–ˆâ–‡â–‚â–†â–…â–‡â–†â–ˆâ–„â–ƒâ–ƒâ–…â–â–…â–ƒâ–„â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–†â–†â–â–†â–…
wandb:      train/ensemble_f1 â–‚â–…â–…â–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–„â–ˆâ–ˆâ–‚â–‚â–…â–‡â–‡â–†â–„â–…â–„â–†â–…â–…â–ƒâ–ƒâ–…â–…â–ˆâ–ƒâ–„â–‡â–‚â–…â–ƒâ–ˆâ–†â–ˆâ–†â–„
wandb:         train/mil_loss â–‡â–ƒâ–…â–„â–ƒâ–„â–„â–…â–…â–†â–„â–â–‚â–‚â–ƒâ–ˆâ–„â–†â–ƒâ–‚â–â–‡â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–ƒâ–†â–„â–‚â–‚â–…â–…â–‚â–ˆâ–
wandb:      train/policy_loss â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9409
wandb: best/eval_avg_mil_loss 0.24296
wandb:  best/eval_ensemble_f1 0.9409
wandb:            eval/avg_f1 0.91135
wandb:      eval/avg_mil_loss 0.26755
wandb:       eval/ensemble_f1 0.91135
wandb:            test/avg_f1 0.90367
wandb:      test/avg_mil_loss 0.21301
wandb:       test/ensemble_f1 0.90367
wandb:           train/avg_f1 0.90203
wandb:      train/ensemble_f1 0.90203
wandb:         train/mil_loss 0.19879
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worthy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yz4dvrc9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071830-yz4dvrc9/logs
wandb: Agent Starting Run: anm0cqvl with config:
wandb: 	actor_learning_rate: 3.401609018248062e-06
wandb: 	attention_dropout_p: 0.036270330758697455
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7963847503429016
wandb: 	temperature: 5.871908814010201
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072024-anm0cqvl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/anm0cqvl
wandb: uploading history steps 87-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–…â–†â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–‡â–…â–…â–ˆâ–‡â–…â–„â–†â–ˆâ–…â–…â–†â–‡â–„â–†â–„â–„â–‡â–ˆâ–ƒâ–„â–…â–„â–†â–„â–‡â–…â–‡â–„â–ƒâ–…â–‚â–â–†â–‡â–†â–†â–…
wandb:      eval/avg_mil_loss â–†â–…â–†â–ƒâ–†â–…â–ƒâ–„â–„â–…â–…â–‚â–ƒâ–…â–â–†â–†â–„â–ƒâ–…â–…â–‡â–ˆâ–ƒâ–†â–‡â–†â–…â–…â–…â–„â–ƒâ–„â–„â–†â–ƒâ–ƒâ–ƒâ–†â–‡
wandb:       eval/ensemble_f1 â–‡â–…â–ƒâ–†â–…â–…â–…â–…â–‡â–ˆâ–„â–†â–ƒâ–‡â–…â–†â–„â–„â–†â–…â–…â–‡â–…â–…â–„â–ƒâ–†â–†â–ƒâ–ƒâ–„â–„â–…â–†â–‚â–†â–…â–â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ˆâ–ˆâ–ƒâ–†â–„â–†â–‡â–†â–†â–†â–…â–†â–‡â–†â–ˆâ–‡â–„â–ˆâ–…â–†â–†â–‚â–ˆâ–â–†â–†â–†â–†â–†â–†â–‡â–‡â–…â–„â–ƒâ–†â–„â–„
wandb:      train/ensemble_f1 â–†â–†â–ˆâ–ˆâ–ƒâ–†â–„â–…â–‡â–…â–†â–‚â–„â–†â–†â–…â–†â–ˆâ–…â–â–„â–„â–…â–ƒâ–„â–„â–â–ˆâ–ˆâ–…â–„â–†â–†â–…â–‡â–‚â–„â–ƒâ–„â–‚
wandb:         train/mil_loss â–ˆâ–„â–†â–†â–†â–‡â–†â–ƒâ–…â–„â–…â–„â–‚â–„â–‚â–„â–‚â–„â–…â–„â–„â–ƒâ–…â–„â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–‚â–„â–â–‚â–ƒâ–â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–‡â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92653
wandb: best/eval_avg_mil_loss 0.22927
wandb:  best/eval_ensemble_f1 0.92653
wandb:            eval/avg_f1 0.90478
wandb:      eval/avg_mil_loss 0.26501
wandb:       eval/ensemble_f1 0.90478
wandb:            test/avg_f1 0.88761
wandb:      test/avg_mil_loss 0.22107
wandb:       test/ensemble_f1 0.88761
wandb:           train/avg_f1 0.89178
wandb:      train/ensemble_f1 0.89178
wandb:         train/mil_loss 0.39174
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run autumn-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/anm0cqvl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072024-anm0cqvl/logs
wandb: Agent Starting Run: bjy0cumv with config:
wandb: 	actor_learning_rate: 2.0715191289695443e-06
wandb: 	attention_dropout_p: 0.029034097952086668
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6656394704575374
wandb: 	temperature: 6.025742021894029
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072212-bjy0cumv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjy0cumv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…â–‡â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–†â–†â–„â–†â–†â–…â–†â–…â–„â–ƒâ–„â–‚â–…â–…â–…â–„â–‡â–ƒâ–„â–†â–„â–…â–…â–„â–…â–ˆâ–‚â–„â–…â–‚â–â–‚â–ƒâ–„â–„â–‚â–ƒ
wandb:      eval/avg_mil_loss â–„â–„â–â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–…â–…â–„â–†â–…â–„â–‡â–„â–†â–„â–…â–†â–„â–…â–ƒâ–„â–ƒâ–…â–…â–…â–ˆâ–†â–…â–…â–ƒâ–†â–…â–‡â–‡â–…
wandb:       eval/ensemble_f1 â–†â–…â–‡â–‡â–†â–ƒâ–†â–†â–…â–…â–„â–…â–†â–…â–„â–„â–ƒâ–„â–†â–„â–…â–…â–ˆâ–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–…â–ƒâ–‡â–ƒâ–‚â–„â–ƒâ–â–ƒâ–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–†â–„â–ˆâ–…â–ˆâ–…â–†â–‡â–†â–†â–†â–†â–†â–†â–„â–„â–‡â–†â–†â–…â–ƒâ–„â–ƒâ–„â–„â–‚â–‚â–†â–‚â–…â–„â–„â–‚â–„â–„â–â–ƒâ–
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–‡â–ˆâ–„â–ˆâ–‡â–†â–‡â–†â–‡â–…â–†â–†â–†â–†â–…â–…â–‡â–‡â–„â–…â–„â–†â–ƒâ–…â–…â–…â–„â–‡â–„â–ƒâ–‚â–…â–„â–…â–„â–ƒâ–
wandb:         train/mil_loss â–…â–ˆâ–†â–†â–ˆâ–„â–…â–…â–…â–„â–…â–…â–ƒâ–„â–…â–…â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–…â–„â–…â–…â–„â–„â–„â–…â–‚â–ƒâ–…â–„â–„â–„â–â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–…â–ƒâ–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–†â–„â–„â–„â–†â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–†â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–†â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93408
wandb: best/eval_avg_mil_loss 0.24765
wandb:  best/eval_ensemble_f1 0.93408
wandb:            eval/avg_f1 0.89416
wandb:      eval/avg_mil_loss 0.32156
wandb:       eval/ensemble_f1 0.89416
wandb:            test/avg_f1 0.90623
wandb:      test/avg_mil_loss 0.21833
wandb:       test/ensemble_f1 0.90623
wandb:           train/avg_f1 0.87253
wandb:      train/ensemble_f1 0.87253
wandb:         train/mil_loss 0.27261
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjy0cumv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072212-bjy0cumv/logs
wandb: Agent Starting Run: n3b8maqg with config:
wandb: 	actor_learning_rate: 3.064554738933209e-06
wandb: 	attention_dropout_p: 0.4677817603077958
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6030123586305005
wandb: 	temperature: 6.709232425838955
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072335-n3b8maqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n3b8maqg
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–†â–„â–„â–„â–…â–‚â–„â–„â–‡â–†â–ƒâ–†â–†â–‡â–…â–‡â–…â–…â–„â–…â–ƒâ–ƒâ–‡â–†â–…â–ƒâ–‡â–†â–†â–†â–…â–„â–†â–†â–…â–„â–â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–â–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–„â–„â–‚â–ƒâ–‚â–ƒâ–„â–„â–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–…â–„â–†â–„â–…â–†â–„â–†â–ˆâ–ƒâ–†â–ˆâ–…â–…â–„â–…â–â–†â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–…â–„â–‚â–„â–„â–„â–„â–‡â–†â–‡â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–†â–„â–†â–‡â–ˆâ–„â–„â–†â–…â–…â–…â–‡â–ƒâ–†â–…â–…â–â–…â–…â–†â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–„â–†â–‡â–†â–‚â–…â–„â–†â–ƒ
wandb:      train/ensemble_f1 â–†â–ˆâ–…â–‡â–…â–…â–ˆâ–„â–‡â–ˆâ–‡â–…â–†â–†â–â–…â–…â–…â–…â–…â–†â–…â–†â–ƒâ–†â–ƒâ–ƒâ–â–ˆâ–†â–„â–â–‡â–‡â–…â–‚â–â–†â–„â–ƒ
wandb:         train/mil_loss â–…â–†â–ƒâ–„â–„â–†â–…â–‡â–„â–…â–†â–â–„â–â–ƒâ–â–ƒâ–†â–‚â–ƒâ–…â–…â–ƒâ–„â–„â–ƒâ–„â–‚â–…â–ƒâ–ƒâ–†â–ƒâ–ˆâ–…â–…â–…â–ƒâ–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94108
wandb: best/eval_avg_mil_loss 0.21439
wandb:  best/eval_ensemble_f1 0.94108
wandb:            eval/avg_f1 0.92261
wandb:      eval/avg_mil_loss 0.29129
wandb:       eval/ensemble_f1 0.92261
wandb:            test/avg_f1 0.91594
wandb:      test/avg_mil_loss 0.23596
wandb:       test/ensemble_f1 0.91594
wandb:           train/avg_f1 0.89451
wandb:      train/ensemble_f1 0.89451
wandb:         train/mil_loss 0.19553
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n3b8maqg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072335-n3b8maqg/logs
wandb: Agent Starting Run: csg8k02t with config:
wandb: 	actor_learning_rate: 3.5423595654807686e-06
wandb: 	attention_dropout_p: 0.27056259481906814
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7975058940204185
wandb: 	temperature: 4.918914306057315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072534-csg8k02t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csg8k02t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–ˆâ–…â–‚â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–‚â–…â–…â–„â–ƒâ–ˆâ–†â–…â–…â–ƒâ–†â–‚â–ƒâ–‚â–„â–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‡â–ƒâ–â–ƒâ–‚â–â–‚
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–…â–„â–†â–„â–„â–„â–„â–‚â–ƒâ–â–†â–…â–â–ƒâ–ƒâ–†â–„â–â–â–ƒâ–…â–…â–„â–…â–†â–â–ƒâ–„â–ˆ
wandb:       eval/ensemble_f1 â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‡â–…â–…â–†â–…â–†â–†â–„â–…â–ƒâ–ˆâ–‚â–ˆâ–‚â–†â–‡â–ƒâ–…â–…â–†â–„â–…â–â–†â–†â–ƒâ–„â–‚â–‚â–„â–„â–â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–†â–‡â–…â–†â–‡â–…â–†â–†â–†â–ˆâ–ˆâ–†â–ˆâ–â–‡â–…â–…â–†â–„â–„â–‡â–…â–„â–‡â–…â–„â–†â–„â–†â–‚â–ƒâ–„â–…â–†â–ƒâ–…â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–ˆâ–†â–†â–ƒâ–ƒâ–…â–…â–‡â–†â–†â–‡â–…â–„â–†â–…â–†â–‡â–„â–…â–…â–†â–‡â–„â–†â–„â–…â–„â–…â–„â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–‚â–
wandb:         train/mil_loss â–†â–ˆâ–†â–†â–†â–…â–†â–†â–…â–…â–…â–‡â–†â–…â–ƒâ–„â–„â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–â–‚â–â–‚â–‚â–ƒâ–ƒâ–…â–â–„
wandb:      train/policy_loss â–…â–‚â–…â–…â–…â–„â–…â–…â–‚â–‡â–„â–â–…â–…â–…â–…â–‡â–…â–†â–…â–†â–†â–…â–…â–†â–…â–‡â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–ƒâ–â–…â–‡â–…â–†â–…â–…â–†â–…â–…â–…â–…â–…â–†â–…â–…â–‡â–…â–‡â–ˆâ–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93361
wandb: best/eval_avg_mil_loss 0.30098
wandb:  best/eval_ensemble_f1 0.93361
wandb:            eval/avg_f1 0.8648
wandb:      eval/avg_mil_loss 0.37671
wandb:       eval/ensemble_f1 0.8648
wandb:            test/avg_f1 0.90236
wandb:      test/avg_mil_loss 0.20684
wandb:       test/ensemble_f1 0.90236
wandb:           train/avg_f1 0.87518
wandb:      train/ensemble_f1 0.87518
wandb:         train/mil_loss 2.95605
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sandy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csg8k02t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072534-csg8k02t/logs
wandb: Agent Starting Run: ruh5ai7o with config:
wandb: 	actor_learning_rate: 2.3212829916331103e-05
wandb: 	attention_dropout_p: 0.3651875631884795
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22899316549973925
wandb: 	temperature: 9.167577384109316
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072734-ruh5ai7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ruh5ai7o
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ƒâ–†â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–†â–„â–ƒâ–†â–ˆâ–†â–â–…â–‚â–‡â–‡â–‚â–„â–†â–…â–‚â–…â–ƒâ–†â–…â–„â–‡â–‡â–…â–‚â–„â–†â–â–†â–„â–‡â–…â–„â–‚â–„â–†â–…â–…
wandb:      eval/avg_mil_loss â–‚â–‚â–„â–„â–„â–…â–ƒâ–ˆâ–„â–‚â–‚â–ƒâ–„â–ƒâ–„â–‚â–„â–â–‚â–ƒâ–…â–‚â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–â–‚
wandb:       eval/ensemble_f1 â–…â–ƒâ–ˆâ–ƒâ–‚â–ˆâ–†â–„â–â–†â–„â–‚â–†â–…â–ƒâ–†â–†â–ƒâ–‚â–†â–†â–‚â–ƒâ–‡â–„â–‚â–‚â–„â–„â–‡â–…â–†â–„â–„â–†â–â–†â–„â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–…â–…â–ˆâ–„â–„â–„â–„â–â–…â–…â–†â–‚â–…â–†â–„â–„â–…â–‡â–…â–„â–…â–…â–…â–…â–„â–†â–‡â–„â–…â–„â–ƒâ–…â–ˆâ–„â–†â–„â–„â–„
wandb:      train/ensemble_f1 â–…â–†â–…â–„â–ˆâ–„â–ƒâ–ˆâ–ƒâ–â–…â–„â–ƒâ–„â–„â–„â–†â–„â–…â–„â–…â–…â–„â–…â–‡â–„â–„â–ƒâ–†â–ƒâ–…â–…â–†â–„â–…â–†â–†â–ƒâ–„â–„
wandb:         train/mil_loss â–…â–…â–‡â–ˆâ–‡â–…â–†â–„â–‡â–…â–„â–†â–†â–ˆâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–‚â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–â–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93395
wandb: best/eval_avg_mil_loss 0.39334
wandb:  best/eval_ensemble_f1 0.93395
wandb:            eval/avg_f1 0.91482
wandb:      eval/avg_mil_loss 0.25808
wandb:       eval/ensemble_f1 0.91482
wandb:            test/avg_f1 0.86217
wandb:      test/avg_mil_loss 0.39351
wandb:       test/ensemble_f1 0.86217
wandb:           train/avg_f1 0.90395
wandb:      train/ensemble_f1 0.90395
wandb:         train/mil_loss 1.35269
wandb:      train/policy_loss 0.13173
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.13173
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run icy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ruh5ai7o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072734-ruh5ai7o/logs
wandb: Agent Starting Run: 2h24vwf7 with config:
wandb: 	actor_learning_rate: 8.057233903035425e-06
wandb: 	attention_dropout_p: 0.27771671124411607
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1656610480195886
wandb: 	temperature: 8.750327063431987
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072917-2h24vwf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2h24vwf7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–…â–„â–„â–â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–†â–â–„â–ƒâ–…â–„â–…â–…â–…â–…â–…â–…â–„â–…â–„â–†â–‚â–†â–‚â–ƒâ–„â–„â–„â–ƒâ–ˆâ–ƒâ–†â–ƒâ–†â–‡â–„â–ƒâ–†â–ˆâ–„â–‡â–‡â–‚
wandb:      eval/avg_mil_loss â–ˆâ–„â–„â–ƒâ–…â–ƒâ–†â–ƒâ–…â–…â–†â–…â–‚â–„â–â–„â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ƒâ–‚â–â–„â–†â–ƒâ–â–‚â–„â–„â–â–‚â–ƒâ–„â–„â–…
wandb:       eval/ensemble_f1 â–„â–„â–†â–â–ƒâ–†â–…â–„â–…â–‡â–…â–…â–‚â–ƒâ–†â–„â–†â–‚â–‡â–‚â–‚â–…â–ƒâ–…â–ˆâ–ƒâ–ƒâ–…â–†â–‡â–â–…â–„â–ƒâ–ƒâ–„â–ˆâ–„â–‚â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‡â–„â–…â–…â–ƒâ–‡â–ˆâ–„â–‚â–‡â–ƒâ–…â–†â–„â–…â–‚â–‚â–‡â–†â–†â–‡â–…â–„â–ƒâ–‡â–ˆâ–‚â–ˆâ–ˆâ–…â–…â–ƒâ–†â–…â–„â–ˆâ–‡â–‡â–„
wandb:      train/ensemble_f1 â–…â–â–…â–ƒâ–†â–ƒâ–‡â–‚â–†â–‚â–…â–‡â–ƒâ–…â–…â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–†â–„â–‚â–ƒâ–ˆâ–…â–‡â–‚â–ƒâ–…â–„â–ƒâ–â–„â–ˆâ–‡â–‚
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–†â–…â–ˆâ–ˆâ–†â–…â–…â–…â–…â–†â–ˆâ–…â–‚â–ƒâ–†â–‚â–…â–…â–„â–†â–…â–„â–…â–â–†â–…â–…â–†â–„â–…â–„â–„â–…â–„â–„â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–ˆâ–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–â–ˆâ–â–â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–â–ˆâ–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.26015
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.8852
wandb:      eval/avg_mil_loss 0.40158
wandb:       eval/ensemble_f1 0.8852
wandb:            test/avg_f1 0.89763
wandb:      test/avg_mil_loss 0.16591
wandb:       test/ensemble_f1 0.89763
wandb:           train/avg_f1 0.89534
wandb:      train/ensemble_f1 0.89534
wandb:         train/mil_loss 0.46415
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2h24vwf7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072917-2h24vwf7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t1emiarz with config:
wandb: 	actor_learning_rate: 1.1046241984893558e-06
wandb: 	attention_dropout_p: 0.1414142898749236
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7864688694591203
wandb: 	temperature: 8.971906720616264
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073048-t1emiarz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t1emiarz
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 105-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–„â–ˆâ–‡â–†â–†â–‡â–‡â–†â–†â–†â–…â–†â–†â–…â–‡â–…â–†â–ƒâ–„â–„â–…â–†â–…â–„â–„â–…â–‡â–…â–„â–‚â–„â–„â–‚â–…â–…â–„â–ƒâ–
wandb:      eval/avg_mil_loss â–‡â–„â–‡â–‚â–…â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–„â–†â–‡â–ƒâ–†â–„â–†â–…â–â–…â–…â–†â–â–†â–ƒâ–„â–„â–…â–ˆâ–„â–„â–…â–‡â–‡
wandb:       eval/ensemble_f1 â–‡â–†â–„â–†â–ˆâ–‡â–…â–†â–ˆâ–†â–‚â–…â–„â–†â–†â–„â–…â–‡â–„â–†â–‚â–„â–…â–…â–‚â–„â–†â–…â–â–…â–†â–ƒâ–‚â–„â–‚â–â–„â–‚â–ƒâ–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–†â–ˆâ–…â–…â–†â–„â–†â–‡â–†â–…â–‡â–‡â–†â–‡â–†â–ƒâ–…â–†â–†â–„â–…â–†â–‚â–ƒâ–„â–…â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–‚â–‚â–
wandb:      train/ensemble_f1 â–‡â–‡â–†â–‡â–…â–„â–‡â–†â–†â–†â–ˆâ–…â–„â–…â–…â–„â–†â–…â–ƒâ–†â–†â–‚â–„â–…â–‡â–„â–„â–„â–‚â–„â–‚â–…â–„â–„â–„â–„â–‚â–‚â–â–
wandb:         train/mil_loss â–†â–…â–…â–ˆâ–…â–†â–„â–„â–„â–…â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–…â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–â–ƒâ–â–ƒâ–„â–‚â–„â–‚â–ƒâ–
wandb:      train/policy_loss â–ƒâ–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–„â–‚â–‚â–â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–…â–†â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ˆâ–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.267
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.87218
wandb:      eval/avg_mil_loss 0.36734
wandb:       eval/ensemble_f1 0.87218
wandb:            test/avg_f1 0.91963
wandb:      test/avg_mil_loss 0.15967
wandb:       test/ensemble_f1 0.91963
wandb:           train/avg_f1 0.87366
wandb:      train/ensemble_f1 0.87366
wandb:         train/mil_loss 0.16596
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run treasured-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t1emiarz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073048-t1emiarz/logs
wandb: Agent Starting Run: aft2y3pe with config:
wandb: 	actor_learning_rate: 0.0002725864690436605
wandb: 	attention_dropout_p: 0.3386660368023196
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1959691456466244
wandb: 	temperature: 7.636904664866885
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073226-aft2y3pe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aft2y3pe
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 112-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ƒâ–â–„â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–„â–†â–†â–…â–‡â–„â–…â–ˆâ–†â–„â–‚â–ƒâ–„â–„â–†â–†â–…â–†â–…â–‚â–â–ƒâ–…â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–†â–†â–…â–‚â–…â–â–„â–ƒâ–„
wandb:      eval/avg_mil_loss â–…â–…â–„â–†â–â–„â–„â–…â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–‡â–ˆâ–ƒâ–…â–„â–‡â–‡â–†â–…â–†â–…â–ƒâ–„â–„â–„â–…â–†â–„â–ˆâ–†â–…
wandb:       eval/ensemble_f1 â–ƒâ–…â–„â–ƒâ–…â–„â–ˆâ–†â–ƒâ–ƒâ–ƒâ–â–ƒâ–‡â–„â–…â–…â–ƒâ–†â–…â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–‚â–„â–…â–ƒâ–‚â–…â–ƒâ–…â–‚â–ƒâ–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–‚â–†â–ˆâ–…â–„â–†â–‡â–‚â–‡â–ƒâ–…â–ƒâ–‚â–â–†â–‡â–ˆâ–‚â–â–‚â–„â–„â–„â–‡â–‡â–ƒâ–†â–„â–ƒâ–â–‚â–‚â–‚â–„â–†â–‚â–„â–…
wandb:      train/ensemble_f1 â–†â–†â–‡â–‡â–†â–ˆâ–†â–‡â–„â–ˆâ–ˆâ–‡â–‚â–…â–†â–…â–ƒâ–†â–†â–†â–…â–…â–‡â–ˆâ–‡â–…â–…â–ƒâ–…â–‡â–‡â–„â–…â–â–…â–ƒâ–„â–„â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–†â–„â–ƒâ–‡â–†â–†â–„â–ƒâ–ƒâ–†â–‚â–‚â–…â–„â–…â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–â–„â–‚â–‚â–‚â–‚â–â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–„â–ˆâ–„â–â–„â–„â–„â–ˆâ–„â–„â–â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.32285
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.86514
wandb:      eval/avg_mil_loss 0.3678
wandb:       eval/ensemble_f1 0.86514
wandb:            test/avg_f1 0.89191
wandb:      test/avg_mil_loss 0.28248
wandb:       test/ensemble_f1 0.89191
wandb:           train/avg_f1 0.87154
wandb:      train/ensemble_f1 0.87154
wandb:         train/mil_loss 1.99975
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aft2y3pe
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073226-aft2y3pe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8s7wfsc0 with config:
wandb: 	actor_learning_rate: 9.665470361171922e-06
wandb: 	attention_dropout_p: 0.4126594969457582
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4168660638842648
wandb: 	temperature: 8.578492133144838
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073426-8s7wfsc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8s7wfsc0
wandb: uploading wandb-summary.json
wandb: uploading history steps 113-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‚â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–â–†â–†â–…â–ƒâ–†â–…â–†â–‚â–ˆâ–ƒâ–†â–„â–…â–„â–…â–†â–„â–„â–…â–†â–†â–…â–ˆâ–‡â–…â–‡â–†â–†â–‡â–…â–†â–ˆâ–…â–†â–„â–†â–‡â–„â–…
wandb:      eval/avg_mil_loss â–†â–†â–…â–ƒâ–„â–ƒâ–â–‚â–â–„â–…â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–‚â–†â–…â–†â–‡â–†â–ƒâ–„â–†â–†â–…â–…â–‡â–†
wandb:       eval/ensemble_f1 â–‚â–†â–â–ˆâ–â–†â–ƒâ–…â–„â–†â–„â–†â–…â–†â–ƒâ–†â–‡â–…â–„â–†â–‡â–‡â–†â–…â–†â–†â–†â–„â–…â–ˆâ–†â–…â–†â–…â–…â–†â–†â–†â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–…â–…â–…â–†â–ƒâ–ƒâ–…â–…â–†â–…â–ƒâ–…â–ƒâ–ƒâ–…â–„â–‚â–‚â–…â–„â–„â–†â–…â–ƒâ–„â–„â–‚â–†â–„â–…â–…â–ƒâ–â–â–ƒâ–„â–„â–ˆ
wandb:      train/ensemble_f1 â–ƒâ–‚â–‚â–„â–ƒâ–…â–‚â–…â–…â–„â–…â–„â–†â–…â–ƒâ–‚â–†â–ƒâ–â–â–„â–‚â–ƒâ–†â–…â–„â–‚â–ˆâ–‚â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ˆ
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–…â–„â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚
wandb:      train/policy_loss â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–†â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.18643
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.89197
wandb:      eval/avg_mil_loss 0.3901
wandb:       eval/ensemble_f1 0.89197
wandb:            test/avg_f1 0.90493
wandb:      test/avg_mil_loss 0.18433
wandb:       test/ensemble_f1 0.90493
wandb:           train/avg_f1 0.88385
wandb:      train/ensemble_f1 0.88385
wandb:         train/mil_loss 0.56012
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run atomic-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8s7wfsc0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073426-8s7wfsc0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zx4sise4 with config:
wandb: 	actor_learning_rate: 0.0003812795773607847
wandb: 	attention_dropout_p: 0.3082131093470254
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.585515869782965
wandb: 	temperature: 4.649321121715929
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073645-zx4sise4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4sise4
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–‡
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–ˆâ–†â–„â–ˆâ–‡â–‡â–‡â–†â–‡â–…â–†â–†â–‡â–‡â–†â–‡â–…â–…â–ƒâ–…â–…â–â–„â–„â–…â–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒâ–â–‚â–‚â–„â–
wandb:      eval/avg_mil_loss â–„â–â–â–…â–â–‚â–â–‚â–‚â–â–ƒâ–‚â–â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–†â–†â–‡â–…â–†â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–†
wandb:       eval/ensemble_f1 â–„â–†â–…â–†â–ƒâ–„â–„â–…â–ˆâ–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–„â–…â–„â–‚â–ƒâ–„â–‚â–ƒâ–„â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–
wandb:           train/avg_f1 â–…â–†â–‡â–‡â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–ˆâ–‡â–‡â–†â–‡â–†â–…â–…â–ƒâ–ƒâ–„â–…â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒ
wandb:      train/ensemble_f1 â–†â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–‡â–‡â–‡â–…â–…â–‡â–‡â–†â–†â–…â–‡â–†â–…â–ƒâ–„â–…â–…â–ƒâ–„â–ƒâ–„â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–„
wandb:         train/mil_loss â–†â–†â–ˆâ–†â–†â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–„â–…â–†â–…â–…â–†â–…â–…â–…â–„â–„â–„â–„â–…â–…â–…â–„â–‡â–‡â–†â–…â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–
wandb:      train/policy_loss â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93715
wandb: best/eval_avg_mil_loss 0.25596
wandb:  best/eval_ensemble_f1 0.93715
wandb:            eval/avg_f1 0.84309
wandb:      eval/avg_mil_loss 0.38586
wandb:       eval/ensemble_f1 0.84309
wandb:           train/avg_f1 0.86844
wandb:      train/ensemble_f1 0.86844
wandb:         train/mil_loss 3.39551
wandb:      train/policy_loss 0.10606
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.10606
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wild-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4sise4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073645-zx4sise4/logs
wandb: ERROR Run zx4sise4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: une9qnob with config:
wandb: 	actor_learning_rate: 0.0005822823892568788
wandb: 	attention_dropout_p: 0.2139476862207863
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0938699251046038
wandb: 	temperature: 1.59265877903082
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073854-une9qnob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/une9qnob
wandb: uploading wandb-summary.json
wandb: uploading history steps 76-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–ˆ
wandb:            eval/avg_f1 â–‚â–†â–‡â–‡â–†â–…â–ƒâ–„â–„â–ˆâ–…â–„â–†â–†â–‡â–…â–†â–‡â–ƒâ–‚â–…â–‡â–‚â–ˆâ–„â–…â–â–†â–†â–„â–…â–…â–…â–â–ƒâ–†â–†â–‚â–…â–‚
wandb:      eval/avg_mil_loss â–‡â–…â–„â–„â–‡â–„â–„â–†â–„â–ƒâ–‡â–†â–ƒâ–ˆâ–†â–â–…â–ƒâ–…â–†â–ˆâ–…â–„â–„â–„â–‚â–…â–†â–…â–†â–‡â–†â–†â–â–…â–‡â–„â–„â–ˆâ–„
wandb:       eval/ensemble_f1 â–â–ƒâ–ƒâ–ˆâ–…â–‚â–„â–„â–ƒâ–„â–‚â–„â–„â–†â–…â–†â–„â–‚â–…â–‡â–ƒâ–…â–‡â–‡â–†â–„â–„â–ƒâ–…â–…â–…â–‡â–„â–ƒâ–„â–…â–ƒâ–…â–†â–
wandb:           train/avg_f1 â–†â–„â–„â–‡â–„â–ƒâ–ƒâ–…â–„â–„â–…â–†â–ˆâ–†â–„â–„â–„â–ƒâ–†â–†â–ƒâ–ˆâ–ƒâ–„â–ƒâ–‡â–†â–…â–†â–„â–‡â–‡â–„â–†â–‡â–ˆâ–„â–†â–…â–
wandb:      train/ensemble_f1 â–†â–ƒâ–â–‚â–‚â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–…â–ƒâ–„â–„â–†â–„â–‚â–‡â–ƒâ–„â–…â–‚â–ˆâ–†â–â–…â–…â–…â–„â–„â–‡â–‡â–ƒâ–…â–‡â–ƒâ–†â–„â–„
wandb:         train/mil_loss â–†â–‡â–‡â–ˆâ–ƒâ–…â–„â–†â–‡â–‚â–ˆâ–†â–ƒâ–…â–†â–…â–†â–ƒâ–„â–…â–ƒâ–â–ƒâ–„â–…â–‚â–…â–…â–‚â–„â–„â–‚â–â–…â–„â–…â–ƒâ–„â–‚â–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–ƒâ–†â–ˆâ–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.29657
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.91482
wandb:      eval/avg_mil_loss 0.27085
wandb:       eval/ensemble_f1 0.91482
wandb:           train/avg_f1 0.89111
wandb:      train/ensemble_f1 0.89111
wandb:         train/mil_loss 2.87322
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run radiant-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/une9qnob
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073854-une9qnob/logs
wandb: ERROR Run une9qnob errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9ny5ckme with config:
wandb: 	actor_learning_rate: 5.4915481843704854e-05
wandb: 	attention_dropout_p: 0.20016079465637215
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 162
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9226202545168436
wandb: 	temperature: 7.239556365785123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074012-9ny5ckme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ny5ckme
wandb: uploading history steps 123-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–„
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–ƒâ–‡â–‡â–‡â–…â–‡â–„â–‚â–‡â–†â–ˆâ–„â–ˆâ–„â–ƒâ–†â–†â–„â–„â–…â–„â–‚â–†â–â–„â–„â–„â–„â–…â–ˆâ–ƒâ–„â–…â–‡â–„â–…â–ƒâ–‚
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–†â–†â–ˆâ–†â–„â–„â–†â–â–…â–‚â–ƒâ–â–ƒâ–„â–†â–…â–„â–‚â–„â–†â–„â–…â–„â–„â–„â–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–…â–ˆâ–†â–ƒâ–†â–ˆâ–…â–…â–‚â–„â–‡â–…â–…â–†â–„â–†â–†â–‡â–ƒâ–„â–…â–…â–„â–‚â–â–„â–…â–„â–‚â–…â–‡â–„â–„â–„â–…â–ƒâ–‡â–ƒâ–‚
wandb:           train/avg_f1 â–ˆâ–†â–ˆâ–†â–†â–‚â–‡â–…â–†â–ˆâ–†â–…â–†â–…â–‡â–…â–‡â–‚â–…â–„â–…â–†â–…â–„â–„â–„â–‚â–†â–‚â–‚â–â–ƒâ–†â–â–„â–„â–„â–ƒâ–‚â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–†â–‡â–…â–…â–†â–…â–†â–†â–†â–„â–„â–…â–…â–„â–„â–„â–‚â–„â–…â–‚â–ƒâ–‚â–ˆâ–„â–…â–†â–…â–„â–„â–ƒâ–ƒâ–â–ƒ
wandb:         train/mil_loss â–†â–ˆâ–‚â–‚â–…â–…â–…â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–…â–…â–„â–ƒâ–„â–…â–„â–ƒâ–â–‚â–„â–„â–†â–‚â–„â–ƒâ–†â–…â–†â–‚â–ƒâ–…â–…â–†
wandb:      train/policy_loss â–„â–„â–„â–ˆâ–†â–†â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–ƒâ–„â–…â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ƒâ–ƒâ–ƒâ–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92669
wandb: best/eval_avg_mil_loss 0.26788
wandb:  best/eval_ensemble_f1 0.92669
wandb:            eval/avg_f1 0.85762
wandb:      eval/avg_mil_loss 0.40765
wandb:       eval/ensemble_f1 0.85762
wandb:           train/avg_f1 0.87439
wandb:      train/ensemble_f1 0.87439
wandb:         train/mil_loss 0.22613
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dainty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ny5ckme
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074012-9ny5ckme/logs
wandb: ERROR Run 9ny5ckme errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9mv58pyv with config:
wandb: 	actor_learning_rate: 3.4223711445639496e-05
wandb: 	attention_dropout_p: 0.2707302691629202
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7428851403894099
wandb: 	temperature: 0.8909713393323426
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074211-9mv58pyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mv58pyv
wandb: uploading wandb-summary.json
wandb: uploading history steps 75-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–„â–â–„â–†â–‚â–„â–‚â–„â–â–ƒâ–…â–„â–ƒâ–ˆâ–‚â–…â–„â–„â–…â–ƒâ–‚â–â–ƒâ–…â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–ƒâ–‚â–
wandb:      eval/avg_mil_loss â–‚â–‚â–â–â–‚â–‚â–ƒâ–â–â–‚â–‚â–ƒâ–„â–â–â–‚â–ƒâ–‚â–ƒâ–â–„â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–â–„â–‚â–ƒâ–â–â–…â–‚â–‚
wandb:       eval/ensemble_f1 â–„â–„â–…â–„â–†â–‡â–…â–†â–ƒâ–‚â–„â–…â–„â–„â–‚â–â–‚â–„â–„â–„â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–…â–„â–ƒâ–†â–â–„â–„â–„â–ƒâ–„â–†â–„â–‚
wandb:           train/avg_f1 â–„â–„â–ƒâ–„â–‡â–…â–„â–†â–…â–…â–…â–ƒâ–ƒâ–‚â–â–ƒâ–„â–…â–†â–ƒâ–ƒâ–„â–„â–‚â–‡â–ƒâ–ƒâ–ƒâ–†â–…â–ˆâ–†â–…â–†â–…â–…â–†â–†â–…â–…
wandb:      train/ensemble_f1 â–†â–‡â–ˆâ–„â–…â–ˆâ–…â–†â–†â–†â–†â–‡â–†â–ƒâ–†â–†â–ƒâ–…â–†â–„â–‡â–†â–†â–…â–†â–…â–‡â–†â–„â–†â–‡â–†â–…â–„â–†â–…â–†â–â–‡â–„
wandb:         train/mil_loss â–ˆâ–ˆâ–†â–‡â–†â–‡â–…â–…â–†â–…â–…â–…â–…â–…â–„â–‚â–„â–…â–…â–…â–„â–‚â–„â–ƒâ–…â–‚â–‚â–„â–‚â–„â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–„â–â–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91135
wandb: best/eval_avg_mil_loss 0.30801
wandb:  best/eval_ensemble_f1 0.91135
wandb:            eval/avg_f1 0.85582
wandb:      eval/avg_mil_loss 0.43071
wandb:       eval/ensemble_f1 0.85582
wandb:           train/avg_f1 0.86527
wandb:      train/ensemble_f1 0.86527
wandb:         train/mil_loss 0.24551
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mv58pyv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074211-9mv58pyv/logs
wandb: ERROR Run 9mv58pyv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: b1wrpl9k with config:
wandb: 	actor_learning_rate: 2.5105516646672105e-06
wandb: 	attention_dropout_p: 0.0773249199725522
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3398966477176455
wandb: 	temperature: 8.662717657235309
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074333-b1wrpl9k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b1wrpl9k
wandb: uploading wandb-summary.json
wandb: uploading history steps 94-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–…â–†â–‚â–…â–…â–ˆâ–„â–…â–â–‚â–ˆâ–…â–„â–ˆâ–„â–…â–„â–ƒâ–…â–‡â–‡â–‡â–ƒâ–ƒâ–„â–‡â–„â–†â–ƒâ–†â–„â–„â–‚â–‡â–‚â–ƒâ–…
wandb:      eval/avg_mil_loss â–†â–„â–ƒâ–ˆâ–„â–‚â–„â–„â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–‡â–„â–ƒâ–ƒâ–ƒâ–ˆâ–â–…â–†â–‚â–„â–„â–„â–†â–„â–†â–ƒâ–†â–ƒâ–â–ƒâ–‡â–…â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–†â–†â–„â–ˆâ–…â–†â–…â–â–†â–ƒâ–„â–‡â–„â–ƒâ–‡â–„â–…â–…â–…â–„â–ƒâ–‡â–†â–†â–ƒâ–ƒâ–â–„â–…â–…â–ƒâ–†â–‡â–…â–ˆâ–‚â–…â–ƒâ–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–…â–„â–„â–‡â–…â–ƒâ–ƒâ–â–†â–â–‚â–„â–…â–…â–‚â–…â–ƒâ–…â–ƒâ–„â–ƒâ–…â–â–‚â–…â–…â–…â–ƒâ–„â–„â–ƒâ–‚â–„â–ƒâ–†â–ˆâ–„â–„
wandb:      train/ensemble_f1 â–ƒâ–…â–†â–…â–‡â–„â–ƒâ–„â–„â–…â–…â–ƒâ–ƒâ–„â–‚â–†â–„â–…â–ƒâ–†â–„â–„â–„â–…â–„â–„â–…â–ƒâ–„â–…â–ƒâ–„â–â–†â–‚â–„â–ƒâ–ˆâ–…â–…
wandb:         train/mil_loss â–†â–‡â–‚â–â–†â–„â–„â–…â–ˆâ–…â–â–ƒâ–„â–ƒâ–…â–ˆâ–‡â–â–‚â–„â–ƒâ–…â–„â–…â–„â–ƒâ–„â–‚â–„â–ƒâ–…â–…â–†â–„â–†â–‚â–…â–…â–ƒâ–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.20072
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.89354
wandb:      eval/avg_mil_loss 0.29762
wandb:       eval/ensemble_f1 0.89354
wandb:            test/avg_f1 0.88704
wandb:      test/avg_mil_loss 0.18762
wandb:       test/ensemble_f1 0.88704
wandb:           train/avg_f1 0.88493
wandb:      train/ensemble_f1 0.88493
wandb:         train/mil_loss 1.99606
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b1wrpl9k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074333-b1wrpl9k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ma49iy7w with config:
wandb: 	actor_learning_rate: 1.0129717410828038e-06
wandb: 	attention_dropout_p: 0.22233680520384613
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5216350944642097
wandb: 	temperature: 5.49691210691188
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074528-ma49iy7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ma49iy7w
wandb: uploading history steps 113-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–â–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–…â–…â–ˆâ–†â–‡â–„â–ƒâ–…â–…â–‡â–…â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–„â–‚â–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–ƒâ–„â–„â–‚â–‚â–‚â–ƒâ–
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–„â–…â–„â–„â–…â–‡â–„â–†â–„â–ˆâ–‡â–‡â–…â–‡â–‡â–†â–†â–†â–†â–ˆâ–…â–…â–…â–ˆâ–‡â–†â–…â–…â–„â–†â–‡â–‡
wandb:       eval/ensemble_f1 â–‡â–ˆâ–…â–†â–‡â–‡â–…â–†â–‡â–ˆâ–†â–‡â–‡â–„â–†â–…â–ƒâ–„â–†â–„â–†â–ƒâ–„â–‚â–„â–„â–„â–â–…â–„â–‚â–â–â–„â–‚â–ƒâ–„â–â–ƒâ–‚
wandb:           train/avg_f1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–†â–…â–…â–…â–…â–…â–„â–„â–…â–…â–„â–…â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–â–‚â–â–
wandb:      train/ensemble_f1 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–…â–…â–†â–…â–„â–„â–ƒâ–„â–„â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–
wandb:         train/mil_loss â–ˆâ–‡â–†â–…â–†â–†â–‡â–„â–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–„â–‚â–â–‚â–„â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–‡â–†â–â–„â–†â–‚â–„â–ƒâ–„â–ˆâ–ˆâ–…â–„â–ƒâ–†â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–†â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–ƒâ–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91909
wandb: best/eval_avg_mil_loss 0.29756
wandb:  best/eval_ensemble_f1 0.91909
wandb:            eval/avg_f1 0.82473
wandb:      eval/avg_mil_loss 0.42887
wandb:       eval/ensemble_f1 0.82473
wandb:           train/avg_f1 0.81369
wandb:      train/ensemble_f1 0.81369
wandb:         train/mil_loss 0.17194
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run winter-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ma49iy7w
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074528-ma49iy7w/logs
wandb: ERROR Run ma49iy7w errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zjni8k2u with config:
wandb: 	actor_learning_rate: 1.8360880672692e-05
wandb: 	attention_dropout_p: 0.3841703588112641
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3559233546546765
wandb: 	temperature: 9.214791006264974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074742-zjni8k2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjni8k2u
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–â–ˆâ–†â–†â–…â–…â–„â–ˆâ–…â–‡â–†â–…â–‚â–…â–‡â–„â–†â–…â–…â–ƒâ–†â–„â–…â–ƒâ–„â–…â–…â–…â–„â–…â–‚â–…â–‚â–†â–„â–‡â–‚â–…
wandb:      eval/avg_mil_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–„â–â–ƒâ–‚â–‚â–â–…â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–†â–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–„â–‡â–„â–ƒ
wandb:       eval/ensemble_f1 â–‚â–†â–‡â–†â–‡â–…â–…â–ˆâ–„â–†â–…â–…â–‚â–…â–„â–ƒâ–„â–†â–†â–…â–†â–‚â–…â–†â–‡â–…â–…â–†â–â–…â–â–ƒâ–…â–†â–„â–‚â–ˆâ–ƒâ–â–‚
wandb:           train/avg_f1 â–…â–„â–ˆâ–‡â–†â–†â–ƒâ–†â–†â–†â–†â–†â–…â–„â–„â–ƒâ–„â–„â–…â–†â–…â–„â–„â–†â–„â–ƒâ–‡â–„â–…â–â–„â–„â–„â–„â–„â–„â–‚â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–†â–…â–…â–‡â–„â–†â–†â–†â–‡â–†â–„â–†â–†â–‡â–†â–…â–…â–„â–ˆâ–†â–…â–‡â–…â–†â–…â–‚â–ƒâ–…â–â–„â–„â–†â–…â–„â–†â–„â–ƒâ–ƒâ–†â–„
wandb:         train/mil_loss â–†â–ˆâ–†â–…â–„â–…â–…â–ƒâ–‚â–„â–„â–†â–„â–„â–…â–…â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–…â–…â–‚â–ƒâ–‚â–„â–„â–‚â–â–‚â–â–‚â–ƒâ–â–‚â–‚â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90742
wandb: best/eval_avg_mil_loss 0.32951
wandb:  best/eval_ensemble_f1 0.90742
wandb:            eval/avg_f1 0.86836
wandb:      eval/avg_mil_loss 0.50663
wandb:       eval/ensemble_f1 0.86836
wandb:           train/avg_f1 0.85571
wandb:      train/ensemble_f1 0.85571
wandb:         train/mil_loss 0.30158
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run likely-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjni8k2u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074742-zjni8k2u/logs
wandb: ERROR Run zjni8k2u errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1rnxe956 with config:
wandb: 	actor_learning_rate: 1.0265087510324368e-06
wandb: 	attention_dropout_p: 0.1515235263317119
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45166847152659995
wandb: 	temperature: 5.418478471437767
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074936-1rnxe956
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rnxe956
wandb: uploading history steps 52-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–†â–„â–†â–†â–ƒâ–ˆâ–ƒâ–ˆâ–…â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–‡â–…â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–…â–„â–‡â–ˆâ–†â–…â–…â–ˆâ–†â–‚â–„â–â–†â–…
wandb:      eval/avg_mil_loss â–„â–‚â–„â–„â–„â–ƒâ–ˆâ–…â–…â–…â–„â–„â–„â–†â–„â–ƒâ–…â–„â–ƒâ–„â–„â–„â–…â–‚â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–‚â–„â–„â–…â–â–„
wandb:       eval/ensemble_f1 â–…â–„â–†â–„â–‚â–†â–ƒâ–ˆâ–„â–ƒâ–…â–…â–„â–ƒâ–…â–„â–‚â–‡â–…â–‚â–‚â–ƒâ–…â–…â–…â–…â–„â–„â–‡â–…â–†â–„â–…â–…â–ˆâ–â–…â–„â–‡â–„
wandb:           train/avg_f1 â–„â–â–ƒâ–ƒâ–„â–ƒâ–…â–†â–„â–†â–…â–ƒâ–â–†â–…â–†â–ƒâ–‡â–†â–ˆâ–ƒâ–…â–…â–‡â–‡â–…â–„â–‡â–‡â–„â–…â–…â–†â–†â–†â–ƒâ–ˆâ–ˆâ–„â–†
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–„â–„â–†â–â–†â–…â–†â–…â–ƒâ–â–†â–…â–†â–„â–†â–ˆâ–…â–…â–…â–…â–ƒâ–‡â–…â–…â–„â–‡â–‡â–…â–…â–…â–…â–‡â–†â–‡â–ƒâ–ˆâ–…
wandb:         train/mil_loss â–ƒâ–…â–ƒâ–†â–†â–ƒâ–„â–ˆâ–ƒâ–…â–„â–†â–„â–â–„â–…â–…â–ƒâ–…â–ƒâ–„â–ƒâ–†â–‚â–†â–†â–ƒâ–„â–…â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‡â–
wandb:      train/policy_loss â–…â–…â–…â–…â–‚â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–…â–„â–…â–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91556
wandb: best/eval_avg_mil_loss 0.35772
wandb:  best/eval_ensemble_f1 0.91556
wandb:            eval/avg_f1 0.8888
wandb:      eval/avg_mil_loss 0.29413
wandb:       eval/ensemble_f1 0.8888
wandb:           train/avg_f1 0.89041
wandb:      train/ensemble_f1 0.89041
wandb:         train/mil_loss 3.93205
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rnxe956
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074936-1rnxe956/logs
wandb: ERROR Run 1rnxe956 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 6hrdjcq0 with config:
wandb: 	actor_learning_rate: 0.00024159212154294333
wandb: 	attention_dropout_p: 0.3105003500734307
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7347681583429799
wandb: 	temperature: 9.049495612147725
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075038-6hrdjcq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6hrdjcq0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–„â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–…â–‡â–ƒâ–ˆâ–†â–‚â–…â–…â–…â–ˆâ–ƒâ–…â–…â–†â–†â–ƒâ–…â–…â–†â–ƒâ–„â–ƒâ–‚â–â–‚â–†â–„â–…â–ˆâ–†â–…â–†â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒ
wandb:      eval/avg_mil_loss â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–â–ƒâ–‚â–â–‚â–‚â–â–â–‚â–â–ˆâ–â–ƒâ–‚â–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–ƒâ–…â–‡â–ƒâ–†â–‚â–…â–…â–†â–‡â–†â–ˆâ–ƒâ–…â–†â–‡â–†â–†â–†â–…â–…â–ƒâ–„â–ƒâ–†â–ƒâ–â–‚â–…â–„â–ˆâ–†â–…â–‚â–ƒâ–†â–…â–ƒâ–‚
wandb:           train/avg_f1 â–ˆâ–„â–…â–…â–…â–…â–ƒâ–ƒâ–…â–‚â–†â–…â–„â–…â–„â–â–…â–‚â–…â–…â–‚â–…â–„â–â–„â–„â–ƒâ–‚â–‚â–ƒâ–„â–â–ƒâ–‚â–‚â–„â–„â–‚â–„â–…
wandb:      train/ensemble_f1 â–ˆâ–„â–…â–†â–„â–†â–…â–†â–…â–†â–†â–†â–ƒâ–ƒâ–†â–†â–ƒâ–„â–†â–†â–†â–ƒâ–…â–„â–„â–„â–„â–ƒâ–„â–…â–…â–…â–ƒâ–…â–„â–ƒâ–…â–„â–…â–
wandb:         train/mil_loss â–†â–‡â–ˆâ–…â–‡â–†â–‡â–†â–ˆâ–„â–„â–„â–†â–„â–†â–‚â–„â–„â–…â–‡â–…â–…â–‡â–ƒâ–„â–„â–‡â–†â–ƒâ–ƒâ–‚â–„â–„â–‡â–â–„â–…â–…â–ƒâ–„
wandb:      train/policy_loss â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9338
wandb: best/eval_avg_mil_loss 0.28648
wandb:  best/eval_ensemble_f1 0.9338
wandb:            eval/avg_f1 0.87898
wandb:      eval/avg_mil_loss 0.3112
wandb:       eval/ensemble_f1 0.87898
wandb:           train/avg_f1 0.86711
wandb:      train/ensemble_f1 0.86711
wandb:         train/mil_loss 0.22222
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comfy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6hrdjcq0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075038-6hrdjcq0/logs
wandb: ERROR Run 6hrdjcq0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: c49m8h3g with config:
wandb: 	actor_learning_rate: 5.163446152079088e-06
wandb: 	attention_dropout_p: 0.14364625633252937
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9105618952559122
wandb: 	temperature: 6.182958862244904
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075135-c49m8h3g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c49m8h3g
wandb: uploading history steps 87-97, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–…â–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–ˆâ–‡â–†â–ˆâ–‡â–†â–…â–‡â–…â–ƒâ–‡â–„â–„â–‚â–†â–‡â–ˆâ–„â–„â–‡â–‚â–…â–†â–†â–‚â–„â–„â–‡â–‚â–â–…â–‡â–‡â–ƒâ–…â–†â–ˆâ–„
wandb:      eval/avg_mil_loss â–…â–„â–…â–…â–â–…â–…â–‚â–„â–†â–…â–ˆâ–…â–†â–„â–„â–„â–†â–…â–„â–†â–†â–†â–„â–ˆâ–„â–…â–„â–…â–„â–†â–‚â–…â–†â–ˆâ–…â–†â–‡â–„â–„
wandb:       eval/ensemble_f1 â–„â–â–„â–‡â–†â–†â–ˆâ–ƒâ–„â–‡â–†â–…â–‡â–…â–…â–†â–„â–„â–‚â–„â–…â–„â–„â–ƒâ–ˆâ–†â–†â–…â–…â–‚â–ˆâ–†â–†â–†â–‚â–†â–…â–†â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ˆâ–†â–ƒâ–…â–ˆâ–„â–„â–„â–„â–„â–…â–†â–â–‡â–â–„â–†â–†â–„â–„â–„â–â–„â–…â–…â–ƒâ–†â–…â–„â–„â–ƒâ–…â–†â–‚â–„â–‚â–†â–…â–
wandb:      train/ensemble_f1 â–„â–„â–ˆâ–ˆâ–‚â–ƒâ–†â–„â–„â–†â–‚â–„â–ƒâ–…â–†â–‡â–†â–…â–†â–„â–„â–†â–ƒâ–‚â–„â–„â–ƒâ–„â–…â–ƒâ–†â–‚â–ƒâ–â–‚â–‡â–†â–…â–„â–„
wandb:         train/mil_loss â–„â–„â–‡â–…â–…â–…â–…â–„â–…â–‡â–†â–ˆâ–…â–…â–†â–†â–‡â–‡â–ƒâ–†â–‡â–„â–ƒâ–„â–ˆâ–„â–‡â–„â–…â–‡â–†â–†â–ˆâ–â–…â–…â–†â–‡â–…â–„
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–ˆâ–â–â–„â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93388
wandb: best/eval_avg_mil_loss 0.20448
wandb:  best/eval_ensemble_f1 0.93388
wandb:            eval/avg_f1 0.89726
wandb:      eval/avg_mil_loss 0.25635
wandb:       eval/ensemble_f1 0.89726
wandb:            test/avg_f1 0.87982
wandb:      test/avg_mil_loss 0.23937
wandb:       test/ensemble_f1 0.87982
wandb:           train/avg_f1 0.89355
wandb:      train/ensemble_f1 0.89355
wandb:         train/mil_loss 0.21925
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run expert-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c49m8h3g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075135-c49m8h3g/logs
wandb: Agent Starting Run: u7agdamg with config:
wandb: 	actor_learning_rate: 1.1959183244652544e-05
wandb: 	attention_dropout_p: 0.04780036694713197
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7595650062012105
wandb: 	temperature: 7.8717581850388765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075309-u7agdamg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7agdamg
wandb: uploading wandb-summary.json
wandb: uploading history steps 164-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–†â–…â–ƒâ–„â–„â–„â–„â–‡â–ƒâ–†â–…â–ˆâ–ƒâ–†â–†â–„â–…â–†â–†â–…â–„â–„â–†â–„â–„â–ˆâ–†â–…â–â–„â–‡â–ƒâ–†â–â–„â–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–„â–‚â–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–„â–„â–â–„â–ƒâ–ƒâ–ƒâ–†â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–„â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–…â–…â–â–ƒâ–ƒâ–†â–‚â–…â–ƒâ–ƒâ–†â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–ƒâ–„â–‚â–†â–‚â–†â–ƒâ–‚â–„â–†â–ƒâ–…â–â–ˆâ–…â–ƒâ–â–…â–‚â–ƒâ–ƒ
wandb:           train/avg_f1 â–â–ˆâ–„â–‚â–„â–„â–ƒâ–†â–„â–„â–„â–‡â–„â–‡â–†â–†â–…â–â–†â–‡â–‡â–†â–ƒâ–ƒâ–‡â–†â–„â–„â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–†â–‡â–„â–ƒ
wandb:      train/ensemble_f1 â–…â–…â–‡â–…â–‚â–†â–‚â–†â–‚â–‚â–…â–„â–„â–ƒâ–…â–â–„â–†â–„â–…â–†â–‡â–„â–„â–ƒâ–„â–…â–ƒâ–„â–†â–â–ƒâ–‚â–„â–†â–…â–ˆâ–„â–‡â–†
wandb:         train/mil_loss â–â–‚â–„â–ˆâ–ˆâ–„â–…â–†â–ƒâ–…â–„â–‚â–ƒâ–„â–„â–‚â–…â–…â–ƒâ–…â–…â–‡â–‚â–„â–ƒâ–…â–†â–…â–†â–‚â–†â–†â–ƒâ–…â–„â–„â–ƒâ–ƒâ–…â–ƒ
wandb:      train/policy_loss â–„â–„â–â–„â–„â–ˆâ–„â–„â–â–â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–ˆâ–â–â–„â–ˆâ–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93371
wandb: best/eval_avg_mil_loss 0.30572
wandb:  best/eval_ensemble_f1 0.93371
wandb:            eval/avg_f1 0.88619
wandb:      eval/avg_mil_loss 0.255
wandb:       eval/ensemble_f1 0.88619
wandb:           train/avg_f1 0.88389
wandb:      train/ensemble_f1 0.88389
wandb:         train/mil_loss 0.23624
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run unique-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7agdamg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075309-u7agdamg/logs
wandb: ERROR Run u7agdamg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l327x5nz with config:
wandb: 	actor_learning_rate: 3.4889928334881583e-06
wandb: 	attention_dropout_p: 0.08102055437813377
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6942688807539016
wandb: 	temperature: 5.8690513955521
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075539-l327x5nz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l327x5nz
wandb: uploading history steps 99-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–…â–„â–‡â–†â–†â–‡â–‚â–„â–‡â–ˆâ–‡â–…â–†â–…â–†â–…â–†â–„â–„â–„â–ˆâ–‚â–„â–…â–†â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–…â–â–…â–‚â–…â–ƒâ–„â–‚â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–…â–‚â–ƒâ–‚â–„â–†â–ƒâ–„â–‚â–…â–‚â–ƒâ–†â–„â–„â–ƒâ–ƒâ–†â–ƒâ–…â–ˆâ–â–„â–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–„â–†â–†â–‚â–„â–†â–‡â–ˆâ–‡â–„â–†â–†â–„â–‚â–†â–‚â–†â–„â–†â–‡â–ˆâ–„â–†â–…â–ƒâ–‡â–â–„â–ƒâ–„â–†â–ƒâ–„â–…â–â–†â–…â–ƒâ–ƒ
wandb:           train/avg_f1 â–…â–„â–‡â–‡â–‡â–ˆâ–†â–†â–†â–ˆâ–†â–†â–„â–„â–„â–…â–†â–ƒâ–‚â–…â–ƒâ–„â–„â–„â–ƒâ–‚â–†â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–ƒâ–
wandb:      train/ensemble_f1 â–…â–…â–ˆâ–ˆâ–†â–†â–ˆâ–ˆâ–‡â–…â–†â–‡â–…â–†â–†â–†â–‡â–ˆâ–‡â–‡â–ƒâ–…â–…â–„â–†â–†â–…â–ƒâ–â–„â–…â–„â–…â–†â–‚â–…â–â–‚â–„â–ƒ
wandb:         train/mil_loss â–†â–…â–…â–‡â–…â–†â–†â–…â–…â–ˆâ–†â–„â–…â–†â–…â–…â–†â–…â–…â–‡â–„â–…â–…â–ƒâ–„â–†â–…â–„â–…â–ƒâ–„â–„â–‚â–„â–„â–„â–â–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–ƒâ–…â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89602
wandb: best/eval_avg_mil_loss 0.32868
wandb:  best/eval_ensemble_f1 0.89602
wandb:            eval/avg_f1 0.84765
wandb:      eval/avg_mil_loss 0.39467
wandb:       eval/ensemble_f1 0.84765
wandb:           train/avg_f1 0.8349
wandb:      train/ensemble_f1 0.8349
wandb:         train/mil_loss 1.75371
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l327x5nz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075539-l327x5nz/logs
wandb: ERROR Run l327x5nz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: csckbe4v with config:
wandb: 	actor_learning_rate: 1.0231043846545432e-05
wandb: 	attention_dropout_p: 0.1375362705760509
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03699301814173939
wandb: 	temperature: 2.3634283025282965
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075748-csckbe4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csckbe4v
wandb: uploading history steps 100-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‚â–…â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‡â–‡â–„â–ˆâ–‡â–ˆâ–†â–…â–…â–‡â–ˆâ–„â–†â–ƒâ–…â–‡â–…â–ƒâ–„â–„â–†â–‚â–‚â–‚â–‡â–…â–â–ƒâ–„â–ˆâ–‡â–‚â–â–‚â–…â–…â–„â–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ˆâ–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–…â–„â–‚â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–‡â–ƒâ–†â–‡â–‚â–†â–…â–†â–ƒâ–†â–„â–†â–ƒâ–‚â–„â–‡â–†â–„â–â–…â–‚â–‚â–†â–ƒâ–†â–…â–ˆâ–ƒâ–ƒâ–ƒâ–â–„â–â–…â–„â–…â–ƒâ–…
wandb:           train/avg_f1 â–…â–…â–…â–†â–‡â–‡â–ƒâ–ˆâ–†â–„â–ƒâ–„â–†â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–„â–„â–‚â–„â–„â–…â–â–â–â–„â–ƒâ–ƒâ–„â–ƒâ–…â–…â–ƒâ–â–‚
wandb:      train/ensemble_f1 â–†â–…â–†â–‡â–†â–†â–†â–†â–…â–ƒâ–†â–ˆâ–„â–…â–„â–‡â–ƒâ–‚â–„â–ƒâ–†â–ƒâ–†â–‚â–„â–…â–…â–…â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–„â–…â–‚â–â–„â–‚
wandb:         train/mil_loss â–†â–†â–†â–†â–…â–‡â–…â–„â–‡â–†â–‡â–†â–†â–†â–†â–…â–„â–‡â–â–„â–†â–…â–…â–…â–„â–…â–‡â–„â–ˆâ–ƒâ–…â–ˆâ–…â–…â–„â–ƒâ–…â–„â–†â–‡
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–ƒâ–„â–„â–„â–ƒâ–„â–†â–„â–„â–„â–„â–„â–â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ƒâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–…â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93025
wandb: best/eval_avg_mil_loss 0.21926
wandb:  best/eval_ensemble_f1 0.93025
wandb:            eval/avg_f1 0.89392
wandb:      eval/avg_mil_loss 0.36661
wandb:       eval/ensemble_f1 0.89392
wandb:           train/avg_f1 0.87333
wandb:      train/ensemble_f1 0.87333
wandb:         train/mil_loss 0.29462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wobbly-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csckbe4v
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075748-csckbe4v/logs
wandb: ERROR Run csckbe4v errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9mslo9yi with config:
wandb: 	actor_learning_rate: 4.769084477296948e-06
wandb: 	attention_dropout_p: 0.4277505181782555
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6234425573274751
wandb: 	temperature: 5.663839814677289
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075936-9mslo9yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mslo9yi
wandb: uploading history steps 101-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–‚â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–†â–ˆâ–‚â–‡â–ˆâ–…â–ˆâ–†â–‡â–†â–†â–…â–‡â–„â–„â–‡â–…â–ˆâ–„â–†â–‡â–‡â–‡â–…â–…â–ƒâ–†â–…â–„â–…â–ƒâ–†â–‚â–„â–â–‡â–
wandb:      eval/avg_mil_loss â–‚â–ƒâ–„â–â–„â–‚â–ƒâ–‚â–„â–â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–„â–ƒâ–„â–ƒâ–„â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–†â–„â–ƒâ–‚â–†â–„â–…â–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–‡â–…â–†â–„â–ˆâ–†â–‡â–…â–ƒâ–†â–†â–…â–‡â–…â–†â–ƒâ–…â–‡â–…â–‚â–‡â–ƒâ–‡â–â–…â–…â–„â–…â–‚â–„â–‚â–†â–ƒâ–‚â–â–ƒâ–†â–†â–…â–ƒ
wandb:           train/avg_f1 â–…â–†â–ˆâ–†â–„â–…â–…â–ƒâ–„â–„â–‡â–ˆâ–‡â–…â–†â–†â–†â–„â–†â–‚â–„â–†â–„â–†â–„â–„â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–„â–…â–„â–â–ƒâ–ƒâ–„
wandb:      train/ensemble_f1 â–†â–†â–ˆâ–ˆâ–†â–ˆâ–…â–†â–…â–†â–†â–„â–…â–…â–…â–…â–†â–„â–ƒâ–„â–„â–†â–…â–…â–„â–„â–ƒâ–†â–‚â–„â–…â–â–ƒâ–ƒâ–„â–„â–„â–„â–…â–„
wandb:         train/mil_loss â–†â–„â–†â–†â–ƒâ–†â–…â–†â–†â–‡â–†â–…â–ˆâ–ˆâ–†â–„â–…â–‡â–†â–‡â–ƒâ–†â–‚â–…â–„â–„â–‡â–„â–„â–„â–†â–…â–ƒâ–„â–†â–ƒâ–ƒâ–…â–â–…
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83342
wandb: best/eval_avg_mil_loss 0.66588
wandb:  best/eval_ensemble_f1 0.83342
wandb:            eval/avg_f1 0.71405
wandb:      eval/avg_mil_loss 1.21735
wandb:       eval/ensemble_f1 0.71405
wandb:           train/avg_f1 0.76438
wandb:      train/ensemble_f1 0.76438
wandb:         train/mil_loss 2.71517
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mslo9yi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075936-9mslo9yi/logs
wandb: ERROR Run 9mslo9yi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: a1uuqwkr with config:
wandb: 	actor_learning_rate: 2.241385889543854e-06
wandb: 	attention_dropout_p: 0.18330529962029157
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8448712984326538
wandb: 	temperature: 5.712022849702002
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080126-a1uuqwkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a1uuqwkr
wandb: uploading wandb-summary.json; uploading config.yaml; uploading history steps 65-80, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–…â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–…â–‚â–â–â–â–ˆâ–ƒâ–‚â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–…â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–…â–…â–â–†â–†â–„â–‡â–„â–ˆâ–‡â–…â–‡â–ˆâ–ˆâ–…â–…â–…â–…â–‡â–†â–„â–…â–‡â–ˆâ–…â–‡â–‡â–…â–‡â–†â–…â–†â–…â–‡â–„â–‡â–…â–‡â–‡
wandb:      eval/avg_mil_loss â–„â–…â–„â–…â–â–ƒâ–â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–„â–‡â–‚â–ƒâ–„â–‚â–ƒâ–‚â–„â–‡â–â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–„â–â–†â–ƒâ–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–â–…â–…â–â–„â–†â–„â–‡â–ˆâ–„â–…â–†â–…â–…â–‡â–ƒâ–‡â–…â–„â–‡â–ˆâ–„â–…â–†â–‡â–…â–‡â–‡â–…â–…â–‡â–‡â–‡â–…â–‡â–‡â–†â–„â–‡
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–‚â–†â–â–ƒâ–„â–†â–„â–ƒâ–…â–ƒâ–†â–…â–…â–„â–ƒâ–‚â–…â–ƒâ–‚â–â–ƒâ–„â–„â–â–„â–†â–ƒâ–‡â–‚â–‡â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–„
wandb:      train/ensemble_f1 â–…â–†â–„â–‡â–ƒâ–ƒâ–‚â–„â–…â–‡â–†â–„â–‡â–†â–…â–†â–…â–ƒâ–„â–ƒâ–‚â–„â–…â–â–…â–‡â–„â–„â–„â–ˆâ–ˆâ–‡â–„â–„â–…â–„â–„â–…â–†â–…
wandb:         train/mil_loss â–ˆâ–‡â–ƒâ–ˆâ–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–†â–ƒâ–„â–â–â–‚â–„â–‚â–„â–†â–…â–„â–â–„â–„â–â–„â–â–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–‚â–‚â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.26182
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.91161
wandb:      eval/avg_mil_loss 0.23895
wandb:       eval/ensemble_f1 0.91161
wandb:           train/avg_f1 0.88902
wandb:      train/ensemble_f1 0.88902
wandb:         train/mil_loss 0.53096
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run crimson-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a1uuqwkr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080126-a1uuqwkr/logs
wandb: ERROR Run a1uuqwkr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4lj4vnol with config:
wandb: 	actor_learning_rate: 0.00011288051337670984
wandb: 	attention_dropout_p: 0.4399087243074741
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9488872545836176
wandb: 	temperature: 7.1835467324155475
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080257-4lj4vnol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lj4vnol
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 105-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–…â–†â–‡â–†â–„â–„â–…â–„â–†â–†â–ƒâ–…â–„â–…â–…â–ƒâ–…â–ƒâ–„â–†â–ƒâ–†â–†â–…â–†â–„â–„â–„â–ƒâ–…â–†â–„â–…â–…â–†â–ƒâ–â–‡
wandb:      eval/avg_mil_loss â–‚â–‚â–‚â–â–ƒâ–â–„â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–†â–„â–ƒâ–…â–„â–…â–†â–„â–‚â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–ˆâ–†â–†â–†â–†â–ˆâ–„â–„â–…â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–†â–…â–…â–„â–…â–„â–„â–…â–ƒâ–„â–ƒâ–„â–„â–…â–„â–ƒâ–â–â–†
wandb:           train/avg_f1 â–ˆâ–‡â–ˆâ–ˆâ–„â–ˆâ–…â–‡â–…â–…â–…â–†â–†â–‡â–†â–†â–†â–ƒâ–…â–…â–„â–…â–„â–ƒâ–…â–â–‡â–ƒâ–„â–…â–„â–ƒâ–„â–…â–ƒâ–ƒâ–„â–ƒâ–…â–†
wandb:      train/ensemble_f1 â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–„â–‡â–…â–…â–‡â–…â–‡â–†â–„â–„â–…â–„â–…â–…â–„â–‡â–…â–â–„â–‡â–…â–„â–…â–„â–…â–†â–„â–…â–„â–„â–…â–…â–ƒ
wandb:         train/mil_loss â–…â–ˆâ–ˆâ–‡â–‚â–†â–„â–…â–ƒâ–„â–…â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–†â–„â–„â–ƒâ–„â–…â–…â–…â–„â–„â–ƒâ–â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–…â–„â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9409
wandb: best/eval_avg_mil_loss 0.19598
wandb:  best/eval_ensemble_f1 0.9409
wandb:            eval/avg_f1 0.91565
wandb:      eval/avg_mil_loss 0.27917
wandb:       eval/ensemble_f1 0.91565
wandb:           train/avg_f1 0.88032
wandb:      train/ensemble_f1 0.88032
wandb:         train/mil_loss 0.20693
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stellar-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lj4vnol
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080257-4lj4vnol/logs
wandb: ERROR Run 4lj4vnol errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: duymtic8 with config:
wandb: 	actor_learning_rate: 1.057110108488449e-06
wandb: 	attention_dropout_p: 0.11353752592398592
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2448840851612648
wandb: 	temperature: 9.835440827727195
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080435-duymtic8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/duymtic8
wandb: uploading wandb-summary.json
wandb: uploading history steps 107-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–â–…â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–…â–…â–†â–‡â–‡â–†â–…â–†â–„â–†â–‡â–ƒâ–‡â–‡â–„â–…â–…â–†â–‚â–„â–‡â–„â–ƒâ–†â–‚â–‡â–†â–ˆâ–ƒâ–ƒâ–‡â–„â–ˆâ–„â–‚â–â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–ˆâ–…â–…â–ƒâ–ƒâ–…â–…â–„â–„â–‚â–†â–‚â–…â–‡â–ƒâ–ƒâ–†â–†â–†â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–ƒâ–„â–â–ƒâ–ˆâ–ƒâ–…â–ƒâ–…
wandb:       eval/ensemble_f1 â–‡â–†â–…â–ƒâ–†â–‡â–†â–†â–„â–…â–„â–†â–ˆâ–…â–‡â–ˆâ–„â–„â–‡â–…â–„â–„â–„â–…â–‡â–…â–†â–â–†â–‚â–„â–…â–„â–…â–ˆâ–‡â–†â–…â–‚â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–„â–‡â–‡â–…â–†â–ƒâ–†â–†â–†â–†â–†â–…â–†â–„â–†â–†â–‡â–†â–ˆâ–…â–…â–†â–…â–ƒâ–â–â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–…â–‚â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–‡â–‡â–…â–‡â–†â–…â–†â–‡â–†â–‡â–†â–†â–†â–‡â–ˆâ–†â–…â–‡â–‡â–‡â–„â–„â–‚â–…â–„â–…â–„â–„â–‚â–„â–„â–„â–„â–…â–„â–†â–â–…â–„â–ƒ
wandb:         train/mil_loss â–„â–ˆâ–„â–ƒâ–…â–†â–‚â–…â–„â–†â–†â–„â–‚â–†â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–„â–ƒâ–„â–„â–â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–†â–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–…â–â–†â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93007
wandb: best/eval_avg_mil_loss 0.26254
wandb:  best/eval_ensemble_f1 0.93007
wandb:            eval/avg_f1 0.90088
wandb:      eval/avg_mil_loss 0.22565
wandb:       eval/ensemble_f1 0.90088
wandb:            test/avg_f1 0.88373
wandb:      test/avg_mil_loss 0.20386
wandb:       test/ensemble_f1 0.88373
wandb:           train/avg_f1 0.89314
wandb:      train/ensemble_f1 0.89314
wandb:         train/mil_loss 0.19955
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run spring-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/duymtic8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080435-duymtic8/logs
wandb: Agent Starting Run: 3qe72njo with config:
wandb: 	actor_learning_rate: 2.3722380584229744e-05
wandb: 	attention_dropout_p: 0.3979634680462585
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40900176991949544
wandb: 	temperature: 9.007204900136744
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080623-3qe72njo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3qe72njo
wandb: uploading wandb-summary.json
wandb: uploading history steps 106-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–‚â–‚â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–‚â–â–â–„â–ƒâ–‚â–‚â–†â–„â–ƒâ–‚â–‚â–„â–†â–ƒâ–†â–…â–ƒâ–„â–ƒâ–„â–…â–„â–„â–‡â–„â–„â–†â–…â–„â–…â–…â–ˆâ–…â–„â–…â–…â–ƒ
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–‚â–‚â–‡â–†â–‚â–ˆâ–‚â–‚â–ƒâ–…â–„â–ƒâ–‚â–†â–‚â–‚â–‚â–ƒâ–„â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–†â–‚â–„â–ƒâ–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–„â–‚â–†â–â–…â–„â–ƒâ–†â–ƒâ–ˆâ–…â–„â–„â–…â–†â–…â–…â–†â–ˆâ–†â–„â–†â–…â–‡â–‡â–‡â–†â–…â–…â–‡â–†â–ˆâ–‡â–‡â–‡â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–„â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–‚â–„â–ƒâ–„â–„â–„â–„â–„â–…â–„â–„â–†â–„â–‡â–„â–…â–†â–…â–ƒâ–…â–†â–‡â–ˆâ–†â–‡â–‡â–†â–ˆ
wandb:      train/ensemble_f1 â–„â–ƒâ–â–„â–â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–„â–…â–„â–†â–„â–…â–…â–…â–…â–…â–†â–†â–…â–…â–…â–‡â–…â–…â–…â–ˆâ–…â–ˆâ–ˆâ–‡â–…â–†
wandb:         train/mil_loss â–…â–„â–†â–…â–†â–†â–…â–‡â–„â–…â–„â–…â–†â–ˆâ–†â–„â–‡â–‡â–‡â–†â–„â–†â–†â–ƒâ–†â–‡â–„â–„â–ˆâ–ƒâ–„â–ƒâ–â–„â–†â–„â–ƒâ–†â–†â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–ƒâ–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90116
wandb: best/eval_avg_mil_loss 0.35313
wandb:  best/eval_ensemble_f1 0.90116
wandb:            eval/avg_f1 0.83576
wandb:      eval/avg_mil_loss 0.50874
wandb:       eval/ensemble_f1 0.83576
wandb:            test/avg_f1 0.85472
wandb:      test/avg_mil_loss 0.3201
wandb:       test/ensemble_f1 0.85472
wandb:           train/avg_f1 0.84579
wandb:      train/ensemble_f1 0.84579
wandb:         train/mil_loss 5.43115
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run iconic-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3qe72njo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080623-3qe72njo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w8iigotb with config:
wandb: 	actor_learning_rate: 1.547796455533775e-05
wandb: 	attention_dropout_p: 0.29830784362446794
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28029420299295227
wandb: 	temperature: 9.44676458713263
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080823-w8iigotb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8iigotb
wandb: uploading wandb-summary.json
wandb: uploading history steps 89-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ˆâ–†â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–…â–„â–†â–…â–…â–‚â–…â–ˆâ–ƒâ–…â–†â–„â–…â–â–‚â–ƒâ–‚â–‚â–†â–ƒâ–ƒâ–ƒâ–†â–…â–â–„â–‚â–„â–â–„â–…â–ˆâ–ƒâ–†â–„â–ƒâ–‡â–…
wandb:      eval/avg_mil_loss â–„â–„â–„â–…â–†â–ƒâ–ƒâ–…â–‚â–‡â–„â–‡â–â–ƒâ–„â–…â–…â–ˆâ–†â–ˆâ–„â–†â–ƒâ–„â–…â–‚â–‡â–‚â–„â–‡â–ƒâ–„â–„â–‚â–…â–†â–„â–â–†â–ƒ
wandb:       eval/ensemble_f1 â–„â–†â–…â–‡â–†â–‚â–†â–â–‡â–…â–†â–‚â–â–…â–ˆâ–…â–…â–ƒâ–„â–‡â–‡â–‡â–‚â–‚â–â–„â–„â–‚â–„â–…â–…â–†â–‡â–†â–…â–ƒâ–ˆâ–â–ƒâ–†
wandb:           train/avg_f1 â–‡â–…â–…â–…â–…â–…â–†â–ƒâ–…â–ˆâ–ƒâ–„â–†â–ƒâ–„â–„â–„â–†â–†â–…â–„â–…â–ƒâ–„â–…â–…â–„â–…â–ƒâ–†â–…â–‚â–…â–ƒâ–ƒâ–„â–â–‚â–ƒâ–
wandb:      train/ensemble_f1 â–ˆâ–†â–†â–†â–†â–…â–…â–ˆâ–‡â–ƒâ–‡â–ƒâ–„â–„â–…â–†â–„â–…â–…â–…â–ƒâ–‡â–‡â–†â–„â–…â–†â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–„â–ƒâ–
wandb:         train/mil_loss â–…â–‡â–‡â–†â–‡â–…â–ˆâ–‡â–…â–„â–„â–†â–…â–…â–…â–†â–…â–„â–ƒâ–…â–‡â–„â–…â–…â–…â–‚â–‚â–…â–†â–„â–†â–‚â–ƒâ–…â–„â–„â–„â–…â–…â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–‡â–…â–â–…â–‚â–…â–…â–…â–†â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94115
wandb: best/eval_avg_mil_loss 0.18787
wandb:  best/eval_ensemble_f1 0.94115
wandb:            eval/avg_f1 0.91928
wandb:      eval/avg_mil_loss 0.24987
wandb:       eval/ensemble_f1 0.91928
wandb:           train/avg_f1 0.87943
wandb:      train/ensemble_f1 0.87943
wandb:         train/mil_loss 0.19083
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run radiant-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8iigotb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080823-w8iigotb/logs
wandb: ERROR Run w8iigotb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 15f4wj3l with config:
wandb: 	actor_learning_rate: 2.9231655203881635e-06
wandb: 	attention_dropout_p: 0.2037673010988607
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35656090810204233
wandb: 	temperature: 9.998191227050764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080956-15f4wj3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15f4wj3l
wandb: uploading wandb-summary.json
wandb: uploading history steps 107-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–†â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–ˆâ–‚â–…â–ƒâ–†â–…â–ˆâ–ƒâ–…â–„â–„â–ƒâ–†â–…â–„â–„â–‚â–ƒâ–â–‚â–ƒâ–†â–ƒâ–‚â–ƒâ–…â–‡â–ƒâ–‡â–„â–„â–â–‡â–…â–…â–„â–„â–†
wandb:      eval/avg_mil_loss â–ƒâ–â–†â–„â–ˆâ–ƒâ–„â–â–„â–†â–†â–‚â–ƒâ–ƒâ–‡â–‚â–…â–‚â–ƒâ–â–ˆâ–†â–„â–„â–â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–…â–„â–ƒâ–‡â–ˆâ–ƒâ–‚â–‡
wandb:       eval/ensemble_f1 â–…â–„â–ˆâ–†â–…â–…â–‡â–†â–ˆâ–†â–…â–„â–…â–†â–„â–„â–‚â–†â–‚â–…â–ƒâ–‚â–†â–‡â–‚â–…â–…â–‡â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–ˆâ–„â–â–„
wandb:           train/avg_f1 â–†â–…â–…â–†â–ˆâ–…â–†â–…â–â–†â–„â–ƒâ–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„â–„â–„â–‡â–†â–ƒâ–„â–‡â–‚â–…â–„â–„â–…â–„â–‚â–…â–…â–„â–
wandb:      train/ensemble_f1 â–‡â–„â–…â–„â–ˆâ–…â–…â–‡â–‡â–â–„â–†â–…â–†â–ƒâ–„â–†â–‡â–„â–‚â–…â–…â–†â–…â–ˆâ–…â–‚â–„â–ƒâ–…â–†â–†â–„â–†â–…â–‚â–ƒâ–†â–ƒâ–„
wandb:         train/mil_loss â–„â–†â–†â–ƒâ–†â–‡â–„â–„â–ˆâ–†â–„â–†â–†â–„â–‚â–†â–‡â–ƒâ–…â–‡â–„â–„â–„â–‡â–„â–‚â–‚â–†â–†â–…â–ƒâ–â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–
wandb:      train/policy_loss â–â–…â–…â–â–â–…â–â–…â–â–â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93032
wandb: best/eval_avg_mil_loss 0.19229
wandb:  best/eval_ensemble_f1 0.93032
wandb:            eval/avg_f1 0.89384
wandb:      eval/avg_mil_loss 0.37782
wandb:       eval/ensemble_f1 0.89384
wandb:           train/avg_f1 0.88493
wandb:      train/ensemble_f1 0.88493
wandb:         train/mil_loss 0.23017
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earthy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15f4wj3l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080956-15f4wj3l/logs
wandb: ERROR Run 15f4wj3l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xl43sblu with config:
wandb: 	actor_learning_rate: 0.00012154699673827924
wandb: 	attention_dropout_p: 0.34762685568222085
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6993289399847991
wandb: 	temperature: 0.4495953267505514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081145-xl43sblu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xl43sblu
wandb: uploading history steps 117-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–…
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–†â–ˆâ–„â–„â–…â–„â–…â–„â–…â–†â–â–†â–‚â–„â–„â–†â–†â–…â–…â–‚â–†â–…â–„â–ƒâ–†â–…â–„â–ƒâ–‚â–ƒâ–‡â–„â–„â–…â–…â–†â–†â–…
wandb:      eval/avg_mil_loss â–…â–‚â–‚â–‚â–ƒâ–‚â–‚â–ˆâ–†â–‚â–‡â–ƒâ–‚â–„â–‚â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–…â–â–„â–‚â–„â–ƒâ–„â–ƒâ–„â–…â–„â–„
wandb:       eval/ensemble_f1 â–â–‡â–ƒâ–…â–…â–„â–†â–„â–…â–†â–…â–„â–ƒâ–†â–…â–†â–‚â–ƒâ–†â–ˆâ–…â–†â–…â–†â–…â–…â–‚â–…â–†â–ƒâ–…â–ƒâ–†â–ƒâ–„â–†â–‡â–†â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–„â–†â–…â–„â–„â–ƒâ–…â–ƒâ–†â–…â–…â–ˆâ–„â–†â–…â–ˆâ–…â–…â–‡â–‚â–…â–†â–…â–‡â–â–…â–…â–†â–„â–„â–„â–‡â–…â–‚â–„â–…â–„â–†
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–„â–ƒâ–†â–„â–†â–ƒâ–†â–„â–†â–†â–†â–„â–†â–‡â–‡â–…â–‡â–†â–â–„â–…â–†â–…â–„â–…â–†â–„â–„â–ƒâ–ƒâ–‡â–ˆâ–†â–â–„â–ƒâ–†
wandb:         train/mil_loss â–†â–‚â–‡â–…â–â–ƒâ–…â–ƒâ–„â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–†â–…â–„â–ƒâ–‚â–…â–„â–ƒâ–„â–ˆâ–ˆâ–ƒâ–†â–…â–ƒâ–„â–„â–†â–ƒâ–ƒâ–…
wandb:      train/policy_loss â–ƒâ–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93351
wandb: best/eval_avg_mil_loss 0.3078
wandb:  best/eval_ensemble_f1 0.93351
wandb:            eval/avg_f1 0.90742
wandb:      eval/avg_mil_loss 0.25013
wandb:       eval/ensemble_f1 0.90742
wandb:            test/avg_f1 0.88211
wandb:      test/avg_mil_loss 0.2288
wandb:       test/ensemble_f1 0.88211
wandb:           train/avg_f1 0.89744
wandb:      train/ensemble_f1 0.89744
wandb:         train/mil_loss 0.2669
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vocal-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xl43sblu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081145-xl43sblu/logs
wandb: Agent Starting Run: vigpsszk with config:
wandb: 	actor_learning_rate: 3.675573215134836e-05
wandb: 	attention_dropout_p: 0.4824389073847605
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8770409373545949
wandb: 	temperature: 3.725094176454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081349-vigpsszk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vigpsszk
wandb: uploading history steps 85-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–â–„â–ˆâ–…
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–…â–†â–‡â–…â–†â–…â–…â–ˆâ–…â–…â–‡â–‡â–‡â–‡â–…â–†â–‡â–„â–„â–â–„â–†â–‚â–†â–†â–„â–„â–„â–„â–†â–„â–‚â–…â–„â–…â–„â–ˆâ–†â–‚
wandb:      eval/avg_mil_loss â–„â–„â–„â–…â–ƒâ–„â–„â–‚â–„â–„â–ƒâ–ƒâ–â–â–„â–ƒâ–„â–â–‚â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–ƒâ–…â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–…â–…â–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–†â–‡â–„â–†â–„â–…â–„â–…â–‡â–ˆâ–„â–…â–†â–†â–ƒâ–„â–…â–†â–ˆâ–ƒâ–…â–„â–ƒâ–‚â–…â–†â–ƒâ–‡â–†â–†â–‚â–„â–„â–â–‚â–…â–ƒâ–†â–ƒâ–‡
wandb:           train/avg_f1 â–ˆâ–†â–‡â–†â–…â–ˆâ–…â–„â–„â–†â–†â–†â–ƒâ–„â–„â–ˆâ–†â–†â–„â–†â–„â–„â–‚â–…â–…â–…â–â–…â–…â–„â–†â–„â–â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„
wandb:      train/ensemble_f1 â–„â–†â–‡â–…â–…â–†â–ˆâ–„â–…â–„â–„â–†â–†â–„â–ˆâ–„â–‚â–ƒâ–†â–†â–ƒâ–…â–‚â–…â–…â–†â–â–…â–‚â–„â–ƒâ–†â–„â–„â–„â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:         train/mil_loss â–ˆâ–„â–†â–…â–‡â–„â–„â–„â–†â–…â–†â–ƒâ–‚â–ƒâ–†â–…â–â–ƒâ–…â–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–„â–…â–‚â–â–ƒâ–„â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–
wandb:      train/policy_loss â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–ˆâ–„â–‚â–„â–„â–„â–„â–„â–â–†â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–…â–‡â–…â–…â–…â–…â–…â–…â–…â–â–…â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93371
wandb: best/eval_avg_mil_loss 0.26347
wandb:  best/eval_ensemble_f1 0.93371
wandb:            eval/avg_f1 0.87948
wandb:      eval/avg_mil_loss 0.26423
wandb:       eval/ensemble_f1 0.87948
wandb:           train/avg_f1 0.88766
wandb:      train/ensemble_f1 0.88766
wandb:         train/mil_loss 0.21799
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run playful-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vigpsszk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081349-vigpsszk/logs
wandb: ERROR Run vigpsszk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: uyiqmqcs with config:
wandb: 	actor_learning_rate: 6.070773767510106e-06
wandb: 	attention_dropout_p: 0.4326555870067055
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7283024637918067
wandb: 	temperature: 5.745938963917164
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081517-uyiqmqcs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uyiqmqcs
wandb: uploading history steps 100-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ƒâ–‡â–…â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‚â–†â–…â–†â–‚â–…â–…â–…â–„â–…â–…â–†â–…â–„â–â–„â–‚â–…
wandb:      eval/avg_mil_loss â–†â–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–ˆâ–†â–„â–ƒâ–…â–…â–‚
wandb:       eval/ensemble_f1 â–„â–†â–†â–†â–†â–‡â–†â–ˆâ–†â–…â–…â–‡â–†â–‡â–ƒâ–†â–†â–†â–†â–†â–†â–…â–‡â–„â–…â–…â–â–„â–†â–„â–‚â–†â–…â–†â–…â–…â–…â–ƒâ–…â–„
wandb:           train/avg_f1 â–†â–†â–…â–†â–†â–†â–†â–†â–…â–‡â–…â–„â–…â–‡â–ˆâ–„â–†â–ƒâ–†â–„â–†â–ƒâ–†â–ƒâ–„â–‚â–„â–„â–…â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–‚â–„â–„â–â–„
wandb:      train/ensemble_f1 â–„â–…â–…â–†â–†â–‡â–…â–…â–†â–…â–„â–…â–…â–†â–ˆâ–…â–…â–…â–„â–„â–„â–ƒâ–„â–…â–â–„â–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒ
wandb:         train/mil_loss â–ˆâ–ˆâ–„â–ˆâ–‡â–ƒâ–„â–†â–…â–ƒâ–†â–ƒâ–…â–â–†â–ƒâ–ƒâ–„â–…â–„â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–†â–„â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–…â–…â–„
wandb:      train/policy_loss â–ˆâ–†â–†â–†â–†â–†â–ƒâ–â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–†â–†â–‡â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ƒâ–…â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94108
wandb: best/eval_avg_mil_loss 0.18596
wandb:  best/eval_ensemble_f1 0.94108
wandb:            eval/avg_f1 0.9047
wandb:      eval/avg_mil_loss 0.24855
wandb:       eval/ensemble_f1 0.9047
wandb:           train/avg_f1 0.89132
wandb:      train/ensemble_f1 0.89132
wandb:         train/mil_loss 0.18372
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run firm-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uyiqmqcs
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081517-uyiqmqcs/logs
wandb: ERROR Run uyiqmqcs errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 2s16bi48 with config:
wandb: 	actor_learning_rate: 0.0004009646338173207
wandb: 	attention_dropout_p: 0.4574122657774131
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.870867891735003
wandb: 	temperature: 8.724381357253563
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081701-2s16bi48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s16bi48
wandb: uploading history steps 137-153, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–„â–‡â–…â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–†â–…â–…â–…â–ˆâ–„â–„â–†â–‡â–†â–…â–…â–ƒâ–…â–…â–„â–ƒâ–ˆâ–…â–â–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–â–ƒâ–…â–„â–‚â–‡â–…â–„â–…â–‡â–…â–‡â–ƒâ–ƒâ–ƒâ–†â–ƒâ–†â–â–†â–„â–„â–‚â–†â–…â–…â–ƒâ–„â–„â–ƒâ–…â–†â–ƒâ–†â–…â–‚â–„â–
wandb:       eval/ensemble_f1 â–„â–„â–„â–…â–‡â–ˆâ–†â–…â–‡â–‡â–‡â–…â–‡â–†â–‡â–†â–†â–†â–„â–†â–†â–†â–‚â–†â–…â–…â–ƒâ–‡â–ƒâ–†â–†â–…â–â–…â–†â–†â–†â–„â–…â–„
wandb:           train/avg_f1 â–ˆâ–†â–‡â–‡â–‡â–‡â–…â–„â–†â–†â–…â–†â–ˆâ–‡â–…â–†â–†â–…â–‡â–†â–„â–†â–†â–†â–„â–†â–ƒâ–„â–…â–„â–„â–†â–â–„â–„â–„â–„â–…â–ƒâ–
wandb:      train/ensemble_f1 â–ˆâ–‡â–‡â–…â–…â–†â–…â–…â–†â–‡â–…â–†â–‡â–‡â–„â–ˆâ–†â–ƒâ–…â–†â–ƒâ–…â–†â–…â–„â–„â–†â–…â–„â–ƒâ–ƒâ–†â–„â–…â–…â–„â–â–„â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–ˆâ–†â–ˆâ–…â–†â–†â–‡â–‡â–…â–ƒâ–…â–„â–„â–ˆâ–„â–†â–„â–†â–†â–„â–‚â–„â–„â–„â–â–„â–‚â–‚â–…â–‚â–„â–„â–„â–„â–ƒâ–‚â–‚â–…â–ƒ
wandb:      train/policy_loss â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94135
wandb: best/eval_avg_mil_loss 0.14486
wandb:  best/eval_ensemble_f1 0.94135
wandb:            eval/avg_f1 0.91194
wandb:      eval/avg_mil_loss 0.28146
wandb:       eval/ensemble_f1 0.91194
wandb:           train/avg_f1 0.89036
wandb:      train/ensemble_f1 0.89036
wandb:         train/mil_loss 0.18102
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vivid-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2s16bi48
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081701-2s16bi48/logs
wandb: ERROR Run 2s16bi48 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ri2n0kmc with config:
wandb: 	actor_learning_rate: 0.00017161307485062078
wandb: 	attention_dropout_p: 0.14507275646655865
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.371320916915179
wandb: 	temperature: 2.558158629149474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081931-ri2n0kmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ri2n0kmc
wandb: uploading history steps 148-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–†â–â–‚â–â–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–â–„â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–†â–ˆâ–†â–†â–ˆâ–‡â–†â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–…â–†â–†â–†â–†â–†â–„â–„â–…â–…â–„â–„â–‚â–ƒâ–„â–â–ƒâ–ƒâ–â–
wandb:      eval/avg_mil_loss â–â–‚â–ƒâ–â–â–â–â–‚â–â–â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–…â–„â–…â–†â–†â–…â–†â–‡â–†â–‡â–ˆâ–‡
wandb:       eval/ensemble_f1 â–†â–‡â–ˆâ–ˆâ–†â–†â–‡â–ˆâ–‡â–†â–†â–‡â–‡â–†â–ˆâ–†â–…â–†â–†â–†â–„â–…â–„â–†â–…â–†â–…â–ƒâ–„â–…â–„â–ƒâ–‚â–„â–‚â–‚â–â–â–â–‚
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–…â–†â–…â–…â–„â–ƒâ–„â–„â–„â–‚â–‚â–ƒâ–â–‚
wandb:      train/ensemble_f1 â–‡â–†â–‡â–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–â–
wandb:         train/mil_loss â–ˆâ–†â–†â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–…â–„â–„â–…â–†â–„â–„â–…â–…â–„â–„â–…â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–‚â–„â–â–ƒ
wandb:      train/policy_loss â–…â–…â–â–…â–…â–†â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–„â–ˆâ–…â–†â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–…â–…â–…â–ƒâ–…â–…â–‡â–…â–„â–…â–„â–…â–…â–†â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.25356
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.81332
wandb:      eval/avg_mil_loss 0.56654
wandb:       eval/ensemble_f1 0.81332
wandb:           train/avg_f1 0.79322
wandb:      train/ensemble_f1 0.79322
wandb:         train/mil_loss 1.34021
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ri2n0kmc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081931-ri2n0kmc/logs
wandb: ERROR Run ri2n0kmc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mvkuwn6d with config:
wandb: 	actor_learning_rate: 2.19970728181698e-05
wandb: 	attention_dropout_p: 0.32400383081889816
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 143
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43461978262161527
wandb: 	temperature: 6.927469694618679
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082232-mvkuwn6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mvkuwn6d
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–â–ˆâ–…
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–ˆâ–â–„â–…â–â–…â–…â–…â–â–„â–‚â–‚â–„â–ƒâ–„â–†â–‡â–‚â–â–†â–ƒâ–‡â–…â–„â–ƒâ–„â–…â–†â–„â–‚â–…â–‚â–‚â–ƒâ–†â–‚â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–…â–ˆâ–„â–‚â–ƒâ–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–ƒâ–…â–†â–‡â–ƒâ–ƒâ–…â–â–‚â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–„â–â–„â–„â–ˆâ–ˆâ–„â–ƒâ–…â–„â–„â–â–‚â–…â–„â–ƒâ–†â–†â–„â–†â–ƒâ–„â–…â–‡â–„â–â–ƒâ–ƒâ–…â–„â–„â–†â–ƒâ–…â–„â–„â–ƒâ–„â–„
wandb:           train/avg_f1 â–†â–‡â–…â–ˆâ–ƒâ–„â–„â–…â–ˆâ–†â–„â–ƒâ–†â–„â–†â–ƒâ–…â–…â–„â–„â–‡â–†â–„â–ƒâ–‚â–‚â–â–‚â–‡â–…â–â–ƒâ–†â–„â–„â–ƒâ–†â–‡â–…â–†
wandb:      train/ensemble_f1 â–†â–…â–…â–ˆâ–…â–…â–†â–‡â–„â–…â–ƒâ–„â–†â–ƒâ–…â–…â–‡â–â–„â–„â–†â–†â–…â–†â–‡â–…â–ƒâ–†â–†â–‡â–ˆâ–†â–„â–‡â–…â–„â–„â–†â–‡â–ˆ
wandb:         train/mil_loss â–ƒâ–„â–†â–…â–…â–‚â–‚â–…â–†â–ƒâ–„â–‚â–…â–ƒâ–ˆâ–…â–‚â–â–ƒâ–â–ƒâ–‚â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–†â–‚â–…â–…â–‡â–ƒâ–„â–†â–…â–ƒâ–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–ƒâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93388
wandb: best/eval_avg_mil_loss 0.26445
wandb:  best/eval_ensemble_f1 0.93388
wandb:            eval/avg_f1 0.90088
wandb:      eval/avg_mil_loss 0.29608
wandb:       eval/ensemble_f1 0.90088
wandb:           train/avg_f1 0.89771
wandb:      train/ensemble_f1 0.89771
wandb:         train/mil_loss 0.2256
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mvkuwn6d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082232-mvkuwn6d/logs
wandb: ERROR Run mvkuwn6d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wtkleszt with config:
wandb: 	actor_learning_rate: 0.00018945463118131363
wandb: 	attention_dropout_p: 0.008273676461495183
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5854272204874191
wandb: 	temperature: 4.816739250978327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082415-wtkleszt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wtkleszt
wandb: uploading history steps 111-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–â–‚â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–â–ƒâ–ˆâ–‡â–…â–†â–†â–‡â–‚â–‡â–…â–„â–…â–…â–‡â–…â–†â–…â–…â–‡â–…â–‡â–„â–†â–„â–…â–‚â–…â–„â–…â–„â–…â–ƒâ–†â–„â–‚â–â–…
wandb:      eval/avg_mil_loss â–ƒâ–â–„â–‚â–…â–„â–„â–†â–‡â–…â–„â–…â–‡â–…â–ƒâ–…â–†â–ƒâ–ƒâ–…â–ƒâ–ƒâ–†â–â–„â–†â–‚â–ƒâ–„â–…â–„â–„â–ˆâ–„â–„â–„â–…â–…â–†â–„
wandb:       eval/ensemble_f1 â–‡â–‡â–â–„â–†â–…â–ˆâ–‡â–†â–„â–‚â–ƒâ–ˆâ–…â–ˆâ–†â–‡â–‡â–…â–†â–…â–ƒâ–‡â–†â–‡â–…â–†â–ˆâ–†â–…â–ƒâ–…â–ƒâ–…â–…â–„â–…â–‡â–„â–„
wandb:           train/avg_f1 â–‡â–…â–ƒâ–†â–„â–†â–ˆâ–…â–…â–…â–„â–†â–ˆâ–ˆâ–…â–†â–…â–‡â–‡â–ˆâ–„â–ˆâ–‡â–‡â–ƒâ–†â–„â–…â–…â–…â–†â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–
wandb:      train/ensemble_f1 â–„â–‚â–†â–ˆâ–„â–…â–…â–ˆâ–‡â–†â–„â–…â–…â–‡â–‡â–…â–‡â–‡â–‡â–†â–„â–†â–†â–„â–ˆâ–„â–ƒâ–„â–„â–…â–†â–‚â–â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–
wandb:         train/mil_loss â–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–„â–…â–‡â–†â–†â–…â–„â–„â–‡â–…â–ƒâ–„â–„â–…â–ƒâ–…â–„â–†â–…â–†â–‚â–„â–†â–…â–†â–…â–…â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–‡â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.24032
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.884
wandb:      eval/avg_mil_loss 0.26756
wandb:       eval/ensemble_f1 0.884
wandb:           train/avg_f1 0.89167
wandb:      train/ensemble_f1 0.89167
wandb:         train/mil_loss 0.82709
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wtkleszt
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082415-wtkleszt/logs
wandb: ERROR Run wtkleszt errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: q6iuix74 with config:
wandb: 	actor_learning_rate: 3.2856041629421323e-06
wandb: 	attention_dropout_p: 0.4294270113235974
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3238248168278983
wandb: 	temperature: 7.739655734321127
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082610-q6iuix74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q6iuix74
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–ƒâ–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–„â–‚â–‚â–ƒâ–„â–…â–ƒâ–…â–„â–…â–„â–…â–„â–…â–…â–…â–„â–…â–…â–‡â–…â–…â–„â–ƒâ–…â–ˆâ–„â–„â–†â–†â–„â–…â–„â–…â–„â–ƒâ–â–…â–†
wandb:      eval/avg_mil_loss â–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ˆâ–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–‚â–‚
wandb:       eval/ensemble_f1 â–…â–„â–…â–ƒâ–ƒâ–†â–ˆâ–…â–ˆâ–„â–„â–†â–…â–ƒâ–‚â–„â–…â–„â–†â–„â–…â–ˆâ–„â–„â–ƒâ–„â–ƒâ–…â–„â–†â–…â–…â–†â–ˆâ–„â–„â–†â–†â–â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–„â–…â–ƒâ–„â–ƒâ–„â–‡â–…â–†â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–†â–†â–‡â–…â–„â–…â–†â–…â–…â–ˆâ–‡â–…
wandb:      train/ensemble_f1 â–„â–‚â–â–„â–‚â–„â–‚â–…â–ƒâ–ƒâ–†â–ƒâ–„â–„â–ƒâ–…â–„â–…â–†â–…â–„â–„â–…â–„â–‡â–‡â–†â–ˆâ–†â–‡â–†â–…â–†â–‡â–…â–…â–†â–…â–‡â–†
wandb:         train/mil_loss â–…â–…â–…â–†â–†â–…â–†â–†â–†â–†â–„â–†â–‡â–‡â–ƒâ–ˆâ–„â–…â–…â–†â–…â–…â–†â–„â–„â–†â–†â–ƒâ–…â–ƒâ–„â–…â–…â–…â–ƒâ–ƒâ–ƒâ–â–†â–ƒ
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9338
wandb: best/eval_avg_mil_loss 0.15119
wandb:  best/eval_ensemble_f1 0.9338
wandb:            eval/avg_f1 0.89688
wandb:      eval/avg_mil_loss 0.38522
wandb:       eval/ensemble_f1 0.89688
wandb:           train/avg_f1 0.86506
wandb:      train/ensemble_f1 0.86506
wandb:         train/mil_loss 5.4967
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rose-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q6iuix74
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082610-q6iuix74/logs
wandb: ERROR Run q6iuix74 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ws7h4u56 with config:
wandb: 	actor_learning_rate: 4.1357020070638704e-05
wandb: 	attention_dropout_p: 0.46268007051195553
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5564148424729671
wandb: 	temperature: 0.6923481930531261
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082931-ws7h4u56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ws7h4u56
wandb: uploading summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–…â–„â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–ƒâ–†â–†â–‡â–ˆâ–„â–†â–‚â–ˆâ–‡â–…â–‡â–ƒâ–†â–â–†â–‡â–…â–ƒâ–…â–…â–‡â–…â–…â–ƒâ–…â–†â–â–„â–†â–â–„â–…â–ƒâ–‚â–â–„
wandb:      eval/avg_mil_loss â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–â–ƒâ–ƒâ–‚â–†â–ƒâ–ƒâ–„â–…â–†â–„â–‚â–ƒâ–ƒâ–…â–…â–…â–‡â–„â–„â–…â–„â–„â–„â–‚â–„â–…â–„â–ƒâ–ˆâ–…â–„
wandb:       eval/ensemble_f1 â–‡â–‡â–†â–†â–‡â–‡â–…â–‡â–ˆâ–†â–ˆâ–†â–‡â–„â–…â–ˆâ–…â–ƒâ–„â–†â–…â–†â–…â–„â–„â–…â–„â–â–„â–‚â–†â–ƒâ–‚â–‡â–…â–„â–„â–ƒâ–†â–„
wandb:           train/avg_f1 â–†â–‡â–ˆâ–†â–ˆâ–…â–†â–‡â–‡â–†â–‡â–†â–…â–…â–…â–†â–…â–…â–†â–†â–„â–…â–„â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–‚â–„â–„â–„â–„â–„â–„â–â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–†â–ˆâ–†â–…â–‡â–†â–ˆâ–‡â–…â–…â–†â–…â–„â–„â–…â–†â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–„â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚
wandb:         train/mil_loss â–†â–ˆâ–ƒâ–ˆâ–ƒâ–…â–‡â–…â–ƒâ–…â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–†â–â–„â–„â–‚â–„â–ƒâ–…â–‚â–„â–ƒâ–…â–…â–…â–â–„â–„â–„â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–ƒâ–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–‡â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93766
wandb: best/eval_avg_mil_loss 0.20674
wandb:  best/eval_ensemble_f1 0.93766
wandb:            eval/avg_f1 0.88319
wandb:      eval/avg_mil_loss 0.26442
wandb:       eval/ensemble_f1 0.88319
wandb:           train/avg_f1 0.85913
wandb:      train/ensemble_f1 0.85913
wandb:         train/mil_loss 0.18014
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dainty-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ws7h4u56
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082931-ws7h4u56/logs
wandb: ERROR Run ws7h4u56 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: udgd795t with config:
wandb: 	actor_learning_rate: 0.0003740428953581395
wandb: 	attention_dropout_p: 0.2845875317531739
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6184849480694462
wandb: 	temperature: 3.605764603608703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083219-udgd795t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/udgd795t
wandb: uploading history steps 80-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–‚â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–ƒâ–‡â–…â–†â–…â–„â–‡â–ˆâ–„â–…â–ƒâ–„â–†â–‡â–‡â–…â–„â–…â–†â–‚â–…â–ƒâ–„â–â–ˆâ–…â–…â–…â–…â–„â–ƒâ–„â–†â–„â–…â–…â–ƒâ–…
wandb:      eval/avg_mil_loss â–…â–â–†â–†â–„â–†â–ƒâ–‚â–‡â–†â–„â–‚â–…â–ˆâ–„â–‡â–…â–…â–‚â–†â–‚â–†â–â–…â–…â–…â–ˆâ–†â–„â–†â–ƒâ–…â–‡â–„â–‡â–‚â–‡â–‡â–„â–…
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–‡â–†â–†â–†â–…â–…â–‡â–â–ˆâ–…â–†â–ˆâ–…â–†â–…â–„â–…â–†â–…â–ƒâ–…â–„â–‡â–â–„â–…â–†â–ƒâ–…â–†â–…â–…â–„â–„â–„â–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–‡â–†â–†â–†â–†â–†â–„â–…â–ƒâ–†â–…â–…â–…â–…â–…â–…â–†â–‡â–ƒâ–ƒâ–â–ƒâ–…â–…â–ƒâ–„â–…â–‚â–„â–„â–…â–…â–…â–‚â–„â–…â–ƒâ–„â–†
wandb:      train/ensemble_f1 â–†â–ˆâ–‡â–ˆâ–…â–ˆâ–…â–†â–„â–„â–†â–…â–…â–…â–‚â–ƒâ–„â–ƒâ–„â–„â–„â–†â–ƒâ–â–…â–„â–†â–†â–„â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–‚
wandb:         train/mil_loss â–ƒâ–‚â–‡â–†â–ƒâ–†â–…â–†â–„â–„â–„â–„â–„â–„â–…â–„â–…â–…â–‚â–‚â–ƒâ–„â–„â–…â–…â–â–ˆâ–‚â–ƒâ–…â–ˆâ–ƒâ–„â–„â–‚â–„â–„â–…â–„â–…
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–…â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.20308
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.88291
wandb:      eval/avg_mil_loss 0.27185
wandb:       eval/ensemble_f1 0.88291
wandb:            test/avg_f1 0.86934
wandb:      test/avg_mil_loss 0.32508
wandb:       test/ensemble_f1 0.86934
wandb:           train/avg_f1 0.87893
wandb:      train/ensemble_f1 0.87893
wandb:         train/mil_loss 0.21826
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/udgd795t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083219-udgd795t/logs
wandb: Agent Starting Run: zfulfikr with config:
wandb: 	actor_learning_rate: 0.0002289132262966363
wandb: 	attention_dropout_p: 0.23974022029334735
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6663332790689431
wandb: 	temperature: 9.055084947121134
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083406-zfulfikr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zfulfikr
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–„â–„â–…â–…â–…â–â–ˆâ–‚â–â–…â–„â–ƒâ–„â–…â–„â–‡â–ƒâ–…â–‚â–…â–„â–„â–„â–ƒâ–…â–„â–„â–„â–…â–„â–ƒâ–‡â–…â–„â–„â–ƒâ–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–â–…â–„â–ƒâ–‡â–…â–„â–†â–â–ˆâ–ƒâ–„â–‡â–ƒâ–‚â–‚â–ƒâ–‚â–„â–„â–‚â–„â–‡â–†â–ƒâ–…â–…â–„â–ƒâ–†â–†â–ˆâ–†â–†â–†â–…â–‚â–„â–…â–‚
wandb:       eval/ensemble_f1 â–†â–â–„â–…â–„â–…â–‚â–…â–„â–†â–„â–…â–„â–…â–ƒâ–…â–‡â–†â–„â–ƒâ–…â–ˆâ–†â–„â–‡â–…â–ˆâ–…â–…â–„â–…â–…â–„â–…â–‡â–ƒâ–‡â–…â–ƒâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–‚â–…â–ƒâ–‚â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–…â–†â–ƒâ–†â–ƒâ–„â–†â–…â–…â–…â–‡â–†â–…â–†â–‡â–‡â–…â–„â–‡â–†â–ƒâ–…â–ˆâ–…
wandb:      train/ensemble_f1 â–ƒâ–â–‚â–ƒâ–…â–‚â–„â–…â–ƒâ–„â–ˆâ–ƒâ–†â–‡â–„â–†â–…â–ƒâ–†â–†â–„â–„â–…â–…â–…â–„â–†â–‡â–…â–‡â–ˆâ–…â–†â–„â–ˆâ–…â–„â–ƒâ–†â–†
wandb:         train/mil_loss â–ˆâ–†â–†â–…â–„â–…â–…â–„â–„â–„â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–â–â–„â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–ˆâ–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–„â–„â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–‡â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75636
wandb: best/eval_avg_mil_loss 4.71175
wandb:  best/eval_ensemble_f1 0.75636
wandb:            eval/avg_f1 0.71479
wandb:      eval/avg_mil_loss 7.46318
wandb:       eval/ensemble_f1 0.71479
wandb:            test/avg_f1 0.68422
wandb:      test/avg_mil_loss 7.84697
wandb:       test/ensemble_f1 0.68422
wandb:           train/avg_f1 0.67889
wandb:      train/ensemble_f1 0.67889
wandb:         train/mil_loss 0.18473
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zfulfikr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083406-zfulfikr/logs
wandb: Agent Starting Run: 8jkac1yo with config:
wandb: 	actor_learning_rate: 4.993398397454436e-05
wandb: 	attention_dropout_p: 0.07784604236474318
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17820934899036056
wandb: 	temperature: 6.061028238031211
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083611-8jkac1yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8jkac1yo
wandb: uploading wandb-summary.json; uploading history steps 117-132, summary
wandb: uploading history steps 117-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–‚â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‚â–ƒâ–‚â–â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–„â–â–„â–„â–ˆâ–ƒâ–…â–ƒâ–‚â–„â–â–†â–‚â–ƒâ–„â–‚â–„â–„â–ƒâ–‚â–ƒâ–„
wandb:      eval/avg_mil_loss â–â–„â–„â–‚â–ƒâ–„â–ˆâ–…â–†â–ƒâ–‚â–ƒâ–ƒâ–†â–†â–…â–â–„â–„â–„â–‡â–‚â–‚â–„â–‚â–…â–‚â–‚â–‡â–…â–ƒâ–„â–†â–…â–ƒâ–…â–‚â–‚â–‚â–„
wandb:       eval/ensemble_f1 â–†â–„â–„â–‚â–†â–†â–†â–„â–…â–‚â–ƒâ–„â–‚â–„â–„â–ƒâ–‚â–‚â–…â–ƒâ–â–…â–†â–…â–„â–…â–„â–ƒâ–ˆâ–ƒâ–…â–…â–„â–…â–‚â–‚â–…â–ƒâ–…â–‚
wandb:           train/avg_f1 â–„â–ƒâ–„â–‡â–†â–„â–„â–…â–„â–ƒâ–„â–…â–â–†â–…â–„â–‚â–†â–„â–…â–…â–„â–‡â–…â–‡â–…â–„â–„â–…â–ƒâ–„â–„â–„â–ˆâ–†â–„â–†â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–…â–…â–…â–ƒâ–ˆâ–…â–‚â–…â–‚â–…â–…â–„â–ˆâ–„â–„â–„â–†â–…â–„â–ƒâ–‡â–„â–…â–â–‚â–„â–ˆâ–â–„â–„â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–‡â–‚â–…
wandb:         train/mil_loss â–…â–†â–ˆâ–†â–„â–‚â–ˆâ–…â–…â–…â–…â–ƒâ–„â–†â–†â–ƒâ–„â–†â–„â–„â–†â–…â–„â–ƒâ–‡â–â–†â–†â–†â–ƒâ–„â–…â–‡â–„â–„â–„â–…â–„â–…â–†
wandb:      train/policy_loss â–ˆâ–â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.94099
wandb: best/eval_avg_mil_loss 0.22138
wandb:  best/eval_ensemble_f1 0.94099
wandb:            eval/avg_f1 0.91467
wandb:      eval/avg_mil_loss 0.29999
wandb:       eval/ensemble_f1 0.91467
wandb:           train/avg_f1 0.8909
wandb:      train/ensemble_f1 0.8909
wandb:         train/mil_loss 0.21406
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run spring-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8jkac1yo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083611-8jkac1yo/logs
wandb: ERROR Run 8jkac1yo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mkskb4ln with config:
wandb: 	actor_learning_rate: 2.9629724987512494e-06
wandb: 	attention_dropout_p: 0.35352481075782144
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.093362053141671
wandb: 	temperature: 8.159943598280453
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083825-mkskb4ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mkskb4ln
wandb: uploading history steps 108-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–â–ˆâ–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–ƒâ–†â–‡â–†â–‡â–‡â–„â–ˆâ–„â–„â–…â–†â–ƒâ–‚â–†â–…â–„â–†â–ƒâ–ƒâ–†â–„â–…â–‡â–â–…â–†â–‡â–‚â–‚â–â–„â–ƒâ–ƒâ–‚â–…â–„â–†
wandb:      eval/avg_mil_loss â–…â–„â–ˆâ–â–…â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–ƒâ–„â–ˆâ–…â–„â–ƒâ–†â–„â–‚â–„â–†â–…â–ˆâ–†â–…â–ˆâ–…â–ƒâ–ƒâ–…â–…â–†â–…â–ƒâ–‡
wandb:       eval/ensemble_f1 â–†â–…â–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–„â–â–…â–ƒâ–…â–†â–…â–„â–‡â–‡â–„â–ˆâ–‡â–‡â–†â–ƒâ–„â–ƒâ–…â–…â–‡â–ƒâ–ƒâ–…â–ƒâ–…â–…â–‚â–ƒâ–„â–…â–‡
wandb:           train/avg_f1 â–†â–†â–†â–‡â–†â–†â–„â–…â–‡â–†â–†â–†â–‡â–‡â–ˆâ–‡â–†â–„â–†â–…â–†â–…â–‚â–…â–‡â–…â–„â–ƒâ–ƒâ–„â–â–„â–†â–…â–„â–ƒâ–…â–‚â–†â–ƒ
wandb:      train/ensemble_f1 â–‚â–†â–ˆâ–†â–ƒâ–†â–„â–†â–‡â–ˆâ–ƒâ–„â–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–†â–„â–ƒâ–„â–„â–†â–„â–‚â–‚â–†â–„â–ƒâ–…â–‡â–…â–„â–ƒâ–„â–‚â–†â–…â–„â–
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–‡â–†â–„â–†â–ˆâ–‡â–†â–„â–†â–…â–…â–†â–…â–„â–†â–„â–‡â–†â–„â–ƒâ–„â–‚â–…â–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–â–‚â–ƒ
wandb:      train/policy_loss â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–„â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.23043
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.91009
wandb:      eval/avg_mil_loss 0.31978
wandb:       eval/ensemble_f1 0.91009
wandb:           train/avg_f1 0.88323
wandb:      train/ensemble_f1 0.88323
wandb:         train/mil_loss 1.28405
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run electric-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mkskb4ln
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083825-mkskb4ln/logs
wandb: ERROR Run mkskb4ln errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: g1arsdhi with config:
wandb: 	actor_learning_rate: 8.878027019592529e-06
wandb: 	attention_dropout_p: 0.16891267802323157
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4969738682370925
wandb: 	temperature: 2.343022613069542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084019-g1arsdhi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1arsdhi
wandb: uploading history steps 78-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–…â–†â–†â–…â–„â–…â–„â–†â–â–†â–‡â–‡â–…â–†â–„â–‡â–ˆâ–‡â–†â–…â–‡â–†â–‡â–†â–ˆâ–„â–…â–ˆâ–…â–…â–†â–„â–„â–…â–…â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–†â–ƒâ–‚â–â–†â–…â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–†â–…â–…â–„â–ƒâ–„â–„â–…â–„â–„â–â–‡â–…â–…â–„â–…â–‡â–ˆâ–„â–ˆâ–…â–†â–ƒ
wandb:       eval/ensemble_f1 â–„â–ˆâ–†â–ƒâ–ƒâ–„â–„â–‚â–†â–…â–†â–„â–†â–„â–â–ƒâ–ƒâ–‚â–†â–‡â–†â–†â–†â–ƒâ–„â–…â–†â–†â–…â–„â–…â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‡
wandb:           train/avg_f1 â–†â–†â–…â–…â–ƒâ–…â–„â–†â–†â–…â–„â–†â–†â–ƒâ–‚â–„â–„â–„â–„â–…â–…â–„â–ˆâ–…â–‚â–ƒâ–‡â–„â–†â–…â–†â–†â–†â–„â–…â–â–„â–‚â–ƒâ–„
wandb:      train/ensemble_f1 â–†â–†â–„â–†â–„â–†â–…â–„â–‡â–…â–†â–â–†â–†â–†â–…â–…â–„â–„â–…â–„â–ˆâ–…â–„â–†â–†â–ƒâ–‡â–„â–ƒâ–„â–…â–…â–ƒâ–„â–„â–ƒâ–„â–…â–…
wandb:         train/mil_loss â–‡â–ƒâ–‡â–ƒâ–„â–ˆâ–ƒâ–…â–ƒâ–„â–„â–„â–…â–…â–‚â–â–…â–„â–…â–†â–†â–‡â–‡â–„â–†â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–„â–†â–ƒâ–ƒâ–„â–…â–…â–ƒâ–…â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.32503
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.91194
wandb:      eval/avg_mil_loss 0.25929
wandb:       eval/ensemble_f1 0.91194
wandb:           train/avg_f1 0.88304
wandb:      train/ensemble_f1 0.88304
wandb:         train/mil_loss 1.053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stellar-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1arsdhi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084019-g1arsdhi/logs
wandb: ERROR Run g1arsdhi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8mw97bl0 with config:
wandb: 	actor_learning_rate: 1.1306961116786264e-05
wandb: 	attention_dropout_p: 0.0355848255168415
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7989734056789406
wandb: 	temperature: 5.337237410467854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084152-8mw97bl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8mw97bl0
wandb: uploading history steps 109-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ƒâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–†â–†â–‡â–†â–„â–ˆâ–‡â–‡â–„â–„â–†â–‡â–†â–ƒâ–…â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–†â–†â–ƒâ–ƒâ–ƒâ–†â–†â–‚â–â–‚â–†â–â–â–…â–ƒâ–„
wandb:      eval/avg_mil_loss â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–…â–‚â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–ƒâ–‡â–„â–ˆâ–…â–‡â–…â–†â–‡â–‡â–ƒâ–†â–…â–…â–‡â–†â–…â–ƒâ–â–ƒâ–…â–„â–ƒâ–‡â–‚â–‚â–‚â–‚â–„â–†â–…â–‚â–ƒâ–‚â–‚â–ƒâ–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–„â–‡â–…â–…â–…â–†â–†â–†â–…â–…â–„â–…â–†â–†â–„â–…â–…â–ˆâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–„â–…â–‚â–…â–‚â–â–„â–â–„â–„â–…
wandb:      train/ensemble_f1 â–…â–„â–…â–…â–‡â–‡â–„â–ˆâ–„â–†â–†â–†â–„â–‡â–‡â–ˆâ–†â–†â–‡â–„â–…â–„â–‡â–…â–„â–‡â–†â–…â–„â–„â–†â–ƒâ–‚â–‡â–†â–„â–†â–â–…â–‚
wandb:         train/mil_loss â–…â–†â–‡â–†â–ƒâ–ƒâ–ˆâ–†â–…â–…â–‡â–†â–†â–ƒâ–†â–„â–…â–ƒâ–â–„â–†â–„â–†â–ƒâ–‚â–ˆâ–…â–ƒâ–…â–‡â–ƒâ–„â–‚â–ƒâ–…â–‚â–â–‚â–â–ƒ
wandb:      train/policy_loss â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–â–ˆâ–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91511
wandb: best/eval_avg_mil_loss 0.32258
wandb:  best/eval_ensemble_f1 0.91511
wandb:            eval/avg_f1 0.88067
wandb:      eval/avg_mil_loss 0.32755
wandb:       eval/ensemble_f1 0.88067
wandb:            test/avg_f1 0.90521
wandb:      test/avg_mil_loss 0.26965
wandb:       test/ensemble_f1 0.90521
wandb:           train/avg_f1 0.86592
wandb:      train/ensemble_f1 0.86592
wandb:         train/mil_loss 2.73619
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run blooming-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8mw97bl0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084152-8mw97bl0/logs
wandb: Agent Starting Run: xc0sfxqf with config:
wandb: 	actor_learning_rate: 2.821941710592629e-06
wandb: 	attention_dropout_p: 0.32442747839589575
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7404102943617946
wandb: 	temperature: 4.685355198840197
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084346-xc0sfxqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xc0sfxqf
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–‚â–„â–‡â–ƒâ–â–„â–„â–„â–ƒâ–…â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–‡â–…â–‡â–‚â–ƒâ–ƒâ–„â–„â–‚â–„â–‡â–‚â–„â–„â–„â–†â–ƒâ–†â–„â–
wandb:      eval/avg_mil_loss â–…â–„â–ˆâ–„â–ƒâ–…â–â–„â–„â–†â–†â–‡â–â–ƒâ–ƒâ–…â–†â–‚â–†â–‚â–„â–ƒâ–â–‚â–ƒâ–†â–â–ƒâ–†â–…â–â–‚â–„â–„â–â–…â–‚â–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–ƒâ–„â–…â–†â–â–…â–‡â–„â–…â–…â–ƒâ–ƒâ–ˆâ–ƒâ–†â–…â–†â–…â–„â–ƒâ–†â–…â–„â–„â–…â–â–…â–„â–†â–†â–…â–„â–…â–…â–„â–†â–‡â–…
wandb:           train/avg_f1 â–‚â–‚â–â–‚â–ƒâ–„â–„â–„â–…â–…â–„â–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–†â–…â–†â–„â–„â–„â–†â–…â–ƒâ–„â–…â–„â–„â–„â–‡â–ˆâ–ƒâ–…â–†â–„â–„â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–â–‚â–‚â–„â–„â–ƒâ–…â–…â–…â–†â–„â–†â–†â–„â–…â–ˆâ–…â–‡â–ˆâ–‡â–…â–„â–†â–…â–†â–…â–†â–…â–…â–…â–„â–…â–„â–‡â–†â–…â–…â–…
wandb:         train/mil_loss â–…â–ˆâ–‡â–„â–†â–†â–„â–†â–‡â–…â–†â–…â–„â–†â–†â–ƒâ–„â–…â–†â–„â–„â–„â–…â–…â–†â–…â–†â–ƒâ–ƒâ–„â–â–ƒâ–„â–„â–ƒâ–ƒâ–†â–„â–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–‚â–…â–…â–…â–„â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–…â–ƒâ–„â–‡â–ƒâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–„â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.24573
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.87733
wandb:      eval/avg_mil_loss 0.30043
wandb:       eval/ensemble_f1 0.87733
wandb:           train/avg_f1 0.88491
wandb:      train/ensemble_f1 0.88491
wandb:         train/mil_loss 4.17975
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glorious-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xc0sfxqf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084346-xc0sfxqf/logs
wandb: ERROR Run xc0sfxqf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: aw9qgbus with config:
wandb: 	actor_learning_rate: 7.996425503513453e-05
wandb: 	attention_dropout_p: 0.43465316110385194
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8333094883995185
wandb: 	temperature: 1.0463941706854396
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084534-aw9qgbus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b1jkj33p
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw9qgbus
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–†â–†â–†â–…â–†â–†â–†â–†â–†â–„â–…â–…â–†â–„â–„â–„â–„â–…â–„â–…â–ƒâ–„â–„â–â–ƒâ–„â–‚
wandb:      eval/avg_mil_loss â–‚â–â–ƒâ–â–‚â–‚â–„â–‚â–ˆâ–…â–â–‚â–ƒâ–‚â–‚â–ƒâ–„â–„â–‚â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–…â–„â–‚â–…â–ƒâ–„â–„â–ƒ
wandb:       eval/ensemble_f1 â–…â–ˆâ–‡â–‡â–‡â–†â–†â–†â–ˆâ–†â–ƒâ–†â–†â–…â–…â–„â–…â–„â–„â–‡â–…â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–â–†â–ƒâ–â–â–‚â–ƒâ–ƒâ–„â–‚
wandb:           train/avg_f1 â–†â–‡â–‡â–‡â–ˆâ–†â–…â–‡â–†â–†â–‡â–‡â–†â–…â–†â–…â–…â–„â–…â–†â–„â–…â–„â–„â–†â–„â–„â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–â–â–â–‚â–
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–‡â–ˆâ–…â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–…â–…â–…â–†â–†â–†â–…â–ƒâ–…â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:         train/mil_loss â–†â–†â–†â–„â–…â–…â–…â–‡â–„â–‡â–…â–†â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–…â–…â–…â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–
wandb:      train/policy_loss â–ƒâ–‡â–ƒâ–ˆâ–ˆâ–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–„â–‡â–…â–ƒâ–…â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–‚â–â–â–‚â–ƒâ–â–‡â–ˆâ–â–â–â–â–â–ƒâ–†â–â–â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85692
wandb: best/eval_avg_mil_loss 0.5353
wandb:  best/eval_ensemble_f1 0.85692
wandb:            eval/avg_f1 0.73077
wandb:      eval/avg_mil_loss 0.85436
wandb:       eval/ensemble_f1 0.73077
wandb:           train/avg_f1 0.74243
wandb:      train/ensemble_f1 0.74243
wandb:         train/mil_loss 1.37123
wandb:      train/policy_loss 0.04538
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.04538
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stilted-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw9qgbus
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084534-aw9qgbus/logs
wandb: ERROR Run aw9qgbus errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 9gh6edjb with config:
wandb: 	actor_learning_rate: 6.738074223709388e-06
wandb: 	attention_dropout_p: 0.2335523720652571
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1806922984980801
wandb: 	temperature: 3.616592685696535
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084757-9gh6edjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9gh6edjb
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–‚â–…â–‚
wandb:  best/eval_ensemble_f1 â–â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–†â–‚â–‡â–†â–…â–†â–†â–…â–ƒâ–…â–„â–†â–‚â–†â–ƒâ–†â–†â–„â–ƒâ–‚â–„â–â–ƒâ–„â–…â–ˆâ–‡â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–‚â–„â–…â–ƒ
wandb:      eval/avg_mil_loss â–‚â–„â–‚â–ƒâ–â–ƒâ–…â–‚â–„â–‚â–â–…â–†â–„â–ƒâ–ƒâ–„â–‡â–„â–ˆâ–ƒâ–„â–‚â–„â–„â–„â–ƒâ–„â–ˆâ–…â–…â–„â–„â–‡â–‡â–…â–…â–ˆâ–…â–…
wandb:       eval/ensemble_f1 â–„â–…â–…â–‡â–â–…â–ƒâ–ˆâ–†â–‡â–‡â–ˆâ–…â–…â–„â–ƒâ–„â–…â–†â–‚â–…â–…â–…â–…â–ƒâ–‚â–„â–„â–‚â–„â–ƒâ–ƒâ–„â–‡â–„â–„â–‚â–‚â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–†â–‡â–†â–†â–†â–„â–†â–†â–†â–‚â–…â–„â–„â–ƒâ–†â–„â–„â–„â–ƒâ–‚â–„â–„â–…â–…â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒ
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–ˆâ–…â–†â–ˆâ–…â–…â–„â–…â–…â–…â–…â–…â–„â–…â–†â–ƒâ–…â–…â–„â–„â–ƒâ–„â–„â–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–„
wandb:         train/mil_loss â–†â–†â–ˆâ–…â–‡â–‡â–„â–ƒâ–†â–…â–…â–†â–â–†â–ˆâ–„â–„â–ƒâ–„â–‚â–ƒâ–„â–†â–…â–†â–„â–†â–ƒâ–„â–†â–…â–ƒâ–†â–ˆâ–…â–…â–…â–ƒâ–„â–„
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–†â–ƒâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–…â–‡â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93025
wandb: best/eval_avg_mil_loss 0.23193
wandb:  best/eval_ensemble_f1 0.93025
wandb:            eval/avg_f1 0.86844
wandb:      eval/avg_mil_loss 0.31072
wandb:       eval/ensemble_f1 0.86844
wandb:            test/avg_f1 0.89511
wandb:      test/avg_mil_loss 0.27247
wandb:       test/ensemble_f1 0.89511
wandb:           train/avg_f1 0.8703
wandb:      train/ensemble_f1 0.8703
wandb:         train/mil_loss 0.21924
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run serene-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9gh6edjb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084757-9gh6edjb/logs
wandb: Agent Starting Run: e9z8w1w2 with config:
wandb: 	actor_learning_rate: 3.2071719043385185e-06
wandb: 	attention_dropout_p: 0.35518519870270554
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2262265476274462
wandb: 	temperature: 2.1698187055813403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085043-e9z8w1w2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9z8w1w2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ƒâ–â–†â–ˆâ–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–„â–ˆâ–„â–‡â–„â–…â–„â–…â–…â–…â–„â–ˆâ–†â–ƒâ–ƒâ–†â–‡â–…â–‚â–„â–„â–ƒâ–„â–ƒâ–„â–‚â–…â–„â–‚â–ƒâ–ƒâ–‚â–…â–„â–…â–…â–‚â–
wandb:      eval/avg_mil_loss â–„â–„â–‚â–ƒâ–ƒâ–â–„â–„â–„â–†â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–…â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–†â–„â–„â–„â–‚â–‡â–…â–„â–„â–…â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–†â–†â–ˆâ–†â–„â–ˆâ–‡â–„â–†â–…â–…â–‡â–†â–„â–…â–‡â–…â–ƒâ–†â–â–„â–„â–„â–†â–…â–ƒâ–„â–ƒâ–ˆâ–†â–‡â–…â–„â–ƒâ–†â–‚â–ˆâ–…â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–†â–†â–†â–†â–‡â–‡â–…â–‡â–ˆâ–†â–…â–†â–„â–†â–…â–…â–†â–„â–…â–†â–ƒâ–…â–†â–†â–†â–„â–…â–„â–„â–…â–ƒâ–â–‚â–‚â–…â–…â–‚â–‚â–„
wandb:      train/ensemble_f1 â–ˆâ–‡â–†â–‡â–†â–†â–…â–ˆâ–†â–‡â–†â–†â–†â–‡â–†â–…â–†â–†â–ƒâ–†â–†â–…â–…â–†â–„â–„â–ƒâ–„â–†â–„â–â–„â–„â–„â–†â–ƒâ–…â–…â–â–ƒ
wandb:         train/mil_loss â–…â–…â–…â–…â–†â–†â–‡â–…â–†â–†â–ˆâ–†â–…â–„â–…â–…â–„â–†â–…â–†â–†â–†â–…â–„â–…â–ƒâ–†â–…â–…â–†â–„â–…â–…â–…â–â–„â–‚â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–…â–‡â–†â–ˆâ–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92662
wandb: best/eval_avg_mil_loss 0.27632
wandb:  best/eval_ensemble_f1 0.92662
wandb:            eval/avg_f1 0.85398
wandb:      eval/avg_mil_loss 0.3057
wandb:       eval/ensemble_f1 0.85398
wandb:            test/avg_f1 0.8982
wandb:      test/avg_mil_loss 0.23893
wandb:       test/ensemble_f1 0.8982
wandb:           train/avg_f1 0.86784
wandb:      train/ensemble_f1 0.86784
wandb:         train/mil_loss 0.26309
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run generous-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e9z8w1w2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085043-e9z8w1w2/logs
wandb: Agent Starting Run: 12jdhpqz with config:
wandb: 	actor_learning_rate: 9.261268695245258e-05
wandb: 	attention_dropout_p: 0.21526992787432464
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2788757446740633
wandb: 	temperature: 3.8131075961843344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085241-12jdhpqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12jdhpqz
wandb: uploading history steps 75-78, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–„â–‡â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–ˆâ–†â–…â–†â–â–ƒâ–„â–†â–ƒâ–…â–†â–‚â–†â–…â–…â–†â–‡â–…â–…â–…â–ˆâ–†â–„â–…â–†â–…â–…â–‡â–„â–‚â–…â–ˆâ–„â–„â–†â–…â–„
wandb:      eval/avg_mil_loss â–„â–‚â–‚â–ƒâ–‡â–â–„â–ƒâ–‡â–ˆâ–‚â–…â–ƒâ–…â–ƒâ–‚â–…â–‚â–‚â–„â–…â–â–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–‡â–‡â–†â–â–ƒâ–ƒâ–‚â–…
wandb:       eval/ensemble_f1 â–†â–„â–„â–†â–†â–â–…â–…â–„â–†â–„â–ˆâ–†â–†â–„â–…â–ƒâ–ƒâ–„â–â–„â–ˆâ–†â–…â–‚â–…â–†â–â–…â–‡â–ƒâ–ˆâ–…â–†â–ƒâ–†â–†â–„â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–…â–‡â–…â–†â–†â–„â–…â–‡â–‡â–…â–ƒâ–â–ƒâ–…â–ˆâ–ƒâ–„â–„â–…â–ƒâ–‚â–‚â–ˆâ–â–…â–„â–…â–„â–â–„â–ˆâ–†â–‚â–‚â–†â–‚â–…â–„
wandb:      train/ensemble_f1 â–â–„â–†â–…â–„â–†â–†â–…â–…â–‡â–…â–‡â–‚â–…â–…â–ˆâ–ƒâ–„â–„â–‡â–ƒâ–ƒâ–ƒâ–†â–…â–„â–…â–…â–„â–…â–ƒâ–„â–ˆâ–†â–‚â–‡â–ƒâ–ƒâ–…â–„
wandb:         train/mil_loss â–‡â–†â–†â–ˆâ–„â–‡â–†â–†â–…â–…â–…â–…â–„â–†â–ƒâ–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–‚â–…â–ƒâ–‚â–„â–â–‚â–â–ƒ
wandb:      train/policy_loss â–…â–…â–ˆâ–â–ˆâ–â–…â–â–…â–ˆâ–â–…â–â–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–â–…â–…â–ˆâ–â–ˆâ–â–â–…â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–…â–ˆâ–â–…â–ˆâ–â–ˆâ–â–â–…â–â–…â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.20837
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.88936
wandb:      eval/avg_mil_loss 0.29316
wandb:       eval/ensemble_f1 0.88936
wandb:            test/avg_f1 0.88674
wandb:      test/avg_mil_loss 0.27349
wandb:       test/ensemble_f1 0.88674
wandb:           train/avg_f1 0.89108
wandb:      train/ensemble_f1 0.89108
wandb:         train/mil_loss 0.30123
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worthy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12jdhpqz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085241-12jdhpqz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rhd36yqi with config:
wandb: 	actor_learning_rate: 3.3441679334188214e-05
wandb: 	attention_dropout_p: 0.30968516603012675
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25454986828201065
wandb: 	temperature: 4.563841751940197
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085417-rhd36yqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rhd36yqi
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–‡â–â–„â–‚â–…â–„â–…â–‡â–†â–…â–‡â–„â–…â–„â–ˆâ–†â–†â–‚â–‚â–„â–ƒâ–†â–ƒâ–„â–ˆâ–†â–‡â–†â–…â–ƒâ–…â–„â–‡â–‚â–‡â–ƒâ–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–†â–„â–ƒâ–†â–â–ƒâ–…â–‡â–‡â–†â–„â–‚â–‚â–…â–ˆâ–‚â–†â–…â–â–‚â–‡â–„â–†â–„â–„â–„â–ˆâ–„â–†â–ƒâ–„â–…â–„â–ƒâ–ˆâ–†â–†â–‡â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–„â–‡â–„â–„â–…â–„â–‡â–…â–ƒâ–…â–‡â–„â–…â–…â–†â–†â–ƒâ–‡â–ƒâ–†â–…â–„â–ˆâ–†â–‡â–†â–…â–ƒâ–…â–„â–‡â–‡â–â–„â–‡â–„â–†â–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–„â–„â–ˆâ–„â–ƒâ–ˆâ–â–‚â–„â–ˆâ–â–ƒâ–‚â–…â–…â–…â–‚â–ƒâ–„â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–„â–â–†â–„â–ˆâ–†â–ˆâ–„â–†â–â–†â–†â–…
wandb:      train/ensemble_f1 â–â–„â–„â–ƒâ–†â–ƒâ–„â–ˆâ–â–‚â–„â–ˆâ–‡â–â–ƒâ–…â–…â–…â–‚â–ƒâ–…â–ƒâ–ƒâ–…â–„â–ƒâ–â–†â–†â–„â–‚â–ˆâ–…â–†â–†â–‡â–â–†â–†â–…
wandb:         train/mil_loss â–†â–‡â–…â–ˆâ–…â–ƒâ–ˆâ–†â–„â–„â–„â–‚â–‡â–‚â–…â–„â–…â–…â–„â–„â–‡â–ƒâ–‚â–…â–ƒâ–‚â–„â–…â–‚â–„â–„â–„â–†â–„â–‚â–‚â–â–â–„â–
wandb:      train/policy_loss â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–…â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–…â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.24196
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.90396
wandb:      eval/avg_mil_loss 0.34518
wandb:       eval/ensemble_f1 0.90396
wandb:            test/avg_f1 0.91989
wandb:      test/avg_mil_loss 0.18906
wandb:       test/ensemble_f1 0.91989
wandb:           train/avg_f1 0.89268
wandb:      train/ensemble_f1 0.89268
wandb:         train/mil_loss 0.5361
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run daily-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rhd36yqi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085417-rhd36yqi/logs
wandb: Agent Starting Run: ty6yrols with config:
wandb: 	actor_learning_rate: 9.507365999903295e-05
wandb: 	attention_dropout_p: 0.08234530115348332
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6836761632283365
wandb: 	temperature: 4.437124754832941
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085520-ty6yrols
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ty6yrols
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–‡â–‡â–…â–ˆâ–‡â–…â–‚â–ƒâ–„â–†â–ƒâ–‚â–…â–†â–„â–†â–†â–†â–„â–…â–ˆâ–…â–„â–†â–…â–†â–‡â–…â–â–ƒâ–„â–†â–…â–†â–ƒâ–ƒâ–‚â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–â–„â–…â–‚â–…â–†â–…â–ƒâ–†â–„â–â–ƒâ–„â–„â–…â–…â–„â–â–†â–„â–‚â–â–ƒâ–„â–ˆâ–‚â–…â–†â–†â–ƒâ–†â–‡â–…
wandb:       eval/ensemble_f1 â–…â–…â–†â–‡â–†â–‡â–†â–†â–…â–…â–ˆâ–…â–…â–ƒâ–„â–ƒâ–…â–â–…â–„â–…â–†â–…â–„â–…â–…â–„â–„â–…â–â–ƒâ–ƒâ–ƒâ–†â–‚â–†â–†â–‚â–ƒâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–ƒâ–…â–ƒâ–…â–†â–„â–‚â–…â–†â–‚â–„â–…â–„â–„â–ƒâ–†â–„â–…â–…â–…â–„â–‡â–‚â–„â–„â–†â–‚â–â–…â–…â–„â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–„
wandb:      train/ensemble_f1 â–†â–ˆâ–…â–‡â–…â–„â–†â–†â–†â–…â–ƒâ–…â–†â–‡â–†â–‚â–…â–„â–„â–…â–…â–†â–„â–‚â–ƒâ–‚â–†â–…â–â–…â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–ƒâ–ƒ
wandb:         train/mil_loss â–‡â–„â–…â–…â–…â–…â–„â–…â–…â–†â–ˆâ–‚â–…â–„â–…â–ƒâ–…â–„â–ƒâ–„â–†â–…â–…â–‚â–„â–„â–ƒâ–‚â–„â–†â–„â–â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ƒâ–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91919
wandb: best/eval_avg_mil_loss 0.21957
wandb:  best/eval_ensemble_f1 0.91919
wandb:            eval/avg_f1 0.88642
wandb:      eval/avg_mil_loss 0.30116
wandb:       eval/ensemble_f1 0.88642
wandb:            test/avg_f1 0.89036
wandb:      test/avg_mil_loss 0.2516
wandb:       test/ensemble_f1 0.89036
wandb:           train/avg_f1 0.8863
wandb:      train/ensemble_f1 0.8863
wandb:         train/mil_loss 0.27573
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ty6yrols
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085520-ty6yrols/logs
wandb: Agent Starting Run: 3qhdn1om with config:
wandb: 	actor_learning_rate: 2.8382278530505597e-06
wandb: 	attention_dropout_p: 0.3611621594454816
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34224244626058253
wandb: 	temperature: 0.37461401223347623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085652-3qhdn1om
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3qhdn1om
wandb: uploading history steps 60-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–†â–„â–ƒâ–‡â–‚â–†â–…â–ˆâ–…â–†â–…â–†â–†â–…â–ˆâ–‡â–ˆâ–†â–â–‡â–…â–…â–…â–…â–ƒâ–†â–‡â–†â–ƒâ–‡â–‡â–‚â–†â–„â–…â–†â–„â–„â–†â–…
wandb:      eval/avg_mil_loss â–„â–„â–‚â–ˆâ–‚â–…â–„â–ƒâ–â–â–„â–…â–…â–„â–‚â–ƒâ–…â–ƒâ–„â–‚â–‚â–ƒâ–†â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–„â–…â–‚â–„
wandb:       eval/ensemble_f1 â–†â–…â–„â–†â–‚â–†â–„â–…â–†â–ƒâ–ƒâ–ƒâ–…â–†â–ˆâ–†â–‡â–‡â–†â–ˆâ–ˆâ–â–…â–…â–ƒâ–†â–‡â–†â–ƒâ–‡â–‚â–ƒâ–†â–„â–…â–†â–†â–ƒâ–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–…â–ƒâ–ƒâ–„â–…â–…â–…â–†â–„â–„â–â–†â–…â–„â–†â–ˆâ–…â–†â–…â–…â–†â–…â–ˆâ–„â–„â–ƒâ–„â–…â–…â–†â–‡â–„â–„â–†â–ƒâ–†â–†â–ˆ
wandb:      train/ensemble_f1 â–…â–…â–…â–„â–â–…â–‚â–ƒâ–ƒâ–†â–…â–…â–â–…â–ƒâ–„â–†â–„â–ƒâ–ƒâ–†â–ˆâ–„â–…â–„â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–‡â–…â–†â–…â–…â–„
wandb:         train/mil_loss â–‡â–‚â–†â–…â–ˆâ–…â–„â–‡â–†â–ƒâ–ƒâ–ƒâ–‡â–‡â–…â–…â–…â–‚â–…â–‚â–…â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–â–‚â–„â–â–ƒâ–‚â–â–ƒâ–‚â–‚â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–„â–â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92223
wandb: best/eval_avg_mil_loss 0.25045
wandb:  best/eval_ensemble_f1 0.92223
wandb:            eval/avg_f1 0.89558
wandb:      eval/avg_mil_loss 0.26813
wandb:       eval/ensemble_f1 0.89558
wandb:            test/avg_f1 0.87885
wandb:      test/avg_mil_loss 0.27584
wandb:       test/ensemble_f1 0.87885
wandb:           train/avg_f1 0.90439
wandb:      train/ensemble_f1 0.90439
wandb:         train/mil_loss 1.65041
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3qhdn1om
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085652-3qhdn1om/logs
wandb: Agent Starting Run: m36t75rs with config:
wandb: 	actor_learning_rate: 0.0006966217285848561
wandb: 	attention_dropout_p: 0.401821066104465
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13481215575768724
wandb: 	temperature: 0.7009405400996183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085800-m36t75rs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m36t75rs
wandb: uploading history steps 149-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‡â–â–†â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–ƒâ–†â–…â–„â–…â–„â–â–†â–…â–„â–†â–„â–ƒâ–…â–†â–ˆâ–†â–…â–…â–ƒâ–†â–„â–„â–ƒâ–‚â–ƒâ–†â–‚â–‡â–…â–‚â–…â–ƒâ–ƒâ–…â–„â–â–…
wandb:      eval/avg_mil_loss â–†â–â–„â–ƒâ–„â–ƒâ–â–„â–†â–‚â–…â–†â–„â–†â–†â–†â–ƒâ–…â–†â–†â–„â–„â–ƒâ–†â–ƒâ–†â–…â–‡â–…â–ƒâ–„â–„â–‡â–…â–†â–ˆâ–…â–‡â–…â–…
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–„â–…â–„â–„â–„â–†â–â–…â–†â–„â–ˆâ–‚â–ƒâ–†â–‚â–„â–…â–…â–„â–„â–„â–…â–„â–‚â–ƒâ–†â–…â–‚â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–…â–†â–„â–†â–…â–ƒâ–…â–…â–‡â–†â–‡â–†â–…â–„â–…â–…â–…â–„â–‡â–†â–†â–â–…â–‚â–ƒâ–…â–‚â–†â–…â–ƒâ–…â–ˆâ–„â–„â–‚â–ƒâ–„â–‚
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–…â–ƒâ–…â–ƒâ–†â–…â–„â–…â–„â–†â–†â–…â–„â–…â–†â–ˆâ–ƒâ–„â–ƒâ–…â–‡â–„â–ƒâ–ˆâ–…â–…â–„â–‚â–ƒâ–…â–ƒâ–…â–ƒâ–‚â–ƒâ–â–‚
wandb:         train/mil_loss â–†â–†â–†â–†â–…â–ˆâ–ˆâ–…â–„â–…â–ˆâ–‡â–…â–„â–‡â–…â–‚â–†â–…â–…â–†â–„â–„â–…â–ƒâ–…â–†â–ƒâ–…â–â–„â–ƒâ–…â–…â–ƒâ–ƒâ–‚â–…â–„â–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–†â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.24392
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.88761
wandb:      eval/avg_mil_loss 0.29639
wandb:       eval/ensemble_f1 0.88761
wandb:            test/avg_f1 0.89302
wandb:      test/avg_mil_loss 0.25497
wandb:       test/ensemble_f1 0.89302
wandb:           train/avg_f1 0.8769
wandb:      train/ensemble_f1 0.8769
wandb:         train/mil_loss 2.35702
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m36t75rs
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085800-m36t75rs/logs
wandb: Agent Starting Run: dgcl5el3 with config:
wandb: 	actor_learning_rate: 0.000954244673722494
wandb: 	attention_dropout_p: 0.3924130277644958
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5015351233716016
wandb: 	temperature: 9.85061924287767
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090045-dgcl5el3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dgcl5el3
wandb: uploading wandb-summary.json
wandb: uploading history steps 153-168, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–â–ˆâ–ƒâ–‚â–†
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–ƒâ–…â–â–…â–„â–ƒâ–…â–†â–…â–„â–‡â–…â–„â–†â–ˆâ–ƒâ–„â–…â–ˆâ–†â–„â–…â–…â–„â–ˆâ–â–‚â–†â–…â–†â–…â–‚â–…â–ƒâ–†â–…â–‡â–‡
wandb:      eval/avg_mil_loss â–†â–„â–‡â–„â–…â–…â–…â–„â–ƒâ–†â–†â–ƒâ–â–…â–ƒâ–„â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ˆâ–„â–…â–â–…â–†â–…â–‚â–†â–„â–†â–ƒâ–‚â–‚â–†â–…
wandb:       eval/ensemble_f1 â–ƒâ–…â–‡â–â–…â–…â–…â–ƒâ–‚â–„â–„â–…â–†â–†â–‡â–„â–…â–…â–‚â–ˆâ–‚â–‡â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–â–„â–„â–„â–‚â–„â–ˆâ–…â–‚â–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–â–‚â–ƒâ–‚â–…â–…â–„â–…â–â–‚â–„â–‚â–ƒâ–‡â–ƒâ–„â–â–„â–ƒâ–†â–ƒâ–ˆâ–…â–‚â–‚â–…â–†â–…â–†â–„â–â–†â–„â–†â–‚â–ƒâ–†â–ƒâ–‚
wandb:      train/ensemble_f1 â–â–ƒâ–„â–ƒâ–ƒâ–„â–…â–â–ƒâ–‚â–„â–‚â–â–ƒâ–„â–ƒâ–ˆâ–‚â–â–‚â–â–‡â–„â–ƒâ–ƒâ–â–†â–â–â–ƒâ–‚â–„â–â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–…
wandb:         train/mil_loss â–‡â–†â–…â–ˆâ–‚â–ˆâ–ˆâ–‡â–…â–„â–†â–ˆâ–ˆâ–ƒâ–…â–„â–†â–‚â–…â–…â–‚â–‡â–â–‡â–ƒâ–ƒâ–‚â–†â–„â–‚â–„â–„â–„â–„â–â–…â–„â–‡â–„â–‚
wandb:      train/policy_loss â–„â–„â–„â–ˆâ–„â–ˆâ–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–â–ˆâ–„â–„â–ˆâ–„â–„â–„â–â–ˆâ–„â–„â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.33178
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.91467
wandb:      eval/avg_mil_loss 0.34287
wandb:       eval/ensemble_f1 0.91467
wandb:            test/avg_f1 0.90914
wandb:      test/avg_mil_loss 0.17628
wandb:       test/ensemble_f1 0.90914
wandb:           train/avg_f1 0.88213
wandb:      train/ensemble_f1 0.88213
wandb:         train/mil_loss 0.32925
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run exalted-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dgcl5el3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090045-dgcl5el3/logs
wandb: Agent Starting Run: 4xg6nml1 with config:
wandb: 	actor_learning_rate: 2.7062131077268756e-06
wandb: 	attention_dropout_p: 0.10895399675951406
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34550794102155413
wandb: 	temperature: 2.9181217446083583
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090305-4xg6nml1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4xg6nml1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–…â–…â–…â–„â–†â–„â–„â–†â–†â–†â–†â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–…â–†â–„â–‡â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‡â–„â–ƒâ–ƒâ–„â–„â–‡â–…â–ƒâ–‚
wandb:      eval/avg_mil_loss â–„â–…â–‚â–ƒâ–„â–…â–…â–„â–ƒâ–‚â–†â–…â–…â–…â–â–…â–‡â–…â–„â–ƒâ–…â–„â–ƒâ–†â–…â–…â–„â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–„â–…â–…â–‚â–ƒâ–ˆâ–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–‡â–„â–„â–„â–„â–†â–…â–†â–…â–†â–†â–‡â–ƒâ–…â–†â–„â–ƒâ–…â–†â–ƒâ–†â–†â–‡â–â–ƒâ–…â–ƒâ–‡â–ƒâ–ƒâ–„â–…â–…â–„â–â–„â–â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ˆâ–„â–…â–‡â–„â–„â–‚â–„â–…â–ˆâ–†â–‚â–ˆâ–„â–„â–†â–ˆâ–…â–ˆâ–…â–‚â–„â–„â–†â–…â–†â–†â–ƒâ–â–„â–„â–ƒâ–…â–‡â–…â–†â–…â–ƒ
wandb:      train/ensemble_f1 â–‚â–†â–ƒâ–ƒâ–ƒâ–‡â–‚â–ˆâ–…â–‚â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–†â–„â–…â–†â–‚â–ƒâ–…â–…â–„â–„â–ƒâ–„â–‚â–‚â–‚â–â–‚â–…â–„â–„â–â–â–„
wandb:         train/mil_loss â–‡â–ƒâ–†â–†â–ˆâ–…â–†â–‡â–„â–†â–†â–„â–…â–‡â–…â–„â–…â–…â–ƒâ–„â–†â–†â–ƒâ–…â–ƒâ–„â–†â–‚â–…â–„â–…â–„â–…â–ƒâ–„â–ƒâ–„â–â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.21866
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.8791
wandb:      eval/avg_mil_loss 0.33789
wandb:       eval/ensemble_f1 0.8791
wandb:            test/avg_f1 0.87622
wandb:      test/avg_mil_loss 0.26483
wandb:       test/ensemble_f1 0.87622
wandb:           train/avg_f1 0.88264
wandb:      train/ensemble_f1 0.88264
wandb:         train/mil_loss 0.29251
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run floral-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4xg6nml1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090305-4xg6nml1/logs
wandb: Agent Starting Run: pz3zgku0 with config:
wandb: 	actor_learning_rate: 1.067033222529124e-06
wandb: 	attention_dropout_p: 0.28209629581312534
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7880506457036284
wandb: 	temperature: 4.563275023111952
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090458-pz3zgku0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pz3zgku0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–ƒâ–…â–ƒ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–…â–†â–„â–„â–…â–„â–‡â–‡â–‡â–ƒâ–ƒâ–…â–†â–â–„â–…â–„â–‡â–ƒâ–â–â–…â–ƒâ–…â–…â–ƒâ–ˆâ–‡â–†â–ˆâ–ƒâ–†â–ƒâ–…â–…â–†â–…â–ˆ
wandb:      eval/avg_mil_loss â–â–…â–„â–„â–‡â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–ƒâ–„â–„â–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–…â–…â–‚â–„â–ƒâ–ˆâ–„â–…â–â–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–…â–‚â–…â–‚â–ƒâ–‡â–ˆâ–‡â–â–…â–„â–†â–†â–‡â–ƒâ–„â–†â–‡â–…â–‡â–„â–„â–†â–ƒâ–„â–ƒâ–…â–†â–‡â–†â–ˆâ–†â–ƒâ–†â–†â–‚â–ƒâ–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‚â–‚â–†â–†â–ƒâ–†â–ˆâ–…â–ƒâ–…â–ƒâ–†â–‚â–â–ƒâ–†â–…â–…â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‡â–„â–…â–„â–‚â–ƒâ–…â–ˆâ–â–ƒâ–„â–„â–…â–‚â–„
wandb:      train/ensemble_f1 â–ƒâ–‚â–ƒâ–†â–†â–‚â–„â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–ƒâ–„â–‚â–‚â–â–…â–ƒâ–…â–ƒâ–„â–‚â–ƒâ–„â–…â–„
wandb:         train/mil_loss â–ƒâ–†â–†â–…â–†â–„â–…â–„â–‚â–ƒâ–‡â–…â–„â–ˆâ–…â–„â–„â–ˆâ–…â–…â–ˆâ–ˆâ–…â–†â–†â–ˆâ–â–„â–†â–…â–ƒâ–„â–ˆâ–ƒâ–‚â–„â–„â–‡â–„â–†
wandb:      train/policy_loss â–…â–…â–…â–ˆâ–â–ˆâ–…â–…â–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–ˆâ–â–…â–â–…â–…â–â–…â–…â–…â–…â–â–â–…â–â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–ˆâ–â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–â–ˆâ–…â–…â–…â–â–ˆâ–…â–…â–ˆâ–…â–…â–â–…â–…â–â–…â–…â–ˆâ–ˆâ–…â–…â–â–…â–â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92223
wandb: best/eval_avg_mil_loss 0.26023
wandb:  best/eval_ensemble_f1 0.92223
wandb:            eval/avg_f1 0.91497
wandb:      eval/avg_mil_loss 0.29028
wandb:       eval/ensemble_f1 0.91497
wandb:            test/avg_f1 0.90493
wandb:      test/avg_mil_loss 0.16802
wandb:       test/ensemble_f1 0.90493
wandb:           train/avg_f1 0.88144
wandb:      train/ensemble_f1 0.88144
wandb:         train/mil_loss 3.17736
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run celestial-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pz3zgku0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090458-pz3zgku0/logs
wandb: Agent Starting Run: 4tok3its with config:
wandb: 	actor_learning_rate: 0.00020509092686755615
wandb: 	attention_dropout_p: 0.44377512460631446
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8804864672395011
wandb: 	temperature: 4.0300282289356755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090637-4tok3its
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tok3its
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–ˆâ–…â–†â–…â–ƒâ–„â–‚â–…â–‚â–‚â–„â–…â–…â–†â–‡â–ƒâ–„â–†â–â–„â–…â–†â–†â–‡â–„â–„â–†â–†â–‡â–†â–ƒâ–‚â–„â–…â–†â–‡â–‡â–‡
wandb:      eval/avg_mil_loss â–„â–†â–†â–‡â–…â–ƒâ–…â–„â–„â–„â–â–„â–ƒâ–‡â–„â–ƒâ–‡â–„â–†â–†â–„â–†â–‡â–…â–‚â–ƒâ–ƒâ–…â–†â–ˆâ–‚â–ƒâ–†â–…â–‡â–ˆâ–…â–„â–‡â–ƒ
wandb:       eval/ensemble_f1 â–â–†â–ƒâ–…â–ƒâ–‚â–„â–…â–‡â–„â–„â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–†â–†â–„â–‚â–„â–ƒâ–ƒâ–„â–‡â–ƒâ–…â–‚â–â–ƒâ–ƒâ–‡â–…â–…â–‚â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–ƒâ–â–‚â–â–„â–ƒâ–†â–†â–ƒâ–â–„â–…â–‡â–„â–„â–‚â–…â–‡â–…â–†â–…â–ƒâ–‚â–†â–„â–…â–„â–ˆâ–‚â–†â–…â–„â–„â–…â–†â–ˆâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–…â–â–…â–ƒâ–…â–„â–„â–ƒâ–…â–†â–†â–‡â–†â–‡â–ƒâ–„â–‚â–…â–†â–…â–ˆâ–†â–‡â–‚â–„â–ˆâ–„â–„â–„â–„â–‚â–†â–…â–†â–„â–ƒâ–…â–ˆâ–ƒâ–ƒ
wandb:         train/mil_loss â–„â–…â–„â–ˆâ–…â–†â–„â–ƒâ–ƒâ–…â–„â–‡â–ƒâ–†â–…â–‡â–ˆâ–‚â–„â–…â–ƒâ–„â–†â–‡â–†â–…â–†â–â–…â–„â–ƒâ–‡â–ƒâ–†â–…â–†â–…â–ƒâ–ˆâ–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.21195
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.88859
wandb:      eval/avg_mil_loss 0.36023
wandb:       eval/ensemble_f1 0.88859
wandb:            test/avg_f1 0.90033
wandb:      test/avg_mil_loss 0.22386
wandb:       test/ensemble_f1 0.90033
wandb:           train/avg_f1 0.89428
wandb:      train/ensemble_f1 0.89428
wandb:         train/mil_loss 2.04797
wandb:      train/policy_loss 0.13384
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.13384
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tok3its
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090637-4tok3its/logs
wandb: Agent Starting Run: 6nfmdl37 with config:
wandb: 	actor_learning_rate: 2.9393663714404093e-05
wandb: 	attention_dropout_p: 0.14720751443549646
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04294698175966771
wandb: 	temperature: 2.5393470314735933
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090825-6nfmdl37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6nfmdl37
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ˆâ–‡â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–…â–„â–ˆâ–ƒâ–…â–†â–‡â–‡â–â–„â–ƒâ–…â–…â–„â–„â–‡â–†â–‚â–‡â–‡â–„â–„â–‡â–ƒâ–„â–†â–…â–…â–‡â–„â–ˆâ–ƒâ–…â–…â–„â–â–†â–…
wandb:      eval/avg_mil_loss â–…â–„â–…â–„â–â–ƒâ–‚â–„â–„â–†â–„â–ˆâ–„â–‚â–„â–„â–„â–‚â–†â–†â–‚â–ƒâ–…â–…â–„â–†â–‡â–…â–ƒâ–‚â–†â–„â–†â–†â–…â–â–†â–„â–ƒâ–ˆ
wandb:       eval/ensemble_f1 â–â–…â–‚â–„â–‡â–„â–…â–ˆâ–…â–ƒâ–…â–…â–â–„â–…â–‡â–ƒâ–‚â–…â–„â–„â–‡â–†â–†â–â–‡â–â–„â–‚â–†â–„â–†â–„â–†â–ƒâ–ƒâ–„â–„â–…â–
wandb:           train/avg_f1 â–„â–„â–‚â–„â–â–†â–ƒâ–†â–†â–ƒâ–‚â–â–‚â–…â–†â–ƒâ–„â–…â–ƒâ–…â–…â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–…â–â–†â–‡â–„â–ƒâ–…â–…â–…â–…â–„â–„â–‚
wandb:      train/ensemble_f1 â–„â–‚â–…â–ƒâ–‚â–†â–…â–ƒâ–…â–…â–‚â–ƒâ–…â–†â–†â–„â–…â–ˆâ–…â–„â–„â–…â–„â–ƒâ–ˆâ–ƒâ–‚â–„â–„â–…â–…â–â–ƒâ–„â–†â–…â–ƒâ–„â–‡â–‚
wandb:         train/mil_loss â–ˆâ–†â–‡â–†â–†â–ˆâ–‡â–†â–ˆâ–ˆâ–†â–‡â–†â–‚â–„â–…â–„â–…â–†â–…â–…â–†â–„â–„â–…â–„â–…â–…â–†â–„â–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–â–„â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–‡â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.20226
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.87756
wandb:      eval/avg_mil_loss 0.34717
wandb:       eval/ensemble_f1 0.87756
wandb:           train/avg_f1 0.88284
wandb:      train/ensemble_f1 0.88284
wandb:         train/mil_loss 2.92706
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run quiet-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6nfmdl37
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090825-6nfmdl37/logs
wandb: ERROR Run 6nfmdl37 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: no2gsiad with config:
wandb: 	actor_learning_rate: 1.6799781682845855e-05
wandb: 	attention_dropout_p: 0.12846526794216784
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6401182717254932
wandb: 	temperature: 2.598803451956968
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091018-no2gsiad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/no2gsiad
wandb: uploading history steps 103-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–„â–†â–ƒâ–ˆâ–†â–…â–‚â–†â–‡â–ƒâ–‡â–‡â–†â–†â–…â–†â–…â–†â–„â–…â–ƒâ–…â–†â–„â–†â–ƒâ–â–†â–†â–‚â–‚â–„â–…â–…â–†â–‡â–†â–…â–„â–†
wandb:      eval/avg_mil_loss â–â–ƒâ–„â–ˆâ–„â–ƒâ–„â–‚â–‚â–‚â–„â–„â–„â–ƒâ–ƒâ–…â–‚â–„â–‚â–„â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–†â–„â–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–
wandb:       eval/ensemble_f1 â–„â–…â–†â–†â–ƒâ–†â–ƒâ–…â–â–ƒâ–‡â–ƒâ–†â–„â–ƒâ–†â–†â–‡â–†â–„â–‡â–…â–†â–‡â–†â–†â–ƒâ–„â–„â–‚â–„â–â–â–â–…â–â–ˆâ–„â–…â–†
wandb:           train/avg_f1 â–†â–†â–…â–‚â–„â–ƒâ–ƒâ–†â–†â–„â–â–„â–ˆâ–ˆâ–„â–†â–‡â–„â–„â–‡â–„â–†â–„â–ƒâ–ƒâ–…â–„â–‡â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–…â–‚
wandb:      train/ensemble_f1 â–‡â–„â–†â–…â–ˆâ–„â–…â–„â–ƒâ–ƒâ–†â–„â–‚â–†â–ˆâ–…â–‡â–„â–„â–„â–„â–†â–‚â–…â–‡â–â–„â–â–ƒâ–â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‡â–‚â–‚
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–…â–‡â–‡â–‡â–…â–ˆâ–‡â–‡â–†â–‡â–…â–‡â–…â–†â–„â–…â–…â–ƒâ–„â–„â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–â–‚â–â–‚
wandb:      train/policy_loss â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–…â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.20443
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.90344
wandb:      eval/avg_mil_loss 0.24292
wandb:       eval/ensemble_f1 0.90344
wandb:           train/avg_f1 0.88268
wandb:      train/ensemble_f1 0.88268
wandb:         train/mil_loss 1.47124
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run northern-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/no2gsiad
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091018-no2gsiad/logs
wandb: ERROR Run no2gsiad errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4f3vto14 with config:
wandb: 	actor_learning_rate: 0.0008405909740341981
wandb: 	attention_dropout_p: 0.23083621438179447
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31013403459854016
wandb: 	temperature: 8.700578546305163
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091248-4f3vto14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4f3vto14
wandb: uploading history steps 106-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–…â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–ˆâ–…â–ƒâ–ƒâ–…â–…â–ˆâ–‡â–‡â–‡â–†â–‚â–‡â–‡â–„â–…â–‚â–â–‚â–‚â–‡â–…â–…â–‚â–‚â–‚â–†â–†â–ƒâ–…â–†â–„â–„â–…â–„â–…â–‡â–
wandb:      eval/avg_mil_loss â–ƒâ–„â–‚â–„â–‚â–„â–„â–„â–„â–„â–‚â–‚â–â–â–„â–ˆâ–‚â–ƒâ–†â–„â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–…â–…â–‚â–„â–‚â–ƒâ–„â–„â–…â–…â–‚â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–„â–…â–‡â–‚â–ˆâ–„â–‚â–†â–†â–„â–ƒâ–…â–…â–‡â–ƒâ–â–…â–…â–ƒâ–…â–‚â–„â–‚â–†â–„â–…â–‚â–„â–…â–…â–„â–„â–…â–ƒâ–…â–„â–‚â–ƒâ–„
wandb:           train/avg_f1 â–‡â–ˆâ–ˆâ–‡â–†â–…â–‡â–†â–ƒâ–†â–†â–†â–‡â–…â–„â–„â–…â–‡â–…â–…â–ƒâ–†â–…â–„â–†â–…â–…â–†â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–…â–â–„
wandb:      train/ensemble_f1 â–‡â–ˆâ–†â–‡â–†â–†â–†â–ˆâ–‡â–„â–†â–„â–…â–ƒâ–†â–‡â–‡â–…â–ƒâ–ƒâ–…â–…â–„â–…â–ƒâ–„â–‡â–„â–†â–„â–„â–…â–†â–„â–„â–„â–ƒâ–â–†â–…
wandb:         train/mil_loss â–„â–…â–…â–ˆâ–‡â–ƒâ–„â–„â–…â–…â–ƒâ–…â–„â–…â–„â–„â–†â–…â–†â–„â–…â–†â–„â–‚â–†â–ƒâ–‚â–ƒâ–†â–‚â–…â–„â–„â–ƒâ–„â–â–ƒâ–‚â–†â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.32031
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.89022
wandb:      eval/avg_mil_loss 0.28747
wandb:       eval/ensemble_f1 0.89022
wandb:           train/avg_f1 0.88151
wandb:      train/ensemble_f1 0.88151
wandb:         train/mil_loss 0.25638
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run flowing-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4f3vto14
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091248-4f3vto14/logs
wandb: ERROR Run 4f3vto14 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dw1wk5tl with config:
wandb: 	actor_learning_rate: 0.0001286751247064528
wandb: 	attention_dropout_p: 0.4851546242099795
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7853571460594675
wandb: 	temperature: 8.639300942551007
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091431-dw1wk5tl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw1wk5tl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–…â–ƒâ–‡â–…â–†â–…â–†â–†â–…â–‚â–„â–ˆâ–„â–„â–„â–†â–ƒâ–†â–â–†â–…â–ƒâ–‚â–„â–ƒâ–ˆâ–…â–„â–…â–†â–…â–„â–…â–…â–‡â–ƒâ–†
wandb:      eval/avg_mil_loss â–‡â–„â–…â–†â–…â–„â–‚â–…â–„â–…â–†â–ƒâ–…â–…â–„â–…â–ˆâ–„â–‡â–ƒâ–ƒâ–…â–…â–†â–ƒâ–‡â–‚â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–…â–„â–â–„â–†â–ƒâ–†â–ˆ
wandb:       eval/ensemble_f1 â–…â–‡â–…â–†â–…â–…â–ƒâ–…â–‡â–„â–ˆâ–…â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–ƒâ–„â–‚â–…â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–…â–…â–‡â–â–„â–ƒâ–„â–…
wandb:           train/avg_f1 â–ˆâ–‡â–„â–ƒâ–â–„â–â–„â–†â–…â–„â–†â–‡â–„â–„â–„â–ƒâ–„â–†â–†â–…â–‡â–ƒâ–†â–…â–„â–„â–‚â–…â–‚â–‚â–†â–â–‡â–‡â–„â–ƒâ–ƒâ–„â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–‚â–…â–ƒâ–†â–‡â–…â–‡â–…â–â–‡â–‡â–…â–ƒâ–ƒâ–†â–…â–ƒâ–„â–‡â–„â–ƒâ–…â–„â–†â–…â–‚â–„â–‡â–‡â–†â–„â–ƒâ–„â–ˆâ–…â–‚â–‚â–„â–†
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–„â–†â–‡â–…â–†â–ˆâ–…â–†â–†â–…â–„â–„â–…â–…â–„â–„â–‚â–â–…â–…â–…â–„â–…â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–„â–„â–…
wandb:      train/policy_loss â–â–â–…â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–‡â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.23903
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.90344
wandb:      eval/avg_mil_loss 0.33218
wandb:       eval/ensemble_f1 0.90344
wandb:           train/avg_f1 0.89515
wandb:      train/ensemble_f1 0.89515
wandb:         train/mil_loss 2.94178
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run copper-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw1wk5tl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091431-dw1wk5tl/logs
wandb: ERROR Run dw1wk5tl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: b5aksgk7 with config:
wandb: 	actor_learning_rate: 1.4902843790329453e-06
wandb: 	attention_dropout_p: 0.01991734248864724
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5605509078394622
wandb: 	temperature: 4.880498263353966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091624-b5aksgk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b5aksgk7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 54-55, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ƒâ–„â–â–ƒâ–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–†â–†â–†â–…â–…â–†â–‡â–‡â–ƒâ–…â–‡â–ƒâ–†â–ˆâ–…â–†â–†â–…â–‡â–…â–â–ˆâ–„â–†â–…â–„â–ˆâ–„â–„â–…â–…â–ƒâ–…â–…â–…â–‡â–†â–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–…â–‡â–ƒâ–…â–†â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆâ–…â–‡â–„â–â–„â–ƒâ–…â–‚â–ƒâ–â–ƒâ–â–„â–…â–„â–„â–‚â–†â–…
wandb:       eval/ensemble_f1 â–…â–†â–†â–„â–…â–‡â–ƒâ–†â–…â–‡â–†â–ˆâ–ˆâ–…â–†â–‡â–…â–…â–â–ˆâ–†â–ˆâ–…â–…â–„â–ˆâ–„â–‚â–„â–…â–…â–ƒâ–…â–…â–ˆâ–…â–‡â–†â–…â–‡
wandb:           train/avg_f1 â–…â–…â–‡â–‡â–„â–ƒâ–„â–…â–…â–‚â–„â–„â–‚â–ˆâ–†â–…â–…â–„â–â–…â–†â–†â–„â–‡â–†â–‡â–„â–ˆâ–ƒâ–‡â–ƒâ–…â–‡â–„â–†â–‡â–†â–„â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–…â–‡â–†â–ƒâ–…â–„â–…â–…â–‚â–„â–‚â–‡â–ƒâ–†â–ƒâ–…â–„â–â–„â–ˆâ–…â–„â–„â–†â–…â–‚â–ƒâ–‡â–ƒâ–‡â–‚â–„â–†â–„â–…â–†â–ƒâ–ƒâ–„â–ƒ
wandb:         train/mil_loss â–„â–‡â–‡â–†â–„â–…â–‡â–‡â–†â–„â–ˆâ–‡â–†â–†â–„â–†â–†â–…â–ƒâ–ˆâ–†â–†â–†â–…â–†â–„â–„â–†â–ˆâ–ƒâ–†â–†â–„â–…â–…â–…â–†â–ƒâ–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91898
wandb: best/eval_avg_mil_loss 0.43674
wandb:  best/eval_ensemble_f1 0.91898
wandb:            eval/avg_f1 0.90758
wandb:      eval/avg_mil_loss 0.36547
wandb:       eval/ensemble_f1 0.90758
wandb:           train/avg_f1 0.88126
wandb:      train/ensemble_f1 0.88126
wandb:         train/mil_loss 0.67477
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run major-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b5aksgk7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091624-b5aksgk7/logs
wandb: ERROR Run b5aksgk7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: blmcd3yw with config:
wandb: 	actor_learning_rate: 0.0003903865430568406
wandb: 	attention_dropout_p: 0.06112355961884691
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8045847346198504
wandb: 	temperature: 3.768092050892319
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091734-blmcd3yw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/blmcd3yw
wandb: uploading wandb-summary.json
wandb: uploading history steps 58-74, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–„â–â–ˆâ–‡â–â–ƒâ–â–…â–…â–ƒâ–ƒâ–‚â–‚â–†â–†â–„â–‚â–„â–‚â–…â–‚â–‡â–„â–„â–‚â–ƒâ–†â–…â–†â–…â–…â–‡â–†â–â–‚â–„â–„â–†â–„â–…
wandb:      eval/avg_mil_loss â–…â–…â–…â–â–‚â–ƒâ–„â–‡â–ƒâ–ˆâ–‚â–â–†â–‚â–…â–â–‚â–ƒâ–†â–…â–„â–ˆâ–ƒâ–†â–„â–ƒâ–â–…â–‚â–„â–„â–â–‚â–‡â–„â–…â–…â–â–…â–‚
wandb:       eval/ensemble_f1 â–„â–†â–ƒâ–‚â–ˆâ–‡â–ˆâ–†â–†â–„â–‚â–…â–ƒâ–…â–„â–…â–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–â–„â–†â–ƒâ–†â–„â–†â–‚â–ƒâ–…â–†â–†â–…â–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–„â–„â–„â–†â–†â–…â–„â–ƒâ–…â–…â–‚â–ƒâ–„â–ƒâ–â–â–„â–…â–ˆâ–„â–…â–â–…â–ƒâ–‚â–†â–â–â–…â–ƒâ–…â–„â–„â–ƒâ–„â–†â–†â–‚
wandb:      train/ensemble_f1 â–ƒâ–…â–ƒâ–…â–„â–‡â–…â–…â–ˆâ–‡â–‚â–ƒâ–†â–…â–‚â–ƒâ–â–â–‡â–…â–„â–ƒâ–â–ˆâ–‚â–ƒâ–‡â–‚â–„â–‡â–„â–‚â–‚â–…â–…â–‚â–…â–ƒâ–‡â–‚
wandb:         train/mil_loss â–ˆâ–ˆâ–„â–„â–‡â–ˆâ–„â–…â–ƒâ–†â–‡â–…â–…â–†â–„â–ƒâ–†â–‚â–†â–„â–‚â–„â–…â–â–ƒâ–„â–†â–ƒâ–…â–‚â–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–‚â–â–‚â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.26793
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.90411
wandb:      eval/avg_mil_loss 0.25837
wandb:       eval/ensemble_f1 0.90411
wandb:            test/avg_f1 0.87951
wandb:      test/avg_mil_loss 0.17971
wandb:       test/ensemble_f1 0.87951
wandb:           train/avg_f1 0.88035
wandb:      train/ensemble_f1 0.88035
wandb:         train/mil_loss 0.49629
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/blmcd3yw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091734-blmcd3yw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4ajhaado with config:
wandb: 	actor_learning_rate: 4.383997085946187e-06
wandb: 	attention_dropout_p: 0.4092617513705835
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2878829305806857
wandb: 	temperature: 0.9316573352213632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091847-4ajhaado
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ajhaado
wandb: uploading history steps 72-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–„â–‡â–„â–ƒâ–„â–â–‡â–„â–ˆâ–†â–ƒâ–‡â–…â–‚â–…â–„â–…â–†â–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–†â–‚â–†â–†â–†â–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–‚â–„â–„â–„â–‚â–ƒâ–„â–„â–„â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ˆâ–ƒâ–„â–†â–ƒâ–…â–…â–„â–‚â–„â–„â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–â–„â–„â–„â–‚â–‡â–†â–…â–†â–ˆâ–…â–„â–…â–„â–ƒâ–…â–…â–„â–…â–†â–ƒâ–ƒâ–ƒâ–†â–„â–â–ƒâ–‚â–†â–†â–†â–ƒâ–„â–„â–„â–„â–ƒâ–†â–‚â–„
wandb:           train/avg_f1 â–â–‡â–‚â–ƒâ–†â–…â–ƒâ–„â–…â–ƒâ–…â–ƒâ–ˆâ–…â–…â–…â–…â–†â–†â–†â–„â–…â–…â–‡â–‡â–†â–„â–†â–„â–„â–ˆâ–„â–„â–‡â–…â–„â–‡â–‡â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–â–…â–‡â–‚â–†â–„â–ˆâ–ƒâ–„â–ƒâ–ƒâ–†â–„â–ƒâ–ƒâ–…â–„â–†â–„â–†â–…â–‡â–…â–„â–†â–†â–„â–†â–…â–„â–†â–ƒâ–‚â–„â–†â–‚â–‡â–…â–ƒ
wandb:         train/mil_loss â–†â–†â–…â–ˆâ–ˆâ–ˆâ–†â–…â–„â–…â–…â–†â–†â–†â–‚â–ƒâ–…â–†â–ƒâ–†â–†â–‚â–…â–†â–†â–„â–„â–„â–„â–„â–â–„â–‚â–‚â–â–‚â–ƒâ–ƒâ–â–ƒ
wandb:      train/policy_loss â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–‚â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–„â–‡â–‡â–‡â–â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.19497
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.88427
wandb:      eval/avg_mil_loss 0.30358
wandb:       eval/ensemble_f1 0.88427
wandb:           train/avg_f1 0.8871
wandb:      train/ensemble_f1 0.8871
wandb:         train/mil_loss 2.33412
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run honest-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ajhaado
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091847-4ajhaado/logs
wandb: ERROR Run 4ajhaado errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ehvpjz0f with config:
wandb: 	actor_learning_rate: 4.140538420721073e-05
wandb: 	attention_dropout_p: 0.12415884580866764
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7358252008576243
wandb: 	temperature: 7.864444147582948
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092030-ehvpjz0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ehvpjz0f
wandb: uploading history steps 141-146, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–…â–„â–„â–…â–„â–ƒâ–…â–ƒâ–†â–ƒâ–„â–„â–ƒâ–…â–ˆâ–‚â–…â–‡â–„â–‡â–ƒâ–†â–„â–„â–ƒâ–„â–…â–…â–‡â–†â–„â–…â–ƒâ–†â–â–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–‡â–…â–…â–ƒâ–†â–…â–ƒâ–ƒâ–†â–…â–â–…â–„â–„â–„â–ƒâ–ƒâ–„â–‡â–…â–‡â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–ƒâ–†â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–ƒâ–†â–‚â–„â–†â–†â–ƒâ–„â–‚â–â–…â–‡â–ˆâ–„â–„â–…â–‡â–ƒâ–ƒâ–†â–…â–‡â–ƒâ–†â–„â–…â–‡â–…â–ˆâ–„â–…â–‡â–‡â–„â–†â–„â–„â–â–ƒ
wandb:           train/avg_f1 â–†â–…â–„â–‡â–†â–„â–„â–ˆâ–†â–…â–…â–†â–…â–‚â–†â–„â–‡â–„â–…â–‚â–…â–…â–ƒâ–‡â–„â–„â–ƒâ–†â–„â–„â–ƒâ–â–„â–â–â–‚â–…â–…â–ƒâ–†
wandb:      train/ensemble_f1 â–…â–…â–„â–‡â–„â–ƒâ–†â–…â–…â–…â–ƒâ–‚â–ƒâ–…â–„â–„â–„â–†â–ƒâ–ƒâ–ƒâ–…â–…â–ˆâ–‡â–…â–ƒâ–„â–ˆâ–†â–â–â–…â–‚â–„â–„â–„â–ƒâ–„â–…
wandb:         train/mil_loss â–â–…â–‡â–…â–…â–„â–‡â–„â–…â–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–„â–†â–†â–„â–…â–†â–ƒâ–„â–†â–‚â–†â–ƒâ–„â–ƒâ–…â–ƒâ–ˆâ–…â–ƒâ–†â–†â–‚â–„â–â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–â–„â–„â–ˆâ–ˆâ–â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–â–„â–â–„â–â–â–„â–„â–â–ˆâ–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.19559
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.91556
wandb:      eval/avg_mil_loss 0.33489
wandb:       eval/ensemble_f1 0.91556
wandb:           train/avg_f1 0.88811
wandb:      train/ensemble_f1 0.88811
wandb:         train/mil_loss 0.24413
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ehvpjz0f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092030-ehvpjz0f/logs
wandb: ERROR Run ehvpjz0f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jn8hsclw with config:
wandb: 	actor_learning_rate: 7.26140785775574e-05
wandb: 	attention_dropout_p: 0.42297937089607063
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3752589736756293
wandb: 	temperature: 1.8328069056734464
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092249-jn8hsclw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jn8hsclw
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–ƒâ–ƒâ–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–â–ƒâ–…â–„â–„â–‚â–†â–â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–‚â–…â–„â–‡â–„â–„â–„â–ƒâ–„â–…â–„â–ƒâ–„â–†â–†â–â–‚â–…â–ƒâ–‚â–ƒâ–ˆâ–‚
wandb:      eval/avg_mil_loss â–ƒâ–‡â–ƒâ–†â–„â–ƒâ–†â–â–‚â–…â–‚â–‚â–‡â–ƒâ–‚â–…â–‡â–ƒâ–ƒâ–„â–„â–„â–„â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–†â–‚â–…â–ˆâ–„â–ƒ
wandb:       eval/ensemble_f1 â–„â–ƒâ–†â–„â–‚â–‡â–†â–â–„â–†â–â–„â–„â–„â–„â–ƒâ–â–ˆâ–„â–…â–ƒâ–†â–…â–„â–†â–ƒâ–ƒâ–ˆâ–‡â–‡â–‡â–„â–ƒâ–„â–‡â–†â–†â–ƒâ–ƒâ–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–„â–â–‚â–ƒâ–…â–‚â–†â–†â–…â–„â–„â–„â–„â–ƒâ–†â–†â–‡â–„â–…â–„â–â–†â–…â–†â–ƒâ–‡â–ƒâ–ƒâ–…â–‡â–ˆâ–…â–„â–…â–‡â–‡â–†â–…
wandb:      train/ensemble_f1 â–…â–â–ƒâ–ƒâ–„â–†â–†â–„â–†â–„â–‚â–†â–…â–†â–‡â–†â–†â–†â–ƒâ–‡â–ˆâ–„â–„â–†â–…â–…â–…â–„â–†â–…â–„â–ˆâ–†â–„â–†â–‡â–…â–‡â–†â–†
wandb:         train/mil_loss â–…â–†â–ˆâ–…â–„â–ƒâ–…â–…â–†â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–…â–„â–‚â–„â–ƒâ–…â–†â–‚â–…â–â–ƒâ–„â–„â–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–†â–â–ˆâ–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.26365
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.88139
wandb:      eval/avg_mil_loss 0.39444
wandb:       eval/ensemble_f1 0.88139
wandb:            test/avg_f1 0.90701
wandb:      test/avg_mil_loss 0.22
wandb:       test/ensemble_f1 0.90701
wandb:           train/avg_f1 0.88892
wandb:      train/ensemble_f1 0.88892
wandb:         train/mil_loss 3.18156
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jn8hsclw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092249-jn8hsclw/logs
wandb: Agent Starting Run: axj0jn0q with config:
wandb: 	actor_learning_rate: 2.9162321491308614e-05
wandb: 	attention_dropout_p: 0.38382678634483497
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.185390923373442
wandb: 	temperature: 6.0270761854058925
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092449-axj0jn0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axj0jn0q
wandb: uploading history steps 91-108; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–„â–‚â–†â–ˆâ–…â–„â–„â–â–â–…â–†â–„â–‡â–‡â–ƒâ–„â–„â–ƒâ–‡â–„â–„â–‡â–„â–†â–…â–†â–ƒâ–†â–†â–‡â–ƒâ–†â–„â–„â–ˆâ–…â–ˆ
wandb:      eval/avg_mil_loss â–†â–„â–‚â–…â–ƒâ–„â–…â–…â–‚â–‚â–ƒâ–…â–‚â–„â–ˆâ–„â–ƒâ–‡â–â–…â–ƒâ–‚â–„â–…â–„â–‚â–‚â–…â–„â–ƒâ–‚â–…â–„â–…â–ƒâ–†â–…â–…â–„â–…
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–„â–†â–‚â–ƒâ–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–…â–ƒâ–â–…â–ƒâ–ƒâ–†â–ƒâ–‚â–…â–…â–ƒâ–†â–„â–†â–ƒâ–„â–‚â–„â–†â–„â–…â–…â–„â–†â–…â–†
wandb:           train/avg_f1 â–†â–‚â–ƒâ–„â–„â–‡â–„â–ˆâ–…â–‡â–†â–‡â–ƒâ–†â–ƒâ–…â–„â–…â–ƒâ–„â–†â–†â–†â–†â–…â–†â–„â–‚â–†â–„â–‡â–†â–…â–‚â–†â–…â–ƒâ–„â–…â–
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–‡â–…â–†â–…â–‡â–ˆâ–…â–†â–ƒâ–‡â–„â–‡â–ˆâ–…â–…â–ˆâ–ˆâ–…â–†â–…â–†â–…â–…â–‡â–†â–…â–‡â–ƒâ–†â–…â–ƒâ–„â–â–„â–…â–…â–…
wandb:         train/mil_loss â–‡â–„â–†â–„â–‡â–‚â–…â–…â–†â–ƒâ–„â–†â–…â–…â–‡â–ˆâ–ˆâ–„â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–†â–ƒâ–„â–‚â–†â–„â–„â–„â–„â–„â–â–â–„â–„â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–„â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–â–ˆâ–„â–â–ˆâ–„â–„â–â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–â–„â–â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9338
wandb: best/eval_avg_mil_loss 0.23012
wandb:  best/eval_ensemble_f1 0.9338
wandb:            eval/avg_f1 0.91873
wandb:      eval/avg_mil_loss 0.23325
wandb:       eval/ensemble_f1 0.91873
wandb:           train/avg_f1 0.87945
wandb:      train/ensemble_f1 0.87945
wandb:         train/mil_loss 0.4956
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/axj0jn0q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092449-axj0jn0q/logs
wandb: ERROR Run axj0jn0q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1m9oaueq with config:
wandb: 	actor_learning_rate: 1.557551255055008e-06
wandb: 	attention_dropout_p: 0.2317454274845523
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38471189197669864
wandb: 	temperature: 9.670072342475317
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092627-1m9oaueq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1m9oaueq
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–†â–â–„â–†
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–‚â–„â–ƒâ–‚â–…â–„â–ƒâ–„â–ƒâ–ˆâ–…â–†â–†â–‚â–„â–â–‡â–…â–‡â–„â–ƒâ–†â–‚â–…â–…â–†â–‡â–…â–†â–…â–‡â–‚â–‡â–ˆâ–…â–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–„â–…â–‡â–„â–…â–†â–ƒâ–„â–ƒâ–„â–ƒâ–…â–‡â–‚â–…â–ƒâ–ˆâ–†â–‡â–„â–ƒâ–â–…â–…â–„â–…â–†â–†â–…â–‡â–…â–„â–„â–ƒâ–ƒâ–„â–‚â–‡â–‡â–„
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–†â–…â–…â–†â–â–„â–‡â–„â–ƒâ–ƒâ–‚â–†â–…â–„â–†â–‡â–…â–†â–‡â–„â–ˆâ–„â–‚â–ˆâ–…â–‡â–„â–…â–†â–†â–†â–‚â–…â–„â–…â–‡â–…
wandb:           train/avg_f1 â–„â–â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–…â–…â–…â–ˆâ–„â–ƒâ–…â–„â–„â–ƒâ–„â–…â–„â–ƒâ–…â–…â–…â–‚â–…â–‚â–„â–…â–ƒâ–„â–„â–ƒâ–ƒâ–‡â–†â–„â–„
wandb:      train/ensemble_f1 â–†â–ƒâ–ˆâ–‡â–…â–…â–ˆâ–‚â–†â–‡â–ˆâ–„â–‡â–…â–„â–†â–‡â–„â–†â–…â–„â–‡â–‡â–‡â–†â–‡â–…â–â–‡â–„â–…â–ˆâ–‡â–†â–†â–…â–…â–ˆâ–†â–…
wandb:         train/mil_loss â–…â–„â–…â–…â–‡â–‡â–†â–ˆâ–ƒâ–ƒâ–…â–„â–ƒâ–‚â–…â–‡â–‚â–ƒâ–…â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–â–„â–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93351
wandb: best/eval_avg_mil_loss 0.28092
wandb:  best/eval_ensemble_f1 0.93351
wandb:            eval/avg_f1 0.90773
wandb:      eval/avg_mil_loss 0.32093
wandb:       eval/ensemble_f1 0.90773
wandb:           train/avg_f1 0.89642
wandb:      train/ensemble_f1 0.89642
wandb:         train/mil_loss 0.29772
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eager-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1m9oaueq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092627-1m9oaueq/logs
wandb: ERROR Run 1m9oaueq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 41fjjjsv with config:
wandb: 	actor_learning_rate: 1.3418209215853745e-06
wandb: 	attention_dropout_p: 0.04700592707233564
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4435283289952415
wandb: 	temperature: 0.09217539717247702
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092928-41fjjjsv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41fjjjsv
wandb: uploading wandb-summary.json
wandb: uploading history steps 109-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–‡â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–„â–ƒâ–‚â–â–„â–‡â–â–‚â–ƒâ–…â–†â–‚â–‡â–‡â–ˆâ–…â–â–‡â–‚â–…â–…â–ƒâ–‚â–„â–â–‡â–‡â–â–†â–…â–…â–…â–ˆâ–ˆâ–…â–‚â–…â–„
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–†â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–â–…â–„â–â–ƒâ–…â–„â–‚â–‚â–‚â–†â–„â–ƒâ–‡â–â–ƒâ–â–‡â–„â–‡â–…â–‚â–‚â–„â–„â–…â–‚â–ƒ
wandb:       eval/ensemble_f1 â–†â–ˆâ–†â–‡â–‡â–„â–ˆâ–„â–†â–„â–‡â–…â–…â–„â–†â–‡â–ˆâ–„â–„â–…â–‡â–†â–‡â–â–…â–…â–…â–…â–…â–…â–‡â–„â–„â–…â–†â–†â–„â–†â–…â–†
wandb:           train/avg_f1 â–‡â–„â–…â–‡â–†â–„â–…â–†â–â–„â–…â–†â–…â–„â–†â–„â–ˆâ–…â–†â–…â–…â–‡â–†â–…â–„â–…â–†â–†â–…â–ƒâ–‡â–†â–…â–…â–…â–…â–â–ƒâ–†â–ˆ
wandb:      train/ensemble_f1 â–„â–„â–ˆâ–ƒâ–‡â–„â–ƒâ–…â–„â–ƒâ–„â–„â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–†â–„â–â–„â–…â–‚â–†â–…â–…â–ƒâ–„â–…â–‚â–‚â–„â–†â–„â–†â–…
wandb:         train/mil_loss â–ƒâ–‡â–†â–ˆâ–…â–†â–…â–„â–†â–„â–‚â–„â–ƒâ–†â–…â–‚â–ˆâ–ƒâ–…â–„â–„â–ƒâ–…â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–â–„â–‚â–…â–…â–â–‚â–„â–ƒâ–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.30547
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.87119
wandb:      eval/avg_mil_loss 0.28017
wandb:       eval/ensemble_f1 0.87119
wandb:           train/avg_f1 0.89167
wandb:      train/ensemble_f1 0.89167
wandb:         train/mil_loss 0.43224
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fine-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41fjjjsv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092928-41fjjjsv/logs
wandb: ERROR Run 41fjjjsv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y5qfcih2 with config:
wandb: 	actor_learning_rate: 1.6671210501819318e-05
wandb: 	attention_dropout_p: 0.2063881796837808
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17909303301924884
wandb: 	temperature: 8.243444383948614
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093122-y5qfcih2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5qfcih2
wandb: uploading history steps 100-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–…â–…â–ƒâ–…â–„â–â–‚â–…â–„â–„â–ƒâ–†â–ƒâ–…â–„â–‡â–…â–…â–‚â–ƒâ–†â–„â–†â–„â–ƒâ–ƒâ–„â–â–„â–ƒâ–‡â–‡â–…â–†â–„â–†â–ˆâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–‚â–‡â–ƒâ–ˆâ–‡â–„â–†â–†â–‚â–…â–ƒâ–„â–‡â–…â–…â–ƒâ–„â–ˆâ–„â–…â–‚â–‚â–ƒâ–ƒâ–„â–ˆâ–…â–‡â–ƒâ–…â–†â–…â–â–†â–…â–„â–…
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–‡â–…â–…â–‡â–‚â–‚â–‚â–„â–ƒâ–‡â–…â–†â–…â–ƒâ–…â–„â–…â–†â–„â–…â–ƒâ–…â–„â–„â–†â–ƒâ–‡â–ƒâ–„â–…â–ƒâ–‡â–â–„â–…â–‡â–†â–‚
wandb:           train/avg_f1 â–‡â–…â–…â–ˆâ–…â–„â–…â–„â–‡â–‡â–†â–„â–ˆâ–…â–†â–ƒâ–‚â–…â–…â–„â–…â–…â–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–ƒâ–„â–‚â–‚â–â–
wandb:      train/ensemble_f1 â–…â–…â–ˆâ–…â–…â–…â–…â–ƒâ–‡â–‡â–†â–ƒâ–†â–†â–ˆâ–…â–†â–„â–‚â–…â–„â–„â–…â–„â–â–ƒâ–â–…â–„â–„â–„â–ƒâ–ƒâ–„â–…â–„â–„â–ƒâ–‚â–
wandb:         train/mil_loss â–†â–„â–†â–„â–…â–†â–‡â–ˆâ–…â–ˆâ–…â–…â–†â–„â–ƒâ–‡â–†â–„â–…â–…â–†â–„â–…â–„â–‡â–†â–„â–ƒâ–„â–„â–â–„â–„â–„â–„â–ƒâ–â–…â–‚â–„
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92653
wandb: best/eval_avg_mil_loss 0.19078
wandb:  best/eval_ensemble_f1 0.92653
wandb:            eval/avg_f1 0.90848
wandb:      eval/avg_mil_loss 0.28632
wandb:       eval/ensemble_f1 0.90848
wandb:           train/avg_f1 0.8739
wandb:      train/ensemble_f1 0.8739
wandb:         train/mil_loss 0.28533
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5qfcih2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093122-y5qfcih2/logs
wandb: ERROR Run y5qfcih2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: vmnz162i with config:
wandb: 	actor_learning_rate: 0.0002825017095972234
wandb: 	attention_dropout_p: 0.2445670347166075
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6539501940117618
wandb: 	temperature: 4.932040976913273
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093300-vmnz162i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmnz162i
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–†â–„â–‚â–„â–…â–…â–ƒâ–„â–†â–…â–†â–â–ƒâ–„â–†â–†â–„â–‡â–‡â–ƒâ–‡â–ƒâ–ƒâ–…â–…â–ˆâ–ˆâ–‡â–†â–†â–„â–„â–‡â–†â–„â–‡â–…â–„
wandb:      eval/avg_mil_loss â–‡â–‚â–ƒâ–…â–„â–‚â–‚â–ƒâ–…â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–„â–„â–…â–ƒâ–…â–…â–â–„â–†â–‚â–†â–„â–ˆâ–„â–„â–ƒâ–…â–…â–„â–…â–ƒâ–†â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–ƒâ–â–…â–†â–ƒâ–…â–ƒâ–…â–†â–‡â–†â–„â–ƒâ–†â–†â–ƒâ–ƒâ–…â–†â–‚â–ƒâ–„â–ˆâ–†â–‚â–…â–ƒâ–‚â–â–„â–ƒâ–…â–…â–„â–…â–„â–„â–„â–…
wandb:           train/avg_f1 â–‚â–…â–‚â–„â–…â–‚â–„â–…â–…â–ƒâ–ƒâ–‡â–…â–…â–…â–„â–†â–ƒâ–â–â–…â–‚â–„â–ƒâ–†â–‡â–ˆâ–‚â–…â–„â–ƒâ–†â–…â–â–…â–…â–…â–„â–…â–„
wandb:      train/ensemble_f1 â–…â–…â–†â–ƒâ–‡â–†â–‚â–†â–†â–‚â–„â–„â–â–‡â–…â–…â–†â–…â–…â–„â–…â–…â–‡â–…â–†â–†â–‡â–†â–…â–„â–‡â–ˆâ–„â–„â–‡â–ƒâ–ƒâ–‡â–†â–…
wandb:         train/mil_loss â–ˆâ–†â–„â–†â–…â–„â–…â–†â–†â–„â–…â–„â–„â–…â–„â–„â–…â–„â–„â–†â–ƒâ–ƒâ–‡â–ƒâ–„â–‚â–‚â–ƒâ–‚â–ƒâ–…â–„â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92261
wandb: best/eval_avg_mil_loss 0.30452
wandb:  best/eval_ensemble_f1 0.92261
wandb:            eval/avg_f1 0.9038
wandb:      eval/avg_mil_loss 0.2636
wandb:       eval/ensemble_f1 0.9038
wandb:           train/avg_f1 0.8913
wandb:      train/ensemble_f1 0.8913
wandb:         train/mil_loss 0.27217
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmnz162i
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093300-vmnz162i/logs
wandb: ERROR Run vmnz162i errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6ax2l9u1 with config:
wandb: 	actor_learning_rate: 3.4502969025460243e-06
wandb: 	attention_dropout_p: 0.007571551089922912
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6150355562289465
wandb: 	temperature: 2.942430979142101
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093449-6ax2l9u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ax2l9u1
wandb: uploading wandb-summary.json
wandb: uploading history steps 91-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‡â–‡â–ƒâ–…â–„â–‡â–…â–ˆâ–„â–…â–…â–ˆâ–„â–â–…â–‡â–…â–„â–„â–†â–‚â–…â–…â–‡â–…â–„â–ƒâ–…â–…â–ƒâ–„â–‚â–„â–„â–…â–ƒâ–„â–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–…â–„â–ƒâ–„â–ƒâ–†â–…â–ƒâ–†â–†â–„â–â–…â–‚â–ƒâ–†â–ƒâ–ˆâ–ƒâ–ƒâ–…â–„â–†â–ƒâ–…â–‚â–ƒâ–„â–ˆâ–†â–ˆâ–†â–†â–ˆâ–ƒâ–„â–‡â–‚
wandb:       eval/ensemble_f1 â–ˆâ–â–…â–…â–„â–ƒâ–‡â–ˆâ–â–…â–ƒâ–â–„â–†â–…â–„â–…â–ƒâ–„â–‚â–ƒâ–‚â–„â–ˆâ–ƒâ–„â–†â–†â–‚â–†â–â–ƒâ–ƒâ–„â–‚â–ˆâ–ƒâ–‚â–‚â–…
wandb:           train/avg_f1 â–‡â–…â–…â–†â–…â–…â–…â–ˆâ–‡â–…â–†â–†â–†â–†â–„â–…â–†â–ˆâ–†â–†â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–‡â–…â–â–†â–„â–†â–†â–‡â–…â–†â–†â–…â–…
wandb:      train/ensemble_f1 â–‡â–…â–…â–†â–…â–…â–‡â–„â–†â–„â–†â–†â–„â–ƒâ–„â–„â–…â–ˆâ–†â–‡â–„â–„â–…â–‡â–‡â–…â–â–‡â–„â–‚â–†â–†â–†â–‡â–„â–ˆâ–†â–‡â–‡â–…
wandb:         train/mil_loss â–…â–…â–†â–†â–†â–†â–‡â–†â–„â–ˆâ–†â–‡â–†â–‡â–…â–…â–‡â–ƒâ–†â–‡â–ˆâ–„â–…â–ƒâ–…â–ˆâ–„â–„â–…â–„â–â–â–ƒâ–…â–…â–…â–…â–ˆâ–†â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.20738
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.878
wandb:      eval/avg_mil_loss 0.32053
wandb:       eval/ensemble_f1 0.878
wandb:           train/avg_f1 0.8871
wandb:      train/ensemble_f1 0.8871
wandb:         train/mil_loss 0.60271
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ax2l9u1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093449-6ax2l9u1/logs
wandb: ERROR Run 6ax2l9u1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3iiqvzd1 with config:
wandb: 	actor_learning_rate: 6.0336193319395275e-05
wandb: 	attention_dropout_p: 0.33294575265865406
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9546260289224212
wandb: 	temperature: 0.0978221277707214
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093621-3iiqvzd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3iiqvzd1
wandb: uploading history steps 52-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–…â–ƒâ–†â–‚â–‡â–‡â–‚â–„â–â–‚â–†â–ƒâ–‡â–„â–…â–‚â–‚â–„â–ƒâ–ƒâ–‚â–…â–„â–„â–ƒâ–ƒâ–ƒâ–†â–â–„â–†â–„â–ƒâ–„â–…â–„â–†â–ˆâ–‚
wandb:      eval/avg_mil_loss â–ƒâ–‡â–…â–…â–ˆâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–„â–„â–„â–‚â–‡â–‚â–…â–‚â–â–…â–‡â–ƒâ–†â–ƒâ–„â–ƒâ–„â–…â–„â–„â–…â–„â–â–‚â–‚â–„â–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–„â–ƒâ–…â–ƒâ–†â–‡â–‚â–…â–„â–‡â–…â–…â–†â–ƒâ–…â–‡â–†â–‡â–ƒâ–‡â–…â–â–„â–„â–„â–„â–…â–†â–ƒâ–†â–„â–†â–…â–†â–…â–†â–ˆâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–…â–ƒâ–â–„â–‚â–â–‚â–‡â–„â–…â–†â–„â–ƒâ–ƒâ–‚â–†â–…â–„â–ˆâ–ˆâ–â–…â–ƒâ–‡â–…â–„â–„â–ˆâ–„â–„â–…â–†â–ƒâ–„â–„â–„â–‚â–…
wandb:      train/ensemble_f1 â–ƒâ–†â–„â–…â–…â–ƒâ–â–ƒâ–„â–‚â–„â–‡â–„â–ƒâ–„â–…â–†â–ƒâ–…â–†â–†â–ˆâ–â–…â–ƒâ–…â–…â–„â–…â–ˆâ–„â–„â–„â–†â–ƒâ–„â–„â–‚â–†â–…
wandb:         train/mil_loss â–†â–‡â–…â–†â–„â–ƒâ–â–†â–„â–…â–†â–…â–‚â–â–„â–„â–…â–…â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–„â–‚â–‚â–‡â–‚â–‚â–ƒâ–„â–â–ƒâ–ƒâ–ˆâ–‚â–„â–†â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92587
wandb: best/eval_avg_mil_loss 0.27556
wandb:  best/eval_ensemble_f1 0.92587
wandb:            eval/avg_f1 0.88591
wandb:      eval/avg_mil_loss 0.25664
wandb:       eval/ensemble_f1 0.88591
wandb:            test/avg_f1 0.91989
wandb:      test/avg_mil_loss 0.1849
wandb:       test/ensemble_f1 0.91989
wandb:           train/avg_f1 0.89262
wandb:      train/ensemble_f1 0.89262
wandb:         train/mil_loss 0.24937
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run quiet-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3iiqvzd1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093621-3iiqvzd1/logs
wandb: Agent Starting Run: zwwd2g0t with config:
wandb: 	actor_learning_rate: 8.172950888168546e-05
wandb: 	attention_dropout_p: 0.2451022783524028
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.005497120722998905
wandb: 	temperature: 7.815955992879937
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093729-zwwd2g0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zwwd2g0t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–ˆâ–…
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–†â–†â–…â–†â–ˆâ–‡â–†â–ˆâ–†â–‡â–‡â–†â–†â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–…â–…â–†â–„â–‡â–…â–†â–†â–„â–ƒâ–ƒâ–„â–†â–â–…â–‚
wandb:      eval/avg_mil_loss â–‚â–ƒâ–â–ƒâ–„â–„â–„â–‚â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–…â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–„â–…â–‡â–†â–„â–†â–…â–†â–‡â–†â–‡â–ˆâ–‡â–ˆ
wandb:       eval/ensemble_f1 â–‡â–ˆâ–…â–ˆâ–…â–†â–…â–†â–…â–ˆâ–‡â–…â–…â–„â–†â–…â–†â–ƒâ–…â–„â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–â–‚â–â–
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–†â–†â–…â–†â–†â–…â–…â–†â–†â–†â–„â–„â–…â–…â–…â–„â–…â–„â–„â–‚â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–â–
wandb:      train/ensemble_f1 â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–‡â–†â–…â–…â–†â–„â–…â–…â–„â–„â–…â–„â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–‚â–â–â–
wandb:         train/mil_loss â–†â–‡â–ˆâ–†â–†â–…â–†â–…â–…â–†â–„â–ƒâ–…â–„â–„â–„â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–
wandb:      train/policy_loss â–â–„â–„â–„â–ˆâ–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–â–â–ˆâ–â–â–â–â–…â–ƒâ–â–â–â–â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–„â–†â–„â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91928
wandb: best/eval_avg_mil_loss 0.23701
wandb:  best/eval_ensemble_f1 0.91928
wandb:            eval/avg_f1 0.8354
wandb:      eval/avg_mil_loss 0.45513
wandb:       eval/ensemble_f1 0.8354
wandb:           train/avg_f1 0.81104
wandb:      train/ensemble_f1 0.81104
wandb:         train/mil_loss 0.20818
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fluent-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zwwd2g0t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093729-zwwd2g0t/logs
wandb: ERROR Run zwwd2g0t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7dsal07f with config:
wandb: 	actor_learning_rate: 0.0003263904793994719
wandb: 	attention_dropout_p: 0.4557638876767941
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 173
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6019343527860107
wandb: 	temperature: 6.481720202521149
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094014-7dsal07f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7dsal07f
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–†â–…â–‡â–‚â–â–„â–†â–‡â–…â–„â–‡â–‚â–ƒâ–ˆâ–†â–†â–…â–„â–ƒâ–…â–…â–…â–‚â–…â–ƒâ–…â–â–†â–†â–„â–†â–…â–„â–‚â–ƒâ–…â–…â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–…â–„â–„â–â–ƒâ–„â–„â–„â–ƒâ–…â–†â–‚â–‚â–„â–†â–„â–„â–„â–„â–…â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–„â–†â–ƒâ–„
wandb:       eval/ensemble_f1 â–ˆâ–…â–„â–†â–…â–‡â–„â–‡â–„â–…â–ƒâ–…â–ˆâ–â–†â–„â–„â–…â–„â–â–„â–ƒâ–â–„â–ƒâ–„â–ƒâ–†â–„â–ƒâ–…â–„â–…â–ƒâ–â–ƒâ–„â–…â–„â–…
wandb:           train/avg_f1 â–‡â–ƒâ–†â–‚â–„â–ƒâ–„â–†â–…â–‚â–ˆâ–„â–†â–…â–ƒâ–„â–…â–†â–ƒâ–†â–â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–â–‚â–ƒâ–ƒâ–„â–â–‚
wandb:      train/ensemble_f1 â–…â–…â–†â–…â–ƒâ–†â–„â–ƒâ–‡â–…â–ƒâ–ˆâ–„â–ƒâ–†â–‡â–…â–†â–„â–†â–„â–…â–ƒâ–†â–†â–ƒâ–„â–ƒâ–‡â–‡â–‚â–â–‚â–ƒâ–„â–„â–ƒâ–…â–„â–ƒ
wandb:         train/mil_loss â–†â–‡â–…â–ˆâ–†â–„â–†â–…â–ƒâ–†â–ˆâ–†â–…â–‡â–ˆâ–„â–„â–ƒâ–‡â–†â–„â–…â–„â–„â–‡â–„â–…â–…â–â–ƒâ–‚â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–„
wandb:      train/policy_loss â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–…â–‚â–â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.30122
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.87885
wandb:      eval/avg_mil_loss 0.28784
wandb:       eval/ensemble_f1 0.87885
wandb:           train/avg_f1 0.88493
wandb:      train/ensemble_f1 0.88493
wandb:         train/mil_loss 0.30667
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run neat-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7dsal07f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094014-7dsal07f/logs
wandb: ERROR Run 7dsal07f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qbqc0825 with config:
wandb: 	actor_learning_rate: 0.00020587923653031675
wandb: 	attention_dropout_p: 0.28783984161047044
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8509422790063299
wandb: 	temperature: 6.239407227940756
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094239-qbqc0825
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbqc0825
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–‚â–…â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–â–‚â–†â–‚â–‡â–ˆâ–„â–â–ƒâ–‚â–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–„â–‚â–…â–„â–†â–…â–ƒâ–ƒâ–‚â–†â–‡â–ƒâ–‚â–…â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–„â–ƒâ–â–†â–„â–‚â–‚â–…â–…â–‚â–†â–ƒâ–„â–ƒâ–…â–„â–…â–ƒâ–†â–ƒâ–…â–‚â–†â–…â–…â–‚â–…â–„â–‚â–†â–ˆâ–…â–„â–„â–†â–…â–‚
wandb:       eval/ensemble_f1 â–…â–†â–ƒâ–ƒâ–‚â–‚â–…â–…â–„â–‚â–…â–‡â–„â–â–†â–†â–†â–…â–…â–ƒâ–„â–…â–‚â–ƒâ–†â–„â–…â–ƒâ–ˆâ–ƒâ–„â–†â–„â–‡â–…â–…â–„â–‡â–ƒâ–‡
wandb:           train/avg_f1 â–‡â–‡â–…â–…â–‡â–„â–‡â–‡â–„â–…â–ƒâ–‡â–…â–‚â–†â–ˆâ–„â–†â–ƒâ–„â–ˆâ–„â–‚â–‡â–‡â–…â–†â–ˆâ–„â–‚â–†â–„â–‡â–â–†â–…â–ˆâ–…â–†â–‡
wandb:      train/ensemble_f1 â–„â–†â–ƒâ–…â–ƒâ–†â–‚â–†â–ƒâ–„â–â–„â–â–…â–ƒâ–ƒâ–ƒâ–ˆâ–…â–†â–ƒâ–ˆâ–‚â–…â–„â–‡â–‡â–„â–„â–†â–‡â–„â–ˆâ–â–†â–†â–ƒâ–„â–ˆâ–…
wandb:         train/mil_loss â–…â–„â–†â–ƒâ–ƒâ–…â–ƒâ–„â–†â–„â–ƒâ–„â–†â–†â–ˆâ–ƒâ–…â–†â–„â–ƒâ–‡â–†â–†â–‡â–‚â–‚â–…â–ƒâ–â–ƒâ–„â–†â–ƒâ–„â–‚â–…â–â–â–„â–„
wandb:      train/policy_loss â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–…â–â–ˆâ–…â–â–â–ˆâ–…â–â–…â–…â–…â–ˆâ–â–â–ˆâ–ˆâ–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–ˆâ–…â–â–…â–â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.23827
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.91087
wandb:      eval/avg_mil_loss 0.25382
wandb:       eval/ensemble_f1 0.91087
wandb:           train/avg_f1 0.89772
wandb:      train/ensemble_f1 0.89772
wandb:         train/mil_loss 0.24358
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbqc0825
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094239-qbqc0825/logs
wandb: ERROR Run qbqc0825 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ey2f0p4o with config:
wandb: 	actor_learning_rate: 8.022046324769785e-05
wandb: 	attention_dropout_p: 0.34711351975201377
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04016020947159116
wandb: 	temperature: 5.496406569391597
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094448-ey2f0p4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2f0p4o
wandb: uploading wandb-summary.json
wandb: uploading history steps 71-82, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–â–ˆâ–†â–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–…â–ƒâ–†â–ƒâ–†â–…â–…â–„â–„â–‡â–†â–‡â–…â–‚â–…â–â–†â–‡â–…â–…â–†â–‡â–†â–†â–‡â–…â–†â–„â–…â–†â–†â–â–†â–…â–ˆâ–†â–‡
wandb:      eval/avg_mil_loss â–„â–…â–‚â–„â–†â–„â–…â–„â–…â–ƒâ–…â–…â–…â–â–‚â–â–„â–†â–†â–„â–ƒâ–â–ƒâ–…â–„â–…â–†â–ƒâ–†â–†â–…â–ˆâ–…â–ˆâ–†â–†â–‡â–…â–†â–‡
wandb:       eval/ensemble_f1 â–†â–†â–†â–…â–…â–‡â–‡â–‡â–…â–…â–„â–ƒâ–…â–‡â–…â–†â–â–‡â–…â–ˆâ–†â–†â–†â–‡â–ˆâ–ƒâ–…â–…â–†â–…â–„â–ˆâ–†â–…â–„â–„â–‡â–ˆâ–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–…â–†â–„â–„â–„â–†â–ƒâ–†â–‚â–…â–†â–…â–…â–ƒâ–…â–‚â–‡â–‚â–ˆâ–…â–…â–…â–‚â–…â–„â–ƒâ–„â–ƒâ–…â–…â–ƒâ–„â–ƒâ–„â–†â–†â–…â–
wandb:      train/ensemble_f1 â–…â–‚â–„â–…â–‚â–„â–‡â–†â–„â–…â–…â–…â–‚â–…â–‚â–‚â–„â–ƒâ–…â–ˆâ–ƒâ–…â–‚â–‡â–‚â–ƒâ–„â–ƒâ–†â–â–ƒâ–ƒâ–„â–ƒâ–…â–…â–†â–†â–„â–
wandb:         train/mil_loss â–‡â–‡â–†â–‡â–…â–ƒâ–…â–„â–„â–„â–‡â–…â–‡â–†â–‡â–…â–„â–†â–„â–„â–ˆâ–ƒâ–…â–â–„â–‚â–„â–‡â–†â–…â–„â–„â–ƒâ–„â–„â–„â–‡â–„â–â–‡
wandb:      train/policy_loss â–â–…â–â–…â–â–…â–…â–…â–â–…â–ˆâ–â–â–ˆâ–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–â–…â–…â–â–…â–…â–â–…â–…â–ˆâ–…â–…â–â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.25908
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.91135
wandb:      eval/avg_mil_loss 0.21665
wandb:       eval/ensemble_f1 0.91135
wandb:            test/avg_f1 0.89792
wandb:      test/avg_mil_loss 0.18566
wandb:       test/ensemble_f1 0.89792
wandb:           train/avg_f1 0.87515
wandb:      train/ensemble_f1 0.87515
wandb:         train/mil_loss 0.29275
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2f0p4o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094448-ey2f0p4o/logs
wandb: Agent Starting Run: zvci1bny with config:
wandb: 	actor_learning_rate: 0.0001026209791553034
wandb: 	attention_dropout_p: 0.19534363339644423
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 115
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2846279194302449
wandb: 	temperature: 4.030196749501731
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094606-zvci1bny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvci1bny
wandb: uploading wandb-summary.json
wandb: uploading history steps 106-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–‡â–â–…â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–„â–†â–…â–…â–†â–„â–ƒâ–†â–„â–„â–„â–„â–„â–â–ƒâ–…â–‚â–…â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–†â–†â–…â–‚â–â–‚â–ˆâ–ƒâ–â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–„â–ƒâ–â–â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–â–„â–„â–…â–ƒâ–„â–ƒâ–‚â–„â–‚â–ƒâ–„â–‚â–â–â–ƒâ–„â–ƒâ–…â–â–‚â–ƒâ–„â–„â–‚
wandb:       eval/ensemble_f1 â–†â–„â–…â–‡â–‡â–…â–‚â–…â–†â–†â–†â–„â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–ƒâ–…â–†â–…â–„â–„â–ƒâ–„â–„â–†â–†â–„â–†â–‡â–â–„â–ˆâ–‚â–„
wandb:           train/avg_f1 â–ˆâ–…â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–†â–†â–…â–‡â–ˆâ–‡â–…â–…â–„â–‡â–‡â–…â–…â–ˆâ–‡â–ƒâ–†â–„â–…â–…â–†â–„â–…â–ƒâ–‡â–…â–…â–…â–â–†
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–ˆâ–…â–ƒâ–…â–ƒâ–„â–…â–„â–ƒâ–„â–…â–„â–„â–ƒâ–„â–„â–„â–†â–†â–…â–‡â–ƒâ–…â–„â–‚â–„â–„â–ƒâ–…â–ƒâ–„â–…â–…â–…â–â–‚
wandb:         train/mil_loss â–â–…â–…â–…â–…â–â–ƒâ–‡â–„â–‡â–„â–…â–‡â–ˆâ–…â–ˆâ–†â–„â–‡â–„â–…â–ƒâ–ƒâ–‡â–…â–…â–‚â–ƒâ–ˆâ–„â–ƒâ–‚â–†â–…â–‚â–ƒâ–„â–…â–†â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93016
wandb: best/eval_avg_mil_loss 0.28714
wandb:  best/eval_ensemble_f1 0.93016
wandb:            eval/avg_f1 0.87151
wandb:      eval/avg_mil_loss 0.41115
wandb:       eval/ensemble_f1 0.87151
wandb:           train/avg_f1 0.86803
wandb:      train/ensemble_f1 0.86803
wandb:         train/mil_loss 0.22449
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run soft-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvci1bny
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094606-zvci1bny/logs
wandb: ERROR Run zvci1bny errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jhdnrsh7 with config:
wandb: 	actor_learning_rate: 0.00015672400664063285
wandb: 	attention_dropout_p: 0.48101881267533814
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27538666133720613
wandb: 	temperature: 5.181600277241941
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094750-jhdnrsh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhdnrsh7
wandb: uploading history steps 147-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–‡â–…â–ƒâ–‡â–ˆâ–†â–…â–…â–…â–â–‡â–†â–…â–†â–„â–‡â–…â–…â–ˆâ–…â–„â–†â–†â–…â–…â–†â–…â–ƒâ–ˆâ–…â–„â–„â–„â–†â–‚â–„â–ƒâ–‚
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–…â–ƒâ–‡â–â–‚â–ƒâ–‚â–ƒâ–…â–„â–†â–…â–„â–‚â–†â–ƒâ–ƒâ–„â–…â–‚â–…â–ƒâ–…â–…â–ƒâ–ˆâ–…â–â–‚
wandb:       eval/ensemble_f1 â–„â–„â–‡â–…â–ˆâ–†â–ˆâ–†â–…â–†â–…â–†â–ƒâ–†â–„â–„â–†â–…â–†â–ƒâ–‡â–†â–†â–†â–…â–„â–…â–„â–ƒâ–…â–â–„â–„â–…â–†â–â–…â–ƒâ–„â–‚
wandb:           train/avg_f1 â–†â–‡â–ˆâ–‡â–†â–†â–‡â–‡â–…â–†â–†â–†â–†â–†â–…â–‡â–…â–…â–‡â–…â–…â–…â–…â–†â–†â–…â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–‚â–
wandb:      train/ensemble_f1 â–ˆâ–…â–†â–†â–„â–„â–…â–…â–…â–†â–‡â–„â–…â–…â–…â–‡â–„â–…â–‡â–…â–„â–„â–„â–‚â–„â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–‚â–„â–„â–â–ƒâ–‚â–ƒâ–
wandb:         train/mil_loss â–…â–ˆâ–…â–…â–„â–…â–„â–„â–„â–†â–†â–…â–ƒâ–„â–…â–…â–…â–„â–„â–„â–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–†â–â–â–â–â–â–â–‡â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.21393
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.89042
wandb:      eval/avg_mil_loss 0.22977
wandb:       eval/ensemble_f1 0.89042
wandb:           train/avg_f1 0.86215
wandb:      train/ensemble_f1 0.86215
wandb:         train/mil_loss 0.24348
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run good-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhdnrsh7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094750-jhdnrsh7/logs
wandb: ERROR Run jhdnrsh7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wo03ttnq with config:
wandb: 	actor_learning_rate: 1.482149595585085e-06
wandb: 	attention_dropout_p: 0.09561582200396151
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6370143107688649
wandb: 	temperature: 5.470459888133469
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095015-wo03ttnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo03ttnq
wandb: uploading history steps 131-146, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–…â–„â–â–‚â–ˆâ–ƒâ–‚â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–†â–‡â–‡â–†â–‡â–†â–…â–…â–†â–ƒâ–ˆâ–…â–ƒâ–†â–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–†â–…â–ƒâ–‡â–…â–„â–…â–…â–†â–‡â–‚â–‡â–ƒâ–„â–†â–ƒâ–â–
wandb:      eval/avg_mil_loss â–‚â–â–„â–ƒâ–…â–„â–â–„â–â–‚â–‚â–…â–‚â–…â–ƒâ–‚â–…â–„â–…â–…â–ƒâ–„â–‚â–†â–„â–…â–ƒâ–„â–ƒâ–‚â–…â–…â–‚â–†â–ˆâ–„â–…â–‚â–…â–…
wandb:       eval/ensemble_f1 â–†â–„â–†â–„â–…â–†â–‡â–„â–„â–„â–„â–„â–†â–ƒâ–„â–…â–‡â–‡â–ƒâ–‡â–„â–…â–…â–ˆâ–…â–…â–„â–†â–„â–…â–†â–‚â–…â–†â–ƒâ–…â–â–‚â–„â–…
wandb:           train/avg_f1 â–…â–†â–†â–‡â–‡â–…â–„â–†â–…â–„â–†â–†â–ƒâ–ˆâ–…â–…â–…â–„â–†â–„â–„â–ˆâ–…â–„â–ƒâ–…â–‡â–ƒâ–…â–…â–„â–…â–„â–‚â–ƒâ–â–‚â–„â–„â–‚
wandb:      train/ensemble_f1 â–‡â–ˆâ–„â–†â–ˆâ–…â–…â–‡â–†â–‡â–„â–†â–…â–†â–ƒâ–†â–…â–„â–„â–„â–ƒâ–ˆâ–…â–†â–ƒâ–†â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–â–ƒâ–‚
wandb:         train/mil_loss â–ˆâ–†â–‡â–…â–‡â–…â–„â–…â–…â–†â–„â–…â–…â–‚â–ƒâ–…â–…â–„â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–…â–â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–ˆâ–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9229
wandb: best/eval_avg_mil_loss 0.26486
wandb:  best/eval_ensemble_f1 0.9229
wandb:            eval/avg_f1 0.88668
wandb:      eval/avg_mil_loss 0.33366
wandb:       eval/ensemble_f1 0.88668
wandb:           train/avg_f1 0.8719
wandb:      train/ensemble_f1 0.8719
wandb:         train/mil_loss 0.21798
wandb:      train/policy_loss -0.11725
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.11725
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glorious-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo03ttnq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095015-wo03ttnq/logs
wandb: ERROR Run wo03ttnq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 26u0g4cf with config:
wandb: 	actor_learning_rate: 4.893322696718856e-06
wandb: 	attention_dropout_p: 0.4227824966335229
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5007798811829925
wandb: 	temperature: 0.2327282961999233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095234-26u0g4cf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26u0g4cf
wandb: uploading history steps 49-52, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–‚â–‚â–ƒâ–ƒâ–„â–â–‚â–‚â–‡â–‡â–†â–â–â–†â–„â–„â–„â–‡â–‚â–„â–â–‚â–„â–â–…â–â–‡â–‡â–‡â–…â–„â–…â–†â–ƒâ–„â–‚â–‡â–‚
wandb:      eval/avg_mil_loss â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–„â–„â–‚â–â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–â–‚
wandb:       eval/ensemble_f1 â–‡â–„â–ˆâ–‚â–ƒâ–ƒâ–„â–„â–‚â–‚â–‡â–‡â–†â–â–â–†â–†â–„â–„â–‡â–‚â–„â–â–‚â–„â–â–…â–â–‡â–‡â–‡â–…â–„â–„â–…â–ƒâ–ƒâ–‚â–‡â–‚
wandb:           train/avg_f1 â–‚â–„â–‚â–ƒâ–„â–ƒâ–„â–‡â–ƒâ–†â–â–„â–…â–â–†â–†â–‚â–„â–„â–†â–‚â–…â–…â–‡â–†â–‚â–ƒâ–…â–„â–†â–‡â–†â–†â–…â–ƒâ–…â–†â–‡â–†â–ˆ
wandb:      train/ensemble_f1 â–‚â–„â–‚â–ƒâ–…â–…â–ƒâ–„â–ƒâ–†â–â–„â–…â–â–…â–ˆâ–†â–‚â–„â–„â–…â–‡â–†â–ƒâ–‚â–…â–…â–„â–†â–†â–†â–†â–…â–ƒâ–ƒâ–…â–†â–‡â–†â–ˆ
wandb:         train/mil_loss â–…â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–ƒâ–…â–‡â–…â–‡â–‚â–„â–ˆâ–…â–ˆâ–„â–„â–‚â–…â–ˆâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–„â–…â–„â–„â–„â–ƒâ–â–„â–†
wandb:      train/policy_loss â–„â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92223
wandb: best/eval_avg_mil_loss 0.32209
wandb:  best/eval_ensemble_f1 0.92223
wandb:            eval/avg_f1 0.88575
wandb:      eval/avg_mil_loss 0.28919
wandb:       eval/ensemble_f1 0.88575
wandb:           train/avg_f1 0.90308
wandb:      train/ensemble_f1 0.90308
wandb:         train/mil_loss 0.33402
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26u0g4cf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095234-26u0g4cf/logs
wandb: ERROR Run 26u0g4cf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7kpgp8l3 with config:
wandb: 	actor_learning_rate: 1.685987179838432e-06
wandb: 	attention_dropout_p: 0.4065086460700109
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.749273350715882
wandb: 	temperature: 0.6150871150099491
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095326-7kpgp8l3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7kpgp8l3
wandb: uploading wandb-summary.json
wandb: uploading history steps 87-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–ˆâ–†â–‡â–†â–†â–†â–ƒâ–†â–†â–…â–‡â–…â–„â–„â–…â–â–…â–…â–†â–„â–„â–…â–ˆâ–†â–†â–ˆâ–‡â–ƒâ–…â–ƒâ–…â–…â–‚â–ƒâ–†â–ƒâ–†
wandb:      eval/avg_mil_loss â–‚â–ƒâ–‚â–ˆâ–ƒâ–‚â–‚â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…â–„â–ƒâ–ƒâ–„â–‚â–„â–„â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–â–„â–â–‚â–‚â–ƒâ–‚â–‚â–„â–
wandb:       eval/ensemble_f1 â–„â–ˆâ–†â–ƒâ–ƒâ–ˆâ–†â–…â–ƒâ–…â–†â–‡â–…â–„â–ƒâ–†â–†â–…â–…â–â–„â–„â–ƒâ–ƒâ–â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–…â–‡â–‡â–…â–…â–â–…â–‚â–„
wandb:           train/avg_f1 â–…â–…â–‡â–„â–…â–‡â–„â–…â–„â–„â–…â–…â–ƒâ–…â–â–„â–ˆâ–…â–‡â–…â–†â–†â–‚â–‚â–…â–„â–…â–‡â–ƒâ–‡â–„â–†â–…â–ƒâ–…â–…â–„â–…â–†â–
wandb:      train/ensemble_f1 â–†â–ƒâ–…â–„â–„â–‡â–…â–…â–„â–…â–†â–…â–…â–ƒâ–ƒâ–„â–ˆâ–…â–„â–…â–ˆâ–†â–‚â–„â–…â–ƒâ–„â–‡â–†â–‡â–„â–‡â–ƒâ–„â–†â–â–„â–…â–„â–„
wandb:         train/mil_loss â–†â–ƒâ–‡â–†â–ˆâ–„â–‚â–…â–„â–‡â–ƒâ–â–„â–ƒâ–†â–ƒâ–â–„â–†â–†â–„â–„â–ƒâ–ƒâ–„â–†â–…â–‚â–…â–†â–ƒâ–„â–„â–„â–‚â–ƒâ–„â–†â–„â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92644
wandb: best/eval_avg_mil_loss 0.26245
wandb:  best/eval_ensemble_f1 0.92644
wandb:            eval/avg_f1 0.9047
wandb:      eval/avg_mil_loss 0.22007
wandb:       eval/ensemble_f1 0.9047
wandb:           train/avg_f1 0.87123
wandb:      train/ensemble_f1 0.87123
wandb:         train/mil_loss 0.24748
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7kpgp8l3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095326-7kpgp8l3/logs
wandb: ERROR Run 7kpgp8l3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: crzf2x48 with config:
wandb: 	actor_learning_rate: 1.0945178284835757e-05
wandb: 	attention_dropout_p: 0.3079343858476582
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2257774795562426
wandb: 	temperature: 8.133558591766123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095459-crzf2x48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/crzf2x48
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–ˆâ–‡â–†â–…â–‡â–‡â–…â–…â–‡â–†â–†â–ˆâ–…â–…â–†â–„â–…â–…â–ƒâ–‡â–„â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–†â–„â–†â–ƒâ–‚â–ƒâ–†â–„â–â–…â–
wandb:      eval/avg_mil_loss â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–„â–ƒâ–…â–ˆâ–„â–ƒâ–…â–â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–†â–‚â–…â–‚â–‚â–‚â–†â–â–ƒâ–…â–ƒâ–…â–…â–†â–…â–…â–…â–†â–…
wandb:       eval/ensemble_f1 â–†â–‡â–ˆâ–‡â–ˆâ–‡â–…â–‡â–ˆâ–‡â–†â–„â–†â–‡â–†â–‡â–ƒâ–†â–„â–†â–„â–†â–„â–…â–‡â–ƒâ–‡â–‡â–†â–…â–„â–„â–…â–ƒâ–†â–‚â–…â–â–†â–‚
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–‡â–ˆâ–…â–ˆâ–†â–…â–†â–„â–†â–…â–†â–†â–‡â–…â–‡â–…â–…â–…â–‡â–†â–†â–…â–†â–ƒâ–…â–ƒâ–„â–…â–„â–„â–„â–„â–„â–â–„â–„â–
wandb:      train/ensemble_f1 â–…â–†â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–…â–†â–‡â–…â–„â–†â–‡â–…â–…â–†â–‡â–‡â–„â–…â–†â–„â–„â–…â–ƒâ–…â–†â–„â–„â–„â–„â–„â–ƒâ–â–‚â–„â–ƒ
wandb:         train/mil_loss â–†â–ˆâ–†â–†â–†â–†â–‡â–…â–…â–…â–„â–…â–„â–„â–„â–„â–…â–…â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–â–
wandb:      train/policy_loss â–„â–„â–„â–…â–„â–„â–‚â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–‡â–†â–â–‡â–„â–ƒâ–„â–„â–ˆâ–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–…â–â–…â–…â–ƒâ–…â–…â–ˆâ–…â–‚â–…â–…â–…â–â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91909
wandb: best/eval_avg_mil_loss 0.2586
wandb:  best/eval_ensemble_f1 0.91909
wandb:            eval/avg_f1 0.85036
wandb:      eval/avg_mil_loss 0.28898
wandb:       eval/ensemble_f1 0.85036
wandb:           train/avg_f1 0.85724
wandb:      train/ensemble_f1 0.85724
wandb:         train/mil_loss 0.20902
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run resilient-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/crzf2x48
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095459-crzf2x48/logs
wandb: ERROR Run crzf2x48 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qg8ji8fi with config:
wandb: 	actor_learning_rate: 9.674909852607551e-05
wandb: 	attention_dropout_p: 0.0847663004185501
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2152829714301745
wandb: 	temperature: 7.106268147648411
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095653-qg8ji8fi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qg8ji8fi
wandb: uploading history steps 188-192, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–…â–…â–‡â–ˆâ–â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–…â–†â–…â–ƒâ–â–â–ƒâ–…â–†â–ƒâ–„â–ƒâ–„â–„â–†â–„â–…â–…â–„â–†â–…â–„â–†â–„â–ƒâ–†â–„â–ˆâ–ƒâ–„â–†â–†â–…â–ˆâ–ƒâ–‚â–‡
wandb:      eval/avg_mil_loss â–ƒâ–‡â–…â–‚â–‚â–…â–‡â–†â–„â–‚â–‚â–†â–†â–ƒâ–†â–ƒâ–‚â–â–ƒâ–„â–‚â–…â–‚â–„â–†â–„â–â–‚â–‚â–†â–‚â–ƒâ–‡â–„â–„â–„â–†â–ˆâ–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–‚â–†â–ƒâ–…â–ƒâ–†â–ƒâ–†â–…â–†â–‚â–…â–ƒâ–„â–…â–ƒâ–‚â–†â–„â–ƒâ–†â–‡â–†â–‚â–†â–†â–â–†â–†â–†â–„â–†â–…â–„â–‡â–ˆâ–ƒâ–„â–†
wandb:           train/avg_f1 â–‡â–‚â–†â–…â–ˆâ–†â–†â–…â–„â–…â–†â–‡â–‡â–…â–â–†â–„â–‡â–…â–„â–‡â–‚â–„â–ƒâ–…â–ˆâ–ƒâ–‚â–†â–ƒâ–…â–ˆâ–„â–ƒâ–ƒâ–„â–†â–„â–†â–„
wandb:      train/ensemble_f1 â–†â–…â–‡â–…â–ƒâ–†â–‚â–†â–†â–…â–„â–„â–…â–ƒâ–†â–â–„â–‡â–„â–ƒâ–‡â–†â–ƒâ–‚â–‚â–ƒâ–ˆâ–ƒâ–„â–†â–†â–…â–…â–„â–‡â–…â–‡â–†â–†â–„
wandb:         train/mil_loss â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–†â–…â–…â–„â–…â–†â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–
wandb:      train/policy_loss â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.25217
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.9145
wandb:      eval/avg_mil_loss 0.26044
wandb:       eval/ensemble_f1 0.9145
wandb:           train/avg_f1 0.88896
wandb:      train/ensemble_f1 0.88896
wandb:         train/mil_loss 0.32868
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fine-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qg8ji8fi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095653-qg8ji8fi/logs
wandb: ERROR Run qg8ji8fi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 87b93str with config:
wandb: 	actor_learning_rate: 5.7915928615901246e-05
wandb: 	attention_dropout_p: 0.19629431921383375
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6091199012575789
wandb: 	temperature: 9.123435374067515
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100035-87b93str
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87b93str
wandb: uploading history steps 134-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–ˆâ–„â–…â–‡â–‡â–…â–„â–…â–†â–…â–„â–…â–‡â–†â–„â–ˆâ–„â–‡â–‚â–†â–‡â–…â–ˆâ–â–†â–ƒâ–„â–…â–„â–„â–„â–ƒâ–„â–†â–„â–ƒâ–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–â–…â–„â–ƒâ–„â–ƒâ–„â–†â–â–ƒâ–ƒâ–…â–‚â–…â–†â–ƒâ–‚â–„â–â–ƒâ–‡â–…â–…â–ƒâ–…â–‚â–„â–ƒâ–„â–‡â–„â–…â–ƒâ–ƒâ–„â–ƒâ–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–…â–„â–„â–„â–‡â–…â–â–„â–†â–…â–‡â–‡â–‡â–…â–†â–†â–ƒâ–„â–„â–‚â–…â–†â–‡â–ˆâ–ˆâ–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–†â–„â–ƒâ–†â–‚â–„
wandb:           train/avg_f1 â–…â–…â–„â–…â–‡â–…â–ˆâ–†â–„â–‡â–„â–ƒâ–…â–†â–ˆâ–†â–„â–„â–„â–…â–…â–„â–‡â–„â–…â–ƒâ–†â–…â–„â–…â–„â–†â–…â–„â–†â–…â–â–‚â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–…â–‡â–ˆâ–„â–â–„â–ƒâ–„â–†â–„â–†â–…â–‡â–ˆâ–…â–„â–…â–…â–‚â–‡â–…â–‡â–ƒâ–ƒâ–†â–„â–†â–„â–‚â–…â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–â–‚â–ƒ
wandb:         train/mil_loss â–ƒâ–ˆâ–†â–‡â–‡â–†â–†â–„â–…â–…â–†â–ƒâ–…â–†â–‡â–ˆâ–…â–„â–…â–…â–…â–ƒâ–„â–…â–„â–„â–„â–â–…â–„â–„â–ƒâ–„â–„â–‡â–…â–‚â–„â–„â–‚
wandb:      train/policy_loss â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.22714
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.89095
wandb:      eval/avg_mil_loss 0.30937
wandb:       eval/ensemble_f1 0.89095
wandb:           train/avg_f1 0.88149
wandb:      train/ensemble_f1 0.88149
wandb:         train/mil_loss 2.59772
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hardy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87b93str
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100035-87b93str/logs
wandb: ERROR Run 87b93str errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mekim345 with config:
wandb: 	actor_learning_rate: 0.0001662066765887502
wandb: 	attention_dropout_p: 0.07262205417677708
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4332492997270365
wandb: 	temperature: 0.8038691535585274
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100420-mekim345
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mekim345
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–„â–‚â–…â–ƒâ–…â–…â–â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–†â–†â–â–„â–ˆâ–„â–ƒâ–‚â–„â–„â–ƒâ–„â–‡â–„â–„â–…â–„â–ƒâ–…â–…â–…â–ƒâ–ƒâ–†
wandb:      eval/avg_mil_loss â–…â–…â–â–…â–ˆâ–ƒâ–†â–…â–…â–„â–ƒâ–‚â–â–ƒâ–ƒâ–…â–…â–…â–†â–…â–…â–„â–„â–†â–ƒâ–…â–„â–…â–„â–ƒâ–…â–†â–„â–†â–ƒâ–„â–ƒâ–‡â–…â–„
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–‚â–„â–…â–‚â–†â–„â–ƒâ–†â–†â–…â–…â–ƒâ–†â–„â–â–„â–„â–ƒâ–ƒâ–„â–…â–†â–†â–â–„â–„â–…â–ƒâ–ˆâ–‡â–ƒâ–…â–…â–‚â–ƒâ–…â–„â–„
wandb:           train/avg_f1 â–„â–…â–…â–„â–„â–…â–†â–â–‚â–„â–‡â–ƒâ–„â–…â–†â–„â–…â–ˆâ–†â–„â–„â–…â–ƒâ–…â–ƒâ–†â–…â–ƒâ–ƒâ–†â–…â–…â–†â–‚â–‚â–‡â–„â–ƒâ–„â–‚
wandb:      train/ensemble_f1 â–â–†â–†â–†â–†â–†â–ˆâ–‡â–…â–†â–…â–†â–…â–†â–‡â–‡â–†â–…â–‡â–†â–ˆâ–†â–‡â–‡â–…â–‡â–…â–‡â–†â–ˆâ–†â–…â–†â–ˆâ–ˆâ–‡â–‡â–…â–ˆâ–†
wandb:         train/mil_loss â–‡â–†â–‡â–†â–ˆâ–ˆâ–…â–„â–†â–„â–„â–†â–„â–„â–…â–ƒâ–„â–„â–„â–„â–„â–‚â–‚â–â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–ƒâ–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–â–†â–‚â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.31307
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.88859
wandb:      eval/avg_mil_loss 0.34847
wandb:       eval/ensemble_f1 0.88859
wandb:           train/avg_f1 0.87924
wandb:      train/ensemble_f1 0.87924
wandb:         train/mil_loss 0.76428
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run laced-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mekim345
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100420-mekim345/logs
wandb: ERROR Run mekim345 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: by5t8q58 with config:
wandb: 	actor_learning_rate: 1.2209926892360976e-06
wandb: 	attention_dropout_p: 0.25014049661966603
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 51
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2670301886825862
wandb: 	temperature: 6.19125712397963
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100558-by5t8q58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/by5t8q58
wandb: uploading wandb-summary.json
wandb: uploading history steps 48-52, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‡â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–‚â–†â–†â–†â–…â–„â–ˆâ–†â–„â–‡â–ƒâ–ƒâ–‡â–‡â–„â–…â–‡â–ƒâ–„â–…â–ˆâ–‚â–ƒâ–ƒâ–…â–ˆâ–ƒâ–ƒâ–„â–…â–‚â–…â–†â–…â–ˆâ–â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–‡â–…â–…â–…â–ƒâ–ƒâ–„â–…â–„â–„â–ƒâ–â–†â–â–†â–‚â–„â–…â–ƒâ–…â–…â–ƒâ–â–†â–‡â–…â–„â–ƒâ–„â–ƒâ–†â–ƒâ–‡â–„â–ƒâ–‚â–ˆâ–…
wandb:       eval/ensemble_f1 â–…â–„â–„â–‚â–†â–ƒâ–†â–…â–„â–ˆâ–†â–„â–‡â–ƒâ–ƒâ–…â–‡â–‡â–„â–…â–ƒâ–„â–…â–ˆâ–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–…â–‚â–…â–†â–…â–ˆâ–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–„â–‚â–…â–ƒâ–‚â–…â–„â–ƒâ–†â–‚â–…â–ˆâ–ˆâ–†â–ƒâ–ƒâ–„â–ˆâ–†â–â–‡â–†â–‡â–…â–‚â–‡â–ƒâ–„â–ƒâ–‡â–„â–„â–„â–…â–„â–…â–‚â–…â–‡
wandb:      train/ensemble_f1 â–â–ƒâ–‚â–…â–ƒâ–â–…â–ƒâ–†â–‚â–†â–…â–ˆâ–ˆâ–†â–‚â–ƒâ–ƒâ–†â–„â–‡â–…â–‡â–„â–†â–â–‡â–‚â–ƒâ–‚â–‡â–ƒâ–„â–ƒâ–…â–ƒâ–„â–â–„â–‡
wandb:         train/mil_loss â–…â–‡â–†â–„â–‚â–…â–ƒâ–‚â–„â–ˆâ–…â–…â–â–ƒâ–†â–„â–†â–„â–„â–†â–â–…â–â–…â–„â–‡â–„â–‚â–‡â–ƒâ–…â–„â–â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91873
wandb: best/eval_avg_mil_loss 0.23339
wandb:  best/eval_ensemble_f1 0.91873
wandb:            eval/avg_f1 0.89296
wandb:      eval/avg_mil_loss 0.30641
wandb:       eval/ensemble_f1 0.89296
wandb:            test/avg_f1 0.90521
wandb:      test/avg_mil_loss 0.19396
wandb:       test/ensemble_f1 0.90521
wandb:           train/avg_f1 0.90044
wandb:      train/ensemble_f1 0.90044
wandb:         train/mil_loss 0.25596
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run crisp-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/by5t8q58
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100558-by5t8q58/logs
wandb: Agent Starting Run: 9bfvg6bs with config:
wandb: 	actor_learning_rate: 0.00024479856229240693
wandb: 	attention_dropout_p: 0.2026519514749396
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11046662069375757
wandb: 	temperature: 1.6829499173084017
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100654-9bfvg6bs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bfvg6bs
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–‡â–‡â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–…â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–‡â–„â–„â–…â–„â–…â–„â–‡â–„â–ˆâ–…â–ƒâ–‡â–â–†â–…â–„â–…â–„â–‡â–…â–‡â–„â–†â–…â–…â–„â–…â–„â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–†â–‡â–…â–ƒâ–‚â–‚â–„â–‚â–ƒâ–†â–ƒâ–ƒâ–â–‚â–„â–„â–‡â–„â–â–ƒâ–„â–…â–…â–†â–ƒâ–‚â–„â–ƒâ–†â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‡
wandb:       eval/ensemble_f1 â–†â–†â–†â–„â–ƒâ–…â–†â–„â–…â–ƒâ–†â–…â–â–ˆâ–†â–…â–‚â–†â–…â–‡â–ˆâ–…â–†â–„â–ˆâ–‡â–„â–…â–†â–ƒâ–‡â–†â–‡â–…â–„â–†â–‡â–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–…â–…â–…â–„â–…â–„â–„â–„â–‚â–…â–â–†â–„â–ƒâ–â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–†â–„â–‚â–„â–„â–…â–„â–‡â–„â–„â–ƒâ–ƒâ–„â–†â–…â–â–…â–ƒ
wandb:      train/ensemble_f1 â–‚â–„â–‚â–…â–…â–„â–…â–ƒâ–…â–ƒâ–…â–„â–„â–„â–…â–‡â–ƒâ–ƒâ–‚â–‡â–â–…â–„â–„â–…â–ƒâ–ƒâ–ˆâ–„â–„â–…â–‚â–„â–ƒâ–†â–†â–…â–…â–†â–‡
wandb:         train/mil_loss â–ˆâ–…â–†â–„â–…â–…â–†â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–â–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.29701
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.8924
wandb:      eval/avg_mil_loss 0.27666
wandb:       eval/ensemble_f1 0.8924
wandb:            test/avg_f1 0.90768
wandb:      test/avg_mil_loss 0.20745
wandb:       test/ensemble_f1 0.90768
wandb:           train/avg_f1 0.90322
wandb:      train/ensemble_f1 0.90322
wandb:         train/mil_loss 0.40627
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bfvg6bs
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100654-9bfvg6bs/logs
wandb: Agent Starting Run: l1fwrpkm with config:
wandb: 	actor_learning_rate: 2.8318445229179417e-05
wandb: 	attention_dropout_p: 0.16325908529567484
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 179
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.005937386942896583
wandb: 	temperature: 8.767392516462833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100854-l1fwrpkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l1fwrpkm
wandb: uploading history steps 95-110, summary; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–…â–†â–ˆâ–†â–†â–…â–„â–„â–„â–„â–…â–„â–…â–„â–„â–†â–â–„â–‚â–„â–‚â–„â–„â–…â–‚â–…â–…â–‚â–„â–„â–„â–ƒâ–„â–†â–„â–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–…â–â–â–ƒâ–…â–‚â–â–„â–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–…â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–†â–„â–…â–„â–‚â–‡â–ƒâ–†â–†â–‚â–‚â–„â–‚â–ƒâ–…â–ƒ
wandb:       eval/ensemble_f1 â–†â–…â–ˆâ–…â–†â–†â–†â–…â–‡â–„â–„â–„â–…â–…â–…â–…â–…â–„â–…â–â–…â–„â–„â–ƒâ–…â–…â–…â–„â–„â–†â–‡â–†â–„â–„â–†â–„â–‚â–â–„â–…
wandb:           train/avg_f1 â–…â–†â–‡â–ƒâ–„â–…â–‡â–ƒâ–…â–…â–„â–„â–†â–ˆâ–…â–„â–‚â–‚â–‚â–„â–…â–ƒâ–„â–ƒâ–…â–ƒâ–„â–‚â–‡â–„â–…â–…â–†â–„â–„â–…â–ƒâ–â–‚â–‚
wandb:      train/ensemble_f1 â–†â–ˆâ–„â–…â–‡â–‡â–ˆâ–…â–‡â–‚â–„â–‡â–„â–‡â–†â–…â–„â–„â–„â–ˆâ–„â–ƒâ–…â–â–‚â–†â–„â–ƒâ–…â–‚â–„â–‚â–…â–‡â–ƒâ–ƒâ–…â–…â–‚â–ƒ
wandb:         train/mil_loss â–†â–„â–…â–…â–ˆâ–…â–†â–…â–…â–„â–†â–„â–‚â–‚â–„â–ƒâ–„â–…â–„â–…â–„â–…â–‚â–„â–†â–„â–…â–„â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–„
wandb:      train/policy_loss â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–„â–â–â–â–â–â–â–â–â–ƒâ–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–‡â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.22311
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.88291
wandb:      eval/avg_mil_loss 0.45726
wandb:       eval/ensemble_f1 0.88291
wandb:           train/avg_f1 0.87072
wandb:      train/ensemble_f1 0.87072
wandb:         train/mil_loss 0.21068
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run good-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l1fwrpkm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100854-l1fwrpkm/logs
wandb: ERROR Run l1fwrpkm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5fatw8w8 with config:
wandb: 	actor_learning_rate: 0.0008827112181241951
wandb: 	attention_dropout_p: 0.3926603763100705
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9968240992205856
wandb: 	temperature: 4.506110894514438
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101053-5fatw8w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5fatw8w8
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–†â–‡â–â–„â–ˆâ–‡
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–…â–‚â–…â–ƒâ–„â–ƒâ–†â–‚â–ƒâ–„â–†â–…â–…â–‚â–†â–‚â–†â–„â–†â–…â–ƒâ–‡â–…â–„â–‚â–‚â–†â–ƒâ–„â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–„â–‡â–â–ˆâ–†
wandb:      eval/avg_mil_loss â–„â–„â–„â–‡â–†â–‡â–ƒâ–„â–„â–ƒâ–‚â–â–…â–„â–…â–‚â–„â–ƒâ–‡â–„â–†â–„â–…â–ˆâ–‡â–…â–ƒâ–‚â–…â–ƒâ–†â–‚â–‡â–„â–ƒâ–…â–‚â–ƒâ–„â–
wandb:       eval/ensemble_f1 â–‚â–…â–‚â–‚â–…â–„â–†â–ƒâ–‚â–„â–…â–…â–‚â–„â–†â–†â–„â–†â–…â–…â–‡â–…â–‚â–„â–‚â–‚â–†â–ƒâ–„â–†â–‚â–†â–„â–ƒâ–ƒâ–‡â–â–ˆâ–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–…â–†â–…â–‡â–‚â–…â–‚â–‚â–…â–„â–ƒâ–„â–†â–…â–‡â–ƒâ–‡â–„â–ƒâ–„â–ˆâ–â–…â–†â–ƒâ–…â–†â–†â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–ƒâ–‚â–‚â–†
wandb:      train/ensemble_f1 â–â–†â–…â–†â–…â–ƒâ–‚â–…â–…â–‚â–…â–„â–„â–†â–…â–‡â–ƒâ–‡â–„â–ƒâ–„â–ˆâ–â–…â–‡â–ƒâ–…â–†â–†â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–„â–ƒâ–‚â–‚â–†
wandb:         train/mil_loss â–‡â–†â–†â–†â–…â–…â–„â–ƒâ–†â–†â–†â–ƒâ–†â–ƒâ–„â–†â–…â–…â–…â–„â–…â–…â–…â–†â–ˆâ–ƒâ–„â–ƒâ–…â–ˆâ–…â–…â–â–…â–ˆâ–ˆâ–„â–‡â–ƒâ–„
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.33147
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.91161
wandb:      eval/avg_mil_loss 0.2061
wandb:       eval/ensemble_f1 0.91161
wandb:            test/avg_f1 0.86514
wandb:      test/avg_mil_loss 0.30153
wandb:       test/ensemble_f1 0.86514
wandb:           train/avg_f1 0.89856
wandb:      train/ensemble_f1 0.89856
wandb:         train/mil_loss 0.26623
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5fatw8w8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101053-5fatw8w8/logs
wandb: Agent Starting Run: anzanutv with config:
wandb: 	actor_learning_rate: 1.054310584265415e-06
wandb: 	attention_dropout_p: 0.13397555118753313
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4268850196124411
wandb: 	temperature: 8.527511557694712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101150-anzanutv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/anzanutv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–ˆâ–†â–ˆâ–‡â–†â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–†â–…â–ƒâ–ƒâ–ƒâ–…â–‡â–ƒâ–…â–„â–‡â–…â–…â–†â–ˆâ–…â–‚â–„â–‡â–‚â–†â–…â–…â–†â–ƒâ–†â–‡â–‚â–„â–…â–…â–ƒâ–…â–â–…â–…â–…â–‚
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–‚â–â–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–„â–‚â–„â–‚â–ƒâ–„â–‚â–„â–„â–ƒâ–„â–‚â–ƒâ–…â–…â–ƒâ–…â–ƒâ–ˆâ–„
wandb:       eval/ensemble_f1 â–…â–„â–…â–ƒâ–†â–…â–…â–â–†â–†â–…â–ˆâ–ˆâ–„â–†â–ˆâ–ƒâ–†â–…â–ˆâ–‡â–…â–„â–†â–‡â–†â–†â–…â–…â–…â–†â–†â–†â–†â–…â–†â–…â–ƒâ–‚â–„
wandb:           train/avg_f1 â–…â–„â–†â–…â–…â–„â–‚â–„â–…â–‚â–…â–†â–…â–…â–…â–†â–„â–„â–„â–‚â–„â–ƒâ–…â–‡â–‡â–…â–…â–„â–ƒâ–‚â–†â–„â–„â–†â–â–ˆâ–ƒâ–‚â–„â–‚
wandb:      train/ensemble_f1 â–…â–…â–‡â–…â–…â–ˆâ–ƒâ–‡â–†â–†â–…â–…â–ƒâ–„â–…â–…â–â–„â–ˆâ–„â–„â–„â–…â–ƒâ–„â–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–†â–ƒâ–‚â–‡â–†â–
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–…â–†â–…â–‡â–…â–„â–‡â–…â–…â–…â–‡â–„â–„â–†â–†â–„â–„â–†â–‚â–…â–…â–„â–ƒâ–„â–†â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–â–
wandb:      train/policy_loss â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–„â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–‡â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.19951
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.88012
wandb:      eval/avg_mil_loss 0.29896
wandb:       eval/ensemble_f1 0.88012
wandb:           train/avg_f1 0.87748
wandb:      train/ensemble_f1 0.87748
wandb:         train/mil_loss 2.75611
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run scarlet-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/anzanutv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101150-anzanutv/logs
wandb: ERROR Run anzanutv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1t36wtxm with config:
wandb: 	actor_learning_rate: 2.0252761989765538e-06
wandb: 	attention_dropout_p: 0.06833007079509135
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0012800999450944817
wandb: 	temperature: 4.550482926145422
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101425-1t36wtxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t36wtxm
wandb: uploading wandb-summary.json
wandb: uploading history steps 184-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–†â–„â–…â–†â–â–ˆâ–„â–„
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–†â–„â–…â–ˆâ–…â–…â–‡â–…â–ƒâ–…â–‡â–…â–â–…â–ˆâ–…â–…â–‡â–†â–…â–…â–…â–…â–†â–…â–†â–‡â–ƒâ–…â–†â–†â–ˆâ–…â–†â–„â–…â–ˆâ–„
wandb:      eval/avg_mil_loss â–ƒâ–‡â–ƒâ–‚â–…â–„â–„â–‡â–„â–â–‚â–ƒâ–„â–†â–ƒâ–…â–ƒâ–„â–‚â–†â–‡â–ƒâ–‚â–„â–†â–ˆâ–†â–…â–„â–‚â–ƒâ–ƒâ–…â–‚â–†â–‚â–†â–ƒâ–„â–‚
wandb:       eval/ensemble_f1 â–…â–…â–ƒâ–‚â–â–„â–‚â–â–„â–„â–ˆâ–â–â–†â–„â–†â–„â–„â–ƒâ–ƒâ–ƒâ–„â–†â–†â–„â–‡â–ƒâ–„â–„â–ˆâ–…â–†â–…â–„â–…â–…â–ƒâ–…â–‡â–„
wandb:           train/avg_f1 â–„â–ƒâ–‚â–…â–ƒâ–†â–†â–…â–ƒâ–„â–†â–ƒâ–‡â–…â–†â–„â–„â–…â–†â–†â–…â–…â–…â–„â–ƒâ–†â–†â–ˆâ–â–‡â–„â–„â–…â–…â–…â–…â–…â–ƒâ–‡â–†
wandb:      train/ensemble_f1 â–ƒâ–…â–…â–„â–ˆâ–ƒâ–„â–„â–ˆâ–…â–„â–†â–‚â–…â–‚â–ƒâ–…â–â–„â–…â–‡â–„â–ƒâ–‚â–…â–‡â–ˆâ–„â–„â–‚â–‚â–†â–†â–†â–…â–ƒâ–„â–†â–†â–…
wandb:         train/mil_loss â–†â–‡â–…â–†â–„â–ˆâ–‡â–‡â–‡â–ˆâ–ƒâ–„â–…â–…â–„â–ƒâ–‚â–…â–„â–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–ƒâ–†â–…â–ƒâ–†â–‚â–‡â–â–ƒâ–…â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–ˆâ–„â–„â–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–â–„â–â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–â–â–â–„â–„â–„â–„â–ˆâ–â–„â–ˆâ–„â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.3057
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.91524
wandb:      eval/avg_mil_loss 0.39622
wandb:       eval/ensemble_f1 0.91524
wandb:           train/avg_f1 0.89448
wandb:      train/ensemble_f1 0.89448
wandb:         train/mil_loss 0.30514
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run genial-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t36wtxm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101425-1t36wtxm/logs
wandb: ERROR Run 1t36wtxm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4iirqa2k with config:
wandb: 	actor_learning_rate: 2.8467004443237855e-05
wandb: 	attention_dropout_p: 0.3508465517921494
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10477265713731589
wandb: 	temperature: 0.810879137046403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101721-4iirqa2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4iirqa2k
wandb: uploading history steps 67-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–„â–‡â–ˆâ–†â–‡â–„â–†â–„â–‡â–†â–†â–…â–ƒâ–…â–†â–†â–†â–†â–„â–…â–„â–„â–ˆâ–†â–‡â–ƒâ–‡â–„â–…â–…â–„â–„â–â–„â–†â–ƒâ–‡â–…
wandb:      eval/avg_mil_loss â–„â–‚â–…â–„â–‚â–„â–‚â–ƒâ–ƒâ–„â–„â–…â–â–ƒâ–…â–â–…â–ƒâ–â–…â–„â–ƒâ–…â–ƒâ–†â–…â–…â–†â–…â–†â–„â–‡â–…â–†â–‚â–ˆâ–ƒâ–†â–ƒâ–‡
wandb:       eval/ensemble_f1 â–ˆâ–‡â–„â–†â–…â–‡â–„â–‡â–„â–ˆâ–ƒâ–„â–†â–†â–†â–„â–ƒâ–…â–…â–†â–†â–ˆâ–„â–‡â–„â–ˆâ–ƒâ–‡â–‡â–‡â–…â–…â–…â–„â–â–ƒâ–‡â–‡â–…â–„
wandb:           train/avg_f1 â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–„â–†â–‡â–†â–†â–„â–†â–„â–„â–†â–„â–…â–…â–„â–„â–„â–…â–ƒâ–„â–ƒâ–„â–‡â–„â–ƒâ–…â–ƒâ–‚â–‚â–â–ƒâ–‚
wandb:      train/ensemble_f1 â–ˆâ–‡â–‡â–„â–ˆâ–‡â–ˆâ–ˆâ–„â–…â–†â–„â–‡â–‡â–ˆâ–ˆâ–‡â–…â–„â–†â–ƒâ–„â–†â–†â–„â–…â–…â–…â–ƒâ–†â–ƒâ–â–…â–ƒâ–â–â–‚â–„â–â–„
wandb:         train/mil_loss â–…â–ˆâ–‡â–†â–‡â–…â–ƒâ–†â–„â–…â–†â–‡â–†â–…â–„â–†â–„â–…â–„â–…â–‡â–ƒâ–…â–„â–„â–‚â–„â–†â–ƒâ–ƒâ–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–â–…â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–‚â–…â–…â–†â–…â–…â–…â–‚â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.2229
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.89014
wandb:      eval/avg_mil_loss 0.31315
wandb:       eval/ensemble_f1 0.89014
wandb:           train/avg_f1 0.86354
wandb:      train/ensemble_f1 0.86354
wandb:         train/mil_loss 0.26591
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4iirqa2k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101721-4iirqa2k/logs
wandb: ERROR Run 4iirqa2k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mfnjwwxb with config:
wandb: 	actor_learning_rate: 1.0827499651812607e-06
wandb: 	attention_dropout_p: 0.3507496930923853
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 161
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1592774272580989
wandb: 	temperature: 2.893104958767684
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101854-mfnjwwxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mfnjwwxb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–„â–…â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–„â–ˆâ–â–†â–‚â–â–ƒâ–†â–ƒâ–…â–„â–ƒâ–†â–†â–‚â–ƒâ–â–„â–‚â–‚â–…â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–†â–…â–„â–†â–ƒâ–‚â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–‚â–ˆâ–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–…â–…â–‚â–ˆâ–ƒâ–„â–‚â–„â–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–„â–‚â–‚â–†â–ƒâ–„â–ƒâ–„â–‚â–â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–…â–…â–†â–„â–…â–ƒâ–ˆâ–ˆâ–„â–„â–…â–…â–…â–‡â–â–…â–â–‚â–„â–‚â–‡â–…â–‡â–…â–‚â–…â–‡â–†â–ƒâ–‚â–…â–†â–…â–ˆâ–…â–ƒâ–‡
wandb:           train/avg_f1 â–„â–…â–ƒâ–â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–‚â–…â–‚â–„â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–„â–â–ƒâ–‚â–…â–â–ˆâ–†â–…â–ƒâ–„â–…â–…â–…â–‚
wandb:      train/ensemble_f1 â–ƒâ–„â–†â–ƒâ–„â–…â–„â–„â–„â–ƒâ–ƒâ–…â–…â–„â–„â–‚â–†â–ƒâ–…â–…â–ˆâ–…â–‡â–„â–…â–†â–„â–†â–…â–„â–ˆâ–‡â–…â–„â–…â–†â–†â–…â–„â–
wandb:         train/mil_loss â–…â–‡â–†â–‡â–‚â–‚â–„â–‡â–„â–…â–ˆâ–†â–„â–„â–ƒâ–…â–‡â–†â–„â–‚â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–†â–…â–…â–†â–…â–„â–†â–‡â–…â–â–…â–‚
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93725
wandb: best/eval_avg_mil_loss 0.34053
wandb:  best/eval_ensemble_f1 0.93725
wandb:            eval/avg_f1 0.90786
wandb:      eval/avg_mil_loss 0.28973
wandb:       eval/ensemble_f1 0.90786
wandb:           train/avg_f1 0.87697
wandb:      train/ensemble_f1 0.87697
wandb:         train/mil_loss 2.92337
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rose-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mfnjwwxb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101854-mfnjwwxb/logs
wandb: ERROR Run mfnjwwxb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: vplm0yvv with config:
wandb: 	actor_learning_rate: 0.0007795534551381014
wandb: 	attention_dropout_p: 0.31247235267933215
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13530877223115567
wandb: 	temperature: 3.039838918568447
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102048-vplm0yvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vplm0yvv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–ƒâ–„â–„â–…â–ƒâ–…â–â–ƒâ–â–…â–„â–…â–†â–ˆâ–ƒâ–ƒâ–ˆâ–…â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–„â–‚â–…â–„â–‡â–ƒâ–â–ˆâ–ƒâ–ƒâ–‡â–„â–…â–„â–ƒâ–„â–ƒâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–„â–†â–„â–„â–‡â–ˆâ–…â–‡â–…â–„â–ƒâ–„â–‚â–‡â–ƒ
wandb:       eval/ensemble_f1 â–†â–†â–…â–†â–…â–‡â–ƒâ–ƒâ–„â–ƒâ–†â–…â–†â–„â–‡â–‡â–…â–†â–†â–†â–…â–„â–„â–ˆâ–†â–†â–„â–…â–…â–„â–„â–â–…â–…â–…â–…â–ƒâ–…â–„â–†
wandb:           train/avg_f1 â–‡â–…â–†â–„â–ƒâ–‡â–ˆâ–„â–…â–ƒâ–‚â–„â–„â–…â–â–…â–â–‚â–†â–…â–„â–†â–„â–…â–„â–„â–â–‚â–‚â–„â–„â–…â–„â–ƒâ–„â–„â–‚â–ƒâ–„â–„
wandb:      train/ensemble_f1 â–„â–ˆâ–‚â–†â–…â–ƒâ–‚â–„â–„â–â–…â–â–â–â–„â–†â–…â–„â–…â–†â–‚â–…â–…â–…â–…â–„â–‚â–‡â–‚â–ƒâ–„â–†â–„â–…â–‡â–ƒâ–…â–…â–„â–„
wandb:         train/mil_loss â–ƒâ–„â–„â–ˆâ–ƒâ–ƒâ–…â–â–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–‚â–„â–â–…â–ƒâ–…â–„â–â–‚â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–â–â–ƒâ–„â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93007
wandb: best/eval_avg_mil_loss 0.25223
wandb:  best/eval_ensemble_f1 0.93007
wandb:            eval/avg_f1 0.90449
wandb:      eval/avg_mil_loss 0.26292
wandb:       eval/ensemble_f1 0.90449
wandb:           train/avg_f1 0.88218
wandb:      train/ensemble_f1 0.88218
wandb:         train/mil_loss 0.22211
wandb:      train/policy_loss 0.06682
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.06682
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run charmed-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vplm0yvv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102048-vplm0yvv/logs
wandb: ERROR Run vplm0yvv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1uiu5bpk with config:
wandb: 	actor_learning_rate: 0.0002288451775098652
wandb: 	attention_dropout_p: 0.0639371857524238
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4966236237170194
wandb: 	temperature: 3.689211808165125
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102314-1uiu5bpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/j8anb0nv
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1uiu5bpk
wandb: uploading history steps 77-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–†â–â–„â–ƒâ–„â–„â–„â–…â–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–‚â–…â–‡â–…â–†â–…â–ƒâ–…â–…â–…â–„â–…â–„â–…â–„â–ƒâ–„â–†â–…â–ˆâ–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–‡â–â–‡â–ƒâ–…â–„â–‚â–…â–„â–‚â–ƒâ–…â–†â–â–ƒâ–…â–ˆâ–‚â–…â–‚â–‚â–…â–ƒâ–‡â–ƒâ–„â–…â–ƒâ–„â–ƒâ–„â–„â–…â–„â–„â–„â–„â–…â–†â–ƒ
wandb:       eval/ensemble_f1 â–‡â–ƒâ–…â–ƒâ–…â–‡â–‚â–ˆâ–ƒâ–…â–ƒâ–‡â–†â–„â–ƒâ–†â–ˆâ–„â–â–…â–„â–‡â–†â–‚â–…â–†â–…â–‡â–„â–…â–‡â–…â–‡â–†â–†â–†â–„â–‡â–…â–†
wandb:           train/avg_f1 â–„â–†â–…â–ƒâ–…â–†â–„â–„â–†â–ˆâ–„â–…â–„â–„â–â–‡â–†â–ƒâ–†â–ƒâ–â–ƒâ–…â–„â–ˆâ–‡â–…â–†â–†â–…â–…â–ƒâ–†â–…â–„â–†â–â–„â–ƒâ–†
wandb:      train/ensemble_f1 â–ˆâ–…â–‚â–„â–‡â–„â–…â–ˆâ–‡â–„â–†â–„â–†â–…â–â–‡â–†â–ƒâ–‡â–†â–„â–ƒâ–â–ƒâ–ƒâ–ˆâ–…â–‡â–…â–†â–…â–…â–‡â–…â–ƒâ–…â–†â–‡â–…â–†
wandb:         train/mil_loss â–ˆâ–†â–…â–‡â–‡â–…â–‡â–†â–ƒâ–‡â–„â–‚â–ˆâ–†â–„â–…â–…â–„â–ƒâ–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–â–â–‡â–„â–„â–„â–„â–‚
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–‚â–ˆâ–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93715
wandb: best/eval_avg_mil_loss 0.27892
wandb:  best/eval_ensemble_f1 0.93715
wandb:            eval/avg_f1 0.89657
wandb:      eval/avg_mil_loss 0.32469
wandb:       eval/ensemble_f1 0.89657
wandb:           train/avg_f1 0.89736
wandb:      train/ensemble_f1 0.89736
wandb:         train/mil_loss 0.24612
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earthy-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1uiu5bpk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102314-1uiu5bpk/logs
wandb: ERROR Run 1uiu5bpk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
