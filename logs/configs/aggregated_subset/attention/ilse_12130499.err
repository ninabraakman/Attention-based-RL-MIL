wandb: Agent Starting Run: 0yc9vqwq with config:
wandb: 	actor_learning_rate: 6.291062752571662e-05
wandb: 	attention_dropout_p: 0.35953906711409
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44035924211942334
wandb: 	temperature: 0.5902833941900287
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041839-0yc9vqwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 129-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ƒâ–ˆâ–ƒâ–†â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–†â–ƒâ–…â–„â–†â–ƒâ–ƒâ–ˆâ–†â–‚â–†â–‡â–„â–„â–‡â–ƒâ–…â–†â–‡â–â–…â–„â–†â–ƒâ–…â–ˆâ–†â–ƒâ–„â–†â–„â–„â–„â–‚â–„â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–‚â–ˆâ–ƒâ–…â–‚â–‚â–†â–„â–…â–‚â–„â–‚â–â–„â–†â–„â–‚â–†â–„â–„â–…â–„â–…â–â–ƒâ–‚â–…â–â–…â–„â–…â–…â–…â–…â–…â–‡â–„â–„â–†â–‚
wandb:       eval/ensemble_f1 â–„â–…â–…â–ƒâ–†â–„â–„â–„â–…â–ƒâ–‡â–„â–ˆâ–†â–…â–†â–‡â–†â–ƒâ–†â–„â–…â–„â–ƒâ–„â–ƒâ–â–†â–ˆâ–ƒâ–…â–â–ƒâ–„â–†â–„â–ƒâ–ƒâ–ƒâ–„
wandb:           train/avg_f1 â–„â–…â–„â–†â–„â–„â–…â–…â–„â–†â–„â–‡â–†â–ˆâ–†â–…â–‚â–…â–ƒâ–†â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–â–…
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–‡â–‚â–…â–…â–†â–„â–‡â–†â–†â–‡â–â–â–ˆâ–„â–…â–â–†â–ƒâ–ƒâ–…â–…â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–…â–â–†
wandb:         train/mil_loss â–†â–†â–„â–‡â–…â–‡â–†â–„â–…â–…â–ˆâ–…â–‡â–„â–…â–†â–‡â–…â–†â–„â–…â–…â–…â–„â–„â–„â–â–â–„â–…â–…â–„â–„â–‚â–†â–‚â–„â–„â–…â–‚
wandb:      train/policy_loss â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–…â–†â–ˆâ–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91524
wandb: best/eval_avg_mil_loss 0.26847
wandb:  best/eval_ensemble_f1 0.91524
wandb:            eval/avg_f1 0.88281
wandb:      eval/avg_mil_loss 0.42302
wandb:       eval/ensemble_f1 0.88281
wandb:           train/avg_f1 0.86567
wandb:      train/ensemble_f1 0.86567
wandb:         train/mil_loss 0.25463
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run astral-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0yc9vqwq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041839-0yc9vqwq/logs
wandb: ERROR Run 0yc9vqwq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: an72l9ma with config:
wandb: 	actor_learning_rate: 1.1125310993939654e-06
wandb: 	attention_dropout_p: 0.04370361774402004
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26249674594713335
wandb: 	temperature: 9.650019794208673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042033-an72l9ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–„â–„â–…â–ˆâ–‡â–…â–…â–ƒâ–â–‚â–‚â–ˆâ–†â–ƒâ–„â–…â–†â–„â–…â–„â–…â–†â–‡â–…â–‡â–ƒâ–ƒâ–‚â–…â–„â–‡â–ƒâ–ƒâ–„â–…â–…â–…â–„â–†â–…
wandb:      eval/avg_mil_loss â–†â–‚â–†â–…â–…â–…â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–…â–ƒâ–„â–„â–„â–ƒâ–…â–„â–„â–‚â–‚â–„â–â–†â–‚â–„â–…â–…â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–†
wandb:       eval/ensemble_f1 â–ˆâ–„â–‡â–„â–…â–‚â–ƒâ–„â–…â–‚â–„â–ƒâ–„â–…â–„â–…â–†â–…â–ƒâ–†â–ˆâ–ƒâ–†â–‡â–ƒâ–„â–ƒâ–ƒâ–„â–…â–ƒâ–„â–†â–‚â–ƒâ–…â–†â–ƒâ–â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–ƒâ–‚â–„â–…â–…â–…â–…â–„â–â–„â–…â–„â–…â–…â–…â–ƒâ–‚â–„â–„â–†â–ƒâ–‚â–‚â–ˆâ–†â–†â–„â–‚â–†â–†â–„â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–…â–„â–…â–…â–…â–…â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–â–ˆâ–†â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–„â–…â–‚â–†â–…â–„
wandb:         train/mil_loss â–‡â–ˆâ–ƒâ–…â–„â–†â–†â–ƒâ–„â–„â–…â–ƒâ–…â–â–ƒâ–†â–„â–‡â–„â–…â–…â–…â–„â–†â–„â–…â–„â–„â–†â–†â–„â–ƒâ–…â–ˆâ–„â–…â–‡â–„â–…â–…
wandb:      train/policy_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–…â–ƒâ–…â–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.25666
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.88652
wandb:      eval/avg_mil_loss 0.35512
wandb:       eval/ensemble_f1 0.88652
wandb:            test/avg_f1 0.91226
wandb:      test/avg_mil_loss 0.22796
wandb:       test/ensemble_f1 0.91226
wandb:           train/avg_f1 0.88262
wandb:      train/ensemble_f1 0.88262
wandb:         train/mil_loss 0.2169
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run colorful-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/an72l9ma
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042033-an72l9ma/logs
wandb: Agent Starting Run: 78ut9eu7 with config:
wandb: 	actor_learning_rate: 2.6288586164078054e-06
wandb: 	attention_dropout_p: 0.03528171558985249
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8554459419204408
wandb: 	temperature: 4.0724431285983815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042206-78ut9eu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: uploading wandb-summary.json
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–…â–‚â–â–…â–ƒâ–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–‡â–ˆâ–„â–…â–â–ƒâ–„â–‡â–„â–†â–…â–‡â–†â–‡â–‡â–†â–…â–†â–†â–†â–‡â–†â–„â–‡â–…â–…â–‡â–†â–…â–‚â–‡â–†â–„â–ˆâ–†â–ƒâ–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–…â–„â–â–‚â–„â–„â–„â–‚â–ˆâ–„â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‡â–„â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„
wandb:       eval/ensemble_f1 â–ƒâ–‚â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–„â–…â–†â–‡â–ƒâ–…â–ƒâ–â–…â–…â–†â–â–ƒâ–…â–„â–†â–ƒâ–…â–†â–ƒâ–ƒâ–…â–†â–†â–…â–ˆâ–‚
wandb:           train/avg_f1 â–ƒâ–…â–„â–…â–„â–…â–†â–„â–†â–â–…â–„â–„â–…â–„â–ƒâ–„â–…â–„â–ƒâ–…â–„â–„â–ƒâ–ƒâ–…â–…â–ƒâ–…â–…â–…â–…â–†â–†â–„â–…â–ˆâ–„â–ƒâ–…
wandb:      train/ensemble_f1 â–†â–„â–ƒâ–‡â–†â–…â–„â–‚â–…â–‡â–†â–†â–â–†â–‚â–…â–ˆâ–„â–†â–‡â–‚â–†â–…â–„â–„â–‡â–„â–…â–…â–„â–‡â–ƒâ–…â–ˆâ–†â–†â–‡â–…â–†â–†
wandb:         train/mil_loss â–‡â–†â–†â–ˆâ–ˆâ–†â–†â–‡â–…â–‡â–…â–‡â–„â–„â–†â–‡â–†â–†â–…â–„â–„â–„â–„â–†â–†â–ƒâ–„â–â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–
wandb:      train/policy_loss â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–†â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.32327
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.86343
wandb:      eval/avg_mil_loss 0.41759
wandb:       eval/ensemble_f1 0.86343
wandb:           train/avg_f1 0.8833
wandb:      train/ensemble_f1 0.8833
wandb:         train/mil_loss 0.84831
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78ut9eu7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042206-78ut9eu7/logs
wandb: ERROR Run 78ut9eu7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: t5pg820r with config:
wandb: 	actor_learning_rate: 0.00011500806257085972
wandb: 	attention_dropout_p: 0.20852219208274136
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5510767760005835
wandb: 	temperature: 5.2847969509308115
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042436-t5pg820r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: uploading history steps 119-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–†â–„â–„â–‡â–ˆâ–ˆâ–„â–„â–ƒâ–ƒâ–„â–‡â–„â–‚â–…â–„â–ƒâ–ˆâ–…â–„â–…â–â–‚â–…â–„â–†â–‡â–â–…â–‚â–„â–…â–â–â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–ˆâ–‚â–„â–ƒâ–„â–‡â–†â–â–‡â–ƒâ–ˆâ–ƒâ–…â–†â–‚â–ƒâ–„â–‡â–„â–…â–†â–‡â–†â–ƒâ–†â–‚â–†â–‡â–†â–†â–†â–…
wandb:       eval/ensemble_f1 â–†â–†â–…â–†â–†â–„â–„â–‡â–ˆâ–ƒâ–…â–†â–„â–„â–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–â–‚â–…â–„â–„â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–„â–‚â–„â–†
wandb:           train/avg_f1 â–‡â–‡â–‡â–†â–ˆâ–…â–‡â–…â–‡â–ˆâ–‡â–†â–„â–…â–…â–…â–‚â–…â–â–ƒâ–…â–ƒâ–…â–„â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–ƒâ–…â–…â–„â–ƒâ–ƒâ–ƒâ–
wandb:      train/ensemble_f1 â–ˆâ–‡â–ˆâ–‡â–…â–‡â–‡â–‡â–…â–ˆâ–†â–‡â–†â–„â–…â–…â–…â–ƒâ–„â–ƒâ–„â–…â–‚â–…â–â–ƒâ–†â–ƒâ–„â–„â–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–„
wandb:         train/mil_loss â–‡â–ˆâ–‡â–‡â–‡â–ƒâ–…â–†â–ƒâ–…â–‡â–„â–â–â–ƒâ–ƒâ–‚â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–„â–„â–„â–ƒâ–„â–„â–„â–„â–†â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–ƒâ–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91203
wandb: best/eval_avg_mil_loss 0.24921
wandb:  best/eval_ensemble_f1 0.91203
wandb:            eval/avg_f1 0.89405
wandb:      eval/avg_mil_loss 0.3178
wandb:       eval/ensemble_f1 0.89405
wandb:           train/avg_f1 0.86448
wandb:      train/ensemble_f1 0.86448
wandb:         train/mil_loss 0.21083
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t5pg820r
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042436-t5pg820r/logs
wandb: ERROR Run t5pg820r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: upg3ueh6 with config:
wandb: 	actor_learning_rate: 1.8125674829039468e-06
wandb: 	attention_dropout_p: 0.07792873795977151
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29278472409294976
wandb: 	temperature: 8.439462172260537
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042700-upg3ueh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/mjcbrctw
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upg3ueh6
