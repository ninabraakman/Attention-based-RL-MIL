wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/validate": read tcp 10.54.18.4:50674->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Agent Starting Run: zqb0317q with config:
wandb: 	actor_learning_rate: 0.0003611871497378264
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8418804767901192
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041715-zqb0317q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqb0317q
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 162-181, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–…â–…â–‚â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‡â–‡â–†â–ˆâ–‚â–‡â–‚â–„â–‡â–ˆâ–‚â–â–‡â–„â–†â–†â–ƒâ–†â–‡â–ˆâ–‡â–ˆâ–‚â–â–ˆâ–ˆâ–‡â–…â–ƒâ–„â–‚â–ˆâ–‡â–‡â–‚â–‡â–‡â–‚â–
wandb:      eval/avg_mil_loss â–‡â–ƒâ–„â–„â–„â–†â–ˆâ–â–â–‡â–„â–…â–„â–‚â–‚â–ƒâ–…â–â–„â–â–†â–…â–ƒâ–ˆâ–…â–…â–„â–…â–‡â–…â–â–…â–…â–„â–‡â–…â–‡â–…â–‚â–
wandb:       eval/ensemble_f1 â–‚â–‡â–†â–â–ˆâ–‚â–ƒâ–‚â–‡â–ˆâ–ˆâ–†â–…â–ˆâ–‡â–ˆâ–‡â–„â–‡â–ˆâ–‡â–‡â–„â–ƒâ–…â–‚â–‚â–‚â–‚â–„â–‡â–‚â–‡â–‡â–‚â–‡â–‚â–‡â–‡â–‡
wandb:           train/avg_f1 â–†â–ƒâ–ƒâ–‡â–…â–‡â–…â–…â–ƒâ–…â–‡â–‡â–…â–ƒâ–ƒâ–‚â–‡â–†â–â–…â–…â–†â–â–…â–‚â–„â–„â–†â–†â–…â–‚â–ˆâ–ˆâ–ƒâ–‡â–†â–„â–…â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–â–†â–‚â–…â–„â–‡â–‚â–‚â–…â–ˆâ–…â–‡â–ƒâ–‡â–…â–†â–†â–†â–„â–†â–†â–†â–…â–‚â–†â–„â–†â–‚â–‡â–„â–…â–â–†â–„â–‡â–…â–…â–‚â–„
wandb:         train/mil_loss â–„â–†â–‡â–â–‡â–„â–„â–â–„â–†â–†â–‡â–…â–„â–…â–…â–…â–†â–ˆâ–„â–„â–‚â–†â–ƒâ–„â–†â–‚â–†â–„â–â–…â–†â–…â–†â–‡â–â–„â–„â–†â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9186
wandb: best/eval_avg_mil_loss 0.30767
wandb:  best/eval_ensemble_f1 0.9186
wandb:            eval/avg_f1 0.8768
wandb:      eval/avg_mil_loss 0.33692
wandb:       eval/ensemble_f1 0.8768
wandb:           train/avg_f1 0.73994
wandb:      train/ensemble_f1 0.73994
wandb:         train/mil_loss 1.32649
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vibrant-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqb0317q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041715-zqb0317q/logs
wandb: ERROR Run zqb0317q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zg2ha9w8 with config:
wandb: 	actor_learning_rate: 0.0004540544197588698
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7776980108301699
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041934-zg2ha9w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zg2ha9w8
wandb: uploading history steps 134-143, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–â–†â–‡â–†â–ƒâ–ˆâ–†â–…â–‡â–ƒâ–†â–†â–‡â–†â–‡â–â–†â–„â–†â–…â–ˆâ–ˆâ–„â–†â–†â–ˆâ–…â–…â–†â–ˆâ–‡â–…â–‡â–‡â–…â–…â–†â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–…â–†â–‚â–„â–‚â–‡â–…â–â–ƒâ–…â–ƒâ–â–â–…â–ƒâ–â–„â–ˆâ–…â–ƒâ–â–„â–â–ƒâ–â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–„â–„â–„â–ƒâ–…â–ƒâ–‡â–„â–„
wandb:       eval/ensemble_f1 â–†â–†â–â–„â–„â–…â–…â–…â–„â–‡â–‚â–†â–‡â–‡â–â–‚â–‚â–‚â–‡â–„â–ˆâ–„â–‡â–‡â–ˆâ–…â–†â–‚â–ƒâ–ˆâ–‡â–…â–ƒâ–ƒâ–†â–â–…â–ƒâ–â–ƒ
wandb:           train/avg_f1 â–ƒâ–…â–„â–„â–…â–‡â–‚â–†â–…â–ƒâ–â–„â–†â–â–…â–†â–…â–…â–…â–…â–„â–„â–‚â–„â–„â–â–„â–„â–‡â–‡â–„â–†â–…â–ˆâ–„â–‡â–ƒâ–†â–‚â–„
wandb:      train/ensemble_f1 â–…â–†â–†â–„â–„â–‡â–…â–„â–ƒâ–†â–„â–â–„â–„â–†â–…â–ƒâ–†â–…â–…â–ƒâ–†â–†â–†â–…â–„â–„â–ƒâ–„â–‡â–†â–…â–…â–„â–†â–†â–†â–ˆâ–‡â–„
wandb:         train/mil_loss â–„â–â–„â–„â–‚â–…â–…â–†â–„â–„â–‡â–ƒâ–…â–…â–„â–…â–‚â–†â–„â–†â–ƒâ–…â–„â–„â–†â–…â–†â–…â–ƒâ–†â–„â–„â–…â–ƒâ–ˆâ–„â–„â–†â–„â–‡
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92612
wandb: best/eval_avg_mil_loss 0.25147
wandb:  best/eval_ensemble_f1 0.92612
wandb:            eval/avg_f1 0.91414
wandb:      eval/avg_mil_loss 0.24478
wandb:       eval/ensemble_f1 0.91414
wandb:           train/avg_f1 0.84267
wandb:      train/ensemble_f1 0.84267
wandb:         train/mil_loss 0.43682
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cerulean-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zg2ha9w8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041934-zg2ha9w8/logs
wandb: ERROR Run zg2ha9w8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wrut1ry0 with config:
wandb: 	actor_learning_rate: 4.253030271860168e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07730794005753461
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042204-wrut1ry0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wrut1ry0
wandb: uploading history steps 119-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–‚â–„â–‡â–ˆâ–ƒâ–ˆâ–â–†â–†â–†â–†â–ˆâ–‡â–‡â–…â–„â–ƒâ–…â–…â–ˆâ–„â–‡â–ƒâ–ƒâ–†â–‡â–ˆâ–ƒâ–‡â–‡â–…â–„â–ˆâ–…â–‡â–‡â–ƒâ–„
wandb:      eval/avg_mil_loss â–†â–†â–„â–ƒâ–â–ƒâ–ƒâ–…â–â–ˆâ–â–â–‚â–ƒâ–ƒâ–â–‚â–‡â–„â–‚â–ƒâ–…â–â–…â–†â–â–„â–â–â–…â–‚â–‚â–„â–‚â–„â–‚â–„â–â–„â–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–†â–ƒâ–‡â–‡â–…â–…â–†â–ˆâ–ƒâ–…â–…â–â–ˆâ–‚â–‡â–‡â–…â–ˆâ–„â–†â–‡â–„â–„â–‡â–‡â–â–‡â–ˆâ–‡â–„â–‡â–‚â–…â–‡â–‡â–ƒâ–…â–…
wandb:           train/avg_f1 â–…â–†â–„â–‡â–â–„â–†â–„â–…â–†â–…â–ƒâ–…â–ƒâ–…â–…â–‡â–†â–„â–…â–„â–„â–†â–…â–…â–„â–„â–‡â–„â–…â–‡â–ˆâ–†â–ƒâ–†â–…â–…â–„â–†â–…
wandb:      train/ensemble_f1 â–†â–†â–‡â–â–„â–„â–†â–ƒâ–†â–…â–…â–…â–…â–‚â–…â–„â–„â–…â–‡â–ˆâ–…â–…â–†â–„â–‡â–„â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–†â–…â–„â–„â–…â–†â–„â–‡â–„
wandb:         train/mil_loss â–‡â–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–…â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–‚â–…â–‚â–ƒâ–„â–„â–…â–ƒâ–ƒâ–â–ƒâ–„â–ˆâ–„â–ƒâ–‚â–†â–„â–†â–ƒâ–â–ƒâ–ƒâ–
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–‡â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91069
wandb: best/eval_avg_mil_loss 0.2985
wandb:  best/eval_ensemble_f1 0.91069
wandb:            eval/avg_f1 0.84153
wandb:      eval/avg_mil_loss 0.48572
wandb:       eval/ensemble_f1 0.84153
wandb:           train/avg_f1 0.83925
wandb:      train/ensemble_f1 0.83925
wandb:         train/mil_loss 0.36735
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vivid-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wrut1ry0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042204-wrut1ry0/logs
wandb: ERROR Run wrut1ry0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9dxdht8z with config:
wandb: 	actor_learning_rate: 1.0702250552462067e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6281277245683898
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042413-9dxdht8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dxdht8z
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–„â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–„â–†â–†â–…â–‡â–‡â–‡â–ƒâ–†â–…â–‡â–‡â–â–ˆâ–‡â–‡â–ˆâ–‡â–…â–‡â–ˆâ–†â–ƒâ–‡â–‡â–‡â–‡â–†â–ˆâ–…â–‡â–„â–…â–…â–ˆâ–‡â–†â–†
wandb:      eval/avg_mil_loss â–â–‚â–â–â–ˆâ–â–…â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–‡â–‚â–‡â–‚â–‚â–â–‚â–‚â–†â–â–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–…â–ˆâ–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–…â–‡â–ˆâ–†â–‡â–…â–‡â–ˆâ–‡â–…â–‡â–ˆâ–‡â–‡â–…â–…â–‡â–‡â–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–‡â–ƒâ–…â–…â–†â–‡â–‚â–…â–†â–†â–†â–„â–…â–†â–„â–ƒâ–â–†â–‚â–†â–…â–„â–†â–†â–…â–†â–†â–†â–…â–ƒâ–‡â–„â–†â–†â–…â–…â–„â–…
wandb:      train/ensemble_f1 â–†â–„â–ˆâ–„â–‡â–„â–ˆâ–ƒâ–„â–„â–„â–‡â–†â–„â–…â–ƒâ–†â–ƒâ–â–†â–„â–‚â–‡â–â–…â–‚â–‡â–ƒâ–†â–„â–ƒâ–†â–†â–ƒâ–†â–†â–‡â–…â–†â–…
wandb:         train/mil_loss â–‚â–‚â–„â–‡â–‡â–…â–ƒâ–…â–â–ƒâ–…â–â–ƒâ–†â–ƒâ–‡â–ƒâ–‚â–„â–ƒâ–ˆâ–…â–…â–…â–„â–†â–„â–â–„â–â–‚â–„â–â–…â–‚â–…â–„â–„â–‚â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.22972
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.90706
wandb:      eval/avg_mil_loss 0.21666
wandb:       eval/ensemble_f1 0.90706
wandb:            test/avg_f1 0.91226
wandb:      test/avg_mil_loss 0.24504
wandb:       test/ensemble_f1 0.91226
wandb:           train/avg_f1 0.89452
wandb:      train/ensemble_f1 0.89452
wandb:         train/mil_loss 0.29021
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dxdht8z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042413-9dxdht8z/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r0qhopzk with config:
wandb: 	actor_learning_rate: 1.5164243902197432e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6422805606996442
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042705-r0qhopzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0qhopzk
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 189-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–ˆâ–ƒâ–‡â–‡â–‡â–†â–†â–‡â–…â–‡â–ˆâ–‡â–‡â–„â–†â–„â–‡â–†â–ˆâ–‡â–‡â–‡â–â–†â–ˆâ–†â–„â–‡â–…â–‡â–â–‡â–†â–ˆâ–†â–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–†â–‚â–ƒâ–â–‚â–‚â–…â–‡â–†â–„â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–ˆâ–„â–‚â–â–…â–„â–‚â–‚â–‚â–†â–†â–â–â–…â–â–â–â–
wandb:       eval/ensemble_f1 â–„â–†â–‡â–‡â–‡â–†â–‡â–„â–ƒâ–„â–‡â–‡â–‡â–‡â–‡â–‡â–„â–‡â–‡â–ˆâ–ˆâ–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–â–‡â–…â–ˆâ–†â–ˆâ–ˆâ–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–…â–†â–„â–‡â–‡â–„â–…â–†â–‡â–†â–ƒâ–‡â–…â–…â–†â–„â–†â–ˆâ–‡â–ˆâ–…â–‚â–„â–„â–‡â–‚â–‡â–„â–…â–„â–â–„â–†â–†â–„â–†â–‡â–
wandb:      train/ensemble_f1 â–†â–…â–„â–„â–„â–†â–…â–…â–ƒâ–„â–â–„â–…â–„â–…â–†â–ˆâ–„â–„â–…â–‡â–…â–„â–…â–‚â–ƒâ–…â–„â–ƒâ–†â–„â–„â–ˆâ–…â–„â–…â–ƒâ–‡â–„â–„
wandb:         train/mil_loss â–„â–…â–„â–‚â–„â–„â–…â–ƒâ–ƒâ–ƒâ–â–„â–â–ƒâ–„â–ˆâ–‡â–â–‚â–†â–„â–‚â–‚â–ƒâ–ƒâ–†â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–„â–‡â–…â–„â–ƒâ–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–…â–…â–â–â–ˆâ–…â–…â–â–ˆâ–…â–â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–ˆâ–â–â–…â–…â–â–…â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.27064
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.9183
wandb:      eval/avg_mil_loss 0.27064
wandb:       eval/ensemble_f1 0.9183
wandb:            test/avg_f1 0.75912
wandb:      test/avg_mil_loss 1.04306
wandb:       test/ensemble_f1 0.75912
wandb:           train/avg_f1 0.84172
wandb:      train/ensemble_f1 0.84172
wandb:         train/mil_loss 0.34028
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eager-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0qhopzk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042705-r0qhopzk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h0dg2p53 with config:
wandb: 	actor_learning_rate: 1.1671056253595047e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.94155635755614
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042955-h0dg2p53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h0dg2p53
wandb: uploading history steps 148-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–†â–ƒâ–‡â–ƒâ–ƒâ–…â–…â–†â–ƒâ–„â–‡â–ˆâ–ƒâ–†â–…â–…â–ƒâ–„â–â–„â–‡â–‡â–„â–‡â–†â–†â–ƒâ–‚â–‡â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–ƒâ–„
wandb:      eval/avg_mil_loss â–†â–†â–ƒâ–„â–…â–…â–…â–‚â–„â–ƒâ–ƒâ–„â–…â–ƒâ–„â–â–†â–ƒâ–‡â–‚â–„â–†â–†â–…â–‡â–ƒâ–†â–„â–ƒâ–ˆâ–„â–„â–…â–…â–ƒâ–„â–„â–ƒâ–‚â–†
wandb:       eval/ensemble_f1 â–‡â–‚â–„â–ƒâ–â–…â–‡â–‡â–„â–…â–†â–ƒâ–ˆâ–â–ƒâ–…â–…â–ƒâ–ƒâ–„â–‡â–ƒâ–„â–†â–â–…â–…â–ƒâ–„â–ƒâ–‡â–…â–ƒâ–†â–‚â–…â–„â–‚â–…â–„
wandb:           train/avg_f1 â–‚â–†â–‡â–…â–‡â–„â–‚â–„â–‚â–‡â–‡â–â–‡â–ƒâ–ˆâ–†â–…â–ƒâ–„â–„â–…â–†â–ˆâ–…â–†â–„â–‡â–†â–…â–†â–‡â–…â–‡â–„â–†â–‡â–„â–†â–ˆâ–ƒ
wandb:      train/ensemble_f1 â–ˆâ–‚â–‚â–‡â–„â–…â–ƒâ–ˆâ–…â–…â–…â–„â–„â–…â–â–ˆâ–…â–â–„â–„â–‚â–‡â–…â–„â–†â–…â–†â–ˆâ–†â–…â–†â–…â–†â–†â–‡â–†â–‡â–‡â–†â–„
wandb:         train/mil_loss â–ˆâ–„â–ƒâ–†â–†â–‡â–†â–„â–†â–‡â–…â–„â–…â–…â–„â–‚â–‚â–‡â–‡â–â–…â–„â–„â–ƒâ–„â–ƒâ–â–„â–ƒâ–…â–„â–…â–„â–…â–ƒâ–„â–â–â–„â–ƒ
wandb:      train/policy_loss â–…â–‚â–…â–…â–â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9112
wandb: best/eval_avg_mil_loss 0.26261
wandb:  best/eval_ensemble_f1 0.9112
wandb:            eval/avg_f1 0.77367
wandb:      eval/avg_mil_loss 0.92889
wandb:       eval/ensemble_f1 0.77367
wandb:           train/avg_f1 0.75775
wandb:      train/ensemble_f1 0.75775
wandb:         train/mil_loss 0.66626
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h0dg2p53
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042955-h0dg2p53/logs
wandb: ERROR Run h0dg2p53 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: blubfyxz with config:
wandb: 	actor_learning_rate: 1.560646110481649e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5796799515136295
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043236-blubfyxz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/blubfyxz
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 187-197, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–â–„â–‚â–â–…
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–ƒâ–†â–‡â–‡â–‡â–‚â–†â–ˆâ–ˆâ–ˆâ–…â–‡â–‡â–…â–ˆâ–†â–ˆâ–ƒâ–‡â–ˆâ–„â–‡â–ˆâ–‚â–ˆâ–‡â–„â–ˆâ–„â–„â–‡â–‡â–…â–ˆâ–‡â–â–†â–‡
wandb:      eval/avg_mil_loss â–ˆâ–‚â–‚â–…â–ƒâ–‚â–„â–†â–ƒâ–ƒâ–„â–‚â–‚â–…â–‚â–â–„â–…â–â–…â–‚â–‚â–†â–‚â–ƒâ–â–â–‚â–‡â–‚â–â–†â–…â–†â–ˆâ–†â–â–†â–†â–‡
wandb:       eval/ensemble_f1 â–…â–‡â–ˆâ–‡â–…â–…â–ˆâ–†â–†â–†â–…â–‡â–…â–ˆâ–†â–‡â–ˆâ–ˆâ–…â–‡â–…â–â–ˆâ–‡â–‡â–…â–ˆâ–ˆâ–…â–‡â–ˆâ–†â–‡â–„â–‡â–ˆâ–…â–ƒâ–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–„â–ˆâ–…â–†â–ˆâ–ƒâ–„â–ƒâ–†â–†â–…â–†â–„â–‡â–…â–†â–„â–…â–„â–†â–ƒâ–†â–ˆâ–…â–„â–…â–ˆâ–…â–†â–„â–…â–…â–â–…â–„â–‡â–…â–‡â–…
wandb:      train/ensemble_f1 â–…â–…â–…â–„â–ƒâ–…â–…â–ƒâ–…â–†â–†â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–†â–†â–„â–†â–„â–…â–ˆâ–‡â–…â–…â–…â–‚â–‡â–ƒâ–„â–â–†â–†â–‡â–ƒ
wandb:         train/mil_loss â–‚â–ƒâ–ƒâ–…â–…â–„â–…â–‚â–â–‚â–ƒâ–„â–‚â–…â–‚â–„â–‡â–…â–‚â–‡â–„â–ƒâ–„â–…â–ˆâ–„â–†â–â–‚â–â–ƒâ–…â–‚â–ƒâ–‚â–…â–„â–‚â–„â–„
wandb:      train/policy_loss â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–„â–ˆâ–„â–„â–â–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–„â–ˆâ–„â–ˆâ–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.30757
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.86656
wandb:      eval/avg_mil_loss 0.35971
wandb:       eval/ensemble_f1 0.86656
wandb:            test/avg_f1 0.74801
wandb:      test/avg_mil_loss 0.70427
wandb:       test/ensemble_f1 0.74801
wandb:           train/avg_f1 0.83007
wandb:      train/ensemble_f1 0.83007
wandb:         train/mil_loss 0.44733
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/blubfyxz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043236-blubfyxz/logs
wandb: Agent Starting Run: r4o9yswr with config:
wandb: 	actor_learning_rate: 1.991553899989447e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6569108298694123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043520-r4o9yswr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4o9yswr
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–†â–‡â–‡â–„â–„â–…â–„â–â–„â–†â–„â–ˆâ–†â–‡â–†â–…â–ˆâ–‡â–ˆâ–ƒâ–†â–†â–…â–‚â–‡â–‡â–„â–…â–ƒâ–„â–‡â–„â–‚â–ˆâ–â–â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–â–„â–ƒâ–ˆâ–‡â–…â–…â–‚â–‡â–â–â–â–‚â–†â–â–‚â–‚â–„â–‚â–†â–â–ƒâ–…â–„â–‚â–„â–‚â–‚â–…â–„â–â–‚â–ˆâ–ƒâ–…â–â–…â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–†â–„â–„â–ˆâ–ƒâ–…â–ƒâ–ˆâ–‡â–†â–ˆâ–„â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–†â–â–„â–‡â–†â–‡â–…â–…â–…â–‡â–‡â–„â–ˆâ–…â–„â–ƒâ–‡â–‡
wandb:           train/avg_f1 â–…â–â–…â–†â–„â–ƒâ–„â–„â–†â–‚â–„â–†â–ƒâ–‡â–‚â–„â–†â–„â–„â–‡â–ƒâ–‚â–…â–‚â–†â–‚â–â–ƒâ–„â–„â–†â–ˆâ–†â–‡â–ˆâ–„â–„â–ƒâ–†â–†
wandb:      train/ensemble_f1 â–‚â–…â–„â–„â–„â–†â–„â–ƒâ–‡â–ƒâ–†â–…â–„â–‡â–…â–‡â–…â–…â–‡â–„â–…â–„â–„â–†â–ƒâ–‡â–‡â–‡â–ƒâ–…â–…â–â–…â–…â–ˆâ–ˆâ–…â–ƒâ–†â–ƒ
wandb:         train/mil_loss â–†â–‡â–„â–ƒâ–„â–…â–…â–‡â–„â–„â–ƒâ–ƒâ–…â–ƒâ–…â–†â–…â–…â–ƒâ–‚â–†â–â–‚â–…â–‚â–ƒâ–…â–ˆâ–†â–…â–„â–ƒâ–‚â–„â–†â–†â–…â–ƒâ–â–…
wandb:      train/policy_loss â–ˆâ–…â–…â–…â–â–…â–ˆâ–ˆâ–…â–ˆâ–…â–…â–…â–…â–â–…â–â–ˆâ–…â–…â–â–…â–…â–â–…â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–â–â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91482
wandb: best/eval_avg_mil_loss 0.30644
wandb:  best/eval_ensemble_f1 0.91482
wandb:            eval/avg_f1 0.9112
wandb:      eval/avg_mil_loss 0.26653
wandb:       eval/ensemble_f1 0.9112
wandb:           train/avg_f1 0.84895
wandb:      train/ensemble_f1 0.84895
wandb:         train/mil_loss 0.58399
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comic-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4o9yswr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043520-r4o9yswr/logs
wandb: ERROR Run r4o9yswr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 014llkp1 with config:
wandb: 	actor_learning_rate: 7.756060870041826e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15514306410442835
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043703-014llkp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/014llkp1
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 148-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–‚â–‚â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–â–â–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–ˆâ–„â–ˆâ–…â–ˆâ–‡â–‡â–â–‡â–†â–…â–‡â–…â–ˆâ–…â–†â–‡â–…â–‡â–ˆâ–‡â–…â–…â–‡â–ˆâ–‡â–…â–…â–„â–„â–ˆâ–„â–‡â–ˆâ–ˆâ–…â–ˆ
wandb:      eval/avg_mil_loss â–‚â–„â–â–â–â–‡â–‚â–â–ˆâ–â–ˆâ–„â–ƒâ–‚â–…â–ƒâ–…â–…â–â–†â–†â–„â–‚â–†â–„â–â–‚â–„â–„â–â–„â–‚â–‚â–â–‡â–ˆâ–â–â–†â–
wandb:       eval/ensemble_f1 â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–…â–…â–„â–ˆâ–ˆâ–†â–…â–‡â–…â–ˆâ–…â–‡â–…â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–…â–ˆâ–ˆâ–â–…â–…â–‡â–ˆâ–ˆ
wandb:           train/avg_f1 â–…â–†â–„â–‡â–ˆâ–„â–…â–‡â–â–†â–‡â–†â–ƒâ–ˆâ–‡â–†â–…â–…â–„â–…â–†â–…â–…â–†â–…â–†â–…â–†â–…â–†â–…â–…â–…â–†â–‚â–†â–†â–…â–†â–†
wandb:      train/ensemble_f1 â–„â–…â–‡â–†â–ˆâ–…â–…â–…â–„â–„â–†â–†â–‚â–‚â–…â–†â–…â–…â–‡â–ˆâ–†â–†â–…â–ˆâ–…â–‡â–„â–†â–„â–„â–†â–ƒâ–‡â–…â–â–…â–†â–ˆâ–‚â–‡
wandb:         train/mil_loss â–†â–ƒâ–„â–ˆâ–…â–ƒâ–ƒâ–‚â–â–…â–„â–…â–…â–‡â–†â–„â–…â–„â–„â–„â–…â–„â–†â–‚â–ƒâ–„â–„â–‚â–„â–„â–„â–…â–„â–†â–„â–„â–…â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–„â–„â–â–ˆâ–â–â–„â–â–„â–ˆâ–â–â–„â–â–„â–â–„â–„â–â–â–â–ˆâ–ˆâ–„â–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–â–„â–ˆâ–„â–â–ˆâ–„â–„â–„â–„â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.2488
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.9026
wandb:      eval/avg_mil_loss 0.24609
wandb:       eval/ensemble_f1 0.9026
wandb:           train/avg_f1 0.81744
wandb:      train/ensemble_f1 0.81744
wandb:         train/mil_loss 0.72078
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worldly-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/014llkp1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043703-014llkp1/logs
wandb: ERROR Run 014llkp1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8amfb352 with config:
wandb: 	actor_learning_rate: 0.0003058988327069652
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 58
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3010258250072888
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043912-8amfb352
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8amfb352
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading history steps 44-58, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆâ–ƒâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–â–ƒâ–†â–„â–…â–†â–„â–†â–‡â–ˆâ–†â–ˆâ–‚â–‡â–ƒâ–ƒâ–„â–‡â–‡â–‡â–…â–†â–‡â–‚â–„â–„â–ƒâ–…â–†â–…â–‡â–„â–…â–†â–‡â–…â–…â–‚â–„
wandb:      eval/avg_mil_loss â–ƒâ–‡â–„â–â–ƒâ–ƒâ–„â–ˆâ–ƒâ–â–â–ƒâ–â–†â–â–„â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–
wandb:       eval/ensemble_f1 â–†â–‚â–„â–†â–…â–†â–†â–â–‡â–‡â–ˆâ–†â–†â–ˆâ–ƒâ–‡â–†â–„â–„â–„â–‡â–‡â–…â–†â–‡â–ƒâ–…â–…â–ƒâ–…â–„â–ˆâ–…â–‡â–…â–…â–‡â–‡â–…â–‡
wandb:           train/avg_f1 â–„â–†â–†â–…â–‡â–ƒâ–‚â–ƒâ–‡â–â–†â–‡â–„â–ƒâ–â–†â–…â–†â–‡â–†â–ƒâ–…â–†â–†â–„â–‡â–†â–…â–‡â–…â–„â–‚â–ƒâ–‡â–‚â–†â–‚â–ƒâ–ƒâ–ˆ
wandb:      train/ensemble_f1 â–„â–…â–„â–†â–‡â–‚â–…â–ƒâ–‚â–†â–…â–†â–„â–â–ˆâ–„â–…â–…â–â–â–„â–…â–„â–„â–…â–…â–„â–†â–…â–„â–ƒâ–†â–†â–‚â–ƒâ–…â–‚â–ƒâ–‚â–‡
wandb:         train/mil_loss â–…â–„â–…â–ƒâ–â–‚â–‡â–„â–†â–‡â–†â–…â–…â–‡â–†â–†â–„â–‚â–†â–ƒâ–†â–ƒâ–…â–ˆâ–†â–‡â–…â–ƒâ–†â–…â–ƒâ–ˆâ–†â–†â–‡â–„â–…â–„â–‡â–„
wandb:      train/policy_loss â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–ƒâ–â–â–â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.21432
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.88918
wandb:      eval/avg_mil_loss 0.27428
wandb:       eval/ensemble_f1 0.88918
wandb:           train/avg_f1 0.88584
wandb:      train/ensemble_f1 0.88584
wandb:         train/mil_loss 0.61191
wandb:      train/policy_loss 0.06392
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.06392
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8amfb352
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043912-8amfb352/logs
wandb: ERROR Run 8amfb352 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1h5poui7 with config:
wandb: 	actor_learning_rate: 1.732028957341321e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2715991685661133
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044020-1h5poui7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1h5poui7
wandb: uploading history steps 117-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–â–…â–†â–…â–†â–‚â–…â–ƒâ–‚â–…â–†â–…â–…â–…â–ƒâ–ˆâ–„â–†â–ƒâ–†â–„â–‡â–†â–†â–„â–…â–ƒâ–…â–‚â–…â–†â–†â–„â–„â–†â–„â–…â–„
wandb:      eval/avg_mil_loss â–„â–…â–ƒâ–‚â–…â–„â–†â–…â–…â–„â–‡â–ˆâ–„â–…â–‚â–‡â–â–…â–„â–„â–†â–ƒâ–…â–…â–…â–ƒâ–…â–…â–„â–ˆâ–‚â–‡â–„â–†â–ƒâ–‡â–„â–‚â–‡â–†
wandb:       eval/ensemble_f1 â–‡â–ƒâ–…â–ƒâ–ˆâ–„â–‚â–†â–†â–„â–ƒâ–ƒâ–†â–…â–…â–„â–†â–ƒâ–…â–â–„â–‚â–†â–…â–†â–„â–†â–„â–‚â–‡â–…â–†â–„â–„â–„â–†â–„â–ƒâ–„â–†
wandb:           train/avg_f1 â–†â–‚â–…â–…â–ˆâ–…â–…â–â–„â–ˆâ–‚â–…â–„â–‚â–‡â–‡â–…â–„â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–†â–â–‡â–†â–…â–…â–…â–…â–„â–„â–„â–â–ƒâ–…â–…â–„
wandb:      train/ensemble_f1 â–†â–‚â–„â–†â–ˆâ–ƒâ–‚â–„â–…â–…â–†â–„â–‡â–…â–‚â–‚â–‡â–‡â–…â–ƒâ–„â–„â–†â–â–…â–„â–ƒâ–ƒâ–…â–…â–‡â–ƒâ–‚â–„â–…â–…â–…â–„â–†â–ƒ
wandb:         train/mil_loss â–†â–†â–ƒâ–„â–…â–†â–ƒâ–†â–…â–„â–†â–…â–…â–…â–†â–…â–„â–„â–…â–‚â–†â–„â–†â–†â–ˆâ–ƒâ–…â–†â–†â–„â–‡â–„â–†â–‚â–†â–†â–„â–„â–…â–
wandb:      train/policy_loss â–â–â–…â–ˆâ–â–…â–â–â–ˆâ–…â–ˆâ–ˆâ–â–…â–…â–…â–â–…â–ˆâ–…â–ˆâ–â–ˆâ–…â–â–â–ˆâ–â–â–ˆâ–â–…â–â–â–â–ˆâ–…â–…â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89963
wandb: best/eval_avg_mil_loss 0.27693
wandb:  best/eval_ensemble_f1 0.89963
wandb:            eval/avg_f1 0.76611
wandb:      eval/avg_mil_loss 0.83172
wandb:       eval/ensemble_f1 0.76611
wandb:           train/avg_f1 0.79198
wandb:      train/ensemble_f1 0.79198
wandb:         train/mil_loss 0.74996
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smart-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1h5poui7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044020-1h5poui7/logs
wandb: ERROR Run 1h5poui7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pcxcj6e9 with config:
wandb: 	actor_learning_rate: 1.1557028098655475e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8583386837872405
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044234-pcxcj6e9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pcxcj6e9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–‡â–„â–†â–â–‚â–…â–…â–„â–†â–…â–‡â–ˆâ–…â–‡â–‚â–„â–„â–ˆâ–ˆâ–‡â–…â–‡â–ˆâ–‡â–‡â–…â–‡â–†â–‡â–†â–‡â–‡â–†â–…â–…â–†â–ƒâ–…
wandb:      eval/avg_mil_loss â–â–„â–…â–…â–‡â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–‚â–…â–†â–ˆâ–ƒâ–„â–‚â–ƒâ–â–…â–„â–‚â–â–„â–„â–‚â–‡â–„â–ƒâ–ƒâ–‡â–‚â–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–„â–†â–ƒâ–‡â–‡â–…â–†â–…â–ƒâ–ˆâ–ƒâ–„â–…â–ˆâ–…â–…â–‡â–ˆâ–ƒâ–‡â–‡â–†â–ˆâ–‡â–ƒâ–‡â–â–†â–…â–‡â–‡â–†â–‡â–…â–‚â–„â–‡â–†â–ˆâ–
wandb:           train/avg_f1 â–„â–†â–‡â–ƒâ–…â–„â–‡â–„â–†â–†â–ˆâ–‡â–„â–†â–„â–†â–…â–„â–ƒâ–†â–…â–ƒâ–†â–„â–„â–â–„â–ƒâ–…â–…â–„â–‡â–†â–ˆâ–…â–‚â–„â–‚â–†â–†
wandb:      train/ensemble_f1 â–…â–„â–„â–†â–…â–„â–‡â–…â–„â–ˆâ–â–„â–†â–ƒâ–ƒâ–‚â–ˆâ–‚â–…â–ƒâ–…â–…â–‡â–†â–„â–ƒâ–„â–„â–†â–†â–†â–…â–‡â–†â–…â–…â–…â–ˆâ–…â–†
wandb:         train/mil_loss â–†â–„â–†â–„â–†â–†â–ƒâ–‚â–‡â–ƒâ–„â–‡â–â–ƒâ–ƒâ–…â–…â–‡â–„â–‡â–…â–†â–…â–‚â–„â–â–„â–â–…â–…â–ƒâ–ˆâ–‡â–†â–…â–„â–‡â–ƒâ–†â–‚
wandb:      train/policy_loss â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9038
wandb: best/eval_avg_mil_loss 0.44117
wandb:  best/eval_ensemble_f1 0.9038
wandb:            eval/avg_f1 0.81381
wandb:      eval/avg_mil_loss 0.73978
wandb:       eval/ensemble_f1 0.81381
wandb:           train/avg_f1 0.85068
wandb:      train/ensemble_f1 0.85068
wandb:         train/mil_loss 0.85016
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run breezy-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pcxcj6e9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044234-pcxcj6e9/logs
wandb: ERROR Run pcxcj6e9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ompsvct3 with config:
wandb: 	actor_learning_rate: 6.5813711307992945e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10871702913803728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044434-ompsvct3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ompsvct3
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–‚â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–‡â–†â–‡â–‡â–‡â–†â–…â–…â–†â–†â–„â–†â–ƒâ–„â–…â–„â–‡â–ˆâ–‡â–ƒâ–…â–†â–ˆâ–â–ˆâ–ˆâ–ˆâ–„â–…â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–â–†
wandb:      eval/avg_mil_loss â–†â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–…â–ƒâ–„â–‚â–„â–â–‡â–„â–„â–‚â–ˆâ–…â–ƒâ–‚â–â–â–â–„â–†â–„â–„â–„â–†â–â–ƒâ–â–ˆâ–â–
wandb:       eval/ensemble_f1 â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–…â–…â–†â–‡â–‡â–†â–…â–‡â–†â–†â–ƒâ–„â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–„â–…â–†â–‡â–‡â–‡â–‚â–‡â–ˆâ–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–„â–„â–…â–„â–â–„â–ƒâ–†â–ƒâ–ƒâ–â–‚â–…â–ƒâ–„â–„â–…â–ƒâ–…â–†â–„â–†â–„â–†â–†â–ƒâ–ˆâ–†â–ƒâ–ƒâ–ƒâ–„â–‡â–…â–ƒâ–…â–‚â–†
wandb:      train/ensemble_f1 â–‚â–„â–‚â–„â–…â–†â–ƒâ–„â–ƒâ–„â–â–‚â–…â–„â–ƒâ–„â–…â–„â–…â–†â–…â–‚â–†â–„â–ƒâ–†â–ƒâ–ˆâ–ˆâ–†â–‚â–„â–†â–‡â–„â–…â–ƒâ–‚â–…â–†
wandb:         train/mil_loss â–â–„â–…â–„â–„â–†â–ƒâ–†â–â–„â–†â–…â–ƒâ–ˆâ–‚â–ƒâ–†â–…â–ƒâ–†â–ƒâ–„â–ƒâ–„â–…â–„â–…â–†â–„â–„â–„â–ƒâ–„â–…â–…â–…â–…â–…â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90363
wandb: best/eval_avg_mil_loss 0.25822
wandb:  best/eval_ensemble_f1 0.90363
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.26776
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.91253
wandb:      test/avg_mil_loss 0.20998
wandb:       test/ensemble_f1 0.91253
wandb:           train/avg_f1 0.84135
wandb:      train/ensemble_f1 0.84135
wandb:         train/mil_loss 0.46284
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ompsvct3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044434-ompsvct3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: me2xaw8k with config:
wandb: 	actor_learning_rate: 4.362505583212767e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6722302846413669
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044625-me2xaw8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/me2xaw8k
wandb: uploading wandb-summary.json
wandb: uploading history steps 40-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–„
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–‚â–ˆâ–ˆâ–‡â–‡â–…â–‡â–â–‡â–‡â–ƒâ–ˆâ–‡â–‡â–‡â–‡â–‡â–…â–‡â–‚â–ˆâ–…â–‡â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–‡â–…â–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–‚â–â–‚â–ƒâ–ƒâ–‚â–†â–‚â–ƒâ–‚â–‡â–ƒâ–ƒâ–â–‚â–ˆâ–‚â–ƒâ–…â–‚â–„â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–…â–ƒâ–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–†â–†â–‚â–ˆâ–ƒâ–‡â–†â–…â–‡â–â–‡â–‡â–ƒâ–ˆâ–†â–‡â–‡â–‡â–†â–…â–‚â–ˆâ–…â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–ˆâ–…â–ˆâ–‡â–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–†â–„â–‚â–„â–‡â–…â–‡â–…â–…â–…â–†â–†â–‚â–‡â–„â–†â–‡â–„â–ƒâ–‡â–…â–‡â–†â–…â–†â–†â–†â–…â–‡â–ˆâ–…â–†â–†â–‡â–„â–â–‡â–…
wandb:      train/ensemble_f1 â–ˆâ–†â–†â–„â–‚â–„â–‡â–…â–‡â–†â–…â–†â–†â–‚â–…â–„â–†â–‡â–„â–…â–‡â–…â–‡â–†â–†â–…â–†â–†â–†â–…â–‡â–ˆâ–…â–†â–†â–‡â–‡â–â–‡â–…
wandb:         train/mil_loss â–‚â–„â–„â–‚â–…â–„â–â–…â–â–‚â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–…â–‚â–‚â–‚â–â–„â–…â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–…â–â–…â–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.28133
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.89702
wandb:      eval/avg_mil_loss 0.32037
wandb:       eval/ensemble_f1 0.89702
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.17713
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.88447
wandb:      train/ensemble_f1 0.88447
wandb:         train/mil_loss 0.23378
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run neat-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/me2xaw8k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044625-me2xaw8k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b2fp99zg with config:
wandb: 	actor_learning_rate: 0.00010817584292266056
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31706992082642815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044748-b2fp99zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b2fp99zg
wandb: uploading history steps 127-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–ƒâ–„â–…â–„â–â–ˆâ–‡â–‡â–…â–‡â–…â–†â–†â–…â–…â–‡â–„â–ˆâ–‡â–‚â–†â–†â–†â–‡â–‡â–…â–…â–…â–‡â–ƒâ–…â–‡â–‡â–†â–†â–‡â–…
wandb:      eval/avg_mil_loss â–…â–‚â–â–ƒâ–‚â–†â–â–ƒâ–â–†â–â–…â–†â–…â–â–â–„â–„â–‚â–â–â–„â–„â–‚â–â–ˆâ–†â–â–†â–ƒâ–…â–â–ˆâ–„â–†â–†â–…â–‡â–„â–…
wandb:       eval/ensemble_f1 â–‚â–…â–‚â–‡â–ˆâ–ˆâ–„â–ˆâ–…â–„â–ˆâ–„â–‡â–„â–…â–‡â–‡â–„â–‚â–‡â–‡â–…â–‡â–â–‡â–„â–‡â–…â–‡â–ƒâ–„â–„â–‡â–‚â–ˆâ–„â–‡â–‡â–…â–‡
wandb:           train/avg_f1 â–â–…â–„â–†â–‚â–†â–…â–„â–…â–‚â–„â–†â–â–ˆâ–„â–…â–…â–„â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–„â–„â–â–„â–„â–…â–†â–„â–„â–…â–‚
wandb:      train/ensemble_f1 â–ƒâ–â–ƒâ–ƒâ–†â–‡â–…â–‚â–ƒâ–„â–â–…â–…â–‚â–†â–†â–‡â–„â–‡â–„â–„â–„â–ˆâ–†â–ˆâ–ƒâ–†â–‚â–‡â–…â–…â–…â–‚â–†â–‡â–‡â–‚â–…â–…â–ƒ
wandb:         train/mil_loss â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–†â–â–ˆâ–ƒâ–‚â–…â–…â–†â–†â–‚â–†â–…â–†â–‚â–…â–‚â–ƒâ–…â–â–ƒâ–…â–„â–…â–‡â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.30835
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.78073
wandb:      eval/avg_mil_loss 0.77012
wandb:       eval/ensemble_f1 0.78073
wandb:           train/avg_f1 0.84612
wandb:      train/ensemble_f1 0.84612
wandb:         train/mil_loss 0.5591
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b2fp99zg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044748-b2fp99zg/logs
wandb: ERROR Run b2fp99zg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mq2906oa with config:
wandb: 	actor_learning_rate: 0.00016886526712504317
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5275697684644662
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044946-mq2906oa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq2906oa
wandb: uploading config.yaml
wandb: uploading history steps 163-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–‡â–†â–‡â–„â–‡â–†â–‡â–„â–„â–ˆâ–…â–‡â–ˆâ–â–„â–…â–…â–†â–‡â–‡â–‡â–†â–ˆâ–ˆâ–†â–ˆâ–ˆâ–†â–‡â–…â–‚â–…â–ˆâ–ˆâ–„â–‡â–…â–…
wandb:      eval/avg_mil_loss â–â–â–…â–â–ƒâ–ƒâ–†â–â–â–„â–„â–â–ƒâ–†â–â–…â–‚â–‚â–â–‚â–ƒâ–„â–‚â–â–„â–â–„â–â–ƒâ–â–ˆâ–â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–
wandb:       eval/ensemble_f1 â–…â–„â–ˆâ–ˆâ–…â–„â–‡â–‡â–‡â–†â–‡â–„â–â–…â–†â–ˆâ–‚â–ƒâ–†â–†â–‡â–„â–‡â–ˆâ–ˆâ–‡â–„â–†â–ˆâ–†â–ƒâ–ˆâ–‡â–…â–†â–…â–…â–‡â–ˆâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–â–…â–ˆâ–…â–‡â–ˆâ–‚â–‚â–„â–‡â–‚â–‚â–„â–ƒâ–…â–†â–„â–ˆâ–†â–ƒâ–…â–„â–â–…â–ƒâ–…â–…â–ƒâ–‚â–‡â–‚â–…â–„â–†â–„â–ƒâ–…â–…â–†
wandb:      train/ensemble_f1 â–†â–„â–‡â–†â–‚â–ˆâ–†â–†â–…â–ƒâ–â–†â–‡â–†â–ƒâ–…â–†â–†â–†â–‡â–‡â–„â–…â–ƒâ–…â–„â–†â–„â–„â–†â–„â–„â–…â–ƒâ–…â–„â–…â–…â–„â–„
wandb:         train/mil_loss â–„â–„â–†â–…â–ƒâ–…â–†â–„â–„â–†â–â–‚â–ƒâ–ˆâ–…â–‡â–„â–„â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–„â–‚â–‚â–ƒâ–‚â–†â–„â–ˆâ–ƒâ–‚â–…
wandb:      train/policy_loss â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–â–„â–„â–â–„â–„â–â–ˆâ–â–„â–„â–„â–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91087
wandb: best/eval_avg_mil_loss 0.26361
wandb:  best/eval_ensemble_f1 0.91087
wandb:            eval/avg_f1 0.86431
wandb:      eval/avg_mil_loss 0.37267
wandb:       eval/ensemble_f1 0.86431
wandb:            test/avg_f1 0.82725
wandb:      test/avg_mil_loss 0.42925
wandb:       test/ensemble_f1 0.82725
wandb:           train/avg_f1 0.83105
wandb:      train/ensemble_f1 0.83105
wandb:         train/mil_loss 0.96197
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run jolly-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mq2906oa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044946-mq2906oa/logs
wandb: Agent Starting Run: 4qzr8b08 with config:
wandb: 	actor_learning_rate: 0.0003492518507333557
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5724683230037436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045216-4qzr8b08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4qzr8b08
wandb: uploading history steps 158-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–â–…â–â–â–…â–ƒâ–ƒâ–‚â–…â–…â–ˆâ–†â–†â–‡â–†â–…â–„â–†â–„â–â–„â–†â–…â–ˆâ–ˆâ–…â–â–†â–‡â–‚â–â–†â–…â–„â–‡â–‡â–‚â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–â–â–ˆâ–†â–†â–‡â–…â–‡â–…â–‡â–„â–‡â–ƒâ–‡â–…â–…â–†â–â–ƒâ–ƒâ–…â–…â–…â–„â–ƒâ–„â–…â–†â–„â–‚â–ƒâ–…â–‡â–†â–ƒâ–…â–„â–†â–‡
wandb:       eval/ensemble_f1 â–…â–‡â–†â–ƒâ–‚â–„â–†â–â–ˆâ–†â–ƒâ–†â–†â–†â–„â–†â–…â–ƒâ–ˆâ–„â–…â–„â–…â–…â–…â–‡â–„â–…â–…â–†â–‚â–…â–„â–ˆâ–„â–„â–ƒâ–†â–‚â–ˆ
wandb:           train/avg_f1 â–‡â–…â–‚â–ƒâ–…â–‚â–…â–…â–„â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–â–â–ƒâ–†â–„â–…â–ƒâ–†â–„â–ˆâ–„â–‡â–†â–ˆâ–„â–ƒâ–ƒâ–†â–‡â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–‚â–†â–‡â–†â–‚â–ƒâ–ƒâ–‚â–„â–„â–…â–…â–â–†â–†â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–„â–…â–‚â–†â–†â–‚â–„â–„â–…â–ƒâ–ƒâ–†â–ˆâ–ƒâ–‚â–‚â–†â–…
wandb:         train/mil_loss â–‚â–‡â–‚â–…â–†â–†â–‡â–…â–‡â–…â–…â–ˆâ–„â–…â–„â–†â–…â–„â–…â–„â–…â–„â–„â–…â–‚â–†â–†â–†â–…â–ƒâ–„â–„â–â–ƒâ–„â–„â–…â–†â–„â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9145
wandb: best/eval_avg_mil_loss 0.24813
wandb:  best/eval_ensemble_f1 0.9145
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.2699
wandb:       eval/ensemble_f1 0.89963
wandb:           train/avg_f1 0.80401
wandb:      train/ensemble_f1 0.80401
wandb:         train/mil_loss 0.77895
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cerulean-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4qzr8b08
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045216-4qzr8b08/logs
wandb: ERROR Run 4qzr8b08 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	size mismatch for task_model.mlp.0.weight: copying a param with shape torch.Size([64, 22]) from checkpoint, the shape in current model is torch.Size([256, 22]).
wandb: ERROR 	size mismatch for task_model.mlp.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).
wandb: ERROR 	size mismatch for task_model.mlp.3.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([2, 256]).
wandb: ERROR 
wandb: Agent Starting Run: 1rwwpg6a with config:
wandb: 	actor_learning_rate: 1.1478792869923586e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.547454803751833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045522-1rwwpg6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rwwpg6a
wandb: uploading wandb-summary.json; uploading history steps 98-116, summary
wandb: uploading history steps 98-116, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‚â–‡â–ƒâ–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–†â–ˆâ–‡â–…â–‚â–ˆâ–‡â–‚â–â–ˆâ–‡â–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–ƒâ–„â–ˆâ–â–…â–â–„â–â–â–…â–ƒâ–‚â–„â–â–â–…â–ˆâ–„â–„â–â–…â–‡â–â–ƒâ–„â–ƒâ–ˆâ–â–„â–â–â–ˆâ–ƒâ–‡â–â–…â–â–
wandb:       eval/ensemble_f1 â–ˆâ–‚â–‚â–‚â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ƒâ–‡â–†â–â–ˆâ–‡â–‚â–ˆâ–‚â–‡â–â–‡â–ˆâ–‡â–ˆâ–‡â–â–‡â–ˆâ–ˆâ–‡â–ƒâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–†â–…â–‡â–„â–…â–‚â–…â–‡â–‡â–†â–†â–‡â–„â–â–†â–…â–†â–…â–„â–…â–„â–†â–‡â–„â–…â–…â–†â–‚â–†â–…â–„â–ƒâ–ˆâ–†â–„â–ˆâ–„â–‡â–†â–‡
wandb:      train/ensemble_f1 â–†â–„â–…â–‡â–†â–‡â–„â–â–‡â–„â–‡â–…â–ˆâ–†â–…â–„â–„â–…â–…â–†â–…â–‡â–…â–…â–„â–…â–…â–ƒâ–†â–‡â–†â–„â–ˆâ–…â–„â–ˆâ–„â–‡â–ˆâ–…
wandb:         train/mil_loss â–„â–‚â–ƒâ–†â–‡â–…â–‡â–…â–‡â–†â–„â–†â–…â–…â–†â–‡â–„â–…â–â–„â–ƒâ–‡â–‚â–ˆâ–…â–„â–…â–„â–‡â–„â–„â–‡â–‡â–„â–…â–…â–…â–ˆâ–â–„
wandb:      train/policy_loss â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–â–â–…â–…â–…â–ƒâ–…â–…â–…â–ˆâ–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91778
wandb: best/eval_avg_mil_loss 0.26113
wandb:  best/eval_ensemble_f1 0.91778
wandb:            eval/avg_f1 0.90725
wandb:      eval/avg_mil_loss 0.29343
wandb:       eval/ensemble_f1 0.90725
wandb:           train/avg_f1 0.81212
wandb:      train/ensemble_f1 0.81212
wandb:         train/mil_loss 0.74734
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rwwpg6a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045522-1rwwpg6a/logs
wandb: ERROR Run 1rwwpg6a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 57ezkmrg with config:
wandb: 	actor_learning_rate: 2.946463204207924e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7181566378930058
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045659-57ezkmrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57ezkmrg
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 76-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–‚â–â–â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–â–ˆâ–ˆâ–‡â–‡â–â–‡â–‡â–…â–‡â–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–…â–‡â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–‚â–‚â–‚â–â–ˆâ–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–†â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–ˆâ–â–‚â–‚â–â–â–ˆâ–‚â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:           train/avg_f1 â–†â–†â–ˆâ–ƒâ–…â–‡â–†â–‡â–…â–â–ƒâ–ˆâ–…â–†â–†â–‡â–†â–†â–„â–‡â–†â–ƒâ–†â–…â–‡â–‡â–†â–„â–†â–‡â–‡â–„â–‡â–„â–„â–‚â–†â–‡â–„â–‡
wandb:      train/ensemble_f1 â–†â–„â–‡â–„â–†â–ˆâ–†â–‡â–â–ˆâ–…â–‡â–‡â–†â–†â–‡â–†â–†â–‡â–…â–†â–„â–…â–…â–‡â–ƒâ–†â–…â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–„â–†â–‚â–‡â–ˆ
wandb:         train/mil_loss â–â–‚â–‚â–‚â–…â–‚â–â–‚â–â–ˆâ–‚â–„â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–†â–â–‚â–ƒâ–‚â–ƒâ–‚â–„â–„â–‚â–â–‚â–…â–„â–‚â–ƒâ–‚â–â–â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–ˆâ–ˆâ–„â–„â–â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–â–â–ˆâ–ˆâ–ˆâ–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–…â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–â–â–…â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.37478
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.90236
wandb:      eval/avg_mil_loss 0.39289
wandb:       eval/ensemble_f1 0.90236
wandb:           train/avg_f1 0.9034
wandb:      train/ensemble_f1 0.9034
wandb:         train/mil_loss 0.26795
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweet-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57ezkmrg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045659-57ezkmrg/logs
wandb: ERROR Run 57ezkmrg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ljtmf28q with config:
wandb: 	actor_learning_rate: 3.95619449739594e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8236292476084578
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045835-ljtmf28q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ljtmf28q
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–ˆâ–…â–‡â–…â–†â–‡â–…â–†â–†â–†â–‡â–ˆâ–†â–†â–…â–‡â–…â–ˆâ–†â–ˆâ–†â–…â–†â–ˆâ–„â–…â–„â–†â–ˆâ–ˆâ–‡â–â–ˆâ–…â–…â–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–ƒâ–„â–†â–â–†â–„â–‚â–ƒâ–…â–ƒâ–‚â–„â–â–ƒâ–…â–â–†â–‚â–†â–†â–ƒâ–â–ˆâ–‡â–ƒâ–„â–‡â–ƒâ–†â–„â–ƒâ–â–â–â–‡â–†â–…â–…â–…
wandb:       eval/ensemble_f1 â–†â–ˆâ–‡â–ˆâ–‚â–‡â–…â–†â–ˆâ–†â–ˆâ–‡â–ˆâ–…â–‡â–ˆâ–…â–†â–†â–†â–ˆâ–†â–…â–†â–ˆâ–ˆâ–…â–†â–…â–„â–†â–†â–‡â–â–ˆâ–†â–†â–ˆâ–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–ƒâ–…â–…â–…â–ˆâ–‡â–‡â–…â–ƒâ–‡â–…â–‡â–†â–„â–†â–‡â–ƒâ–ˆâ–„â–†â–ƒâ–ƒâ–†â–„â–‡â–ˆâ–‚â–â–ˆâ–†â–†â–„â–†â–…â–†â–ƒâ–ƒâ–„
wandb:      train/ensemble_f1 â–„â–„â–ƒâ–…â–„â–„â–‡â–†â–†â–„â–†â–…â–„â–†â–…â–„â–„â–…â–ƒâ–‚â–„â–‚â–†â–…â–†â–â–ƒâ–‡â–ƒâ–‡â–…â–ƒâ–…â–…â–ƒâ–…â–‚â–ƒâ–„â–ˆ
wandb:         train/mil_loss â–‚â–„â–ƒâ–„â–‡â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–…â–„â–ˆâ–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–„â–†â–„â–„â–…â–ƒâ–‡â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–‡â–…â–…â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91886
wandb: best/eval_avg_mil_loss 0.25863
wandb:  best/eval_ensemble_f1 0.91886
wandb:            eval/avg_f1 0.89726
wandb:      eval/avg_mil_loss 0.98345
wandb:       eval/ensemble_f1 0.89726
wandb:            test/avg_f1 0.87982
wandb:      test/avg_mil_loss 0.80032
wandb:       test/ensemble_f1 0.87982
wandb:           train/avg_f1 0.87846
wandb:      train/ensemble_f1 0.87846
wandb:         train/mil_loss 1.01891
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zesty-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ljtmf28q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045835-ljtmf28q/logs
wandb: Agent Starting Run: yq3mzo5c with config:
wandb: 	actor_learning_rate: 3.0350393511609658e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8639572820726955
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045931-yq3mzo5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yq3mzo5c
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–‡â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–„â–ˆâ–‚â–‡â–ˆâ–ˆâ–†â–†â–†â–ˆâ–…â–…â–†â–…â–ƒâ–‡â–…â–„â–â–…â–„â–…â–ˆâ–‡â–…â–‡â–…â–ˆâ–…â–†â–ˆâ–‡â–„â–‡â–ˆâ–…â–‡â–ƒ
wandb:      eval/avg_mil_loss â–…â–‚â–â–‚â–‚â–„â–ƒâ–†â–â–„â–„â–†â–â–„â–„â–…â–ˆâ–…â–ƒâ–ƒâ–‚â–„â–…â–â–â–‚â–â–ƒâ–†â–„â–†â–†â–‚â–„â–ƒâ–†â–ƒâ–â–‚â–†
wandb:       eval/ensemble_f1 â–‡â–„â–…â–…â–‡â–ˆâ–ƒâ–ˆâ–†â–ˆâ–…â–‡â–…â–„â–„â–â–…â–…â–†â–…â–…â–ˆâ–‡â–‡â–ˆâ–…â–…â–ˆâ–„â–ˆâ–‡â–ˆâ–‚â–†â–†â–†â–„â–‡â–ˆâ–ˆ
wandb:           train/avg_f1 â–„â–†â–†â–†â–…â–ƒâ–…â–…â–…â–„â–‡â–ƒâ–‡â–‡â–â–„â–‡â–‡â–…â–„â–†â–†â–…â–ƒâ–…â–…â–…â–„â–„â–ˆâ–†â–‡â–„â–ˆâ–†â–„â–‚â–…â–…â–…
wandb:      train/ensemble_f1 â–†â–„â–„â–†â–†â–‡â–â–…â–„â–ƒâ–ƒâ–‡â–â–…â–ƒâ–ƒâ–…â–…â–…â–…â–ƒâ–†â–„â–„â–…â–‚â–†â–…â–…â–†â–†â–„â–†â–‡â–†â–‡â–†â–„â–„â–ˆ
wandb:         train/mil_loss â–†â–ˆâ–†â–‡â–†â–…â–ƒâ–ƒâ–ˆâ–‡â–…â–ƒâ–„â–…â–ƒâ–†â–…â–â–…â–…â–‡â–ƒâ–…â–„â–„â–„â–‡â–…â–†â–„â–…â–…â–„â–†â–‡â–ƒâ–†â–ƒâ–‚â–†
wandb:      train/policy_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–â–â–â–ˆâ–â–„â–â–„â–„â–„â–ˆâ–„â–â–ˆâ–â–â–„â–„â–„â–ˆâ–„â–„â–â–ˆâ–â–„â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–â–„â–„â–ˆâ–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–„â–ˆâ–„â–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92271
wandb: best/eval_avg_mil_loss 0.22897
wandb:  best/eval_ensemble_f1 0.92271
wandb:            eval/avg_f1 0.74241
wandb:      eval/avg_mil_loss 1.21414
wandb:       eval/ensemble_f1 0.74241
wandb:           train/avg_f1 0.82799
wandb:      train/ensemble_f1 0.82799
wandb:         train/mil_loss 0.71845
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yq3mzo5c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045931-yq3mzo5c/logs
wandb: ERROR Run yq3mzo5c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 26dg1z6f with config:
wandb: 	actor_learning_rate: 5.119273058670944e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07741403453764772
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050125-26dg1z6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26dg1z6f
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 133-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–‡â–‚â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‚â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–„â–‡â–â–ƒâ–ˆâ–â–ˆâ–ƒâ–‡â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–…â–‡â–ƒâ–â–…â–„â–â–ƒâ–„â–â–â–…â–â–„â–„â–â–â–â–â–‚â–„â–…â–â–â–â–ˆâ–„â–â–ƒâ–â–â–â–ƒâ–â–â–â–‚â–…â–â–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–„â–‡â–ˆâ–â–‡â–ˆâ–ˆâ–‡â–‡â–â–„â–‡â–‡â–ˆâ–‡â–…â–‚â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ƒâ–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–„â–†â–ˆâ–ƒâ–†â–ƒâ–†â–†â–†â–…â–…â–„â–ˆâ–‡â–‡â–…â–†â–ƒâ–‚â–„â–†â–ƒâ–†â–†â–†â–‡â–‡â–ƒâ–„â–‚â–†â–â–†â–‡â–ˆâ–…â–ƒâ–„â–‡
wandb:      train/ensemble_f1 â–†â–†â–‡â–†â–‡â–…â–„â–†â–„â–ˆâ–…â–†â–‡â–†â–…â–…â–†â–„â–†â–†â–†â–…â–†â–‡â–‡â–‡â–ƒâ–ƒâ–†â–„â–†â–â–†â–…â–…â–ƒâ–ˆâ–„â–„â–„
wandb:         train/mil_loss â–‚â–â–‡â–…â–‚â–ƒâ–‚â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–„â–‚â–â–…â–„â–‚â–‚â–‚â–â–ˆâ–„â–…â–„â–„â–ƒâ–„â–†â–ˆâ–„â–‚â–ƒâ–ƒâ–†â–…â–ƒâ–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–â–…â–…â–…â–…â–ˆâ–â–…â–…â–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–…â–â–…â–…â–ˆâ–…â–…â–â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.29024
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.85859
wandb:      eval/avg_mil_loss 1.56614
wandb:       eval/ensemble_f1 0.85859
wandb:            test/avg_f1 0.9422
wandb:      test/avg_mil_loss 0.13466
wandb:       test/ensemble_f1 0.9422
wandb:           train/avg_f1 0.88164
wandb:      train/ensemble_f1 0.88164
wandb:         train/mil_loss 0.23907
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cerulean-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26dg1z6f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050125-26dg1z6f/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8akxj2oj with config:
wandb: 	actor_learning_rate: 1.915604283272696e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.910014827476276
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050439-8akxj2oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8akxj2oj
wandb: uploading history steps 89-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–…â–‚â–â–†â–†â–ƒâ–‡â–†â–ƒâ–†â–ƒâ–„â–…â–†â–ƒâ–…â–ˆâ–‡â–ƒâ–…â–‡â–†â–†â–ƒâ–†â–…â–‡â–†â–„â–†â–‡â–†â–…â–ƒâ–†â–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–†â–„â–…â–„â–ˆâ–ƒâ–†â–„â–†â–ƒâ–†â–…â–‚â–…â–†â–„â–„â–„â–ƒâ–…â–‡â–„â–â–‚â–…â–ˆâ–ƒâ–ƒâ–„â–…â–…â–…â–ƒâ–„â–ƒâ–†â–ƒâ–†â–…â–„
wandb:       eval/ensemble_f1 â–ˆâ–†â–†â–„â–‚â–â–â–ƒâ–â–†â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–ˆâ–‡â–‡â–„â–ƒâ–„â–‡â–…â–‡â–‡â–…â–‡â–ƒâ–‡â–†â–‡â–„â–†â–ƒâ–‡â–ˆâ–‡â–…
wandb:           train/avg_f1 â–ƒâ–„â–ƒâ–‡â–‡â–…â–‡â–…â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–„â–ƒâ–†â–…â–â–ˆâ–‚â–„â–ƒâ–„â–…â–…â–„â–‡â–…â–ƒâ–‡â–‡â–‡
wandb:      train/ensemble_f1 â–„â–„â–„â–†â–„â–…â–„â–…â–†â–„â–â–…â–‡â–†â–…â–†â–„â–…â–…â–‡â–…â–…â–…â–…â–†â–„â–„â–„â–„â–ˆâ–…â–…â–„â–†â–ƒâ–„â–…â–‡â–…â–‡
wandb:         train/mil_loss â–…â–‚â–†â–ˆâ–‡â–„â–‡â–ƒâ–…â–†â–ƒâ–„â–ƒâ–‡â–…â–ƒâ–ƒâ–‡â–ƒâ–„â–â–†â–†â–†â–†â–…â–„â–â–„â–„â–â–‚â–‚â–…â–ƒâ–„â–‚â–†â–â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.34201
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.91524
wandb:      eval/avg_mil_loss 0.28878
wandb:       eval/ensemble_f1 0.91524
wandb:           train/avg_f1 0.91468
wandb:      train/ensemble_f1 0.91468
wandb:         train/mil_loss 0.25064
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fine-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8akxj2oj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050439-8akxj2oj/logs
wandb: ERROR Run 8akxj2oj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0507261l with config:
wandb: 	actor_learning_rate: 1.3895148242810273e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4897502018050327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050612-0507261l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0507261l
wandb: uploading history steps 183-186, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–ƒâ–†â–…â–‚â–†â–„â–â–‚â–…â–„â–ƒâ–†â–…â–…â–‚â–‡â–ƒâ–†â–…â–…â–ƒâ–…â–ƒâ–ˆâ–ƒâ–‚â–…â–†â–„â–„â–ˆâ–„â–„â–„â–ˆâ–‚â–…â–„
wandb:      eval/avg_mil_loss â–‚â–‡â–‚â–„â–†â–…â–…â–ƒâ–ƒâ–ƒâ–…â–‚â–†â–ƒâ–„â–…â–ˆâ–„â–…â–„â–â–„â–‡â–„â–„â–„â–…â–‚â–…â–„â–†â–†â–†â–†â–ƒâ–…â–‡â–…â–‡â–„
wandb:       eval/ensemble_f1 â–†â–…â–â–†â–‚â–„â–‚â–‚â–‚â–†â–‚â–†â–‡â–â–…â–‚â–ƒâ–‚â–…â–…â–…â–‚â–†â–†â–„â–‡â–ƒâ–ˆâ–„â–â–ƒâ–†â–‚â–ƒâ–‚â–„â–â–„â–ƒâ–†
wandb:           train/avg_f1 â–„â–…â–‚â–†â–…â–â–…â–ƒâ–…â–‚â–„â–ˆâ–„â–„â–…â–‚â–†â–„â–„â–…â–„â–…â–„â–ƒâ–…â–†â–„â–‚â–†â–ƒâ–…â–…â–…â–‡â–…â–ƒâ–‡â–‡â–†â–…
wandb:      train/ensemble_f1 â–„â–ˆâ–…â–„â–„â–…â–…â–„â–…â–‡â–ƒâ–†â–‡â–†â–…â–ƒâ–†â–‡â–…â–‡â–…â–†â–…â–…â–„â–ƒâ–„â–‡â–†â–„â–â–ƒâ–…â–ˆâ–…â–„â–†â–…â–…â–†
wandb:         train/mil_loss â–‡â–‡â–…â–‡â–†â–„â–…â–ˆâ–‡â–†â–‡â–†â–…â–…â–„â–…â–‡â–‡â–„â–…â–…â–…â–…â–…â–…â–…â–ˆâ–‡â–‡â–â–„â–…â–‡â–‡â–…â–‡â–‡â–…â–ƒâ–‡
wandb:      train/policy_loss â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–„â–ˆâ–ˆâ–â–ˆâ–â–„â–„â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–„â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–„â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91482
wandb: best/eval_avg_mil_loss 0.22048
wandb:  best/eval_ensemble_f1 0.91482
wandb:            eval/avg_f1 0.80957
wandb:      eval/avg_mil_loss 1.27666
wandb:       eval/ensemble_f1 0.80957
wandb:           train/avg_f1 0.74145
wandb:      train/ensemble_f1 0.74145
wandb:         train/mil_loss 1.1549
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0507261l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050612-0507261l/logs
wandb: ERROR Run 0507261l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: az1lsibq with config:
wandb: 	actor_learning_rate: 1.2016142109494789e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7494108516954057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050939-az1lsibq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az1lsibq
wandb: uploading history steps 123-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–„â–†â–ˆâ–ˆâ–…â–…â–„â–…â–…â–†â–‡â–ƒâ–‚â–‡â–†â–‡â–ˆâ–‚â–…â–ˆâ–…â–…â–„â–â–â–ˆâ–„â–„â–‚â–‚â–„â–„â–„â–…â–…â–…â–…
wandb:      eval/avg_mil_loss â–„â–‡â–ƒâ–ˆâ–ƒâ–ƒâ–„â–ƒâ–‡â–„â–ƒâ–†â–†â–…â–ƒâ–ƒâ–‡â–…â–â–†â–„â–†â–‡â–â–â–ƒâ–‡â–â–…â–†â–â–…â–„â–…â–„â–…â–†â–„â–„â–‡
wandb:       eval/ensemble_f1 â–„â–„â–…â–„â–†â–ˆâ–†â–…â–‡â–†â–…â–…â–ƒâ–„â–…â–â–‡â–†â–â–‡â–„â–…â–…â–„â–…â–‡â–„â–ˆâ–‚â–†â–‚â–ˆâ–‡â–†â–…â–‚â–ˆâ–…â–…â–ˆ
wandb:           train/avg_f1 â–„â–‡â–‚â–…â–†â–…â–‡â–â–†â–…â–‚â–†â–†â–‚â–‡â–…â–…â–†â–ƒâ–„â–…â–„â–…â–†â–…â–†â–â–†â–‚â–†â–‡â–ˆâ–‡â–…â–‡â–„â–„â–‡â–†â–…
wandb:      train/ensemble_f1 â–†â–†â–…â–…â–…â–†â–â–†â–ƒâ–†â–â–…â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–…â–â–ƒâ–‚â–…â–ˆâ–†â–ƒâ–…â–†â–ƒâ–†â–„â–†â–…â–ƒâ–…â–…â–…â–…
wandb:         train/mil_loss â–â–„â–…â–ƒâ–ƒâ–„â–„â–…â–…â–†â–…â–†â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–ˆâ–†â–„â–†â–‚â–‚â–„â–„â–„â–„â–â–…â–„â–…â–…â–„â–…â–†â–ƒâ–„â–‚â–‚
wandb:      train/policy_loss â–…â–…â–…â–â–ˆâ–…â–…â–…â–â–ˆâ–â–…â–â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–…â–…â–…â–…â–â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–ˆâ–…â–…â–…â–ˆâ–â–ˆâ–ˆâ–â–â–…â–…â–â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–…â–…â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.27414
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.73484
wandb:      eval/avg_mil_loss 2.21561
wandb:       eval/ensemble_f1 0.73484
wandb:           train/avg_f1 0.77154
wandb:      train/ensemble_f1 0.77154
wandb:         train/mil_loss 1.22767
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run denim-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/az1lsibq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050939-az1lsibq/logs
wandb: ERROR Run az1lsibq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: x5pi7mey with config:
wandb: 	actor_learning_rate: 0.0004986861987900722
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 99
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05880241171963107
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051137-x5pi7mey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x5pi7mey
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 95-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–„â–ˆâ–‚â–‡â–„â–‚â–â–‚â–ˆâ–‚â–â–†â–ˆâ–„â–ˆâ–ˆâ–…â–„â–†â–ˆâ–‡â–ˆâ–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‚â–ˆâ–ˆâ–‚â–â–ˆâ–‚â–†
wandb:      eval/avg_mil_loss â–‚â–„â–‚â–â–ƒâ–â–„â–â–‚â–…â–â–ˆâ–ˆâ–…â–‚â–ƒâ–â–ƒâ–…â–…â–ƒâ–†â–‡â–‚â–â–â–‚â–…â–â–ƒâ–…â–ƒâ–…â–â–‡â–„â–ˆâ–‚â–â–‚
wandb:       eval/ensemble_f1 â–ˆâ–‡â–ˆâ–ˆâ–‚â–„â–ˆâ–†â–‡â–„â–â–„â–‚â–‡â–‡â–‡â–‡â–ˆâ–‡â–„â–ˆâ–…â–ˆâ–‚â–‡â–‡â–…â–‡â–‡â–‡â–â–‡â–†â–ˆâ–ˆâ–†â–ˆâ–‡â–â–‡
wandb:           train/avg_f1 â–„â–„â–‡â–…â–„â–…â–ƒâ–…â–„â–…â–ƒâ–…â–ƒâ–ˆâ–â–†â–„â–…â–„â–‡â–ƒâ–†â–‚â–†â–…â–„â–†â–ƒâ–…â–ˆâ–…â–‡â–‡â–…â–‡â–…â–„â–…â–…â–„
wandb:      train/ensemble_f1 â–…â–‚â–„â–†â–†â–…â–‡â–„â–…â–…â–†â–â–…â–‡â–‚â–‚â–‡â–…â–…â–ˆâ–†â–†â–…â–…â–…â–†â–…â–…â–…â–„â–†â–…â–†â–…â–…â–†â–…â–…â–„â–‡
wandb:         train/mil_loss â–…â–…â–…â–„â–†â–†â–†â–ˆâ–†â–„â–‚â–ƒâ–†â–„â–ƒâ–†â–ƒâ–…â–ƒâ–†â–„â–ƒâ–…â–…â–ƒâ–„â–†â–‡â–‚â–†â–…â–…â–…â–ˆâ–â–„â–†â–„â–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92281
wandb: best/eval_avg_mil_loss 0.32441
wandb:  best/eval_ensemble_f1 0.92281
wandb:            eval/avg_f1 0.89312
wandb:      eval/avg_mil_loss 1.29437
wandb:       eval/ensemble_f1 0.89312
wandb:           train/avg_f1 0.83557
wandb:      train/ensemble_f1 0.83557
wandb:         train/mil_loss 1.03374
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run honest-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x5pi7mey
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051137-x5pi7mey/logs
wandb: ERROR Run x5pi7mey errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0oleuv4o with config:
wandb: 	actor_learning_rate: 0.0005540688190108043
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4011252236110291
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051310-0oleuv4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0oleuv4o
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ƒâ–ˆâ–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–†â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–â–‚â–ˆâ–â–‚â–â–â–„â–â–‡â–‡â–ƒâ–‚â–â–
wandb:       eval/ensemble_f1 â–‡â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–†â–â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–„â–‡â–†â–‡â–„â–…â–„â–†â–…â–…â–†â–‡â–„â–ƒâ–„â–†â–‡â–†â–â–…â–â–‚â–…â–„â–‚â–ˆâ–„â–‡â–…â–†â–‡â–‡â–ƒâ–…â–‡â–†â–„â–†â–„
wandb:      train/ensemble_f1 â–„â–‡â–â–ƒâ–†â–…â–†â–…â–…â–…â–…â–‡â–…â–‚â–…â–‚â–„â–„â–ƒâ–…â–„â–ƒâ–…â–ƒâ–„â–†â–…â–…â–†â–…â–…â–…â–ˆâ–„â–‡â–†â–†â–ˆâ–‡â–…
wandb:         train/mil_loss â–„â–„â–â–ƒâ–„â–…â–†â–â–ƒâ–â–ƒâ–„â–â–â–‡â–‡â–…â–‚â–â–†â–â–‚â–â–ˆâ–…â–…â–â–ƒâ–…â–†â–ƒâ–…â–…â–ƒâ–†â–‡â–â–ƒâ–†â–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–â–„â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.25487
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.89873
wandb:      eval/avg_mil_loss 0.25595
wandb:       eval/ensemble_f1 0.89873
wandb:            test/avg_f1 0.92999
wandb:      test/avg_mil_loss 0.13694
wandb:       test/ensemble_f1 0.92999
wandb:           train/avg_f1 0.85684
wandb:      train/ensemble_f1 0.85684
wandb:         train/mil_loss 0.42823
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run blooming-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0oleuv4o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051310-0oleuv4o/logs
wandb: Agent Starting Run: ro7f19zq with config:
wandb: 	actor_learning_rate: 0.0007051797173640962
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5275383522950099
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051459-ro7f19zq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ro7f19zq
wandb: uploading history steps 98-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–†â–‚â–‡â–ƒâ–ˆâ–…â–…â–†â–„â–†â–‡â–â–„â–†â–†â–ˆâ–ƒâ–†â–…â–„â–„â–ˆâ–…â–…â–ˆâ–„â–„â–†â–„â–„â–‡â–â–ƒâ–…â–â–†â–‡â–†
wandb:      eval/avg_mil_loss â–â–…â–…â–â–…â–ƒâ–‚â–„â–…â–„â–ƒâ–‡â–â–ˆâ–†â–†â–‚â–â–ƒâ–‡â–ˆâ–‡â–…â–ˆâ–ƒâ–ƒâ–†â–…â–†â–…â–‡â–ƒâ–ˆâ–‡â–ˆâ–…â–ƒâ–â–†â–ƒ
wandb:       eval/ensemble_f1 â–…â–ƒâ–ˆâ–„â–ƒâ–„â–ƒâ–‡â–„â–†â–„â–†â–†â–†â–„â–„â–…â–†â–ƒâ–ƒâ–â–„â–„â–ˆâ–…â–†â–„â–„â–…â–…â–…â–„â–ƒâ–ˆâ–ƒâ–â–ƒâ–‚â–…â–†
wandb:           train/avg_f1 â–†â–…â–†â–„â–â–ƒâ–†â–…â–…â–…â–‚â–‚â–…â–‡â–…â–†â–â–†â–†â–…â–†â–ƒâ–†â–…â–ˆâ–…â–‡â–…â–„â–†â–†â–†â–†â–…â–†â–†â–…â–†â–…â–…
wandb:      train/ensemble_f1 â–†â–†â–…â–„â–†â–„â–‡â–…â–†â–‡â–ˆâ–‡â–†â–„â–â–†â–†â–…â–†â–†â–„â–„â–†â–ƒâ–„â–…â–…â–…â–ˆâ–„â–…â–…â–†â–†â–†â–„â–„â–†â–†â–„
wandb:         train/mil_loss â–ƒâ–„â–â–„â–ƒâ–„â–…â–‚â–…â–ˆâ–…â–„â–â–ƒâ–„â–…â–…â–†â–‡â–ƒâ–ƒâ–…â–…â–ƒâ–…â–ˆâ–„â–ƒâ–…â–ƒâ–†â–…â–‡â–†â–…â–‚â–†â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–â–…â–ˆâ–…â–â–â–ˆâ–â–ˆâ–…â–â–ˆâ–…â–…â–ˆâ–ˆâ–â–â–â–â–â–â–…â–…â–…â–ˆâ–ˆâ–â–â–â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–ˆâ–â–„â–ˆâ–â–â–ˆâ–„â–ˆâ–„â–â–„â–â–â–â–ˆâ–ˆâ–„â–„â–ˆâ–â–„â–â–â–„â–â–â–„â–„â–ˆâ–â–„â–„â–ˆâ–ˆâ–„â–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90283
wandb: best/eval_avg_mil_loss 0.25488
wandb:  best/eval_ensemble_f1 0.90283
wandb:            eval/avg_f1 0.83154
wandb:      eval/avg_mil_loss 0.61582
wandb:       eval/ensemble_f1 0.83154
wandb:           train/avg_f1 0.80573
wandb:      train/ensemble_f1 0.80573
wandb:         train/mil_loss 0.99594
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ro7f19zq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051459-ro7f19zq/logs
wandb: ERROR Run ro7f19zq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0k8bsmzn with config:
wandb: 	actor_learning_rate: 0.0005795801635478494
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4789669032226256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051709-0k8bsmzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0k8bsmzn
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 42-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ƒâ–ˆâ–…â–…â–‡â–â–‡â–†â–‡â–‡â–‚â–‡â–‡â–‡â–‡â–ƒâ–‡â–‡â–„â–‡â–‡â–â–ƒâ–…â–†â–†â–†â–‚â–ƒâ–ˆâ–‚â–ƒâ–†â–ˆâ–†â–‡â–â–‡
wandb:      eval/avg_mil_loss â–„â–â–…â–â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–â–…â–â–‡â–â–‚â–‚â–…â–â–ƒâ–â–„â–â–…â–„â–‚â–„â–â–…â–ˆâ–…â–â–â–ˆâ–‚â–†â–â–„â–‚
wandb:       eval/ensemble_f1 â–„â–„â–ˆâ–†â–†â–‡â–‚â–‡â–‡â–…â–‡â–ƒâ–‡â–‡â–â–‡â–‡â–„â–‡â–‡â–…â–‡â–„â–‡â–ƒâ–†â–†â–„â–‡â–†â–„â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–ˆâ–†â–‚â–‡
wandb:           train/avg_f1 â–…â–†â–„â–…â–…â–…â–„â–…â–ƒâ–ˆâ–„â–‚â–ƒâ–„â–„â–…â–„â–†â–…â–‚â–…â–…â–…â–†â–â–ƒâ–‡â–„â–ƒâ–„â–‚â–ˆâ–‡â–ƒâ–ƒâ–†â–†â–…â–…â–
wandb:      train/ensemble_f1 â–…â–†â–„â–…â–…â–…â–„â–…â–ˆâ–ƒâ–ˆâ–‚â–ƒâ–„â–„â–…â–„â–…â–…â–â–…â–…â–…â–†â–â–ƒâ–‡â–„â–ƒâ–„â–‚â–ˆâ–‡â–ƒâ–ƒâ–†â–†â–…â–†â–
wandb:         train/mil_loss â–…â–„â–ƒâ–„â–†â–†â–„â–„â–‚â–„â–â–…â–„â–ƒâ–‡â–‚â–„â–…â–ƒâ–„â–†â–†â–‚â–…â–†â–†â–‚â–„â–ƒâ–‡â–…â–â–ƒâ–…â–ˆâ–†â–„â–‚â–‚â–ƒ
wandb:      train/policy_loss â–â–…â–…â–…â–…â–ˆâ–â–â–â–ˆâ–â–ˆâ–â–…â–…â–…â–â–ˆâ–…â–ˆâ–…â–ˆâ–…â–â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–…â–ˆâ–…â–â–â–…â–ˆâ–ˆâ–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–„â–„â–ˆâ–â–â–ˆâ–â–„â–â–ˆâ–â–„â–„â–„â–â–„â–ˆâ–ˆâ–ˆâ–„â–â–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–ˆâ–„â–ˆâ–â–â–„â–ˆâ–ˆâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92249
wandb: best/eval_avg_mil_loss 0.23378
wandb:  best/eval_ensemble_f1 0.92249
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.29352
wandb:       eval/ensemble_f1 0.89963
wandb:           train/avg_f1 0.84509
wandb:      train/ensemble_f1 0.84509
wandb:         train/mil_loss 0.40876
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0k8bsmzn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051709-0k8bsmzn/logs
wandb: ERROR Run 0k8bsmzn errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: yaj2y5df with config:
wandb: 	actor_learning_rate: 5.338695990004126e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4623155714048989
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051812-yaj2y5df
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yaj2y5df
wandb: uploading wandb-summary.json; uploading history steps 93-111, summary
wandb: uploading history steps 93-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–â–ˆâ–‡â–‚â–ˆâ–ƒâ–ˆâ–ˆâ–‚â–ˆâ–‡â–‚â–‚â–â–ˆâ–‚â–„â–ˆâ–ˆâ–â–ˆâ–†â–†â–„â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–„â–ˆ
wandb:      eval/avg_mil_loss â–†â–„â–â–â–„â–‚â–â–â–â–ƒâ–…â–„â–†â–†â–‚â–â–â–…â–ƒâ–â–ƒâ–…â–‚â–ˆâ–…â–ƒâ–â–â–â–â–â–ƒâ–â–â–…â–ƒâ–â–â–ƒâ–
wandb:       eval/ensemble_f1 â–„â–†â–ˆâ–â–‡â–â–‡â–ˆâ–ˆâ–ˆâ–‚â–‡â–ˆâ–‚â–ˆâ–‡â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–†â–ˆâ–†â–…â–‚â–â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–‚â–ˆ
wandb:           train/avg_f1 â–‡â–†â–„â–‡â–‡â–ˆâ–ƒâ–†â–ˆâ–†â–„â–†â–„â–†â–‡â–…â–„â–â–ˆâ–†â–„â–†â–…â–ˆâ–‚â–ƒâ–‡â–ƒâ–…â–†â–…â–‡â–†â–„â–‡â–†â–†â–…â–„â–†
wandb:      train/ensemble_f1 â–‡â–†â–‡â–†â–‡â–†â–ƒâ–ˆâ–ƒâ–†â–ƒâ–†â–‡â–ƒâ–ƒâ–…â–„â–ƒâ–„â–ƒâ–…â–ƒâ–…â–ƒâ–‚â–…â–†â–‡â–†â–‚â–„â–…â–‡â–…â–†â–â–…â–„â–…â–†
wandb:         train/mil_loss â–„â–„â–†â–ˆâ–ƒâ–…â–„â–‡â–ƒâ–â–†â–„â–†â–‡â–…â–ƒâ–„â–†â–„â–„â–„â–â–ƒâ–…â–…â–‚â–ƒâ–…â–„â–‚â–â–‚â–„â–„â–‚â–‚â–‚â–‚â–„â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–â–â–â–…â–…â–…â–…â–…â–…â–â–…â–â–ˆâ–…â–…â–…â–…â–â–ƒâ–…â–…â–…â–â–â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–â–…â–â–…â–â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–â–ƒâ–…â–…â–…â–â–…â–…â–…â–â–â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93007
wandb: best/eval_avg_mil_loss 0.36912
wandb:  best/eval_ensemble_f1 0.93007
wandb:            eval/avg_f1 0.89485
wandb:      eval/avg_mil_loss 0.42964
wandb:       eval/ensemble_f1 0.89485
wandb:           train/avg_f1 0.83183
wandb:      train/ensemble_f1 0.83183
wandb:         train/mil_loss 0.5263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lemon-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yaj2y5df
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051812-yaj2y5df/logs
wandb: ERROR Run yaj2y5df errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xou0udua with config:
wandb: 	actor_learning_rate: 8.776424713560277e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8611017299708021
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051950-xou0udua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xou0udua
wandb: uploading history steps 52-68, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–„â–‡â–‡â–†â–„â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–„â–‡â–‡â–„â–„â–‡â–‡â–‡â–ˆâ–ˆâ–†â–â–‡â–†â–‡â–…â–ˆâ–„â–ˆâ–ˆâ–‡â–ˆâ–…â–„â–ˆâ–‡
wandb:      eval/avg_mil_loss â–…â–„â–â–â–â–†â–â–â–ˆâ–ƒâ–â–â–†â–â–‚â–â–â–ˆâ–…â–â–‡â–â–„â–â–â–â–‡â–â–…â–‚â–ˆâ–ƒâ–â–„â–…â–â–…â–â–„â–…
wandb:       eval/ensemble_f1 â–‡â–ƒâ–‡â–‡â–‡â–…â–‡â–‡â–ˆâ–ƒâ–…â–‡â–‡â–ˆâ–‡â–ˆâ–ƒâ–‚â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–‡â–„â–ˆâ–ƒâ–„â–ˆâ–…â–‡â–â–ƒâ–ƒâ–‡â–‡â–ƒâ–‡
wandb:           train/avg_f1 â–…â–„â–„â–ƒâ–…â–â–„â–‡â–†â–â–ˆâ–ˆâ–…â–‚â–†â–ƒâ–‡â–ƒâ–†â–ˆâ–†â–…â–†â–‚â–ƒâ–†â–‡â–†â–ƒâ–„â–…â–…â–ƒâ–„â–ƒâ–‚â–‡â–†â–„â–‡
wandb:      train/ensemble_f1 â–„â–ƒâ–‚â–†â–ˆâ–„â–†â–…â–‚â–„â–†â–‡â–„â–â–†â–…â–„â–‡â–…â–ˆâ–‚â–„â–…â–†â–…â–‚â–„â–‚â–…â–„â–„â–â–„â–‚â–‚â–‚â–‡â–…â–„â–†
wandb:         train/mil_loss â–ƒâ–†â–ˆâ–†â–„â–‚â–„â–‡â–ƒâ–…â–„â–‚â–„â–„â–ƒâ–†â–†â–ƒâ–„â–„â–„â–„â–ƒâ–„â–‡â–â–ƒâ–…â–…â–ƒâ–ƒâ–„â–…â–‚â–†â–â–‚â–†â–â–…
wandb:      train/policy_loss â–„â–„â–„â–â–â–ˆâ–ˆâ–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–„â–„â–„â–â–„â–„â–â–„â–ˆâ–„â–â–„â–â–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91909
wandb: best/eval_avg_mil_loss 0.29283
wandb:  best/eval_ensemble_f1 0.91909
wandb:            eval/avg_f1 0.87537
wandb:      eval/avg_mil_loss 1.13423
wandb:       eval/ensemble_f1 0.87537
wandb:           train/avg_f1 0.87076
wandb:      train/ensemble_f1 0.87076
wandb:         train/mil_loss 0.89583
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vibrant-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xou0udua
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051950-xou0udua/logs
wandb: ERROR Run xou0udua errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tnhatydn with config:
wandb: 	actor_learning_rate: 6.340074782229502e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4221644215275578
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052058-tnhatydn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tnhatydn
wandb: uploading history steps 137-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–ƒâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–†â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–…â–â–â–ƒâ–…â–†â–‚â–„â–â–‚â–â–‚â–â–‚â–â–‚â–â–‡â–â–â–â–†â–‚â–‚â–‚â–…â–â–…â–â–‚â–â–â–â–â–ˆâ–†â–†â–â–†
wandb:       eval/ensemble_f1 â–‚â–ˆâ–ˆâ–‚â–‡â–ƒâ–ƒâ–ˆâ–ˆâ–ˆâ–â–‚â–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–…â–‡â–…â–†â–ˆâ–‡â–‚â–‡â–ˆâ–…â–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–‚â–ƒâ–ˆâ–‚â–†â–…â–„â–ƒâ–ƒâ–‡â–„â–ƒâ–„â–…â–‚â–„â–†â–…â–†â–‚â–ƒâ–ƒâ–…â–ˆâ–…â–„â–†â–†â–†â–…â–‡â–„â–ˆâ–†â–…â–â–…â–ƒâ–‡â–†
wandb:      train/ensemble_f1 â–ˆâ–ƒâ–…â–…â–†â–†â–‡â–„â–…â–†â–„â–…â–…â–ƒâ–ˆâ–ƒâ–â–…â–ˆâ–‡â–…â–‚â–…â–„â–†â–„â–‡â–‚â–‡â–ˆâ–†â–…â–‡â–‡â–†â–…â–ƒâ–‡â–„â–†
wandb:         train/mil_loss â–„â–ƒâ–†â–ƒâ–†â–ˆâ–ƒâ–†â–„â–†â–…â–„â–ƒâ–‡â–„â–…â–â–†â–â–â–‚â–„â–ƒâ–„â–…â–ƒâ–ƒâ–…â–‚â–†â–‚â–†â–â–‚â–†â–ƒâ–…â–…â–‡â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91161
wandb: best/eval_avg_mil_loss 0.27117
wandb:  best/eval_ensemble_f1 0.91161
wandb:            eval/avg_f1 0.87779
wandb:      eval/avg_mil_loss 1.14951
wandb:       eval/ensemble_f1 0.87779
wandb:           train/avg_f1 0.88488
wandb:      train/ensemble_f1 0.88488
wandb:         train/mil_loss 0.31815
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run resilient-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tnhatydn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052058-tnhatydn/logs
wandb: ERROR Run tnhatydn errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4c1loiqb with config:
wandb: 	actor_learning_rate: 0.0001405249573010007
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11253828324683568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052312-4c1loiqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4c1loiqb
wandb: uploading wandb-summary.json
wandb: uploading history steps 112-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–†â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–ˆâ–ˆâ–„â–‚â–‚â–ˆâ–‚â–‚â–ˆâ–‡â–ˆâ–‚â–ƒâ–ˆâ–‡â–ˆâ–‚â–‡â–ˆâ–ˆâ–„â–‡â–â–â–‚â–‚â–‡â–‡â–ˆâ–‡â–‚â–ˆâ–‚â–ˆ
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–â–â–„â–‡â–„â–…â–‡â–„â–â–…â–â–â–â–ˆâ–„â–â–â–…â–â–â–†â–„â–ˆâ–„â–†â–ˆâ–‡â–ƒâ–„â–â–…â–†â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–‚â–ƒâ–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ˆâ–ˆâ–‡â–ƒâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–â–‚â–‚â–ƒâ–‡â–ˆâ–â–ƒâ–ˆâ–‡â–ˆâ–‚â–ˆ
wandb:           train/avg_f1 â–…â–„â–ƒâ–â–„â–â–„â–†â–„â–â–„â–ƒâ–†â–†â–„â–ˆâ–†â–‚â–ƒâ–ƒâ–„â–…â–†â–ˆâ–„â–‡â–ƒâ–„â–ˆâ–†â–…â–‚â–‚â–…â–…â–‚â–ƒâ–ƒâ–…â–†
wandb:      train/ensemble_f1 â–…â–â–‡â–…â–ƒâ–„â–†â–‡â–†â–ƒâ–„â–†â–‡â–†â–…â–ˆâ–ƒâ–„â–‡â–‡â–…â–…â–†â–‚â–†â–„â–‡â–‡â–ˆâ–‡â–‡â–…â–†â–†â–‡â–‡â–†â–…â–‡â–ƒ
wandb:         train/mil_loss â–†â–ƒâ–…â–„â–„â–‚â–„â–ƒâ–ƒâ–…â–†â–‚â–…â–ƒâ–â–„â–„â–„â–„â–â–ƒâ–„â–†â–ƒâ–ƒâ–„â–„â–…â–ˆâ–â–„â–‚â–…â–ƒâ–…â–„â–„â–…â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.38974
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.90325
wandb:      eval/avg_mil_loss 0.40539
wandb:       eval/ensemble_f1 0.90325
wandb:           train/avg_f1 0.74329
wandb:      train/ensemble_f1 0.74329
wandb:         train/mil_loss 1.28133
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run proud-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4c1loiqb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052312-4c1loiqb/logs
wandb: ERROR Run 4c1loiqb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 2hy0sj0l with config:
wandb: 	actor_learning_rate: 0.0005015367254993286
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5569132019802567
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052456-2hy0sj0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2hy0sj0l
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–ˆâ–‚â–„â–…â–‡â–„â–‡â–„â–†â–„â–…â–ƒâ–…â–†â–ˆâ–†â–†â–…â–†â–‡â–…â–„â–â–‚â–†â–…â–„â–‡â–†â–…â–†â–ˆâ–†â–ƒâ–†â–†â–„â–‚
wandb:      eval/avg_mil_loss â–â–„â–„â–â–ƒâ–†â–ƒâ–†â–„â–†â–â–…â–ƒâ–„â–‡â–†â–‚â–ƒâ–…â–‡â–„â–ƒâ–‡â–…â–ƒâ–†â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–†â–â–â–ˆâ–„â–†
wandb:       eval/ensemble_f1 â–ˆâ–„â–â–†â–‚â–…â–…â–‚â–†â–‡â–…â–‡â–…â–…â–„â–â–…â–…â–ƒâ–‡â–…â–ƒâ–„â–…â–â–‚â–ƒâ–†â–„â–†â–†â–‡â–â–…â–…â–ƒâ–‡â–‚â–…â–
wandb:           train/avg_f1 â–„â–‚â–„â–â–ƒâ–„â–†â–‡â–ƒâ–„â–†â–„â–ƒâ–„â–‡â–„â–ˆâ–†â–„â–ƒâ–„â–…â–†â–…â–‡â–„â–…â–„â–ƒâ–†â–ƒâ–…â–…â–„â–…â–…â–…â–„â–ƒâ–…
wandb:      train/ensemble_f1 â–„â–„â–â–ƒâ–„â–ƒâ–…â–„â–…â–†â–„â–ƒâ–…â–…â–„â–…â–†â–‡â–‡â–â–ƒâ–â–†â–„â–‡â–„â–…â–‡â–†â–†â–„â–†â–‚â–ˆâ–…â–‡â–…â–…â–…â–…
wandb:         train/mil_loss â–…â–‡â–â–ˆâ–†â–†â–ƒâ–…â–„â–„â–†â–…â–„â–‚â–„â–…â–†â–ƒâ–„â–‚â–ƒâ–†â–„â–‚â–ƒâ–ƒâ–…â–„â–†â–ƒâ–†â–†â–…â–…â–„â–ƒâ–†â–„â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–â–â–„â–ˆâ–â–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–â–„â–ˆâ–„â–â–„â–„â–„â–ˆâ–â–„â–„â–â–â–„â–ˆâ–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91524
wandb: best/eval_avg_mil_loss 0.24393
wandb:  best/eval_ensemble_f1 0.91524
wandb:            eval/avg_f1 0.68464
wandb:      eval/avg_mil_loss 1.39777
wandb:       eval/ensemble_f1 0.68464
wandb:           train/avg_f1 0.8225
wandb:      train/ensemble_f1 0.8225
wandb:         train/mil_loss 0.87136
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2hy0sj0l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052456-2hy0sj0l/logs
wandb: ERROR Run 2hy0sj0l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ttbt731e with config:
wandb: 	actor_learning_rate: 1.3862987397811845e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20290671275703764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052655-ttbt731e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttbt731e
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–…â–†â–†â–†â–†â–‡â–‡â–†â–„â–„â–†â–„â–‡â–†â–‡â–‡â–†â–†â–…â–â–…â–†â–„â–ƒâ–†â–…â–‡â–†â–‡â–†â–†â–†â–…â–…â–‚â–†â–†â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–„â–‚â–„â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–â–…â–†â–†â–†â–†â–„â–‡â–†â–…â–…â–„â–„â–†â–‡â–†â–‡â–†â–‡â–‡â–†â–…â–†â–‡â–…â–†â–ƒâ–ƒâ–†â–†â–‡â–‚â–‡â–…â–‡â–ƒâ–†â–ˆâ–„â–„
wandb:           train/avg_f1 â–†â–â–„â–„â–ƒâ–ƒâ–‡â–‡â–‡â–„â–ƒâ–„â–ƒâ–†â–†â–†â–‚â–†â–†â–‚â–ƒâ–‡â–ˆâ–ˆâ–‡â–†â–†â–„â–…â–„â–‚â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–…â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–‚â–‚â–†â–…â–†â–†â–â–ƒâ–†â–†â–ƒâ–‚â–ˆâ–‡â–…â–ƒâ–†â–„â–…â–…â–ƒâ–…â–…â–â–â–„â–„â–ˆâ–„â–‚â–†â–†â–‡â–†â–„â–†â–ƒâ–„
wandb:         train/mil_loss â–†â–…â–ƒâ–‚â–â–‡â–„â–…â–ƒâ–ƒâ–‚â–‚â–â–„â–‚â–ˆâ–ƒâ–ƒâ–†â–â–†â–†â–†â–…â–‚â–…â–ƒâ–…â–…â–‚â–â–†â–…â–„â–„â–†â–„â–‡â–‚â–‡
wandb:      train/policy_loss â–ˆâ–„â–â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–„â–„â–â–â–ˆâ–â–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.926
wandb: best/eval_avg_mil_loss 0.21256
wandb:  best/eval_ensemble_f1 0.926
wandb:            eval/avg_f1 0.86444
wandb:      eval/avg_mil_loss 0.36444
wandb:       eval/ensemble_f1 0.86444
wandb:           train/avg_f1 0.884
wandb:      train/ensemble_f1 0.884
wandb:         train/mil_loss 0.25856
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttbt731e
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052655-ttbt731e/logs
wandb: ERROR Run ttbt731e errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5tynn9q1 with config:
wandb: 	actor_learning_rate: 5.370354296041898e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013171697156451834
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052859-5tynn9q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5tynn9q1
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–†â–…â–†â–„â–†â–…â–†â–ˆâ–ˆâ–‚â–„â–†â–„â–†â–„â–ƒâ–…â–„â–â–„â–‡â–…â–†â–†â–…â–…â–†â–†â–…â–…â–†â–‡â–†â–†â–ƒâ–ˆâ–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–†â–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–â–†â–†â–ƒâ–†â–…â–‡â–…â–…â–„â–‚â–ƒâ–â–„â–„â–„â–„â–ƒâ–â–†â–…â–…â–ƒâ–ƒâ–…â–ˆâ–â–‚â–…
wandb:       eval/ensemble_f1 â–„â–„â–†â–„â–†â–‡â–†â–…â–†â–†â–ˆâ–‚â–„â–†â–†â–†â–„â–ƒâ–…â–…â–â–„â–‡â–â–ˆâ–†â–…â–†â–ˆâ–†â–…â–…â–†â–‡â–‡â–†â–ƒâ–ˆâ–‡â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–†â–ƒâ–†â–„â–†â–ƒâ–‚â–…â–ƒâ–…â–„â–…â–…â–â–…â–†â–ƒâ–…â–‚â–‡â–…â–â–‚â–…â–…â–†â–„â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡â–…â–ˆâ–†â–…â–†
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–†â–ƒâ–†â–„â–ƒâ–â–†â–ƒâ–…â–„â–…â–†â–‚â–†â–„â–„â–‚â–‡â–‚â–ƒâ–†â–‡â–…â–†â–„â–ƒâ–…â–ƒâ–†â–ˆâ–‡â–„â–„â–ˆâ–†â–†â–…â–†
wandb:         train/mil_loss â–‚â–â–‡â–ƒâ–…â–„â–ƒâ–‚â–„â–…â–…â–…â–‚â–ƒâ–„â–†â–„â–†â–‡â–„â–…â–„â–‚â–…â–†â–…â–…â–…â–„â–„â–„â–ˆâ–„â–†â–ˆâ–ƒâ–…â–â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–„â–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–ˆâ–â–â–â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–ˆâ–â–„â–„â–â–â–ˆâ–„â–â–â–ˆâ–â–â–â–„â–â–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–„â–ˆâ–â–ˆâ–„â–ˆâ–ˆâ–ˆâ–â–â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–ˆâ–â–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–„â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89983
wandb: best/eval_avg_mil_loss 0.37057
wandb:  best/eval_ensemble_f1 0.89983
wandb:            eval/avg_f1 0.81021
wandb:      eval/avg_mil_loss 1.27664
wandb:       eval/ensemble_f1 0.81021
wandb:            test/avg_f1 0.81941
wandb:      test/avg_mil_loss 0.83197
wandb:       test/ensemble_f1 0.81941
wandb:           train/avg_f1 0.81815
wandb:      train/ensemble_f1 0.81815
wandb:         train/mil_loss 0.69839
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run peachy-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5tynn9q1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052859-5tynn9q1/logs
wandb: Agent Starting Run: 7vlclpy8 with config:
wandb: 	actor_learning_rate: 8.594685939333766e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10283865968694672
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053005-7vlclpy8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vlclpy8
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading history steps 102-116, summary
wandb: uploading history steps 102-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–…â–â–‚â–‡â–‡â–„â–ˆâ–‡â–ƒâ–…â–…â–‡â–ˆâ–‚â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‚â–‡â–†â–‡â–†â–‡â–‚â–‡â–‡â–‡â–…â–‡â–ƒâ–‡â–ˆâ–†â–‡â–ƒ
wandb:      eval/avg_mil_loss â–â–ƒâ–‚â–„â–ˆâ–„â–â–…â–‚â–‚â–‚â–â–‚â–â–ƒâ–†â–â–…â–â–â–‚â–„â–â–…â–…â–‚â–†â–†â–ƒâ–„â–â–‚â–…â–‚â–„â–‚â–„â–â–â–ƒ
wandb:       eval/ensemble_f1 â–‡â–„â–„â–ˆâ–‡â–…â–‡â–â–…â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–„â–…â–…â–†â–…â–ˆâ–‡â–„â–‡â–â–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–‡â–‚â–„â–„â–‡â–‡â–‡â–†
wandb:           train/avg_f1 â–†â–†â–†â–„â–…â–†â–„â–‡â–ƒâ–â–…â–…â–„â–„â–…â–…â–…â–„â–…â–‡â–‡â–‡â–†â–‡â–‚â–„â–…â–ˆâ–†â–…â–†â–…â–ˆâ–ˆâ–…â–‚â–†â–‡â–†â–†
wandb:      train/ensemble_f1 â–…â–â–ƒâ–…â–…â–ƒâ–†â–†â–‚â–â–ƒâ–†â–‚â–ˆâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–†â–…â–†â–…â–„â–…â–‡â–ƒâ–‡â–â–ƒâ–„â–„â–„â–ƒâ–…â–†â–„
wandb:         train/mil_loss â–„â–„â–„â–…â–â–…â–„â–ƒâ–ƒâ–ƒâ–…â–…â–‚â–„â–…â–†â–‚â–„â–„â–ƒâ–ˆâ–„â–ƒâ–„â–†â–…â–„â–„â–†â–…â–„â–‚â–…â–„â–‚â–…â–…â–„â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.24472
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.8502
wandb:      eval/avg_mil_loss 0.45357
wandb:       eval/ensemble_f1 0.8502
wandb:           train/avg_f1 0.85242
wandb:      train/ensemble_f1 0.85242
wandb:         train/mil_loss 0.74159
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vlclpy8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053005-7vlclpy8/logs
wandb: ERROR Run 7vlclpy8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kye8nxc0 with config:
wandb: 	actor_learning_rate: 1.5572829940534458e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5247598145756838
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053204-kye8nxc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kye8nxc0
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–„â–„â–ƒâ–ƒâ–…â–…â–‚â–â–…â–‚â–ƒâ–†â–…â–…â–ƒâ–‡â–‡â–ƒâ–†â–„â–†â–…â–„â–†â–…â–…â–ƒâ–…â–†â–†â–…â–ˆâ–ˆâ–ƒâ–†â–…â–…â–ƒ
wandb:      eval/avg_mil_loss â–â–„â–ƒâ–‚â–ƒâ–†â–â–‚â–‚â–ˆâ–ƒâ–â–â–‚â–â–‡â–‡â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–ƒâ–â–‚â–â–‚â–‚â–‚â–â–‚â–‡â–ƒâ–â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–„â–„â–…â–â–…â–…â–„â–ƒâ–„â–†â–ƒâ–„â–„â–†â–…â–„â–‡â–…â–ƒâ–‚â–…â–†â–„â–…â–‡â–†â–…â–ˆâ–‡â–…â–‡â–…â–†â–‡â–„â–ƒâ–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–â–ƒâ–ƒâ–…â–â–…â–„â–‚â–ƒâ–‚â–‡â–„â–†â–„â–‡â–‚â–…â–†â–†â–…â–†â–…â–ˆâ–†â–„â–†â–ƒâ–„â–†â–…â–ƒâ–ƒâ–…â–…â–‡â–ƒâ–…â–†â–…
wandb:      train/ensemble_f1 â–‚â–ƒâ–„â–ƒâ–†â–…â–ƒâ–„â–†â–ƒâ–…â–„â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–†â–†â–…â–ƒâ–†â–„â–ƒâ–„â–ˆâ–„â–ƒâ–„â–†â–ƒâ–‚â–„â–…â–ƒâ–…â–†â–ƒâ–
wandb:         train/mil_loss â–…â–†â–„â–ˆâ–„â–ˆâ–†â–†â–‡â–…â–…â–„â–†â–…â–‡â–ƒâ–…â–†â–ƒâ–ƒâ–‡â–„â–ˆâ–ƒâ–‚â–†â–…â–…â–â–…â–…â–…â–…â–…â–…â–„â–…â–ƒâ–†â–…
wandb:      train/policy_loss â–â–„â–„â–ˆâ–„â–â–ˆâ–„â–â–ˆâ–â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–â–â–â–â–„â–â–ˆâ–ˆâ–â–â–„â–â–â–ˆâ–„â–„â–ˆâ–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92987
wandb: best/eval_avg_mil_loss 0.23285
wandb:  best/eval_ensemble_f1 0.92987
wandb:            eval/avg_f1 0.87885
wandb:      eval/avg_mil_loss 0.30705
wandb:       eval/ensemble_f1 0.87885
wandb:            test/avg_f1 0.93824
wandb:      test/avg_mil_loss 0.17772
wandb:       test/ensemble_f1 0.93824
wandb:           train/avg_f1 0.9065
wandb:      train/ensemble_f1 0.9065
wandb:         train/mil_loss 0.25453
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rich-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kye8nxc0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053204-kye8nxc0/logs
wandb: Agent Starting Run: 5hmtdk7e with config:
wandb: 	actor_learning_rate: 2.4862251946331192e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 179
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9523689272621172
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053429-5hmtdk7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5hmtdk7e
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–ƒâ–…â–…â–„â–†â–ƒâ–‡â–ƒâ–â–†â–ƒâ–…â–„â–†â–‚â–†â–†â–†â–„â–†â–‡â–‡â–‡â–…â–‡â–†â–ˆâ–‡â–ƒâ–…â–ˆâ–‡â–…â–ƒâ–†â–‚â–…
wandb:      eval/avg_mil_loss â–„â–…â–…â–…â–…â–„â–…â–â–ƒâ–ˆâ–„â–†â–â–…â–†â–ƒâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–…â–„â–ˆâ–ƒâ–‡â–…â–ˆâ–ˆâ–„â–ƒâ–„â–„â–…â–„â–…
wandb:       eval/ensemble_f1 â–„â–„â–…â–†â–„â–‚â–…â–„â–‡â–†â–†â–ƒâ–†â–…â–â–‚â–†â–‚â–†â–ƒâ–…â–ƒâ–…â–ˆâ–…â–‡â–†â–…â–â–„â–†â–‡â–â–ˆâ–„â–†â–ƒâ–‡â–‚â–‚
wandb:           train/avg_f1 â–ƒâ–†â–‚â–„â–‡â–†â–â–†â–…â–†â–‡â–ƒâ–„â–…â–†â–„â–‚â–ƒâ–‡â–‡â–‚â–„â–…â–†â–„â–ƒâ–ˆâ–„â–‡â–‚â–ƒâ–†â–„â–„â–†â–ˆâ–…â–…â–„â–…
wandb:      train/ensemble_f1 â–„â–„â–„â–„â–…â–†â–‚â–â–ƒâ–‡â–†â–…â–…â–†â–…â–ƒâ–†â–…â–…â–†â–ƒâ–†â–†â–ˆâ–ƒâ–†â–„â–…â–†â–„â–‡â–ˆâ–„â–†â–„â–…â–„â–‡â–…â–„
wandb:         train/mil_loss â–†â–†â–†â–…â–„â–‡â–†â–„â–„â–ˆâ–„â–†â–„â–„â–‡â–†â–„â–†â–†â–†â–„â–†â–„â–†â–…â–„â–…â–„â–ƒâ–…â–„â–…â–ƒâ–„â–…â–‡â–‡â–â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–„â–â–ˆâ–„â–„â–„â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–ˆâ–„â–â–„â–ˆâ–â–â–ˆâ–â–â–â–â–„â–ˆâ–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88619
wandb: best/eval_avg_mil_loss 0.28637
wandb:  best/eval_ensemble_f1 0.88619
wandb:            eval/avg_f1 0.77933
wandb:      eval/avg_mil_loss 1.42938
wandb:       eval/ensemble_f1 0.77933
wandb:           train/avg_f1 0.70353
wandb:      train/ensemble_f1 0.70353
wandb:         train/mil_loss 0.87828
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run valiant-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5hmtdk7e
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053429-5hmtdk7e/logs
wandb: ERROR Run 5hmtdk7e errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ybmqekus with config:
wandb: 	actor_learning_rate: 9.956015840137674e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8532267946235748
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053756-ybmqekus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ybmqekus
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‡â–‚â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–‚
wandb:      eval/avg_mil_loss â–‚â–â–…â–ˆâ–â–â–‚â–ˆâ–â–†â–‚â–â–â–ˆâ–â–‚â–‚â–‚â–‚â–†â–â–â–â–â–â–†â–‚â–‚â–â–‚â–†â–â–‚â–‚â–â–â–‚â–â–â–‚
wandb:       eval/ensemble_f1 â–ˆâ–‡â–ˆâ–‚â–ˆâ–‚â–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‚â–‡â–ˆâ–ˆâ–ˆâ–‚â–‡â–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–„â–…â–â–…â–„â–‡â–‡â–†â–â–ƒâ–„â–‚â–…â–…â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–†â–…â–‡â–†â–…â–…â–‚â–‡â–†â–…â–†â–‡â–‡â–‡â–‡â–„â–‡â–ƒ
wandb:      train/ensemble_f1 â–†â–…â–…â–‡â–†â–„â–‡â–‡â–„â–†â–‡â–‡â–ˆâ–…â–†â–‡â–‡â–†â–…â–…â–…â–†â–‡â–…â–†â–â–†â–†â–‡â–„â–ˆâ–ƒâ–ˆâ–‡â–„â–ˆâ–†â–‡â–„â–‡
wandb:         train/mil_loss â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ˆâ–â–„â–ƒâ–…â–ƒâ–â–â–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–ƒâ–„â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–â–â–ƒâ–†â–„â–‡â–â–‚â–ƒ
wandb:      train/policy_loss â–„â–ˆâ–â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–â–„â–ˆâ–„â–ˆâ–â–„â–„â–â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–â–„â–„â–â–â–â–„â–„â–„â–â–„â–„â–ˆâ–â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91919
wandb: best/eval_avg_mil_loss 0.26392
wandb:  best/eval_ensemble_f1 0.91919
wandb:            eval/avg_f1 0.60955
wandb:      eval/avg_mil_loss 1.20057
wandb:       eval/ensemble_f1 0.60955
wandb:            test/avg_f1 0.92999
wandb:      test/avg_mil_loss 0.12173
wandb:       test/ensemble_f1 0.92999
wandb:           train/avg_f1 0.87077
wandb:      train/ensemble_f1 0.87077
wandb:         train/mil_loss 0.54221
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run proud-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ybmqekus
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053756-ybmqekus/logs
wandb: Agent Starting Run: q642gvb2 with config:
wandb: 	actor_learning_rate: 0.0008472301789468481
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6141530198172529
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053949-q642gvb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q642gvb2
wandb: uploading history steps 55-59, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–â–†â–†â–…â–ƒâ–‡â–‡â–‡â–†â–„â–„â–„â–‡â–‡â–‡â–‡â–‡â–„â–ƒâ–…â–‡â–‡â–†â–…â–„â–‡â–†â–‡â–ˆâ–ƒâ–…â–‡â–…â–ˆâ–ˆâ–†â–‡â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–â–ˆâ–‚â–â–â–ˆâ–ƒâ–†â–…â–„â–â–ƒâ–â–â–â–…â–†â–„â–‚â–‡â–ƒâ–†â–„â–‚â–‚â–‚â–‚â–‡â–‚â–ƒâ–â–ƒâ–â–‚â–ƒâ–â–â–‚
wandb:       eval/ensemble_f1 â–â–…â–‡â–…â–‡â–‡â–‡â–ƒâ–…â–‚â–‚â–‡â–…â–‡â–†â–ˆâ–ˆâ–‚â–â–ƒâ–‡â–…â–ƒâ–‚â–„â–†â–‡â–†â–ˆâ–â–ƒâ–‡â–„â–‡â–‡â–…â–‡â–‡â–‡â–†
wandb:           train/avg_f1 â–…â–†â–‡â–…â–…â–ƒâ–ƒâ–†â–†â–…â–ˆâ–„â–‚â–‡â–ƒâ–‡â–…â–†â–ƒâ–ƒâ–„â–‡â–†â–‡â–†â–‚â–‡â–…â–ƒâ–†â–…â–‡â–†â–â–…â–â–ˆâ–†â–ƒâ–…
wandb:      train/ensemble_f1 â–…â–…â–†â–…â–ƒâ–ƒâ–†â–†â–…â–…â–†â–„â–‚â–‡â–†â–ƒâ–…â–‡â–…â–†â–…â–„â–‡â–†â–†â–‚â–…â–…â–†â–ƒâ–‡â–†â–â–…â–…â–â–ˆâ–†â–ƒâ–…
wandb:         train/mil_loss â–ƒâ–„â–†â–„â–†â–…â–…â–…â–„â–‡â–…â–…â–ˆâ–‚â–†â–„â–‚â–…â–…â–„â–â–…â–„â–„â–ƒâ–‚â–†â–„â–„â–ƒâ–„â–„â–ƒâ–‡â–ƒâ–ƒâ–‡â–ƒâ–‚â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91161
wandb: best/eval_avg_mil_loss 0.23117
wandb:  best/eval_ensemble_f1 0.91161
wandb:            eval/avg_f1 0.88198
wandb:      eval/avg_mil_loss 0.36766
wandb:       eval/ensemble_f1 0.88198
wandb:           train/avg_f1 0.8726
wandb:      train/ensemble_f1 0.8726
wandb:         train/mil_loss 0.44595
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run crimson-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q642gvb2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053949-q642gvb2/logs
wandb: ERROR Run q642gvb2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 468qxog8 with config:
wandb: 	actor_learning_rate: 3.9967526658685935e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21850180637701055
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054118-468qxog8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/468qxog8
wandb: uploading history steps 122-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–ˆâ–‡â–…â–„â–…â–‡â–„â–ˆâ–…â–‡â–‡â–â–…â–…â–‡â–‚â–…â–â–…â–‡â–†â–‡â–‚â–…â–ƒâ–†â–‡â–‡â–„â–ƒâ–‡â–‡â–…â–ƒâ–…â–‡â–…
wandb:      eval/avg_mil_loss â–ƒâ–â–„â–‚â–„â–ƒâ–ƒâ–â–ƒâ–â–â–â–„â–„â–„â–„â–ƒâ–‚â–â–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ˆâ–‚â–ˆâ–â–â–â–â–„â–…â–†â–â–„â–„â–‡
wandb:       eval/ensemble_f1 â–†â–‡â–…â–…â–„â–„â–„â–‡â–„â–…â–ˆâ–…â–†â–‡â–ˆâ–‡â–…â–†â–…â–…â–‚â–†â–…â–‡â–†â–†â–‚â–†â–†â–ˆâ–†â–ˆâ–‡â–„â–„â–‡â–„â–…â–„â–
wandb:           train/avg_f1 â–ˆâ–„â–…â–ƒâ–‚â–„â–‡â–‚â–…â–†â–‚â–„â–ˆâ–†â–†â–‡â–ƒâ–ƒâ–†â–„â–‡â–…â–ˆâ–†â–â–…â–„â–„â–‚â–…â–…â–…â–†â–‡â–…â–†â–ƒâ–…â–„â–†
wandb:      train/ensemble_f1 â–‡â–†â–†â–â–ƒâ–‡â–†â–…â–ƒâ–…â–†â–†â–†â–…â–…â–„â–†â–…â–†â–‡â–…â–…â–†â–†â–„â–ƒâ–†â–†â–†â–…â–†â–…â–†â–†â–†â–ˆâ–†â–…â–„â–ƒ
wandb:         train/mil_loss â–ƒâ–ƒâ–†â–…â–‡â–„â–‚â–…â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–†â–ƒâ–ƒâ–†â–…â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–ˆâ–â–„â–ƒâ–„â–ˆâ–†â–‚â–ƒâ–…â–„â–ˆâ–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–…â–â–â–â–…â–…â–ˆâ–ˆâ–â–…â–â–…â–…â–…â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91511
wandb: best/eval_avg_mil_loss 0.21059
wandb:  best/eval_ensemble_f1 0.91511
wandb:            eval/avg_f1 0.87838
wandb:      eval/avg_mil_loss 0.3426
wandb:       eval/ensemble_f1 0.87838
wandb:           train/avg_f1 0.83794
wandb:      train/ensemble_f1 0.83794
wandb:         train/mil_loss 0.83104
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/468qxog8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054118-468qxog8/logs
wandb: ERROR Run 468qxog8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: k261su7p with config:
wandb: 	actor_learning_rate: 0.00015262332364058553
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6671335498977113
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054351-k261su7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k261su7p
wandb: uploading wandb-summary.json; uploading history steps 180-196, summary
wandb: uploading history steps 180-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–„â–‚â–ˆâ–â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–†â–†â–‡â–†â–â–†â–…â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–„â–„â–†â–‡â–‡â–†â–‡â–†â–†
wandb:      eval/avg_mil_loss â–â–â–â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–ˆâ–ƒâ–â–‚â–â–‚â–â–‚â–
wandb:       eval/ensemble_f1 â–‡â–‡â–‡â–†â–…â–â–‡â–‡â–ƒâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–ˆâ–‡â–…â–‡â–…â–‡â–‡â–ƒâ–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡
wandb:           train/avg_f1 â–ƒâ–…â–„â–ƒâ–†â–„â–ƒâ–„â–…â–„â–…â–†â–†â–†â–…â–„â–…â–†â–ˆâ–â–„â–„â–…â–†â–†â–†â–‡â–†â–…â–‡â–ƒâ–„â–ƒâ–ˆâ–†â–†â–†â–„â–†â–†
wandb:      train/ensemble_f1 â–…â–†â–‚â–…â–†â–ˆâ–†â–…â–ƒâ–‡â–†â–†â–…â–„â–„â–…â–â–ƒâ–†â–†â–…â–„â–„â–‡â–…â–„â–‡â–…â–‡â–†â–„â–†â–‚â–…â–„â–†â–…â–†â–‚â–…
wandb:         train/mil_loss â–‚â–‚â–„â–â–‚â–ˆâ–‚â–…â–‚â–â–‚â–‚â–‡â–ƒâ–…â–„â–…â–‚â–†â–…â–‚â–†â–ƒâ–ƒâ–„â–‚â–ˆâ–â–„â–ƒâ–â–‚â–‚â–„â–‚â–‚â–„â–†â–ƒâ–„
wandb:      train/policy_loss â–â–â–„â–„â–„â–ˆâ–„â–â–„â–„â–ˆâ–â–â–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–â–ˆâ–ˆâ–„â–„â–â–â–„â–„â–â–ˆâ–â–â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–â–„â–ˆâ–â–„â–„â–â–â–â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–â–„â–„â–â–â–„â–„â–„â–„â–â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93016
wandb: best/eval_avg_mil_loss 0.2575
wandb:  best/eval_ensemble_f1 0.93016
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.23677
wandb:       eval/ensemble_f1 0.9105
wandb:           train/avg_f1 0.88721
wandb:      train/ensemble_f1 0.88721
wandb:         train/mil_loss 0.27534
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run firm-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k261su7p
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054351-k261su7p/logs
wandb: ERROR Run k261su7p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8eb7r3b8 with config:
wandb: 	actor_learning_rate: 7.350901874956819e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3093564576101532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054641-8eb7r3b8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8eb7r3b8
wandb: uploading history steps 51-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–â–ƒâ–ƒâ–†â–†â–„â–†â–†â–ƒâ–‚â–…â–‚â–†â–‚â–†â–‚â–‡â–…â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆâ–…â–ƒâ–†â–â–‚â–†â–„â–„
wandb:      eval/avg_mil_loss â–„â–â–ˆâ–…â–ƒâ–„â–‚â–‚â–„â–â–†â–†â–‡â–…â–ˆâ–ƒâ–ˆâ–„â–†â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–†â–‡â–ƒâ–‚â–„â–†â–‚â–…â–ƒâ–„â–ˆâ–ˆâ–‚â–…â–†
wandb:       eval/ensemble_f1 â–†â–†â–†â–â–ƒâ–†â–„â–†â–„â–†â–…â–‚â–…â–‚â–„â–‚â–†â–‚â–‡â–‚â–ˆâ–…â–‡â–‡â–‚â–„â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–ˆâ–…â–ƒâ–‚â–â–‚â–†â–„
wandb:           train/avg_f1 â–‚â–…â–ƒâ–…â–†â–‡â–…â–â–…â–‚â–…â–†â–†â–†â–â–ˆâ–…â–…â–†â–„â–†â–‡â–†â–†â–‚â–‡â–‚â–‡â–ƒâ–„â–†â–†â–„â–„â–…â–…â–â–†â–…â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–…â–…â–„â–…â–â–…â–‚â–…â–†â–†â–â–ˆâ–…â–†â–†â–„â–ƒâ–„â–†â–‡â–†â–†â–‚â–‡â–‚â–‡â–ƒâ–„â–†â–†â–„â–„â–…â–…â–†â–…â–‡â–†
wandb:         train/mil_loss â–ƒâ–‚â–‚â–…â–†â–„â–†â–„â–‚â–ƒâ–…â–ƒâ–…â–ˆâ–…â–…â–…â–…â–†â–…â–†â–„â–…â–…â–ƒâ–„â–„â–„â–†â–„â–‚â–„â–‚â–‡â–…â–…â–ƒâ–â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89535
wandb: best/eval_avg_mil_loss 0.30708
wandb:  best/eval_ensemble_f1 0.89535
wandb:            eval/avg_f1 0.69377
wandb:      eval/avg_mil_loss 2.02298
wandb:       eval/ensemble_f1 0.69377
wandb:           train/avg_f1 0.69498
wandb:      train/ensemble_f1 0.69498
wandb:         train/mil_loss 1.41154
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8eb7r3b8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054641-8eb7r3b8/logs
wandb: ERROR Run 8eb7r3b8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d59nllhz with config:
wandb: 	actor_learning_rate: 0.00014519936905673465
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6343368116791726
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054743-d59nllhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d59nllhz
wandb: uploading history steps 51-66
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–‚â–â–â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–„â–…â–†â–„â–„â–‡â–â–‡â–‚â–„â–â–‡â–‚â–‡â–„â–…â–ˆâ–„â–‡â–„â–‡â–†â–…â–‡â–ˆâ–…â–…â–‡â–ˆâ–‡â–‡â–ˆâ–„â–‡â–†â–„â–ˆâ–‡â–„
wandb:      eval/avg_mil_loss â–ˆâ–†â–ƒâ–‚â–â–ˆâ–â–„â–„â–â–…â–‚â–ƒâ–‡â–ƒâ–â–ƒâ–„â–â–â–ƒâ–ˆâ–„â–…â–â–ƒâ–â–„â–„â–‚â–â–â–‚â–„â–ƒâ–…â–‚â–â–â–†
wandb:       eval/ensemble_f1 â–‚â–„â–†â–†â–ˆâ–…â–…â–‡â–ƒâ–â–…â–ˆâ–‡â–ˆâ–…â–…â–ˆâ–…â–ƒâ–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–…â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ˆâ–„â–‡â–ˆâ–„â–‡â–„â–‡â–„â–ˆâ–‡â–ˆâ–†â–†â–‡â–…â–†â–†â–†â–ƒâ–†â–â–…â–„â–„â–ˆâ–†â–†â–‡â–†â–ƒâ–‡â–„â–‡â–‚â–‡â–†â–‡â–…
wandb:      train/ensemble_f1 â–‚â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–ƒâ–†â–ƒâ–‡â–ˆâ–…â–†â–†â–‡â–†â–†â–„â–…â–ƒâ–…â–…â–ƒâ–ˆâ–‡â–†â–†â–†â–‚â–…â–ˆâ–‡â–…â–â–‡â–…â–…â–†â–„
wandb:         train/mil_loss â–ƒâ–…â–„â–…â–„â–†â–…â–…â–…â–†â–…â–†â–„â–‚â–…â–ƒâ–†â–„â–‚â–ƒâ–ƒâ–ˆâ–„â–â–„â–„â–ƒâ–ƒâ–…â–‚â–„â–†â–†â–ƒâ–‡â–ƒâ–„â–…â–„â–†
wandb:      train/policy_loss â–â–…â–…â–…â–…â–…â–ˆâ–ˆâ–â–â–…â–â–…â–…â–ˆâ–…â–â–…â–â–â–ˆâ–ˆâ–â–…â–…â–…â–â–â–ˆâ–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–ˆâ–…â–â–â–…â–…â–â–…â–â–â–…â–…â–ˆâ–â–…â–â–â–â–â–…â–…â–…â–â–…â–…â–…â–ˆâ–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91909
wandb: best/eval_avg_mil_loss 0.22543
wandb:  best/eval_ensemble_f1 0.91909
wandb:            eval/avg_f1 0.72518
wandb:      eval/avg_mil_loss 1.63934
wandb:       eval/ensemble_f1 0.72518
wandb:            test/avg_f1 0.83391
wandb:      test/avg_mil_loss 0.50028
wandb:       test/ensemble_f1 0.83391
wandb:           train/avg_f1 0.81569
wandb:      train/ensemble_f1 0.81569
wandb:         train/mil_loss 0.86992
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d59nllhz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054743-d59nllhz/logs
wandb: Agent Starting Run: oudogo0t with config:
wandb: 	actor_learning_rate: 0.00048127670329342674
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5310335507007667
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054850-oudogo0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oudogo0t
wandb: uploading history steps 84-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–†â–…â–…â–†â–ƒâ–†â–…â–â–‚â–ˆâ–…â–…â–‚â–…â–‡â–„â–ƒâ–†â–‡â–†â–‚â–‚â–…â–ˆâ–†â–…â–…â–ˆâ–ƒâ–…â–…â–ˆâ–…â–†â–‡â–†â–„â–…
wandb:      eval/avg_mil_loss â–â–ƒâ–„â–ƒâ–„â–…â–…â–†â–„â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–ƒâ–†â–…â–ƒâ–„â–†â–†â–„â–†â–â–ƒâ–ƒâ–…â–ƒâ–„â–†â–„â–…â–â–…â–ƒâ–ƒâ–â–„â–…
wandb:       eval/ensemble_f1 â–„â–„â–ˆâ–„â–‚â–†â–†â–…â–â–…â–ˆâ–ˆâ–‚â–ˆâ–‡â–ˆâ–†â–‡â–‚â–ƒâ–ˆâ–„â–…â–†â–…â–†â–‡â–…â–ˆâ–‡â–…â–ˆâ–„â–…â–ˆâ–†â–‡â–†â–ˆâ–…
wandb:           train/avg_f1 â–‚â–…â–ƒâ–ˆâ–…â–…â–…â–‡â–†â–†â–…â–…â–…â–ƒâ–…â–‡â–„â–„â–‚â–†â–†â–ƒâ–…â–ˆâ–„â–†â–…â–„â–…â–†â–‡â–ƒâ–â–†â–„â–†â–‡â–‚â–†â–†
wandb:      train/ensemble_f1 â–‡â–‡â–â–…â–…â–ˆâ–†â–„â–‡â–†â–…â–„â–ƒâ–‚â–„â–â–…â–†â–†â–ƒâ–ˆâ–„â–…â–…â–„â–ƒâ–ƒâ–‡â–ƒâ–„â–†â–„â–â–†â–†â–‡â–‚â–„â–…â–…
wandb:         train/mil_loss â–…â–‡â–„â–„â–…â–‡â–†â–ƒâ–…â–ˆâ–†â–…â–‡â–…â–…â–â–‡â–…â–…â–ˆâ–…â–…â–…â–„â–…â–…â–ˆâ–„â–†â–…â–ƒâ–ƒâ–†â–ˆâ–†â–„â–ˆâ–…â–‚â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9046
wandb: best/eval_avg_mil_loss 0.25735
wandb:  best/eval_ensemble_f1 0.9046
wandb:            eval/avg_f1 0.71385
wandb:      eval/avg_mil_loss 1.42481
wandb:       eval/ensemble_f1 0.71385
wandb:           train/avg_f1 0.76484
wandb:      train/ensemble_f1 0.76484
wandb:         train/mil_loss 1.78618
wandb:      train/policy_loss 0.16962
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.16962
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comic-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oudogo0t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054850-oudogo0t/logs
wandb: ERROR Run oudogo0t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wbdowogr with config:
wandb: 	actor_learning_rate: 0.0003177746617422737
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2662440145387509
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055013-wbdowogr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wbdowogr
wandb: uploading history steps 131-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ƒâ–…â–‡â–ˆâ–†â–†â–â–…â–ˆâ–…â–ˆâ–ˆâ–ˆâ–…â–‡â–‚â–ˆâ–†â–ˆâ–…â–ƒâ–ƒâ–…â–ˆâ–…â–…â–…â–ˆâ–…â–‚â–„â–â–†â–‡â–†â–‚â–ˆâ–…
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–â–ƒâ–â–‡â–â–ƒâ–„â–‡â–„â–â–„â–â–â–â–†â–†â–ƒâ–„â–â–…â–‚â–†â–â–ˆâ–ƒâ–â–â–â–†â–…â–†â–‚â–†â–„â–†â–‡â–‡
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ˆâ–ƒâ–†â–ˆâ–‚â–‡â–ˆâ–ˆâ–‡â–‚â–ˆâ–ˆâ–…â–‡â–†â–†â–ˆâ–†â–„â–†â–‚â–ƒâ–…â–‡â–‡â–…â–‡â–…â–„â–†â–â–ˆâ–‚â–â–ˆâ–…â–‡â–ƒ
wandb:           train/avg_f1 â–…â–„â–„â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–‡â–…â–â–ƒâ–…â–ˆâ–‚â–…â–…â–ƒâ–†â–…â–â–…â–„â–ƒâ–†â–‚â–‡â–„â–„â–‚â–…â–†â–‡â–ƒâ–‚â–…â–‡â–‚â–„
wandb:      train/ensemble_f1 â–ƒâ–…â–…â–ƒâ–ƒâ–†â–…â–„â–†â–„â–„â–…â–†â–„â–ˆâ–†â–…â–†â–â–„â–…â–„â–ƒâ–ˆâ–„â–‡â–‡â–„â–„â–„â–…â–‚â–ƒâ–‚â–„â–…â–ƒâ–â–†â–†
wandb:         train/mil_loss â–…â–…â–…â–‚â–„â–„â–†â–ˆâ–ƒâ–…â–‡â–‚â–‡â–ƒâ–„â–â–„â–†â–„â–…â–ƒâ–„â–…â–†â–‡â–…â–„â–‚â–„â–…â–…â–…â–ƒâ–†â–†â–„â–ˆâ–â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–…â–…â–…â–â–ˆâ–ˆâ–â–…â–…â–…â–ˆâ–…â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–â–…â–…â–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91194
wandb: best/eval_avg_mil_loss 0.28452
wandb:  best/eval_ensemble_f1 0.91194
wandb:            eval/avg_f1 0.73706
wandb:      eval/avg_mil_loss 1.51932
wandb:       eval/ensemble_f1 0.73706
wandb:           train/avg_f1 0.74876
wandb:      train/ensemble_f1 0.74876
wandb:         train/mil_loss 1.69677
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wbdowogr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055013-wbdowogr/logs
wandb: ERROR Run wbdowogr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bz81ds4u with config:
wandb: 	actor_learning_rate: 0.00030488404285729617
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7666347995405883
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055227-bz81ds4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bz81ds4u
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 72-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–ˆâ–‚â–ƒâ–‡â–‚â–ƒâ–ƒâ–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–ˆâ–ˆâ–‡â–‡â–ƒâ–ƒâ–ˆâ–‚â–‡â–â–ˆâ–ƒâ–ƒâ–‡â–‡â–‡â–ˆâ–„â–ˆâ–‚â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–…â–…â–‡â–…â–ƒâ–„â–ƒâ–â–„â–‚â–ˆâ–‚â–ƒâ–…â–â–â–â–…â–„â–‡â–‡â–„â–â–…â–‡â–â–…â–…â–â–„â–â–…â–â–‚â–â–â–…
wandb:       eval/ensemble_f1 â–‚â–ƒâ–‡â–ˆâ–ƒâ–‚â–‡â–ƒâ–‡â–‡â–ˆâ–ˆâ–‡â–ƒâ–ˆâ–‚â–‚â–‡â–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–‡â–‚â–‡â–ˆâ–ˆâ–ˆâ–„â–‚â–‡â–‡â–ƒâ–‡â–‡â–ˆâ–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–‡â–…â–…â–†â–‡â–‡â–ƒâ–‡â–†â–„â–…â–„â–‚â–…â–†â–…â–ƒâ–ƒâ–ƒâ–â–†â–‡â–„â–†â–‡â–„â–…â–…â–…â–†â–…â–…â–‚â–†â–ˆâ–ƒâ–†â–†â–…
wandb:      train/ensemble_f1 â–ˆâ–†â–„â–‚â–ƒâ–†â–ˆâ–‚â–†â–†â–„â–‡â–‡â–ƒâ–†â–„â–„â–ˆâ–…â–…â–„â–„â–…â–„â–ƒâ–†â–„â–„â–â–‡â–„â–…â–…â–‚â–…â–†â–…â–…â–ˆâ–‡
wandb:         train/mil_loss â–„â–‚â–ƒâ–†â–â–…â–ˆâ–ƒâ–„â–‚â–„â–†â–„â–„â–ˆâ–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–„â–…â–‡â–†â–†â–‚â–„â–ƒâ–‡â–â–„â–ƒâ–„â–…â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–ˆâ–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.25463
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.8544
wandb:      eval/avg_mil_loss 1.69225
wandb:       eval/ensemble_f1 0.8544
wandb:            test/avg_f1 0.59441
wandb:      test/avg_mil_loss 2.15411
wandb:       test/ensemble_f1 0.59441
wandb:           train/avg_f1 0.72518
wandb:      train/ensemble_f1 0.72518
wandb:         train/mil_loss 0.87448
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devout-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bz81ds4u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055227-bz81ds4u/logs
wandb: Agent Starting Run: z8uv4fw8 with config:
wandb: 	actor_learning_rate: 1.386715186681691e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7961681544134133
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055350-z8uv4fw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z8uv4fw8
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–†â–†â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–„â–‡â–ˆâ–‡â–‡â–…â–…â–‡â–‡â–ƒâ–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–
wandb:      eval/avg_mil_loss â–‚â–„â–ƒâ–„â–â–â–â–â–â–â–â–‚â–â–‚â–â–…â–â–‚â–†â–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–â–‚â–ƒâ–â–„â–‚â–â–ˆ
wandb:       eval/ensemble_f1 â–‡â–†â–…â–„â–†â–ƒâ–‡â–ˆâ–‡â–â–†â–‚â–‡â–ˆâ–â–‡â–ƒâ–†â–ƒâ–‡â–†â–†â–†â–‡â–†â–‡â–…â–‡â–†â–„â–‡â–†â–‡â–‡â–‚â–â–…â–‡â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–…â–ˆâ–…â–„â–…â–â–‡â–…â–…â–„â–‚â–…â–„â–…â–‚â–†â–„â–‡â–ƒâ–†â–„â–†â–„â–†â–…â–„â–…â–†â–‡â–…â–…â–…â–…â–„â–†â–…â–„â–„
wandb:      train/ensemble_f1 â–…â–‡â–…â–…â–ˆâ–†â–†â–†â–†â–„â–‡â–…â–†â–…â–„â–†â–„â–„â–„â–‡â–‡â–†â–†â–†â–†â–‡â–†â–‡â–†â–†â–…â–â–†â–†â–„â–†â–†â–†â–†â–†
wandb:         train/mil_loss â–…â–ˆâ–…â–‚â–â–ƒâ–‡â–„â–…â–…â–…â–†â–„â–†â–…â–…â–„â–„â–„â–‡â–„â–‚â–„â–„â–„â–…â–‚â–ˆâ–‡â–„â–„â–…â–‚â–…â–ƒâ–„â–‡â–ƒâ–†â–
wandb:      train/policy_loss â–â–ˆâ–ˆâ–„â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–„â–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–„â–ˆâ–â–ˆâ–„â–ˆâ–„â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–â–„â–â–â–„â–â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90799
wandb: best/eval_avg_mil_loss 0.29476
wandb:  best/eval_ensemble_f1 0.90799
wandb:            eval/avg_f1 0.81387
wandb:      eval/avg_mil_loss 0.55054
wandb:       eval/ensemble_f1 0.81387
wandb:            test/avg_f1 0.92406
wandb:      test/avg_mil_loss 0.17745
wandb:       test/ensemble_f1 0.92406
wandb:           train/avg_f1 0.86527
wandb:      train/ensemble_f1 0.86527
wandb:         train/mil_loss 0.29585
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z8uv4fw8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055350-z8uv4fw8/logs
wandb: Agent Starting Run: p9e7xusb with config:
wandb: 	actor_learning_rate: 3.7677387277305614e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1710140007017078
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055620-p9e7xusb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/7oyxzwid
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9e7xusb
wandb: uploading history steps 66-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–ˆâ–†â–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–â–„â–‡â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–â–â–‡â–‚â–‡â–‡â–‡â–…â–„â–ˆâ–ˆâ–‚â–â–ˆâ–‡â–„â–‡â–ˆâ–‚â–‡â–‡â–ˆâ–ˆâ–ƒâ–‡â–‡â–„â–‡
wandb:      eval/avg_mil_loss â–â–â–ƒâ–â–…â–‚â–…â–…â–†â–‡â–â–â–ƒâ–â–ƒâ–â–â–ˆâ–â–‚â–â–â–â–â–â–…â–‚â–â–â–‚â–‚â–â–â–â–‡â–ƒâ–…â–…â–â–ƒ
wandb:       eval/ensemble_f1 â–‡â–‡â–â–…â–ˆâ–†â–„â–‡â–‡â–‡â–‡â–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–‡â–†â–ˆâ–…â–ˆâ–„â–‡â–ˆâ–‡â–‡â–ˆâ–…â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–‡â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–‡â–…â–‚â–…â–†â–ƒâ–‡â–‡â–‡â–†â–‡â–†â–„â–…â–ˆâ–…â–‡â–†â–…â–…â–ƒâ–†â–ƒâ–‡â–‡â–„â–†â–†â–ˆâ–…â–…â–â–†â–ƒâ–ˆâ–†â–‚â–…
wandb:      train/ensemble_f1 â–„â–‡â–„â–…â–‚â–†â–…â–†â–‡â–‡â–ˆâ–…â–‡â–†â–…â–†â–„â–…â–…â–†â–†â–…â–†â–†â–†â–„â–…â–ƒâ–„â–†â–‡â–‡â–‚â–ƒâ–†â–…â–â–ƒâ–ˆâ–…
wandb:         train/mil_loss â–ƒâ–…â–…â–„â–…â–„â–‚â–ƒâ–†â–…â–„â–‡â–ƒâ–ˆâ–„â–…â–„â–ˆâ–ˆâ–â–‚â–â–…â–…â–„â–ƒâ–ƒâ–…â–‚â–…â–„â–ƒâ–ƒâ–â–â–‚â–…â–‡â–ƒâ–‚
wandb:      train/policy_loss â–â–„â–„â–„â–ˆâ–â–â–„â–â–â–„â–ˆâ–â–„â–„â–â–„â–ˆâ–„â–â–ˆâ–„â–â–â–â–„â–„â–ˆâ–„â–ˆâ–â–â–â–„â–„â–ˆâ–ˆâ–â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–„â–„â–„â–ˆâ–â–â–„â–â–â–„â–â–„â–ˆâ–„â–â–„â–â–ˆâ–â–„â–„â–„â–â–â–â–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–ˆâ–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91467
wandb: best/eval_avg_mil_loss 0.24754
wandb:  best/eval_ensemble_f1 0.91467
wandb:            eval/avg_f1 0.83911
wandb:      eval/avg_mil_loss 0.46073
wandb:       eval/ensemble_f1 0.83911
wandb:            test/avg_f1 0.9228
wandb:      test/avg_mil_loss 0.23387
wandb:       test/ensemble_f1 0.9228
wandb:           train/avg_f1 0.87258
wandb:      train/ensemble_f1 0.87258
wandb:         train/mil_loss 0.29883
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deep-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p9e7xusb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055620-p9e7xusb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: xhq6x1mh with config:
wandb: 	actor_learning_rate: 2.1786776000940597e-05
wandb: 	attention_dropout_p: 0.3750008439920331
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5460227785101878
wandb: 	temperature: 4.841646849125286
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055750-xhq6x1mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xhq6x1mh
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 176-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ƒâ–„â–„â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–„â–ˆâ–‚â–ƒâ–ˆâ–â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–â–„
wandb:      eval/avg_mil_loss â–„â–â–†â–â–‡â–â–â–â–â–ƒâ–â–ƒâ–â–â–â–â–ˆâ–‚â–„â–…â–â–ƒâ–â–â–‡â–â–…â–â–†â–â–â–ˆâ–‚â–‡â–â–â–ˆâ–â–â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–‚â–ˆâ–‡â–ƒâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–ˆâ–†â–ˆâ–ˆâ–ƒâ–„â–â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–…â–†â–†â–…â–„â–…â–…â–‚â–â–†â–…â–†â–„â–†â–‡â–…â–†â–…â–„â–‚â–…â–…â–„â–†â–…â–„â–…â–ˆâ–†â–ƒâ–ˆâ–‡â–†â–†â–ƒâ–‡â–†â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–„â–…â–ƒâ–‡â–„â–†â–…â–†â–†â–„â–†â–…â–„â–â–„â–…â–‚â–„â–â–„â–†â–„â–ƒâ–…â–‡â–‡â–…â–ˆâ–ƒâ–…â–†â–‚â–‡â–ƒâ–†â–‡â–„â–…
wandb:         train/mil_loss â–…â–â–ƒâ–„â–…â–â–„â–„â–…â–‚â–„â–ƒâ–â–ƒâ–‚â–„â–„â–‚â–‚â–…â–ƒâ–…â–…â–„â–„â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–„â–„â–ˆâ–„â–ƒâ–…â–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92922
wandb: best/eval_avg_mil_loss 0.20381
wandb:  best/eval_ensemble_f1 0.92922
wandb:            eval/avg_f1 0.56911
wandb:      eval/avg_mil_loss 2.15497
wandb:       eval/ensemble_f1 0.56911
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.15181
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.79277
wandb:      train/ensemble_f1 0.79277
wandb:         train/mil_loss 0.36901
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xhq6x1mh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055750-xhq6x1mh/logs
wandb: Agent Starting Run: flwvrw8q with config:
wandb: 	actor_learning_rate: 0.0008877959157771573
wandb: 	attention_dropout_p: 0.28976751959991853
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12133058633249338
wandb: 	temperature: 5.458266961560282
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060024-flwvrw8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flwvrw8q
wandb: uploading history steps 119-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–…â–†â–â–ƒâ–„â–„â–…â–‡â–†â–„â–…â–ƒâ–†â–…â–‚â–„â–…â–…â–„â–ˆâ–…â–†â–…â–…â–†â–…â–…â–†â–…â–†â–‡â–†â–†â–„â–†â–†â–‡â–ƒ
wandb:      eval/avg_mil_loss â–†â–†â–†â–„â–„â–„â–ƒâ–…â–‡â–„â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‚â–‚â–„â–…â–„â–ˆâ–‚â–â–…â–‡â–‚â–‚â–‚â–â–„â–â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ˆ
wandb:       eval/ensemble_f1 â–„â–…â–†â–„â–„â–„â–‡â–‚â–„â–â–â–…â–„â–„â–ˆâ–„â–…â–†â–ƒâ–„â–†â–ƒâ–†â–‚â–…â–…â–…â–†â–„â–…â–…â–†â–„â–‡â–ˆâ–†â–ƒâ–„â–ˆâ–
wandb:           train/avg_f1 â–†â–…â–„â–…â–…â–…â–…â–‚â–„â–ˆâ–…â–â–‡â–‡â–ˆâ–‡â–†â–„â–†â–„â–„â–ˆâ–…â–‡â–ƒâ–„â–ƒâ–„â–‡â–†â–…â–‚â–„â–…â–†â–…â–„â–‡â–‡â–†
wandb:      train/ensemble_f1 â–†â–…â–â–…â–„â–„â–…â–„â–‡â–ˆâ–ƒâ–…â–ƒâ–…â–†â–…â–„â–„â–„â–â–ƒâ–„â–†â–„â–ƒâ–‚â–‡â–†â–‚â–„â–â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–…â–‡â–†
wandb:         train/mil_loss â–„â–„â–‚â–…â–…â–†â–„â–‚â–…â–ƒâ–…â–„â–„â–†â–†â–ƒâ–†â–„â–†â–…â–‡â–„â–†â–…â–‡â–…â–†â–‚â–…â–„â–ƒâ–ˆâ–…â–ƒâ–â–â–‚â–ƒâ–…â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9145
wandb: best/eval_avg_mil_loss 0.23252
wandb:  best/eval_ensemble_f1 0.9145
wandb:            eval/avg_f1 0.81736
wandb:      eval/avg_mil_loss 0.8321
wandb:       eval/ensemble_f1 0.81736
wandb:           train/avg_f1 0.81311
wandb:      train/ensemble_f1 0.81311
wandb:         train/mil_loss 0.71156
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flwvrw8q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060024-flwvrw8q/logs
wandb: ERROR Run flwvrw8q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4448jn3y with config:
wandb: 	actor_learning_rate: 4.930054653123006e-06
wandb: 	attention_dropout_p: 0.43165213048321355
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9984060104089852
wandb: 	temperature: 9.960456978082856
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060251-4448jn3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4448jn3y
wandb: uploading wandb-summary.json
wandb: uploading history steps 162-170, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–†
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–ˆâ–ˆâ–â–„â–ˆâ–„â–„â–â–ˆâ–â–ˆâ–…â–„â–ˆâ–…â–â–„â–‚â–ˆâ–ƒâ–ˆâ–„â–„â–„â–„â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–‡â–ˆâ–„â–…â–ˆâ–…
wandb:      eval/avg_mil_loss â–„â–‡â–ˆâ–ƒâ–„â–…â–‚â–‚â–‚â–‚â–â–„â–â–„â–â–„â–ƒâ–ƒâ–„â–‡â–‚â–„â–„â–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–â–…â–â–†â–‚â–â–‚â–‚â–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–„â–ˆâ–‚â–‚â–„â–ˆâ–ƒâ–…â–„â–„â–ˆâ–ƒâ–„â–„â–ˆâ–ˆâ–ƒâ–ˆâ–„â–„â–â–ˆâ–„â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–‚â–„â–ˆâ–…â–„â–ˆâ–„â–â–„â–„
wandb:           train/avg_f1 â–‡â–†â–†â–â–†â–†â–„â–…â–†â–ˆâ–…â–…â–„â–‡â–ˆâ–…â–ˆâ–‚â–…â–‡â–ƒâ–ƒâ–ƒâ–…â–‡â–ˆâ–â–ƒâ–ˆâ–„â–ˆâ–…â–…â–†â–ˆâ–ƒâ–‡â–ƒâ–‚â–‡
wandb:      train/ensemble_f1 â–ˆâ–…â–„â–†â–†â–†â–‡â–†â–†â–…â–ƒâ–‡â–„â–„â–†â–â–ˆâ–„â–…â–†â–†â–‡â–†â–…â–…â–†â–†â–„â–‡â–†â–…â–ƒâ–†â–†â–†â–†â–‡â–†â–‡â–„
wandb:         train/mil_loss â–‚â–‡â–‡â–…â–‚â–…â–„â–…â–‚â–„â–ˆâ–…â–ƒâ–…â–„â–â–…â–„â–ƒâ–…â–„â–„â–‚â–‚â–…â–ƒâ–…â–„â–ƒâ–†â–„â–ƒâ–‚â–†â–ƒâ–ƒâ–‚â–„â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ƒâ–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–†â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.36626
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.64935
wandb:      eval/avg_mil_loss 0.83065
wandb:       eval/ensemble_f1 0.64935
wandb:           train/avg_f1 0.6597
wandb:      train/ensemble_f1 0.6597
wandb:         train/mil_loss 0.64683
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4448jn3y
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060251-4448jn3y/logs
wandb: ERROR Run 4448jn3y errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ixg7der1 with config:
wandb: 	actor_learning_rate: 0.00010473543636660006
wandb: 	attention_dropout_p: 0.4328101342272287
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05246899978816855
wandb: 	temperature: 6.414414184937199
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060506-ixg7der1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ixg7der1
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 80-93, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–ˆâ–„â–ˆâ–„â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–„â–ˆâ–ˆâ–â–„â–‡â–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–‚â–ˆâ–‡â–‡â–ˆâ–„â–‡â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–†â–â–â–‚â–‡â–…â–â–ƒâ–ƒâ–‚â–â–â–â–ƒâ–†â–„â–…â–â–ƒâ–â–â–â–ƒâ–â–ˆâ–â–â–â–â–ƒâ–‡â–‚â–â–ƒâ–‚â–†â–â–â–â–
wandb:       eval/ensemble_f1 â–‡â–‡â–‚â–‡â–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–‡â–â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–ƒâ–‚â–‡â–‡â–‡â–ˆâ–ˆâ–„â–‡â–‡â–‡â–‡â–ˆâ–ƒâ–ƒâ–‡â–‡â–‡â–ˆ
wandb:           train/avg_f1 â–ˆâ–†â–…â–…â–†â–ˆâ–†â–…â–ˆâ–†â–â–‚â–†â–„â–…â–ƒâ–„â–†â–…â–†â–‚â–†â–†â–…â–„â–ˆâ–†â–…â–…â–†â–‚â–‡â–ˆâ–…â–ˆâ–â–„â–†â–ƒâ–ˆ
wandb:      train/ensemble_f1 â–†â–…â–†â–‡â–ˆâ–„â–†â–†â–…â–‡â–â–†â–…â–ˆâ–†â–†â–…â–„â–…â–†â–ƒâ–…â–†â–†â–„â–‡â–†â–…â–†â–…â–ˆâ–†â–‡â–„â–‡â–‡â–‚â–…â–„â–ˆ
wandb:         train/mil_loss â–ƒâ–‚â–…â–…â–…â–†â–„â–„â–‚â–‚â–‚â–„â–†â–„â–„â–ƒâ–‡â–‚â–„â–†â–ƒâ–„â–ƒâ–†â–‚â–„â–ƒâ–…â–„â–ƒâ–‡â–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒâ–â–„â–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–ƒâ–ˆâ–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.25374
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.91414
wandb:      eval/avg_mil_loss 0.32535
wandb:       eval/ensemble_f1 0.91414
wandb:           train/avg_f1 0.86711
wandb:      train/ensemble_f1 0.86711
wandb:         train/mil_loss 0.71132
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ixg7der1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060506-ixg7der1/logs
wandb: ERROR Run ixg7der1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9f77rhq6 with config:
wandb: 	actor_learning_rate: 5.337153653349163e-05
wandb: 	attention_dropout_p: 0.18420673905129056
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7776436634283742
wandb: 	temperature: 7.251928634662654
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060623-9f77rhq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9f77rhq6
wandb: uploading history steps 185-195, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–â–„â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–…â–…â–…â–ˆâ–†â–„â–†â–ˆâ–„â–„â–…â–†â–†â–…â–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–‡â–…â–…â–†â–â–„â–†â–…â–…â–ˆâ–„â–‡â–…â–…â–ˆâ–‡
wandb:      eval/avg_mil_loss â–‚â–‚â–„â–†â–‚â–ƒâ–‚â–†â–ƒâ–…â–†â–â–†â–‚â–‚â–†â–ƒâ–…â–…â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–…â–ˆâ–â–„â–‚â–‚â–ƒâ–‚â–‚â–â–…â–â–â–‚
wandb:       eval/ensemble_f1 â–‚â–†â–†â–„â–â–†â–…â–ˆâ–ƒâ–†â–„â–„â–…â–†â–…â–„â–„â–„â–â–„â–ˆâ–ˆâ–„â–ˆâ–„â–†â–„â–‡â–„â–‡â–…â–ˆâ–ˆâ–†â–†â–…â–ˆâ–†â–ƒâ–ˆ
wandb:           train/avg_f1 â–â–‚â–‚â–„â–â–„â–ƒâ–…â–‚â–‚â–†â–†â–…â–†â–ƒâ–…â–…â–„â–…â–ƒâ–†â–…â–‡â–†â–…â–ƒâ–„â–…â–‡â–…â–ˆâ–â–„â–‡â–ˆâ–…â–„â–…â–†â–†
wandb:      train/ensemble_f1 â–…â–‚â–†â–„â–„â–„â–‚â–â–„â–ƒâ–â–ƒâ–„â–â–†â–„â–ƒâ–‚â–ƒâ–â–…â–ˆâ–ƒâ–†â–†â–…â–„â–†â–…â–ƒâ–‡â–…â–…â–ˆâ–‡â–‡â–ˆâ–…â–…â–†
wandb:         train/mil_loss â–…â–…â–…â–†â–†â–…â–‡â–„â–‡â–…â–†â–†â–„â–‚â–†â–…â–†â–ˆâ–…â–‚â–…â–â–ƒâ–„â–ƒâ–…â–‚â–…â–„â–„â–â–…â–‚â–‚â–…â–„â–ƒâ–„â–…â–†
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.31194
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.8992
wandb:      eval/avg_mil_loss 0.29291
wandb:       eval/ensemble_f1 0.8992
wandb:           train/avg_f1 0.76488
wandb:      train/ensemble_f1 0.76488
wandb:         train/mil_loss 1.06278
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swept-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9f77rhq6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060623-9f77rhq6/logs
wandb: ERROR Run 9f77rhq6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: akynmkyj with config:
wandb: 	actor_learning_rate: 0.00045334785675111026
wandb: 	attention_dropout_p: 0.4714195386822193
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5276035937008845
wandb: 	temperature: 4.512925390472296
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060908-akynmkyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akynmkyj
wandb: uploading history steps 145-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–„â–…â–…â–ƒâ–†â–‚â–„â–†â–…â–„â–„â–ƒâ–ƒâ–…â–„â–†â–…â–†â–„â–„â–â–ƒâ–„â–…â–…â–‚â–ƒâ–‚â–ƒâ–ˆâ–…â–„â–ƒâ–†â–ƒâ–†â–ƒâ–‡â–…
wandb:      eval/avg_mil_loss â–‡â–„â–„â–…â–…â–…â–â–„â–†â–ˆâ–…â–…â–†â–„â–…â–…â–†â–„â–„â–…â–ƒâ–†â–ƒâ–…â–…â–ƒâ–„â–…â–ƒâ–‡â–†â–…â–…â–†â–„â–„â–ƒâ–†â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‡â–†â–ƒâ–„â–‡â–ˆâ–†â–…â–…â–‚â–…â–…â–‡â–â–…â–…â–…â–…â–…â–…â–‚â–…â–†â–„â–„â–„â–ƒâ–†â–ƒâ–„â–„â–†â–ˆâ–‚â–„â–ƒâ–…â–†â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–†â–‚â–…â–ƒâ–„â–â–…â–„â–†â–‡â–‚â–„â–†â–†â–†â–ƒâ–†â–„â–ˆâ–ˆâ–†â–†â–†â–‡â–‡â–†â–„â–ƒâ–„â–„â–„â–„â–†â–†â–ƒâ–†â–ƒâ–†
wandb:      train/ensemble_f1 â–…â–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–„â–‚â–‚â–â–…â–‚â–ƒâ–„â–…â–â–…â–„â–ˆâ–†â–â–‡â–…â–„â–†â–…â–†â–„â–…â–ƒâ–„â–†â–‡â–‡â–…â–ƒâ–…â–ƒâ–†
wandb:         train/mil_loss â–„â–‚â–…â–†â–„â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–…â–„â–‚â–†â–ƒâ–…â–…â–ƒâ–„â–„â–ƒâ–†â–‚â–ƒâ–ƒâ–„â–â–ƒâ–â–„â–„â–â–…â–…â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89279
wandb: best/eval_avg_mil_loss 0.70843
wandb:  best/eval_ensemble_f1 0.89279
wandb:            eval/avg_f1 0.69106
wandb:      eval/avg_mil_loss 1.48995
wandb:       eval/ensemble_f1 0.69106
wandb:            test/avg_f1 0.50511
wandb:      test/avg_mil_loss 2.64815
wandb:       test/ensemble_f1 0.50511
wandb:           train/avg_f1 0.66847
wandb:      train/ensemble_f1 0.66847
wandb:         train/mil_loss 1.65149
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swept-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akynmkyj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060908-akynmkyj/logs
wandb: Agent Starting Run: jz6wueqa with config:
wandb: 	actor_learning_rate: 2.1576115973016788e-06
wandb: 	attention_dropout_p: 0.113849149223401
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4409844807422324
wandb: 	temperature: 3.577427074161783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061158-jz6wueqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jz6wueqa
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 80-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–ƒâ–ˆâ–â–ˆâ–‡â–ˆâ–‡â–ƒâ–‚â–ˆâ–ˆâ–‚â–‚â–â–â–ˆâ–‡â–„â–ˆâ–‚â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–‡â–‚â–ˆâ–ˆâ–ˆâ–‡â–‚â–ˆ
wandb:      eval/avg_mil_loss â–‚â–‚â–â–‚â–â–â–ƒâ–†â–‚â–â–â–„â–ƒâ–‚â–â–‚â–…â–‚â–‚â–ˆâ–…â–â–„â–â–‚â–ˆâ–â–…â–ƒâ–â–â–â–ƒâ–‚â–†â–â–†â–‚â–â–„
wandb:       eval/ensemble_f1 â–„â–ˆâ–ˆâ–â–ˆâ–„â–ƒâ–â–â–ˆâ–ˆâ–‡â–‚â–‚â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–„â–‡â–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–…â–ˆâ–‚â–„â–…â–ˆâ–„
wandb:           train/avg_f1 â–†â–„â–†â–‡â–ƒâ–…â–‡â–„â–â–…â–†â–†â–‡â–…â–†â–…â–†â–‡â–„â–‡â–…â–„â–†â–…â–…â–†â–ˆâ–†â–„â–‡â–…â–„â–…â–ˆâ–ˆâ–„â–…â–„â–†â–…
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–†â–‡â–…â–…â–‡â–…â–ƒâ–ƒâ–‡â–„â–ƒâ–…â–‡â–ƒâ–‚â–‡â–ƒâ–…â–…â–…â–…â–â–…â–ˆâ–„â–„â–ƒâ–‡â–†â–„â–…â–„â–ƒâ–ˆâ–„â–„â–‚
wandb:         train/mil_loss â–‚â–â–†â–â–†â–‡â–â–„â–„â–„â–‚â–„â–„â–†â–‚â–â–â–…â–ƒâ–‚â–„â–‚â–†â–‡â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–ƒâ–‚â–†â–ƒâ–‡â–‚â–†â–ˆâ–‚â–‚
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.3477
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.58809
wandb:      eval/avg_mil_loss 2.0618
wandb:       eval/ensemble_f1 0.58809
wandb:           train/avg_f1 0.59593
wandb:      train/ensemble_f1 0.59593
wandb:         train/mil_loss 1.42371
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worthy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jz6wueqa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061158-jz6wueqa/logs
wandb: ERROR Run jz6wueqa errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 99wawcxg with config:
wandb: 	actor_learning_rate: 3.0329339811975447e-06
wandb: 	attention_dropout_p: 0.4305614339655348
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.747667786996881
wandb: 	temperature: 1.3241855417043769
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061311-99wawcxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/99wawcxg
wandb: uploading history steps 92-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–…â–ˆâ–„â–ˆâ–‡â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–‡â–…â–ˆâ–…â–ˆâ–‡â–…â–ˆâ–‡â–â–‡â–â–…â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–…
wandb:      eval/avg_mil_loss â–ˆâ–‚â–ƒâ–‚â–„â–‚â–…â–‚â–‚â–„â–‚â–‚â–‚â–â–â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–ƒâ–‚â–…â–‚â–ˆâ–…â–â–„â–ƒâ–â–â–‚â–‚â–…â–„
wandb:       eval/ensemble_f1 â–‡â–ƒâ–ˆâ–ˆâ–‚â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–†â–‚â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ƒâ–ˆâ–‡â–‡â–‚â–ƒâ–ˆâ–‡â–ˆâ–ƒâ–ƒ
wandb:           train/avg_f1 â–†â–…â–ƒâ–ƒâ–„â–†â–†â–ƒâ–…â–„â–â–‚â–†â–ˆâ–…â–‡â–„â–ƒâ–ˆâ–…â–ƒâ–„â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–†â–‡â–‡â–†â–†â–„â–…â–‡â–‡
wandb:      train/ensemble_f1 â–†â–…â–ƒâ–…â–‚â–‡â–†â–‡â–‡â–â–ˆâ–…â–â–‡â–‡â–ƒâ–‡â–ˆâ–â–ƒâ–ƒâ–„â–†â–ƒâ–„â–†â–„â–…â–„â–â–…â–†â–ƒâ–…â–ƒâ–†â–…â–…â–ˆâ–„
wandb:         train/mil_loss â–„â–„â–â–ƒâ–„â–†â–„â–ƒâ–‚â–ƒâ–„â–‡â–†â–„â–‡â–„â–â–‡â–„â–…â–…â–‡â–…â–‚â–„â–â–‚â–‡â–ƒâ–‚â–ƒâ–ƒâ–„â–ˆâ–‚â–‚â–‚â–…â–†â–…
wandb:      train/policy_loss â–†â–†â–â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.23215
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.81381
wandb:      eval/avg_mil_loss 0.50412
wandb:       eval/ensemble_f1 0.81381
wandb:           train/avg_f1 0.86757
wandb:      train/ensemble_f1 0.86757
wandb:         train/mil_loss 0.37006
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/99wawcxg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061311-99wawcxg/logs
wandb: ERROR Run 99wawcxg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ujtqce08 with config:
wandb: 	actor_learning_rate: 0.00017913634215676612
wandb: 	attention_dropout_p: 0.15196220697611895
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27305139271227485
wandb: 	temperature: 2.0215728299715696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061444-ujtqce08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujtqce08
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–ˆâ–„â–„â–…â–â–†â–‡â–†â–‚â–„â–…â–†â–ƒâ–„â–„â–†â–‡â–…â–†â–…â–„â–†â–†â–ˆâ–…â–ƒâ–„â–‡â–‡â–…â–ˆâ–„â–ƒâ–ˆâ–†â–„â–‚â–„â–„â–ƒ
wandb:      eval/avg_mil_loss â–â–…â–„â–‚â–„â–ƒâ–‚â–†â–…â–…â–†â–‡â–‡â–â–‚â–‚â–„â–‚â–„â–†â–„â–â–…â–…â–ƒâ–„â–„â–„â–ƒâ–…â–„â–ƒâ–†â–â–…â–…â–„â–â–…â–ˆ
wandb:       eval/ensemble_f1 â–„â–…â–…â–„â–‡â–†â–…â–ƒâ–‡â–†â–…â–†â–‡â–‡â–†â–ˆâ–†â–…â–‡â–…â–…â–„â–†â–†â–†â–†â–†â–…â–â–†â–ˆâ–…â–ƒâ–„â–…â–„â–„â–‡â–…â–„
wandb:           train/avg_f1 â–…â–„â–†â–‚â–…â–„â–…â–†â–…â–†â–„â–„â–…â–…â–‚â–„â–‡â–„â–‚â–â–â–‚â–†â–…â–†â–„â–†â–„â–„â–„â–†â–‡â–‡â–‚â–ˆâ–…â–…â–‚â–„â–…
wandb:      train/ensemble_f1 â–…â–†â–‚â–†â–„â–†â–„â–†â–ƒâ–†â–…â–ˆâ–…â–†â–ƒâ–â–â–„â–„â–…â–†â–‚â–‡â–â–„â–„â–†â–„â–„â–†â–†â–ƒâ–‚â–‡â–‡â–ˆâ–„â–„â–‚â–…
wandb:         train/mil_loss â–…â–†â–…â–ƒâ–†â–…â–†â–‚â–‡â–ƒâ–ˆâ–…â–„â–‚â–ƒâ–†â–…â–„â–†â–ƒâ–†â–ˆâ–†â–ƒâ–â–â–‡â–…â–â–„â–„â–„â–…â–ƒâ–‚â–‚â–ƒâ–…â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91497
wandb: best/eval_avg_mil_loss 0.25947
wandb:  best/eval_ensemble_f1 0.91497
wandb:            eval/avg_f1 0.66377
wandb:      eval/avg_mil_loss 1.84311
wandb:       eval/ensemble_f1 0.66377
wandb:           train/avg_f1 0.79722
wandb:      train/ensemble_f1 0.79722
wandb:         train/mil_loss 0.70258
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fluent-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujtqce08
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061444-ujtqce08/logs
wandb: ERROR Run ujtqce08 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bjc6mq54 with config:
wandb: 	actor_learning_rate: 7.866924644614167e-06
wandb: 	attention_dropout_p: 0.0655144199690505
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10334588883768414
wandb: 	temperature: 6.707625330593634
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061638-bjc6mq54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjc6mq54
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–†â–…â–„â–„â–†â–â–…â–„â–ƒâ–â–‚â–‡â–â–†â–‡â–…â–„â–†â–†â–ƒâ–†â–†â–ˆâ–ˆâ–…â–‚â–…â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ˆâ–‡â–ƒâ–ˆâ–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–â–…â–â–ˆâ–â–†â–â–†â–ƒâ–†â–„â–„â–„â–‡â–…â–ƒâ–‚â–ˆâ–†â–â–‚â–†â–…â–†â–ƒâ–„â–†â–â–…â–ˆâ–ƒâ–„â–„â–†â–ˆâ–‚â–‡â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–†â–ˆâ–„â–†â–„â–†â–†â–ˆâ–†â–ˆâ–†â–‚â–†â–‚â–‚â–‡â–…â–„â–ƒâ–†â–ƒâ–„â–‡â–ƒâ–ˆâ–‡â–„â–„â–‡â–ƒâ–†â–‡â–„â–„â–ƒâ–â–†â–†â–‡
wandb:           train/avg_f1 â–„â–†â–ƒâ–ƒâ–ƒâ–â–„â–‚â–ƒâ–ƒâ–„â–†â–„â–…â–„â–‚â–ƒâ–‡â–†â–†â–‡â–…â–†â–ƒâ–ƒâ–â–„â–„â–ƒâ–â–â–„â–†â–„â–…â–ˆâ–ƒâ–ƒâ–…â–„
wandb:      train/ensemble_f1 â–†â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–†â–„â–†â–„â–…â–ƒâ–…â–„â–‡â–„â–„â–…â–„â–†â–„â–„â–„â–â–†â–…â–†â–ˆâ–ƒâ–ƒâ–…â–…â–â–ƒâ–„
wandb:         train/mil_loss â–„â–…â–‚â–†â–ƒâ–„â–„â–†â–‚â–…â–‚â–ƒâ–…â–„â–‚â–ƒâ–„â–†â–ƒâ–„â–‡â–ƒâ–ƒâ–„â–‡â–ƒâ–„â–ˆâ–ƒâ–…â–„â–„â–…â–‚â–ƒâ–â–‚â–…â–‚â–ƒ
wandb:      train/policy_loss â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ˆâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92236
wandb: best/eval_avg_mil_loss 0.22709
wandb:  best/eval_ensemble_f1 0.92236
wandb:            eval/avg_f1 0.878
wandb:      eval/avg_mil_loss 0.78202
wandb:       eval/ensemble_f1 0.878
wandb:           train/avg_f1 0.7848
wandb:      train/ensemble_f1 0.7848
wandb:         train/mil_loss 0.81462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hopeful-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjc6mq54
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061638-bjc6mq54/logs
wandb: ERROR Run bjc6mq54 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hpc8xj7o with config:
wandb: 	actor_learning_rate: 2.4886124273660947e-05
wandb: 	attention_dropout_p: 0.2674479333834804
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22821302142379973
wandb: 	temperature: 1.480537426787053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061831-hpc8xj7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hpc8xj7o
wandb: uploading history steps 86-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–„â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–‡â–†â–‡â–„â–ƒâ–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–…â–‡â–‚â–â–‡â–†â–†â–‡â–‡â–†â–‡â–‚â–ˆâ–‡â–‡â–ƒâ–„â–‡â–†â–‡
wandb:      eval/avg_mil_loss â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–â–â–ƒâ–â–ƒâ–â–â–â–â–â–ˆâ–â–â–‚â–â–â–â–â–ƒâ–…â–‚â–â–ˆâ–â–‚â–â–â–â–‚â–‚â–â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–†â–‡â–â–‡â–‡â–ˆâ–†â–†â–‡â–†â–‡â–‡â–†â–‡â–ˆâ–…â–‡â–ƒâ–‡â–‡â–…â–‚â–†â–‡â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ˆâ–‚â–†â–‚â–†â–†â–†â–â–„â–ƒâ–…â–‡â–…â–…â–‡â–‡â–…â–†â–…â–‚â–‚â–‡â–‡â–…â–ƒâ–…â–…â–†â–‚â–‡â–‡â–â–ˆâ–„â–…â–†â–…â–†â–…
wandb:      train/ensemble_f1 â–‡â–ˆâ–„â–…â–†â–‚â–‡â–…â–„â–‡â–…â–„â–„â–‚â–‡â–‡â–â–†â–†â–…â–‡â–„â–ˆâ–…â–†â–‡â–†â–†â–…â–…â–ƒâ–…â–ƒâ–ˆâ–…â–†â–†â–…â–‡â–„
wandb:         train/mil_loss â–„â–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–â–„â–‚â–ˆâ–‚â–„â–ƒâ–†â–„â–‚â–…â–‚â–„â–‚â–„â–ƒâ–‚â–„â–„â–†â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–â–…â–â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–„â–â–â–â–â–â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.23861
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.89327
wandb:      eval/avg_mil_loss 0.28491
wandb:       eval/ensemble_f1 0.89327
wandb:            test/avg_f1 0.91168
wandb:      test/avg_mil_loss 0.19932
wandb:       test/ensemble_f1 0.91168
wandb:           train/avg_f1 0.88081
wandb:      train/ensemble_f1 0.88081
wandb:         train/mil_loss 0.26909
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dazzling-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hpc8xj7o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061831-hpc8xj7o/logs
wandb: Agent Starting Run: zclrrrs1 with config:
wandb: 	actor_learning_rate: 0.00025587687371741817
wandb: 	attention_dropout_p: 0.4527958838728934
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8345184743694471
wandb: 	temperature: 1.4755999681722751
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062014-zclrrrs1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zclrrrs1
wandb: uploading wandb-summary.json
wandb: uploading history steps 77-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–„â–â–„â–„â–‡â–ˆâ–ˆâ–ˆâ–‚â–…â–‡â–ˆâ–„â–‡â–…â–ˆâ–‚â–‡â–ˆâ–‡â–…â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–‡â–â–„â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–â–„â–‡â–…â–‚â–â–ƒâ–„â–â–„â–‚â–ƒâ–ƒâ–„â–â–…â–„â–‚â–…â–ƒâ–‚â–â–„â–â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–‡â–„â–…â–‚â–„â–„â–â–…
wandb:       eval/ensemble_f1 â–‡â–â–„â–„â–ˆâ–ˆâ–‚â–ƒâ–…â–ˆâ–„â–‡â–…â–‡â–ˆâ–‡â–…â–„â–‡â–ˆâ–ˆâ–„â–ˆâ–ƒâ–‚â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–‚â–ƒâ–„â–‡â–ƒâ–„â–„â–ˆâ–ˆâ–ƒ
wandb:           train/avg_f1 â–†â–‡â–‡â–„â–„â–…â–„â–ˆâ–†â–…â–ƒâ–†â–‡â–‡â–‡â–†â–‡â–…â–†â–†â–‚â–‡â–„â–ƒâ–„â–…â–‡â–‡â–…â–†â–‡â–‡â–…â–†â–â–„â–†â–†â–†â–†
wandb:      train/ensemble_f1 â–‡â–†â–†â–‡â–„â–†â–‚â–†â–‡â–‡â–…â–„â–†â–„â–‚â–â–‡â–„â–†â–‚â–„â–…â–…â–†â–ˆâ–‡â–ƒâ–„â–†â–ˆâ–†â–…â–†â–†â–ƒâ–‡â–…â–†â–†â–ˆ
wandb:         train/mil_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–„â–†â–†â–‚â–†â–…â–ƒâ–…â–‚â–â–…â–‚â–„â–ƒâ–„â–„â–â–†â–…â–ƒâ–…â–‚â–†â–†â–ƒâ–†â–‚â–‚â–‚â–†â–‚â–‚â–„
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91482
wandb: best/eval_avg_mil_loss 0.34945
wandb:  best/eval_ensemble_f1 0.91482
wandb:            eval/avg_f1 0.44448
wandb:      eval/avg_mil_loss 2.19057
wandb:       eval/ensemble_f1 0.44448
wandb:           train/avg_f1 0.77486
wandb:      train/ensemble_f1 0.77486
wandb:         train/mil_loss 0.45609
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zclrrrs1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062014-zclrrrs1/logs
wandb: ERROR Run zclrrrs1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5kt2r8li with config:
wandb: 	actor_learning_rate: 1.9744662297506503e-05
wandb: 	attention_dropout_p: 0.0949176905025554
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2872335963640149
wandb: 	temperature: 2.2893781050152895
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062131-5kt2r8li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5kt2r8li
wandb: uploading history steps 162-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–ƒâ–„â–†â–†â–ƒâ–„â–â–„â–†â–„â–…â–â–…â–„â–„â–ƒâ–…â–ƒâ–„â–„â–„â–ˆâ–†â–„â–†â–„â–„â–‡â–†â–…â–„â–†â–„â–ƒâ–†â–†â–†â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–…â–†â–ƒâ–…â–„â–ƒâ–…â–†â–„â–ƒâ–„â–ƒâ–‚â–‡â–…â–„â–ƒâ–…â–‡â–‡â–â–ƒâ–„â–„â–‚â–ƒâ–â–†â–â–ˆâ–ƒâ–‚â–…â–„â–„â–‚â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–ƒâ–†â–…â–ˆâ–„â–ƒâ–†â–†â–â–†â–„â–„â–…â–…â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–‚â–ˆâ–…â–‡â–„â–…â–†â–†â–„â–ˆâ–…â–…â–„â–…â–…â–†â–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–…â–ˆâ–†â–„â–‚â–‡â–…â–„â–„â–â–†â–…â–…â–…â–†â–„â–…â–„â–…â–ƒâ–ˆâ–†â–ƒâ–‡â–‡â–‡â–ˆâ–…â–ƒâ–†â–†â–ˆâ–„â–†â–†â–…â–…â–†
wandb:      train/ensemble_f1 â–ƒâ–…â–‡â–„â–…â–„â–…â–‡â–…â–‡â–…â–„â–…â–„â–â–„â–…â–†â–†â–†â–…â–†â–ƒâ–ˆâ–ˆâ–„â–†â–‡â–…â–†â–‡â–†â–„â–‡â–„â–ˆâ–†â–†â–…â–…
wandb:         train/mil_loss â–†â–…â–…â–…â–…â–ƒâ–„â–ˆâ–†â–ƒâ–„â–…â–‚â–†â–…â–†â–„â–†â–„â–„â–‡â–…â–ƒâ–„â–…â–…â–ƒâ–†â–„â–„â–â–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–ˆâ–‚
wandb:      train/policy_loss â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.30141
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.55396
wandb:      eval/avg_mil_loss 1.56945
wandb:       eval/ensemble_f1 0.55396
wandb:            test/avg_f1 0.72957
wandb:      test/avg_mil_loss 0.74979
wandb:       test/ensemble_f1 0.72957
wandb:           train/avg_f1 0.75221
wandb:      train/ensemble_f1 0.75221
wandb:         train/mil_loss 0.98034
wandb:      train/policy_loss -0.1698
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.1698
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run jolly-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5kt2r8li
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062131-5kt2r8li/logs
wandb: Agent Starting Run: k01cckmu with config:
wandb: 	actor_learning_rate: 1.2383045779212704e-06
wandb: 	attention_dropout_p: 0.26253854355842277
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5180604482160881
wandb: 	temperature: 3.651771373330397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062356-k01cckmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k01cckmu
wandb: uploading wandb-summary.json
wandb: uploading history steps 175-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–…â–†â–‚â–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–â–„â–…â–â–‚â–â–â–„â–‚â–„â–â–ˆâ–‚â–ˆâ–ˆâ–ƒâ–ˆâ–‚â–ˆâ–â–‚â–â–â–…â–†â–â–â–‚â–†â–â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–â–â–
wandb:      eval/avg_mil_loss â–ˆâ–…â–‡â–‡â–ƒâ–†â–‡â–…â–‡â–†â–ƒâ–„â–‡â–‡â–…â–…â–â–„â–‡â–†â–…â–…â–ˆâ–†â–…â–ˆâ–‚â–ƒâ–ˆâ–„â–†â–ˆâ–‡â–†â–‡â–ˆâ–ƒâ–†â–†â–„
wandb:       eval/ensemble_f1 â–…â–‚â–ˆâ–…â–„â–â–…â–„â–‚â–…â–‚â–â–‚â–†â–‚â–ˆâ–ˆâ–â–„â–‚â–â–†â–â–…â–…â–‚â–â–‚â–â–‚â–â–â–â–ˆâ–â–‡â–‚â–ƒâ–‡â–‚
wandb:           train/avg_f1 â–‚â–‚â–…â–†â–†â–„â–ƒâ–†â–‡â–â–ƒâ–…â–…â–‡â–…â–„â–…â–„â–„â–„â–‚â–…â–ƒâ–ƒâ–…â–‚â–‡â–†â–‚â–„â–†â–…â–†â–‡â–…â–†â–†â–‡â–ˆâ–
wandb:      train/ensemble_f1 â–‚â–„â–‚â–†â–â–‡â–…â–‡â–…â–…â–‚â–…â–‚â–…â–‡â–„â–‚â–„â–„â–†â–‚â–ˆâ–…â–„â–†â–…â–ƒâ–„â–„â–…â–ˆâ–ˆâ–ˆâ–†â–ƒâ–ƒâ–‡â–†â–ƒâ–
wandb:         train/mil_loss â–ƒâ–‡â–†â–…â–…â–†â–†â–‡â–‡â–…â–„â–„â–†â–‡â–„â–„â–ˆâ–„â–ƒâ–‡â–…â–ƒâ–ƒâ–‚â–…â–…â–†â–‡â–…â–…â–…â–‡â–â–…â–…â–†â–„â–‚â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90325
wandb: best/eval_avg_mil_loss 0.28989
wandb:  best/eval_ensemble_f1 0.90325
wandb:            eval/avg_f1 0.3426
wandb:      eval/avg_mil_loss 2.69172
wandb:       eval/ensemble_f1 0.3426
wandb:           train/avg_f1 0.46611
wandb:      train/ensemble_f1 0.46611
wandb:         train/mil_loss 1.98638
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run restful-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k01cckmu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062356-k01cckmu/logs
wandb: ERROR Run k01cckmu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7d93yqwl with config:
wandb: 	actor_learning_rate: 1.2310884145268782e-05
wandb: 	attention_dropout_p: 0.12199876368472112
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3119023653224603
wandb: 	temperature: 1.0391069215999515
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062631-7d93yqwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7d93yqwl
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‚â–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–ƒâ–‡â–…â–‡â–…â–…â–…â–ˆâ–‡â–…â–ˆâ–…â–ƒâ–…â–„â–†â–‡â–†â–…â–„â–‡â–…â–„â–â–ƒâ–‡â–‚â–„â–ˆâ–…â–â–†â–ƒâ–‡â–ˆâ–„â–…
wandb:      eval/avg_mil_loss â–„â–‚â–‡â–„â–„â–‚â–„â–„â–†â–…â–ƒâ–†â–â–…â–‡â–„â–‚â–…â–„â–ƒâ–„â–„â–…â–ƒâ–…â–ƒâ–„â–„â–†â–‚â–‡â–†â–„â–„â–ˆâ–‡â–„â–…â–†â–ƒ
wandb:       eval/ensemble_f1 â–‡â–‡â–…â–‡â–…â–‡â–†â–‡â–…â–‡â–ˆâ–‡â–†â–ˆâ–…â–†â–…â–‡â–‡â–†â–‡â–…â–…â–„â–‡â–†â–ƒâ–‡â–„â–†â–†â–â–‡â–ƒâ–‡â–ˆâ–„â–†â–â–†
wandb:           train/avg_f1 â–†â–†â–…â–â–‡â–‚â–‚â–†â–†â–†â–†â–ƒâ–„â–…â–…â–â–…â–†â–†â–…â–…â–…â–ƒâ–…â–ˆâ–‡â–ˆâ–‡â–…â–†â–†â–„â–ƒâ–‚â–‡â–…â–‡â–‡â–…â–…
wandb:      train/ensemble_f1 â–†â–†â–„â–â–‡â–‡â–†â–‚â–†â–„â–„â–ƒâ–ƒâ–„â–…â–…â–â–†â–…â–†â–„â–„â–…â–…â–†â–ˆâ–ƒâ–ˆâ–‡â–†â–„â–‡â–†â–ƒâ–‚â–ƒâ–…â–…â–‡â–†
wandb:         train/mil_loss â–ƒâ–ˆâ–†â–…â–‚â–„â–ƒâ–…â–ƒâ–†â–†â–ƒâ–‡â–…â–…â–…â–„â–ˆâ–…â–„â–„â–‡â–†â–…â–„â–†â–ƒâ–ƒâ–„â–…â–…â–„â–…â–„â–‡â–…â–ˆâ–…â–…â–
wandb:      train/policy_loss â–ƒâ–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90344
wandb: best/eval_avg_mil_loss 0.26662
wandb:  best/eval_ensemble_f1 0.90344
wandb:            eval/avg_f1 0.73934
wandb:      eval/avg_mil_loss 1.1674
wandb:       eval/ensemble_f1 0.73934
wandb:           train/avg_f1 0.71834
wandb:      train/ensemble_f1 0.71834
wandb:         train/mil_loss 0.84395
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7d93yqwl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062631-7d93yqwl/logs
wandb: ERROR Run 7d93yqwl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: n1v2tvl7 with config:
wandb: 	actor_learning_rate: 6.146031656084934e-06
wandb: 	attention_dropout_p: 0.16385900110454676
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2524635045686202
wandb: 	temperature: 3.947773975454012
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062754-n1v2tvl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n1v2tvl7
wandb: uploading history steps 54-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–ˆ
wandb:            eval/avg_f1 â–â–â–‚â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–…â–†â–â–â–‚â–„â–â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–ˆâ–†â–â–…â–ƒâ–‚â–†â–„â–†â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb:      eval/avg_mil_loss â–…â–ˆâ–‡â–‡â–†â–‡â–†â–ˆâ–‡â–†â–†â–†â–†â–†â–ƒâ–‡â–†â–†â–‡â–…â–…â–‡â–‡â–…â–…â–†â–…â–â–‡â–„â–…â–†â–‡â–„â–‡â–„â–†â–‡â–†â–†
wandb:       eval/ensemble_f1 â–â–‚â–â–‚â–‚â–†â–‚â–‚â–‚â–ƒâ–„â–‚â–†â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–„â–‚â–â–ƒâ–ƒâ–‚â–ˆâ–â–„â–‚â–ˆâ–ˆâ–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ƒâ–…â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–‚â–„â–‚â–…â–ƒâ–ƒâ–ƒâ–ˆâ–„â–„â–‚â–†â–†â–„â–„â–…â–†â–‡â–†â–…â–ƒâ–„â–†â–…â–ƒâ–ƒâ–ƒâ–…â–…â–
wandb:      train/ensemble_f1 â–†â–â–…â–‚â–â–…â–ƒâ–„â–ƒâ–‚â–â–ƒâ–ƒâ–…â–â–‚â–„â–‚â–ˆâ–‚â–â–ƒâ–ƒâ–ƒâ–„â–„â–‡â–†â–„â–„â–†â–ˆâ–„â–„â–‚â–‚â–â–…â–â–ƒ
wandb:         train/mil_loss â–†â–‡â–†â–‡â–…â–„â–‡â–…â–…â–†â–†â–‡â–…â–‡â–…â–…â–†â–‡â–‡â–„â–„â–‡â–…â–†â–„â–†â–…â–„â–„â–…â–†â–†â–…â–†â–ˆâ–‡â–…â–†â–â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88231
wandb: best/eval_avg_mil_loss 0.52201
wandb:  best/eval_ensemble_f1 0.88231
wandb:            eval/avg_f1 0.41284
wandb:      eval/avg_mil_loss 3.19408
wandb:       eval/ensemble_f1 0.41284
wandb:            test/avg_f1 0.38062
wandb:      test/avg_mil_loss 3.68283
wandb:       test/ensemble_f1 0.38062
wandb:           train/avg_f1 0.48465
wandb:      train/ensemble_f1 0.48465
wandb:         train/mil_loss 2.83687
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glad-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n1v2tvl7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062754-n1v2tvl7/logs
wandb: Agent Starting Run: z39q9sc9 with config:
wandb: 	actor_learning_rate: 8.477867394945432e-05
wandb: 	attention_dropout_p: 0.03807401104135061
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9701630757031292
wandb: 	temperature: 1.9736013162256285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062851-z39q9sc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z39q9sc9
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–†â–„â–†â–†â–ƒâ–†â–†â–â–ƒâ–„â–ƒâ–„â–…â–…â–‡â–†â–ˆâ–…â–†â–…â–„â–„â–…â–„â–…â–„â–ƒâ–†â–ˆâ–‚â–ƒâ–ˆâ–‚â–ƒâ–„â–‚â–†â–†â–‡â–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–‡â–ƒâ–…â–„â–ˆâ–‚â–„â–ƒâ–„â–„â–ƒâ–†â–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–…â–„â–ˆâ–‚â–†â–‚â–â–„â–„â–…â–ƒâ–‚â–†â–†â–â–â–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–‡â–†â–…â–‡â–‚â–„â–…â–„â–†â–‡â–‡â–‡â–…â–ˆâ–…â–„â–†â–†â–‡â–â–ƒâ–‡â–†â–‡â–…â–†â–ˆâ–ƒâ–†â–„â–ƒâ–…â–†â–„â–†â–†â–‡â–‡
wandb:           train/avg_f1 â–ˆâ–„â–…â–…â–‚â–„â–†â–„â–†â–ƒâ–‡â–…â–†â–‡â–†â–‡â–†â–ƒâ–‡â–ƒâ–ƒâ–„â–â–‡â–†â–ƒâ–ƒâ–ˆâ–†â–…â–…â–ˆâ–‡â–†â–‚â–‡â–ƒâ–†â–…â–„
wandb:      train/ensemble_f1 â–„â–ƒâ–…â–†â–‚â–‡â–ƒâ–†â–„â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–…â–â–ƒâ–…â–‡â–ˆâ–ˆâ–…â–â–‡â–‡â–…â–ƒâ–‚â–…â–…â–„â–ˆâ–„â–†â–„â–‡â–„â–‡â–…
wandb:         train/mil_loss â–„â–â–ƒâ–…â–„â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–…â–„â–…â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–‚â–…â–‚â–…â–ƒâ–ƒâ–†â–…â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90363
wandb: best/eval_avg_mil_loss 0.2562
wandb:  best/eval_ensemble_f1 0.90363
wandb:            eval/avg_f1 0.79895
wandb:      eval/avg_mil_loss 0.83354
wandb:       eval/ensemble_f1 0.79895
wandb:           train/avg_f1 0.76435
wandb:      train/ensemble_f1 0.76435
wandb:         train/mil_loss 1.06502
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smooth-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z39q9sc9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062851-z39q9sc9/logs
wandb: ERROR Run z39q9sc9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jpk9ef47 with config:
wandb: 	actor_learning_rate: 9.150260511031313e-05
wandb: 	attention_dropout_p: 0.4651100507574969
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04236521469325216
wandb: 	temperature: 6.258501640290288
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063120-jpk9ef47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jpk9ef47
wandb: uploading history steps 155-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‚â–†â–…â–„â–…â–ƒâ–…â–…â–†â–…â–…â–†â–ƒâ–‡â–†â–‡â–†â–ƒâ–…â–…â–ˆâ–ˆâ–…â–†â–†â–…â–„â–â–„â–‡â–ˆâ–„â–…â–†â–‡â–†â–†â–†â–ƒ
wandb:      eval/avg_mil_loss â–†â–ƒâ–†â–‚â–‚â–†â–†â–†â–â–…â–…â–†â–„â–ƒâ–„â–â–‚â–…â–†â–…â–ˆâ–…â–ƒâ–‚â–‚â–„â–ƒâ–â–ƒâ–‚â–„â–†â–‚â–ƒâ–„â–ƒâ–…â–„â–†â–‚
wandb:       eval/ensemble_f1 â–†â–‚â–…â–…â–ƒâ–â–†â–â–…â–…â–…â–†â–ƒâ–…â–ƒâ–†â–„â–…â–†â–ƒâ–‡â–…â–†â–ˆâ–…â–†â–†â–…â–†â–†â–†â–†â–„â–‚â–„â–†â–…â–…â–ƒâ–…
wandb:           train/avg_f1 â–ƒâ–ƒâ–…â–ƒâ–‡â–†â–â–ˆâ–‡â–ƒâ–‚â–†â–ƒâ–„â–ƒâ–‡â–ˆâ–„â–‡â–‡â–‡â–â–â–…â–ƒâ–…â–†â–‡â–„â–†â–†â–‡â–„â–„â–ƒâ–†â–‚â–‡â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–„â–‡â–ƒâ–ƒâ–â–„â–‡â–„â–…â–†â–…â–„â–ƒâ–„â–„â–ƒâ–…â–ˆâ–„â–‡â–†â–…â–ƒâ–‡â–‡â–…â–„â–†â–„â–‡â–†â–†â–‡â–†â–†â–„â–…â–‡â–†
wandb:         train/mil_loss â–‡â–†â–‡â–…â–†â–‡â–‡â–‡â–†â–ƒâ–†â–…â–„â–ˆâ–†â–‡â–…â–ˆâ–…â–„â–‡â–‡â–†â–„â–‚â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–â–ˆâ–†â–…â–‚â–‚â–‡â–ˆâ–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8992
wandb: best/eval_avg_mil_loss 0.21249
wandb:  best/eval_ensemble_f1 0.8992
wandb:            eval/avg_f1 0.5905
wandb:      eval/avg_mil_loss 1.7958
wandb:       eval/ensemble_f1 0.5905
wandb:           train/avg_f1 0.73441
wandb:      train/ensemble_f1 0.73441
wandb:         train/mil_loss 1.23251
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run easy-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jpk9ef47
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063120-jpk9ef47/logs
wandb: ERROR Run jpk9ef47 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4be6bm1f with config:
wandb: 	actor_learning_rate: 2.318268244280028e-05
wandb: 	attention_dropout_p: 0.11753174151079632
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29676595668674133
wandb: 	temperature: 3.2884334172907694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063421-4be6bm1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4be6bm1f
wandb: uploading history steps 141-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–‚â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–ˆâ–…â–ˆâ–…â–‚â–†â–†â–‚â–†â–‡â–ˆâ–ˆâ–ƒâ–…â–ˆâ–†â–ˆâ–…â–ˆâ–…â–â–…â–…â–ˆâ–ˆâ–„â–†â–†â–„â–ˆâ–†â–…â–†â–‡â–ˆâ–…â–†
wandb:      eval/avg_mil_loss â–‚â–…â–â–‚â–‚â–„â–…â–‚â–â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–„â–‚â–ƒâ–„â–â–â–ƒâ–â–‚â–â–‚â–‚â–â–â–„â–â–‚â–‚â–ƒâ–â–‚â–ˆâ–
wandb:       eval/ensemble_f1 â–†â–†â–‡â–ˆâ–‡â–„â–†â–â–†â–ˆâ–ˆâ–â–ƒâ–…â–ˆâ–‡â–ˆâ–…â–†â–ˆâ–‡â–…â–…â–ˆâ–ˆâ–ˆâ–†â–ƒâ–†â–„â–…â–†â–‡â–‡â–„â–…â–ˆâ–„â–†â–…
wandb:           train/avg_f1 â–„â–…â–„â–ˆâ–…â–„â–„â–…â–„â–„â–…â–†â–‚â–â–„â–‚â–ˆâ–â–ƒâ–…â–…â–†â–…â–ˆâ–†â–„â–„â–†â–„â–„â–†â–ƒâ–†â–ƒâ–â–ƒâ–ƒâ–…â–†â–„
wandb:      train/ensemble_f1 â–ˆâ–‡â–…â–„â–‡â–…â–…â–†â–„â–ƒâ–…â–‡â–„â–ˆâ–„â–„â–‚â–„â–„â–…â–†â–„â–ˆâ–â–†â–‡â–„â–ƒâ–‡â–‡â–…â–…â–‡â–†â–‡â–†â–„â–†â–…â–†
wandb:         train/mil_loss â–„â–„â–ƒâ–ƒâ–…â–…â–‡â–‚â–‡â–…â–„â–†â–ˆâ–ƒâ–â–„â–„â–â–…â–„â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–…â–„â–‡â–‚â–ƒâ–ƒâ–„â–„â–…â–‚â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.26531
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.71187
wandb:      eval/avg_mil_loss 1.35615
wandb:       eval/ensemble_f1 0.71187
wandb:           train/avg_f1 0.8174
wandb:      train/ensemble_f1 0.8174
wandb:         train/mil_loss 1.31967
wandb:      train/policy_loss -0.06696
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.06696
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dark-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4be6bm1f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063421-4be6bm1f/logs
wandb: ERROR Run 4be6bm1f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lcytuca5 with config:
wandb: 	actor_learning_rate: 4.651077487530821e-06
wandb: 	attention_dropout_p: 0.4169082629225236
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08535046313588135
wandb: 	temperature: 7.107116799356455
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063630-lcytuca5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcytuca5
wandb: uploading wandb-summary.json; uploading history steps 106-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–ˆâ–…â–ˆâ–ˆâ–‚â–‡â–†â–‡â–‚â–†â–†â–†â–ˆâ–†â–…â–†â–…â–†â–ˆâ–‡â–†â–†â–…â–„â–†â–†â–†â–…â–„â–†â–…â–â–‡â–‚â–ˆâ–‡â–‡â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–‚â–„â–‡â–„â–„â–…â–„â–…â–…â–â–â–†â–†â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–…â–ˆâ–‚â–ƒâ–‡â–…â–„â–â–…â–‚â–ƒâ–‡â–‚â–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–…â–ˆâ–†â–†â–‡â–ˆâ–ƒâ–ƒâ–ˆâ–‚â–†â–‡â–‚â–†â–†â–ˆâ–†â–‚â–‡â–ˆâ–†â–‚â–â–ˆâ–‚â–†â–‚â–…â–†â–ˆâ–†â–†â–†â–ƒâ–†â–ˆâ–ˆâ–…â–â–…
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–ƒâ–â–…â–†â–ƒâ–…â–„â–â–ƒâ–ƒâ–‚â–ƒâ–†â–ƒâ–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–â–†â–ƒâ–…â–„â–ƒâ–†â–„â–…â–„â–‚â–…â–†â–„â–…â–‚
wandb:      train/ensemble_f1 â–…â–…â–†â–…â–‡â–‡â–‡â–‡â–„â–…â–‡â–…â–‡â–†â–†â–ˆâ–„â–„â–…â–„â–â–…â–ˆâ–…â–ƒâ–‡â–†â–†â–ƒâ–…â–†â–†â–„â–‡â–†â–†â–†â–†â–†â–…
wandb:         train/mil_loss â–…â–‚â–…â–…â–‡â–„â–‡â–„â–‡â–ƒâ–„â–ˆâ–ƒâ–…â–ƒâ–…â–ƒâ–„â–†â–…â–ƒâ–„â–â–ƒâ–ƒâ–…â–â–ƒâ–‚â–ƒâ–†â–‡â–ƒâ–ƒâ–„â–â–„â–†â–ƒâ–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–â–â–„â–„â–ˆâ–ˆâ–†â–„â–ˆâ–ƒâ–ˆâ–†â–ˆâ–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–ˆâ–â–ˆâ–„â–ˆâ–„â–â–ƒâ–„â–„â–ˆâ–ˆâ–â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.27036
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.72685
wandb:      eval/avg_mil_loss 2.38826
wandb:       eval/ensemble_f1 0.72685
wandb:           train/avg_f1 0.73635
wandb:      train/ensemble_f1 0.73635
wandb:         train/mil_loss 1.6364
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run still-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcytuca5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063630-lcytuca5/logs
wandb: ERROR Run lcytuca5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mnflvvkz with config:
wandb: 	actor_learning_rate: 2.409310646688514e-06
wandb: 	attention_dropout_p: 0.3815551408063677
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9500890656524132
wandb: 	temperature: 2.504749694275165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063818-mnflvvkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnflvvkz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–â–„â–ˆâ–…â–…â–…â–â–…â–„â–…â–…â–…â–…â–…â–ˆâ–‚â–…â–â–…â–‚â–…â–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–„â–…â–…â–…â–‚â–…â–â–…â–…â–…
wandb:      eval/avg_mil_loss â–…â–‡â–â–ˆâ–„â–â–„â–…â–„â–ƒâ–†â–„â–„â–â–†â–„â–ƒâ–ƒâ–â–„â–â–ƒâ–„â–ƒâ–ƒâ–…â–„â–â–â–â–ƒâ–†â–‚â–„â–…â–„â–„â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–…â–ƒâ–ˆâ–†â–…â–ƒâ–ƒâ–…â–…â–†â–…â–ˆâ–…â–ˆâ–†â–ƒâ–…â–…â–…â–ˆâ–‡â–ˆâ–â–ˆâ–ƒâ–…â–ƒâ–‡â–…â–ˆâ–†â–†â–‡â–ƒâ–ƒâ–†â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–â–„â–†â–„â–„â–â–†â–ƒâ–„â–…â–‚â–…â–ˆâ–ƒâ–ƒâ–„â–‚â–†â–ƒâ–…â–‚â–…â–‡â–…â–…â–„â–†â–…â–ƒâ–…â–ƒâ–…â–„â–â–ƒâ–…â–„â–†â–†
wandb:      train/ensemble_f1 â–‚â–„â–ƒâ–„â–…â–†â–„â–†â–…â–‡â–ƒâ–â–ƒâ–…â–…â–ˆâ–†â–†â–ƒâ–‡â–„â–„â–‚â–…â–…â–ƒâ–†â–„â–„â–„â–„â–ƒâ–…â–ƒâ–…â–…â–„â–„â–…â–†
wandb:         train/mil_loss â–‡â–‡â–„â–‡â–…â–‚â–…â–ƒâ–‡â–ƒâ–…â–…â–†â–…â–‡â–†â–„â–‚â–„â–…â–‡â–ˆâ–„â–„â–„â–„â–â–„â–‡â–„â–‡â–ƒâ–ƒâ–„â–„â–†â–…â–†â–‚â–†
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92937
wandb: best/eval_avg_mil_loss 0.3013
wandb:  best/eval_ensemble_f1 0.92937
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.67697
wandb:       eval/ensemble_f1 0.79074
wandb:            test/avg_f1 0.80972
wandb:      test/avg_mil_loss 0.37385
wandb:       test/ensemble_f1 0.80972
wandb:           train/avg_f1 0.80545
wandb:      train/ensemble_f1 0.80545
wandb:         train/mil_loss 0.65736
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run denim-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnflvvkz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063818-mnflvvkz/logs
wandb: Agent Starting Run: g63jyxex with config:
wandb: 	actor_learning_rate: 0.0001801374602086915
wandb: 	attention_dropout_p: 0.3044137492239417
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46481595092850136
wandb: 	temperature: 6.567912751740495
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063956-g63jyxex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g63jyxex
wandb: uploading history steps 132-150; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–„â–„â–„â–‚â–ˆâ–„â–„â–‚â–„â–„â–…â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–â–ƒâ–…â–…â–…â–‚â–…â–…â–„â–‚â–ˆâ–ˆâ–„â–…â–…â–…â–…â–„â–â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–†â–‡â–…â–„â–ƒâ–ˆâ–ƒâ–ˆâ–‚â–…â–…â–‡â–„â–…â–…â–‚â–‚â–‡â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–…â–â–…â–…â–‡â–‚â–‚â–…â–‡â–‚â–…â–„â–…
wandb:       eval/ensemble_f1 â–‚â–…â–„â–„â–„â–ˆâ–„â–‚â–„â–‚â–„â–„â–ˆâ–…â–‚â–ƒâ–ƒâ–„â–…â–â–…â–‚â–‚â–…â–…â–„â–ˆâ–â–ˆâ–ˆâ–ƒâ–…â–…â–…â–ˆâ–â–â–…â–…â–‚
wandb:           train/avg_f1 â–ƒâ–‚â–…â–‚â–ƒâ–‡â–‚â–„â–„â–…â–„â–„â–‚â–ƒâ–ƒâ–„â–†â–‚â–…â–„â–…â–„â–„â–„â–‡â–‚â–â–‚â–„â–‚â–ƒâ–„â–†â–…â–†â–‚â–â–ˆâ–…â–„
wandb:      train/ensemble_f1 â–â–ƒâ–‚â–ƒâ–„â–‚â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–„â–…â–…â–‚â–‚â–„â–†â–‚â–…â–‚â–†â–‚â–…â–ˆâ–†â–ƒâ–„â–…â–‡â–â–â–‚â–ˆâ–‡â–†â–‚â–†
wandb:         train/mil_loss â–‚â–„â–„â–…â–…â–…â–†â–†â–†â–ƒâ–ˆâ–‚â–„â–ƒâ–„â–ƒâ–„â–„â–ˆâ–â–ƒâ–…â–‚â–„â–†â–ƒâ–„â–†â–„â–…â–‚â–…â–â–‡â–„â–…â–…â–ƒâ–†â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91467
wandb: best/eval_avg_mil_loss 0.32185
wandb:  best/eval_ensemble_f1 0.91467
wandb:            eval/avg_f1 0.39974
wandb:      eval/avg_mil_loss 2.20486
wandb:       eval/ensemble_f1 0.39974
wandb:           train/avg_f1 0.56902
wandb:      train/ensemble_f1 0.56902
wandb:         train/mil_loss 1.11777
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bright-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g63jyxex
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063956-g63jyxex/logs
wandb: ERROR Run g63jyxex errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nmvncgd3 with config:
wandb: 	actor_learning_rate: 1.100276914536888e-05
wandb: 	attention_dropout_p: 0.08545410870841263
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9086033247214296
wandb: 	temperature: 0.16077718688284004
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064211-nmvncgd3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nmvncgd3
wandb: uploading wandb-summary.json
wandb: uploading history steps 92-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–„â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–‚â–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–‡â–ˆâ–ƒâ–‚â–ˆâ–‡â–‡â–‡â–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–‡â–ˆâ–ƒâ–ˆâ–‡â–‚â–â–ƒâ–ƒâ–ƒâ–ˆâ–ˆâ–‡â–ˆâ–ƒâ–â–‡â–‡
wandb:      eval/avg_mil_loss â–…â–â–…â–†â–ƒâ–ƒâ–â–†â–ƒâ–ƒâ–‚â–†â–†â–„â–ƒâ–…â–‡â–„â–â–â–†â–†â–‡â–†â–†â–â–â–…â–ƒâ–ˆâ–„â–â–ƒâ–‡â–â–â–â–†â–„â–
wandb:       eval/ensemble_f1 â–ƒâ–‚â–ƒâ–‡â–‡â–ˆâ–„â–‡â–„â–„â–ˆâ–…â–‚â–‡â–‡â–„â–â–‡â–‡â–„â–ˆâ–â–ˆâ–„â–ˆâ–ˆâ–ƒâ–‚â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–„â–†â–†â–ˆâ–†â–‡â–†â–‡â–ƒâ–†â–…â–‡â–‚â–‡â–ˆâ–„â–…â–…â–†â–ˆâ–„â–…â–â–…â–…â–„â–„â–‡â–…â–„â–ƒâ–‚â–ƒâ–‡â–…â–…â–†â–„
wandb:      train/ensemble_f1 â–…â–†â–ˆâ–†â–…â–ˆâ–†â–„â–‡â–ˆâ–…â–†â–…â–†â–â–ƒâ–‚â–‡â–†â–‡â–ƒâ–…â–ƒâ–„â–…â–…â–…â–‡â–ƒâ–„â–…â–„â–ƒâ–„â–†â–…â–†â–…â–†â–„
wandb:         train/mil_loss â–ƒâ–†â–â–…â–â–‚â–„â–‚â–†â–â–†â–ƒâ–…â–„â–…â–„â–†â–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–„â–ˆâ–â–…â–‡â–ƒâ–‚â–ƒâ–„â–„â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.24713
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.86417
wandb:      eval/avg_mil_loss 0.36554
wandb:       eval/ensemble_f1 0.86417
wandb:            test/avg_f1 0.43582
wandb:      test/avg_mil_loss 1.90037
wandb:       test/ensemble_f1 0.43582
wandb:           train/avg_f1 0.80372
wandb:      train/ensemble_f1 0.80372
wandb:         train/mil_loss 0.52244
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nmvncgd3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064211-nmvncgd3/logs
wandb: Agent Starting Run: tsykheky with config:
wandb: 	actor_learning_rate: 8.42485509882352e-06
wandb: 	attention_dropout_p: 0.25819518933022223
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6260921663637279
wandb: 	temperature: 9.295688682752363
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064344-tsykheky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsykheky
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 169-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–ƒâ–ˆâ–ˆâ–„â–‡â–ˆâ–…â–ˆâ–‡â–„â–â–ˆâ–‚â–ˆâ–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–„â–‚â–†â–ˆâ–â–†â–†â–ˆâ–„â–ƒâ–ˆâ–…â–‚â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‡â–â–ƒâ–â–„â–†â–ƒâ–„â–„â–…â–‚â–ˆâ–‚â–â–…â–…â–…â–ƒâ–ƒâ–…â–„â–â–„â–ƒâ–‚â–…â–„â–…â–„â–‚â–‚â–â–ƒâ–‚â–†â–…â–…â–â–„â–…
wandb:       eval/ensemble_f1 â–ˆâ–‡â–†â–…â–ˆâ–ˆâ–ˆâ–†â–‚â–ˆâ–„â–â–ˆâ–‚â–‚â–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–†â–ˆâ–…â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–„â–ƒâ–ˆâ–ˆâ–‚â–„â–…
wandb:           train/avg_f1 â–‚â–…â–…â–ƒâ–„â–…â–‡â–â–†â–‡â–…â–ˆâ–„â–…â–‡â–‚â–‚â–†â–…â–‚â–‡â–‡â–ƒâ–‡â–ƒâ–…â–â–†â–‚â–ƒâ–†â–†â–„â–„â–‚â–„â–†â–†â–…â–†
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‡â–†â–…â–‡â–„â–…â–…â–ƒâ–‡â–†â–‡â–„â–„â–ˆâ–ƒâ–‚â–‡â–ƒâ–„â–†â–†â–†â–â–†â–†â–…â–‚â–†â–ƒâ–„â–„â–‡â–‡â–…â–†â–‡â–„â–…
wandb:         train/mil_loss â–„â–…â–„â–…â–„â–ˆâ–…â–‚â–ƒâ–…â–†â–„â–‡â–†â–„â–ƒâ–„â–ƒâ–„â–†â–„â–‚â–…â–†â–‚â–â–…â–‡â–…â–…â–…â–ƒâ–†â–ƒâ–â–„â–†â–„â–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91104
wandb: best/eval_avg_mil_loss 0.28415
wandb:  best/eval_ensemble_f1 0.91104
wandb:            eval/avg_f1 0.87871
wandb:      eval/avg_mil_loss 2.14335
wandb:       eval/ensemble_f1 0.87871
wandb:           train/avg_f1 0.76819
wandb:      train/ensemble_f1 0.76819
wandb:         train/mil_loss 1.29142
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsykheky
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064344-tsykheky/logs
wandb: ERROR Run tsykheky errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4m1j4fo6 with config:
wandb: 	actor_learning_rate: 0.00046570371214183664
wandb: 	attention_dropout_p: 0.3224735109010155
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7428630387964165
wandb: 	temperature: 9.154708017511435
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064609-4m1j4fo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4m1j4fo6
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 112-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–…â–‡â–…â–ˆâ–ˆâ–‡â–ˆâ–„â–…â–‚â–ƒâ–ƒâ–â–ƒâ–„â–ˆâ–‡â–ƒâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ƒâ–‡â–ˆâ–‡â–ƒâ–„â–„â–…â–„â–‡â–„â–…â–„â–ˆâ–‡
wandb:      eval/avg_mil_loss â–â–‚â–â–†â–â–„â–„â–‚â–„â–‚â–†â–‚â–â–†â–†â–ƒâ–ˆâ–„â–‚â–‚â–‚â–…â–„â–„â–â–ƒâ–â–ƒâ–‚â–ƒâ–…â–‡â–‚â–‚â–„â–‚â–ƒâ–ƒâ–â–
wandb:       eval/ensemble_f1 â–ˆâ–„â–ˆâ–ˆâ–„â–…â–ˆâ–ˆâ–„â–ˆâ–ƒâ–„â–ƒâ–‡â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–‡â–…â–ˆâ–ˆâ–…â–…â–…â–‚â–ˆâ–â–„â–ˆâ–…â–…â–‡â–ƒâ–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–„â–„â–†â–„â–…â–…â–ƒâ–â–„â–„â–…â–ƒâ–„â–„â–…â–‡â–‚â–„â–„â–„â–‚â–†â–„â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–â–‡â–„â–…â–ƒâ–…â–ˆâ–†â–…
wandb:      train/ensemble_f1 â–†â–ˆâ–â–†â–†â–„â–‚â–…â–â–„â–ˆâ–‡â–†â–†â–…â–ƒâ–†â–‚â–†â–ƒâ–…â–„â–‡â–‡â–†â–†â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆâ–†â–ˆâ–…â–â–ˆâ–
wandb:         train/mil_loss â–…â–‡â–ƒâ–â–‚â–‚â–…â–‚â–‡â–…â–…â–ƒâ–ƒâ–‡â–„â–„â–ƒâ–‚â–‚â–…â–„â–„â–‡â–…â–ƒâ–‚â–â–ƒâ–„â–‚â–„â–…â–ƒâ–ˆâ–…â–ƒâ–†â–†â–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.38586
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.40598
wandb:       eval/ensemble_f1 0.9105
wandb:            test/avg_f1 0.90463
wandb:      test/avg_mil_loss 0.2735
wandb:       test/ensemble_f1 0.90463
wandb:           train/avg_f1 0.71943
wandb:      train/ensemble_f1 0.71943
wandb:         train/mil_loss 0.83276
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run expert-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4m1j4fo6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064609-4m1j4fo6/logs
wandb: Agent Starting Run: ai1vktmn with config:
wandb: 	actor_learning_rate: 2.9859631058581894e-06
wandb: 	attention_dropout_p: 0.03974653216419749
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1992324353251297
wandb: 	temperature: 4.330440365883321
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064758-ai1vktmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai1vktmn
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–…â–…â–ƒâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ˆâ–†â–…â–…â–„â–„â–…â–‚â–ˆâ–‡â–‡â–â–‡â–†â–†â–‡â–„â–†â–†â–ƒâ–†â–†â–‚â–‚â–‚â–„â–â–‡â–‡â–‚â–…â–†â–†â–†â–…â–…â–‡â–…
wandb:      eval/avg_mil_loss â–ƒâ–‡â–ƒâ–‚â–‚â–â–„â–†â–„â–„â–‡â–…â–†â–ƒâ–ƒâ–ˆâ–…â–‚â–ƒâ–ƒâ–„â–‚â–„â–„â–‡â–†â–‡â–…â–„â–ˆâ–…â–…â–„â–‚â–„â–‡â–…â–ƒâ–„â–‚
wandb:       eval/ensemble_f1 â–‚â–â–†â–‡â–‡â–†â–„â–â–„â–„â–†â–‚â–‚â–†â–‡â–‡â–†â–†â–†â–ˆâ–„â–„â–‡â–…â–‡â–‚â–â–‡â–ˆâ–â–†â–‡â–†â–…â–â–ˆâ–„â–ƒâ–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–…â–„â–„â–‚â–ˆâ–‡â–…â–„â–„â–â–…â–…â–ƒâ–â–‡â–„â–…â–…â–ƒâ–„â–…â–‡â–‚â–…â–„â–‚â–†â–ˆâ–„â–…â–†â–„â–„â–ƒâ–‡â–…â–†â–‡
wandb:      train/ensemble_f1 â–â–…â–„â–…â–…â–‡â–ƒâ–‚â–ƒâ–ˆâ–„â–‡â–…â–‡â–„â–„â–ƒâ–ƒâ–…â–„â–‡â–‡â–…â–‚â–‡â–‡â–…â–‡â–…â–„â–…â–‡â–…â–„â–ƒâ–„â–ƒâ–ƒâ–…â–…
wandb:         train/mil_loss â–„â–‡â–„â–„â–‚â–…â–‡â–…â–…â–…â–ƒâ–„â–…â–ˆâ–…â–‚â–…â–ƒâ–…â–â–†â–†â–„â–„â–„â–…â–†â–„â–‚â–ƒâ–†â–…â–‚â–„â–…â–„â–„â–†â–‚â–ƒ
wandb:      train/policy_loss â–‚â–‚â–‡â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–‚â–„â–„â–„â–„â–„â–‡â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90646
wandb: best/eval_avg_mil_loss 0.25635
wandb:  best/eval_ensemble_f1 0.90646
wandb:            eval/avg_f1 0.74365
wandb:      eval/avg_mil_loss 1.3233
wandb:       eval/ensemble_f1 0.74365
wandb:            test/avg_f1 0.65471
wandb:      test/avg_mil_loss 2.01423
wandb:       test/ensemble_f1 0.65471
wandb:           train/avg_f1 0.75554
wandb:      train/ensemble_f1 0.75554
wandb:         train/mil_loss 1.31137
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai1vktmn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064758-ai1vktmn/logs
wandb: Agent Starting Run: mfsjzgty with config:
wandb: 	actor_learning_rate: 1.266570277867515e-06
wandb: 	attention_dropout_p: 0.28573121544878016
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21499990818371809
wandb: 	temperature: 6.77539079742998
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065139-mfsjzgty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mfsjzgty
wandb: uploading history steps 173-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ˆâ–‚â–‚â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–„â–â–ƒâ–„â–†â–â–‚â–…â–„â–‚â–„â–„â–ˆâ–†â–‡â–â–‡â–ƒâ–†â–…â–ˆâ–†â–†â–†â–‡â–‡â–†â–‚â–ƒâ–†â–â–‡â–ˆâ–‡â–â–‡â–…â–‚
wandb:      eval/avg_mil_loss â–‡â–†â–ˆâ–‡â–…â–„â–„â–‡â–†â–ƒâ–‡â–…â–„â–„â–…â–…â–…â–…â–„â–…â–„â–‚â–…â–…â–†â–„â–†â–†â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–†â–‚â–†â–‡â–ƒâ–â–†
wandb:       eval/ensemble_f1 â–ƒâ–‚â–‚â–â–„â–„â–†â–„â–†â–„â–â–…â–†â–ƒâ–â–ƒâ–‡â–…â–â–ƒâ–„â–„â–ƒâ–…â–…â–‡â–‡â–ƒâ–ƒâ–…â–…â–…â–…â–†â–…â–â–ƒâ–â–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–„â–ƒâ–„â–…â–‚â–†â–…â–…â–‡â–‚â–…â–„â–…â–…â–„â–…â–†â–…â–ƒâ–ƒâ–†â–ˆâ–…â–…â–†â–ˆâ–†â–‡â–‡â–‡â–…
wandb:      train/ensemble_f1 â–ƒâ–…â–â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–â–ƒâ–„â–ƒâ–„â–ƒâ–„â–…â–…â–…â–„â–†â–„â–…â–ƒâ–„â–„â–…â–„â–…â–ƒâ–ƒâ–ƒâ–‡â–ˆâ–…â–†â–…â–…â–†â–‡
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–…â–ˆâ–…â–ˆâ–…â–„â–ˆâ–†â–„â–†â–ƒâ–…â–†â–ˆâ–ƒâ–‡â–ƒâ–„â–†â–„â–†â–„â–…â–†â–‚â–â–â–„â–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65905
wandb: best/eval_avg_mil_loss 0.8228
wandb:  best/eval_ensemble_f1 0.65905
wandb:            eval/avg_f1 0.37271
wandb:      eval/avg_mil_loss 2.91287
wandb:       eval/ensemble_f1 0.37271
wandb:            test/avg_f1 0.61383
wandb:      test/avg_mil_loss 0.99803
wandb:       test/ensemble_f1 0.61383
wandb:           train/avg_f1 0.51958
wandb:      train/ensemble_f1 0.51958
wandb:         train/mil_loss 1.65302
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mfsjzgty
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065139-mfsjzgty/logs
wandb: Agent Starting Run: vifv4u4h with config:
wandb: 	actor_learning_rate: 9.637507958317216e-06
wandb: 	attention_dropout_p: 0.11076624954734438
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7032308547717373
wandb: 	temperature: 8.095363741729768
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065419-vifv4u4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vifv4u4h
wandb: uploading history steps 74-91, summary; uploading wandb-summary.json
wandb: uploading history steps 92-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–ˆâ–‚â–ˆâ–‡â–ˆâ–ˆâ–‡â–„â–ˆâ–ˆâ–ƒâ–„â–‚â–ˆâ–ˆâ–„â–ˆâ–â–ˆâ–ˆâ–ˆâ–‚â–„â–…â–ˆâ–…â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ƒâ–‡â–‚â–‚â–„â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–‚â–ƒâ–„â–ˆâ–„â–„â–‚â–‚â–„â–†â–â–„â–ƒâ–‚â–†â–…â–â–„â–†â–‚â–„â–†â–â–â–‚â–ƒâ–‚â–â–â–â–‚â–â–‚â–…â–‡â–â–†
wandb:       eval/ensemble_f1 â–„â–ƒâ–„â–…â–ˆâ–ˆâ–‡â–ˆâ–‚â–‡â–‚â–ˆâ–„â–„â–â–„â–„â–ˆâ–‡â–â–‡â–‡â–‚â–ˆâ–„â–‚â–â–„â–ˆâ–„â–‡â–…â–ˆâ–‡â–ˆâ–„â–ˆâ–‡â–‡â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–…â–„â–…â–…â–†â–‡â–‚â–„â–†â–ƒâ–ˆâ–†â–†â–‡â–…â–‡â–„â–‡â–†â–…â–‡â–ƒâ–†â–†â–‡â–â–…â–†â–†â–„â–‡â–…â–…â–„â–†â–‡â–
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–„â–‚â–…â–‚â–„â–…â–…â–„â–â–„â–ƒâ–†â–„â–ˆâ–„â–†â–‚â–„â–…â–…â–â–„â–†â–†â–…â–„â–…â–…â–„â–…â–„â–
wandb:         train/mil_loss â–ƒâ–‚â–†â–„â–„â–ƒâ–…â–ˆâ–…â–ƒâ–†â–‚â–†â–…â–†â–„â–„â–„â–„â–…â–…â–„â–…â–‡â–â–…â–†â–„â–„â–‚â–…â–‡â–†â–‚â–†â–…â–ƒâ–†â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–â–ˆâ–â–„â–„â–„â–„â–â–„â–â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.32823
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.63149
wandb:      eval/avg_mil_loss 1.04953
wandb:       eval/ensemble_f1 0.63149
wandb:           train/avg_f1 0.55031
wandb:      train/ensemble_f1 0.55031
wandb:         train/mil_loss 1.02468
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run peachy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vifv4u4h
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065419-vifv4u4h/logs
wandb: ERROR Run vifv4u4h errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5fpve8fo with config:
wandb: 	actor_learning_rate: 1.9114673786080992e-06
wandb: 	attention_dropout_p: 0.3760853983522699
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.946205765093049
wandb: 	temperature: 8.37405239149835
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065551-5fpve8fo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5fpve8fo
wandb: uploading history steps 151-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ˆâ–ƒâ–„â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–â–‚â–‚â–…â–†â–‚â–†â–ƒâ–†â–ˆâ–†â–…â–â–…â–„â–‚â–ˆâ–…â–‡â–„â–‚â–„â–ƒâ–…â–†â–„â–„â–‚â–ƒâ–…â–ˆâ–‡â–…â–†â–„â–„â–ƒâ–„
wandb:      eval/avg_mil_loss â–ˆâ–†â–…â–…â–…â–…â–‚â–†â–„â–†â–„â–‚â–„â–ƒâ–„â–…â–ƒâ–ƒâ–†â–…â–…â–â–…â–‚â–‚â–ƒâ–â–„â–„â–â–‚â–„â–†â–ƒâ–…â–„â–ƒâ–‚â–‚â–
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–„â–„â–†â–ˆâ–†â–…â–â–„â–â–†â–„â–ˆâ–†â–‡â–‡â–ƒâ–…â–„â–…â–‡â–„â–‡â–ƒâ–‡â–‡â–…â–†â–ƒâ–‡â–„â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–†â–ƒâ–…â–‡â–„â–…â–‚â–ƒâ–†â–…â–„â–…â–ƒâ–†â–†â–…â–…â–†â–„â–‡â–…â–„â–ˆâ–†â–…â–‡â–…â–†â–†
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‡â–‚â–ƒâ–…â–…â–ƒâ–ƒâ–â–„â–„â–†â–…â–†â–â–†â–ƒâ–…â–†â–†â–…â–‡â–‡â–ƒâ–†â–†â–„â–ˆâ–†â–‡â–‡â–‡â–…â–†â–ˆâ–‡â–…â–ˆâ–‡
wandb:         train/mil_loss â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–„â–ƒâ–„â–‡â–†â–…â–…â–ƒâ–ƒâ–†â–„â–…â–„â–ƒâ–„â–‡â–…â–‚â–‡â–‚â–ƒâ–‚â–„â–„â–„â–„â–…â–ƒâ–„â–â–„â–„â–…
wandb:      train/policy_loss â–†â–â–†â–†â–†â–…â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88215
wandb: best/eval_avg_mil_loss 0.38718
wandb:  best/eval_ensemble_f1 0.88215
wandb:            eval/avg_f1 0.88215
wandb:      eval/avg_mil_loss 0.38718
wandb:       eval/ensemble_f1 0.88215
wandb:            test/avg_f1 0.65357
wandb:      test/avg_mil_loss 1.31664
wandb:       test/ensemble_f1 0.65357
wandb:           train/avg_f1 0.73452
wandb:      train/ensemble_f1 0.73452
wandb:         train/mil_loss 1.06036
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5fpve8fo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065551-5fpve8fo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qy1gp378 with config:
wandb: 	actor_learning_rate: 4.521310608845224e-06
wandb: 	attention_dropout_p: 0.20820253033291924
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14244501814576116
wandb: 	temperature: 8.713077718351629
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065852-qy1gp378
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qy1gp378
wandb: uploading history steps 121-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‡â–…â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–‡â–‡â–ˆâ–…â–â–‡â–ˆâ–†â–†â–†â–„â–„â–ˆâ–ˆâ–ˆâ–‚â–†â–ˆâ–ˆâ–‡â–ƒâ–‡â–†â–†â–ˆâ–‡â–†â–…â–ˆâ–…â–„â–ƒâ–…â–„â–‡â–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–ƒâ–â–â–ƒâ–â–â–ƒâ–„â–„â–ƒâ–â–…â–‚â–ƒâ–ƒâ–„â–â–…â–†â–‚â–ˆâ–…â–…â–‚â–â–ˆâ–ƒâ–‚â–„â–…â–‡â–â–‡â–‚â–…â–‚â–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–…â–ˆâ–„â–„â–…â–ˆâ–‡â–‡â–†â–…â–…â–…â–†â–„â–†â–†â–†â–ˆâ–‚â–ˆâ–†â–‡â–‡â–‚â–…â–â–â–ˆâ–†â–ˆâ–ƒâ–…â–…â–‚â–‡â–†â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–‡â–ƒâ–‡â–‡â–…â–ˆâ–†â–â–…â–„â–†â–„â–…â–„â–„â–†â–†â–…â–…â–â–‚â–†â–ˆâ–†â–†â–ˆâ–†â–‡â–„â–…â–ƒâ–ˆâ–‡â–†â–ˆâ–…â–ƒâ–‚
wandb:      train/ensemble_f1 â–‡â–†â–‚â–…â–…â–â–‡â–†â–„â–ƒâ–†â–…â–„â–„â–†â–…â–‚â–ˆâ–…â–„â–‚â–†â–…â–„â–…â–†â–ƒâ–„â–ˆâ–…â–ƒâ–ˆâ–„â–‚â–†â–†â–ƒâ–†â–‡â–„
wandb:         train/mil_loss â–‚â–†â–‚â–„â–…â–„â–…â–„â–ƒâ–‡â–†â–‚â–‚â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ˆâ–„â–…â–„â–ˆâ–‡â–ƒâ–†â–‡â–…â–„â–ƒâ–„â–†â–ƒâ–â–…â–ˆâ–‡â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.31336
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.75726
wandb:      eval/avg_mil_loss 1.02166
wandb:       eval/ensemble_f1 0.75726
wandb:            test/avg_f1 0.77723
wandb:      test/avg_mil_loss 0.47302
wandb:       test/ensemble_f1 0.77723
wandb:           train/avg_f1 0.7609
wandb:      train/ensemble_f1 0.7609
wandb:         train/mil_loss 0.74148
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fearless-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qy1gp378
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065852-qy1gp378/logs
wandb: Agent Starting Run: lmbjpcnj with config:
wandb: 	actor_learning_rate: 0.00045212723914902846
wandb: 	attention_dropout_p: 0.2164793240727867
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05134473710260079
wandb: 	temperature: 2.6449141797554256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070051-lmbjpcnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lmbjpcnj
wandb: uploading history steps 97-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–â–…â–ˆâ–…â–„â–ˆâ–‡â–ˆâ–ƒâ–…â–‡â–„â–…â–…â–…â–…â–†â–‡â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–„â–†â–…â–ƒâ–…â–‡â–‡â–‡â–‡â–ƒâ–†
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–†â–„â–‚â–…â–â–â–ƒâ–†â–‡â–„â–â–‚â–ˆâ–‚â–„â–ƒâ–ƒâ–‚â–‚â–ˆâ–â–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–‡â–…â–‚â–ƒâ–‚â–„â–‡â–â–„â–„
wandb:       eval/ensemble_f1 â–ƒâ–†â–ˆâ–†â–„â–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–…â–‡â–†â–†â–„â–†â–…â–…â–‡â–‡â–…â–„â–ˆâ–‡â–‡â–…â–‡â–ˆâ–‡â–…â–„â–â–†â–†â–‡â–†â–‡â–…â–…
wandb:           train/avg_f1 â–†â–ˆâ–„â–†â–„â–â–†â–„â–†â–„â–†â–‡â–…â–„â–†â–…â–„â–†â–‡â–†â–†â–…â–…â–…â–„â–‡â–…â–ƒâ–‡â–…â–ˆâ–„â–†â–†â–ˆâ–…â–‡â–ƒâ–†â–…
wandb:      train/ensemble_f1 â–„â–„â–†â–†â–ƒâ–ƒâ–…â–‚â–â–ƒâ–„â–„â–„â–‡â–ƒâ–„â–‚â–„â–„â–…â–ƒâ–„â–ƒâ–„â–…â–ƒâ–„â–…â–ˆâ–â–„â–„â–†â–„â–ƒâ–…â–‚â–„â–…â–…
wandb:         train/mil_loss â–„â–‚â–‡â–ƒâ–‡â–â–‚â–‚â–‡â–„â–‚â–ƒâ–„â–„â–„â–…â–‡â–ƒâ–â–„â–ƒâ–…â–…â–„â–…â–„â–ƒâ–„â–†â–†â–‡â–ˆâ–„â–â–†â–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.26956
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.86024
wandb:      eval/avg_mil_loss 0.32663
wandb:       eval/ensemble_f1 0.86024
wandb:           train/avg_f1 0.81385
wandb:      train/ensemble_f1 0.81385
wandb:         train/mil_loss 0.5084
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fragrant-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lmbjpcnj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070051-lmbjpcnj/logs
wandb: ERROR Run lmbjpcnj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: t2c236v2 with config:
wandb: 	actor_learning_rate: 2.6368426030140062e-05
wandb: 	attention_dropout_p: 0.3952243242628392
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17722777007407498
wandb: 	temperature: 5.855783749984291
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070244-t2c236v2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t2c236v2
wandb: uploading history steps 97-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–…â–‚â–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–‡â–â–ƒâ–‡â–‡â–‚â–ƒâ–‡â–„â–‚â–†â–ƒâ–ˆâ–…â–ƒâ–‚â–…â–†â–‡â–…â–‡â–ˆâ–‡â–‡â–†â–†â–‡â–„â–…â–…â–„â–„â–…â–ƒâ–ˆâ–†â–†â–†
wandb:      eval/avg_mil_loss â–‡â–‡â–†â–†â–„â–‡â–†â–…â–ƒâ–ˆâ–„â–‡â–„â–…â–‚â–‡â–ƒâ–…â–‚â–‚â–„â–‚â–„â–â–ƒâ–…â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–…â–ƒâ–…â–‚â–„â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–„â–…â–‚â–…â–â–ˆâ–ƒâ–†â–â–„â–…â–â–‚â–„â–ƒâ–‚â–†â–…â–â–†â–„â–…â–â–„â–‡â–ˆâ–†â–†â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–‡â–â–…â–‡â–…â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–„â–„â–†â–ƒâ–ƒâ–‚â–„â–…â–„â–‚â–„â–‚â–†â–…â–‡â–ƒâ–…â–†â–…â–…â–ƒâ–ˆâ–…â–„â–†â–‡â–‡â–â–†â–…â–…â–„â–‡
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–‚â–„â–†â–„â–„â–‚â–„â–‚â–†â–„â–„â–„â–…â–…â–„â–„â–…â–‡â–‡â–â–…â–ˆâ–…â–„â–†â–‡â–†
wandb:         train/mil_loss â–‚â–†â–†â–â–ˆâ–…â–„â–…â–…â–ƒâ–†â–…â–…â–…â–…â–…â–„â–…â–ƒâ–„â–…â–„â–‚â–„â–ƒâ–„â–„â–‚â–‚â–„â–ƒâ–â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91173
wandb: best/eval_avg_mil_loss 0.28748
wandb:  best/eval_ensemble_f1 0.91173
wandb:            eval/avg_f1 0.79905
wandb:      eval/avg_mil_loss 0.46795
wandb:       eval/ensemble_f1 0.79905
wandb:           train/avg_f1 0.83002
wandb:      train/ensemble_f1 0.83002
wandb:         train/mil_loss 0.42284
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t2c236v2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070244-t2c236v2/logs
wandb: ERROR Run t2c236v2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bh81u9kc with config:
wandb: 	actor_learning_rate: 0.0006344534279305844
wandb: 	attention_dropout_p: 0.204126182632062
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23201103886208263
wandb: 	temperature: 4.042254870601484
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070449-bh81u9kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bh81u9kc
wandb: uploading wandb-summary.json
wandb: uploading history steps 56-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–…â–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–„â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ƒâ–…â–ˆâ–„â–ˆâ–‡â–„â–â–ˆâ–â–„â–„â–„â–ƒâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–…â–ƒâ–‚â–„â–ˆâ–„â–…â–‚â–â–…â–‚â–„â–…â–…
wandb:      eval/avg_mil_loss â–…â–…â–„â–‚â–â–ƒâ–…â–‚â–ƒâ–‚â–‚â–„â–ƒâ–â–ƒâ–ƒâ–„â–ˆâ–‚â–‚â–ƒâ–â–â–ƒâ–…â–‚â–ƒâ–ƒâ–†â–ƒâ–‚â–…â–†â–‚â–‚â–…â–ƒâ–ƒâ–‚â–‚
wandb:       eval/ensemble_f1 â–‚â–„â–ˆâ–ˆâ–„â–ƒâ–‚â–ˆâ–ƒâ–ˆâ–…â–ˆâ–‡â–„â–„â–„â–„â–ˆâ–â–„â–„â–‚â–ƒâ–ˆâ–‚â–ˆâ–ˆâ–…â–ƒâ–ˆâ–„â–ˆâ–ƒâ–‚â–…â–ƒâ–‚â–…â–…â–ƒ
wandb:           train/avg_f1 â–ƒâ–…â–…â–ƒâ–ƒâ–‚â–…â–‚â–ˆâ–†â–„â–„â–â–ƒâ–„â–„â–„â–…â–‡â–„â–…â–„â–ƒâ–‚â–†â–ƒâ–„â–ƒâ–ƒâ–‡â–…â–„â–‚â–ƒâ–†â–†â–…â–†â–ƒâ–†
wandb:      train/ensemble_f1 â–ƒâ–…â–…â–ƒâ–ƒâ–‚â–…â–ˆâ–†â–…â–…â–„â–„â–‡â–„â–…â–â–„â–ƒâ–„â–‡â–„â–‚â–„â–‚â–„â–â–‚â–ƒâ–ƒâ–‡â–…â–„â–…â–„â–ƒâ–†â–ƒâ–…â–ƒ
wandb:         train/mil_loss â–„â–„â–ƒâ–ƒâ–‡â–ƒâ–…â–ƒâ–†â–…â–…â–‡â–ˆâ–…â–„â–†â–„â–„â–…â–‚â–ƒâ–ƒâ–†â–â–â–ƒâ–…â–‡â–…â–„â–„â–„â–„â–‚â–ƒâ–ˆâ–‚â–„â–…â–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–â–„â–„â–ˆâ–„â–ˆâ–„â–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.35691
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.62207
wandb:      eval/avg_mil_loss 0.95252
wandb:       eval/ensemble_f1 0.62207
wandb:           train/avg_f1 0.76864
wandb:      train/ensemble_f1 0.76864
wandb:         train/mil_loss 0.87587
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run solar-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bh81u9kc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070449-bh81u9kc/logs
wandb: ERROR Run bh81u9kc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qi95z0dc with config:
wandb: 	actor_learning_rate: 0.00031066600427007515
wandb: 	attention_dropout_p: 0.2404099530046111
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4209732365111992
wandb: 	temperature: 2.973312994999351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070551-qi95z0dc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qi95z0dc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–‡â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–†â–ˆâ–‡â–‡â–‡â–…â–…â–„â–ˆâ–‡â–‡â–…â–ƒâ–†â–‡â–‡â–ˆâ–‡â–‡â–…â–†â–‡â–…â–‡â–‡â–ˆâ–‡â–…â–‡â–‡â–‡â–†â–†â–‡â–‡â–â–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–†â–‚â–„â–„â–†â–‚â–ƒâ–…â–‚â–ƒâ–…â–‚â–ƒâ–ˆâ–ƒâ–â–â–‚â–„â–‚â–ƒâ–‚â–†â–‚â–‚â–â–…â–ƒâ–„â–‚â–‚â–„â–ƒâ–‚â–„â–…â–„
wandb:       eval/ensemble_f1 â–†â–ƒâ–†â–†â–ˆâ–‚â–†â–ƒâ–„â–ƒâ–…â–†â–…â–ˆâ–„â–†â–ƒâ–…â–‡â–†â–…â–ˆâ–ˆâ–‡â–†â–†â–„â–†â–†â–ˆâ–ˆâ–â–…â–‡â–†â–†â–†â–†â–ƒâ–„
wandb:           train/avg_f1 â–†â–„â–ƒâ–„â–…â–…â–†â–‚â–…â–‡â–…â–ˆâ–…â–„â–…â–ƒâ–â–…â–„â–â–‚â–„â–‚â–ƒâ–†â–„â–†â–„â–‡â–„â–„â–ƒâ–†â–‡â–„â–„â–‚â–„â–†â–ƒ
wandb:      train/ensemble_f1 â–â–…â–„â–…â–…â–…â–ƒâ–ƒâ–‡â–ƒâ–†â–„â–…â–…â–ƒâ–ˆâ–…â–…â–…â–„â–†â–†â–…â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–…â–„â–…â–„â–†â–‡â–†â–…â–…â–…â–…
wandb:         train/mil_loss â–…â–‚â–‚â–‚â–ƒâ–…â–ƒâ–ˆâ–„â–â–…â–ƒâ–…â–ƒâ–‚â–„â–‡â–„â–„â–ƒâ–†â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‡â–‚â–‚â–„â–…â–ƒâ–‚â–‚â–â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–„â–„â–„â–ƒâ–„â–„â–â–„â–‚â–„â–ƒâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.26286
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.72463
wandb:      eval/avg_mil_loss 1.00118
wandb:       eval/ensemble_f1 0.72463
wandb:           train/avg_f1 0.77647
wandb:      train/ensemble_f1 0.77647
wandb:         train/mil_loss 0.60473
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silvery-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qi95z0dc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070551-qi95z0dc/logs
wandb: ERROR Run qi95z0dc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: u5mghsv4 with config:
wandb: 	actor_learning_rate: 7.522776964127412e-06
wandb: 	attention_dropout_p: 0.05511842106296155
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2058095108226491
wandb: 	temperature: 0.9088674062567892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070739-u5mghsv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u5mghsv4
wandb: uploading history steps 55-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–†â–‡â–ˆâ–…â–‚â–‚â–†â–†â–â–ˆâ–†â–…â–†â–…â–â–…â–ƒâ–†â–ˆâ–„â–‡â–‚â–„â–ˆâ–…â–‡â–†â–ƒâ–…â–â–‡â–‚â–â–…â–ƒâ–…â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–„â–ƒâ–â–â–ƒâ–„â–…â–‚â–‚â–â–â–ƒâ–„â–…â–‚â–…â–‡â–ƒâ–‚â–„â–‡â–„â–„â–‚â–†â–â–ƒâ–‚â–„â–‚â–†â–ˆâ–…â–‚â–…â–…â–†â–‚â–†â–‚
wandb:       eval/ensemble_f1 â–†â–†â–‡â–ˆâ–„â–†â–ˆâ–„â–„â–‡â–ˆâ–„â–ˆâ–†â–†â–‡â–†â–†â–„â–„â–ƒâ–ˆâ–„â–†â–‡â–†â–ˆâ–‡â–‡â–†â–†â–â–„â–„â–…â–„â–‡â–†â–…â–…
wandb:           train/avg_f1 â–„â–â–†â–â–†â–‚â–†â–†â–†â–„â–ƒâ–…â–…â–†â–„â–„â–…â–…â–„â–†â–ƒâ–…â–†â–…â–ƒâ–„â–…â–‡â–…â–†â–„â–ˆâ–„â–‚â–†â–†â–ˆâ–‚â–…â–‚
wandb:      train/ensemble_f1 â–„â–â–†â–â–†â–„â–‚â–†â–„â–†â–ƒâ–…â–‡â–…â–„â–„â–‡â–„â–…â–…â–‡â–ƒâ–…â–†â–„â–…â–ƒâ–…â–‡â–„â–ˆâ–…â–„â–‚â–ˆâ–†â–†â–ˆâ–‚â–„
wandb:         train/mil_loss â–„â–„â–†â–†â–â–ƒâ–„â–„â–ˆâ–ƒâ–‚â–„â–ƒâ–„â–‚â–†â–ƒâ–‚â–â–…â–ƒâ–â–ƒâ–‚â–„â–…â–„â–ƒâ–„â–…â–‚â–…â–ƒâ–„â–…â–„â–‡â–‚â–„â–„
wandb:      train/policy_loss â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.22453
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.8964
wandb:      eval/avg_mil_loss 0.51907
wandb:       eval/ensemble_f1 0.8964
wandb:           train/avg_f1 0.80953
wandb:      train/ensemble_f1 0.80953
wandb:         train/mil_loss 0.84773
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u5mghsv4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070739-u5mghsv4/logs
wandb: ERROR Run u5mghsv4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5kr9lyzj with config:
wandb: 	actor_learning_rate: 2.2915075215841347e-06
wandb: 	attention_dropout_p: 0.2383566172703224
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22962712277086297
wandb: 	temperature: 1.0762304214464211
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070852-5kr9lyzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5kr9lyzj
wandb: uploading history steps 123-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–ƒâ–ˆâ–…â–‡â–†â–†â–†â–†â–„â–„â–…â–ˆâ–†â–†â–„â–ˆâ–…â–„â–…â–„â–†â–…â–…â–†â–†â–‡â–…â–†â–â–„â–†â–ˆâ–†â–…â–ƒâ–†â–†
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–„â–‚â–„â–„â–â–…â–ˆâ–…â–„â–„â–„â–„â–„â–†â–ƒâ–…â–ƒâ–ƒâ–â–„â–…â–†â–ƒâ–…â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–â–…â–…â–ƒâ–…â–‚â–„
wandb:       eval/ensemble_f1 â–†â–ˆâ–†â–ˆâ–‚â–…â–…â–†â–ƒâ–†â–ˆâ–…â–ˆâ–‡â–„â–…â–†â–‡â–‡â–‚â–ˆâ–„â–‡â–‚â–…â–…â–…â–†â–‡â–†â–ƒâ–„â–†â–…â–†â–„â–…â–‚â–â–…
wandb:           train/avg_f1 â–ƒâ–‡â–†â–†â–‚â–‡â–„â–ƒâ–…â–ƒâ–…â–†â–†â–ƒâ–†â–†â–…â–…â–†â–ƒâ–ˆâ–„â–†â–ƒâ–„â–†â–„â–†â–â–ƒâ–â–‡â–†â–†â–„â–‡â–†â–†â–…â–‚
wandb:      train/ensemble_f1 â–‚â–ˆâ–…â–ƒâ–…â–‡â–…â–ƒâ–‚â–‚â–…â–…â–…â–†â–‡â–‡â–‡â–…â–†â–„â–†â–†â–…â–„â–‚â–‡â–‡â–…â–ƒâ–„â–â–ƒâ–‡â–ƒâ–†â–†â–„â–„â–ˆâ–‚
wandb:         train/mil_loss â–†â–‚â–‡â–ƒâ–…â–†â–…â–„â–„â–ˆâ–„â–‡â–ƒâ–ˆâ–„â–†â–…â–‡â–…â–„â–†â–„â–…â–‡â–†â–†â–…â–â–ˆâ–„â–„â–‡â–‡â–…â–†â–„â–ƒâ–ˆâ–„â–‚
wandb:      train/policy_loss â–…â–…â–…â–„â–‚â–…â–…â–…â–â–‚â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–ƒâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90236
wandb: best/eval_avg_mil_loss 0.24542
wandb:  best/eval_ensemble_f1 0.90236
wandb:            eval/avg_f1 0.77295
wandb:      eval/avg_mil_loss 0.98178
wandb:       eval/ensemble_f1 0.77295
wandb:           train/avg_f1 0.73565
wandb:      train/ensemble_f1 0.73565
wandb:         train/mil_loss 0.67432
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earnest-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5kr9lyzj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070852-5kr9lyzj/logs
wandb: ERROR Run 5kr9lyzj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: i6cqnzpj with config:
wandb: 	actor_learning_rate: 1.5764276575381284e-06
wandb: 	attention_dropout_p: 0.3621218311252414
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 61
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.97418447425363
wandb: 	temperature: 6.7157697355634705
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071122-i6cqnzpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6cqnzpj
wandb: uploading history steps 51-62, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‡â–‡â–…â–†â–†â–ˆâ–‡â–…â–†â–…â–…â–†â–„â–„â–…â–…â–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–‡â–ˆâ–…â–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–…â–ˆâ–‡â–ˆ
wandb:      eval/avg_mil_loss â–â–â–â–‚â–‚â–ƒâ–â–‚â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–†â–…â–â–ƒâ–ƒâ–â–â–ƒâ–…â–„â–ƒâ–ˆâ–„â–â–ƒâ–â–ƒâ–ƒâ–â–â–‚â–ƒâ–ƒâ–â–
wandb:       eval/ensemble_f1 â–‡â–…â–‡â–„â–†â–‡â–…â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–…â–…â–…â–ˆâ–‡â–‡â–ˆâ–‡â–…â–…â–…â–ˆâ–‡â–â–‡â–ˆâ–„â–†â–ˆâ–…â–ˆâ–†â–ˆâ–‡â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–â–…â–â–â–ˆâ–ˆâ–†â–ƒâ–„â–„â–…â–…â–„â–ƒâ–…â–…â–„â–…â–†â–‚â–„â–„â–‚â–†â–„â–ƒâ–ƒâ–„â–„â–…â–‡â–‡â–„â–‡â–…â–‡â–ƒâ–‚â–…
wandb:      train/ensemble_f1 â–„â–â–†â–†â–â–‚â–â–…â–ƒâ–ˆâ–„â–‡â–„â–…â–…â–…â–‚â–ƒâ–…â–…â–†â–ƒâ–„â–†â–‡â–‡â–†â–ƒâ–„â–†â–…â–‡â–ˆâ–„â–‡â–ƒâ–â–‚â–‡â–…
wandb:         train/mil_loss â–ƒâ–„â–‚â–…â–‚â–‡â–„â–…â–„â–ƒâ–ƒâ–ˆâ–„â–…â–‚â–„â–†â–…â–„â–…â–…â–…â–‡â–…â–ƒâ–„â–‚â–‚â–ˆâ–â–…â–‡â–†â–„â–†â–‚â–†â–‚â–ƒâ–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–„â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91796
wandb: best/eval_avg_mil_loss 0.28997
wandb:  best/eval_ensemble_f1 0.91796
wandb:            eval/avg_f1 0.8924
wandb:      eval/avg_mil_loss 0.28286
wandb:       eval/ensemble_f1 0.8924
wandb:            test/avg_f1 0.89926
wandb:      test/avg_mil_loss 0.24534
wandb:       test/ensemble_f1 0.89926
wandb:           train/avg_f1 0.8005
wandb:      train/ensemble_f1 0.8005
wandb:         train/mil_loss 0.99552
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6cqnzpj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071122-i6cqnzpj/logs
wandb: Agent Starting Run: k2j3ygar with config:
wandb: 	actor_learning_rate: 0.0002262959128035346
wandb: 	attention_dropout_p: 0.04711542416611392
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9855794899099266
wandb: 	temperature: 8.110339479086504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071223-k2j3ygar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k2j3ygar
wandb: uploading wandb-summary.json
wandb: uploading history steps 90-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–…â–‚â–ˆâ–â–‡â–†â–â–†â–â–ƒâ–†â–â–â–ˆâ–ƒâ–‚â–‡â–‚â–ˆâ–…â–‚â–ƒâ–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–ˆâ–ˆâ–†â–…
wandb:      eval/avg_mil_loss â–…â–„â–„â–„â–‡â–ˆâ–ˆâ–â–â–ˆâ–„â–â–†â–†â–ƒâ–„â–‡â–„â–…â–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–ˆâ–…â–†â–†â–â–‡â–‡â–â–„â–‚
wandb:       eval/ensemble_f1 â–ƒâ–‚â–‚â–…â–â–ˆâ–‚â–‡â–‡â–â–â–‡â–‡â–…â–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–â–„â–ˆâ–‚â–â–ƒâ–ƒâ–â–ˆâ–‚â–â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–„â–„â–â–…â–ˆâ–‡â–‡â–…â–…â–‚â–…â–†â–„â–…â–…â–…â–†â–†â–…â–…â–†â–…â–„â–„â–ƒâ–„â–…â–‡â–…â–†â–„â–…â–…â–ˆâ–…â–†â–„
wandb:      train/ensemble_f1 â–‚â–†â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–‚â–ˆâ–†â–†â–„â–…â–„â–„â–…â–†â–…â–â–†â–ˆâ–…â–‚â–„â–ƒâ–…â–„â–…â–ƒâ–„â–ƒâ–„â–…â–†â–„â–„â–‚â–‚â–„
wandb:         train/mil_loss â–‡â–„â–ƒâ–„â–„â–…â–„â–…â–†â–ƒâ–„â–…â–ƒâ–†â–†â–ˆâ–†â–ƒâ–‚â–„â–†â–…â–…â–‡â–„â–ƒâ–ƒâ–„â–†â–‡â–ƒâ–…â–â–ƒâ–‚â–„â–†â–ƒâ–â–„
wandb:      train/policy_loss â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ƒâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.26018
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.65581
wandb:      eval/avg_mil_loss 0.54336
wandb:       eval/ensemble_f1 0.65581
wandb:            test/avg_f1 0.35601
wandb:      test/avg_mil_loss 3.36408
wandb:       test/ensemble_f1 0.35601
wandb:           train/avg_f1 0.60233
wandb:      train/ensemble_f1 0.60233
wandb:         train/mil_loss 2.19036
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run divine-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k2j3ygar
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071223-k2j3ygar/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uhzdbayn with config:
wandb: 	actor_learning_rate: 6.577350141823249e-05
wandb: 	attention_dropout_p: 0.15530466862121284
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6482432289004448
wandb: 	temperature: 5.212188647411544
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071407-uhzdbayn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhzdbayn
wandb: uploading wandb-summary.json
wandb: uploading history steps 162-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‡â–†â–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–â–â–‚â–â–‡â–â–â–‡â–ƒâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‡â–‡â–ˆâ–‚â–â–‚â–ˆâ–ˆâ–…â–ƒâ–â–‚â–‚â–ˆâ–‡â–ˆâ–‚â–ˆâ–ƒâ–‚â–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–ƒâ–‡â–ƒâ–„â–…â–ƒâ–„â–…â–…â–„â–â–„â–„â–„â–â–†â–ˆâ–…â–†â–…â–„â–„â–†â–…â–„â–‚â–†â–„â–„â–„â–â–†â–ƒâ–‚â–„â–…â–„
wandb:       eval/ensemble_f1 â–„â–â–‚â–…â–ˆâ–â–‡â–…â–ƒâ–ˆâ–ˆâ–ˆâ–ƒâ–‚â–â–…â–ˆâ–ƒâ–ˆâ–‚â–â–‡â–‚â–‚â–ˆâ–ˆâ–â–ƒâ–‚â–‚â–‡â–ƒâ–â–‚â–‚â–ƒâ–ˆâ–‚â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–†â–…â–‚â–…â–‚â–„â–†â–ˆâ–„â–ƒâ–ƒâ–‚â–‡â–†â–‚â–†â–ˆâ–†â–…â–„â–ƒâ–…â–†â–…â–ƒâ–‚â–†â–‚â–„â–„â–ƒâ–„â–†â–„â–â–„â–†â–„â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–ƒâ–…â–…â–„â–ˆâ–„â–ƒâ–ƒâ–‚â–‡â–†â–ˆâ–„â–†â–ƒâ–‚â–ƒâ–ƒâ–â–„â–…â–…â–…â–‚â–ƒâ–‡â–‡â–†â–ƒâ–„â–†â–…â–…â–„â–‡â–†â–†â–…
wandb:         train/mil_loss â–ƒâ–†â–†â–ˆâ–†â–‡â–†â–‡â–†â–‡â–†â–„â–…â–â–â–†â–ˆâ–‡â–…â–†â–‡â–‡â–…â–†â–„â–…â–†â–ˆâ–†â–ƒâ–…â–‡â–†â–ƒâ–†â–„â–ƒâ–„â–ƒâ–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.26679
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.45671
wandb:      eval/avg_mil_loss 3.1219
wandb:       eval/ensemble_f1 0.45671
wandb:            test/avg_f1 0.53146
wandb:      test/avg_mil_loss 2.36894
wandb:       test/ensemble_f1 0.53146
wandb:           train/avg_f1 0.66606
wandb:      train/ensemble_f1 0.66606
wandb:         train/mil_loss 1.46854
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run easy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhzdbayn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071407-uhzdbayn/logs
wandb: Agent Starting Run: fo04m2kc with config:
wandb: 	actor_learning_rate: 2.4775241308708745e-05
wandb: 	attention_dropout_p: 0.07524304262002635
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6720414570524121
wandb: 	temperature: 0.6747334656287851
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071637-fo04m2kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo04m2kc
wandb: uploading history steps 73-81, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–ƒâ–ˆâ–â–‚â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–„â–ƒâ–„â–ˆâ–ˆâ–„â–…â–„â–„â–„â–†â–‡â–ˆâ–„â–„â–â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–„â–ˆâ–ˆâ–‡â–„â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–‡â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–…â–†â–â–‚â–ƒâ–ƒâ–‡â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–†â–†â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–â–ƒâ–†â–„â–„
wandb:       eval/ensemble_f1 â–„â–„â–„â–ƒâ–…â–ˆâ–†â–†â–„â–„â–†â–‡â–ˆâ–…â–‡â–ˆâ–„â–â–‡â–ˆâ–…â–„â–ˆâ–ˆâ–…â–…â–„â–ˆâ–„â–ˆâ–…â–„â–ˆâ–ˆâ–ˆâ–„â–…â–…â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‚â–…â–†â–†â–â–‡â–…â–‡â–ƒâ–†â–„â–ˆâ–…â–ˆâ–‡â–…â–†â–‡â–„â–‡â–ˆâ–ƒâ–‡â–…â–‡â–†â–„â–‡â–†â–…â–„â–…â–ƒâ–…â–ˆâ–„â–„â–‚
wandb:      train/ensemble_f1 â–‡â–‚â–„â–†â–„â–†â–â–…â–‡â–ƒâ–…â–ƒâ–…â–†â–…â–ˆâ–…â–ˆâ–ˆâ–„â–â–‡â–…â–†â–†â–ˆâ–…â–‡â–„â–„â–…â–‡â–„â–‡â–„â–„â–…â–ƒâ–†â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–„â–ˆâ–†â–…â–‡â–„â–…â–†â–ƒâ–†â–‡â–„â–„â–‡â–†â–„â–†â–†â–„â–†â–†â–…â–„â–…â–„â–ˆâ–†â–ƒâ–â–…â–…â–…â–†â–‡â–†â–…â–‡â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.32133
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.63149
wandb:      eval/avg_mil_loss 0.93254
wandb:       eval/ensemble_f1 0.63149
wandb:            test/avg_f1 0.59751
wandb:      test/avg_mil_loss 1.29009
wandb:       test/ensemble_f1 0.59751
wandb:           train/avg_f1 0.79804
wandb:      train/ensemble_f1 0.79804
wandb:         train/mil_loss 0.52545
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run magic-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fo04m2kc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071637-fo04m2kc/logs
wandb: Agent Starting Run: ogzo83q4 with config:
wandb: 	actor_learning_rate: 1.5602295019828245e-06
wandb: 	attention_dropout_p: 0.35596160155935896
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.296698971463483
wandb: 	temperature: 2.2215704243812153
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071749-ogzo83q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ogzo83q4
wandb: uploading wandb-summary.json
wandb: uploading history steps 109-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–â–‚â–ˆâ–ˆâ–…â–ƒâ–ˆâ–â–‚â–ˆâ–‚â–…â–†â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–‚â–â–â–â–ƒâ–ƒâ–…â–â–…â–„â–â–â–â–…â–ƒâ–â–…â–…â–â–„â–‚â–â–„â–‚â–…â–ˆâ–â–â–‚â–â–â–‚â–…â–‚â–â–‚â–â–ƒâ–
wandb:       eval/ensemble_f1 â–ˆâ–„â–…â–ˆâ–â–â–‡â–ˆâ–„â–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–„â–ˆâ–‡â–‡â–ˆâ–â–„â–„â–ˆâ–ˆâ–„â–ˆâ–‡â–â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–…â–…â–†â–…â–†â–ƒâ–†â–…â–…â–…â–‡â–†â–‚â–…â–â–ƒâ–…â–„â–…â–†â–„â–‡â–„â–†â–ˆâ–†â–…â–†â–†â–„â–†â–„â–…â–…â–…â–…â–†â–‡
wandb:      train/ensemble_f1 â–…â–…â–†â–‡â–„â–ˆâ–„â–‡â–…â–…â–†â–…â–‡â–ˆâ–â–‡â–‡â–„â–†â–…â–…â–‡â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–…â–‡â–‡â–†â–†â–‡â–‚â–‡â–ˆ
wandb:         train/mil_loss â–†â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–…â–„â–‡â–â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–„â–„â–…â–‚â–„â–‚â–‚â–†â–â–…â–ƒâ–†
wandb:      train/policy_loss â–ˆâ–„â–„â–„â–„â–„â–â–„â–â–„â–â–„â–ˆâ–„â–â–â–ˆâ–„â–ˆâ–â–â–ˆâ–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–â–„â–„â–„â–„â–â–„â–ˆâ–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–ˆâ–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–â–…â–ˆâ–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.2418
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.90646
wandb:      eval/avg_mil_loss 0.35533
wandb:       eval/ensemble_f1 0.90646
wandb:            test/avg_f1 0.93426
wandb:      test/avg_mil_loss 0.11714
wandb:       test/ensemble_f1 0.93426
wandb:           train/avg_f1 0.88535
wandb:      train/ensemble_f1 0.88535
wandb:         train/mil_loss 0.42961
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run denim-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ogzo83q4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071749-ogzo83q4/logs
wandb: Agent Starting Run: 97sad1pa with config:
wandb: 	actor_learning_rate: 8.532227200855418e-05
wandb: 	attention_dropout_p: 0.32416197408419145
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0572249662180665
wandb: 	temperature: 6.848685349830113
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071933-97sad1pa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/97sad1pa
wandb: uploading wandb-summary.json
wandb: uploading history steps 71-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–†â–ˆâ–„â–ˆâ–ˆâ–â–â–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–â–„â–…â–„â–„â–„â–…â–ˆâ–ƒâ–„â–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–‚â–‡â–ˆâ–„â–„â–ˆâ–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–â–†â–ˆâ–‚â–‚â–†â–„â–‚â–…â–„â–ƒâ–‚â–„â–‚â–‚â–â–‚â–„â–‚â–‚â–ƒâ–…â–‚â–…â–‚â–â–…â–â–â–‚â–ƒâ–â–
wandb:       eval/ensemble_f1 â–‚â–ˆâ–„â–ˆâ–†â–…â–ˆâ–„â–ˆâ–â–„â–ˆâ–â–ˆâ–„â–„â–‚â–â–„â–ƒâ–ˆâ–ˆâ–„â–ˆâ–„â–„â–„â–„â–â–„â–†â–ˆâ–‚â–‡â–ˆâ–„â–„â–ˆâ–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–â–‡â–†â–…â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–„â–„â–â–„â–„â–‚â–†â–†â–‡â–‚â–…â–ƒâ–„â–†â–„â–…â–†â–‡â–…â–…â–†â–„â–…â–†â–…â–ˆâ–…â–…â–„
wandb:      train/ensemble_f1 â–‚â–ƒâ–†â–‡â–…â–â–…â–„â–‡â–…â–ˆâ–†â–„â–„â–ƒâ–ƒâ–„â–…â–…â–†â–‡â–…â–‚â–†â–„â–ƒâ–…â–„â–…â–†â–…â–†â–‚â–„â–…â–…â–…â–…â–‡â–†
wandb:         train/mil_loss â–‚â–…â–…â–…â–â–‡â–„â–â–‡â–…â–…â–„â–„â–…â–„â–†â–‚â–ƒâ–„â–„â–†â–„â–ƒâ–…â–ƒâ–ˆâ–†â–„â–ƒâ–„â–†â–‡â–†â–‚â–‡â–‚â–„â–„â–†â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.34849
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.88259
wandb:      eval/avg_mil_loss 0.32397
wandb:       eval/ensemble_f1 0.88259
wandb:            test/avg_f1 0.41015
wandb:      test/avg_mil_loss 2.44692
wandb:       test/ensemble_f1 0.41015
wandb:           train/avg_f1 0.77393
wandb:      train/ensemble_f1 0.77393
wandb:         train/mil_loss 1.33514
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glad-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/97sad1pa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071933-97sad1pa/logs
wandb: Agent Starting Run: gw7wo163 with config:
wandb: 	actor_learning_rate: 0.000211464539641324
wandb: 	attention_dropout_p: 0.2574749847100511
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5674524881148417
wandb: 	temperature: 6.137452965822183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072051-gw7wo163
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gw7wo163
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 91-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–ˆâ–‚â–ƒâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒâ–…â–„â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–‚â–‡â–‚â–ˆâ–…â–‚â–‚â–‚â–‚â–‡â–‚â–ƒâ–‚â–‚â–ˆâ–‚â–‚â–‚â–‚
wandb:      eval/avg_mil_loss â–„â–‡â–…â–†â–‚â–‚â–…â–ƒâ–„â–†â–‡â–…â–â–ˆâ–„â–…â–†â–…â–„â–„â–‡â–ˆâ–…â–†â–„â–…â–†â–â–ˆâ–„â–‚â–„â–†â–…â–ˆâ–…â–ˆâ–‡â–†â–…
wandb:       eval/ensemble_f1 â–‚â–ˆâ–ƒâ–‚â–â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–â–ˆâ–ˆâ–‚â–†â–‚â–ƒâ–â–‚â–„â–ˆâ–‚â–‡â–ˆâ–‚â–…â–â–‚â–â–‚â–â–ƒâ–ƒâ–â–â–ˆâ–‚â–‚â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–ƒâ–…â–„â–†â–…â–„â–†â–„â–‚â–„â–„â–†â–‚â–‚â–†â–ƒâ–‡â–…â–„â–…â–…â–„â–†â–†â–ˆâ–†â–…â–„â–„â–„â–ƒâ–†â–†â–ƒâ–…â–â–†â–…â–„
wandb:      train/ensemble_f1 â–‚â–…â–…â–…â–‡â–…â–ƒâ–ƒâ–‚â–ˆâ–‚â–ƒâ–â–„â–…â–â–„â–‡â–„â–…â–‚â–†â–„â–ƒâ–„â–„â–…â–†â–†â–…â–†â–…â–„â–„â–†â–ƒâ–ƒâ–…â–‡â–‡
wandb:         train/mil_loss â–‚â–„â–„â–ƒâ–ƒâ–…â–…â–‚â–†â–…â–‡â–…â–ƒâ–‚â–„â–â–…â–‚â–‚â–†â–‚â–…â–…â–„â–‡â–†â–†â–ˆâ–â–‚â–…â–†â–…â–‚â–ƒâ–ˆâ–â–†â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.26346
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.36577
wandb:      eval/avg_mil_loss 2.49869
wandb:       eval/ensemble_f1 0.36577
wandb:            test/avg_f1 0.90521
wandb:      test/avg_mil_loss 0.57348
wandb:       test/ensemble_f1 0.90521
wandb:           train/avg_f1 0.5408
wandb:      train/ensemble_f1 0.5408
wandb:         train/mil_loss 2.0821
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dainty-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gw7wo163
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072051-gw7wo163/logs
wandb: Agent Starting Run: 1rxai4yi with config:
wandb: 	actor_learning_rate: 1.6443651450617705e-05
wandb: 	attention_dropout_p: 0.3169601050371865
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 83
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8678427988609606
wandb: 	temperature: 3.574858875515984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072223-1rxai4yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rxai4yi
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 71-84, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–â–„â–‚â–‚â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–â–‡â–‚â–ˆâ–â–ˆâ–ƒâ–„â–ˆâ–‡â–ˆâ–„â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–†â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–„â–ˆâ–…â–„â–†â–…â–…â–…â–â–„â–ƒâ–…â–‡â–…â–…â–ˆâ–†â–‚â–ƒâ–…â–„â–†â–ƒâ–‡â–†â–â–ƒâ–ˆâ–„â–ƒâ–†â–…â–â–â–ƒâ–…â–â–‡â–‚
wandb:       eval/ensemble_f1 â–‡â–‚â–â–â–â–ƒâ–ˆâ–ˆâ–ƒâ–‚â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–ˆâ–‚â–ƒâ–‚â–‡â–‡â–‚â–â–ˆâ–â–‚â–ƒâ–‡â–‡â–„â–„â–ˆâ–‡â–ˆâ–„â–†â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‚â–ƒâ–„â–„â–†â–‚â–…â–„â–…â–†â–‚â–â–ˆâ–„â–‡â–ƒâ–†â–ƒâ–‡â–…â–„â–…â–„â–†â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–‚â–†â–‚
wandb:      train/ensemble_f1 â–‚â–„â–‚â–ƒâ–„â–†â–…â–…â–ƒâ–†â–â–ˆâ–„â–†â–â–†â–ƒâ–„â–†â–†â–…â–„â–‡â–…â–†â–â–ƒâ–„â–ƒâ–…â–†â–„â–‚â–„â–‡â–„â–‚â–ƒâ–‡â–…
wandb:         train/mil_loss â–…â–‡â–‚â–…â–„â–‡â–ƒâ–†â–â–†â–ˆâ–„â–…â–„â–ƒâ–‡â–…â–†â–…â–â–…â–„â–ˆâ–…â–ƒâ–…â–…â–‡â–…â–†â–…â–ƒâ–ƒâ–‡â–â–ƒâ–†â–…â–â–„
wandb:      train/policy_loss â–†â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.27188
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.65381
wandb:      eval/avg_mil_loss 0.74989
wandb:       eval/ensemble_f1 0.65381
wandb:            test/avg_f1 0.34336
wandb:      test/avg_mil_loss 2.69737
wandb:       test/ensemble_f1 0.34336
wandb:           train/avg_f1 0.53694
wandb:      train/ensemble_f1 0.53694
wandb:         train/mil_loss 1.77461
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run valiant-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1rxai4yi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072223-1rxai4yi/logs
wandb: Agent Starting Run: n0sit1yj with config:
wandb: 	actor_learning_rate: 8.600832816545013e-06
wandb: 	attention_dropout_p: 0.19468771472574825
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1267083723483724
wandb: 	temperature: 8.172058414928815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072403-n0sit1yj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n0sit1yj
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–ˆâ–…â–‡â–ˆâ–…â–ˆâ–…â–†â–‚â–ˆâ–…â–ˆâ–…â–„â–…â–†â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–‡â–‡â–†â–‡â–‡â–‚â–ƒâ–…â–†â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–ˆ
wandb:      eval/avg_mil_loss â–…â–…â–‚â–â–†â–…â–ƒâ–‚â–â–„â–„â–ˆâ–„â–…â–ƒâ–„â–„â–‚â–…â–„â–„â–â–â–ƒâ–â–â–„â–‚â–†â–ƒâ–ˆâ–‡â–…â–‡â–â–â–…â–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–†â–ˆâ–‡â–ƒâ–…â–‡â–ˆâ–ˆâ–…â–†â–ˆâ–ˆâ–…â–â–…â–ˆâ–…â–…â–„â–‡â–…â–ˆâ–ˆâ–†â–†â–…â–‡â–‡â–‡â–…â–ƒâ–…â–‡â–ˆâ–ˆâ–…â–†â–…â–â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‡â–ƒâ–ƒâ–ƒâ–‡â–‚â–…â–„â–†â–…â–ˆâ–†â–…â–‚â–†â–‡â–‡â–‡â–ƒâ–…â–†â–ƒâ–„â–â–„â–ˆâ–†â–‡â–ˆâ–…â–…â–†â–†â–‡â–ƒâ–…â–ˆâ–ˆâ–ƒ
wandb:      train/ensemble_f1 â–â–„â–ˆâ–ƒâ–‚â–„â–„â–‡â–„â–‡â–ƒâ–‡â–„â–‡â–„â–‡â–†â–†â–…â–ƒâ–†â–ˆâ–‡â–ƒâ–„â–…â–â–…â–…â–†â–‡â–ƒâ–‚â–‡â–„â–ƒâ–…â–ˆâ–ˆâ–ƒ
wandb:         train/mil_loss â–„â–„â–ƒâ–†â–…â–ƒâ–ƒâ–†â–„â–„â–„â–ˆâ–ƒâ–ƒâ–‡â–„â–…â–…â–„â–…â–‚â–…â–ƒâ–ƒâ–…â–„â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–…â–†â–ƒâ–…
wandb:      train/policy_loss â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.23556
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.89327
wandb:      eval/avg_mil_loss 0.75288
wandb:       eval/ensemble_f1 0.89327
wandb:            test/avg_f1 0.50182
wandb:      test/avg_mil_loss 2.04011
wandb:       test/ensemble_f1 0.50182
wandb:           train/avg_f1 0.75165
wandb:      train/ensemble_f1 0.75165
wandb:         train/mil_loss 1.02261
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run astral-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n0sit1yj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072403-n0sit1yj/logs
wandb: Agent Starting Run: yjvl8tup with config:
wandb: 	actor_learning_rate: 1.3435393295793707e-06
wandb: 	attention_dropout_p: 0.3922582527151732
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7776717738223946
wandb: 	temperature: 5.816361095433233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072546-yjvl8tup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjvl8tup
wandb: uploading history steps 118-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–…â–ˆâ–ˆâ–‚â–†â–ˆâ–…â–„â–ˆâ–‡â–ƒâ–…â–â–‡â–‡â–…â–…â–†â–…â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–„â–‡â–…â–…â–ˆâ–ˆâ–„â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–ˆâ–â–‚â–â–â–â–â–„â–â–â–â–â–„â–‡â–â–â–â–â–„â–â–ƒâ–â–â–†â–‚â–â–â–„â–â–‚â–â–â–â–â–†â–â–â–â–…â–†
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–†â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ƒâ–ƒâ–ˆâ–‡â–‡â–ˆâ–ˆâ–â–ˆâ–‡â–‡â–ˆâ–ƒâ–‡â–‡â–‚â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–„â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–…â–‡â–‡â–†â–„â–†â–ƒâ–‡â–„â–„â–ˆâ–‡â–†â–…â–‡â–…â–…â–†â–ˆâ–‚â–†â–ˆâ–‡â–â–†â–ˆâ–‡â–‡â–†â–†â–†â–†â–‡â–†â–†â–ƒâ–‡â–‚
wandb:      train/ensemble_f1 â–†â–ƒâ–‡â–†â–†â–‡â–ƒâ–ƒâ–†â–…â–„â–†â–†â–‚â–â–ƒâ–†â–†â–…â–†â–…â–†â–‡â–†â–‡â–…â–…â–…â–†â–†â–„â–„â–…â–„â–…â–„â–…â–ˆâ–…â–ƒ
wandb:         train/mil_loss â–…â–„â–‚â–†â–‚â–…â–ƒâ–‚â–…â–ˆâ–…â–‚â–‚â–„â–„â–„â–‚â–„â–‚â–„â–„â–‚â–ƒâ–„â–„â–â–‡â–‚â–„â–‚â–„â–…â–‚â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.29076
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.91845
wandb:      eval/avg_mil_loss 0.29654
wandb:       eval/ensemble_f1 0.91845
wandb:            test/avg_f1 0.93076
wandb:      test/avg_mil_loss 0.13666
wandb:       test/ensemble_f1 0.93076
wandb:           train/avg_f1 0.84526
wandb:      train/ensemble_f1 0.84526
wandb:         train/mil_loss 0.43754
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run solar-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjvl8tup
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072546-yjvl8tup/logs
wandb: Agent Starting Run: qhw2q1bu with config:
wandb: 	actor_learning_rate: 2.2253708535904764e-06
wandb: 	attention_dropout_p: 0.4375437877819952
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8184584009944175
wandb: 	temperature: 7.297857627783877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072745-qhw2q1bu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qhw2q1bu
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–‡â–ˆâ–…â–„â–ˆâ–ˆâ–„â–ˆâ–‡â–…â–‡â–ˆâ–â–‡â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–ƒâ–‚â–„â–„â–â–â–â–‚â–â–„â–‚â–â–ƒâ–ˆâ–â–ƒâ–â–ˆâ–â–‚â–„â–â–â–â–â–ƒâ–â–†â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–ƒâ–â–‡â–â–
wandb:       eval/ensemble_f1 â–ˆâ–„â–…â–ˆâ–†â–ˆâ–ˆâ–ˆâ–„â–…â–‡â–ˆâ–ˆâ–…â–â–ˆâ–…â–ˆâ–…â–„â–‡â–ƒâ–ˆâ–ˆâ–„â–…â–†â–†â–†â–†â–…â–ˆâ–‡â–…â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‚â–‡â–…â–‡â–†â–…â–„â–…â–…â–…â–†â–†â–‡â–†â–ˆâ–…â–…â–†â–…â–…â–‚â–†â–‚â–ƒâ–†â–…â–„â–†â–…â–…â–…â–…â–â–‡â–ƒâ–†â–†â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–ƒâ–„â–ƒâ–‡â–ƒâ–â–…â–…â–‡â–†â–…â–ƒâ–…â–â–…â–…â–„â–‡â–†â–ˆâ–‡â–…â–†â–„â–…â–…â–„â–…â–ƒâ–‚â–…â–…â–„â–…â–ƒâ–…â–â–ƒ
wandb:         train/mil_loss â–â–â–‚â–‚â–‚â–…â–…â–…â–…â–„â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–†â–„â–…â–„â–‚â–‚â–ƒâ–â–‚â–ˆâ–ƒâ–‚â–ƒâ–â–ƒâ–„â–‚â–‚â–…â–„â–â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–…â–…â–ˆâ–â–…â–â–â–…â–ˆâ–â–…â–â–â–â–â–…â–…â–…â–…â–â–…â–ˆâ–â–…â–…â–…â–â–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.28647
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.92558
wandb:      eval/avg_mil_loss 0.30755
wandb:       eval/ensemble_f1 0.92558
wandb:            test/avg_f1 0.89399
wandb:      test/avg_mil_loss 0.18293
wandb:       test/ensemble_f1 0.89399
wandb:           train/avg_f1 0.85007
wandb:      train/ensemble_f1 0.85007
wandb:         train/mil_loss 0.50187
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run upbeat-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qhw2q1bu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072745-qhw2q1bu/logs
wandb: Agent Starting Run: j6a7qb47 with config:
wandb: 	actor_learning_rate: 1.4726792602994571e-06
wandb: 	attention_dropout_p: 0.373778899355803
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7786217304438653
wandb: 	temperature: 7.404587257364543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072924-j6a7qb47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6a7qb47
wandb: uploading history steps 118-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–ˆâ–…â–‡â–‚â–‡â–„â–„â–…â–‚â–…â–‡â–ƒâ–‡â–‚â–‚â–ˆâ–†â–â–…â–…â–…â–…â–…â–†â–†â–ƒâ–…â–…â–ˆâ–†â–ˆâ–ˆâ–…â–ˆâ–ˆâ–‚â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–ƒâ–…â–â–„â–„â–„â–„â–„â–ƒâ–ˆâ–ƒâ–‡â–„â–„â–‚â–ˆâ–ˆâ–„â–„â–ƒâ–‚â–â–…â–ƒâ–‚â–„â–„â–„â–ƒâ–â–„â–â–ƒâ–â–„â–„â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–…â–…â–‡â–…â–‚â–‚â–…â–…â–…â–‡â–…â–â–…â–…â–„â–â–…â–…â–…â–…â–ˆâ–…â–ˆâ–‚â–‚â–‚â–…â–ƒâ–ˆâ–ˆâ–…â–ˆâ–ƒâ–‚â–ˆâ–‚â–…â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‡â–„â–…â–‚â–…â–â–‚â–ƒâ–…â–„â–‡â–…â–ˆâ–†â–†â–‡â–â–…â–ˆâ–„â–…â–„â–…â–â–„â–†â–…â–ƒâ–„â–†â–†â–…â–„â–â–…â–†â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–‡â–â–…â–…â–„â–ƒâ–†â–‚â–…â–…â–‡â–…â–†â–ƒâ–‚â–‡â–ˆâ–„â–„â–†â–†â–‡â–‚â–ƒâ–‡â–…â–†â–‡â–„â–†â–„â–ˆâ–‚â–…â–…â–‡â–ˆâ–ƒâ–†
wandb:         train/mil_loss â–…â–„â–…â–‡â–ƒâ–‡â–ˆâ–„â–†â–ƒâ–„â–„â–…â–†â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–„â–…â–â–â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–„â–‚â–â–ƒâ–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.31979
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.68436
wandb:      eval/avg_mil_loss 0.67734
wandb:       eval/ensemble_f1 0.68436
wandb:            test/avg_f1 0.70764
wandb:      test/avg_mil_loss 0.8261
wandb:       test/ensemble_f1 0.70764
wandb:           train/avg_f1 0.69704
wandb:      train/ensemble_f1 0.69704
wandb:         train/mil_loss 0.55024
wandb:      train/policy_loss -0.13404
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.13404
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6a7qb47
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072924-j6a7qb47/logs
wandb: Agent Starting Run: smf6ej9j with config:
wandb: 	actor_learning_rate: 2.535038403019846e-06
wandb: 	attention_dropout_p: 0.39304168226700614
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9133098760114062
wandb: 	temperature: 9.422765711193712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073118-smf6ej9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smf6ej9j
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–ƒâ–…â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–†â–‚â–†â–…â–â–‡â–†â–…â–†â–†â–‡â–ˆâ–ˆâ–ƒâ–‡â–ƒâ–ˆâ–†â–…â–…â–†â–‡â–ˆâ–ˆâ–…â–„â–‡â–…â–ƒâ–†â–‡â–…â–†â–…â–‡â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–†â–†â–…â–ƒâ–„â–„â–„â–ˆâ–ƒâ–„â–…â–ƒâ–…â–…â–„â–†â–ˆâ–†â–ƒâ–ƒâ–â–â–â–…â–„â–„â–â–†â–„â–…â–…â–„â–ƒâ–‚â–ƒâ–„â–â–‚â–„â–‚
wandb:       eval/ensemble_f1 â–†â–ˆâ–†â–…â–†â–…â–†â–„â–‚â–…â–ˆâ–ˆâ–†â–…â–‚â–â–ˆâ–†â–†â–†â–…â–ˆâ–ˆâ–ˆâ–†â–†â–†â–ˆâ–ˆâ–„â–…â–ƒâ–†â–†â–ƒâ–‚â–ƒâ–†â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ˆâ–‚â–…â–‡â–‚â–â–â–…â–„â–ƒâ–†â–‡â–‚â–…â–ƒâ–ƒâ–‡â–„â–„â–†â–„â–„â–ˆâ–„â–†â–„â–„â–…â–‡â–†â–ƒâ–…â–…â–†â–‡â–‡â–„â–…â–ƒ
wandb:      train/ensemble_f1 â–„â–„â–„â–…â–…â–†â–‡â–…â–ƒâ–„â–„â–ƒâ–„â–â–‡â–„â–„â–ƒâ–…â–‡â–â–„â–†â–„â–‡â–…â–ˆâ–‚â–‡â–…â–…â–…â–…â–„â–…â–…â–†â–…â–†â–„
wandb:         train/mil_loss â–…â–…â–ˆâ–†â–ƒâ–…â–„â–ƒâ–‚â–â–„â–…â–…â–ƒâ–„â–…â–‚â–„â–„â–‚â–„â–…â–ƒâ–†â–ƒâ–‡â–…â–‚â–…â–‚â–‚â–„â–ƒâ–„â–ƒâ–…â–ˆâ–ƒâ–‚â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90646
wandb: best/eval_avg_mil_loss 0.30819
wandb:  best/eval_ensemble_f1 0.90646
wandb:            eval/avg_f1 0.878
wandb:      eval/avg_mil_loss 0.77477
wandb:       eval/ensemble_f1 0.878
wandb:            test/avg_f1 0.44941
wandb:      test/avg_mil_loss 1.25854
wandb:       test/ensemble_f1 0.44941
wandb:           train/avg_f1 0.67203
wandb:      train/ensemble_f1 0.67203
wandb:         train/mil_loss 1.22158
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run efficient-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smf6ej9j
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073118-smf6ej9j/logs
wandb: Agent Starting Run: 2o0qo6hl with config:
wandb: 	actor_learning_rate: 1.973205299751745e-06
wandb: 	attention_dropout_p: 0.3939713103718733
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.842208373892611
wandb: 	temperature: 6.248123183006085
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073327-2o0qo6hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/lycs9zpn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2o0qo6hl
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–â–†â–†â–‚â–„â–†â–†â–‡â–†â–…â–ˆâ–„â–ƒâ–…â–…â–ƒâ–ƒâ–…â–„â–ƒâ–†â–…â–…â–„â–„â–…â–†â–†â–…â–‡â–„â–…â–†â–†â–†â–†â–…â–„
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–…â–ƒâ–„â–„â–…â–‚â–ƒâ–…â–…â–ˆâ–‚â–…â–‡â–ƒâ–ƒâ–†â–„â–ˆâ–…â–ƒâ–…â–…â–†â–†â–„â–†â–ƒâ–‡â–„â–…â–â–‡â–ƒâ–…â–…â–ƒâ–‡
wandb:       eval/ensemble_f1 â–†â–…â–‚â–†â–„â–‚â–„â–„â–†â–…â–‡â–‡â–ƒâ–ƒâ–ˆâ–„â–„â–ƒâ–‡â–ƒâ–…â–…â–†â–…â–„â–‚â–‚â–‚â–†â–ƒâ–…â–‡â–…â–†â–„â–„â–…â–†â–„â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–†â–ƒâ–â–…â–‚â–†â–…â–â–„â–†â–‚â–…â–„â–â–ƒâ–…â–ˆâ–†â–„â–‡â–‡â–†â–‡â–†â–„â–‡â–…â–†â–†â–†â–†â–…â–ƒâ–†â–…â–…â–‡â–‡
wandb:      train/ensemble_f1 â–„â–‚â–…â–†â–†â–â–„â–…â–…â–†â–†â–…â–†â–ƒâ–…â–ƒâ–ˆâ–â–…â–…â–†â–†â–„â–†â–†â–ƒâ–„â–…â–†â–†â–…â–…â–†â–…â–…â–†â–…â–†â–‡â–†
wandb:         train/mil_loss â–‡â–ˆâ–‡â–„â–‡â–…â–…â–ƒâ–…â–…â–„â–‡â–„â–†â–„â–†â–ƒâ–„â–ˆâ–„â–ˆâ–‡â–…â–„â–‡â–…â–â–‚â–‡â–„â–…â–ƒâ–…â–‚â–…â–‚â–„â–„â–‚â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88591
wandb: best/eval_avg_mil_loss 0.92127
wandb:  best/eval_ensemble_f1 0.88591
wandb:            eval/avg_f1 0.57301
wandb:      eval/avg_mil_loss 2.24786
wandb:       eval/ensemble_f1 0.57301
wandb:            test/avg_f1 0.67246
wandb:      test/avg_mil_loss 1.3512
wandb:       test/ensemble_f1 0.67246
wandb:           train/avg_f1 0.71659
wandb:      train/ensemble_f1 0.71659
wandb:         train/mil_loss 1.21405
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run classic-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2o0qo6hl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073327-2o0qo6hl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 0ynzdfd2 with config:
wandb: 	actor_learning_rate: 0.0006557550527354232
wandb: 	attention_dropout_p: 0.2295487274958678
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8948874478650376
wandb: 	temperature: 9.250950200610715
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073642-0ynzdfd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ynzdfd2
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 82-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡
wandb:      eval/avg_mil_loss â–ˆâ–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–†â–â–â–â–â–â–â–â–â–ˆâ–ƒâ–â–â–â–
wandb:       eval/ensemble_f1 â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–†â–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‚â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–â–‡â–ˆâ–‡â–„â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–‚â–†â–‡â–„â–ƒâ–„â–†â–†â–…â–…â–…â–†â–†â–‡â–‡â–…â–„â–…â–†â–ˆâ–…â–ƒâ–†â–†â–‡â–†â–†â–†â–†â–ƒâ–…â–ƒâ–ˆâ–…â–…â–†â–‚â–„
wandb:      train/ensemble_f1 â–ƒâ–‡â–…â–‚â–…â–‚â–…â–…â–ƒâ–„â–ƒâ–‚â–†â–„â–…â–‡â–â–„â–ˆâ–†â–…â–…â–†â–†â–‡â–†â–„â–‚â–…â–†â–†â–†â–†â–ƒâ–…â–…â–ƒâ–ˆâ–…â–…
wandb:         train/mil_loss â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–â–‚â–‚â–â–‚â–â–„â–ƒâ–ƒâ–‚â–â–‚â–â–…â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–â–‚â–â–â–„â–ˆâ–‚â–ƒâ–†â–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–â–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–â–ˆâ–â–ˆâ–„â–ˆâ–â–â–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93715
wandb: best/eval_avg_mil_loss 0.23616
wandb:  best/eval_ensemble_f1 0.93715
wandb:            eval/avg_f1 0.90438
wandb:      eval/avg_mil_loss 0.20299
wandb:       eval/ensemble_f1 0.90438
wandb:            test/avg_f1 0.91963
wandb:      test/avg_mil_loss 0.18576
wandb:       test/ensemble_f1 0.91963
wandb:           train/avg_f1 0.89942
wandb:      train/ensemble_f1 0.89942
wandb:         train/mil_loss 0.52825
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run expert-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ynzdfd2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073642-0ynzdfd2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s8s25vl1 with config:
wandb: 	actor_learning_rate: 0.0004399644090579088
wandb: 	attention_dropout_p: 0.3644597458662244
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.988522059208011
wandb: 	temperature: 7.432094391873986
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073825-s8s25vl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s8s25vl1
wandb: uploading history steps 74-76, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–†â–…â–„â–„â–„â–…â–„â–„â–„â–†â–â–…â–â–â–†â–†â–†â–†â–„â–…â–„â–‡â–…â–ƒâ–†â–„â–‡â–‡â–†â–†â–ˆâ–ˆâ–ƒâ–ˆâ–‡â–…â–‡
wandb:      eval/avg_mil_loss â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–ƒâ–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–ˆâ–‚
wandb:       eval/ensemble_f1 â–†â–†â–†â–‡â–ˆâ–†â–â–†â–†â–†â–†â–†â–‡â–„â–†â–„â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–†â–†â–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–…â–„â–„â–„â–…â–‡â–…â–ˆâ–†â–„â–„â–…â–†â–†â–…â–ˆâ–ˆâ–‡â–…â–„â–…â–‡â–†â–†â–‡â–…â–…â–‡â–‡â–…â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–…â–‡â–„
wandb:      train/ensemble_f1 â–†â–â–„â–„â–„â–‡â–…â–ƒâ–„â–†â–†â–…â–ˆâ–†â–…â–†â–…â–‡â–‡â–…â–…â–†â–†â–†â–†â–‡â–ƒâ–„â–‡â–…â–…â–ˆâ–ˆâ–…â–‡â–‡â–‡â–…â–‡â–†
wandb:         train/mil_loss â–ƒâ–ƒâ–‡â–‚â–ƒâ–ƒâ–„â–†â–ˆâ–„â–‚â–„â–†â–ƒâ–‚â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–„â–…â–‚â–‚â–„â–‚â–‡â–„â–â–ˆâ–â–„â–‚â–‚â–‚â–ƒâ–ˆ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–ˆâ–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93693
wandb: best/eval_avg_mil_loss 0.21467
wandb:  best/eval_ensemble_f1 0.93693
wandb:            eval/avg_f1 0.90773
wandb:      eval/avg_mil_loss 0.2635
wandb:       eval/ensemble_f1 0.90773
wandb:            test/avg_f1 0.91373
wandb:      test/avg_mil_loss 0.20554
wandb:       test/ensemble_f1 0.91373
wandb:           train/avg_f1 0.89855
wandb:      train/ensemble_f1 0.89855
wandb:         train/mil_loss 0.24332
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run likely-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s8s25vl1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073825-s8s25vl1/logs
wandb: Agent Starting Run: ai0covd1 with config:
wandb: 	actor_learning_rate: 3.827246143155911e-06
wandb: 	attention_dropout_p: 0.03177852752302085
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2688001079046559
wandb: 	temperature: 5.074735626393951
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073932-ai0covd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai0covd1
wandb: uploading wandb-summary.json
wandb: uploading history steps 82-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–…â–ˆâ–‚â–„â–„â–†â–ˆâ–ƒâ–ˆâ–…â–ƒâ–ƒâ–…â–„â–‚â–â–ƒâ–…â–â–†â–„â–ˆâ–†â–ˆâ–„â–„â–…â–†â–†â–†â–â–ˆâ–‚â–„â–‡â–‡â–…â–ƒ
wandb:      eval/avg_mil_loss â–â–ƒâ–†â–ƒâ–„â–‡â–„â–ƒâ–‚â–â–†â–â–†â–â–†â–ƒâ–„â–„â–…â–…â–„â–‚â–„â–ˆâ–…â–„â–ƒâ–â–…â–…â–…â–„â–â–†â–„â–‚â–ˆâ–„â–â–†
wandb:       eval/ensemble_f1 â–‡â–…â–…â–ƒâ–…â–‚â–†â–‚â–‚â–‚â–ˆâ–ƒâ–‚â–…â–…â–ƒâ–…â–â–‡â–ˆâ–…â–â–„â–„â–†â–ˆâ–ˆâ–„â–ƒâ–†â–ƒâ–ˆâ–†â–…â–„â–„â–ƒâ–‡â–ˆâ–‡
wandb:           train/avg_f1 â–…â–†â–„â–„â–„â–…â–ˆâ–„â–…â–ˆâ–…â–†â–â–ƒâ–„â–†â–‚â–‚â–…â–…â–‚â–†â–…â–†â–…â–ƒâ–„â–„â–„â–…â–…â–„â–ƒâ–…â–…â–„â–„â–ƒâ–†â–„
wandb:      train/ensemble_f1 â–…â–†â–ƒâ–‚â–†â–„â–…â–„â–ˆâ–…â–ƒâ–…â–†â–â–ƒâ–ƒâ–†â–‚â–…â–…â–‚â–†â–†â–‡â–ƒâ–„â–…â–…â–„â–ƒâ–ƒâ–…â–„â–‡â–†â–„â–…â–†â–„â–‡
wandb:         train/mil_loss â–†â–†â–…â–ˆâ–‚â–„â–…â–†â–…â–ƒâ–†â–„â–ƒâ–‚â–â–ƒâ–‡â–ˆâ–‡â–…â–†â–‚â–…â–ƒâ–†â–†â–‚â–ˆâ–„â–†â–„â–‚â–…â–‚â–„â–ƒâ–„â–‡â–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91796
wandb: best/eval_avg_mil_loss 0.24082
wandb:  best/eval_ensemble_f1 0.91796
wandb:            eval/avg_f1 0.69205
wandb:      eval/avg_mil_loss 2.83476
wandb:       eval/ensemble_f1 0.69205
wandb:           train/avg_f1 0.7803
wandb:      train/ensemble_f1 0.7803
wandb:         train/mil_loss 1.56823
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smart-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai0covd1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073932-ai0covd1/logs
wandb: ERROR Run ai0covd1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: frnnpwju with config:
wandb: 	actor_learning_rate: 0.0006675821315533491
wandb: 	attention_dropout_p: 0.3984092114255729
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6525650067395523
wandb: 	temperature: 8.486968904123222
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074046-frnnpwju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frnnpwju
wandb: uploading history steps 101-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–â–ƒâ–…â–„â–‡â–ƒâ–ƒâ–ˆâ–…â–„â–…â–…â–‡â–â–„â–ƒâ–ƒâ–„â–‚â–†â–…â–…â–†â–…â–ˆâ–„â–ˆâ–…â–„â–‡â–†â–‡â–‚â–‡â–†â–†â–…â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–†â–…â–ˆâ–â–‚â–‚â–„â–„â–…â–„â–â–…â–ƒâ–ƒâ–‚â–„â–‡â–…â–ƒâ–†â–ƒâ–…â–‚â–‚â–‚â–‡â–â–„â–„â–†â–ƒâ–ƒâ–‚â–â–„â–…â–‚â–„
wandb:       eval/ensemble_f1 â–†â–†â–‚â–…â–â–‡â–ˆâ–†â–‡â–‚â–ƒâ–„â–‚â–†â–â–„â–†â–†â–…â–ƒâ–‚â–ƒâ–‡â–…â–†â–†â–‚â–‡â–ˆâ–…â–†â–‚â–„â–…â–‡â–„â–…â–†â–ƒâ–†
wandb:           train/avg_f1 â–…â–†â–†â–†â–‡â–ƒâ–‚â–†â–â–‚â–ƒâ–ƒâ–…â–ƒâ–†â–†â–ƒâ–‡â–ˆâ–…â–ƒâ–‡â–ˆâ–‚â–„â–…â–ƒâ–„â–ˆâ–ˆâ–†â–†â–†â–…â–„â–‡â–…â–ƒâ–…â–†
wandb:      train/ensemble_f1 â–…â–…â–…â–…â–…â–„â–†â–†â–â–†â–†â–…â–…â–„â–ƒâ–ƒâ–ƒâ–†â–„â–†â–ˆâ–ƒâ–‚â–†â–†â–â–„â–…â–†â–ˆâ–„â–ƒâ–‡â–…â–…â–ƒâ–…â–…â–‡â–„
wandb:         train/mil_loss â–â–‡â–‡â–…â–„â–‡â–ƒâ–†â–ƒâ–…â–‚â–„â–ƒâ–„â–†â–†â–‚â–„â–„â–‡â–ƒâ–ˆâ–…â–ƒâ–…â–„â–„â–…â–†â–…â–…â–…â–‚â–ƒâ–…â–ƒâ–†â–‡â–ƒâ–†
wandb:      train/policy_loss â–„â–ˆâ–ˆâ–„â–ˆâ–â–ˆâ–ˆâ–ˆâ–„â–â–ˆâ–„â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–„â–â–â–â–„â–â–ˆâ–ˆâ–â–„â–„â–„â–„â–â–ˆâ–ˆâ–â–â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.21805
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.85682
wandb:      eval/avg_mil_loss 1.41483
wandb:       eval/ensemble_f1 0.85682
wandb:           train/avg_f1 0.81251
wandb:      train/ensemble_f1 0.81251
wandb:         train/mil_loss 1.37585
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frnnpwju
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074046-frnnpwju/logs
wandb: ERROR Run frnnpwju errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: gqzlp813 with config:
wandb: 	actor_learning_rate: 0.0002331540600936535
wandb: 	attention_dropout_p: 0.31306827199536413
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8627850731472052
wandb: 	temperature: 6.684713651025216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074249-gqzlp813
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqzlp813
wandb: uploading history steps 99-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–†
wandb:  best/eval_ensemble_f1 â–â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–‡â–â–†â–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ƒâ–‡â–„â–‡â–ˆâ–ˆâ–„â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–ˆâ–â–â–â–â–â–…â–â–‡â–â–â–†â–â–â–â–‚â–ƒâ–â–â–â–â–â–ƒâ–ƒâ–â–â–â–â–ƒâ–ƒâ–…â–‚â–‚â–â–â–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–‡â–‚â–ˆâ–‚â–ˆâ–‡â–‡â–‡â–ˆâ–â–‚â–â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–‡â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–…â–‚â–ƒâ–ƒâ–„â–„â–‚â–„â–†â–â–„â–‚â–†â–ƒâ–ƒâ–†â–‡â–†â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡â–„â–‡â–†â–…â–„â–„â–ƒâ–…â–‡â–ƒâ–â–ƒâ–„â–„
wandb:      train/ensemble_f1 â–…â–„â–„â–„â–„â–…â–…â–…â–‚â–…â–„â–†â–„â–…â–„â–ƒâ–…â–†â–‡â–…â–„â–„â–„â–†â–‡â–‡â–ˆâ–„â–â–†â–ƒâ–…â–…â–‡â–…â–…â–„â–‚â–ƒâ–„
wandb:         train/mil_loss â–…â–‚â–ƒâ–‡â–†â–‚â–‚â–â–„â–„â–„â–‚â–…â–â–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–â–…â–ˆâ–â–‚â–†â–†â–„â–„â–„â–ƒâ–ƒâ–„â–…â–ƒâ–…â–‚â–†
wandb:      train/policy_loss â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–â–…â–…â–ˆâ–…â–ˆâ–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.30571
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.91432
wandb:      eval/avg_mil_loss 0.24828
wandb:       eval/ensemble_f1 0.91432
wandb:            test/avg_f1 0.92222
wandb:      test/avg_mil_loss 0.15213
wandb:       test/ensemble_f1 0.92222
wandb:           train/avg_f1 0.87807
wandb:      train/ensemble_f1 0.87807
wandb:         train/mil_loss 0.24746
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run valiant-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqzlp813
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074249-gqzlp813/logs
wandb: Agent Starting Run: cj3zivxg with config:
wandb: 	actor_learning_rate: 0.0008238625066208179
wandb: 	attention_dropout_p: 0.3128694436792375
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8798320774755176
wandb: 	temperature: 7.574754859429643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074417-cj3zivxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cj3zivxg
wandb: uploading wandb-summary.json
wandb: uploading history steps 80-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–†â–†â–‡â–â–†â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–„â–‡â–ˆâ–†â–â–…â–†â–‡â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–„â–ˆâ–ˆâ–†â–ˆâ–‡â–ˆ
wandb:      eval/avg_mil_loss â–â–„â–â–â–‚â–†â–„â–ƒâ–…â–„â–ƒâ–‚â–‚â–â–…â–‚â–â–â–‚â–â–ƒâ–â–â–â–†â–â–…â–†â–â–â–â–â–‡â–‚â–†â–ƒâ–ˆâ–â–â–
wandb:       eval/ensemble_f1 â–…â–ˆâ–‡â–…â–‡â–„â–ˆâ–ˆâ–‡â–†â–ˆâ–†â–†â–‡â–â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–…â–ˆâ–†â–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–â–ˆâ–„â–…â–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–…â–ƒâ–†â–‡â–…â–‡â–ƒâ–ˆâ–ƒâ–…â–‡â–„â–…â–…â–„â–†â–„â–ƒâ–‡â–â–ˆâ–‡â–ƒâ–‡â–‚â–…â–ƒâ–…â–„â–†â–†â–‚â–‡â–†â–†â–‡â–‡â–‡
wandb:      train/ensemble_f1 â–‡â–†â–…â–ƒâ–ˆâ–‡â–‡â–„â–ƒâ–ˆâ–…â–„â–†â–„â–†â–…â–‡â–ƒâ–†â–ˆâ–„â–‡â–â–‡â–†â–†â–‡â–‡â–‚â–‚â–…â–…â–ˆâ–ƒâ–…â–‡â–„â–‡â–‡â–ƒ
wandb:         train/mil_loss â–‚â–†â–ƒâ–…â–…â–ƒâ–„â–‚â–„â–‡â–„â–‚â–ˆâ–ƒâ–ƒâ–†â–â–ƒâ–â–…â–‚â–‚â–‚â–‡â–â–â–…â–‚â–ˆâ–‡â–ƒâ–‚â–†â–…â–‚â–â–†â–‚â–‡â–
wandb:      train/policy_loss â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–â–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–â–…â–â–ˆâ–…â–…â–â–…â–â–…â–…â–â–…â–ˆâ–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9409
wandb: best/eval_avg_mil_loss 0.25293
wandb:  best/eval_ensemble_f1 0.9409
wandb:            eval/avg_f1 0.92558
wandb:      eval/avg_mil_loss 0.25558
wandb:       eval/ensemble_f1 0.92558
wandb:            test/avg_f1 0.93845
wandb:      test/avg_mil_loss 0.10618
wandb:       test/ensemble_f1 0.93845
wandb:           train/avg_f1 0.82339
wandb:      train/ensemble_f1 0.82339
wandb:         train/mil_loss 0.24584
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worldly-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cj3zivxg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074417-cj3zivxg/logs
wandb: Agent Starting Run: f1s02g51 with config:
wandb: 	actor_learning_rate: 0.0003968188117598157
wandb: 	attention_dropout_p: 0.2903559704447366
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9871261516648232
wandb: 	temperature: 9.94446563376274
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074535-f1s02g51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f1s02g51
wandb: uploading history steps 60-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–‚â–‡â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–‡â–ˆâ–‡â–‚â–‡â–…â–‡â–ˆâ–…â–ˆâ–ˆâ–‡â–ˆâ–â–ˆ
wandb:      eval/avg_mil_loss â–â–ˆâ–â–â–ƒâ–â–‚â–â–…â–â–â–â–„â–â–â–â–‚â–â–†â–‡â–„â–ˆâ–â–ƒâ–â–â–†â–‚â–â–â–„â–â–â–â–â–â–…â–ƒâ–â–
wandb:       eval/ensemble_f1 â–‡â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–‚â–ˆâ–â–ˆâ–†â–ˆâ–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–…â–‡â–‡â–ˆâ–‡â–â–‡â–ˆâ–ˆâ–ˆâ–â–…â–ˆ
wandb:           train/avg_f1 â–ƒâ–‡â–‡â–†â–†â–„â–ˆâ–…â–†â–â–„â–‚â–…â–‡â–‚â–‡â–…â–…â–‡â–†â–‚â–†â–…â–ƒâ–†â–†â–‡â–†â–‚â–ƒâ–ƒâ–„â–‡â–†â–‚â–„â–‡â–ƒâ–‡â–
wandb:      train/ensemble_f1 â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–„â–„â–†â–‡â–†â–ˆâ–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–â–‡â–†â–…â–†â–…â–‡â–„â–„â–†â–ˆâ–†â–‡â–…â–„â–‡
wandb:         train/mil_loss â–ƒâ–â–…â–†â–ˆâ–‚â–â–â–‚â–„â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–…â–ƒâ–‚â–ƒâ–…â–…â–‚â–â–„â–â–‚â–ƒâ–„â–‚â–‚â–†â–„â–…â–‚â–â–‚â–†
wandb:      train/policy_loss â–…â–ˆâ–…â–…â–â–ˆâ–…â–…â–â–…â–…â–…â–ˆâ–…â–…â–ˆâ–â–…â–…â–…â–â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–ˆâ–â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–…â–â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.24883
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.92193
wandb:      eval/avg_mil_loss 0.25806
wandb:       eval/ensemble_f1 0.92193
wandb:           train/avg_f1 0.87626
wandb:      train/ensemble_f1 0.87626
wandb:         train/mil_loss 0.93712
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f1s02g51
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074535-f1s02g51/logs
wandb: ERROR Run f1s02g51 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: flftdx40 with config:
wandb: 	actor_learning_rate: 0.0001256457839141494
wandb: 	attention_dropout_p: 0.38428299102460944
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8259453844931133
wandb: 	temperature: 6.050349664348598
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074637-flftdx40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flftdx40
wandb: uploading history steps 55-72, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–…â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–‚â–†â–ˆâ–â–ˆâ–‡â–…â–…â–ˆâ–†â–‚â–„â–ˆâ–„â–‡â–„â–â–ˆâ–…â–ˆâ–…â–ƒâ–…â–†â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–…â–‡â–ˆâ–ˆâ–ˆâ–„â–ˆâ–…â–…
wandb:      eval/avg_mil_loss â–â–„â–ˆâ–‚â–ƒâ–â–â–…â–â–„â–ƒâ–ƒâ–ƒâ–â–…â–â–ƒâ–‚â–„â–‚â–‚â–„â–ƒâ–„â–„â–„â–‚â–â–â–â–â–ƒâ–â–…â–…â–â–â–ƒâ–â–
wandb:       eval/ensemble_f1 â–‚â–…â–â–‡â–‡â–‡â–…â–‡â–ˆâ–†â–ˆâ–‚â–ˆâ–„â–„â–ˆâ–„â–‡â–„â–ƒâ–‡â–†â–ˆâ–‚â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–„â–ˆâ–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–„â–‚â–ˆâ–ˆâ–†â–„â–‡â–‡â–†â–‡â–…â–ˆâ–†â–‡â–‡â–†â–„â–†â–‡â–â–ƒâ–†â–†â–„â–ˆâ–‡â–„â–‡â–‡â–†â–†â–…â–…â–†â–‡â–†â–†â–†
wandb:      train/ensemble_f1 â–…â–…â–„â–†â–†â–‡â–…â–ƒâ–…â–‡â–„â–…â–†â–‡â–…â–…â–„â–…â–†â–â–…â–…â–…â–„â–‡â–‡â–†â–„â–†â–…â–„â–„â–ƒâ–‚â–‡â–ˆâ–…â–†â–„â–†
wandb:         train/mil_loss â–†â–ƒâ–‚â–ƒâ–„â–ˆâ–‚â–‚â–…â–ˆâ–‚â–„â–„â–„â–‡â–ƒâ–‚â–â–‡â–„â–„â–‚â–„â–‚â–‚â–‚â–„â–‚â–ƒâ–…â–ƒâ–…â–‚â–‡â–â–ƒâ–…â–‡â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–â–â–ˆâ–…â–…â–â–â–ˆâ–â–â–…â–…â–…â–â–…â–ˆâ–…â–ˆâ–…â–ˆâ–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.23636
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.80283
wandb:      eval/avg_mil_loss 1.83441
wandb:       eval/ensemble_f1 0.80283
wandb:            test/avg_f1 0.90493
wandb:      test/avg_mil_loss 0.25178
wandb:       test/ensemble_f1 0.90493
wandb:           train/avg_f1 0.86711
wandb:      train/ensemble_f1 0.86711
wandb:         train/mil_loss 0.95585
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run still-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flftdx40
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074637-flftdx40/logs
wandb: Agent Starting Run: gqic6by4 with config:
wandb: 	actor_learning_rate: 0.0003061393104552007
wandb: 	attention_dropout_p: 0.3280724540695707
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9233409236279146
wandb: 	temperature: 6.190185424234952
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074744-gqic6by4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqic6by4
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–ˆâ–„â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ƒâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–â–â–â–â–‚â–ƒâ–â–â–â–â–â–‚â–ˆâ–â–â–â–â–â–ƒâ–â–„â–„â–â–„â–â–„â–â–â–â–â–â–…â–‡â–â–â–â–â–â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–„â–„â–†â–‡â–‚â–ƒâ–‡â–ƒâ–ˆâ–„â–‚â–ƒâ–â–ƒâ–†â–„â–„â–„â–ƒâ–ˆâ–‡â–‡â–†â–ˆâ–…â–‡â–â–ƒâ–‡â–†â–ƒâ–…â–„â–â–…â–…â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–…â–‡â–„â–…â–‡â–‚â–„â–‡â–â–„â–‚â–…â–†â–‡â–…â–†â–…â–„â–ƒâ–„â–‚â–ˆâ–‡â–ˆâ–‡â–ˆâ–…â–‡â–„â–†â–‡â–…â–„â–†â–†â–„â–…â–…â–‡
wandb:         train/mil_loss â–„â–ƒâ–â–ƒâ–„â–‚â–„â–„â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–â–…â–ƒâ–…â–„â–ƒâ–â–…â–„â–â–„â–ˆâ–â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–…â–…â–„â–„
wandb:      train/policy_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.29012
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.91087
wandb:      eval/avg_mil_loss 0.26746
wandb:       eval/ensemble_f1 0.91087
wandb:            test/avg_f1 0.92358
wandb:      test/avg_mil_loss 0.12774
wandb:       test/ensemble_f1 0.92358
wandb:           train/avg_f1 0.8792
wandb:      train/ensemble_f1 0.8792
wandb:         train/mil_loss 0.9053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run easy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqic6by4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074744-gqic6by4/logs
wandb: Agent Starting Run: sv6u4ug7 with config:
wandb: 	actor_learning_rate: 0.0006482598298324099
wandb: 	attention_dropout_p: 0.33593239365036903
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7093643647533849
wandb: 	temperature: 9.51648079074369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074851-sv6u4ug7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sv6u4ug7
wandb: uploading wandb-summary.json
wandb: uploading history steps 120-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–„â–‡â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–‡â–„â–ˆâ–‡â–â–ˆâ–„â–ƒâ–‡â–ˆâ–†â–„â–‡â–‡â–â–‡â–‡â–‡â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–†â–„â–‚â–ƒâ–‡â–‚â–â–â–â–â–â–„â–â–„â–ƒâ–â–‚â–ƒâ–â–â–â–â–ƒâ–â–â–â–†â–â–ƒâ–„â–â–â–‚â–ƒâ–â–‚â–‚â–ˆâ–â–
wandb:       eval/ensemble_f1 â–„â–ˆâ–„â–†â–†â–‚â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–â–ˆâ–â–‡â–†â–ˆâ–ˆâ–‡â–„â–‡â–ƒâ–‡â–‡â–„â–‡â–ˆâ–„â–†â–‡â–…â–„â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–†â–‡â–‚â–„â–ƒâ–‡â–†â–†â–‚â–†â–†â–ƒâ–‡â–ƒâ–‡â–…â–†â–‡â–…â–„â–‡â–†â–â–‚â–‡â–†â–„â–…â–…â–…â–ˆâ–†â–…â–ƒâ–…â–…â–ƒâ–†
wandb:      train/ensemble_f1 â–†â–…â–†â–‡â–‡â–ˆâ–„â–ˆâ–…â–…â–‡â–†â–‡â–…â–ˆâ–‡â–ˆâ–ˆâ–†â–„â–â–…â–†â–†â–†â–…â–‡â–ƒâ–†â–‡â–‡â–†â–†â–†â–ˆâ–‡â–‡â–‡â–†â–ƒ
wandb:         train/mil_loss â–…â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–â–ˆâ–‚â–„â–ƒâ–…â–…â–‚â–„â–„â–†â–„â–‚â–‚â–â–…â–‚â–ƒâ–„â–‚â–‚â–„â–…â–ƒâ–†â–â–ƒâ–‚â–„â–‚â–†
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–ˆâ–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.27233
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.7755
wandb:      eval/avg_mil_loss 2.59744
wandb:       eval/ensemble_f1 0.7755
wandb:            test/avg_f1 0.88427
wandb:      test/avg_mil_loss 0.30919
wandb:       test/ensemble_f1 0.88427
wandb:           train/avg_f1 0.79881
wandb:      train/ensemble_f1 0.79881
wandb:         train/mil_loss 1.3277
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sv6u4ug7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074851-sv6u4ug7/logs
wandb: Agent Starting Run: zolp3m82 with config:
wandb: 	actor_learning_rate: 0.0004449968001349981
wandb: 	attention_dropout_p: 0.16789350818725596
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8639520008897708
wandb: 	temperature: 8.493118642232542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075035-zolp3m82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zolp3m82
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 100-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–‡â–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–‡â–ˆâ–„â–ˆâ–ƒâ–‡â–â–ˆâ–ˆâ–‡â–ƒâ–ˆâ–â–ˆâ–â–‡â–ˆâ–‚â–‡â–‡â–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:      eval/avg_mil_loss â–â–â–‚â–‚â–â–â–â–â–‚â–â–†â–â–…â–â–„â–†â–…â–‚â–â–„â–â–â–‡â–„â–â–â–…â–‡â–â–â–â–ˆâ–â–‚â–ƒâ–â–…â–â–…â–‡
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–ˆâ–ƒâ–„â–ˆâ–…â–ƒâ–ˆâ–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–â–ˆâ–ˆâ–‡â–ˆâ–‡â–ƒâ–‡â–ˆâ–†â–…â–ˆâ–â–ˆâ–ˆ
wandb:           train/avg_f1 â–†â–ƒâ–…â–…â–ƒâ–ƒâ–†â–ƒâ–…â–„â–…â–…â–…â–„â–ˆâ–‚â–ƒâ–â–ƒâ–„â–„â–…â–…â–„â–‚â–‡â–…â–‡â–‚â–ƒâ–…â–‚â–…â–†â–„â–‡â–…â–‚â–†â–†
wandb:      train/ensemble_f1 â–ˆâ–„â–‡â–„â–†â–„â–†â–‚â–†â–…â–‡â–ƒâ–‚â–â–‚â–†â–…â–„â–„â–ƒâ–…â–ƒâ–…â–ƒâ–‡â–‡â–„â–‡â–…â–„â–‡â–…â–‡â–†â–„â–…â–‡â–„â–†â–†
wandb:         train/mil_loss â–ƒâ–„â–‚â–‡â–ƒâ–‡â–â–ƒâ–…â–…â–†â–ƒâ–„â–ƒâ–…â–â–ƒâ–†â–†â–‡â–ƒâ–…â–‚â–…â–ƒâ–ˆâ–â–ƒâ–„â–ˆâ–„â–…â–â–‡â–ƒâ–ƒâ–ƒâ–„â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–…â–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–â–…â–…â–ˆâ–…â–â–…â–ˆâ–…â–â–…â–â–…â–…â–â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.26194
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.8926
wandb:      eval/avg_mil_loss 2.55356
wandb:       eval/ensemble_f1 0.8926
wandb:           train/avg_f1 0.87281
wandb:      train/ensemble_f1 0.87281
wandb:         train/mil_loss 0.97919
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dashing-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zolp3m82
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075035-zolp3m82/logs
wandb: ERROR Run zolp3m82 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9apx8r7b with config:
wandb: 	actor_learning_rate: 0.00037595759107709586
wandb: 	attention_dropout_p: 0.3309684687471713
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8725364478352147
wandb: 	temperature: 5.915421225691441
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075202-9apx8r7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9apx8r7b
wandb: uploading wandb-summary.json
wandb: uploading history steps 98-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–‚â–ƒâ–…â–ˆâ–‡â–„â–â–„â–‡â–ˆâ–‚â–„â–‚â–ƒâ–†â–‚â–†â–…â–‡â–„â–‚â–‡â–â–‡â–‡â–…â–…â–ƒâ–â–â–ƒâ–†â–â–„â–ƒâ–â–ƒâ–‚â–ƒ
wandb:      eval/avg_mil_loss â–„â–†â–…â–„â–†â–„â–…â–‡â–‡â–ƒâ–‡â–…â–„â–ˆâ–…â–…â–‡â–‚â–†â–†â–…â–…â–ˆâ–†â–‡â–†â–…â–ƒâ–‡â–‡â–‡â–â–…â–‚â–…â–ƒâ–†â–†â–‡â–…
wandb:       eval/ensemble_f1 â–‡â–„â–ƒâ–ˆâ–â–‚â–…â–ˆâ–‡â–‡â–‚â–…â–‡â–„â–‚â–ƒâ–†â–†â–…â–…â–ˆâ–ƒâ–‡â–â–‡â–ƒâ–â–‡â–‡â–…â–ƒâ–â–ˆâ–ƒâ–†â–„â–‚â–ƒâ–â–…
wandb:           train/avg_f1 â–ˆâ–ˆâ–ƒâ–…â–…â–‡â–„â–…â–ƒâ–ˆâ–â–‡â–‡â–‡â–„â–‚â–‡â–‡â–ƒâ–„â–‡â–‡â–†â–„â–„â–ˆâ–‡â–ƒâ–â–…â–…â–…â–…â–…â–‚â–‚â–†â–ˆâ–‚â–„
wandb:      train/ensemble_f1 â–„â–‡â–ƒâ–„â–‡â–†â–ˆâ–ˆâ–‡â–…â–ˆâ–‡â–ƒâ–‡â–ƒâ–„â–…â–‡â–â–…â–‡â–„â–…â–…â–†â–‡â–…â–…â–„â–…â–ˆâ–†â–…â–ƒâ–„â–ƒâ–‡â–ˆâ–„â–…
wandb:         train/mil_loss â–…â–…â–ƒâ–„â–„â–‡â–†â–„â–…â–‚â–…â–…â–„â–†â–ˆâ–…â–…â–†â–„â–ƒâ–„â–…â–ƒâ–„â–…â–†â–„â–…â–„â–â–…â–†â–„â–ƒâ–‚â–†â–…â–„â–‡â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9183
wandb: best/eval_avg_mil_loss 0.27845
wandb:  best/eval_ensemble_f1 0.9183
wandb:            eval/avg_f1 0.87537
wandb:      eval/avg_mil_loss 1.37948
wandb:       eval/ensemble_f1 0.87537
wandb:           train/avg_f1 0.70998
wandb:      train/ensemble_f1 0.70998
wandb:         train/mil_loss 2.23642
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devout-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9apx8r7b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075202-9apx8r7b/logs
wandb: ERROR Run 9apx8r7b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: py6q7x2u with config:
wandb: 	actor_learning_rate: 0.0003197228059153668
wandb: 	attention_dropout_p: 0.22894051422816564
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9687727648478192
wandb: 	temperature: 8.35814962868229
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075330-py6q7x2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/py6q7x2u
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–‡â–‚â–‚â–ˆâ–â–‡â–ˆâ–‡â–ˆâ–ƒâ–ˆâ–ˆâ–ƒâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–â–ˆâ–ƒâ–„â–ˆâ–‚â–‚â–ˆâ–ƒâ–‚â–ˆâ–ƒâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–â–„â–ƒâ–…â–…â–†â–‡â–â–â–…â–„â–â–‡â–„â–ƒâ–â–‚â–ƒâ–†â–„â–„â–â–‡â–…â–„â–ˆâ–ƒâ–â–…â–„â–„â–ƒâ–â–ƒâ–„â–‡â–â–â–„â–†
wandb:       eval/ensemble_f1 â–‚â–‚â–‚â–ˆâ–‡â–‚â–â–â–â–ƒâ–‡â–‚â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–ˆâ–…â–ˆâ–„â–ˆâ–‡â–ˆâ–ˆâ–â–ƒâ–‚â–„â–ƒâ–‚â–‚â–ˆâ–ˆâ–ƒâ–ˆâ–‚â–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–â–‡â–†â–‡â–†â–†â–ˆâ–…â–†â–…â–…â–†â–†â–‡â–„â–…â–†â–‡â–†â–‡â–†â–„â–„â–†â–„â–„â–†â–ƒâ–‡â–„â–„â–…â–†â–†â–ƒâ–†â–…â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–â–‡â–†â–„â–‡â–†â–…â–†â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–‡â–„â–…â–†â–†â–„â–†â–„â–…â–‡â–„â–„â–„â–‡â–…â–†â–†â–†â–†â–ƒ
wandb:         train/mil_loss â–†â–„â–†â–‡â–ƒâ–„â–ƒâ–â–…â–‡â–‚â–ƒâ–ˆâ–†â–…â–…â–†â–‚â–…â–„â–†â–…â–‚â–ƒâ–„â–†â–‡â–…â–‡â–…â–„â–†â–„â–‡â–…â–â–ƒâ–‡â–‚â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9145
wandb: best/eval_avg_mil_loss 0.25343
wandb:  best/eval_ensemble_f1 0.9145
wandb:            eval/avg_f1 0.84992
wandb:      eval/avg_mil_loss 2.62357
wandb:       eval/ensemble_f1 0.84992
wandb:            test/avg_f1 0.92222
wandb:      test/avg_mil_loss 0.23266
wandb:       test/ensemble_f1 0.92222
wandb:           train/avg_f1 0.70325
wandb:      train/ensemble_f1 0.70325
wandb:         train/mil_loss 1.3415
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/py6q7x2u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075330-py6q7x2u/logs
wandb: Agent Starting Run: 5jk4labh with config:
wandb: 	actor_learning_rate: 0.0005805655305946761
wandb: 	attention_dropout_p: 0.36240539603098065
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7209759604460654
wandb: 	temperature: 8.047868262437426
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075437-5jk4labh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5jk4labh
wandb: uploading history steps 80-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–‡â–ˆâ–„â–„â–ˆâ–‡â–â–†â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ƒâ–‡â–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–‡â–‡â–‡â–ˆâ–â–‡â–ˆâ–ˆâ–â–ˆâ–‡â–‡â–‡
wandb:      eval/avg_mil_loss â–„â–â–â–â–†â–†â–â–‚â–â–ˆâ–â–„â–â–â–â–†â–â–â–â–â–â–â–â–„â–â–â–â–â–‚â–†â–…â–„â–‚â–…â–â–â–ƒâ–â–â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–…â–„â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–‡â–ˆâ–‚â–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–â–ˆâ–…â–‡
wandb:           train/avg_f1 â–…â–„â–‡â–‡â–ˆâ–…â–â–†â–‡â–†â–†â–‡â–‡â–†â–„â–…â–…â–ƒâ–‡â–‚â–†â–ˆâ–ˆâ–‡â–‡â–†â–ƒâ–ˆâ–†â–‡â–…â–„â–†â–„â–„â–…â–ˆâ–†â–†â–ˆ
wandb:      train/ensemble_f1 â–ƒâ–â–‡â–‡â–‡â–…â–„â–‚â–ƒâ–ˆâ–†â–…â–„â–†â–„â–†â–†â–„â–‚â–„â–â–„â–…â–‡â–‡â–†â–‚â–ƒâ–…â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–…â–…â–…â–‡â–…
wandb:         train/mil_loss â–„â–†â–‡â–‡â–‚â–„â–ƒâ–…â–â–…â–„â–…â–„â–ƒâ–…â–„â–†â–ƒâ–„â–‚â–ˆâ–„â–…â–„â–â–…â–ƒâ–‚â–†â–‚â–â–„â–â–‚â–‚â–â–â–ƒâ–ƒâ–ƒ
wandb:      train/policy_loss â–„â–â–â–„â–ˆâ–„â–„â–â–„â–„â–„â–ˆâ–„â–„â–â–ˆâ–„â–â–„â–„â–„â–â–â–ˆâ–„â–â–ˆâ–„â–â–„â–„â–„â–„â–â–„â–ˆâ–ˆâ–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–…â–…â–…â–â–â–ˆâ–â–…â–…â–…â–…â–ˆâ–…â–ˆâ–â–â–â–…â–…â–â–…â–ˆâ–â–ˆâ–…â–â–ˆâ–ˆâ–…â–…â–…â–…â–…â–â–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92976
wandb: best/eval_avg_mil_loss 0.26598
wandb:  best/eval_ensemble_f1 0.92976
wandb:            eval/avg_f1 0.88682
wandb:      eval/avg_mil_loss 0.3809
wandb:       eval/ensemble_f1 0.88682
wandb:           train/avg_f1 0.87717
wandb:      train/ensemble_f1 0.87717
wandb:         train/mil_loss 0.24926
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run autumn-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5jk4labh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075437-5jk4labh/logs
wandb: ERROR Run 5jk4labh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: aciic9k8 with config:
wandb: 	actor_learning_rate: 0.0006596623567354373
wandb: 	attention_dropout_p: 0.2648293263393907
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8691705343621111
wandb: 	temperature: 8.986346436245524
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075550-aciic9k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aciic9k8
wandb: uploading history steps 88-106
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–…â–ƒâ–ƒâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–„â–ƒâ–‡â–‡â–„â–„â–ˆâ–„â–„â–‡â–‡â–‡â–ˆâ–‡â–…â–‚â–ˆâ–…â–‡â–†â–‚â–…â–‡â–ƒâ–ˆâ–ˆâ–ˆâ–…â–‡â–†â–â–„â–ˆ
wandb:      eval/avg_mil_loss â–â–â–â–â–â–…â–‡â–„â–â–‚â–â–ƒâ–ƒâ–â–â–â–†â–‚â–„â–â–â–ƒâ–…â–…â–â–â–â–ˆâ–„â–„â–ƒâ–…â–â–â–„â–…â–â–â–â–
wandb:       eval/ensemble_f1 â–‡â–‡â–‡â–ˆâ–„â–ƒâ–ˆâ–â–„â–‡â–‡â–‡â–†â–†â–ˆâ–…â–ˆâ–ˆâ–‡â–‚â–„â–ˆâ–ƒâ–ˆâ–‡â–ˆâ–‡â–‡â–„â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‚â–‡â–‡â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–…â–„â–…â–†â–‡â–†â–…â–†â–ˆâ–…â–†â–„â–…â–†â–„â–â–„â–†â–ƒâ–„â–„â–‡â–†â–†â–…â–†â–‡â–ƒâ–‡â–†â–…â–…â–‡â–…â–‡â–…â–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–†â–…â–…â–†â–…â–ˆâ–ƒâ–…â–‡â–…â–ˆâ–„â–†â–…â–â–„â–…â–„â–„â–†â–ƒâ–„â–…â–…â–†â–ƒâ–„â–†â–ƒâ–…â–‡â–‡â–…â–…â–‡â–†â–„â–†â–„
wandb:         train/mil_loss â–â–â–„â–‡â–†â–‚â–…â–ƒâ–„â–â–…â–„â–…â–ƒâ–ˆâ–†â–…â–…â–…â–ˆâ–…â–„â–†â–ˆâ–…â–ˆâ–„â–†â–…â–†â–‡â–„â–„â–‚â–„â–ˆâ–‡â–…â–†â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–‚â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.23579
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.81743
wandb:      eval/avg_mil_loss 1.00143
wandb:       eval/ensemble_f1 0.81743
wandb:            test/avg_f1 0.74418
wandb:      test/avg_mil_loss 1.59502
wandb:       test/ensemble_f1 0.74418
wandb:           train/avg_f1 0.84729
wandb:      train/ensemble_f1 0.84729
wandb:         train/mil_loss 0.60955
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run amber-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aciic9k8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075550-aciic9k8/logs
wandb: Agent Starting Run: sfcng64y with config:
wandb: 	actor_learning_rate: 7.210229387249357e-05
wandb: 	attention_dropout_p: 0.3224854863298031
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 63
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7492271385905022
wandb: 	temperature: 7.329341818754403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075728-sfcng64y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfcng64y
wandb: uploading wandb-summary.json
wandb: uploading history steps 59-63, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–‡â–ƒâ–‡â–„â–‡â–‚â–‡â–…â–‡â–‚â–ˆâ–„â–„â–‡â–‡â–„â–‚â–…â–‡â–ƒâ–…â–ˆâ–„â–ˆâ–‚â–ˆâ–‡â–‚â–‡â–‡â–ˆâ–‡â–…â–ƒâ–â–‚â–…â–â–ƒ
wandb:      eval/avg_mil_loss â–â–…â–„â–„â–‚â–ˆâ–„â–…â–…â–…â–†â–„â–…â–„â–„â–‡â–…â–…â–„â–ˆâ–„â–â–ƒâ–â–â–„â–‡â–„â–„â–„â–…â–‡â–â–…â–…â–‚â–‡â–‡â–‚â–„
wandb:       eval/ensemble_f1 â–‚â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ƒâ–‡â–‡â–…â–‡â–‡â–‚â–ˆâ–ƒâ–„â–ˆâ–‡â–„â–…â–‡â–‚â–â–ƒâ–ˆâ–ˆâ–‚â–ˆâ–ƒâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–…â–„â–â–ƒ
wandb:           train/avg_f1 â–…â–†â–…â–„â–†â–„â–…â–…â–„â–…â–„â–„â–ˆâ–…â–†â–„â–†â–ƒâ–…â–…â–†â–„â–†â–â–‡â–†â–…â–†â–…â–‡â–…â–†â–…â–„â–‡â–„â–„â–†â–‡â–‡
wandb:      train/ensemble_f1 â–…â–†â–…â–†â–…â–…â–„â–…â–…â–„â–ˆâ–…â–‡â–†â–†â–†â–ƒâ–„â–…â–…â–„â–â–‡â–„â–…â–…â–†â–…â–‡â–…â–†â–…â–„â–„â–‡â–‡â–†â–…â–ƒâ–‡
wandb:         train/mil_loss â–„â–„â–…â–‚â–â–„â–†â–ˆâ–â–ƒâ–…â–„â–â–„â–‡â–ƒâ–‚â–„â–…â–‡â–…â–„â–…â–†â–ƒâ–ƒâ–†â–…â–…â–ˆâ–…â–…â–‚â–†â–â–†â–†â–„â–‚â–„
wandb:      train/policy_loss â–…â–…â–â–…â–…â–ˆâ–…â–ˆâ–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–â–…â–…â–…â–ˆâ–…â–…â–â–…â–â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.38596
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.65612
wandb:      eval/avg_mil_loss 1.75971
wandb:       eval/ensemble_f1 0.65612
wandb:           train/avg_f1 0.85114
wandb:      train/ensemble_f1 0.85114
wandb:         train/mil_loss 1.50946
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run crimson-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfcng64y
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075728-sfcng64y/logs
wandb: ERROR Run sfcng64y errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hmphz1p0 with config:
wandb: 	actor_learning_rate: 0.00015466039147701843
wandb: 	attention_dropout_p: 0.36468087571317154
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.969996977509948
wandb: 	temperature: 7.3725892428329
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075831-hmphz1p0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmphz1p0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–â–†â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–â–„
wandb:      eval/avg_mil_loss â–â–…â–â–‚â–â–â–ˆâ–‚â–†â–†â–â–â–â–â–â–ˆâ–†â–â–â–â–â–â–…â–ˆâ–â–â–‚â–â–â–…â–â–â–â–â–â–â–â–‚â–‡â–‚
wandb:       eval/ensemble_f1 â–ˆâ–‡â–‡â–‡â–ˆâ–„â–ˆâ–‡â–‡â–‡â–ˆâ–â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–‡â–‡â–‡â–…â–…â–†â–‚â–‡â–†â–…â–ƒâ–‡â–„â–â–ƒâ–ˆâ–†â–…â–„â–ƒâ–ˆâ–…â–ˆâ–‡â–‡â–ˆâ–…â–‡â–‡â–ƒâ–…â–ƒâ–‡â–…â–â–…â–†â–‡
wandb:      train/ensemble_f1 â–‡â–…â–‡â–ˆâ–†â–†â–ƒâ–‚â–‡â–ƒâ–…â–ƒâ–„â–‡â–â–ˆâ–†â–…â–‚â–„â–†â–„â–‡â–ƒâ–‡â–‡â–‡â–‡â–ƒâ–…â–ƒâ–‡â–„â–ƒâ–‡â–â–…â–†â–‡â–ƒ
wandb:         train/mil_loss â–â–ƒâ–â–â–„â–ƒâ–„â–â–…â–â–„â–„â–â–â–†â–†â–ƒâ–â–„â–â–â–„â–ƒâ–â–â–ƒâ–„â–†â–ˆâ–â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–‡â–‡â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.26685
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.74099
wandb:      eval/avg_mil_loss 0.60554
wandb:       eval/ensemble_f1 0.74099
wandb:            test/avg_f1 0.91594
wandb:      test/avg_mil_loss 0.12735
wandb:       test/ensemble_f1 0.91594
wandb:           train/avg_f1 0.83515
wandb:      train/ensemble_f1 0.83515
wandb:         train/mil_loss 0.99303
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run royal-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmphz1p0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075831-hmphz1p0/logs
wandb: Agent Starting Run: 08numy12 with config:
wandb: 	actor_learning_rate: 7.68875383519145e-05
wandb: 	attention_dropout_p: 0.2731026447644113
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8650408442029501
wandb: 	temperature: 5.966559884775497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075928-08numy12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/08numy12
wandb: uploading wandb-summary.json
wandb: uploading history steps 40-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–†â–†â–ƒâ–‡â–‡â–‡â–ˆâ–…â–…â–ˆâ–ˆâ–ƒâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–‚â–â–‚â–â–ˆâ–‡â–ˆâ–„â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–â–â–‚â–‚â–‚â–‚â–…â–„â–ƒâ–â–ƒâ–„â–ƒâ–â–„â–„â–â–â–‚â–â–†â–â–‡â–ˆâ–â–…â–â–†â–ƒâ–‚â–‚â–…â–â–â–â–„â–â–â–
wandb:       eval/ensemble_f1 â–‡â–ˆâ–†â–ˆâ–†â–†â–‡â–ƒâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–â–â–ˆâ–â–‡â–ˆâ–„â–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–„â–†â–†â–†â–ƒâ–ƒâ–‚â–‚â–‡â–†â–â–ˆâ–‡â–†â–ƒâ–ƒâ–„â–â–ƒâ–‚â–†â–ˆâ–†â–„â–â–†â–„â–…â–„â–…â–†â–‚â–‚â–ƒâ–‚â–…â–…â–…â–†
wandb:      train/ensemble_f1 â–‡â–†â–„â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–‡â–‡â–„â–â–ˆâ–†â–ƒâ–ƒâ–„â–â–‚â–ˆâ–†â–„â–†â–„â–…â–†â–„â–ƒâ–„â–†â–‚â–â–ƒâ–‚â–…â–…â–†â–†
wandb:         train/mil_loss â–ƒâ–…â–ƒâ–…â–…â–ƒâ–ƒâ–„â–†â–ƒâ–„â–ƒâ–†â–ˆâ–…â–„â–…â–„â–„â–†â–†â–„â–„â–†â–…â–…â–â–ƒâ–†â–…â–„â–‡â–†â–ƒâ–‡â–…â–…â–„â–‚â–
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–â–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.28061
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.89004
wandb:      eval/avg_mil_loss 2.52157
wandb:       eval/ensemble_f1 0.89004
wandb:            test/avg_f1 0.68409
wandb:      test/avg_mil_loss 2.91853
wandb:       test/ensemble_f1 0.68409
wandb:           train/avg_f1 0.85431
wandb:      train/ensemble_f1 0.85431
wandb:         train/mil_loss 0.22799
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dandy-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/08numy12
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075928-08numy12/logs
wandb: Agent Starting Run: atxrlks2 with config:
wandb: 	actor_learning_rate: 0.00030701615398042093
wandb: 	attention_dropout_p: 0.2403376653721759
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8073821950584139
wandb: 	temperature: 8.30048535188
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080020-atxrlks2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atxrlks2
wandb: uploading history steps 90-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ƒâ–â–ˆâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–ˆâ–ˆâ–‡â–„â–‡â–‡â–ˆâ–‡â–â–‡â–ƒâ–‡â–ˆâ–‡â–‡â–…â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–â–â–ƒâ–â–‚â–â–â–â–â–„â–â–â–â–‚â–â–â–ƒâ–„â–â–„â–â–â–â–â–â–…â–â–â–„â–â–ˆâ–â–â–„â–„â–â–â–â–„â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–†â–ƒâ–†â–‡â–‡â–†â–ˆâ–…â–‡â–…â–‡â–ˆâ–‡â–†â–‡â–‚â–‡â–â–‡â–‡â–‡â–†â–„â–ƒâ–‡â–ˆâ–†â–‡â–†â–‡â–‡â–†â–„â–ˆâ–†â–‡â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–ˆâ–„â–…â–â–â–„â–†â–â–†â–„â–†â–…â–„â–†â–…â–†â–‡â–†â–…â–†â–ƒâ–‡â–…â–„â–‡â–…â–†â–†â–…â–…â–…â–†â–†â–„â–…â–†â–†â–†
wandb:      train/ensemble_f1 â–†â–…â–ˆâ–…â–ƒâ–‡â–‚â–â–…â–†â–†â–„â–†â–ƒâ–…â–†â–†â–†â–…â–…â–†â–„â–…â–‡â–„â–…â–†â–†â–†â–…â–†â–„â–†â–‡â–…â–…â–…â–†â–†â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–„â–ˆâ–…â–„â–‚â–‡â–„â–†â–„â–…â–â–ƒâ–ˆâ–‚â–‡â–‡â–â–…â–…â–â–ƒâ–ƒâ–ƒâ–†â–‚â–ƒâ–‚â–…â–…â–‚â–†â–„â–„â–â–ƒâ–‚â–â–„
wandb:      train/policy_loss â–ˆâ–…â–ˆâ–…â–â–…â–…â–â–…â–ˆâ–…â–â–ˆâ–…â–…â–â–…â–…â–â–…â–â–ˆâ–…â–…â–ˆâ–…â–ˆâ–…â–â–…â–ˆâ–ˆâ–ˆâ–â–…â–…â–â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92634
wandb: best/eval_avg_mil_loss 0.24661
wandb:  best/eval_ensemble_f1 0.92634
wandb:            eval/avg_f1 0.91845
wandb:      eval/avg_mil_loss 0.20125
wandb:       eval/ensemble_f1 0.91845
wandb:            test/avg_f1 0.91566
wandb:      test/avg_mil_loss 0.24385
wandb:       test/ensemble_f1 0.91566
wandb:           train/avg_f1 0.88948
wandb:      train/ensemble_f1 0.88948
wandb:         train/mil_loss 0.41456
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atxrlks2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080020-atxrlks2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sco2vjjr with config:
wandb: 	actor_learning_rate: 0.0005197749145630058
wandb: 	attention_dropout_p: 0.17383459244863675
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8975315825624264
wandb: 	temperature: 8.179159281802104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080203-sco2vjjr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sco2vjjr
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–ˆâ–‡â–â–ˆâ–†â–†â–†â–‡â–ˆâ–ˆâ–…â–‚â–…â–ˆâ–ƒâ–ˆâ–‡â–„â–‡â–†â–…â–‡â–„â–‡â–†â–‚â–ˆâ–ƒâ–†â–‡â–â–ˆâ–‡â–ˆâ–†â–‡â–‡â–ˆ
wandb:      eval/avg_mil_loss â–„â–â–„â–†â–‚â–â–â–‚â–â–„â–ˆâ–â–â–â–â–ƒâ–‚â–â–‚â–â–â–ƒâ–â–â–â–…â–‚â–â–ƒâ–â–ƒâ–ƒâ–…â–„â–ƒâ–â–†â–‚â–ƒâ–
wandb:       eval/ensemble_f1 â–‡â–‡â–†â–‚â–…â–†â–‡â–‡â–†â–â–ˆâ–ˆâ–‚â–†â–†â–…â–‡â–‡â–ˆâ–‡â–ƒâ–‡â–ˆâ–…â–†â–†â–‡â–†â–‚â–‚â–‡â–ˆâ–†â–†â–‡â–‡â–†â–‡â–‚â–ˆ
wandb:           train/avg_f1 â–‡â–ˆâ–…â–„â–…â–…â–…â–„â–„â–…â–†â–‚â–ˆâ–„â–ˆâ–‚â–…â–‚â–‚â–‡â–ƒâ–‚â–‚â–…â–„â–ƒâ–†â–†â–ƒâ–„â–ƒâ–„â–â–†â–†â–‡â–…â–„â–†â–…
wandb:      train/ensemble_f1 â–ˆâ–„â–ƒâ–‚â–†â–…â–ƒâ–…â–‡â–†â–ƒâ–„â–ˆâ–„â–‡â–„â–†â–†â–‡â–†â–ƒâ–„â–â–‚â–‚â–‡â–„â–…â–…â–‡â–„â–ƒâ–ƒâ–„â–ˆâ–…â–‡â–„â–‡â–†
wandb:         train/mil_loss â–„â–ƒâ–‚â–‚â–‚â–…â–„â–‚â–…â–ƒâ–‡â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–‚â–‚â–†â–„â–â–‚â–„â–ƒâ–„â–ˆâ–â–ƒâ–ƒâ–…â–†
wandb:      train/policy_loss â–„â–„â–â–„â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–â–ˆâ–â–„â–â–ˆâ–„â–â–â–„â–â–„â–â–ˆâ–„â–ˆâ–ˆâ–â–„â–„â–ˆâ–„â–ˆâ–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.21232
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.91467
wandb:      eval/avg_mil_loss 0.23807
wandb:       eval/ensemble_f1 0.91467
wandb:           train/avg_f1 0.84765
wandb:      train/ensemble_f1 0.84765
wandb:         train/mil_loss 0.46785
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sco2vjjr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080203-sco2vjjr/logs
wandb: ERROR Run sco2vjjr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bp714fc9 with config:
wandb: 	actor_learning_rate: 1.054517491703243e-06
wandb: 	attention_dropout_p: 0.3934038775968901
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5895962956747095
wandb: 	temperature: 4.1370378649912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080351-bp714fc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bp714fc9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–‚â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–…â–‡â–‡â–…â–ƒâ–‚â–†â–ƒâ–…â–…â–ˆâ–â–ƒâ–ˆâ–…â–‡â–†â–ˆâ–…â–ƒâ–‚â–‡â–ƒâ–‡â–ƒâ–ƒâ–†â–‡â–†â–…â–ƒâ–ˆâ–…â–…â–ˆâ–…â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–‚â–â–‚â–ƒâ–â–†â–ˆâ–ƒâ–ƒâ–ƒâ–†â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–â–ƒâ–â–â–„â–‚â–„â–â–â–ƒâ–â–‚â–â–â–‚â–â–â–…â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–…â–‡â–…â–†â–ˆâ–‡â–†â–‡â–‚â–„â–†â–„â–†â–‡â–…â–…â–…â–„â–„â–†â–ˆâ–„â–‡â–†â–‡â–ƒâ–†â–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–â–„
wandb:           train/avg_f1 â–‚â–…â–…â–„â–…â–…â–…â–â–†â–„â–†â–…â–…â–ƒâ–…â–‚â–…â–„â–ƒâ–†â–„â–…â–‚â–ƒâ–…â–â–„â–‡â–…â–„â–„â–…â–„â–‡â–†â–„â–ˆâ–„â–…â–‡
wandb:      train/ensemble_f1 â–‚â–†â–†â–…â–†â–†â–‡â–†â–…â–â–…â–‡â–„â–‡â–…â–ˆâ–…â–…â–„â–„â–†â–„â–†â–‚â–„â–‡â–…â–„â–†â–†â–„â–†â–„â–…â–„â–…â–ˆâ–…â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–‚â–‚â–…â–ƒâ–†â–„â–‚â–„â–†â–„â–…â–…â–…â–…â–†â–†â–ƒâ–â–‚â–„â–‡â–ˆâ–‚â–…â–„â–‚â–â–ƒâ–„â–ƒâ–†â–â–‡â–‚â–‚â–…â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.2499
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.77313
wandb:      eval/avg_mil_loss 1.13058
wandb:       eval/ensemble_f1 0.77313
wandb:           train/avg_f1 0.8046
wandb:      train/ensemble_f1 0.8046
wandb:         train/mil_loss 0.604
wandb:      train/policy_loss 0.09062
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.09062
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bp714fc9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080351-bp714fc9/logs
wandb: ERROR Run bp714fc9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zvuk99rq with config:
wandb: 	actor_learning_rate: 9.716960961869669e-06
wandb: 	attention_dropout_p: 0.17590590943126294
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5801564342496827
wandb: 	temperature: 9.75887942703739
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080723-zvuk99rq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvuk99rq
wandb: uploading history steps 106-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–…â–…â–…â–ˆâ–ˆâ–‡â–†â–ˆâ–„â–ˆâ–ˆâ–‚â–‚â–…â–‡â–ˆâ–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–…â–ˆâ–†â–ˆâ–…â–…â–‡â–â–…â–ˆâ–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–â–„â–ƒâ–†â–â–„â–â–â–ƒâ–…â–ƒâ–â–â–‡â–â–â–†â–†â–„â–‡â–â–„â–†â–â–„â–†â–â–„â–ƒâ–â–â–â–â–„â–†â–†â–ˆâ–â–â–
wandb:       eval/ensemble_f1 â–‡â–…â–â–…â–ˆâ–…â–ˆâ–‡â–ˆâ–…â–…â–…â–‡â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–…â–ˆâ–‡â–…â–â–ˆâ–„â–…â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‚
wandb:           train/avg_f1 â–ƒâ–‡â–†â–…â–‡â–…â–‡â–…â–ˆâ–„â–†â–„â–…â–‡â–†â–‡â–„â–‚â–†â–ƒâ–ƒâ–„â–†â–â–†â–…â–ƒâ–ˆâ–†â–†â–‡â–†â–‚â–†â–ƒâ–…â–†â–‡â–†â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–„â–†â–…â–†â–†â–„â–ƒâ–†â–…â–†â–…â–†â–„â–…â–‡â–†â–†â–†â–â–„â–‡â–…â–…â–†â–„â–…â–„â–ˆâ–ƒâ–„â–…â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–†â–†
wandb:         train/mil_loss â–…â–„â–„â–„â–ƒâ–‚â–„â–…â–…â–„â–ƒâ–†â–…â–…â–„â–‡â–†â–…â–†â–„â–ƒâ–ˆâ–„â–‚â–„â–…â–„â–…â–„â–ƒâ–†â–‡â–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„
wandb:      train/policy_loss â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–ˆâ–â–…â–ˆâ–…â–…â–ˆâ–â–â–…â–…â–ˆâ–â–…â–ˆâ–…â–…â–…â–…â–ˆâ–ˆâ–…â–ˆâ–â–…â–ˆâ–…â–…â–…â–…â–â–…â–â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.22151
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.67676
wandb:      eval/avg_mil_loss 1.44383
wandb:       eval/ensemble_f1 0.67676
wandb:           train/avg_f1 0.8629
wandb:      train/ensemble_f1 0.8629
wandb:         train/mil_loss 0.49143
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvuk99rq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080723-zvuk99rq/logs
wandb: ERROR Run zvuk99rq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mnhj0t9s with config:
wandb: 	actor_learning_rate: 5.936592791705304e-06
wandb: 	attention_dropout_p: 0.4671643171663796
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24894286823307463
wandb: 	temperature: 7.159764619323256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080912-mnhj0t9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnhj0t9s
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–‡â–ˆâ–†â–ƒâ–ˆâ–â–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–„â–‡â–ˆâ–‡â–…â–ˆâ–ˆâ–‚â–…â–ˆâ–ˆâ–ƒâ–ˆâ–‡â–…â–„â–„â–ˆâ–„â–ˆâ–„â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–â–„â–…â–…â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–„â–ƒâ–…â–â–‡â–‡â–…â–…â–ƒâ–â–„â–‡â–ˆâ–ƒâ–‚â–â–â–ƒâ–…â–„â–„â–â–„â–†â–ƒâ–„â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ƒâ–ˆâ–â–ˆâ–ƒâ–ˆâ–ˆâ–ƒâ–ƒâ–‡â–‡â–†â–ˆâ–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–„â–„â–‡â–„â–†â–ˆâ–ˆâ–‡â–ˆ
wandb:           train/avg_f1 â–‡â–…â–†â–…â–„â–‡â–…â–…â–…â–…â–â–„â–†â–†â–†â–†â–ˆâ–…â–…â–„â–†â–…â–…â–‡â–…â–…â–…â–…â–†â–„â–†â–†â–‡â–‡â–„â–‚â–ƒâ–„â–‡â–…
wandb:      train/ensemble_f1 â–‡â–ƒâ–ƒâ–†â–ˆâ–‡â–ƒâ–„â–†â–…â–…â–…â–‡â–ˆâ–…â–†â–„â–ˆâ–…â–†â–‡â–†â–†â–„â–„â–†â–„â–…â–„â–†â–‡â–‡â–‡â–†â–ƒâ–‚â–ˆâ–‡â–â–„
wandb:         train/mil_loss â–…â–„â–„â–â–†â–…â–…â–†â–ƒâ–ƒâ–â–„â–…â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–…â–‡â–…â–…â–ƒâ–â–â–†â–ƒâ–ƒâ–„â–†â–ƒâ–†â–ƒâ–ˆ
wandb:      train/policy_loss â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–ˆâ–…â–â–â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.2513
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.78286
wandb:      eval/avg_mil_loss 1.60067
wandb:       eval/ensemble_f1 0.78286
wandb:           train/avg_f1 0.81605
wandb:      train/ensemble_f1 0.81605
wandb:         train/mil_loss 2.07481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zesty-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnhj0t9s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080912-mnhj0t9s/logs
wandb: ERROR Run mnhj0t9s errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: i503qan7 with config:
wandb: 	actor_learning_rate: 0.00019879629590319688
wandb: 	attention_dropout_p: 0.038755654773574955
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7708508807262189
wandb: 	temperature: 7.170663149433617
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081101-i503qan7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i503qan7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‚â–ˆâ–‚â–†â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–…â–„â–„â–â–‡â–ˆâ–†â–„â–ˆâ–„â–ˆâ–ˆâ–†â–†â–ƒâ–‡â–ˆâ–‡â–†â–‡â–†â–ˆâ–‚â–‡â–ƒâ–‡â–…â–ƒâ–‡â–†â–„â–‡â–†â–…â–ƒâ–„â–„â–†
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–â–…â–‡â–„â–„â–ƒâ–…â–ƒâ–‡â–„â–‡â–â–†â–â–ƒâ–â–ˆâ–ƒâ–â–‡â–†â–â–„â–„â–‚â–‚â–…â–â–…â–„â–†â–†â–„â–ƒâ–ƒâ–â–…
wandb:       eval/ensemble_f1 â–…â–…â–„â–†â–ƒâ–ƒâ–„â–ƒâ–‚â–‡â–†â–‚â–…â–ƒâ–‚â–†â–ˆâ–ˆâ–†â–ƒâ–„â–ƒâ–„â–ˆâ–â–‡â–â–„â–‡â–†â–†â–…â–ƒâ–…â–„â–…â–‚â–‚â–„â–‡
wandb:           train/avg_f1 â–…â–„â–ƒâ–â–†â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–„â–…â–„â–…â–‡â–„â–…â–ƒâ–†â–‚â–ƒâ–‡â–‡â–ƒâ–ƒâ–„â–…â–ˆâ–„â–ƒâ–…â–ƒâ–†â–„â–„â–‚â–ƒ
wandb:      train/ensemble_f1 â–‡â–…â–„â–†â–„â–†â–‡â–…â–ƒâ–„â–‡â–…â–…â–…â–…â–…â–†â–ˆâ–…â–†â–„â–…â–†â–„â–„â–ˆâ–†â–„â–â–„â–ˆâ–…â–‡â–…â–…â–‡â–ƒâ–„â–…â–ˆ
wandb:         train/mil_loss â–ƒâ–‚â–†â–…â–ƒâ–„â–„â–„â–ˆâ–„â–…â–…â–ƒâ–ˆâ–„â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–„â–‚â–‚â–‚â–„â–‚â–â–ƒâ–„â–‚â–‚â–‚â–„â–…â–â–„â–„
wandb:      train/policy_loss â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91069
wandb: best/eval_avg_mil_loss 0.22223
wandb:  best/eval_ensemble_f1 0.91069
wandb:            eval/avg_f1 0.84259
wandb:      eval/avg_mil_loss 0.9915
wandb:       eval/ensemble_f1 0.84259
wandb:           train/avg_f1 0.84338
wandb:      train/ensemble_f1 0.84338
wandb:         train/mil_loss 1.02843
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i503qan7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081101-i503qan7/logs
wandb: ERROR Run i503qan7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lrg4avj8 with config:
wandb: 	actor_learning_rate: 0.0007817875934294041
wandb: 	attention_dropout_p: 0.33794260021191563
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.607991116314001
wandb: 	temperature: 8.069983236431668
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081346-lrg4avj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lrg4avj8
wandb: uploading history steps 105-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‡â–ƒâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–†â–…â–‡â–…â–…â–‡â–‡â–ˆâ–‡â–…â–‡â–ˆâ–‡â–ˆâ–‡â–„â–ˆâ–„â–ˆâ–†â–†â–„â–†â–ƒâ–
wandb:      eval/avg_mil_loss â–„â–ˆâ–‚â–â–„â–â–„â–â–…â–â–„â–‡â–ƒâ–…â–â–‚â–‚â–â–‚â–ƒâ–‡â–„â–‡â–â–â–â–â–â–…â–ƒâ–†â–ƒâ–â–â–‡â–†â–ƒâ–‚â–‡â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–…â–„â–‡â–‡â–…â–â–ˆâ–ˆâ–„â–ˆâ–ˆâ–‡â–„â–…â–…â–‡â–‡â–…â–‡â–ˆâ–â–ƒâ–…â–‡â–„â–†â–†â–ˆâ–†â–†â–…â–†â–ƒâ–†â–†â–‡â–ˆâ–ˆ
wandb:           train/avg_f1 â–â–‚â–…â–†â–â–…â–†â–…â–†â–…â–†â–…â–„â–†â–…â–†â–ˆâ–…â–ƒâ–†â–…â–‡â–ƒâ–â–…â–…â–ƒâ–†â–‚â–†â–ƒâ–â–‚â–ƒâ–…â–†â–ˆâ–„â–†â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–„â–‡â–ƒâ–â–ƒâ–„â–‡â–‚â–…â–„â–†â–„â–†â–ˆâ–ƒâ–ˆâ–„â–…â–†â–ƒâ–†â–†â–„â–„â–‡â–†â–†â–ƒâ–†â–ƒâ–…â–†â–‚â–â–„â–ƒâ–â–†â–ƒ
wandb:         train/mil_loss â–ƒâ–ƒâ–„â–ƒâ–ˆâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–„â–„â–„â–‚â–…â–„â–ƒâ–…â–ƒâ–‚â–â–†â–‚â–„â–„â–ƒâ–‚â–†â–ƒâ–ƒâ–ˆâ–„â–„â–‚â–‡â–‚â–„â–„
wandb:      train/policy_loss â–†â–†â–â–†â–ƒâ–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92587
wandb: best/eval_avg_mil_loss 0.26682
wandb:  best/eval_ensemble_f1 0.92587
wandb:            eval/avg_f1 0.90758
wandb:      eval/avg_mil_loss 0.2852
wandb:       eval/ensemble_f1 0.90758
wandb:           train/avg_f1 0.8117
wandb:      train/ensemble_f1 0.8117
wandb:         train/mil_loss 0.62044
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run still-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lrg4avj8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081346-lrg4avj8/logs
wandb: ERROR Run lrg4avj8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: um2ms642 with config:
wandb: 	actor_learning_rate: 1.7235845192372547e-06
wandb: 	attention_dropout_p: 0.05475548032213695
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2951514724188967
wandb: 	temperature: 2.9863485681971733
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081529-um2ms642
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/um2ms642
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–ˆâ–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–†â–„â–†â–†â–‚â–‡â–ƒâ–†â–â–†â–‡â–„â–‡â–ƒâ–„â–…â–‡â–…â–ˆâ–†â–…â–â–‡â–‡â–ˆâ–…â–ƒâ–…â–†â–‡â–‡â–ƒâ–†â–…â–„â–…â–‡â–†â–…â–…
wandb:      eval/avg_mil_loss â–â–„â–„â–‚â–‚â–…â–‚â–ˆâ–‚â–â–„â–â–†â–â–â–ƒâ–„â–â–â–â–‡â–ƒâ–„â–‚â–â–†â–‚â–…â–‚â–‚â–ƒâ–â–‚â–…â–…â–ƒâ–â–â–â–ƒ
wandb:       eval/ensemble_f1 â–‡â–†â–ƒâ–†â–†â–‡â–‚â–†â–†â–…â–‡â–ƒâ–†â–‡â–‡â–ˆâ–„â–†â–†â–†â–‡â–‡â–…â–â–ˆâ–ƒâ–‡â–…â–†â–…â–‡â–‚â–‡â–‚â–†â–„â–‡â–‡â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–‡â–ƒâ–ˆâ–ƒâ–„â–â–ˆâ–„â–„â–‡â–„â–‡â–‚â–†â–ƒâ–„â–‚â–‚â–…â–…â–ƒâ–…â–„â–‚â–ƒâ–†â–…â–…â–†â–…â–‚â–„â–…â–…â–‚â–‡â–ƒâ–ƒâ–…
wandb:      train/ensemble_f1 â–„â–‡â–…â–„â–„â–ˆâ–…â–†â–…â–‡â–…â–‡â–‡â–„â–„â–†â–†â–„â–…â–†â–†â–…â–…â–…â–„â–†â–†â–ˆâ–†â–†â–†â–…â–†â–â–„â–ƒâ–‡â–‡â–„â–‡
wandb:         train/mil_loss â–ƒâ–ƒâ–ˆâ–ˆâ–„â–â–â–ƒâ–‚â–…â–‡â–„â–…â–„â–ˆâ–ƒâ–ƒâ–‚â–‚â–†â–†â–†â–„â–…â–†â–…â–„â–…â–…â–ƒâ–„â–…â–‡â–‡â–„â–‚â–„â–‡â–‡â–ƒ
wandb:      train/policy_loss â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–„â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93735
wandb: best/eval_avg_mil_loss 0.21837
wandb:  best/eval_ensemble_f1 0.93735
wandb:            eval/avg_f1 0.85398
wandb:      eval/avg_mil_loss 0.72475
wandb:       eval/ensemble_f1 0.85398
wandb:            test/avg_f1 0.88427
wandb:      test/avg_mil_loss 0.43341
wandb:       test/ensemble_f1 0.88427
wandb:           train/avg_f1 0.86885
wandb:      train/ensemble_f1 0.86885
wandb:         train/mil_loss 0.74832
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run toasty-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/um2ms642
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081529-um2ms642/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 72dqvrul with config:
wandb: 	actor_learning_rate: 4.136593160895814e-05
wandb: 	attention_dropout_p: 0.3992303130650154
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.943509210515096
wandb: 	temperature: 8.974601506421592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081707-72dqvrul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/72dqvrul
wandb: uploading wandb-summary.json; uploading history steps 88-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–ƒâ–‚â–‡â–‚â–â–‡â–‡â–ƒâ–ˆâ–ˆâ–ƒâ–ˆâ–…â–ˆâ–ˆâ–‡â–†â–ƒâ–‚â–‡â–‡â–†â–ƒâ–ˆâ–‚â–‡â–†â–†â–„â–‡â–‡â–‡â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–â–â–â–„â–ƒâ–â–ƒâ–†â–â–â–â–â–â–…â–„â–„â–â–â–â–ƒâ–„â–…â–â–„â–â–â–…â–ƒâ–†â–â–â–…â–ƒâ–â–â–…â–â–ƒâ–†â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–…â–…â–â–‚â–‡â–…â–…â–†â–ˆâ–‡â–‡â–‡â–…â–…â–ˆâ–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–‡â–‚â–‡â–…â–ˆâ–ˆâ–â–‡â–…â–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–…
wandb:           train/avg_f1 â–†â–„â–…â–„â–…â–ƒâ–ˆâ–†â–†â–‚â–†â–„â–ƒâ–„â–†â–…â–â–…â–„â–ƒâ–…â–ƒâ–‚â–†â–…â–‡â–†â–„â–…â–†â–„â–ƒâ–ˆâ–„â–ƒâ–„â–„â–…â–†â–„
wandb:      train/ensemble_f1 â–„â–…â–…â–„â–„â–‚â–‚â–ˆâ–‚â–…â–‡â–ƒâ–†â–…â–†â–…â–„â–‚â–…â–„â–†â–â–…â–…â–‡â–„â–†â–„â–…â–ˆâ–ƒâ–ƒâ–ˆâ–…â–„â–‡â–†â–„â–†â–„
wandb:         train/mil_loss â–ˆâ–ƒâ–‚â–…â–ƒâ–‡â–â–„â–ˆâ–„â–„â–„â–…â–‡â–‡â–„â–…â–ƒâ–‡â–â–‡â–‡â–ƒâ–†â–„â–ƒâ–‡â–„â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–„â–†â–ƒâ–ƒâ–†â–ƒâ–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.24182
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.59186
wandb:      eval/avg_mil_loss 4.24671
wandb:       eval/ensemble_f1 0.59186
wandb:           train/avg_f1 0.79013
wandb:      train/ensemble_f1 0.79013
wandb:         train/mil_loss 0.8126
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run giddy-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/72dqvrul
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081707-72dqvrul/logs
wandb: ERROR Run 72dqvrul errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xl1vgyc4 with config:
wandb: 	actor_learning_rate: 0.0007972088751073179
wandb: 	attention_dropout_p: 0.31381722004625023
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 115
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8148259135402944
wandb: 	temperature: 6.221440789447984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081851-xl1vgyc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xl1vgyc4
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–…â–„â–ˆâ–…â–‚â–â–…â–ƒâ–ƒâ–„â–ƒâ–‡â–ƒâ–…â–…â–…â–‚â–…â–‚â–…â–ƒâ–ƒâ–ˆâ–„â–ƒâ–â–…â–ƒâ–‡â–…â–ƒâ–„â–…â–…â–…â–„â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–…â–â–…â–‡â–‚â–ˆâ–‡â–ƒâ–‡â–‡â–„â–ˆâ–„â–„â–ƒâ–‡â–†â–„â–…â–â–‡â–‡â–…â–â–‡â–†â–‡â–…â–ƒâ–…â–„â–ƒâ–…â–†â–…â–…â–†â–…â–…â–†
wandb:       eval/ensemble_f1 â–ˆâ–„â–ˆâ–„â–â–ƒâ–‚â–…â–…â–‚â–„â–„â–…â–‡â–„â–ƒâ–…â–…â–â–ˆâ–‚â–‚â–†â–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–„â–„â–‚â–‡â–„â–†â–‚â–ˆ
wandb:           train/avg_f1 â–…â–…â–„â–„â–ƒâ–…â–ˆâ–„â–…â–â–…â–‚â–ƒâ–‡â–†â–â–†â–ƒâ–…â–ƒâ–†â–…â–†â–†â–…â–„â–ƒâ–…â–„â–ƒâ–„â–…â–„â–„â–‡â–ƒâ–‡â–…â–‚â–…
wandb:      train/ensemble_f1 â–†â–…â–…â–‡â–†â–„â–…â–ƒâ–ˆâ–â–‚â–†â–‡â–…â–…â–ƒâ–…â–‡â–ƒâ–†â–†â–…â–ƒâ–†â–ˆâ–ƒâ–ƒâ–…â–…â–ƒâ–„â–‡â–†â–‚â–…â–„â–ƒâ–…â–„â–ƒ
wandb:         train/mil_loss â–„â–†â–â–†â–‡â–†â–„â–†â–„â–‚â–…â–„â–„â–…â–„â–ƒâ–ƒâ–â–„â–…â–„â–ƒâ–ƒâ–…â–…â–‡â–ƒâ–ƒâ–…â–ƒâ–‡â–ˆâ–ƒâ–„â–‚â–ƒâ–â–„â–†â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91535
wandb: best/eval_avg_mil_loss 0.28679
wandb:  best/eval_ensemble_f1 0.91535
wandb:            eval/avg_f1 0.91184
wandb:      eval/avg_mil_loss 0.25608
wandb:       eval/ensemble_f1 0.91184
wandb:           train/avg_f1 0.70132
wandb:      train/ensemble_f1 0.70132
wandb:         train/mil_loss 2.32785
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hopeful-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xl1vgyc4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081851-xl1vgyc4/logs
wandb: ERROR Run xl1vgyc4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 37gbwi5s with config:
wandb: 	actor_learning_rate: 0.00013847489226039838
wandb: 	attention_dropout_p: 0.34606599783448316
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8598260138878141
wandb: 	temperature: 8.177830781098981
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082028-37gbwi5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37gbwi5s
wandb: uploading wandb-summary.json
wandb: uploading history steps 87-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‡â–…â–ˆâ–‚â–ˆâ–…â–†â–†â–ˆâ–†â–‡â–ƒâ–…â–ˆâ–„â–â–ˆâ–‡â–‡â–…â–„â–…â–ˆâ–ˆâ–…â–ˆâ–‡â–…â–ˆâ–ˆâ–…â–†â–…â–‡â–‡â–‡â–‡â–†
wandb:      eval/avg_mil_loss â–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…â–…â–‚â–„â–†â–…â–ˆâ–„â–â–‚â–‚â–ƒâ–‚â–â–„â–‡â–†â–ƒâ–â–ƒâ–â–ƒâ–â–†â–„â–…â–…â–ƒâ–â–„â–„â–
wandb:       eval/ensemble_f1 â–ˆâ–‡â–…â–‡â–†â–†â–‚â–ˆâ–…â–†â–†â–…â–†â–†â–…â–…â–â–‡â–ˆâ–†â–‡â–…â–…â–„â–…â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–…â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ƒâ–â–ƒâ–…â–ƒâ–„â–ƒâ–‡â–…â–…â–ˆâ–„â–„â–…â–‡â–‚â–‡â–„â–‡â–„â–„â–‡â–ƒâ–„â–â–…â–†â–…â–ƒâ–†â–„â–ƒâ–…â–…â–ƒâ–…â–…â–‚â–…
wandb:      train/ensemble_f1 â–â–…â–…â–ƒâ–‡â–‡â–‚â–†â–„â–ƒâ–„â–…â–„â–„â–ˆâ–†â–…â–…â–†â–†â–ˆâ–ˆâ–ƒâ–†â–…â–‡â–†â–…â–ƒâ–„â–†â–„â–…â–…â–†â–„â–‡â–‡â–‡â–†
wandb:         train/mil_loss â–ƒâ–†â–…â–†â–…â–„â–ƒâ–„â–†â–†â–„â–„â–†â–„â–ƒâ–‡â–ƒâ–â–†â–ƒâ–„â–†â–ƒâ–‡â–†â–…â–…â–ƒâ–ˆâ–„â–‡â–ƒâ–ƒâ–ƒâ–ˆâ–†â–ƒâ–„â–†â–ˆ
wandb:      train/policy_loss â–ˆâ–„â–ˆâ–ˆâ–„â–„â–„â–â–„â–„â–â–â–ˆâ–ˆâ–„â–â–â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–â–â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–ˆâ–„â–„â–â–„â–â–„â–â–â–ˆâ–„â–ˆâ–â–ˆâ–â–„â–â–ˆâ–„â–„â–„â–„â–„â–â–„â–ˆâ–â–„â–„â–â–ˆâ–â–„â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91467
wandb: best/eval_avg_mil_loss 0.22875
wandb:  best/eval_ensemble_f1 0.91467
wandb:            eval/avg_f1 0.81748
wandb:      eval/avg_mil_loss 1.26382
wandb:       eval/ensemble_f1 0.81748
wandb:            test/avg_f1 0.73723
wandb:      test/avg_mil_loss 2.45205
wandb:       test/ensemble_f1 0.73723
wandb:           train/avg_f1 0.84357
wandb:      train/ensemble_f1 0.84357
wandb:         train/mil_loss 1.46248
wandb:      train/policy_loss 0.08466
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.08466
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dutiful-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37gbwi5s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082028-37gbwi5s/logs
wandb: Agent Starting Run: g9cqcfeq with config:
wandb: 	actor_learning_rate: 1.2049372854798869e-06
wandb: 	attention_dropout_p: 0.30580260708254675
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6153552994034045
wandb: 	temperature: 9.367453840990589
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082202-g9cqcfeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g9cqcfeq
wandb: uploading wandb-summary.json
wandb: uploading history steps 95-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–‡â–â–‡â–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–‡â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–ƒâ–„â–ˆâ–ˆâ–‡â–ƒâ–ˆâ–†â–‡â–ƒâ–ˆâ–„â–†â–‡â–‡
wandb:      eval/avg_mil_loss â–…â–â–ƒâ–â–ˆâ–‚â–…â–â–â–â–†â–†â–â–‚â–„â–ƒâ–â–…â–ƒâ–„â–‡â–â–ƒâ–â–„â–â–â–â–â–â–…â–†â–ƒâ–â–â–ƒâ–â–„â–…â–‚
wandb:       eval/ensemble_f1 â–†â–ˆâ–„â–ˆâ–‡â–„â–â–ˆâ–ˆâ–‡â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–‡â–â–ˆâ–ƒâ–‡â–ˆâ–â–†â–ˆâ–ˆâ–‡â–„â–†â–‡â–…â–ƒâ–ˆâ–†â–„â–‚â–†â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–…â–‡â–…â–ƒâ–…â–…â–‚â–„â–†â–‚â–„â–†â–ƒâ–‡â–†â–ƒâ–…â–…â–ƒâ–…â–ˆâ–ƒâ–‡â–…â–â–…â–‡â–„â–„â–ƒâ–…â–…â–„â–„â–…â–…â–†â–†â–…
wandb:      train/ensemble_f1 â–â–…â–‡â–…â–„â–ˆâ–ƒâ–†â–†â–„â–…â–†â–„â–‚â–†â–„â–‡â–„â–…â–â–…â–‡â–…â–…â–†â–ˆâ–…â–‡â–â–ˆâ–‚â–„â–…â–‡â–„â–…â–†â–…â–„â–†
wandb:         train/mil_loss â–…â–ƒâ–„â–ˆâ–ƒâ–ƒâ–â–ƒâ–…â–â–ƒâ–„â–ˆâ–‡â–„â–â–†â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–…â–‚â–…â–â–‡â–‚â–…â–‡â–ƒâ–„â–„â–„â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.26521
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.86496
wandb:      eval/avg_mil_loss 0.42088
wandb:       eval/ensemble_f1 0.86496
wandb:            test/avg_f1 0.92625
wandb:      test/avg_mil_loss 0.10919
wandb:       test/ensemble_f1 0.92625
wandb:           train/avg_f1 0.85515
wandb:      train/ensemble_f1 0.85515
wandb:         train/mil_loss 0.51613
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cosmic-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g9cqcfeq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082202-g9cqcfeq/logs
wandb: Agent Starting Run: p36bfc9w with config:
wandb: 	actor_learning_rate: 1.589104454854089e-05
wandb: 	attention_dropout_p: 0.3492315994987027
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2924159680607049
wandb: 	temperature: 5.936726164288872
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082330-p36bfc9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p36bfc9w
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–ˆâ–‡â–ˆâ–„â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–…â–†â–…â–‡â–„â–â–ˆâ–ˆâ–ˆâ–‡â–…â–‡â–ˆâ–‡â–‡â–…â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–„â–‡
wandb:      eval/avg_mil_loss â–ˆâ–â–â–â–â–â–â–â–â–†â–ˆâ–â–â–†â–â–â–ƒâ–‚â–†â–â–‚â–â–â–â–â–â–‡â–†â–â–‡â–ˆâ–â–‚â–ˆâ–â–â–â–â–â–†
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‚â–‡â–ƒâ–‡â–ˆâ–ˆâ–‚â–„â–…â–â–â–ˆâ–†â–‡â–‡â–ˆâ–‚â–†â–†â–‡â–‡â–ƒâ–‡â–â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–â–‚â–ƒâ–…â–ƒâ–„â–„â–‚â–„â–…â–…â–†â–†â–…â–‡â–â–ƒâ–†â–ƒâ–ˆâ–ˆâ–‡â–ƒâ–‡â–‚â–‡â–…â–†â–ƒâ–ƒâ–‚â–„â–†â–‚â–…â–†â–…â–â–‡â–†
wandb:      train/ensemble_f1 â–…â–‚â–†â–‡â–…â–‚â–‡â–â–ƒâ–†â–‡â–„â–‡â–â–‡â–†â–‡â–†â–…â–†â–ƒâ–†â–ˆâ–‡â–‡â–ˆâ–ƒâ–‚â–‚â–†â–†â–†â–…â–†â–ƒâ–‚â–‡â–†â–â–†
wandb:         train/mil_loss â–„â–„â–ƒâ–…â–ƒâ–‚â–†â–†â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–…â–â–…â–ˆâ–ƒâ–‚â–‚â–‚â–„â–ƒâ–â–„â–„â–…â–‚â–†â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92624
wandb: best/eval_avg_mil_loss 0.25416
wandb:  best/eval_ensemble_f1 0.92624
wandb:            eval/avg_f1 0.92281
wandb:      eval/avg_mil_loss 0.25672
wandb:       eval/ensemble_f1 0.92281
wandb:           train/avg_f1 0.85931
wandb:      train/ensemble_f1 0.85931
wandb:         train/mil_loss 0.54825
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run driven-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p36bfc9w
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082330-p36bfc9w/logs
wandb: ERROR Run p36bfc9w errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2qlf88sz with config:
wandb: 	actor_learning_rate: 2.5787642814173593e-05
wandb: 	attention_dropout_p: 0.1815326114714132
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6585852683516172
wandb: 	temperature: 3.1412137870204946
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082545-2qlf88sz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2qlf88sz
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 113-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‚â–ˆâ–‡â–‡â–ˆâ–ˆâ–â–ˆ
wandb:      eval/avg_mil_loss â–â–…â–â–‡â–â–â–â–â–â–â–â–…â–â–‡â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–…â–…â–…â–â–†â–â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:           train/avg_f1 â–†â–„â–ƒâ–„â–‡â–‡â–…â–‡â–ˆâ–‡â–„â–ƒâ–†â–‚â–„â–†â–‡â–…â–‡â–‚â–‚â–â–…â–‡â–†â–‡â–†â–„â–ƒâ–…â–ˆâ–„â–…â–†â–ˆâ–„â–ˆâ–ˆâ–„â–„
wandb:      train/ensemble_f1 â–…â–…â–†â–ƒâ–†â–‡â–ˆâ–…â–†â–„â–ƒâ–ƒâ–‚â–‡â–„â–„â–†â–†â–„â–‚â–…â–‡â–‚â–ˆâ–†â–â–†â–„â–‡â–ƒâ–„â–ˆâ–„â–†â–‡â–‡â–ˆâ–†â–ˆâ–„
wandb:         train/mil_loss â–â–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‡â–ƒâ–‚â–…â–‚â–â–…â–„â–„â–†â–‚â–†â–…â–ˆâ–ƒâ–ƒâ–â–„â–â–â–…â–„â–ƒâ–„â–„â–†â–…â–ƒâ–ƒâ–…â–â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–â–…â–…â–ˆâ–…â–â–…â–…â–â–…â–…â–â–…â–…â–â–…â–ˆâ–…â–…â–â–â–â–…â–â–â–…â–…â–â–…â–…â–…â–…â–ˆâ–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91813
wandb: best/eval_avg_mil_loss 0.27193
wandb:  best/eval_ensemble_f1 0.91813
wandb:            eval/avg_f1 0.77985
wandb:      eval/avg_mil_loss 0.57476
wandb:       eval/ensemble_f1 0.77985
wandb:           train/avg_f1 0.85048
wandb:      train/ensemble_f1 0.85048
wandb:         train/mil_loss 0.85151
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run legendary-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2qlf88sz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082545-2qlf88sz/logs
wandb: ERROR Run 2qlf88sz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3axpxefr with config:
wandb: 	actor_learning_rate: 0.00030726235587871494
wandb: 	attention_dropout_p: 0.25794683550111974
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8988832807002889
wandb: 	temperature: 7.762380141947375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082723-3axpxefr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3axpxefr
wandb: uploading history steps 52-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–‡â–â–‡â–‡â–‡â–â–„â–‡â–ƒâ–‚â–‡â–‡â–†â–‚â–…â–‡â–ƒâ–‡â–‡â–‚â–‚â–‡â–…â–…â–ˆâ–‡â–ƒâ–‡â–‡â–‡â–â–â–‡â–†â–†â–†â–‡â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–â–„â–…â–ƒâ–‚â–â–â–„â–‚â–„â–â–â–â–ˆâ–â–‚â–‚â–â–ˆâ–„â–„â–â–â–‡â–ƒâ–â–â–‚â–â–„â–â–‚â–…â–…â–‚â–„â–†â–â–„â–
wandb:       eval/ensemble_f1 â–‡â–‡â–…â–†â–‡â–„â–…â–‡â–„â–‡â–‡â–‡â–„â–†â–‡â–…â–‡â–‡â–â–„â–ˆâ–†â–†â–ˆâ–‡â–…â–‡â–ˆâ–„â–‡â–ƒâ–„â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†
wandb:           train/avg_f1 â–…â–ˆâ–‚â–†â–‚â–…â–„â–‚â–â–„â–ƒâ–†â–‚â–…â–ƒâ–…â–ƒâ–„â–‡â–ƒâ–„â–ƒâ–†â–„â–…â–‚â–„â–…â–â–„â–‚â–‚â–„â–…â–…â–†â–‚â–†â–„â–„
wandb:      train/ensemble_f1 â–†â–‚â–‡â–ˆâ–„â–…â–ƒâ–â–…â–…â–‡â–‚â–†â–ƒâ–„â–ƒâ–„â–…â–ƒâ–‡â–„â–‡â–‚â–…â–†â–†â–â–…â–ˆâ–‚â–…â–‚â–‡â–†â–†â–‚â–‡â–…â–ƒâ–‡
wandb:         train/mil_loss â–„â–„â–ƒâ–‡â–…â–†â–‚â–…â–ƒâ–‡â–…â–„â–†â–ˆâ–…â–‚â–…â–‚â–ƒâ–ˆâ–…â–‚â–„â–„â–…â–„â–„â–â–…â–†â–ƒâ–„â–…â–‚â–â–„â–ƒâ–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–„â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–„â–â–ˆâ–ˆâ–„â–ˆâ–â–â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–â–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–„â–â–ˆâ–ˆâ–â–„â–„â–„â–â–„â–ˆâ–â–â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–„â–„â–„â–„â–„â–â–â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.24595
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.88704
wandb:      eval/avg_mil_loss 0.28424
wandb:       eval/ensemble_f1 0.88704
wandb:           train/avg_f1 0.89541
wandb:      train/ensemble_f1 0.89541
wandb:         train/mil_loss 0.37901
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3axpxefr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082723-3axpxefr/logs
wandb: ERROR Run 3axpxefr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xkgh7eap with config:
wandb: 	actor_learning_rate: 6.828358932253308e-05
wandb: 	attention_dropout_p: 0.19510921580487683
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15545077262568965
wandb: 	temperature: 5.320886228542373
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082819-xkgh7eap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xkgh7eap
wandb: uploading history steps 108-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–…
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–„â–„â–†â–‡â–‚â–„â–â–‡â–„â–ˆâ–„â–…â–†â–ˆâ–†â–„â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆâ–ƒâ–„â–„â–…â–‡â–…â–†â–…â–„â–‡â–ƒâ–‡â–ˆâ–…â–‡
wandb:      eval/avg_mil_loss â–ˆâ–â–†â–ƒâ–ƒâ–†â–â–ƒâ–â–ƒâ–â–„â–‚â–â–â–ƒâ–‚â–â–â–‚â–ƒâ–â–ƒâ–â–‚â–„â–„â–‚â–‚â–ƒâ–…â–‚â–â–‚â–ƒâ–…â–â–â–…â–‚
wandb:       eval/ensemble_f1 â–â–†â–ƒâ–„â–‚â–†â–ˆâ–â–ˆâ–…â–ˆâ–†â–ƒâ–‡â–‡â–…â–†â–…â–‡â–…â–ˆâ–„â–ˆâ–„â–ƒâ–„â–‡â–†â–„â–†â–‡â–ˆâ–ˆâ–‡â–…â–…â–‡â–ˆâ–…â–…
wandb:           train/avg_f1 â–†â–ƒâ–ƒâ–†â–ˆâ–ƒâ–„â–‚â–‡â–…â–…â–„â–…â–†â–ƒâ–†â–…â–‡â–†â–„â–â–ƒâ–‡â–„â–†â–â–„â–„â–†â–…â–ˆâ–…â–ƒâ–‚â–‡â–†â–„â–†â–…â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–…â–ƒâ–ƒâ–†â–‚â–„â–†â–†â–‚â–ƒâ–‚â–‚â–„â–ƒâ–†â–…â–„â–…â–„â–ƒâ–…â–â–‚â–„â–‚â–…â–ƒâ–ƒâ–…â–‡â–…â–ƒâ–…â–ƒâ–ƒâ–…â–„â–ˆ
wandb:         train/mil_loss â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ˆâ–‚â–…â–â–„â–‚â–„â–‚â–‚â–â–„â–‚â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–â–„â–„â–‚â–„â–„â–‚â–‚â–ƒâ–‚â–â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.26553
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.89354
wandb:      eval/avg_mil_loss 0.39222
wandb:       eval/ensemble_f1 0.89354
wandb:           train/avg_f1 0.86712
wandb:      train/ensemble_f1 0.86712
wandb:         train/mil_loss 0.51772
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xkgh7eap
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082819-xkgh7eap/logs
wandb: ERROR Run xkgh7eap errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nub2gnhe with config:
wandb: 	actor_learning_rate: 1.1513533074087305e-05
wandb: 	attention_dropout_p: 0.28722782370516475
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7629796028748131
wandb: 	temperature: 4.484176983619163
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083040-nub2gnhe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nub2gnhe
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–„â–â–„â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–‡â–†â–„â–†â–†â–‚â–†â–â–…â–†â–ƒâ–„â–…â–…â–‚â–„â–„â–ƒâ–ƒâ–†â–„â–„â–…â–…â–‚â–†â–…â–â–…â–ƒâ–ƒâ–…â–„â–…â–†â–ˆâ–‚â–„â–†
wandb:      eval/avg_mil_loss â–‚â–…â–ƒâ–…â–„â–ƒâ–‚â–ƒâ–†â–†â–ˆâ–„â–„â–…â–†â–‚â–ˆâ–„â–‡â–‡â–â–…â–…â–â–…â–ƒâ–ƒâ–…â–‚â–ˆâ–„â–„â–…â–†â–â–„â–„â–ƒâ–‚â–‡
wandb:       eval/ensemble_f1 â–…â–†â–„â–„â–†â–‚â–†â–â–‚â–„â–„â–„â–„â–„â–†â–…â–…â–‡â–ƒâ–ˆâ–„â–â–‚â–…â–…â–„â–…â–ˆâ–ˆâ–‡â–‚â–†â–†â–…â–‡â–…â–†â–ˆâ–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–†â–…â–„â–„â–ƒâ–†â–„â–â–…â–â–„â–„â–…â–ƒâ–„â–„â–ƒâ–‡â–‡â–„â–„â–†â–„â–ˆâ–‡â–†â–†â–…â–‡â–„â–†â–…â–„â–†â–‡â–‡â–„â–†
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–„â–…â–†â–‡â–†â–…â–…â–†â–â–ƒâ–„â–†â–†â–„â–†â–ƒâ–†â–„â–„â–…â–„â–†â–†â–„â–„â–‡â–‡â–†â–ˆâ–‡â–†â–†â–…â–‡â–†â–„â–†
wandb:         train/mil_loss â–…â–„â–„â–â–…â–ƒâ–ƒâ–„â–ƒâ–â–…â–†â–…â–‡â–ƒâ–„â–„â–…â–„â–†â–…â–„â–…â–„â–ƒâ–ƒâ–…â–ƒâ–„â–…â–†â–‚â–„â–†â–„â–„â–ˆâ–†â–†â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90687
wandb: best/eval_avg_mil_loss 0.28421
wandb:  best/eval_ensemble_f1 0.90687
wandb:            eval/avg_f1 0.74696
wandb:      eval/avg_mil_loss 2.02059
wandb:       eval/ensemble_f1 0.74696
wandb:            test/avg_f1 0.79022
wandb:      test/avg_mil_loss 1.16154
wandb:       test/ensemble_f1 0.79022
wandb:           train/avg_f1 0.80245
wandb:      train/ensemble_f1 0.80245
wandb:         train/mil_loss 1.60555
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nub2gnhe
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083040-nub2gnhe/logs
wandb: Agent Starting Run: u0qbm9a0 with config:
wandb: 	actor_learning_rate: 1.065669522070243e-06
wandb: 	attention_dropout_p: 0.4384932760919677
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23104189107380557
wandb: 	temperature: 2.457361075154015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083310-u0qbm9a0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u0qbm9a0
wandb: uploading wandb-summary.json
wandb: uploading history steps 93-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–â–…â–ˆâ–ˆâ–‡â–…â–ˆâ–ˆâ–‚â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ƒâ–ˆâ–†
wandb:      eval/avg_mil_loss â–â–ƒâ–ƒâ–â–â–ƒâ–â–†â–â–â–â–â–‚â–‚â–â–ˆâ–‚â–†â–â–â–â–â–â–â–â–â–â–‚â–â–…â–†â–â–†â–â–â–â–â–‚â–â–‚
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–‡â–ˆâ–â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–â–‚â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–‚â–‚â–†â–ˆâ–ˆâ–ˆâ–‚â–†
wandb:           train/avg_f1 â–„â–…â–ƒâ–ƒâ–…â–â–ƒâ–‡â–‡â–„â–ˆâ–‡â–…â–ƒâ–‡â–‚â–ƒâ–†â–„â–…â–…â–‚â–…â–…â–„â–„â–ˆâ–„â–„â–†â–‡â–‚â–ƒâ–…â–ƒâ–‡â–„â–…â–„â–‡
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–…â–â–†â–„â–‡â–„â–„â–ƒâ–„â–‚â–„â–‚â–„â–ƒâ–†â–„â–„â–„â–†â–…â–…â–„â–ˆâ–„â–†â–†â–‡â–…â–…â–‚â–†â–…â–‚â–‡â–ƒâ–ƒâ–…â–‡
wandb:         train/mil_loss â–â–â–ƒâ–‚â–‡â–ƒâ–ƒâ–ƒâ–‚â–â–â–ƒâ–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–…â–‚â–â–‚â–„â–‚â–‚â–‚â–‚â–…â–…â–â–‚â–â–ˆâ–ƒâ–â–…â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–â–ˆâ–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–â–ˆâ–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93315
wandb: best/eval_avg_mil_loss 0.24765
wandb:  best/eval_ensemble_f1 0.93315
wandb:            eval/avg_f1 0.91886
wandb:      eval/avg_mil_loss 0.27091
wandb:       eval/ensemble_f1 0.91886
wandb:           train/avg_f1 0.87214
wandb:      train/ensemble_f1 0.87214
wandb:         train/mil_loss 0.7302
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run skilled-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u0qbm9a0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083310-u0qbm9a0/logs
wandb: ERROR Run u0qbm9a0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8l6lehnv with config:
wandb: 	actor_learning_rate: 4.2424525663552914e-05
wandb: 	attention_dropout_p: 0.3745240037204649
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34093043221355834
wandb: 	temperature: 0.9041547626777512
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083438-8l6lehnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8l6lehnv
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 175-183, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–â–‚â–ƒâ–ƒâ–â–â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–†â–†â–ˆâ–‡â–‡â–ˆâ–†â–…â–…â–‡â–‡â–‡â–„â–†â–…â–ˆâ–†â–ƒâ–â–‡â–ˆâ–†â–†â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–ˆâ–‡â–†â–†â–ˆâ–†â–‡
wandb:      eval/avg_mil_loss â–â–â–‡â–ƒâ–â–‚â–ˆâ–â–â–â–â–ƒâ–â–ƒâ–ƒâ–â–â–ƒâ–„â–‡â–„â–ƒâ–â–‚â–â–„â–ƒâ–†â–â–â–â–…â–…â–â–â–„â–‚â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–ˆâ–…â–…â–ˆâ–†â–ˆâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–â–†â–ˆâ–†â–…â–ˆâ–ˆâ–†â–ˆâ–‡â–…â–†â–ˆâ–†â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‡â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–…â–…â–†â–ƒâ–‚â–‡â–„â–ˆâ–‡â–…â–…â–‡â–†â–„â–…â–†â–†â–â–‡â–†â–‚â–†â–…â–ƒâ–…â–ˆâ–â–„â–‚â–ƒâ–„â–ƒ
wandb:      train/ensemble_f1 â–…â–â–ƒâ–…â–…â–„â–…â–†â–ƒâ–ƒâ–‚â–…â–…â–ƒâ–‚â–†â–ƒâ–„â–„â–„â–†â–ˆâ–…â–ƒâ–†â–†â–†â–„â–‡â–„â–„â–â–†â–‡â–†â–†â–‡â–…â–…â–„
wandb:         train/mil_loss â–…â–…â–ƒâ–†â–„â–ƒâ–‚â–‡â–‚â–‚â–…â–ƒâ–‚â–…â–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–†â–‚â–ˆâ–„â–„â–„â–„â–â–…â–ƒâ–‚â–†â–‡â–‚
wandb:      train/policy_loss â–„â–â–â–ˆâ–ˆâ–â–„â–ˆâ–„â–ˆâ–ˆâ–â–„â–â–ˆâ–ˆâ–„â–„â–ˆâ–â–â–ˆâ–ˆâ–â–â–â–ˆâ–â–â–„â–„â–â–ˆâ–„â–„â–„â–ˆâ–„â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93315
wandb: best/eval_avg_mil_loss 0.198
wandb:  best/eval_ensemble_f1 0.93315
wandb:            eval/avg_f1 0.92558
wandb:      eval/avg_mil_loss 0.19906
wandb:       eval/ensemble_f1 0.92558
wandb:            test/avg_f1 0.737
wandb:      test/avg_mil_loss 1.72477
wandb:       test/ensemble_f1 0.737
wandb:           train/avg_f1 0.88397
wandb:      train/ensemble_f1 0.88397
wandb:         train/mil_loss 0.45967
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run mild-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8l6lehnv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083438-8l6lehnv/logs
wandb: Agent Starting Run: 9m2f7ihc with config:
wandb: 	actor_learning_rate: 0.0002665565045102378
wandb: 	attention_dropout_p: 0.1552108650896208
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4740948453128271
wandb: 	temperature: 6.199731399486974
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083809-9m2f7ihc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9m2f7ihc
wandb: uploading history steps 121-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–…â–„â–‚â–†â–‡â–ƒâ–…â–†â–…â–ˆâ–„â–ƒâ–†â–ƒâ–…â–ƒâ–â–…â–„â–ˆâ–„â–ˆâ–…â–„â–ˆâ–…â–†â–…â–†â–…â–„â–…â–†â–‡â–ˆâ–†â–‡â–„â–„
wandb:      eval/avg_mil_loss â–â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–…â–†â–ƒâ–„â–†â–„â–â–ƒâ–„â–ˆâ–†â–‡â–‡â–„â–â–â–ƒâ–„â–†â–„â–â–„â–â–…â–ƒâ–â–â–ˆâ–„â–„â–„â–â–…
wandb:       eval/ensemble_f1 â–„â–ˆâ–„â–„â–„â–…â–‚â–‚â–ƒâ–ˆâ–ƒâ–‡â–„â–‚â–ˆâ–ˆâ–†â–†â–ˆâ–‡â–ˆâ–„â–‡â–â–…â–‡â–„â–†â–†â–…â–‡â–†â–‡â–‡â–…â–…â–…â–…â–ˆâ–ˆ
wandb:           train/avg_f1 â–†â–…â–…â–„â–‡â–„â–„â–…â–…â–†â–†â–…â–…â–…â–ƒâ–…â–‡â–‡â–ƒâ–„â–†â–…â–â–‚â–ƒâ–„â–„â–„â–„â–‡â–…â–„â–…â–…â–…â–ˆâ–…â–ƒâ–…â–‡
wandb:      train/ensemble_f1 â–„â–†â–„â–ƒâ–„â–ƒâ–…â–…â–†â–‚â–„â–‚â–„â–ƒâ–…â–…â–‡â–…â–†â–†â–‚â–‚â–…â–‚â–„â–„â–ƒâ–ƒâ–…â–ƒâ–„â–â–†â–ƒâ–†â–…â–ˆâ–ƒâ–†â–„
wandb:         train/mil_loss â–†â–ˆâ–…â–„â–…â–„â–„â–„â–„â–‡â–ƒâ–ˆâ–ƒâ–…â–†â–‚â–…â–„â–ƒâ–‡â–„â–ƒâ–‚â–ƒâ–…â–†â–†â–„â–„â–ˆâ–†â–…â–‡â–„â–†â–â–…â–‚â–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92542
wandb: best/eval_avg_mil_loss 0.22444
wandb:  best/eval_ensemble_f1 0.92542
wandb:            eval/avg_f1 0.80543
wandb:      eval/avg_mil_loss 1.23526
wandb:       eval/ensemble_f1 0.80543
wandb:           train/avg_f1 0.89062
wandb:      train/ensemble_f1 0.89062
wandb:         train/mil_loss 0.79067
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9m2f7ihc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083809-9m2f7ihc/logs
wandb: ERROR Run 9m2f7ihc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ffkxpghj with config:
wandb: 	actor_learning_rate: 1.744581767066708e-05
wandb: 	attention_dropout_p: 0.0028478083147970845
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02854590525715528
wandb: 	temperature: 7.964743754649168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084044-ffkxpghj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffkxpghj
wandb: uploading history steps 161-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–…â–ˆâ–‚â–â–â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–â–†â–…â–…â–†â–‡â–†â–†â–†â–†â–‡â–„â–‡â–‚â–‡â–…â–„â–‡â–†â–„â–‡â–ˆâ–„â–‡â–ƒâ–‡â–‡â–‡â–†â–‡â–‡â–…â–…â–‡â–ˆâ–‡â–†â–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–â–ƒâ–â–â–ƒâ–ˆâ–â–â–â–â–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–…â–â–ƒâ–â–â–â–„â–…â–‚â–‚â–â–â–ƒâ–â–â–„â–â–‚â–ƒâ–ƒâ–â–
wandb:       eval/ensemble_f1 â–„â–…â–„â–†â–†â–…â–†â–…â–‡â–„â–†â–â–ƒâ–„â–â–†â–ˆâ–†â–‡â–…â–†â–„â–ƒâ–„â–†â–ˆâ–†â–ƒâ–†â–†â–…â–†â–‡â–ƒâ–‡â–‡â–†â–‡â–…â–‡
wandb:           train/avg_f1 â–†â–…â–ƒâ–…â–…â–‡â–†â–…â–„â–„â–…â–…â–ƒâ–…â–‡â–‡â–…â–â–†â–‚â–‡â–‚â–„â–†â–„â–…â–…â–†â–…â–„â–†â–…â–…â–…â–…â–ˆâ–†â–‡â–…â–
wandb:      train/ensemble_f1 â–…â–„â–…â–‚â–ƒâ–„â–…â–…â–†â–…â–‡â–„â–‡â–‡â–„â–†â–…â–†â–‡â–…â–†â–â–ƒâ–†â–‚â–…â–„â–„â–‡â–…â–ƒâ–„â–ˆâ–„â–…â–ˆâ–…â–…â–„â–†
wandb:         train/mil_loss â–ƒâ–…â–ˆâ–ˆâ–ƒâ–‡â–â–‡â–ƒâ–„â–†â–…â–…â–„â–ƒâ–ƒâ–‡â–‚â–‚â–ˆâ–†â–ƒâ–…â–†â–†â–„â–ˆâ–„â–ƒâ–‡â–…â–†â–†â–…â–â–‡â–„â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93328
wandb: best/eval_avg_mil_loss 0.22973
wandb:  best/eval_ensemble_f1 0.93328
wandb:            eval/avg_f1 0.90344
wandb:      eval/avg_mil_loss 0.26925
wandb:       eval/ensemble_f1 0.90344
wandb:           train/avg_f1 0.87683
wandb:      train/ensemble_f1 0.87683
wandb:         train/mil_loss 0.57456
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polar-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffkxpghj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084044-ffkxpghj/logs
wandb: ERROR Run ffkxpghj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5pkxucx0 with config:
wandb: 	actor_learning_rate: 1.5423349222608305e-05
wandb: 	attention_dropout_p: 0.31019507390679624
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48602855131242506
wandb: 	temperature: 2.3063937322628982
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084355-5pkxucx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5pkxucx0
wandb: uploading history steps 116-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–…â–…â–ƒâ–ƒâ–â–ƒâ–„
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–…â–„â–†â–†â–…â–‡â–…â–†â–†â–‡â–‡â–‡â–ˆâ–†â–…â–‡â–†â–‡â–…â–†â–†â–‡â–ˆâ–â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‚â–‡â–ˆ
wandb:      eval/avg_mil_loss â–…â–…â–†â–…â–†â–†â–…â–†â–…â–ƒâ–‚â–…â–„â–…â–…â–ƒâ–„â–ˆâ–„â–†â–„â–…â–ƒâ–„â–ƒâ–â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–„â–„â–…â–‡â–…
wandb:       eval/ensemble_f1 â–ƒâ–†â–†â–†â–…â–„â–„â–‡â–„â–…â–†â–„â–„â–†â–†â–‚â–‡â–†â–…â–‡â–„â–‡â–…â–…â–‡â–†â–‡â–†â–‡â–†â–„â–„â–†â–‡â–‡â–…â–â–‡â–ˆâ–‡
wandb:           train/avg_f1 â–ƒâ–ƒâ–â–â–ƒâ–†â–ˆâ–‚â–ƒâ–‚â–…â–â–‚â–…â–‚â–…â–…â–…â–…â–„â–ƒâ–ƒâ–‡â–ƒâ–‡â–ƒâ–ƒâ–„â–…â–…â–‚â–†â–‚â–‡â–†â–‚â–‚â–ƒâ–†â–ƒ
wandb:      train/ensemble_f1 â–„â–ƒâ–â–„â–…â–ƒâ–†â–ˆâ–‚â–„â–ƒâ–ƒâ–…â–‡â–‚â–„â–„â–…â–‚â–„â–„â–„â–„â–‡â–‡â–‚â–„â–„â–„â–ƒâ–†â–„â–†â–…â–ƒâ–†â–†â–‚â–ƒâ–ƒ
wandb:         train/mil_loss â–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–â–ˆâ–†â–†â–„â–ƒâ–‚â–…â–â–ƒâ–‚â–‚â–‚â–‚â–†â–„â–â–…â–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–…â–‡â–ƒâ–â–…â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–ˆâ–…â–…â–…â–‚â–…â–…â–„â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9409
wandb: best/eval_avg_mil_loss 0.23052
wandb:  best/eval_ensemble_f1 0.9409
wandb:            eval/avg_f1 0.92964
wandb:      eval/avg_mil_loss 0.20832
wandb:       eval/ensemble_f1 0.92964
wandb:           train/avg_f1 0.91619
wandb:      train/ensemble_f1 0.91619
wandb:         train/mil_loss 0.21242
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swift-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5pkxucx0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084355-5pkxucx0/logs
wandb: ERROR Run 5pkxucx0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: s1u4mwlw with config:
wandb: 	actor_learning_rate: 2.320967819270162e-05
wandb: 	attention_dropout_p: 0.3979927928450333
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 190
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9581488696079604
wandb: 	temperature: 5.269330052076679
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084549-s1u4mwlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s1u4mwlw
wandb: uploading history steps 174-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–‡â–â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–‡â–…â–‡â–…â–…â–‡â–‡â–…â–…â–„â–‚â–‚â–‡â–‡â–„â–‚â–‚â–‡â–‡â–‡â–ˆâ–â–ˆâ–„â–†â–„â–‡â–†â–†â–†â–†â–†â–†â–„â–…â–ˆâ–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–â–ƒâ–ƒâ–ƒâ–†â–ƒâ–â–â–‚â–ƒâ–ƒâ–â–â–‚â–â–â–ˆâ–„â–â–‚â–†â–ƒâ–ƒâ–‚â–‚â–â–„â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–
wandb:       eval/ensemble_f1 â–†â–†â–…â–ˆâ–‡â–â–„â–‡â–ˆâ–ˆâ–†â–…â–‡â–„â–„â–ƒâ–ˆâ–„â–‡â–…â–‡â–†â–†â–†â–„â–‡â–ƒâ–„â–†â–†â–…â–‡â–‡â–…â–†â–‡â–…â–‡â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–…â–‡â–‡â–„â–‚â–†â–…â–„â–†â–„â–…â–„â–‡â–†â–‡â–„â–‚â–ˆâ–…â–„â–„â–†â–â–„â–…â–…â–ƒâ–ƒâ–ˆâ–ˆâ–…â–ˆâ–†â–…â–„â–„â–ƒâ–„â–„
wandb:      train/ensemble_f1 â–ƒâ–‡â–†â–†â–†â–„â–†â–‡â–…â–‡â–„â–†â–…â–ƒâ–…â–†â–†â–…â–†â–…â–‡â–‡â–‡â–†â–‡â–ƒâ–„â–ˆâ–ˆâ–…â–†â–…â–†â–…â–ƒâ–‡â–†â–â–…â–†
wandb:         train/mil_loss â–„â–‚â–‚â–ƒâ–†â–†â–â–†â–ƒâ–„â–ƒâ–‚â–„â–…â–…â–…â–…â–†â–…â–…â–ƒâ–…â–‡â–„â–…â–„â–ƒâ–…â–†â–ƒâ–…â–…â–„â–‚â–‚â–‡â–‚â–ˆâ–…â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–„â–â–â–„â–„â–â–â–â–â–„â–ˆâ–ˆâ–â–â–„â–„â–â–„â–â–â–ˆâ–â–„â–â–„â–„â–„â–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92573
wandb: best/eval_avg_mil_loss 0.19233
wandb:  best/eval_ensemble_f1 0.92573
wandb:            eval/avg_f1 0.82481
wandb:      eval/avg_mil_loss 1.65905
wandb:       eval/ensemble_f1 0.82481
wandb:            test/avg_f1 0.85173
wandb:      test/avg_mil_loss 0.8246
wandb:       test/ensemble_f1 0.85173
wandb:           train/avg_f1 0.85146
wandb:      train/ensemble_f1 0.85146
wandb:         train/mil_loss 0.5381
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run gallant-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s1u4mwlw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084549-s1u4mwlw/logs
wandb: Agent Starting Run: xxs821lf with config:
wandb: 	actor_learning_rate: 0.0009092507311817712
wandb: 	attention_dropout_p: 0.41897401833862347
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3258535731656551
wandb: 	temperature: 8.157191668244417
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084920-xxs821lf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxs821lf
wandb: uploading history steps 117-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–ƒâ–‡â–…â–‡â–â–‚â–…â–ˆâ–„â–†â–‡â–ƒâ–…â–ˆâ–„â–‡â–†â–…â–‡â–â–†â–†â–ƒâ–†â–„â–†â–‡â–‚â–†â–‡â–…â–‡â–†â–‡â–ˆâ–†â–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–‚â–†â–ƒâ–â–…â–â–ƒâ–ƒâ–„â–†â–„â–…â–â–„â–ˆâ–„â–ˆâ–†â–…â–…â–„â–…â–…â–ƒâ–„â–‚â–ƒâ–†â–ƒâ–„â–ƒâ–…â–…â–â–ƒâ–…â–ƒâ–‡
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ˆâ–„â–ƒâ–‡â–…â–ˆâ–â–‚â–…â–…â–…â–„â–†â–„â–†â–‡â–†â–ˆâ–‡â–â–â–„â–ƒâ–„â–„â–‡â–‚â–„â–‡â–†â–„â–‡â–‡â–ƒâ–ˆâ–…â–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–…â–ƒâ–„â–†â–†â–…â–ˆâ–†â–†â–…â–…â–ƒâ–„â–ƒâ–†â–…â–†â–„â–„â–ƒâ–„â–†â–„â–…â–„â–„â–†â–†â–‡â–…â–…â–†â–ƒâ–‚â–„â–…â–â–…
wandb:      train/ensemble_f1 â–‡â–…â–‡â–‡â–‡â–‡â–‡â–†â–„â–…â–†â–„â–‡â–‡â–‡â–‡â–ˆâ–†â–…â–„â–ƒâ–†â–‡â–ƒâ–…â–„â–‡â–†â–ˆâ–†â–†â–†â–‡â–…â–†â–â–†â–†â–†â–†
wandb:         train/mil_loss â–…â–ˆâ–…â–…â–…â–‚â–„â–…â–â–ƒâ–†â–…â–ƒâ–…â–„â–…â–„â–…â–„â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–†â–„â–â–ƒâ–‚â–‡â–†â–â–„â–‚â–„â–†â–„â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–…â–…â–…â–…â–ˆâ–â–â–…â–ˆâ–â–…â–â–â–…â–…â–…â–…â–…â–â–â–…â–â–â–…â–…â–ˆâ–…â–â–…â–â–ˆâ–â–ˆâ–…â–…â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.19113
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.7763
wandb:      eval/avg_mil_loss 2.49389
wandb:       eval/ensemble_f1 0.7763
wandb:            test/avg_f1 0.69284
wandb:      test/avg_mil_loss 1.8577
wandb:       test/ensemble_f1 0.69284
wandb:           train/avg_f1 0.81511
wandb:      train/ensemble_f1 0.81511
wandb:         train/mil_loss 1.28255
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxs821lf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084920-xxs821lf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dwrgdmna with config:
wandb: 	actor_learning_rate: 1.0638809379099498e-06
wandb: 	attention_dropout_p: 0.4751366924658339
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9124860397246376
wandb: 	temperature: 8.417063628108412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085125-dwrgdmna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dwrgdmna
wandb: uploading wandb-summary.json
wandb: uploading history steps 73-80, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–„â–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–‡â–ˆâ–‡â–‡â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–â–â–â–â–â–„â–â–â–…â–ˆâ–â–…â–â–â–â–â–â–â–â–†â–â–â–†â–â–â–â–â–†â–â–â–â–â–ˆâ–ˆâ–â–â–â–â–â–
wandb:       eval/ensemble_f1 â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–‡â–ˆâ–‡â–‚â–ˆâ–ˆâ–‚â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‚â–ˆâ–…â–‚â–ƒâ–„â–‡â–„â–†â–†â–„â–‡â–‡â–†â–†â–…â–‡â–…â–†â–‚â–„â–…â–…â–†â–‡â–‚â–ƒâ–‡â–‡â–†â–â–‡â–†â–ˆâ–â–‡â–‡â–‡â–‚
wandb:      train/ensemble_f1 â–‡â–…â–ƒâ–†â–„â–‡â–…â–…â–†â–‡â–„â–…â–†â–‡â–â–†â–ˆâ–‡â–†â–…â–…â–†â–‡â–†â–…â–‡â–ƒâ–„â–‡â–ƒâ–…â–‚â–†â–‡â–ˆâ–„â–‡â–‚â–…â–ƒ
wandb:         train/mil_loss â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–†â–ƒâ–â–„â–â–‚â–â–†â–…â–ƒâ–ˆâ–ƒâ–„â–‚â–ƒâ–â–„â–â–â–„â–‚â–‚â–ƒâ–„â–…â–â–„â–…â–ƒâ–„â–‚â–ƒ
wandb:      train/policy_loss â–â–â–…â–…â–â–â–…â–…â–ˆâ–…â–â–â–…â–â–…â–ˆâ–…â–â–…â–…â–…â–…â–â–â–…â–ˆâ–ˆâ–…â–ˆâ–â–…â–ˆâ–…â–ˆâ–…â–…â–…â–â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–…â–â–â–…â–â–…â–…â–…â–…â–â–â–â–…â–…â–ˆâ–…â–â–â–â–…â–…â–â–…â–â–…â–ˆâ–â–â–â–…â–…â–…â–â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.28101
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.89312
wandb:      eval/avg_mil_loss 0.28002
wandb:       eval/ensemble_f1 0.89312
wandb:            test/avg_f1 0.92307
wandb:      test/avg_mil_loss 0.16173
wandb:       test/ensemble_f1 0.92307
wandb:           train/avg_f1 0.84383
wandb:      train/ensemble_f1 0.84383
wandb:         train/mil_loss 0.63829
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run swift-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dwrgdmna
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085125-dwrgdmna/logs
wandb: Agent Starting Run: mk6lw00s with config:
wandb: 	actor_learning_rate: 0.00010770068133216093
wandb: 	attention_dropout_p: 0.1160824787995532
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 155
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7796282350137056
wandb: 	temperature: 3.7551350921660065
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085238-mk6lw00s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mk6lw00s
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–†
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–„â–ˆâ–…â–…â–…â–…â–†â–‡â–†â–„â–…â–…â–‡â–„â–‡â–„â–…â–„â–ƒâ–â–…â–‡â–„â–‚â–…â–„â–„â–„â–„â–„â–‚â–…â–ˆâ–„â–„â–‡â–‚
wandb:      eval/avg_mil_loss â–ƒâ–…â–â–…â–ƒâ–„â–‡â–„â–†â–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–†â–„â–…â–ƒâ–„â–‚â–ƒâ–‚â–ˆâ–ƒâ–„â–„â–„â–‡â–‚â–„â–…â–…â–‡â–‡â–„â–„â–„â–…â–†
wandb:       eval/ensemble_f1 â–„â–‡â–†â–„â–„â–…â–ƒâ–†â–„â–„â–„â–…â–…â–†â–„â–ˆâ–‡â–„â–„â–„â–†â–‡â–„â–„â–ƒâ–â–‡â–…â–„â–â–ƒâ–ˆâ–…â–ˆâ–‚â–…â–„â–†â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–…â–‚â–…â–ƒâ–…â–ƒâ–ƒâ–…â–†â–„â–…â–…â–â–…â–†â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ˆâ–ˆâ–‡â–ƒâ–„â–‚â–‚â–ˆâ–ƒâ–„â–…â–ƒâ–…â–‚â–„â–…â–„
wandb:      train/ensemble_f1 â–‡â–†â–‡â–…â–‡â–‡â–‚â–„â–ƒâ–†â–…â–‚â–…â–…â–…â–†â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–„â–ˆâ–„â–†â–‡â–„â–ƒâ–â–…â–ˆâ–…â–ƒâ–„â–„â–„â–‚â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–…â–†â–…â–…â–ƒâ–‡â–†â–ƒâ–‚â–ˆâ–…â–†â–…â–â–ƒâ–…â–„â–‚â–„â–†â–ƒâ–†â–ƒâ–„â–‡â–â–…â–…â–…â–†â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–‚â–…â–‡
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–ˆâ–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–ˆâ–â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92193
wandb: best/eval_avg_mil_loss 0.22737
wandb:  best/eval_ensemble_f1 0.92193
wandb:            eval/avg_f1 0.90758
wandb:      eval/avg_mil_loss 0.22786
wandb:       eval/ensemble_f1 0.90758
wandb:            test/avg_f1 0.92704
wandb:      test/avg_mil_loss 0.18855
wandb:       test/ensemble_f1 0.92704
wandb:           train/avg_f1 0.90946
wandb:      train/ensemble_f1 0.90946
wandb:         train/mil_loss 0.25283
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run divine-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mk6lw00s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085238-mk6lw00s/logs
wandb: Agent Starting Run: v4aenbqr with config:
wandb: 	actor_learning_rate: 7.546320021072715e-06
wandb: 	attention_dropout_p: 0.4228517808045403
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02082585553178351
wandb: 	temperature: 8.472123891708444
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085452-v4aenbqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4aenbqr
wandb: uploading history steps 120-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–…â–„â–†â–†â–ƒâ–‡â–…â–‡â–ˆâ–ƒâ–ƒâ–†â–ˆâ–…â–…â–„â–…â–ƒâ–†â–„â–‡â–‚â–‡â–‚â–†â–„â–†â–ƒâ–…â–†â–„â–†â–…â–†â–…â–â–…â–ˆâ–‡
wandb:      eval/avg_mil_loss â–ˆâ–„â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–…â–„â–…â–ƒâ–ƒâ–…â–„â–ƒâ–…â–…â–…â–â–†â–ˆâ–‡â–‚â–„â–ƒâ–‡â–…â–ˆâ–‚â–…â–‚â–…â–ƒâ–‡â–…â–„â–„â–†â–…
wandb:       eval/ensemble_f1 â–†â–‡â–ƒâ–‡â–‡â–‡â–„â–‡â–†â–…â–„â–…â–„â–†â–‡â–‡â–ˆâ–…â–…â–ƒâ–„â–†â–…â–†â–…â–†â–‡â–ˆâ–‚â–„â–…â–†â–…â–†â–†â–â–…â–†â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–ˆâ–‡â–ˆâ–‚â–‡â–†â–‚â–ƒâ–„â–†â–„â–†â–„â–„â–…â–†â–‚â–‚â–â–†â–‡â–„â–„â–‡â–‚â–†â–ˆâ–†â–„â–…â–…â–…â–…â–‡â–†â–ƒâ–…â–â–„
wandb:      train/ensemble_f1 â–†â–ˆâ–ˆâ–…â–ˆâ–â–ƒâ–„â–‡â–‡â–‡â–…â–†â–…â–‡â–…â–†â–‚â–ƒâ–„â–†â–†â–ƒâ–…â–‡â–‡â–„â–…â–„â–‡â–…â–†â–†â–†â–‡â–„â–…â–‡â–ƒâ–ƒ
wandb:         train/mil_loss â–…â–„â–…â–„â–‡â–„â–ˆâ–ƒâ–…â–‡â–†â–„â–„â–‚â–†â–†â–‡â–ƒâ–â–ƒâ–†â–ƒâ–‚â–ƒâ–„â–†â–†â–…â–„â–„â–…â–‚â–…â–…â–†â–„â–„â–ƒâ–†â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.22325
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.89983
wandb:      eval/avg_mil_loss 0.63949
wandb:       eval/ensemble_f1 0.89983
wandb:            test/avg_f1 0.8505
wandb:      test/avg_mil_loss 0.63384
wandb:       test/ensemble_f1 0.8505
wandb:           train/avg_f1 0.83872
wandb:      train/ensemble_f1 0.83872
wandb:         train/mil_loss 0.68594
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4aenbqr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085452-v4aenbqr/logs
wandb: Agent Starting Run: fu570mxf with config:
wandb: 	actor_learning_rate: 0.00026962566225785436
wandb: 	attention_dropout_p: 0.287464373981729
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9428321589770282
wandb: 	temperature: 2.958111294325063
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085728-fu570mxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu570mxf
wandb: uploading history steps 67-72, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–‡â–‡â–†â–…â–‡â–ˆâ–‡â–„â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–„â–…â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–â–†â–…â–‡â–†â–‡â–…â–‡â–‡â–†â–‡â–„
wandb:      eval/avg_mil_loss â–â–â–ƒâ–‚â–â–â–ƒâ–â–…â–‚â–‚â–‚â–â–‚â–‚â–â–†â–â–…â–â–ƒâ–†â–ƒâ–†â–â–â–‚â–ƒâ–â–ˆâ–†â–â–ƒâ–â–â–â–â–â–…â–†
wandb:       eval/ensemble_f1 â–‡â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–ƒâ–„â–„â–„â–…â–„â–‡â–…â–‡â–…â–â–‡â–…â–‚â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‚â–…â–…â–†â–‡â–…â–ˆâ–„â–†â–â–„â–‡â–…â–†â–…â–…â–‡â–†â–…â–‡â–…â–†â–…â–…â–„â–…â–†â–‡â–„â–†â–…â–„â–†â–ˆâ–…â–ˆâ–…â–‡â–„
wandb:      train/ensemble_f1 â–‚â–â–„â–ƒâ–…â–„â–‡â–…â–‡â–ˆâ–…â–ƒâ–‡â–†â–„â–…â–…â–…â–„â–„â–„â–†â–„â–†â–…â–…â–…â–„â–…â–‡â–ˆâ–„â–…â–‡â–†â–„â–‡â–…â–†â–…
wandb:         train/mil_loss â–„â–‡â–ˆâ–ƒâ–‚â–â–‚â–ƒâ–…â–ƒâ–‚â–†â–‚â–„â–†â–…â–†â–ƒâ–‚â–â–…â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‡â–‚â–ƒâ–…â–‚â–…â–†â–‚â–â–„
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92951
wandb: best/eval_avg_mil_loss 0.19351
wandb:  best/eval_ensemble_f1 0.92951
wandb:            eval/avg_f1 0.83934
wandb:      eval/avg_mil_loss 0.93535
wandb:       eval/ensemble_f1 0.83934
wandb:            test/avg_f1 0.90521
wandb:      test/avg_mil_loss 0.18525
wandb:       test/ensemble_f1 0.90521
wandb:           train/avg_f1 0.87925
wandb:      train/ensemble_f1 0.87925
wandb:         train/mil_loss 0.4319
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu570mxf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085728-fu570mxf/logs
wandb: Agent Starting Run: ex1y80k8 with config:
wandb: 	actor_learning_rate: 3.403020065406091e-05
wandb: 	attention_dropout_p: 0.42810668793200535
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4660057500598964
wandb: 	temperature: 7.481207649980015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085856-ex1y80k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ex1y80k8
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–†â–…â–ˆâ–ˆâ–…â–…â–†â–†â–ˆâ–†â–‚â–…â–ˆâ–†â–…â–†â–‚â–…â–ˆâ–‚â–ˆâ–†â–…â–…â–†â–â–†â–…â–ƒâ–…â–†â–…â–ˆâ–ˆâ–ˆâ–…â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–â–…â–â–‚â–â–‚â–â–…â–„â–â–ƒâ–ƒâ–„â–ƒâ–ˆâ–â–ˆâ–„â–â–â–‚â–ƒâ–„â–„â–ƒâ–‡â–„â–ƒâ–…â–‡â–„â–ƒâ–„â–‚â–â–ƒâ–
wandb:       eval/ensemble_f1 â–ˆâ–„â–„â–†â–…â–…â–…â–†â–ˆâ–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–â–…â–â–â–‚â–‡â–…â–‚â–‡â–‡â–‡â–„â–„â–‡â–„â–…â–…â–‚â–ˆâ–ˆâ–‚â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–„â–„â–„â–†â–…â–„â–â–…â–„â–‡â–â–†â–‚â–†â–…â–„â–…â–‡â–ˆâ–†â–„â–„â–…â–‚â–ƒâ–†â–†â–…â–…â–„â–‡â–…â–…â–„â–ƒâ–ƒâ–„â–ƒ
wandb:      train/ensemble_f1 â–„â–‡â–…â–…â–„â–„â–…â–ƒâ–…â–ƒâ–…â–…â–…â–†â–‡â–…â–…â–„â–ˆâ–‡â–ˆâ–†â–…â–‡â–…â–…â–…â–„â–â–ˆâ–„â–‡â–…â–†â–ƒâ–…â–„â–…â–„â–„
wandb:         train/mil_loss â–ƒâ–‡â–ƒâ–†â–…â–…â–ƒâ–ƒâ–ƒâ–†â–…â–†â–†â–†â–„â–„â–â–„â–„â–†â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–ˆâ–„â–†â–†â–†â–‚â–ƒâ–„â–…â–†â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.25755
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.9216
wandb:      eval/avg_mil_loss 0.24533
wandb:       eval/ensemble_f1 0.9216
wandb:            test/avg_f1 0.93026
wandb:      test/avg_mil_loss 0.21277
wandb:       test/ensemble_f1 0.93026
wandb:           train/avg_f1 0.74303
wandb:      train/ensemble_f1 0.74303
wandb:         train/mil_loss 1.00414
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run robust-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ex1y80k8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085856-ex1y80k8/logs
wandb: Agent Starting Run: 148d0zk0 with config:
wandb: 	actor_learning_rate: 0.00028823132636815306
wandb: 	attention_dropout_p: 0.22486833339509657
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34244837703910314
wandb: 	temperature: 0.6116218545883256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090101-148d0zk0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/148d0zk0
wandb: uploading history steps 50-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–†â–„â–…â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–†â–ƒâ–â–‡â–†â–†â–ˆâ–‡â–…â–…â–…â–†â–‡â–†â–…â–ˆâ–‚â–†â–…â–ƒâ–†â–‡â–†â–‚â–‡â–ˆâ–…â–†â–ˆ
wandb:      eval/avg_mil_loss â–‚â–…â–†â–‚â–â–ƒâ–„â–‚â–„â–„â–‚â–‡â–ˆâ–ƒâ–‡â–‚â–â–â–…â–‚â–„â–†â–‚â–„â–ƒâ–…â–â–…â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–„â–‚â–â–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–‡â–†â–…â–ƒâ–…â–ˆâ–…â–‡â–‡â–†â–…â–†â–ƒâ–‡â–†â–‡â–„â–‡â–ˆâ–„â–†â–†â–†â–…â–ˆâ–ˆâ–‚â–…â–…â–‡â–ƒâ–†â–‡â–…â–â–‡â–‡â–„â–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–ƒâ–„â–„â–…â–„â–‡â–†â–‚â–‡â–‡â–†â–‡â–…â–ˆâ–ƒâ–ˆâ–‚â–†â–„â–â–…â–…â–…â–‚â–…â–†â–…â–‚â–†â–…â–…â–†â–‡â–‡â–‚â–ˆâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–†â–„â–„â–„â–ˆâ–…â–„â–‡â–†â–‚â–‡â–‡â–†â–‡â–…â–ˆâ–ƒâ–ˆâ–‚â–†â–„â–â–…â–…â–…â–‚â–…â–…â–„â–‚â–…â–…â–†â–…â–†â–‡â–‡â–‚â–ˆâ–„
wandb:         train/mil_loss â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–„â–‡â–ˆâ–†â–„â–…â–…â–‚â–…â–ƒâ–…â–„â–‚â–â–„â–„â–ƒâ–‡â–„â–„â–„â–â–‚â–„â–…â–‚â–‚â–‚â–‚â–ƒâ–‚â–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–ˆâ–…â–â–â–ˆâ–…â–…â–â–…â–â–â–…â–â–…â–…â–…â–ˆâ–…â–ˆâ–…â–â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92558
wandb: best/eval_avg_mil_loss 0.24847
wandb:  best/eval_ensemble_f1 0.92558
wandb:            eval/avg_f1 0.89327
wandb:      eval/avg_mil_loss 0.29605
wandb:       eval/ensemble_f1 0.89327
wandb:            test/avg_f1 0.92061
wandb:      test/avg_mil_loss 0.46378
wandb:       test/ensemble_f1 0.92061
wandb:           train/avg_f1 0.76496
wandb:      train/ensemble_f1 0.76496
wandb:         train/mil_loss 1.47766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lemon-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/148d0zk0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090101-148d0zk0/logs
wandb: Agent Starting Run: dej4rezu with config:
wandb: 	actor_learning_rate: 0.0004465570759430152
wandb: 	attention_dropout_p: 0.27821045374758674
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4339416697087267
wandb: 	temperature: 8.556923795976697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090153-dej4rezu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dej4rezu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–â–†â–ƒâ–â–‚â–„â–â–†â–…â–‚â–ƒâ–‡â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–‚â–ˆâ–â–„â–ˆâ–„â–…â–â–‡â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–‚
wandb:      eval/avg_mil_loss â–‚â–†â–ˆâ–„â–…â–…â–ƒâ–ƒâ–…â–„â–‚â–‡â–ƒâ–…â–…â–†â–ƒâ–‚â–ƒâ–„â–†â–‚â–ˆâ–‚â–â–‡â–‚â–‡â–†â–„â–†â–†â–…â–ƒâ–â–‡â–…â–†â–…â–…
wandb:       eval/ensemble_f1 â–‚â–„â–†â–ƒâ–…â–‡â–„â–„â–„â–ƒâ–„â–â–„â–„â–†â–„â–„â–…â–ƒâ–‡â–â–ˆâ–†â–‚â–‡â–†â–…â–…â–„â–ƒâ–„â–„â–†â–…â–‚â–ƒâ–ƒâ–„â–ˆâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‡â–â–â–†â–†â–„â–„â–ˆâ–†â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–…â–„â–…â–‡â–†â–†â–„â–…â–…â–‚â–„â–†â–‡â–‚â–†â–†â–‚â–†â–‡â–†â–„â–…â–†â–…
wandb:      train/ensemble_f1 â–„â–†â–‡â–‡â–…â–…â–„â–…â–‡â–…â–ˆâ–‚â–†â–†â–…â–…â–…â–†â–…â–„â–â–…â–…â–‡â–‡â–„â–„â–†â–…â–…â–…â–†â–†â–‡â–…â–‡â–†â–‡â–ˆâ–ˆ
wandb:         train/mil_loss â–†â–„â–‚â–‡â–†â–†â–‡â–ˆâ–„â–†â–‚â–‡â–‡â–†â–‡â–…â–ƒâ–ƒâ–ƒâ–…â–„â–†â–ƒâ–†â–…â–…â–ƒâ–ƒâ–„â–…â–†â–…â–†â–…â–ƒâ–„â–„â–‚â–â–ƒ
wandb:      train/policy_loss â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‚â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90687
wandb: best/eval_avg_mil_loss 0.27641
wandb:  best/eval_ensemble_f1 0.90687
wandb:            eval/avg_f1 0.7583
wandb:      eval/avg_mil_loss 2.01989
wandb:       eval/ensemble_f1 0.7583
wandb:            test/avg_f1 0.81204
wandb:      test/avg_mil_loss 1.34998
wandb:       test/ensemble_f1 0.81204
wandb:           train/avg_f1 0.76203
wandb:      train/ensemble_f1 0.76203
wandb:         train/mil_loss 1.81148
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dej4rezu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090153-dej4rezu/logs
wandb: Agent Starting Run: qbfcsrla with config:
wandb: 	actor_learning_rate: 0.00015912691533047227
wandb: 	attention_dropout_p: 0.30507636408451083
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9437826490177144
wandb: 	temperature: 9.712598111863697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090519-qbfcsrla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2j3xnbn3
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbfcsrla
wandb: uploading history steps 120-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–…â–†â–…â–†â–†â–‚â–ˆâ–…â–†â–†â–„â–†â–„â–‡â–„â–„â–‡â–†â–…â–ˆâ–â–‡â–„â–†â–‚â–‡â–…â–‡â–‚â–ˆâ–„â–‡â–…â–ƒâ–†â–‡â–‡â–†â–†
wandb:      eval/avg_mil_loss â–„â–â–ƒâ–â–„â–†â–â–â–â–„â–‚â–†â–„â–â–…â–â–‚â–â–â–‡â–â–„â–…â–ƒâ–†â–…â–â–â–â–â–â–‚â–â–‚â–â–ƒâ–‚â–â–ˆâ–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–†â–‡â–†â–‡â–…â–…â–„â–‡â–‡â–â–†â–†â–‚â–„â–…â–ƒâ–‡â–„â–…â–‚â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–…â–†â–„â–„â–ƒâ–…â–‡â–‡â–‡â–‡â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‡â–…â–†â–†â–ˆâ–‡â–†â–†â–â–†â–ƒâ–ƒâ–…â–„â–ƒâ–ˆâ–ˆâ–†â–†â–ƒâ–†â–†â–…â–„â–ˆâ–‡â–‡â–‡â–†â–†â–‚â–ƒâ–ˆâ–‡â–‚â–†â–‡â–†â–„
wandb:      train/ensemble_f1 â–„â–…â–ƒâ–„â–…â–‡â–†â–â–‡â–†â–„â–…â–‡â–‡â–ˆâ–…â–„â–„â–†â–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†â–†â–‡â–ˆâ–ˆâ–†â–‡â–‡â–‚â–ˆâ–†â–„â–„â–‡
wandb:         train/mil_loss â–‡â–‚â–‡â–…â–ˆâ–ƒâ–ƒâ–„â–†â–‚â–…â–„â–„â–„â–„â–‚â–ƒâ–„â–…â–â–…â–‚â–‚â–‡â–‚â–†â–â–ƒâ–„â–†â–ƒâ–ƒâ–„â–ƒâ–…â–…â–†â–„â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92964
wandb: best/eval_avg_mil_loss 0.2106
wandb:  best/eval_ensemble_f1 0.92964
wandb:            eval/avg_f1 0.87478
wandb:      eval/avg_mil_loss 0.2932
wandb:       eval/ensemble_f1 0.87478
wandb:            test/avg_f1 0.9128
wandb:      test/avg_mil_loss 0.20494
wandb:       test/ensemble_f1 0.9128
wandb:           train/avg_f1 0.8648
wandb:      train/ensemble_f1 0.8648
wandb:         train/mil_loss 0.53897
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earnest-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbfcsrla
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090519-qbfcsrla/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 8c7c45uw with config:
wandb: 	actor_learning_rate: 0.0001666758125412651
wandb: 	attention_dropout_p: 0.4921669887758097
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3070493311554222
wandb: 	temperature: 8.256612426348385
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090832-8c7c45uw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8c7c45uw
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 73-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–‡â–ˆâ–†â–‡â–ˆâ–…â–ˆâ–„â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–„â–†â–‚â–‡â–ˆâ–ˆâ–†â–ˆâ–†â–‡â–†â–„â–†â–†â–†â–â–†â–ƒâ–†â–‡â–‡â–‡â–„
wandb:      eval/avg_mil_loss â–‚â–‚â–‚â–â–ƒâ–â–‚â–â–â–‚â–ƒâ–‚â–‚â–…â–â–â–â–â–‚â–‚â–â–„â–ƒâ–ˆâ–â–‚â–‚â–ƒâ–„â–â–‚â–â–‚â–„â–…â–ƒâ–‚â–‚â–‚â–„
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–„â–‡â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–†â–â–†â–‡â–‚â–ˆâ–†â–‡â–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–„â–ƒâ–‡â–‡â–†â–ˆâ–†â–„â–‡â–ƒâ–‡â–„â–…â–‡â–†â–â–†â–†â–†â–ˆâ–‡â–…â–‡â–†â–„â–„â–†â–…â–ˆâ–†â–…â–„â–…â–†â–‡â–‚â–‡â–ˆ
wandb:      train/ensemble_f1 â–‡â–†â–‡â–†â–‡â–†â–ƒâ–ˆâ–†â–„â–†â–ƒâ–…â–†â–ƒâ–„â–†â–„â–†â–†â–‡â–‡â–†â–…â–ƒâ–„â–„â–…â–‡â–†â–ˆâ–ˆâ–…â–…â–‡â–†â–…â–ƒâ–â–„
wandb:         train/mil_loss â–…â–‚â–ˆâ–‚â–‚â–ˆâ–â–‚â–…â–„â–„â–â–â–ƒâ–‡â–„â–…â–„â–„â–‚â–…â–‚â–ƒâ–‡â–…â–‚â–‚â–‡â–„â–ˆâ–ƒâ–‚â–‡â–‚â–‚â–â–â–â–ƒâ–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92907
wandb: best/eval_avg_mil_loss 0.25297
wandb:  best/eval_ensemble_f1 0.92907
wandb:            eval/avg_f1 0.69289
wandb:      eval/avg_mil_loss 0.61827
wandb:       eval/ensemble_f1 0.69289
wandb:            test/avg_f1 0.91253
wandb:      test/avg_mil_loss 0.26803
wandb:       test/ensemble_f1 0.91253
wandb:           train/avg_f1 0.83467
wandb:      train/ensemble_f1 0.83467
wandb:         train/mil_loss 0.28434
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8c7c45uw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090832-8c7c45uw/logs
wandb: Agent Starting Run: yx4oumhw with config:
wandb: 	actor_learning_rate: 6.649950137601314e-06
wandb: 	attention_dropout_p: 0.47521382520518535
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10649666769415957
wandb: 	temperature: 8.194038044443712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090949-yx4oumhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yx4oumhw
wandb: uploading history steps 189-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–‡â–†â–†â–…â–â–…â–†â–…â–†â–…â–†â–†â–„â–†â–…â–†â–‡â–…â–†â–ˆâ–†â–†â–†â–…â–…â–„â–„â–‡â–†â–‡â–‡â–…â–‡â–ƒâ–„â–…â–‡â–†
wandb:      eval/avg_mil_loss â–„â–„â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–…â–ˆâ–„â–‡â–„â–‚â–â–„â–‚â–â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–…â–…â–„â–„â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–„â–„â–‚
wandb:       eval/ensemble_f1 â–‡â–‡â–…â–â–‡â–„â–‡â–‡â–…â–‡â–„â–ƒâ–‡â–„â–‡â–…â–„â–†â–ƒâ–…â–‡â–ˆâ–…â–…â–„â–„â–„â–â–†â–‚â–…â–„â–ƒâ–†â–„â–„â–„â–‡â–„â–„
wandb:           train/avg_f1 â–†â–ƒâ–‡â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–„â–…â–…â–…â–„â–â–„â–†â–ƒâ–‚â–…â–…â–‡â–â–ƒâ–ˆâ–ƒâ–‚â–‡â–ˆâ–†â–„â–†â–‚â–†â–‚â–„â–…â–…
wandb:      train/ensemble_f1 â–‚â–‚â–‚â–‚â–‡â–„â–ƒâ–…â–â–…â–â–„â–ƒâ–…â–‚â–…â–…â–ƒâ–â–…â–…â–…â–‡â–ƒâ–…â–„â–…â–„â–ˆâ–„â–„â–ƒâ–‡â–…â–…â–‚â–‡â–…â–ƒâ–…
wandb:         train/mil_loss â–„â–…â–„â–ˆâ–â–ƒâ–‡â–‡â–…â–„â–ˆâ–…â–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–…â–…â–â–ƒâ–ƒâ–…â–â–„â–â–‚â–…â–â–„â–„â–‚â–â–…â–†â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92998
wandb: best/eval_avg_mil_loss 0.25773
wandb:  best/eval_ensemble_f1 0.92998
wandb:            eval/avg_f1 0.81381
wandb:      eval/avg_mil_loss 1.1756
wandb:       eval/ensemble_f1 0.81381
wandb:           train/avg_f1 0.7987
wandb:      train/ensemble_f1 0.7987
wandb:         train/mil_loss 0.70525
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run flowing-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yx4oumhw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090949-yx4oumhw/logs
wandb: ERROR Run yx4oumhw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 23s2wl6z with config:
wandb: 	actor_learning_rate: 2.512221386131954e-05
wandb: 	attention_dropout_p: 0.4379531276000336
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.99850967092889
wandb: 	temperature: 5.015068092945832
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091316-23s2wl6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/23s2wl6z
wandb: uploading history steps 58-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–‚â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–†â–ƒâ–â–…â–ƒâ–â–‡â–†â–„â–ƒâ–‡â–„â–„â–†â–‚â–…â–‚â–„â–„â–†â–„â–ƒâ–„â–ˆâ–†â–…â–‡â–„â–„â–‡â–…â–„â–…â–ƒâ–†â–ƒâ–â–ˆ
wandb:      eval/avg_mil_loss â–„â–â–ƒâ–…â–ˆâ–…â–ƒâ–‡â–…â–‚â–†â–†â–„â–‡â–„â–…â–‚â–„â–†â–…â–‚â–ƒâ–ˆâ–…â–ƒâ–â–…â–„â–†â–…â–„â–ƒâ–ƒâ–ƒâ–†â–†â–„â–‡â–„â–
wandb:       eval/ensemble_f1 â–…â–‡â–†â–ƒâ–‚â–…â–…â–â–†â–‡â–â–„â–ƒâ–„â–„â–‚â–…â–†â–ˆâ–…â–„â–ƒâ–„â–†â–†â–ƒâ–ˆâ–†â–‡â–…â–…â–„â–‡â–…â–„â–†â–â–ƒâ–â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–†â–ƒâ–‚â–„â–„â–„â–…â–…â–…â–…â–†â–ƒâ–…â–â–ƒâ–ƒâ–†â–†â–„â–…â–…â–„â–„â–ƒâ–‡â–…â–…â–…â–…â–…â–…â–…â–„â–ˆâ–„â–…â–…â–†
wandb:      train/ensemble_f1 â–…â–…â–†â–ƒâ–‚â–…â–„â–„â–…â–†â–„â–…â–…â–…â–…â–ƒâ–†â–…â–…â–†â–â–…â–…â–…â–„â–„â–„â–‡â–…â–…â–…â–…â–…â–…â–„â–„â–ˆâ–…â–…â–…
wandb:         train/mil_loss â–ƒâ–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‡â–…â–ƒâ–„â–â–…â–ˆâ–†â–„â–…â–ƒâ–†â–„â–ƒâ–‚â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–„â–‚â–…â–ƒâ–ƒâ–„â–„â–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8782
wandb: best/eval_avg_mil_loss 0.84733
wandb:  best/eval_ensemble_f1 0.8782
wandb:            eval/avg_f1 0.86861
wandb:      eval/avg_mil_loss 0.33246
wandb:       eval/ensemble_f1 0.86861
wandb:            test/avg_f1 0.8768
wandb:      test/avg_mil_loss 0.26996
wandb:       test/ensemble_f1 0.8768
wandb:           train/avg_f1 0.73769
wandb:      train/ensemble_f1 0.73769
wandb:         train/mil_loss 0.70011
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/23s2wl6z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091316-23s2wl6z/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: osgxc3ni with config:
wandb: 	actor_learning_rate: 2.5644501603829684e-05
wandb: 	attention_dropout_p: 0.2122726869164256
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04211724903804426
wandb: 	temperature: 6.853514069233912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091458-osgxc3ni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/osgxc3ni
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–†â–‚â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–‡â–†â–‡â–†â–…â–ˆâ–ˆâ–…â–â–ƒâ–ƒâ–†â–ƒâ–ˆâ–†â–ˆâ–ˆâ–…â–†â–…â–†â–†â–ˆâ–‚â–†â–…â–‚â–„â–‡â–…â–„â–„â–ˆâ–„â–ƒâ–ƒâ–†â–‚
wandb:      eval/avg_mil_loss â–…â–‡â–ƒâ–„â–‚â–â–â–â–ƒâ–…â–ƒâ–‡â–†â–†â–ƒâ–â–„â–„â–‚â–â–…â–„â–â–„â–ƒâ–„â–ƒâ–‡â–…â–‚â–â–ƒâ–ƒâ–…â–ˆâ–‡â–„â–â–ƒâ–ˆ
wandb:       eval/ensemble_f1 â–„â–‡â–‡â–†â–‡â–†â–†â–…â–ˆâ–‡â–„â–ƒâ–…â–ˆâ–„â–„â–…â–‡â–†â–†â–…â–‡â–†â–ƒâ–â–‡â–‡â–‡â–†â–ˆâ–…â–‡â–ƒâ–„â–„â–†â–„â–†â–‡â–„
wandb:           train/avg_f1 â–‡â–†â–…â–‡â–â–ˆâ–ˆâ–†â–…â–†â–†â–‡â–ƒâ–…â–†â–†â–ˆâ–„â–ƒâ–…â–…â–…â–…â–„â–ˆâ–‡â–ˆâ–…â–ˆâ–†â–‡â–†â–‡â–†â–…â–„â–‡â–…â–…â–„
wandb:      train/ensemble_f1 â–‡â–†â–…â–‡â–†â–‡â–†â–†â–â–„â–ƒâ–…â–„â–…â–ƒâ–†â–†â–ˆâ–†â–…â–„â–„â–†â–…â–…â–ˆâ–…â–‡â–…â–…â–…â–‡â–‚â–†â–ˆâ–ˆâ–ˆâ–…â–‡â–‚
wandb:         train/mil_loss â–„â–…â–‚â–†â–ƒâ–‚â–†â–„â–ƒâ–…â–ƒâ–…â–ƒâ–‡â–‡â–ƒâ–ƒâ–ˆâ–†â–‡â–„â–…â–ƒâ–†â–†â–ƒâ–…â–‚â–„â–â–…â–…â–„â–‚â–‡â–â–‚â–…â–…â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91482
wandb: best/eval_avg_mil_loss 0.23281
wandb:  best/eval_ensemble_f1 0.91482
wandb:            eval/avg_f1 0.76871
wandb:      eval/avg_mil_loss 1.14883
wandb:       eval/ensemble_f1 0.76871
wandb:           train/avg_f1 0.78553
wandb:      train/ensemble_f1 0.78553
wandb:         train/mil_loss 0.57876
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run giddy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/osgxc3ni
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091458-osgxc3ni/logs
wandb: ERROR Run osgxc3ni errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: iyo97ad0 with config:
wandb: 	actor_learning_rate: 3.124882605657151e-05
wandb: 	attention_dropout_p: 0.4588879923574557
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 72
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9860564720564368
wandb: 	temperature: 3.610686063228774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091637-iyo97ad0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iyo97ad0
wandb: uploading history steps 72-72, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–…â–„â–„â–†â–‡â–‡â–‚â–‡â–†â–‡â–ˆâ–‡â–„â–ˆâ–ƒâ–‚â–â–†â–‡â–…â–ˆâ–„â–…â–„â–ˆâ–†â–†â–„â–‡â–†â–‡â–…â–ˆâ–†â–ƒâ–‡â–ˆâ–…
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–„â–ˆâ–‚â–‚â–…â–â–„â–â–‚â–â–‡â–‚â–‚â–…â–â–„â–‚â–â–‡â–ƒâ–„â–‚â–‡â–„â–â–ˆâ–†â–â–ƒâ–‚â–‡â–‚â–…â–ƒâ–‚â–„â–…
wandb:       eval/ensemble_f1 â–†â–†â–…â–…â–„â–„â–ƒâ–†â–†â–…â–‚â–†â–…â–†â–…â–‡â–‡â–†â–ˆâ–â–‡â–„â–…â–‡â–„â–…â–„â–ˆâ–„â–‡â–†â–„â–ˆâ–†â–‡â–…â–†â–ƒâ–‡â–…
wandb:           train/avg_f1 â–†â–ƒâ–†â–…â–„â–ƒâ–†â–ƒâ–‚â–â–†â–…â–„â–„â–‡â–…â–…â–â–…â–…â–ˆâ–ƒâ–„â–…â–„â–‚â–„â–ƒâ–‚â–‚â–‡â–…â–‚â–…â–‚â–„â–…â–ƒâ–‚â–ˆ
wandb:      train/ensemble_f1 â–†â–†â–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–…â–ƒâ–â–…â–†â–…â–‡â–„â–…â–â–…â–ƒâ–ƒâ–ˆâ–ƒâ–„â–…â–„â–‚â–†â–†â–‡â–…â–‚â–‚â–„â–‚â–„â–‚â–ˆ
wandb:         train/mil_loss â–„â–„â–„â–ƒâ–†â–„â–…â–†â–†â–„â–ƒâ–ƒâ–‡â–ˆâ–ƒâ–ƒâ–‡â–…â–ƒâ–‡â–‡â–ƒâ–†â–ƒâ–†â–‡â–…â–„â–‚â–†â–„â–ƒâ–â–‚â–â–ƒâ–…â–ƒâ–…â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91467
wandb: best/eval_avg_mil_loss 0.24185
wandb:  best/eval_ensemble_f1 0.91467
wandb:            eval/avg_f1 0.84619
wandb:      eval/avg_mil_loss 0.56985
wandb:       eval/ensemble_f1 0.84619
wandb:           train/avg_f1 0.87852
wandb:      train/ensemble_f1 0.87852
wandb:         train/mil_loss 0.62393
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iyo97ad0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091637-iyo97ad0/logs
wandb: ERROR Run iyo97ad0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a94tsja2 with config:
wandb: 	actor_learning_rate: 0.0007460057744635761
wandb: 	attention_dropout_p: 0.4979690889443175
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15266382426798486
wandb: 	temperature: 8.217816283315294
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091806-a94tsja2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a94tsja2
wandb: uploading history steps 172-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–‚â–ƒâ–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–…â–†â–…â–„â–‚â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–‚â–ƒâ–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–â–…â–…â–…â–„â–…â–„â–…â–„â–„â–…â–„â–…â–â–…â–‚â–‚â–‚â–†â–†â–†â–…â–…â–‚â–‡â–†â–‡â–†â–‡â–†â–…â–‡â–†â–‡â–ˆâ–…â–ˆâ–‡
wandb:      eval/avg_mil_loss â–†â–†â–†â–†â–ˆâ–†â–…â–…â–…â–…â–„â–„â–„â–„â–‡â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–‚â–â–„â–‚â–‚â–â–â–
wandb:       eval/ensemble_f1 â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–‚â–†â–â–†â–†â–†â–†â–†â–„â–†â–…â–ƒâ–‡â–ƒâ–‡â–‡â–ˆâ–ˆâ–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–â–„â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–„â–„â–…â–…â–†â–…â–…â–†â–†â–„â–…â–…â–†â–ƒâ–…â–†â–…â–„â–†â–†â–…â–„â–…â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:      train/ensemble_f1 â–â–‚â–„â–ƒâ–‚â–„â–‚â–„â–ƒâ–…â–…â–„â–…â–…â–†â–†â–…â–…â–…â–†â–†â–„â–†â–ƒâ–‡â–„â–…â–‡â–…â–†â–‡â–†â–…â–‡â–ˆâ–‡â–†â–†â–…â–‡
wandb:         train/mil_loss â–‡â–ˆâ–‡â–„â–†â–†â–…â–„â–…â–†â–ƒâ–ƒâ–„â–ƒâ–…â–„â–„â–„â–…â–„â–‚â–‚â–ƒâ–„â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.93315
wandb: best/eval_avg_mil_loss 0.20935
wandb:  best/eval_ensemble_f1 0.93315
wandb:            eval/avg_f1 0.92573
wandb:      eval/avg_mil_loss 0.18859
wandb:       eval/ensemble_f1 0.92573
wandb:            test/avg_f1 0.92704
wandb:      test/avg_mil_loss 0.15344
wandb:       test/ensemble_f1 0.92704
wandb:           train/avg_f1 0.91871
wandb:      train/ensemble_f1 0.91871
wandb:         train/mil_loss 0.20702
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run visionary-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a94tsja2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091806-a94tsja2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8ui6ldc9 with config:
wandb: 	actor_learning_rate: 0.0008872854847380531
wandb: 	attention_dropout_p: 0.03458433516466469
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7459036270981984
wandb: 	temperature: 5.6430553158258325
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092122-8ui6ldc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ui6ldc9
wandb: uploading history steps 86-93, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–ƒâ–†â–„â–„â–‚â–ƒâ–†â–‡â–‚â–„â–‡â–â–‡â–…â–ˆâ–‡â–†â–…â–â–…â–‚â–ƒâ–ƒâ–‡â–„â–‡â–ƒâ–„â–†â–‚â–…â–â–ƒâ–†â–…â–„â–â–„
wandb:      eval/avg_mil_loss â–‚â–…â–„â–ƒâ–â–†â–â–‚â–ˆâ–„â–‚â–‚â–†â–ƒâ–ƒâ–‚â–â–â–‡â–‚â–‡â–‚â–‡â–…â–…â–…â–â–„â–‚â–ƒâ–‚â–‚â–ƒâ–‡â–…â–„â–â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–†â–…â–…â–ˆâ–â–ƒâ–ƒâ–ƒâ–‡â–…â–ˆâ–‡â–‡â–…â–‡â–ƒâ–‡â–ƒâ–…â–†â–„â–…â–‡â–…â–†â–ƒâ–†â–†â–ƒâ–„â–„â–†â–‡â–†â–†â–„â–†â–ƒâ–‚â–…
wandb:           train/avg_f1 â–ˆâ–ƒâ–ƒâ–ƒâ–†â–„â–â–…â–„â–â–…â–‚â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–‡â–…â–†â–†â–…â–ƒâ–ƒâ–…â–…â–„â–„â–‡â–‡â–†â–‚â–„â–…â–ˆâ–†â–…â–„â–…
wandb:      train/ensemble_f1 â–„â–ˆâ–„â–â–…â–‡â–†â–…â–ƒâ–†â–‡â–…â–ƒâ–…â–„â–„â–…â–…â–ƒâ–„â–„â–…â–‡â–…â–†â–„â–…â–†â–†â–…â–‡â–ƒâ–†â–‡â–ƒâ–†â–‡â–†â–‚â–†
wandb:         train/mil_loss â–‡â–†â–‡â–ˆâ–ƒâ–…â–†â–„â–ˆâ–…â–„â–†â–…â–ƒâ–„â–†â–‚â–‡â–†â–‡â–„â–‡â–ƒâ–†â–‡â–…â–â–ƒâ–…â–†â–„â–‚â–ƒâ–…â–„â–…â–…â–ƒâ–…â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92223
wandb: best/eval_avg_mil_loss 0.26055
wandb:  best/eval_ensemble_f1 0.92223
wandb:            eval/avg_f1 0.82482
wandb:      eval/avg_mil_loss 0.79066
wandb:       eval/ensemble_f1 0.82482
wandb:           train/avg_f1 0.82596
wandb:      train/ensemble_f1 0.82596
wandb:         train/mil_loss 0.7174
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stellar-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ui6ldc9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092122-8ui6ldc9/logs
wandb: ERROR Run 8ui6ldc9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0a7yqbii with config:
wandb: 	actor_learning_rate: 0.00012694496785094274
wandb: 	attention_dropout_p: 0.24658983605563017
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6493854977260568
wandb: 	temperature: 1.104950736354714
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092306-0a7yqbii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0a7yqbii
wandb: uploading history steps 158-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–„â–‚â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–â–…â–…â–‚â–…â–„â–‡â–ƒâ–ƒâ–„â–‡â–…â–‡â–ˆâ–‡â–„â–…â–†â–…â–‡â–„â–„â–†â–‡â–ƒâ–ˆâ–‡â–†â–‡â–ˆâ–…â–†â–ˆâ–‡â–„â–…â–†â–…â–„
wandb:      eval/avg_mil_loss â–„â–†â–…â–„â–ƒâ–‚â–„â–„â–„â–†â–…â–ˆâ–‚â–‚â–‚â–…â–ƒâ–â–‚â–ƒâ–ƒâ–„â–‚â–â–â–†â–†â–ƒâ–â–ƒâ–ˆâ–…â–„â–…â–‚â–„â–ˆâ–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–…â–ƒâ–â–…â–†â–„â–„â–…â–‡â–…â–ƒâ–‡â–†â–…â–ˆâ–‡â–ˆâ–â–…â–†â–ˆâ–‚â–‚â–…â–…â–ˆâ–ˆâ–…â–‡â–‡â–‡â–†â–†â–…â–â–†â–…â–†â–„â–…
wandb:           train/avg_f1 â–„â–‡â–…â–â–„â–…â–ƒâ–…â–†â–‡â–ƒâ–…â–…â–†â–…â–‡â–„â–†â–„â–…â–†â–†â–…â–…â–…â–†â–…â–†â–ˆâ–…â–†â–†â–…â–‡â–‡â–‡â–ƒâ–ƒâ–…â–‡
wandb:      train/ensemble_f1 â–„â–…â–â–…â–„â–…â–†â–…â–ƒâ–†â–…â–‡â–„â–†â–†â–‡â–‡â–‡â–ˆâ–„â–†â–‡â–†â–…â–‡â–ˆâ–…â–†â–†â–‡â–†â–ƒâ–‡â–‡â–‡â–†â–ˆâ–†â–†â–‡
wandb:         train/mil_loss â–†â–…â–ƒâ–†â–‡â–…â–‚â–ƒâ–ƒâ–…â–„â–‡â–‚â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–„â–ˆâ–ƒâ–†â–ˆâ–ƒâ–â–â–ƒâ–„â–†â–ƒâ–‚â–‚â–…â–ƒâ–„â–†â–†â–„â–„
wandb:      train/policy_loss â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9103
wandb: best/eval_avg_mil_loss 0.27465
wandb:  best/eval_ensemble_f1 0.9103
wandb:            eval/avg_f1 0.8014
wandb:      eval/avg_mil_loss 0.79036
wandb:       eval/ensemble_f1 0.8014
wandb:           train/avg_f1 0.80026
wandb:      train/ensemble_f1 0.80026
wandb:         train/mil_loss 0.7651
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run treasured-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0a7yqbii
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092306-0a7yqbii/logs
wandb: ERROR Run 0a7yqbii errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3083obha with config:
wandb: 	actor_learning_rate: 3.937369917229598e-05
wandb: 	attention_dropout_p: 0.2163113430355666
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7748038139045392
wandb: 	temperature: 2.9832127156222477
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092607-3083obha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3083obha
wandb: uploading history steps 57-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–‚â–„â–…â–„â–†â–†â–â–†â–…â–ƒâ–„â–„â–„â–„â–…â–†â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–…â–â–â–…â–ƒâ–„â–†â–„â–…â–†â–ƒâ–„â–ˆ
wandb:      eval/avg_mil_loss â–â–…â–†â–…â–…â–…â–…â–†â–ƒâ–ƒâ–„â–„â–‡â–„â–„â–„â–†â–…â–‡â–‡â–„â–†â–„â–…â–†â–†â–„â–ƒâ–ˆâ–ˆâ–„â–…â–„â–„â–…â–…â–ƒâ–…â–…â–‚
wandb:       eval/ensemble_f1 â–ˆâ–â–ƒâ–‚â–…â–„â–ƒâ–â–„â–†â–…â–ƒâ–„â–„â–„â–„â–…â–†â–ƒâ–‚â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‡â–â–…â–…â–ƒâ–„â–„â–†â–ƒâ–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–„â–…â–…â–†â–…â–ƒâ–ƒâ–ˆâ–†â–‡â–‡â–…â–â–†â–„â–†â–‡â–‡â–‡â–…â–ˆâ–…â–†â–‡â–†â–ˆâ–…â–‚â–„â–‚â–ˆâ–‚â–…â–†â–ƒâ–ˆâ–…â–‡
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–…â–…â–†â–…â–ƒâ–‚â–ˆâ–‡â–…â–‡â–‡â–…â–ƒâ–…â–‡â–‡â–ƒâ–ˆâ–…â–…â–‡â–‡â–ƒâ–ˆâ–„â–…â–‚â–„â–„â–â–ˆâ–â–…â–†â–‚â–ˆâ–†
wandb:         train/mil_loss â–†â–†â–…â–†â–…â–…â–‡â–‡â–…â–„â–ˆâ–‡â–†â–…â–…â–ƒâ–‡â–…â–‡â–„â–…â–‡â–„â–†â–„â–ˆâ–„â–†â–â–†â–…â–„â–‡â–…â–„â–…â–„â–†â–ƒâ–…
wandb:      train/policy_loss â–†â–†â–ˆâ–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88652
wandb: best/eval_avg_mil_loss 0.58063
wandb:  best/eval_ensemble_f1 0.88652
wandb:            eval/avg_f1 0.88652
wandb:      eval/avg_mil_loss 0.58063
wandb:       eval/ensemble_f1 0.88652
wandb:            test/avg_f1 0.64348
wandb:      test/avg_mil_loss 1.62014
wandb:       test/ensemble_f1 0.64348
wandb:           train/avg_f1 0.70728
wandb:      train/ensemble_f1 0.70728
wandb:         train/mil_loss 1.4896
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run blooming-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3083obha
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092607-3083obha/logs
wandb: Agent Starting Run: 8qgg6zux with config:
wandb: 	actor_learning_rate: 1.6933074620890775e-06
wandb: 	attention_dropout_p: 0.05867535612452168
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23668946458948129
wandb: 	temperature: 2.758826631209146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092713-8qgg6zux
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8qgg6zux
wandb: uploading wandb-summary.json
wandb: uploading history steps 157-167, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–†â–‡â–†â–ˆâ–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–‡â–ƒâ–ˆâ–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–„â–‚â–â–ˆâ–â–…â–â–â–â–â–…â–â–‚â–â–‚â–â–â–â–â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–ˆâ–†â–ˆâ–‡â–ˆâ–†â–ˆâ–†â–‚â–†â–„â–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–„â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–„â–…â–‡â–‡â–…â–„â–„â–†â–‡â–†â–…â–‚â–†â–†â–„â–‡â–ˆâ–ˆâ–â–‡â–‡â–ˆâ–†â–ƒâ–…â–‡â–†â–‡â–†â–ˆâ–‡â–†â–ˆâ–„â–†â–„â–†â–‡
wandb:      train/ensemble_f1 â–†â–‡â–†â–â–…â–ƒâ–‡â–ƒâ–ƒâ–‡â–‡â–ƒâ–„â–†â–ˆâ–„â–ƒâ–‡â–ˆâ–‡â–…â–ˆâ–…â–‡â–„â–‡â–ˆâ–…â–ƒâ–†â–ƒâ–†â–ˆâ–ƒâ–ˆâ–…â–„â–…â–†â–‡
wandb:         train/mil_loss â–†â–„â–â–‚â–ƒâ–‚â–â–â–„â–ƒâ–â–â–ƒâ–‚â–â–â–â–‚â–ƒâ–ƒâ–â–â–â–‚â–ƒâ–„â–ˆâ–…â–„â–â–â–ƒâ–â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–â–ˆâ–„â–„â–„â–â–„â–„â–â–â–„â–„â–ˆâ–„â–„â–â–ˆâ–„â–„â–ˆâ–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–â–„â–ˆâ–â–„â–„â–„â–â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92209
wandb: best/eval_avg_mil_loss 0.32343
wandb:  best/eval_ensemble_f1 0.92209
wandb:            eval/avg_f1 0.84296
wandb:      eval/avg_mil_loss 0.37434
wandb:       eval/ensemble_f1 0.84296
wandb:            test/avg_f1 0.91784
wandb:      test/avg_mil_loss 0.14218
wandb:       test/ensemble_f1 0.91784
wandb:           train/avg_f1 0.89615
wandb:      train/ensemble_f1 0.89615
wandb:         train/mil_loss 0.49849
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run volcanic-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8qgg6zux
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092713-8qgg6zux/logs
wandb: Agent Starting Run: vo5ivjpd with config:
wandb: 	actor_learning_rate: 2.952703079266372e-06
wandb: 	attention_dropout_p: 0.09257075001672366
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6876486397270735
wandb: 	temperature: 8.162180271180105
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092928-vo5ivjpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vo5ivjpd
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–ƒâ–ˆâ–ƒâ–‡â–ƒâ–ˆâ–‡â–â–ˆâ–‡â–â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–‚â–ˆâ–‡â–‡â–ˆâ–ˆâ–‚â–‡â–‡â–ˆâ–‡â–‡â–‡â–ƒâ–â–‡â–†â–„â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–â–â–â–ƒâ–â–„â–â–â–…â–â–ƒâ–ƒâ–…â–„â–â–…â–„â–â–â–â–â–â–„â–â–„â–ˆâ–â–â–â–„â–„â–ƒâ–…â–…â–‡â–ƒâ–
wandb:       eval/ensemble_f1 â–‡â–„â–ƒâ–ˆâ–„â–‡â–ˆâ–‡â–‚â–ˆâ–‡â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‚â–‡â–‡â–ˆâ–‡â–ˆâ–‚â–‡â–‡â–â–‡â–ˆâ–‡â–‡â–„â–„â–‚â–†â–„â–â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–‡â–‡â–ˆâ–…â–‡â–…â–â–ˆâ–†â–ˆâ–ˆâ–†â–†â–†â–†â–…â–†â–†â–ˆâ–‡â–…â–‡â–‡â–…â–†â–†â–‚â–‡â–‡â–…â–‡â–†â–‡â–…â–„â–…â–†â–†
wandb:      train/ensemble_f1 â–†â–†â–†â–‡â–ˆâ–‡â–…â–‡â–â–…â–ˆâ–„â–†â–†â–†â–†â–…â–†â–†â–ˆâ–ˆâ–‡â–†â–†â–‡â–†â–‚â–‡â–…â–†â–†â–‡â–„â–†â–‡â–…â–„â–…â–†â–†
wandb:         train/mil_loss â–„â–„â–ƒâ–„â–†â–ƒâ–„â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–†â–‡â–…â–ƒâ–‚â–â–„â–„â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–„â–‚â–„â–ˆâ–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90646
wandb: best/eval_avg_mil_loss 0.32798
wandb:  best/eval_ensemble_f1 0.90646
wandb:            eval/avg_f1 0.85032
wandb:      eval/avg_mil_loss 0.37514
wandb:       eval/ensemble_f1 0.85032
wandb:            test/avg_f1 0.84214
wandb:      test/avg_mil_loss 0.18276
wandb:       test/ensemble_f1 0.84214
wandb:           train/avg_f1 0.78801
wandb:      train/ensemble_f1 0.78801
wandb:         train/mil_loss 1.12755
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run restful-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vo5ivjpd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092928-vo5ivjpd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jqfjbzjk with config:
wandb: 	actor_learning_rate: 0.00010266024307139768
wandb: 	attention_dropout_p: 0.2405611729696343
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2616956315673892
wandb: 	temperature: 1.648445395053364
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093031-jqfjbzjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqfjbzjk
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 98-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–â–„â–‚â–ƒâ–‡â–ƒâ–ˆâ–ˆâ–â–ƒâ–‚â–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–‚â–‡â–ˆâ–ƒâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–‚â–‚â–„â–„â–‚â–ˆâ–ˆâ–„
wandb:      eval/avg_mil_loss â–â–‚â–ˆâ–â–â–â–ƒâ–â–‡â–„â–â–â–â–ƒâ–‚â–â–â–ƒâ–â–ˆâ–†â–â–â–ƒâ–„â–ƒâ–„â–„â–â–ƒâ–…â–†â–ƒâ–â–…â–ƒâ–â–â–â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–ƒâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–„â–ƒâ–ˆâ–‡â–ˆâ–ˆâ–‚â–ƒâ–ˆâ–„â–‚â–â–ƒâ–ˆâ–„â–ˆâ–„â–ˆâ–„â–„â–ˆâ–‡â–„â–‚â–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–†â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–„â–†â–â–„â–„â–ƒâ–…â–„â–‚â–†â–†â–‚â–„â–†â–ƒâ–„â–†â–ƒâ–‡â–ˆâ–‡â–…â–„â–‡â–ƒâ–†â–†â–‚â–†â–ˆâ–„
wandb:      train/ensemble_f1 â–ƒâ–„â–„â–…â–ƒâ–…â–…â–ƒâ–‚â–‡â–†â–„â–‚â–„â–†â–„â–„â–„â–†â–‚â–†â–ƒâ–‡â–â–ƒâ–‡â–„â–…â–†â–„â–…â–â–ƒâ–†â–„â–„â–„â–†â–ˆâ–ƒ
wandb:         train/mil_loss â–…â–…â–ƒâ–ƒâ–â–„â–„â–ƒâ–…â–…â–ƒâ–„â–ƒâ–†â–†â–ƒâ–…â–ƒâ–‡â–„â–„â–‚â–…â–ƒâ–ˆâ–ƒâ–„â–„â–‡â–„â–ƒâ–ƒâ–‡â–„â–„â–„â–ƒâ–…â–…â–ƒ
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91394
wandb: best/eval_avg_mil_loss 0.28028
wandb:  best/eval_ensemble_f1 0.91394
wandb:            eval/avg_f1 0.65381
wandb:      eval/avg_mil_loss 1.11583
wandb:       eval/ensemble_f1 0.65381
wandb:           train/avg_f1 0.75394
wandb:      train/ensemble_f1 0.75394
wandb:         train/mil_loss 0.76163
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqfjbzjk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093031-jqfjbzjk/logs
wandb: ERROR Run jqfjbzjk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jmf7lt5b with config:
wandb: 	actor_learning_rate: 4.783900197690554e-06
wandb: 	attention_dropout_p: 0.4841232938032552
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18035406233942253
wandb: 	temperature: 7.68870466099819
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093158-jmf7lt5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jmf7lt5b
wandb: uploading wandb-summary.json
wandb: uploading history steps 133-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–„â–ˆâ–„â–â–ˆâ–ˆâ–‡â–‡â–ƒâ–ˆâ–‚â–ˆâ–‡â–ƒâ–…â–ˆâ–„â–ˆâ–ƒâ–‡â–‡â–‡â–ˆâ–‡â–‚â–‡â–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–‚â–ƒâ–†â–â–„â–â–â–â–â–ˆâ–‡â–â–‡â–â–†â–‚â–â–â–‚â–ƒâ–…â–…â–†â–„â–‚â–ƒâ–ˆâ–â–â–ƒâ–‚â–â–â–ƒâ–„â–„â–„â–„â–â–ƒ
wandb:       eval/ensemble_f1 â–‡â–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–‡â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–†â–„â–ƒâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‚â–ˆâ–ˆâ–„â–‚â–‡â–„â–ƒâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‚â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ˆâ–…â–†â–…â–…â–â–…â–†â–‡â–„â–„â–‡â–ƒâ–†â–†â–„â–‚â–†â–ƒâ–„â–†â–‡â–†â–„â–‡â–†â–…â–†â–…â–…â–â–…â–†â–†â–ƒâ–‚â–„â–†â–…
wandb:      train/ensemble_f1 â–â–†â–ˆâ–„â–„â–ˆâ–…â–„â–†â–ˆâ–‡â–‚â–„â–†â–„â–â–„â–…â–…â–‡â–ƒâ–…â–‚â–„â–†â–…â–‡â–†â–„â–„â–ƒâ–‚â–†â–‚â–ƒâ–‚â–„â–ƒâ–„â–†
wandb:         train/mil_loss â–ƒâ–‚â–ƒâ–…â–„â–ƒâ–‚â–â–ƒâ–„â–†â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–ˆâ–‚â–„â–ˆâ–…â–…â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…
wandb:      train/policy_loss â–„â–„â–â–â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–†â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–†â–„â–ˆâ–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9216
wandb: best/eval_avg_mil_loss 0.26256
wandb:  best/eval_ensemble_f1 0.9216
wandb:            eval/avg_f1 0.90438
wandb:      eval/avg_mil_loss 0.30195
wandb:       eval/ensemble_f1 0.90438
wandb:            test/avg_f1 0.88136
wandb:      test/avg_mil_loss 1.15121
wandb:       test/ensemble_f1 0.88136
wandb:           train/avg_f1 0.80866
wandb:      train/ensemble_f1 0.80866
wandb:         train/mil_loss 0.70966
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run distinctive-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jmf7lt5b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093158-jmf7lt5b/logs
wandb: Agent Starting Run: eyxkcw0l with config:
wandb: 	actor_learning_rate: 1.1172883419379586e-06
wandb: 	attention_dropout_p: 0.1873729909872514
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 86
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9529914191154164
wandb: 	temperature: 4.176845460679351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093357-eyxkcw0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eyxkcw0l
wandb: uploading wandb-summary.json
wandb: uploading history steps 75-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–ˆâ–‚â–ˆâ–ƒâ–â–‚â–ƒâ–„â–‡â–ˆâ–â–„â–‡â–„â–‚â–ˆâ–†â–ˆâ–‚â–…â–†â–â–ˆâ–ƒâ–ˆâ–…â–‡â–‡â–ˆâ–‚â–ˆâ–ƒâ–ˆâ–„â–ˆâ–‚â–ˆâ–‚â–‚
wandb:      eval/avg_mil_loss â–†â–„â–‡â–‡â–‚â–ƒâ–‚â–‡â–…â–„â–â–ƒâ–…â–‡â–ƒâ–‡â–„â–…â–…â–„â–‡â–„â–…â–â–…â–ƒâ–†â–…â–†â–…â–â–ˆâ–…â–„â–…â–…â–„â–„â–ˆâ–†
wandb:       eval/ensemble_f1 â–‚â–ˆâ–ƒâ–ƒâ–â–â–ƒâ–…â–‚â–„â–„â–ˆâ–ˆâ–„â–ˆâ–â–‚â–ˆâ–‚â–ƒâ–‚â–ˆâ–‡â–‡â–‚â–‡â–â–„â–ƒâ–‚â–‚â–„â–‡â–ˆâ–ˆâ–ˆâ–„â–‚â–…â–ƒ
wandb:           train/avg_f1 â–ƒâ–ˆâ–ƒâ–†â–„â–…â–ƒâ–…â–„â–†â–„â–†â–…â–„â–„â–†â–…â–…â–†â–…â–„â–†â–ƒâ–†â–…â–†â–â–†â–„â–ˆâ–‡â–…â–ˆâ–†â–„â–ƒâ–†â–†â–†â–„
wandb:      train/ensemble_f1 â–†â–â–…â–…â–‚â–ƒâ–â–…â–…â–†â–ƒâ–…â–„â–ƒâ–„â–ƒâ–„â–…â–„â–…â–…â–…â–„â–ƒâ–†â–ƒâ–…â–„â–†â–†â–ˆâ–ƒâ–†â–„â–‡â–†â–‡â–†â–†â–ƒ
wandb:         train/mil_loss â–…â–‚â–„â–†â–…â–„â–‡â–…â–„â–„â–‡â–‚â–‡â–…â–ƒâ–†â–„â–ˆâ–„â–„â–ˆâ–„â–‚â–†â–ƒâ–…â–ƒâ–‡â–ƒâ–„â–†â–…â–‚â–†â–â–…â–‚â–‚â–„â–„
wandb:      train/policy_loss â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91069
wandb: best/eval_avg_mil_loss 0.38449
wandb:  best/eval_ensemble_f1 0.91069
wandb:            eval/avg_f1 0.57209
wandb:      eval/avg_mil_loss 1.67005
wandb:       eval/ensemble_f1 0.57209
wandb:           train/avg_f1 0.68577
wandb:      train/ensemble_f1 0.68577
wandb:         train/mil_loss 0.98708
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dandy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eyxkcw0l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093357-eyxkcw0l/logs
wandb: ERROR Run eyxkcw0l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: c9dr46ky with config:
wandb: 	actor_learning_rate: 7.611665203993396e-05
wandb: 	attention_dropout_p: 0.4879884470965411
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 82
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.96073281361581
wandb: 	temperature: 0.28715318214363905
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093515-c9dr46ky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c9dr46ky
wandb: uploading history steps 72-82, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–‡â–ˆâ–â–ˆâ–‡â–„â–‡â–‚â–ƒâ–‡â–‡â–ƒâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–„â–…â–ƒâ–‚
wandb:      eval/avg_mil_loss â–…â–„â–â–â–ˆâ–…â–„â–ƒâ–‚â–ƒâ–‚â–â–â–…â–…â–â–â–ƒâ–„â–â–â–â–‚â–â–â–â–ƒâ–„â–â–â–â–ƒâ–â–â–â–‚â–â–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–ƒâ–‡â–‡â–ˆâ–â–‡â–‡â–„â–‡â–‚â–ƒâ–‡â–ƒâ–ˆâ–ƒâ–ˆâ–ƒâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‚â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ƒâ–‡â–…â–ƒâ–„â–‡
wandb:           train/avg_f1 â–†â–…â–„â–‚â–…â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–†â–„â–‚â–…â–‚â–‚â–†â–†â–„â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–…â–„â–…â–…â–„â–†â–ƒâ–…â–â–ƒâ–ˆ
wandb:      train/ensemble_f1 â–…â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ˆâ–„â–…â–ƒâ–ƒâ–‡â–‚â–ƒâ–…â–†â–„â–„â–„â–†â–…â–ƒâ–â–„â–…â–â–†â–ƒâ–†â–…â–‚â–ƒâ–â–„â–ˆ
wandb:         train/mil_loss â–‚â–…â–„â–â–‚â–…â–„â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–…â–„â–…â–…â–‚â–ƒâ–ƒâ–…â–„â–â–†â–‡â–…â–„â–‚â–†â–‚â–ˆâ–ƒâ–‚â–…â–ƒâ–ƒâ–â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–„â–ˆâ–â–„â–„â–â–â–„â–â–â–â–„â–„â–ˆâ–„â–ˆâ–â–â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–ˆâ–„â–„â–ˆâ–â–„â–â–ˆâ–„â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.25373
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.89279
wandb:      eval/avg_mil_loss 0.3291
wandb:       eval/ensemble_f1 0.89279
wandb:           train/avg_f1 0.89844
wandb:      train/ensemble_f1 0.89844
wandb:         train/mil_loss 0.36859
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run floral-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c9dr46ky
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093515-c9dr46ky/logs
wandb: ERROR Run c9dr46ky errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5tnowm5w with config:
wandb: 	actor_learning_rate: 1.2914001917263224e-05
wandb: 	attention_dropout_p: 0.28544454523367135
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5473075968264228
wandb: 	temperature: 6.055832141287913
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093638-5tnowm5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5tnowm5w
wandb: uploading history steps 97-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–…â–ƒâ–†â–†â–„â–…â–†â–†â–…â–†â–†â–‚â–†â–…â–…â–…â–†â–†â–„â–‡â–‡â–†â–‡â–„â–†â–‡â–ˆâ–‡â–‡â–‡â–â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ƒâ–†â–‡
wandb:      train/ensemble_f1 â–ˆâ–„â–‡â–†â–†â–†â–…â–†â–ˆâ–†â–…â–‡â–‚â–‚â–‡â–†â–ˆâ–†â–‡â–‡â–†â–‡â–„â–…â–†â–‡â–‡â–ˆâ–‡â–†â–…â–â–†â–ƒâ–†â–‡â–„â–‡â–„â–‡
wandb:         train/mil_loss â–„â–„â–„â–ƒâ–‡â–ˆâ–…â–ƒâ–„â–„â–…â–ƒâ–…â–‡â–„â–„â–â–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–„â–‡â–ƒâ–ƒâ–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–†â–„
wandb:      train/policy_loss â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91373
wandb: best/eval_avg_mil_loss 0.35477
wandb:  best/eval_ensemble_f1 0.91373
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.35803
wandb:       eval/ensemble_f1 0.90599
wandb:           train/avg_f1 0.90372
wandb:      train/ensemble_f1 0.90372
wandb:         train/mil_loss 0.29869
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smart-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5tnowm5w
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093638-5tnowm5w/logs
wandb: ERROR Run 5tnowm5w errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: s7eu13fm with config:
wandb: 	actor_learning_rate: 0.0005429441428349776
wandb: 	attention_dropout_p: 0.26187093801785183
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3447506534582091
wandb: 	temperature: 0.20998940817962383
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093812-s7eu13fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s7eu13fm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–…â–†â–†â–‚â–…â–ƒâ–ƒâ–â–ˆâ–‚â–ˆâ–‡â–‚â–ƒâ–ˆâ–†â–ˆâ–‚â–ƒâ–ˆâ–ˆâ–‚â–„â–„â–ˆâ–â–†â–…â–‡â–‚â–ˆâ–„â–‚â–‡â–ˆâ–ˆâ–ƒâ–‡
wandb:      eval/avg_mil_loss â–…â–â–‚â–‚â–‚â–…â–â–ˆâ–â–…â–â–†â–…â–â–ˆâ–…â–…â–…â–â–…â–‡â–‡â–‚â–â–…â–‚â–†â–…â–â–ƒâ–â–‡â–†â–‚â–â–â–‚â–†â–…â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–‡â–‚â–ˆâ–„â–†â–„â–†â–ƒâ–‡â–ˆâ–ˆâ–‚â–„â–ƒâ–ƒâ–ˆâ–†â–†â–ˆâ–„â–„â–‡â–„â–ƒâ–ˆâ–…â–ƒâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–„â–‚â–„â–‡â–ƒâ–„â–â–…â–‡â–…â–†â–‡â–…â–‚â–„â–„â–ˆâ–â–ƒâ–‚â–†â–…â–„â–†â–‡â–‡â–†â–…â–…â–ƒâ–…â–…â–„â–…â–…â–„â–…â–ƒâ–†â–†
wandb:      train/ensemble_f1 â–â–â–…â–‡â–ƒâ–ˆâ–ƒâ–„â–…â–†â–†â–ƒâ–ˆâ–„â–ƒâ–…â–…â–…â–†â–†â–…â–ƒâ–‡â–‡â–‡â–…â–ƒâ–†â–†â–…â–„â–†â–ƒâ–…â–‡â–„â–ƒâ–…â–„â–†
wandb:         train/mil_loss â–ƒâ–ƒâ–„â–ƒâ–„â–…â–„â–‚â–„â–‚â–…â–„â–‚â–ƒâ–„â–‚â–„â–ƒâ–…â–…â–‚â–…â–ƒâ–ƒâ–ˆâ–„â–…â–ƒâ–â–…â–„â–„â–„â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.34591
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.78501
wandb:      eval/avg_mil_loss 1.44905
wandb:       eval/ensemble_f1 0.78501
wandb:           train/avg_f1 0.79751
wandb:      train/ensemble_f1 0.79751
wandb:         train/mil_loss 1.06679
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s7eu13fm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093812-s7eu13fm/logs
wandb: ERROR Run s7eu13fm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: uxvrxflz with config:
wandb: 	actor_learning_rate: 7.61640452576267e-05
wandb: 	attention_dropout_p: 0.3315159986110641
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7903026128452927
wandb: 	temperature: 6.3327780278767465
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094042-uxvrxflz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uxvrxflz
wandb: uploading history steps 52-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–„â–â–
wandb:  best/eval_ensemble_f1 â–â–â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–ˆâ–ˆâ–ƒâ–†â–ƒâ–‚â–â–…â–†â–‡â–…â–‚â–ƒâ–…â–ˆâ–‚â–ƒâ–‡â–…â–ˆâ–…â–†â–…â–…â–„â–ˆâ–†â–‚â–†â–ˆâ–ƒâ–…â–…â–ƒâ–…â–„â–„â–…
wandb:      eval/avg_mil_loss â–‡â–„â–…â–â–„â–†â–„â–†â–…â–†â–…â–…â–‚â–‡â–ˆâ–ƒâ–†â–‡â–„â–ƒâ–…â–„â–â–„â–„â–†â–…â–â–ˆâ–ƒâ–†â–â–†â–‡â–†â–„â–…â–‡â–‡â–‡
wandb:       eval/ensemble_f1 â–…â–…â–„â–ƒâ–ƒâ–‚â–â–…â–†â–†â–‚â–ƒâ–ƒâ–‚â–…â–…â–ƒâ–†â–‡â–‚â–…â–ˆâ–…â–…â–†â–†â–ˆâ–ƒâ–‚â–†â–†â–…â–…â–…â–†â–„â–ƒâ–ˆâ–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–†â–†â–†â–ƒâ–ƒâ–…â–„â–„â–„â–ƒâ–…â–…â–‚â–‡â–†â–„â–ƒâ–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–„â–„â–ƒâ–†â–†â–„â–„â–ƒâ–â–†â–ˆâ–…
wandb:      train/ensemble_f1 â–…â–‡â–†â–‡â–‡â–„â–„â–†â–…â–…â–†â–ƒâ–‡â–ˆâ–‡â–…â–„â–†â–†â–„â–…â–„â–„â–…â–ƒâ–ƒâ–…â–ˆâ–‚â–‡â–„â–â–…â–‚â–…â–…â–„â–‡â–†â–†
wandb:         train/mil_loss â–†â–…â–…â–ƒâ–…â–„â–†â–‚â–‡â–‚â–…â–†â–…â–ƒâ–…â–‡â–„â–†â–„â–…â–„â–ƒâ–‡â–„â–‡â–ƒâ–ƒâ–‚â–â–ƒâ–‡â–â–ˆâ–…â–ƒâ–ƒâ–ˆâ–‡â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90018
wandb: best/eval_avg_mil_loss 0.28763
wandb:  best/eval_ensemble_f1 0.90018
wandb:            eval/avg_f1 0.7422
wandb:      eval/avg_mil_loss 1.09002
wandb:       eval/ensemble_f1 0.7422
wandb:            test/avg_f1 0.72624
wandb:      test/avg_mil_loss 1.63631
wandb:       test/ensemble_f1 0.72624
wandb:           train/avg_f1 0.72518
wandb:      train/ensemble_f1 0.72518
wandb:         train/mil_loss 1.5003
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uxvrxflz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094042-uxvrxflz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 57ejpc1r with config:
wandb: 	actor_learning_rate: 1.6045296968276115e-06
wandb: 	attention_dropout_p: 0.40250382391121936
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06872622173887477
wandb: 	temperature: 1.9738155430297888
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094154-57ejpc1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57ejpc1r
wandb: uploading history steps 98-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–‡â–…â–ˆâ–‡â–†â–‡â–†â–â–†â–ƒâ–ˆâ–‡â–‡â–†â–ˆâ–†â–ˆâ–†â–†â–†â–†â–…â–†â–†â–†â–„â–‡â–‡â–‡â–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–‚â–‚â–‚â–â–‡â–„â–‚â–‡â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–ˆâ–‚â–â–‚â–ƒâ–â–ƒâ–‚â–‚
wandb:       eval/ensemble_f1 â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–†â–†â–ˆâ–‡â–†â–‡â–†â–â–…â–ˆâ–ƒâ–‡â–â–†â–ˆâ–†â–†â–ˆâ–†â–…â–†â–†â–â–„â–…â–‡â–‡â–…â–†â–‡â–‡â–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–…â–†â–â–†â–„â–…â–…â–ƒâ–„â–…â–ƒâ–‡â–…â–†â–…â–‚â–ƒâ–„â–†â–…â–…â–†â–ƒâ–â–„â–†â–„â–…â–†â–ƒâ–ƒâ–†â–„â–†â–„â–‡â–ƒâ–ˆ
wandb:      train/ensemble_f1 â–„â–‚â–ƒâ–†â–„â–‡â–‡â–†â–…â–†â–†â–„â–…â–„â–ƒâ–ƒâ–…â–ƒâ–ˆâ–„â–‡â–â–†â–„â–‚â–‡â–ƒâ–†â–ƒâ–…â–…â–ƒâ–„â–â–ˆâ–‚â–„â–†â–ˆâ–…
wandb:         train/mil_loss â–ƒâ–ƒâ–ˆâ–â–„â–‡â–â–‚â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–„â–„â–„â–‚â–‚â–„â–‡â–†â–‚â–ƒâ–ƒâ–‡â–‚â–‚â–ƒâ–‚â–…â–ƒâ–„â–„â–‚â–â–‚â–â–…â–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91845
wandb: best/eval_avg_mil_loss 0.24984
wandb:  best/eval_ensemble_f1 0.91845
wandb:            eval/avg_f1 0.89558
wandb:      eval/avg_mil_loss 0.28583
wandb:       eval/ensemble_f1 0.89558
wandb:            test/avg_f1 0.9141
wandb:      test/avg_mil_loss 0.24262
wandb:       test/ensemble_f1 0.9141
wandb:           train/avg_f1 0.92089
wandb:      train/ensemble_f1 0.92089
wandb:         train/mil_loss 0.25777
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run electric-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57ejpc1r
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094154-57ejpc1r/logs
wandb: Agent Starting Run: d99fxs4f with config:
wandb: 	actor_learning_rate: 0.0001370305254997265
wandb: 	attention_dropout_p: 0.16939373118113216
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45898401470441386
wandb: 	temperature: 7.518377484204125
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094353-d99fxs4f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d99fxs4f
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–‡â–ˆâ–†â–ˆâ–ƒâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ƒâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–â–‚â–ƒâ–â–ˆâ–‡â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–â–â–„â–â–†â–†â–â–â–â–â–â–â–ƒâ–â–â–„â–ƒâ–„â–†â–‡â–â–„â–â–â–…â–â–„â–â–â–…â–â–ˆâ–ƒâ–â–â–â–â–
wandb:       eval/ensemble_f1 â–‚â–ˆâ–ˆâ–ˆâ–‡â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–‡â–ˆâ–‚â–ˆâ–â–‚â–ˆâ–ˆâ–â–ˆâ–â–ƒâ–ˆâ–ˆâ–ˆâ–„â–‚â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ƒâ–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–…â–‚â–‡â–…â–‚â–…â–†â–â–ƒâ–†â–‡â–…â–„â–…â–…â–‡â–„â–†â–ƒâ–‡â–†â–…â–†â–†â–â–„â–†â–„â–ˆâ–…â–†â–†â–„â–„â–„â–„â–…â–ƒâ–…â–ˆ
wandb:      train/ensemble_f1 â–‡â–…â–‚â–‡â–ˆâ–„â–ƒâ–â–‡â–‡â–…â–„â–ƒâ–‡â–‡â–ƒâ–‡â–…â–…â–†â–â–„â–‡â–…â–„â–ˆâ–…â–„â–†â–…â–„â–‚â–†â–†â–…â–†â–ƒâ–…â–„â–…
wandb:         train/mil_loss â–…â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–„â–ƒâ–â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–„â–…â–‚â–‚â–‚â–ƒâ–„â–„â–…â–†â–ƒâ–‚â–„â–ƒâ–…â–„â–‚â–ˆâ–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–â–„â–„â–„â–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91778
wandb: best/eval_avg_mil_loss 0.28572
wandb:  best/eval_ensemble_f1 0.91778
wandb:            eval/avg_f1 0.91778
wandb:      eval/avg_mil_loss 0.2839
wandb:       eval/ensemble_f1 0.91778
wandb:           train/avg_f1 0.84421
wandb:      train/ensemble_f1 0.84421
wandb:         train/mil_loss 0.47214
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d99fxs4f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094353-d99fxs4f/logs
wandb: ERROR Run d99fxs4f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hiynwmf6 with config:
wandb: 	actor_learning_rate: 0.00013187692182470658
wandb: 	attention_dropout_p: 0.4335472372877428
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19405331884230503
wandb: 	temperature: 8.127329669569884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094526-hiynwmf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hiynwmf6
wandb: uploading wandb-summary.json
wandb: uploading history steps 154-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–â–â–ˆâ–â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–„â–„â–â–„â–‚â–â–â–â–ˆâ–†â–‚â–‚â–„â–‚â–â–„â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–…â–â–â–â–‚â–‚â–„â–â–„â–‚â–‚â–‚â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–„â–‡â–â–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–…â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‡â–†â–†â–‡â–…â–†â–†â–‡â–ƒâ–†â–‡â–†â–…â–‡â–‡â–ˆâ–„â–†â–‡â–‡â–ƒâ–„â–ˆâ–‡â–ˆâ–†â–„â–‚â–ƒâ–†â–‡â–‡â–ƒâ–…â–â–‡â–…â–ˆ
wandb:      train/ensemble_f1 â–‡â–‡â–„â–ˆâ–…â–…â–‡â–ˆâ–„â–‡â–†â–…â–ˆâ–‡â–…â–…â–‚â–…â–‡â–†â–‡â–…â–„â–…â–„â–ˆâ–‡â–†â–‡â–ˆâ–…â–„â–†â–‡â–…â–ˆâ–â–‡â–…â–‡
wandb:         train/mil_loss â–â–‚â–„â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–„â–â–â–ƒâ–‚â–„â–â–â–â–‚â–â–„â–â–â–â–â–„â–…â–ƒâ–ˆâ–ƒâ–â–‚â–â–â–ƒ
wandb:      train/policy_loss â–â–ˆâ–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–â–ˆâ–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92542
wandb: best/eval_avg_mil_loss 0.24626
wandb:  best/eval_ensemble_f1 0.92542
wandb:            eval/avg_f1 0.91394
wandb:      eval/avg_mil_loss 0.27131
wandb:       eval/ensemble_f1 0.91394
wandb:            test/avg_f1 0.92596
wandb:      test/avg_mil_loss 0.12897
wandb:       test/ensemble_f1 0.92596
wandb:           train/avg_f1 0.86619
wandb:      train/ensemble_f1 0.86619
wandb:         train/mil_loss 0.66241
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run classic-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hiynwmf6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094526-hiynwmf6/logs
wandb: Agent Starting Run: 3urx7w4z with config:
wandb: 	actor_learning_rate: 6.762336624211239e-05
wandb: 	attention_dropout_p: 0.4441611410334853
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9684900351198646
wandb: 	temperature: 4.020802803396341
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094742-3urx7w4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3urx7w4z
wandb: uploading history steps 126-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–‚â–„â–„â–ˆâ–ƒâ–â–†â–†â–â–‡â–†â–ˆâ–ƒâ–†â–‡â–„â–…â–‡â–ˆâ–‡â–‡â–‡â–â–„â–†â–‡â–†â–‡â–…â–‡â–‡â–„â–ˆâ–†â–‚â–…â–†â–„
wandb:      eval/avg_mil_loss â–‚â–‚â–…â–ƒâ–…â–‡â–‚â–…â–‚â–â–†â–‚â–†â–â–‚â–‚â–‚â–…â–‚â–ƒâ–â–‚â–â–†â–‚â–‚â–â–…â–‚â–†â–ˆâ–…â–‚â–…â–…â–‚â–†â–…â–…â–†
wandb:       eval/ensemble_f1 â–…â–‡â–ˆâ–‡â–†â–…â–‡â–…â–„â–‡â–ƒâ–‡â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–‡â–ƒâ–ƒâ–„â–ˆâ–†â–„â–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–‡â–‡â–‚â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–â–‡â–…â–â–„â–†â–†â–ƒâ–…â–ˆâ–ƒâ–…â–‡â–„â–‡â–†â–„â–‡â–‡â–„â–„â–ƒâ–„â–‡â–…â–…â–…â–‡â–â–†â–‡â–‡â–…â–„â–…â–…â–ˆâ–ˆâ–‡
wandb:      train/ensemble_f1 â–…â–„â–ƒâ–ƒâ–„â–„â–‚â–…â–„â–…â–…â–„â–…â–‡â–†â–„â–…â–ƒâ–ƒâ–„â–„â–â–ˆâ–„â–„â–…â–„â–…â–„â–…â–†â–…â–ƒâ–†â–…â–„â–‡â–†â–‡â–…
wandb:         train/mil_loss â–ƒâ–…â–‚â–†â–„â–…â–â–„â–…â–†â–…â–‚â–…â–„â–ˆâ–†â–†â–„â–…â–ƒâ–ƒâ–†â–…â–†â–…â–†â–…â–…â–‚â–‚â–ˆâ–„â–ƒâ–„â–„â–‡â–†â–†â–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92261
wandb: best/eval_avg_mil_loss 0.24257
wandb:  best/eval_ensemble_f1 0.92261
wandb:            eval/avg_f1 0.77933
wandb:      eval/avg_mil_loss 0.78973
wandb:       eval/ensemble_f1 0.77933
wandb:            test/avg_f1 0.87293
wandb:      test/avg_mil_loss 0.27112
wandb:       test/ensemble_f1 0.87293
wandb:           train/avg_f1 0.84597
wandb:      train/ensemble_f1 0.84597
wandb:         train/mil_loss 0.60393
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run splendid-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3urx7w4z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094742-3urx7w4z/logs
wandb: Agent Starting Run: m3xx7wg1 with config:
wandb: 	actor_learning_rate: 0.0002351829971807688
wandb: 	attention_dropout_p: 0.35102959265826617
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8553385289439946
wandb: 	temperature: 0.027662860250360355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095017-m3xx7wg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m3xx7wg1
wandb: uploading history steps 53-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–„â–ˆâ–‡â–‡â–‡â–…â–…â–‡â–ƒâ–‡â–…â–‡
wandb:      eval/avg_mil_loss â–‚â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–ƒâ–‚â–â–‚â–â–‚â–â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–ƒâ–
wandb:       eval/ensemble_f1 â–ˆâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–…â–‡â–ˆâ–‡â–ˆâ–‡â–â–„â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–…â–…â–‡â–„â–ˆâ–‡â–†
wandb:           train/avg_f1 â–…â–…â–„â–‡â–„â–‡â–†â–†â–†â–…â–‚â–â–…â–…â–…â–†â–…â–…â–„â–…â–ˆâ–…â–†â–„â–…â–‚â–‚â–‚â–ƒâ–…â–…â–ƒâ–†â–†â–„â–…â–…â–‚â–†â–…
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–„â–‡â–†â–†â–„â–‡â–…â–„â–…â–„â–†â–‚â–†â–…â–…â–„â–…â–ˆâ–…â–†â–†â–…â–‚â–â–‚â–„â–…â–…â–ƒâ–†â–„â–ƒâ–…â–„â–â–†â–„
wandb:         train/mil_loss â–‚â–‡â–‚â–…â–ˆâ–ƒâ–ƒâ–†â–ƒâ–â–‚â–‚â–ƒâ–â–ˆâ–„â–‡â–‚â–ˆâ–‡â–â–…â–‚â–‚â–‚â–†â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–†â–‚â–‡â–ƒâ–…â–‚â–‚
wandb:      train/policy_loss â–ˆâ–…â–…â–â–…â–…â–…â–ˆâ–â–…â–â–…â–…â–â–…â–…â–ˆâ–…â–ˆâ–…â–…â–â–â–â–…â–…â–ˆâ–…â–â–ˆâ–â–…â–ˆâ–…â–…â–…â–…â–â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–â–„â–ˆâ–„â–ˆâ–â–„â–„â–â–„â–â–ˆâ–ˆâ–ˆâ–„â–â–„â–â–â–„â–„â–„â–„â–„â–â–ˆâ–„â–â–ˆâ–„â–„â–â–„â–„â–â–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.25784
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.89312
wandb:      eval/avg_mil_loss 0.28897
wandb:       eval/ensemble_f1 0.89312
wandb:           train/avg_f1 0.88406
wandb:      train/ensemble_f1 0.88406
wandb:         train/mil_loss 0.27883
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run soft-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m3xx7wg1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095017-m3xx7wg1/logs
wandb: ERROR Run m3xx7wg1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 747zbtng with config:
wandb: 	actor_learning_rate: 5.446871493996085e-05
wandb: 	attention_dropout_p: 0.24088806064303053
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9471846256307596
wandb: 	temperature: 0.0902846941456248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095118-747zbtng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/747zbtng
wandb: uploading wandb-summary.json
wandb: uploading history steps 77-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–ƒâ–‡â–ˆâ–‚â–‡â–ƒâ–‡â–ƒâ–‡â–ˆâ–†â–‡â–ˆâ–„â–ˆâ–‡â–ƒâ–ˆâ–â–ƒâ–ƒâ–‡â–…â–‚â–‡â–‡â–‡â–‡â–ˆâ–†â–‚â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:      eval/avg_mil_loss â–â–„â–„â–†â–„â–â–ˆâ–„â–â–„â–„â–„â–†â–â–â–â–â–â–†â–â–…â–†â–â–â–„â–„â–„â–†â–…â–ƒâ–†â–‚â–â–â–â–‚â–â–„â–„â–„
wandb:       eval/ensemble_f1 â–‡â–ƒâ–ˆâ–‚â–‡â–‡â–ˆâ–ˆâ–ƒâ–†â–ƒâ–†â–‡â–†â–…â–â–‡â–ˆâ–â–‡â–‚â–„â–ˆâ–‡â–‡â–†â–â–‡â–ˆâ–ƒâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–‚â–„â–â–ƒâ–‚â–‚â–ƒâ–…â–‚â–ƒâ–…â–ƒâ–‡â–†â–ˆâ–ƒâ–„â–…â–„â–ƒâ–„â–ƒâ–‚â–…â–…â–„â–â–…â–‚â–„â–…â–ƒâ–â–…â–ƒâ–ƒâ–‚â–…â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–‚â–…â–„â–…â–‚â–â–ƒâ–…â–†â–ˆâ–…â–…â–…â–ƒâ–…â–â–„â–‡â–…â–ƒâ–ƒâ–†â–†â–‚â–‡â–†â–…â–ƒâ–‚â–ƒâ–†â–…â–†â–…â–„â–ƒâ–„â–„
wandb:         train/mil_loss â–†â–…â–â–†â–„â–…â–…â–ƒâ–ƒâ–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–„â–…â–ƒâ–†â–‚â–„â–†â–…â–â–‚â–„â–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–„â–„â–ƒâ–„â–â–‚â–‚â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.90599
wandb: best/eval_avg_mil_loss 0.4274
wandb:  best/eval_ensemble_f1 0.90599
wandb:            eval/avg_f1 0.89963
wandb:      eval/avg_mil_loss 0.3237
wandb:       eval/ensemble_f1 0.89963
wandb:            test/avg_f1 0.93076
wandb:      test/avg_mil_loss 0.24036
wandb:       test/ensemble_f1 0.93076
wandb:           train/avg_f1 0.70968
wandb:      train/ensemble_f1 0.70968
wandb:         train/mil_loss 0.66249
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run royal-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/747zbtng
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095118-747zbtng/logs
wandb: Agent Starting Run: byxpzky8 with config:
wandb: 	actor_learning_rate: 0.00099198934739014
wandb: 	attention_dropout_p: 0.26310195958770494
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9115050412175368
wandb: 	temperature: 8.209561595887441
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095241-byxpzky8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/byxpzky8
wandb: uploading history steps 125-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–…â–†â–ˆâ–‡â–‡â–â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–…â–ˆâ–‡â–„â–„â–…â–ˆâ–†â–‡â–‡â–†â–‡â–„â–‡â–‡â–‡â–‡
wandb:      eval/avg_mil_loss â–â–…â–…â–â–ˆâ–‚â–â–â–…â–â–â–â–„â–â–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–â–â–‚â–â–‚â–„â–…â–â–„â–‚â–â–…â–â–â–ƒâ–â–â–
wandb:       eval/ensemble_f1 â–…â–‡â–„â–„â–‡â–…â–â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–…â–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–†â–ƒâ–ˆâ–…â–ƒâ–‚â–‡â–‡â–ƒâ–…â–†â–†â–…â–ƒâ–„â–‡â–ˆâ–‡â–‡
wandb:           train/avg_f1 â–„â–…â–„â–‚â–…â–†â–…â–„â–…â–…â–„â–†â–„â–†â–…â–‡â–ƒâ–†â–†â–†â–‡â–…â–…â–†â–ƒâ–ƒâ–…â–…â–â–…â–ƒâ–ƒâ–ˆâ–ƒâ–†â–†â–‚â–‡â–ƒâ–†
wandb:      train/ensemble_f1 â–…â–†â–†â–â–…â–…â–†â–‡â–…â–ƒâ–ƒâ–…â–„â–ƒâ–…â–†â–…â–ˆâ–„â–†â–„â–…â–„â–†â–†â–ƒâ–ƒâ–†â–…â–†â–†â–…â–†â–†â–…â–†â–„â–‡â–…â–…
wandb:         train/mil_loss â–‚â–†â–„â–…â–…â–…â–‚â–â–â–†â–„â–ƒâ–ƒâ–‡â–ƒâ–…â–„â–ƒâ–…â–…â–‡â–…â–ƒâ–‚â–ƒâ–…â–„â–‚â–ƒâ–‚â–†â–…â–‡â–ˆâ–ƒâ–‚â–„â–„â–ƒâ–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.23227
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.9038
wandb:      eval/avg_mil_loss 0.28378
wandb:       eval/ensemble_f1 0.9038
wandb:           train/avg_f1 0.82635
wandb:      train/ensemble_f1 0.82635
wandb:         train/mil_loss 0.41568
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dauntless-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/byxpzky8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095241-byxpzky8/logs
wandb: ERROR Run byxpzky8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 92ttvk4t with config:
wandb: 	actor_learning_rate: 3.1793815679197725e-06
wandb: 	attention_dropout_p: 0.3471022333229003
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4994279916604113
wandb: 	temperature: 6.976248560292171
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095511-92ttvk4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92ttvk4t
wandb: uploading history steps 175-180, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‚â–‡â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–â–‡â–„â–‡â–‡â–ˆâ–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–…â–‡â–…â–„â–„â–‡â–†â–„â–‡â–…â–ƒâ–†â–‡â–…â–ƒâ–…â–†â–‚â–‚â–„â–†â–â–…â–„â–…â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–‡â–…â–„â–†â–†â–â–‚â–ˆâ–„â–„â–„â–„â–…â–„â–…â–†â–ƒâ–â–â–â–‚â–…â–†â–…â–â–…â–‚â–…â–ƒâ–ƒâ–„â–…â–ƒâ–â–ˆâ–†â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‚â–‚â–„â–‡â–â–ƒâ–‚â–ƒâ–…â–…â–†â–‚â–…â–ˆâ–…â–…â–ƒâ–„â–‡â–ƒâ–„â–ˆâ–…â–‚â–‚â–…â–‚â–…â–‡â–…â–…â–ˆâ–‚â–…â–„â–‡â–†â–…â–‡â–‚
wandb:           train/avg_f1 â–‡â–„â–…â–…â–…â–ˆâ–†â–†â–„â–…â–†â–‚â–ƒâ–‡â–ƒâ–â–…â–†â–…â–†â–„â–â–‡â–„â–‡â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–„â–†â–ˆâ–†â–ƒâ–â–„â–…â–ˆ
wandb:      train/ensemble_f1 â–‚â–…â–„â–…â–„â–‡â–ƒâ–ˆâ–†â–†â–ˆâ–…â–„â–…â–‡â–…â–ƒâ–‡â–†â–â–ƒâ–„â–‡â–‚â–ƒâ–„â–„â–ƒâ–†â–…â–„â–…â–„â–‚â–„â–‚â–…â–„â–…â–‡
wandb:         train/mil_loss â–‡â–…â–ˆâ–ƒâ–…â–‚â–ˆâ–†â–…â–„â–ˆâ–„â–„â–‚â–ƒâ–„â–„â–„â–ƒâ–ˆâ–„â–„â–…â–‡â–‚â–ƒâ–†â–‡â–‡â–…â–ƒâ–…â–†â–„â–â–ƒâ–‚â–†â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91148
wandb: best/eval_avg_mil_loss 0.29963
wandb:  best/eval_ensemble_f1 0.91148
wandb:            eval/avg_f1 0.89046
wandb:      eval/avg_mil_loss 0.33158
wandb:       eval/ensemble_f1 0.89046
wandb:           train/avg_f1 0.74767
wandb:      train/ensemble_f1 0.74767
wandb:         train/mil_loss 0.97771
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92ttvk4t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095511-92ttvk4t/logs
wandb: ERROR Run 92ttvk4t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: fu2ndrax with config:
wandb: 	actor_learning_rate: 3.807382116395525e-06
wandb: 	attention_dropout_p: 0.26214818620141983
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9732489516228262
wandb: 	temperature: 7.863696308005664
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095751-fu2ndrax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu2ndrax
wandb: uploading history steps 137-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–…â–…â–…â–†â–†â–‡â–ƒâ–…â–†â–‡â–â–â–„â–…â–ˆâ–ˆâ–†â–†â–ˆâ–…â–‡â–…â–„â–…â–„â–†â–…â–„â–‡â–ˆâ–…â–‡â–…â–â–‡â–†â–…â–…
wandb:      eval/avg_mil_loss â–‚â–…â–…â–„â–„â–…â–ƒâ–â–â–…â–†â–„â–â–‡â–â–â–‚â–†â–â–†â–…â–†â–â–†â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–â–‚â–†â–„â–„â–„â–â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–†â–…â–…â–„â–„â–‡â–…â–ƒâ–‡â–„â–‚â–„â–â–‡â–…â–†â–‡â–ˆâ–ˆâ–†â–†â–†â–†â–ˆâ–†â–ˆâ–†â–†â–‚â–ˆâ–ƒâ–ˆâ–‡â–ˆâ–„â–‡â–‡â–ˆâ–ˆ
wandb:           train/avg_f1 â–‡â–‚â–„â–„â–â–ƒâ–…â–„â–„â–…â–ƒâ–‚â–‚â–‚â–†â–„â–ƒâ–‡â–ˆâ–‡â–ƒâ–„â–†â–‡â–…â–„â–†â–„â–…â–†â–…â–‡â–‚â–†â–‡â–‚â–†â–ˆâ–†â–„
wandb:      train/ensemble_f1 â–‡â–„â–ƒâ–…â–‡â–…â–†â–…â–‚â–†â–…â–‚â–ƒâ–ˆâ–…â–‡â–ƒâ–ˆâ–ƒâ–â–‡â–‡â–†â–‚â–‡â–†â–ƒâ–†â–ˆâ–„â–†â–‡â–„â–„â–‡â–„â–‡â–‡â–â–‡
wandb:         train/mil_loss â–„â–…â–†â–…â–…â–…â–ˆâ–†â–„â–‚â–‚â–ƒâ–ˆâ–†â–ˆâ–…â–„â–…â–†â–ƒâ–„â–…â–…â–„â–‚â–ƒâ–…â–…â–†â–„â–ƒâ–†â–„â–†â–ƒâ–„â–‡â–‡â–†â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88319
wandb: best/eval_avg_mil_loss 0.34184
wandb:  best/eval_ensemble_f1 0.88319
wandb:            eval/avg_f1 0.86131
wandb:      eval/avg_mil_loss 0.76871
wandb:       eval/ensemble_f1 0.86131
wandb:           train/avg_f1 0.77393
wandb:      train/ensemble_f1 0.77393
wandb:         train/mil_loss 0.89076
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu2ndrax
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095751-fu2ndrax/logs
wandb: ERROR Run fu2ndrax errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0foc5r86 with config:
wandb: 	actor_learning_rate: 8.915415213062558e-06
wandb: 	attention_dropout_p: 0.0730310987481913
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.662167154854286
wandb: 	temperature: 8.934936714030703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100011-0foc5r86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0foc5r86
wandb: uploading history steps 124-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‡â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‚â–‚â–ˆâ–‚â–†â–…â–„â–„â–‡â–ƒâ–…â–†â–…â–†â–‡â–…â–ˆâ–…â–†â–â–„â–…â–„â–ƒâ–‡â–„â–â–ƒâ–†â–„â–†â–†â–…â–„â–‡â–…â–…â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–â–…â–ƒâ–ƒâ–…â–‚â–„â–ƒâ–†â–â–…â–„â–…â–…â–‡â–‚â–†â–‚â–ƒâ–ƒâ–ˆâ–†â–…â–ƒâ–â–â–„â–†â–…â–…â–â–…â–†â–…â–…â–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–†â–…â–†â–„â–…â–†â–…â–…â–†â–…â–„â–„â–â–†â–…â–…â–„â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–‚â–ƒâ–†â–‡â–„â–…â–ˆâ–‡â–…â–†â–…â–…â–†â–…â–†â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–â–â–‡â–„â–„â–„â–ˆâ–…â–…â–…â–„â–…â–ƒâ–„â–„â–„â–„â–„â–†â–†â–„â–†â–‚â–†â–„â–†â–ƒâ–„â–„â–ˆâ–‡â–„â–„â–†â–ƒâ–†â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–„â–‚â–‡â–…â–â–‡â–‡â–„â–…â–„â–…â–…â–„â–…â–‡â–ƒâ–…â–ˆâ–‡â–ˆâ–†â–ˆâ–„â–‡â–…â–‚â–ˆâ–„â–‡â–„â–†â–†â–†â–†â–…â–†â–†â–â–ƒ
wandb:         train/mil_loss â–ƒâ–ˆâ–†â–ƒâ–…â–â–ƒâ–‚â–ƒâ–…â–„â–ƒâ–â–†â–†â–â–…â–ˆâ–„â–…â–‡â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–†â–‚â–„â–…â–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–„â–ˆâ–„â–„â–â–„â–â–ˆâ–ˆâ–â–„â–„â–â–„â–â–â–ˆâ–„â–â–â–â–„â–„â–ˆâ–â–„â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–„â–ˆâ–â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.30824
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.84296
wandb:      eval/avg_mil_loss 0.52569
wandb:       eval/ensemble_f1 0.84296
wandb:            test/avg_f1 0.69317
wandb:      test/avg_mil_loss 1.25316
wandb:       test/ensemble_f1 0.69317
wandb:           train/avg_f1 0.74129
wandb:      train/ensemble_f1 0.74129
wandb:         train/mil_loss 0.79157
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run peach-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0foc5r86
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100011-0foc5r86/logs
wandb: Agent Starting Run: ya3t05rk with config:
wandb: 	actor_learning_rate: 1.0595850878935249e-06
wandb: 	attention_dropout_p: 0.4999530863901343
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7793793509352421
wandb: 	temperature: 2.7842751263856105
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100240-ya3t05rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ya3t05rk
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 131-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–‚â–â–ˆâ–‡â–ˆâ–ƒâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–â–ˆâ–‡â–‚â–‚â–„â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–„â–„â–…â–…â–„â–â–â–â–â–â–â–„â–â–â–ˆâ–â–â–â–â–â–‚â–â–„â–„â–â–…â–â–„â–â–â–ƒâ–ƒâ–â–â–„â–â–ˆâ–„â–â–„
wandb:       eval/ensemble_f1 â–‡â–ˆâ–‚â–‡â–‚â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–â–ƒâ–‡â–ˆâ–‡â–ˆâ–‚â–†â–‚â–‡â–‡â–ˆâ–‡â–‚â–‡â–„â–‚â–ƒâ–ƒâ–‚â–ˆâ–‚
wandb:           train/avg_f1 â–…â–‚â–ƒâ–…â–‚â–‡â–†â–ƒâ–‡â–â–‚â–…â–ˆâ–†â–…â–ƒâ–…â–„â–‡â–ˆâ–‡â–†â–…â–‡â–ƒâ–…â–…â–…â–ƒâ–‡â–…â–ƒâ–ˆâ–‚â–‡â–â–„â–„â–ƒâ–ˆ
wandb:      train/ensemble_f1 â–†â–„â–…â–‡â–…â–‡â–‡â–„â–‡â–ˆâ–…â–‡â–‡â–ˆâ–†â–†â–ˆâ–…â–‡â–…â–…â–‡â–†â–‡â–ˆâ–†â–‡â–„â–‡â–„â–‡â–†â–ƒâ–‡â–â–…â–…â–†â–…â–ˆ
wandb:         train/mil_loss â–‚â–…â–ƒâ–â–…â–‚â–…â–â–ƒâ–ƒâ–…â–‚â–ƒâ–†â–ˆâ–ƒâ–â–‚â–„â–ƒâ–‚â–„â–„â–†â–„â–„â–…â–ƒâ–„â–„â–ƒâ–ƒâ–…â–†â–‚â–…â–ˆâ–…â–„â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.26247
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.87779
wandb:      eval/avg_mil_loss 1.61995
wandb:       eval/ensemble_f1 0.87779
wandb:           train/avg_f1 0.82099
wandb:      train/ensemble_f1 0.82099
wandb:         train/mil_loss 0.76401
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run helpful-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ya3t05rk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100240-ya3t05rk/logs
wandb: ERROR Run ya3t05rk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.65.6:53154->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: rfezlh46 with config:
wandb: 	actor_learning_rate: 7.448897603011291e-05
wandb: 	attention_dropout_p: 0.32510724629189003
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2985923617972627
wandb: 	temperature: 9.403746102373605
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100501-rfezlh46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfezlh46
wandb: uploading wandb-summary.json
wandb: uploading history steps 38-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–„â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–ˆâ–‚â–ˆâ–â–ˆâ–‡â–ˆâ–‡â–‚â–‡â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ˆâ–‚â–ˆâ–â–ˆâ–‡â–‡â–ˆâ–‚â–ˆâ–‡â–ƒâ–ˆâ–‚â–‡â–‚â–‡â–ˆâ–‚â–ƒâ–„â–‡
wandb:      eval/avg_mil_loss â–â–ƒâ–â–„â–â–â–…â–ƒâ–ƒâ–…â–…â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–‡â–…â–ˆâ–â–„â–…â–„â–„â–â–„â–ƒâ–ƒâ–„â–ƒâ–‡â–„â–…â–‚â–â–…â–„â–…
wandb:       eval/ensemble_f1 â–„â–ˆâ–‚â–ˆâ–â–ˆâ–‡â–‡â–ˆâ–‚â–ˆâ–‡â–‡â–„â–ˆâ–ƒâ–ˆâ–‚â–‡â–â–‡â–‡â–‡â–ˆâ–â–‡â–ƒâ–ƒâ–ˆâ–‚â–‚â–‡â–â–ˆâ–‚â–„â–ƒâ–‚â–‚â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–ƒâ–†â–„â–„â–‡â–…â–‚â–†â–‡â–†â–ƒâ–…â–†â–â–†â–‡â–„â–„â–„â–…â–ˆâ–ƒâ–†â–…â–ƒâ–†â–…â–†â–„â–…â–„â–†â–„â–ƒâ–„â–†â–…â–†
wandb:      train/ensemble_f1 â–„â–‚â–ƒâ–†â–ƒâ–ƒâ–‡â–…â–â–†â–…â–‚â–„â–†â–„â–„â–‡â–ƒâ–ƒâ–„â–…â–ˆâ–ƒâ–†â–„â–…â–…â–…â–†â–†â–…â–ƒâ–†â–…â–„â–‚â–„â–†â–„â–†
wandb:         train/mil_loss â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–†â–„â–ˆâ–†â–…â–ƒâ–…â–‚â–â–ƒâ–‚â–†â–„â–ƒâ–„â–„â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–â–„â–â–„â–†â–ƒâ–„
wandb:      train/policy_loss â–â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91069
wandb: best/eval_avg_mil_loss 0.29639
wandb:  best/eval_ensemble_f1 0.91069
wandb:            eval/avg_f1 0.88575
wandb:      eval/avg_mil_loss 1.70264
wandb:       eval/ensemble_f1 0.88575
wandb:            test/avg_f1 0.91253
wandb:      test/avg_mil_loss 0.24929
wandb:       test/ensemble_f1 0.91253
wandb:           train/avg_f1 0.83561
wandb:      train/ensemble_f1 0.83561
wandb:         train/mil_loss 0.98566
wandb:      train/policy_loss -0.21201
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.21201
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfezlh46
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100501-rfezlh46/logs
wandb: Agent Starting Run: mrlt6jtl with config:
wandb: 	actor_learning_rate: 0.00013060894072685226
wandb: 	attention_dropout_p: 0.41900361105134104
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3447417018451988
wandb: 	temperature: 1.7288312126997052
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100548-mrlt6jtl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mrlt6jtl
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–„â–ˆâ–ˆâ–…â–ˆâ–‡â–†â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–…â–ˆâ–ˆâ–ˆâ–â–‡â–†â–ƒâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–…â–„â–†â–„â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–†â–‚â–â–…â–ƒâ–â–‚â–ƒâ–†â–â–‚â–â–â–â–†â–ˆâ–…â–â–â–‡â–â–‡â–ƒâ–â–â–„â–â–â–ˆâ–‚â–â–…â–ƒâ–„â–â–â–â–
wandb:       eval/ensemble_f1 â–ˆâ–„â–‡â–‡â–ˆâ–…â–ˆâ–‡â–†â–…â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–…â–ˆâ–‡â–ˆâ–â–‡â–†â–ƒâ–ˆâ–‡â–ˆâ–ˆâ–„â–†â–ˆâ–„â–‡â–„â–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–ˆâ–†â–â–ƒâ–ˆâ–…â–…â–„â–„â–…â–„â–…â–â–…â–‡â–‡â–‡â–…â–…â–…â–â–…â–‡â–…â–‡â–‡â–…â–ƒâ–ƒâ–„â–„â–…â–ƒâ–„â–ˆâ–†â–…â–‚â–†â–…
wandb:      train/ensemble_f1 â–ˆâ–†â–â–ƒâ–ˆâ–…â–„â–…â–…â–„â–…â–‡â–ˆâ–‡â–‡â–…â–…â–ˆâ–…â–‡â–†â–…â–‡â–…â–‡â–‡â–…â–ƒâ–ƒâ–„â–…â–ƒâ–„â–ˆâ–†â–†â–…â–‚â–†â–…
wandb:         train/mil_loss â–‚â–†â–ƒâ–‚â–ˆâ–…â–„â–†â–†â–ƒâ–†â–‚â–‚â–â–ƒâ–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–â–…â–ƒâ–…â–‚â–‡â–…â–ƒâ–„â–‚â–‡â–„â–ƒâ–†â–‡
wandb:      train/policy_loss â–‚â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92177
wandb: best/eval_avg_mil_loss 0.22018
wandb:  best/eval_ensemble_f1 0.92177
wandb:            eval/avg_f1 0.91758
wandb:      eval/avg_mil_loss 0.2638
wandb:       eval/ensemble_f1 0.91758
wandb:           train/avg_f1 0.82061
wandb:      train/ensemble_f1 0.82061
wandb:         train/mil_loss 0.91865
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run azure-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mrlt6jtl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100548-mrlt6jtl/logs
wandb: ERROR Run mrlt6jtl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x9wscoco with config:
wandb: 	actor_learning_rate: 4.7445565870788856e-05
wandb: 	attention_dropout_p: 0.29136497919624466
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6348066445967524
wandb: 	temperature: 7.701365397441169
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100647-x9wscoco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x9wscoco
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–„â–â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–‡â–ƒâ–†â–…â–„â–‡â–„â–‡â–‡â–…â–…â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–…â–‡â–‡â–†â–‡â–ˆâ–…â–‡â–ƒâ–â–†â–‡â–†â–‡â–†â–‡â–„â–…
wandb:      eval/avg_mil_loss â–â–‚â–‚â–â–‚â–â–„â–â–â–â–‚â–„â–‚â–â–„â–‚â–â–…â–â–â–‚â–‚â–‚â–â–â–â–â–â–„â–â–â–‚â–â–„â–ˆâ–‚â–„â–â–â–‚
wandb:       eval/ensemble_f1 â–†â–†â–†â–†â–ƒâ–‡â–†â–„â–…â–†â–‚â–†â–…â–‡â–‡â–ƒâ–†â–ƒâ–‡â–†â–…â–†â–†â–†â–†â–…â–…â–†â–†â–ˆâ–†â–†â–†â–†â–‡â–„â–â–†â–â–ƒ
wandb:           train/avg_f1 â–„â–†â–‡â–„â–ƒâ–ƒâ–„â–„â–‡â–†â–‡â–‚â–ˆâ–‡â–‚â–†â–†â–…â–†â–ˆâ–‡â–„â–„â–ˆâ–†â–†â–„â–…â–…â–†â–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–†â–„â–†â–
wandb:      train/ensemble_f1 â–„â–…â–…â–„â–†â–„â–ƒâ–…â–„â–„â–†â–‡â–„â–†â–‚â–†â–…â–†â–†â–…â–…â–‡â–ƒâ–…â–†â–…â–ˆâ–‡â–…â–†â–†â–†â–„â–ˆâ–„â–†â–†â–ˆâ–†â–
wandb:         train/mil_loss â–„â–â–â–‡â–‚â–„â–‚â–…â–‚â–„â–ƒâ–‚â–…â–‚â–„â–‚â–…â–â–„â–â–ƒâ–ˆâ–‚â–â–ƒâ–‚â–‚â–â–‚â–‚â–…â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9334
wandb: best/eval_avg_mil_loss 0.28038
wandb:  best/eval_ensemble_f1 0.9334
wandb:            eval/avg_f1 0.84651
wandb:      eval/avg_mil_loss 0.57225
wandb:       eval/ensemble_f1 0.84651
wandb:           train/avg_f1 0.8314
wandb:      train/ensemble_f1 0.8314
wandb:         train/mil_loss 0.37286
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x9wscoco
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100647-x9wscoco/logs
wandb: ERROR Run x9wscoco errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v3b2qznr with config:
wandb: 	actor_learning_rate: 1.136096610560762e-06
wandb: 	attention_dropout_p: 0.309034836871534
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23641854096569528
wandb: 	temperature: 9.796430350538031
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100900-v3b2qznr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v3b2qznr
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–…â–ƒâ–…â–†â–â–‡â–…â–†â–‡â–ˆâ–ˆâ–…â–…â–‡â–ˆâ–†â–ˆâ–â–„â–ˆâ–„â–ƒâ–…â–‚â–ƒâ–…â–‚â–…â–†â–†â–ˆâ–„â–†â–‡â–…â–†â–ˆâ–…
wandb:      eval/avg_mil_loss â–ˆâ–â–ƒâ–â–„â–„â–â–ƒâ–…â–„â–ƒâ–†â–â–ƒâ–…â–‡â–†â–â–‚â–…â–„â–‚â–â–‚â–†â–†â–†â–„â–…â–„â–„â–ƒâ–ƒâ–„â–„â–…â–„â–†â–ƒâ–
wandb:       eval/ensemble_f1 â–‡â–…â–„â–†â–…â–‡â–…â–†â–„â–‡â–‡â–†â–…â–…â–…â–…â–†â–â–†â–„â–…â–ˆâ–„â–…â–„â–†â–ˆâ–‡â–ƒâ–…â–…â–…â–ˆâ–„â–‡â–ƒâ–‡â–ˆâ–‡â–‡
wandb:           train/avg_f1 â–…â–„â–†â–â–â–ƒâ–ƒâ–†â–‡â–‚â–…â–…â–„â–ˆâ–ˆâ–†â–„â–‚â–…â–…â–„â–‡â–ƒâ–‚â–„â–‡â–†â–…â–…â–‡â–„â–†â–ƒâ–„â–†â–ƒâ–…â–…â–„â–‡
wandb:      train/ensemble_f1 â–ˆâ–†â–ƒâ–‡â–„â–…â–†â–‡â–‡â–ˆâ–‡â–„â–â–‡â–„â–„â–‡â–‡â–ƒâ–…â–„â–…â–ˆâ–‡â–…â–„â–†â–…â–‡â–†â–†â–†â–†â–ƒâ–„â–‡â–†â–‡â–…â–‡
wandb:         train/mil_loss â–„â–ˆâ–„â–„â–‚â–…â–‚â–‚â–„â–â–â–‚â–ƒâ–ƒâ–„â–†â–â–„â–†â–†â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–‡â–…â–ƒâ–„â–‡â–‚â–‚â–„â–†â–‚â–ƒâ–‚â–‚â–„
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9105
wandb: best/eval_avg_mil_loss 0.37715
wandb:  best/eval_ensemble_f1 0.9105
wandb:            eval/avg_f1 0.77651
wandb:      eval/avg_mil_loss 0.90894
wandb:       eval/ensemble_f1 0.77651
wandb:           train/avg_f1 0.79656
wandb:      train/ensemble_f1 0.79656
wandb:         train/mil_loss 0.83596
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misunderstood-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v3b2qznr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100900-v3b2qznr/logs
wandb: ERROR Run v3b2qznr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 03zc7z19 with config:
wandb: 	actor_learning_rate: 4.530445757213499e-05
wandb: 	attention_dropout_p: 0.30840319073930034
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04854126734388997
wandb: 	temperature: 3.9323132988103513
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101206-03zc7z19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03zc7z19
wandb: uploading history steps 95-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–ƒâ–„â–â–â–„â–â–ƒâ–…â–„â–†â–ƒâ–„â–…â–â–‚â–†â–ƒâ–‚â–‚â–…â–„â–‡â–„â–ˆâ–„â–„â–„â–„â–‚â–„â–‚â–â–‡â–„â–…â–„â–†â–…
wandb:      eval/avg_mil_loss â–ˆâ–†â–…â–„â–…â–ƒâ–‡â–…â–‡â–†â–ƒâ–†â–ˆâ–…â–…â–ˆâ–„â–…â–‡â–…â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–…â–‚â–ƒâ–‚â–…â–ˆâ–â–‚â–…â–ƒâ–„â–ˆâ–†â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‚â–…â–…â–‡â–ƒâ–…â–„â–„â–ƒâ–†â–‚â–â–†â–…â–‡â–‚â–…â–„â–…â–‡â–‡â–ƒâ–‚â–†â–„â–ˆâ–‚â–‡â–…â–ƒâ–„â–„â–‚â–ƒâ–‚â–„â–„â–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–‡â–†â–†â–„â–…â–ƒâ–ƒâ–„â–…â–ƒâ–†â–„â–‚â–ƒâ–†â–‡â–ƒâ–ƒâ–†â–†â–‡â–ˆâ–ƒâ–…â–…â–ƒâ–‡â–„â–‡â–†â–„â–„â–†â–„â–ƒâ–…â–†â–…
wandb:      train/ensemble_f1 â–†â–‡â–‡â–†â–†â–ˆâ–‚â–‚â–â–ƒâ–†â–ƒâ–†â–ˆâ–ˆâ–…â–†â–†â–†â–†â–„â–ƒâ–…â–‚â–‡â–„â–ˆâ–ˆâ–„â–†â–„â–„â–†â–„â–…â–ƒâ–‡â–…â–â–‡
wandb:         train/mil_loss â–ƒâ–ˆâ–‡â–†â–ƒâ–…â–„â–…â–…â–…â–ˆâ–ƒâ–‡â–„â–‡â–„â–‚â–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–…â–„â–„â–‚â–‚â–‚â–â–†â–†â–ƒâ–…â–…â–…â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79914
wandb: best/eval_avg_mil_loss 1.33932
wandb:  best/eval_ensemble_f1 0.79914
wandb:            eval/avg_f1 0.7257
wandb:      eval/avg_mil_loss 1.57509
wandb:       eval/ensemble_f1 0.7257
wandb:            test/avg_f1 0.66977
wandb:      test/avg_mil_loss 1.60117
wandb:       test/ensemble_f1 0.66977
wandb:           train/avg_f1 0.63603
wandb:      train/ensemble_f1 0.63603
wandb:         train/mil_loss 1.90535
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run electric-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03zc7z19
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101206-03zc7z19/logs
wandb: Agent Starting Run: 715w72xy with config:
wandb: 	actor_learning_rate: 3.99994404755441e-06
wandb: 	attention_dropout_p: 0.2802917714864346
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4422523799958602
wandb: 	temperature: 2.948299834952862
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101411-715w72xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/715w72xy
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–‚â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–†â–†â–‡â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:      eval/avg_mil_loss â–‚â–‚â–â–‡â–ƒâ–â–â–â–â–â–â–ƒâ–‚â–â–ƒâ–â–‚â–â–‚â–â–â–†â–‚â–â–â–‚â–â–†â–â–…â–â–â–‚â–„â–‚â–‚â–ˆâ–â–‚â–
wandb:       eval/ensemble_f1 â–‡â–ˆâ–â–†â–‚â–ˆâ–ˆâ–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–…â–‡â–ˆâ–‡â–ˆ
wandb:           train/avg_f1 â–…â–…â–‡â–„â–„â–‡â–†â–„â–†â–‡â–‡â–â–„â–‡â–†â–…â–…â–†â–‡â–„â–ƒâ–†â–…â–ƒâ–ˆâ–‡â–†â–†â–…â–‡â–ˆâ–ƒâ–‡â–ˆâ–‚â–‡â–ƒâ–†â–„â–„
wandb:      train/ensemble_f1 â–†â–ƒâ–‡â–‡â–‡â–ƒâ–„â–…â–‡â–â–â–ˆâ–ˆâ–‡â–â–†â–‡â–†â–ƒâ–†â–„â–ƒâ–†â–‡â–„â–†â–‚â–‡â–„â–„â–„â–‡â–‡â–„â–ˆâ–‡â–ƒâ–…â–…â–‡
wandb:         train/mil_loss â–ƒâ–…â–‚â–‚â–‚â–‚â–†â–‚â–‚â–ƒâ–‚â–‚â–â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–…â–â–‚â–â–‚â–ˆâ–†â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–†â–ƒâ–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–„â–â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–â–ˆâ–„â–ˆâ–„â–„â–â–ˆâ–„â–„â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–â–„â–„â–â–â–„â–„â–â–„â–â–â–â–„â–â–ˆâ–„â–ˆâ–„â–â–„â–„â–„â–â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.37406
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.91009
wandb:      eval/avg_mil_loss 0.29175
wandb:       eval/ensemble_f1 0.91009
wandb:           train/avg_f1 0.89094
wandb:      train/ensemble_f1 0.89094
wandb:         train/mil_loss 0.38325
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pious-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/715w72xy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101411-715w72xy/logs
wandb: ERROR Run 715w72xy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: f4zzs5mm with config:
wandb: 	actor_learning_rate: 2.235129365795481e-05
wandb: 	attention_dropout_p: 0.4500569794895986
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.828959215920253
wandb: 	temperature: 7.660654759929711
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101609-f4zzs5mm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4zzs5mm
wandb: uploading wandb-summary.json
wandb: uploading history steps 92-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–‚â–ˆâ–â–‡â–ˆâ–ˆâ–‡â–ƒâ–ˆâ–ƒâ–„â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ƒâ–‡â–ˆâ–‡â–ˆâ–‚â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‚â–ˆ
wandb:      eval/avg_mil_loss â–â–â–‚â–†â–â–â–â–ˆâ–â–â–â–â–â–‚â–ˆâ–â–â–â–â–†â–†â–†â–â–â–â–â–ˆâ–‡â–„â–â–â–ˆâ–ˆâ–†â–‚â–â–â–…â–â–
wandb:       eval/ensemble_f1 â–ˆâ–‡â–‡â–ˆâ–ˆâ–‚â–‡â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–â–‡â–ˆâ–ƒâ–‡â–ˆâ–ˆâ–‚â–…â–ˆâ–ˆâ–â–‡â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:           train/avg_f1 â–‚â–ˆâ–†â–‡â–ˆâ–‚â–†â–ˆâ–…â–‚â–…â–…â–ƒâ–†â–†â–‡â–…â–ƒâ–„â–†â–…â–ƒâ–†â–‡â–†â–â–†â–‡â–ˆâ–†â–…â–â–‡â–…â–„â–‡â–‡â–ƒâ–…â–†
wandb:      train/ensemble_f1 â–ˆâ–‡â–‚â–†â–†â–…â–‡â–†â–‚â–‡â–†â–‡â–„â–ƒâ–…â–…â–†â–ƒâ–„â–ˆâ–†â–‡â–â–†â–‡â–„â–„â–‡â–â–†â–ˆâ–†â–†â–…â–†â–ˆâ–ƒâ–‡â–‡â–‡
wandb:         train/mil_loss â–„â–ƒâ–‡â–„â–„â–ƒâ–ƒâ–ƒâ–â–„â–„â–â–‡â–ƒâ–ƒâ–„â–‚â–â–ƒâ–ƒâ–…â–â–‡â–„â–‚â–…â–â–ˆâ–†â–â–â–â–ƒâ–†â–†â–„â–‚â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–ˆâ–â–â–…â–…â–â–…â–…â–…â–ˆâ–â–…â–…â–â–…â–…â–…â–ˆâ–â–…â–ˆâ–…â–…â–…â–â–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.26097
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.90599
wandb:      eval/avg_mil_loss 0.3307
wandb:       eval/ensemble_f1 0.90599
wandb:           train/avg_f1 0.88443
wandb:      train/ensemble_f1 0.88443
wandb:         train/mil_loss 0.95228
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run northern-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f4zzs5mm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101609-f4zzs5mm/logs
wandb: ERROR Run f4zzs5mm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: vxyzowkn with config:
wandb: 	actor_learning_rate: 7.070974417718699e-06
wandb: 	attention_dropout_p: 0.432688363675597
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5019304916993966
wandb: 	temperature: 7.747278474238532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101742-vxyzowkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vxyzowkn
wandb: uploading history steps 182-200, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–‚â–„â–„â–â–â–„
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–ˆâ–‡â–†â–ƒâ–†â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–‡â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–‡â–ˆâ–ƒâ–†â–â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–…â–â–‚â–„â–‚â–‡â–‚â–‡â–â–‚â–†â–‚â–ƒâ–…â–‚â–…â–â–‚â–â–‚â–â–‚â–â–‚â–ˆâ–â–‚â–â–‡â–â–â–â–„â–„â–‡â–„â–‚â–â–
wandb:       eval/ensemble_f1 â–‡â–ƒâ–‡â–ˆâ–…â–†â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–â–â–ˆâ–†â–‡â–ˆâ–‡â–â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–ƒâ–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–‡â–‡â–„â–ƒâ–†â–…â–ˆâ–†â–†â–…â–‚â–„â–†â–…â–ƒâ–…â–…â–‚â–‡â–ˆâ–†â–„â–‡â–†â–ƒâ–‡â–…â–†â–ƒâ–…â–†â–‡â–ƒâ–†â–ƒâ–‚â–†â–†â–
wandb:      train/ensemble_f1 â–ƒâ–‡â–…â–‡â–†â–‡â–…â–†â–„â–‡â–†â–‡â–†â–ƒâ–†â–„â–†â–†â–„â–‡â–‡â–‡â–…â–…â–ƒâ–†â–ƒâ–„â–†â–…â–„â–…â–„â–…â–†â–ˆâ–â–…â–…â–…
wandb:         train/mil_loss â–ƒâ–…â–ƒâ–ƒâ–â–â–‚â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–„â–…â–„â–ƒâ–‚â–„â–‡â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–…â–…â–ƒâ–†â–‚â–„â–„â–ƒâ–â–ƒâ–‚â–ˆâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–ˆâ–ƒâ–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.92542
wandb: best/eval_avg_mil_loss 0.29646
wandb:  best/eval_ensemble_f1 0.92542
wandb:            eval/avg_f1 0.78609
wandb:      eval/avg_mil_loss 0.45299
wandb:       eval/ensemble_f1 0.78609
wandb:            test/avg_f1 0.68674
wandb:      test/avg_mil_loss 1.47346
wandb:       test/ensemble_f1 0.68674
wandb:           train/avg_f1 0.78299
wandb:      train/ensemble_f1 0.78299
wandb:         train/mil_loss 0.43919
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vxyzowkn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101742-vxyzowkn/logs
wandb: Agent Starting Run: 1tcc3fsc with config:
wandb: 	actor_learning_rate: 1.033491747945693e-06
wandb: 	attention_dropout_p: 0.43124816917601183
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31708257846036003
wandb: 	temperature: 6.253959621927948
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102033-1tcc3fsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1tcc3fsc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‡â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–…â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–‚â–ˆâ–ˆâ–‡â–ˆâ–‚â–‡â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–ˆâ–ˆâ–‡â–†â–„â–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–„â–‡â–ˆâ–„â–‚â–â–‚â–ˆâ–‡â–‡â–ˆâ–ƒâ–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–â–„â–ƒâ–„â–…â–ƒâ–„â–â–â–‚â–‚â–…â–ƒâ–â–…â–â–ƒâ–ƒâ–…â–â–„â–ˆâ–â–â–ƒâ–â–„â–‡â–ƒâ–…â–‚â–…â–ƒâ–„â–„â–‚â–„â–
wandb:       eval/ensemble_f1 â–ˆâ–‚â–ˆâ–â–ƒâ–ˆâ–ˆâ–‚â–ˆâ–ƒâ–‚â–‡â–ˆâ–„â–‚â–â–â–ˆâ–ˆâ–ƒâ–‡â–‡â–„â–ƒâ–„â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–ƒâ–ˆ
wandb:           train/avg_f1 â–ˆâ–„â–„â–„â–‚â–‡â–†â–„â–‡â–ƒâ–„â–†â–†â–†â–†â–†â–†â–ƒâ–†â–…â–…â–‡â–‚â–‚â–„â–â–‚â–„â–†â–ˆâ–ƒâ–‚â–„â–†â–„â–…â–‚â–„â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–„â–ˆâ–ˆâ–„â–†â–‡â–„â–†â–ƒâ–„â–†â–†â–†â–ƒâ–‡â–ƒâ–ƒâ–†â–…â–…â–…â–…â–†â–…â–‚â–…â–â–â–„â–ƒâ–†â–„â–…â–„â–…â–†â–†â–†â–…
wandb:         train/mil_loss â–„â–„â–…â–„â–ƒâ–â–†â–…â–…â–ƒâ–…â–†â–‡â–†â–…â–‡â–â–…â–…â–†â–ƒâ–…â–ƒâ–„â–„â–ƒâ–…â–„â–ˆâ–…â–„â–„â–…â–â–…â–‚â–ƒâ–…â–„â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.32163
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.86131
wandb:      eval/avg_mil_loss 0.46047
wandb:       eval/ensemble_f1 0.86131
wandb:           train/avg_f1 0.77811
wandb:      train/ensemble_f1 0.77811
wandb:         train/mil_loss 0.48224
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1tcc3fsc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102033-1tcc3fsc/logs
wandb: ERROR Run 1tcc3fsc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wbnyf8k9 with config:
wandb: 	actor_learning_rate: 0.00030859192796312495
wandb: 	attention_dropout_p: 0.0004803304856913493
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5358195160439596
wandb: 	temperature: 9.398759120274786
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102236-wbnyf8k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wbnyf8k9
wandb: uploading history steps 67-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–†â–„â–†â–ˆâ–‚â–†â–„â–…â–…â–‡â–‚â–…â–†â–â–†â–„â–…â–„â–…â–ƒâ–†â–‚â–â–…â–…â–…â–„â–†â–â–†â–„â–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–†â–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–„â–…â–„â–ƒâ–…â–ƒâ–„â–„â–„â–ƒâ–…â–„â–ˆâ–„â–„â–ˆâ–…â–‚â–„â–…â–„â–…â–‚â–â–„â–ƒâ–ˆâ–…â–†â–‡â–ƒâ–ƒâ–ƒâ–â–ƒâ–†â–â–†
wandb:       eval/ensemble_f1 â–†â–…â–‡â–‚â–†â–†â–…â–…â–ˆâ–…â–…â–†â–„â–„â–†â–„â–†â–†â–ƒâ–ˆâ–‡â–‚â–…â–…â–ƒâ–„â–â–†â–†â–„â–ˆâ–…â–‡â–ˆâ–ˆâ–…â–„â–ˆâ–†â–„
wandb:           train/avg_f1 â–†â–ƒâ–„â–â–†â–†â–ˆâ–„â–ƒâ–„â–…â–„â–‚â–…â–…â–„â–„â–†â–ƒâ–„â–…â–‚â–…â–…â–ƒâ–…â–‡â–„â–†â–†â–‡â–…â–‡â–…â–†â–…â–‚â–…â–‡â–†
wandb:      train/ensemble_f1 â–ƒâ–„â–â–†â–…â–„â–ƒâ–†â–…â–‡â–ˆâ–…â–‚â–†â–†â–„â–‡â–…â–…â–„â–„â–‚â–…â–ƒâ–‚â–†â–„â–‚â–ƒâ–†â–â–ˆâ–„â–‡â–‡â–ƒâ–‚â–…â–ˆâ–ƒ
wandb:         train/mil_loss â–…â–„â–…â–…â–„â–…â–†â–„â–ƒâ–…â–†â–†â–…â–„â–†â–†â–ƒâ–„â–…â–„â–„â–†â–‚â–…â–…â–„â–…â–„â–ƒâ–ˆâ–„â–‚â–‡â–„â–„â–„â–†â–…â–â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.28171
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.72001
wandb:      eval/avg_mil_loss 1.52762
wandb:       eval/ensemble_f1 0.72001
wandb:           train/avg_f1 0.79769
wandb:      train/ensemble_f1 0.79769
wandb:         train/mil_loss 0.86893
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wandering-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wbnyf8k9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102236-wbnyf8k9/logs
wandb: ERROR Run wbnyf8k9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 6yj8ovdx with config:
wandb: 	actor_learning_rate: 0.0006208028085899434
wandb: 	attention_dropout_p: 0.28330284692376195
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2490365503198273
wandb: 	temperature: 0.8716648545617511
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102409-6yj8ovdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6yj8ovdx
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–ƒâ–â–†
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‡â–‡â–ˆâ–ˆâ–â–ƒâ–‚â–ˆâ–„â–‚â–ˆâ–‡â–‡â–‡â–…â–ƒâ–‚â–ˆâ–ƒâ–„â–‡â–ƒâ–ˆâ–â–ˆâ–†â–ˆâ–ƒâ–‡â–ˆâ–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‚â–‡â–‡
wandb:      eval/avg_mil_loss â–â–â–ˆâ–„â–„â–â–ƒâ–â–…â–„â–‚â–â–…â–â–„â–‚â–â–â–â–‚â–„â–‚â–â–â–â–„â–â–â–â–‡â–‚â–â–â–ƒâ–ƒâ–„â–„â–â–ƒâ–…
wandb:       eval/ensemble_f1 â–…â–‡â–‡â–ˆâ–‡â–ˆâ–…â–ƒâ–â–ƒâ–ˆâ–ˆâ–…â–‡â–‡â–…â–‡â–‚â–ˆâ–…â–ˆâ–„â–ƒâ–‡â–ˆâ–‡â–‡â–ˆâ–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–‚â–‡â–‚â–‡â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–„â–ƒâ–…â–ƒâ–‡â–‡â–†â–â–„â–†â–…â–„â–ƒâ–†â–…â–…â–„â–„â–ƒâ–‡â–…â–‡â–‡â–†â–…â–†â–…â–†â–†â–ˆâ–„â–…â–‡â–…â–‡â–†â–†â–†
wandb:      train/ensemble_f1 â–‚â–ƒâ–ƒâ–â–‚â–†â–„â–‡â–„â–†â–‚â–„â–…â–†â–ƒâ–‚â–â–…â–…â–„â–‡â–ƒâ–…â–‡â–‡â–„â–…â–„â–‡â–ˆâ–†â–„â–…â–†â–ƒâ–†â–„â–…â–…â–ƒ
wandb:         train/mil_loss â–„â–â–ƒâ–‚â–…â–†â–ƒâ–‡â–†â–„â–†â–ˆâ–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–‚â–†â–‚â–„â–ƒâ–ƒâ–‡â–‚â–‚â–‚â–†â–„â–‚â–ƒâ–„â–‚â–‚â–‚â–â–ƒâ–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91009
wandb: best/eval_avg_mil_loss 0.38301
wandb:  best/eval_ensemble_f1 0.91009
wandb:            eval/avg_f1 0.8392
wandb:      eval/avg_mil_loss 0.77681
wandb:       eval/ensemble_f1 0.8392
wandb:            test/avg_f1 0.83139
wandb:      test/avg_mil_loss 0.47082
wandb:       test/ensemble_f1 0.83139
wandb:           train/avg_f1 0.80398
wandb:      train/ensemble_f1 0.80398
wandb:         train/mil_loss 0.87775
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6yj8ovdx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102409-6yj8ovdx/logs
wandb: Agent Starting Run: qehpkxah with config:
wandb: 	actor_learning_rate: 3.7549978265600065e-06
wandb: 	attention_dropout_p: 0.08213410503815488
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2615767933125235
wandb: 	temperature: 4.60970241714177
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102547-qehpkxah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qehpkxah
wandb: uploading history steps 121-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–ƒâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–„â–†â–…â–ƒâ–‡â–‡â–„â–‡â–…â–…â–‡â–…â–‚â–†â–‡â–†â–†â–†â–‡â–…â–ˆâ–„â–‡â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–â–‡â–†â–…â–„â–
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ˆâ–â–…â–„â–†â–‚â–â–„â–‚â–‚â–†â–‚â–‚â–‚â–‚â–„â–â–‚â–â–â–â–‚â–‚â–„â–ƒâ–â–‚â–‚â–â–†â–‚â–„â–â–„â–â–â–â–„
wandb:       eval/ensemble_f1 â–…â–ˆâ–„â–†â–‡â–ƒâ–‚â–‡â–‡â–ˆâ–‡â–†â–†â–‡â–†â–†â–‡â–†â–ˆâ–…â–†â–‡â–†â–„â–‡â–‡â–…â–ˆâ–…â–†â–†â–…â–…â–â–‡â–ˆâ–†â–‡â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–…â–‚â–„â–„â–„â–â–…â–‚â–ˆâ–†â–†â–ƒâ–†â–†â–‚â–ƒâ–…â–…â–„â–„â–„â–†â–‡â–‚â–‚â–†â–†â–„â–…â–ˆâ–ƒâ–…â–‚â–…â–†â–†â–†â–†â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–†â–†â–…â–„â–‡â–‚â–‡â–ƒâ–ƒâ–„â–â–„â–ƒâ–…â–…â–„â–‡â–‚â–†â–…â–ƒâ–ˆâ–‡â–ˆâ–„â–†â–†â–„â–†â–„
wandb:         train/mil_loss â–…â–„â–…â–‡â–†â–„â–…â–ƒâ–‚â–†â–‚â–„â–…â–…â–„â–ƒâ–‡â–‡â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‡â–†â–„â–ƒâ–‡â–†â–ƒâ–†â–â–ƒâ–‡â–„â–â–ˆâ–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–„â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–ˆâ–â–„â–„â–â–â–â–„â–â–â–„â–ˆâ–â–„â–â–ˆâ–ˆâ–â–â–„â–ˆâ–â–â–„â–ˆâ–â–„â–â–„â–„â–„â–â–„â–â–ˆâ–ˆâ–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91497
wandb: best/eval_avg_mil_loss 0.25838
wandb:  best/eval_ensemble_f1 0.91497
wandb:            eval/avg_f1 0.81018
wandb:      eval/avg_mil_loss 0.63645
wandb:       eval/ensemble_f1 0.81018
wandb:            test/avg_f1 0.83272
wandb:      test/avg_mil_loss 0.51427
wandb:       test/ensemble_f1 0.83272
wandb:           train/avg_f1 0.84322
wandb:      train/ensemble_f1 0.84322
wandb:         train/mil_loss 0.31378
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qehpkxah
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102547-qehpkxah/logs
wandb: Agent Starting Run: pgwmhwwf with config:
wandb: 	actor_learning_rate: 0.00011361533731642604
wandb: 	attention_dropout_p: 0.38767662019673393
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8208958393364526
wandb: 	temperature: 6.378091182938381
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102811-pgwmhwwf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgwmhwwf
wandb: uploading wandb-summary.json
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–ƒâ–‚â–„â–ˆâ–‡â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–‚â–‡â–‡â–ˆâ–ƒâ–„â–‚â–ˆâ–‡â–‚â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–â–â–†â–‚â–„â–â–â–„â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–…â–„â–…â–â–„â–â–…â–â–…â–â–â–â–â–„â–…â–â–…â–â–
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–‚â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–â–‡â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–†â–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–ˆâ–„â–ƒâ–ˆâ–ˆâ–†â–†â–„â–ˆâ–†â–„â–‡â–ƒâ–„â–ƒâ–‡â–‚â–…â–„â–†â–‡â–„â–ƒâ–„â–‡â–â–‡â–ƒâ–„â–â–ƒ
wandb:      train/ensemble_f1 â–…â–„â–†â–…â–„â–‚â–†â–‡â–…â–„â–‡â–…â–†â–‡â–ƒâ–„â–„â–†â–†â–†â–‚â–ƒâ–…â–„â–„â–ƒâ–„â–ƒâ–†â–…â–‡â–†â–†â–â–ˆâ–ƒâ–‡â–â–‚â–ƒ
wandb:         train/mil_loss â–â–…â–„â–‚â–ˆâ–ƒâ–‚â–„â–‚â–…â–„â–…â–‚â–ƒâ–…â–‚â–„â–„â–â–‚â–„â–â–„â–‚â–ƒâ–„â–„â–‚â–…â–â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–‚
wandb:      train/policy_loss â–…â–…â–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–â–…â–â–ˆâ–…â–â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–ˆâ–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9145
wandb: best/eval_avg_mil_loss 0.2857
wandb:  best/eval_ensemble_f1 0.9145
wandb:            eval/avg_f1 0.88936
wandb:      eval/avg_mil_loss 0.38856
wandb:       eval/ensemble_f1 0.88936
wandb:            test/avg_f1 0.90066
wandb:      test/avg_mil_loss 0.24405
wandb:       test/ensemble_f1 0.90066
wandb:           train/avg_f1 0.78804
wandb:      train/ensemble_f1 0.78804
wandb:         train/mil_loss 0.49216
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run azure-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgwmhwwf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102811-pgwmhwwf/logs
wandb: Agent Starting Run: ucyqfgpi with config:
wandb: 	actor_learning_rate: 2.259112612448718e-05
wandb: 	attention_dropout_p: 0.1695637734840344
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17347085215997515
wandb: 	temperature: 0.7872084217682607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102945-ucyqfgpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucyqfgpi
wandb: uploading history steps 121-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–†â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‚â–‡â–†â–†â–…â–†â–ˆâ–ˆâ–‚â–‡â–…â–†â–‡â–…â–†â–‡â–†â–ƒâ–†â–†â–…â–…â–…â–†â–ˆâ–…â–ˆâ–†â–â–†
wandb:      eval/avg_mil_loss â–‡â–†â–…â–ˆâ–†â–ˆâ–…â–‡â–†â–…â–…â–ƒâ–„â–…â–„â–†â–…â–ƒâ–…â–ƒâ–ƒâ–…â–…â–„â–„â–„â–‚â–†â–„â–„â–ˆâ–„â–†â–ƒâ–ƒâ–ƒâ–…â–â–„â–„
wandb:       eval/ensemble_f1 â–…â–ˆâ–†â–ˆâ–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‚â–‡â–ˆâ–†â–ˆâ–‡â–†â–…â–‡â–…â–‡â–‡â–†â–†â–ˆâ–†â–…â–„â–‡â–‡â–‡â–…â–†â–ˆâ–‡â–â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–†â–…â–‚â–â–„â–†â–…â–„â–†â–…â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–„â–…â–…â–ˆâ–…â–„â–„â–†â–ƒâ–ƒâ–‡â–„â–„â–ˆâ–„â–†â–ƒ
wandb:      train/ensemble_f1 â–…â–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–„â–…â–†â–„â–…â–†â–…â–â–†â–…â–…â–…â–„â–†â–ƒâ–„â–†â–…â–…â–…â–â–„â–„â–…â–…â–†â–…â–…â–…â–…â–ˆâ–‚
wandb:         train/mil_loss â–ˆâ–†â–ƒâ–‚â–…â–ƒâ–ˆâ–„â–„â–†â–„â–†â–„â–â–â–â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–„â–„â–„â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–…â–â–‚
wandb:      train/policy_loss â–…â–â–…â–ˆâ–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–ˆâ–ˆâ–â–…â–…â–…â–â–â–ˆâ–…â–…â–…â–â–ˆâ–…â–â–ˆâ–â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91778
wandb: best/eval_avg_mil_loss 0.24038
wandb:  best/eval_ensemble_f1 0.91778
wandb:            eval/avg_f1 0.9105
wandb:      eval/avg_mil_loss 0.23804
wandb:       eval/ensemble_f1 0.9105
wandb:            test/avg_f1 0.92999
wandb:      test/avg_mil_loss 0.16677
wandb:       test/ensemble_f1 0.92999
wandb:           train/avg_f1 0.8907
wandb:      train/ensemble_f1 0.8907
wandb:         train/mil_loss 0.29849
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run super-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucyqfgpi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102945-ucyqfgpi/logs
wandb: Agent Starting Run: wt4zdyzk with config:
wandb: 	actor_learning_rate: 2.076153959846433e-05
wandb: 	attention_dropout_p: 0.32040277317712185
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6478552940762307
wandb: 	temperature: 6.603092398229919
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103215-wt4zdyzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wt4zdyzk
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–†â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–…â–ˆâ–ˆâ–ˆâ–…â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‚â–…â–†â–ƒâ–â–ƒâ–†â–†â–ˆâ–ˆâ–ˆâ–â–‡â–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–„â–†â–‡â–…â–ˆ
wandb:      eval/avg_mil_loss â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–„â–ƒâ–ˆâ–â–â–â–…â–â–â–â–â–ƒâ–„â–â–â–â–â–â–â–â–…â–…â–â–
wandb:       eval/ensemble_f1 â–ˆâ–‡â–…â–ˆâ–†â–‡â–ˆâ–†â–†â–…â–‡â–ˆâ–‡â–‡â–…â–ˆâ–†â–‡â–ˆâ–†â–‡â–ˆâ–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–…â–…â–†â–â–ˆâ–„â–…â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–ˆâ–†â–„â–ƒâ–‡â–†â–…â–‚â–†â–„â–†â–…â–†â–„â–‚â–…â–‚â–…â–„â–„â–â–‚â–†â–‡â–‡â–†â–„â–ƒâ–ƒâ–†â–†â–†â–„â–„â–ƒâ–ƒâ–†â–‚
wandb:      train/ensemble_f1 â–…â–…â–…â–†â–†â–†â–…â–„â–‡â–…â–†â–‚â–‡â–‚â–‡â–‡â–‚â–†â–‡â–â–…â–†â–†â–‡â–„â–„â–‚â–†â–ˆâ–ƒâ–†â–†â–‚â–…â–ƒâ–„â–„â–…â–…â–…
wandb:         train/mil_loss â–„â–â–†â–ˆâ–‚â–„â–†â–…â–‚â–ƒâ–‚â–…â–„â–…â–„â–„â–ƒâ–â–…â–„â–„â–„â–ƒâ–„â–„â–‡â–„â–†â–ƒâ–†â–ˆâ–‚â–‚â–ƒâ–†â–ƒâ–ƒâ–â–â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91467
wandb: best/eval_avg_mil_loss 0.2755
wandb:  best/eval_ensemble_f1 0.91467
wandb:            eval/avg_f1 0.90623
wandb:      eval/avg_mil_loss 0.31229
wandb:       eval/ensemble_f1 0.90623
wandb:            test/avg_f1 0.76637
wandb:      test/avg_mil_loss 0.53058
wandb:       test/ensemble_f1 0.76637
wandb:           train/avg_f1 0.86299
wandb:      train/ensemble_f1 0.86299
wandb:         train/mil_loss 0.38927
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sleek-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wt4zdyzk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103215-wt4zdyzk/logs
wandb: Agent Starting Run: n7u4u86s with config:
wandb: 	actor_learning_rate: 0.0001109121520402896
wandb: 	attention_dropout_p: 0.1756132181188629
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02756771749448328
wandb: 	temperature: 2.146075720357784
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103436-n7u4u86s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n7u4u86s
wandb: uploading history steps 101-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–ƒ
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–„â–‡â–…â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–…â–‡â–ƒâ–…â–ˆâ–ˆâ–ˆâ–ƒâ–â–ˆâ–‚â–‡â–‚â–‡â–‡â–ˆâ–ˆâ–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‚â–‚â–ƒâ–‡â–‚â–‚â–‚â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–‚â–â–â–â–‚â–â–ƒâ–‚â–â–†â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb:       eval/ensemble_f1 â–…â–â–‡â–„â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–„â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‡â–†â–„â–„â–‡â–…â–ƒâ–„â–…â–†â–ƒâ–†â–ƒâ–…â–‡â–†â–…â–…â–‡â–†â–‡â–‡â–†â–†â–â–â–…â–‡â–„â–ƒâ–†â–‡â–ˆâ–„â–…â–…â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–‡â–…â–ƒâ–‡â–ƒâ–ƒâ–ˆâ–‡â–ˆâ–†â–ƒâ–…â–…â–‡â–„â–„â–ˆâ–ƒâ–‡â–…â–†â–†â–…â–†â–‡â–…â–‡â–…â–„â–â–†â–…â–†â–†â–ƒâ–…â–…â–…â–…â–†
wandb:         train/mil_loss â–‚â–„â–„â–…â–‚â–„â–ƒâ–ƒâ–…â–…â–…â–„â–‚â–„â–†â–‚â–„â–ƒâ–ƒâ–„â–â–â–ƒâ–ˆâ–â–…â–†â–‚â–â–ˆâ–‚â–ƒâ–‚â–ƒâ–â–â–ƒâ–ƒâ–†â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–â–â–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–…â–…â–…â–â–â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–…â–â–ˆâ–…â–…â–â–…â–…â–ˆâ–…â–…â–ˆâ–…â–â–…â–…â–ˆâ–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91758
wandb: best/eval_avg_mil_loss 0.31876
wandb:  best/eval_ensemble_f1 0.91758
wandb:            eval/avg_f1 0.91373
wandb:      eval/avg_mil_loss 0.31141
wandb:       eval/ensemble_f1 0.91373
wandb:            test/avg_f1 0.91375
wandb:      test/avg_mil_loss 0.20094
wandb:       test/ensemble_f1 0.91375
wandb:           train/avg_f1 0.85705
wandb:      train/ensemble_f1 0.85705
wandb:         train/mil_loss 0.29956
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vocal-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n7u4u86s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103436-n7u4u86s/logs
wandb: Agent Starting Run: db9p3obd with config:
wandb: 	actor_learning_rate: 6.980222390300796e-06
wandb: 	attention_dropout_p: 0.4488454451028573
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8533224232639253
wandb: 	temperature: 7.029805398067582
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103624-db9p3obd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/db9p3obd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–â–‚â–ˆâ–‡â–†â–â–„â–„â–…â–ˆâ–‡â–ˆâ–‚â–ƒâ–ˆâ–ˆâ–ƒâ–†â–†â–‡â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–â–‡â–…â–‚â–‡â–ˆâ–ˆâ–‡â–‚â–ƒâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–…â–â–â–…â–â–ƒâ–â–â–…â–â–‚â–â–ƒâ–ˆâ–…â–…â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–â–„â–„â–„â–„â–â–â–„â–‚â–â–â–‚â–„â–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–ˆâ–â–‚â–‡â–ˆâ–ˆâ–â–‡â–‡â–…â–‡â–â–ˆâ–ˆâ–‚â–‡â–‚â–‡â–ˆâ–ˆâ–…â–„â–„â–ˆâ–‡â–ˆâ–‡â–‡â–…â–â–‚â–†â–ˆâ–ˆâ–‡â–â–‡â–ƒâ–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ˆâ–„â–„â–†â–…â–ƒâ–†â–â–…â–ˆâ–†â–‡â–…â–†â–ˆâ–…â–„â–‡â–†â–‡â–„â–†â–‡â–„â–‡â–ˆâ–…â–…â–„â–…â–†â–„â–†â–‡â–…â–†â–†â–…
wandb:      train/ensemble_f1 â–†â–‡â–‡â–„â–‡â–†â–…â–â–…â–…â–†â–†â–ˆâ–ˆâ–†â–†â–ˆâ–…â–‡â–‡â–…â–‡â–‡â–‡â–„â–‡â–…â–‡â–†â–…â–‚â–‡â–…â–†â–†â–„â–…â–…â–ˆâ–„
wandb:         train/mil_loss â–„â–„â–„â–†â–‚â–‡â–…â–†â–„â–‚â–„â–†â–‚â–‚â–„â–ƒâ–„â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–‡â–‚â–ƒâ–†â–‚â–â–‚â–â–ƒâ–…
wandb:      train/policy_loss â–…â–ˆâ–ˆâ–…â–â–ˆâ–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–ˆâ–â–â–…â–â–ˆâ–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–â–„â–â–„â–„â–„â–„â–„â–â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9216
wandb: best/eval_avg_mil_loss 0.25173
wandb:  best/eval_ensemble_f1 0.9216
wandb:            eval/avg_f1 0.69623
wandb:      eval/avg_mil_loss 0.94122
wandb:       eval/ensemble_f1 0.69623
wandb:            test/avg_f1 0.84076
wandb:      test/avg_mil_loss 0.74324
wandb:       test/ensemble_f1 0.84076
wandb:           train/avg_f1 0.77701
wandb:      train/ensemble_f1 0.77701
wandb:         train/mil_loss 0.88859
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/db9p3obd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103624-db9p3obd/logs
wandb: Agent Starting Run: 6xezg0u4 with config:
wandb: 	actor_learning_rate: 0.0001898112177850988
wandb: 	attention_dropout_p: 0.10886442800668387
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 190
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3430278759072731
wandb: 	temperature: 0.7276997666780338
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103833-6xezg0u4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6xezg0u4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–‚â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–â–ˆâ–‡â–…â–†â–‡â–…â–‡â–‡â–…â–„â–…â–…â–‡â–†â–‡â–…â–ˆâ–‡â–ƒâ–†â–…â–ˆâ–ˆâ–‡â–…â–â–„â–†â–…â–…â–…â–…â–„â–†â–†â–„â–ƒ
wandb:      eval/avg_mil_loss â–‚â–â–„â–ƒâ–â–â–„â–…â–…â–„â–‚â–ˆâ–‡â–‚â–ƒâ–„â–†â–â–‚â–â–‡â–ˆâ–„â–…â–†â–â–†â–‚â–†â–â–„â–‡â–‡â–…â–„â–ƒâ–â–‡â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ƒâ–…â–†â–‡â–‡â–„â–„â–‡â–ˆâ–†â–‡â–†â–‡â–…â–…â–„â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–…â–‡â–‚â–†â–â–„â–‡â–‡â–‚â–ˆâ–ƒâ–„â–†â–„â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–ƒâ–â–ƒâ–„â–„â–ƒâ–„â–…â–…â–†â–…â–…â–‚â–…â–†â–…â–…â–„â–†â–…â–„â–ƒâ–…â–…â–…â–„â–‡â–…â–„â–ˆâ–ƒâ–‚â–ƒâ–„â–„â–…â–„â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–‡â–„â–†â–ƒâ–‡â–†â–ƒâ–…â–…â–†â–‡â–†â–‡â–†â–†â–†â–‡â–â–„â–†â–†â–…â–…â–ƒâ–„â–†â–‡â–…â–ˆâ–…â–ˆâ–ƒâ–‡â–ƒâ–‡â–†â–„â–‡
wandb:         train/mil_loss â–„â–ƒâ–‚â–‡â–ˆâ–ˆâ–†â–…â–†â–‚â–‚â–ƒâ–…â–†â–†â–ƒâ–†â–„â–‡â–…â–â–†â–…â–‡â–‡â–ƒâ–„â–†â–„â–„â–†â–†â–†â–‡â–„â–‚â–â–‡â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91414
wandb: best/eval_avg_mil_loss 0.24059
wandb:  best/eval_ensemble_f1 0.91414
wandb:            eval/avg_f1 0.88992
wandb:      eval/avg_mil_loss 0.3445
wandb:       eval/ensemble_f1 0.88992
wandb:            test/avg_f1 0.79867
wandb:      test/avg_mil_loss 0.87831
wandb:       test/ensemble_f1 0.79867
wandb:           train/avg_f1 0.81119
wandb:      train/ensemble_f1 0.81119
wandb:         train/mil_loss 0.57603
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweet-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6xezg0u4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103833-6xezg0u4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: naxvs5ee with config:
wandb: 	actor_learning_rate: 4.06420046141033e-06
wandb: 	attention_dropout_p: 0.2262776387108461
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12966451983246874
wandb: 	temperature: 5.228748566385927
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104049-naxvs5ee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/naxvs5ee
wandb: uploading history steps 134-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ƒâ–‚â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–…â–ˆâ–„â–‡â–…â–ˆâ–†â–…â–†â–‡â–ƒâ–„â–„â–†â–…â–‡â–…â–ˆâ–â–‡â–„â–†â–ˆâ–„â–…â–…â–ˆâ–‡â–„â–„â–
wandb:      eval/avg_mil_loss â–„â–‚â–…â–‚â–„â–‡â–ƒâ–â–…â–â–ˆâ–â–„â–‡â–†â–â–…â–…â–â–„â–„â–ƒâ–†â–â–„â–„â–ƒâ–…â–„â–†â–…â–‡â–‚â–ƒâ–†â–â–ƒâ–‚â–ƒâ–
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–‚â–„â–‚â–â–ˆâ–ˆâ–†â–ˆâ–ˆâ–…â–‡â–ˆâ–‚â–ƒâ–â–‚â–…â–†â–†â–‡â–„â–…â–…â–ˆâ–†â–‡â–„â–â–ˆâ–‡â–ˆâ–…â–ˆâ–‡â–„â–…â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–ƒâ–„â–…â–„â–ƒâ–ƒâ–…â–…â–†â–…â–â–„â–„â–…â–†â–‡â–…â–…â–„â–†â–ˆâ–„â–…â–ƒâ–‡â–…â–ƒâ–‡â–†â–„â–‡â–…â–…â–ƒâ–†â–…â–…â–‡
wandb:      train/ensemble_f1 â–ˆâ–ƒâ–‚â–…â–…â–†â–ƒâ–‚â–‚â–…â–â–ƒâ–…â–…â–‚â–ƒâ–†â–ˆâ–…â–â–ƒâ–…â–…â–…â–ƒâ–‡â–ˆâ–†â–†â–…â–â–…â–‚â–‡â–ƒâ–ƒâ–…â–ˆâ–‡â–ƒ
wandb:         train/mil_loss â–„â–…â–†â–…â–ƒâ–â–„â–„â–â–†â–†â–‡â–ˆâ–†â–‡â–…â–†â–‚â–…â–…â–†â–…â–ƒâ–‚â–†â–…â–„â–…â–…â–†â–…â–‡â–ˆâ–ƒâ–„â–…â–ƒâ–„â–„â–
wandb:      train/policy_loss â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.9216
wandb: best/eval_avg_mil_loss 0.2772
wandb:  best/eval_ensemble_f1 0.9216
wandb:            eval/avg_f1 0.48369
wandb:      eval/avg_mil_loss 2.57349
wandb:       eval/ensemble_f1 0.48369
wandb:            test/avg_f1 0.9141
wandb:      test/avg_mil_loss 0.20458
wandb:       test/ensemble_f1 0.9141
wandb:           train/avg_f1 0.71885
wandb:      train/ensemble_f1 0.71885
wandb:         train/mil_loss 0.88137
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pious-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/naxvs5ee
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104049-naxvs5ee/logs
wandb: Agent Starting Run: dv2ms1f2 with config:
wandb: 	actor_learning_rate: 4.378907464089375e-05
wandb: 	attention_dropout_p: 0.10226360897753112
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20600354421128075
wandb: 	temperature: 0.3350067126409795
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104305-dv2ms1f2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dv2ms1f2
wandb: uploading wandb-summary.json
wandb: uploading history steps 162-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–…â–ƒâ–ƒâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–ˆâ–…â–†â–…â–†â–†â–…â–ˆâ–†â–ˆâ–†â–†â–ˆâ–ˆâ–â–‡â–…â–†â–†â–‡â–†â–ˆâ–†â–†â–â–â–â–†â–‡â–‡â–ˆâ–ƒâ–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–â–‚â–‚â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‡â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–…â–â–â–‚â–‚â–
wandb:       eval/ensemble_f1 â–†â–†â–…â–†â–ƒâ–†â–ˆâ–ˆâ–†â–ˆâ–†â–†â–†â–â–ˆâ–…â–ˆâ–†â–†â–ˆâ–†â–†â–‡â–â–ˆâ–†â–†â–ƒâ–ˆâ–‡â–ˆâ–ˆâ–†â–â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–…â–„â–†â–„â–‡â–‚â–ƒâ–ƒâ–…â–„â–„â–…â–‡â–‚â–†â–†â–â–…â–†â–…â–ˆâ–ˆâ–†â–‡â–‚â–†â–„â–…â–‡â–‡â–‡â–‚â–‡â–ˆâ–…â–…â–‡â–ƒ
wandb:      train/ensemble_f1 â–†â–…â–†â–…â–„â–†â–…â–„â–ˆâ–„â–…â–‡â–…â–‡â–…â–†â–â–ˆâ–†â–†â–‡â–†â–‡â–‡â–„â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–†â–…â–ˆâ–‡â–„â–‚â–‡â–ˆ
wandb:         train/mil_loss â–â–‡â–‡â–â–„â–‚â–…â–‡â–…â–…â–†â–â–â–„â–â–„â–â–…â–ƒâ–‚â–†â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–â–ƒâ–„â–…â–ˆâ–†â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–„â–â–„â–â–„â–„â–â–„â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91432
wandb: best/eval_avg_mil_loss 0.30718
wandb:  best/eval_ensemble_f1 0.91432
wandb:            eval/avg_f1 0.86861
wandb:      eval/avg_mil_loss 0.4446
wandb:       eval/ensemble_f1 0.86861
wandb:            test/avg_f1 0.9141
wandb:      test/avg_mil_loss 0.22377
wandb:       test/ensemble_f1 0.9141
wandb:           train/avg_f1 0.85017
wandb:      train/ensemble_f1 0.85017
wandb:         train/mil_loss 0.40587
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deft-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dv2ms1f2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104305-dv2ms1f2/logs
wandb: Agent Starting Run: qydbowxw with config:
wandb: 	actor_learning_rate: 2.2923234612065392e-05
wandb: 	attention_dropout_p: 0.387620016998815
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.069447903117411
wandb: 	temperature: 5.0798805185721605
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104535-qydbowxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/vqaof6bn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qydbowxw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–‡â–‚â–‡â–†â–‚â–…â–‡â–…â–…â–‡â–…â–†â–‡â–‡â–…â–‡â–„â–†â–„â–…â–ƒâ–…â–â–ˆâ–†â–‡â–…â–†â–ˆâ–†â–ƒâ–‡â–…â–…â–‚â–†â–ˆâ–‚
wandb:      eval/avg_mil_loss â–â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–â–‚â–â–â–â–â–ˆâ–ƒâ–â–‚â–ƒâ–â–â–‚â–„â–„â–â–ƒâ–â–â–â–‚â–ƒâ–â–ƒâ–â–ƒâ–„â–
wandb:       eval/ensemble_f1 â–†â–‡â–…â–‚â–ƒâ–…â–†â–…â–‡â–…â–†â–†â–‡â–„â–…â–‡â–„â–‡â–„â–…â–„â–†â–‚â–…â–ˆâ–ˆâ–ˆâ–…â–â–„â–ˆâ–†â–…â–‡â–…â–ˆâ–…â–ˆâ–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–„â–ƒâ–…â–ƒâ–†â–†â–…â–†â–…â–„â–„â–„â–ƒâ–„â–‚â–…â–…â–„â–…â–„â–…â–…â–†â–ˆâ–„â–„â–…â–„â–„â–…â–…â–…â–…â–†â–…â–„â–ƒâ–
wandb:      train/ensemble_f1 â–†â–‚â–†â–…â–†â–ƒâ–…â–…â–„â–ƒâ–†â–†â–…â–ƒâ–…â–ƒâ–„â–…â–…â–„â–…â–…â–„â–ˆâ–…â–…â–„â–„â–„â–„â–†â–†â–‡â–…â–…â–…â–…â–ƒâ–ƒâ–
wandb:         train/mil_loss â–…â–…â–„â–‚â–ƒâ–ƒâ–‡â–â–„â–„â–‚â–„â–…â–‚â–ˆâ–ƒâ–…â–‚â–‡â–ƒâ–â–…â–â–‚â–ƒâ–„â–…â–ƒâ–…â–ƒâ–…â–â–ƒâ–â–‡â–ƒâ–‚â–‚â–ƒâ–„
wandb:      train/policy_loss â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91778
wandb: best/eval_avg_mil_loss 0.25547
wandb:  best/eval_ensemble_f1 0.91778
wandb:            eval/avg_f1 0.73752
wandb:      eval/avg_mil_loss 1.64114
wandb:       eval/ensemble_f1 0.73752
wandb:            test/avg_f1 0.92191
wandb:      test/avg_mil_loss 0.20698
wandb:       test/ensemble_f1 0.92191
wandb:           train/avg_f1 0.77671
wandb:      train/ensemble_f1 0.77671
wandb:         train/mil_loss 0.56591
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qydbowxw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104535-qydbowxw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
