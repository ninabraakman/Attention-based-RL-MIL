wandb: Agent Starting Run: zxzvx83j with config:
wandb: 	actor_learning_rate: 7.785972984755701e-05
wandb: 	attention_dropout_p: 0.0023236273311059708
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27718320989541256
wandb: 	temperature: 1.6770086602967538
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041917-zxzvx83j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxzvx83j
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▅▅▆██
wandb: best/eval_avg_mil_loss ▇▃▇█▆▄▃▁▄
wandb:  best/eval_ensemble_f1 ▁▂▃▃▅▅▆██
wandb:            eval/avg_f1 ▅▆▄▆▆▅▆▆▆▇▁▅▄▇█▄▆▆▅▄▄▇▄▅▅▁▃▃▃▅▆▇▄▃▅▅▇▃▄▃
wandb:      eval/avg_mil_loss ▅▂▅▄▅▅▄▃▅▆▅▂▅▅▅▅▅▄▃▇▄▃▅▆▆▃█▆▅▆▃▁▃▇▄▁▅███
wandb:       eval/ensemble_f1 ▅▆▄▄▆▄▅▅▆▆▇▇▁▅▄▆█▃▄▆▄▅▄▇▄▅▁▃▃▅▆▇▄▃▅▅▇▃▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▆▃▅▄▅▃▆▄▅▄▄▃▁▃▁█▄▃▄▄▅▅▃▃▇▄▅▅▃▄▅▄▄▂▄▄▆
wandb:      train/ensemble_f1 ▅▃▆▃▆▄▅▅▃▆▄▅▄▄▃▃▁▃█▃▇▃▄▅▅▄▂▇▃▅▅▄▃▃▅▆▆▂▄▆
wandb:         train/mil_loss ▆▆▆▃█▅█▃▆▄▅▆█▆▃▃▅▆▃▆▁▂▆▇▅▂▇▆▂▄▅▁▂▇▄▂▅▅▅▂
wandb:      train/policy_loss ▅▅▅▅▇▅▁▅▅▅▅▅▂▅▅▅▅▅▅▅▇█▅▅▅▄▅▂▇▅▅▅▅▅▅▆▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆█▆▁▆▆▆▆▂▆▆▆▆▆▆▆▆▇▆▆▆▄▆▂█▆▆▇▆▆▆▇▄▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82836
wandb: best/eval_avg_mil_loss 0.43542
wandb:  best/eval_ensemble_f1 0.82836
wandb:            eval/avg_f1 0.77005
wandb:      eval/avg_mil_loss 0.53374
wandb:       eval/ensemble_f1 0.77005
wandb:            test/avg_f1 0.77274
wandb:      test/avg_mil_loss 0.51198
wandb:       test/ensemble_f1 0.77274
wandb:           train/avg_f1 0.79876
wandb:      train/ensemble_f1 0.79876
wandb:         train/mil_loss 1.2984
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxzvx83j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041917-zxzvx83j/logs
wandb: Agent Starting Run: sw6go1o5 with config:
wandb: 	actor_learning_rate: 1.0218385501048948e-06
wandb: 	attention_dropout_p: 0.48121419969755674
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8554077793051938
wandb: 	temperature: 7.303572845926196
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042024-sw6go1o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sw6go1o5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▁▂█
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▅▄▅▅▅▅▆▇▄▃▄▅▅▆▃█▃▆▃▄▆▄▄▄█▆▄▁▂▂▄▃▄▃▂▄▂▅▄▃
wandb:      eval/avg_mil_loss ▂▃▃▅▄▃▇▁▆▄▁▂▄▅▄▂▄▄▃▄▂▄▃▅▂▃▅▅▃▆▆▄▅▄▃▂▃█▆▄
wandb:       eval/ensemble_f1 ▆▄▅▇▅▃▅▆▂▇▅▅▆▄▅▄▄▃▄▂▆▄▃▇▄▃▇█▃▄▁▇▄▂▃▃▅▅▆▃
wandb:           train/avg_f1 ▇█▆▅▆█▆▅▅▄▇█▇▇▇▅▃▇▄▇▆▄▆▄▆▅▄▂▄▁▃▁▄▂▅▃▃▃▂▃
wandb:      train/ensemble_f1 ▇▆▇▇▅▆█▆▅▇▆▇█▅▇▇▇▄▇▄▃▆▆▇▅▄▃▆▃▅▂▃▅▅▃▃▄▁▃▁
wandb:         train/mil_loss ▆█▆▇█▆▅▅▇▇▆▆▇▇▅▆▆▆▅▅▅▅▅▄▁▄▄▄▄▅▃▂▂▂▁▂▂▄▄▁
wandb:      train/policy_loss ▄▅▄▄▄▄▄▄▄▃▄▄▅▄▄▄▅▄▄▄▅▆▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄█▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▄▅▂▂▂▂▂▂▂█▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.47211
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.77371
wandb:      eval/avg_mil_loss 0.4699
wandb:       eval/ensemble_f1 0.77371
wandb:           train/avg_f1 0.76244
wandb:      train/ensemble_f1 0.76244
wandb:         train/mil_loss 1.86037
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sw6go1o5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042024-sw6go1o5/logs
wandb: ERROR Run sw6go1o5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ujyw26zj with config:
wandb: 	actor_learning_rate: 3.6247589881007986e-05
wandb: 	attention_dropout_p: 0.3833739748252211
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8833137213637785
wandb: 	temperature: 1.6608634365301178
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042335-ujyw26zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujyw26zj
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃█
wandb: best/eval_avg_mil_loss ▅▄█▁
wandb:  best/eval_ensemble_f1 ▁▂▃█
wandb:            eval/avg_f1 ▆▃▃▆▄▅▅▄▆▄▄▆▇▄▆▅▄▃▄▂▄▅▆▃▅▄▆▅▄█▃▅▆▃▄▁▅▄▂▂
wandb:      eval/avg_mil_loss ▆▄▅▃▅▄▆▁▅▃▄▃▂▃▄▂▃▅▇▃▅▃▅▃▄▄▃▄▁▆▆█▃▃▅▄▅▃▄▄
wandb:       eval/ensemble_f1 ▇▆▄▄▄▆▅▅▆▅▅▅▆▇█▅▄▄▃▅▇▅▅▄▅▇▆▁▇▆▄▆▇█▄▄▅▆▄▂
wandb:           train/avg_f1 ▆▅▆█▅▇█▆▅▇▄▄▄▅▄█▇▆▄█▄▃▃▇▁▆▆▅▅▅▅▄▃▆▆▅▄▂▁▂
wandb:      train/ensemble_f1 ▄▅▄▄▄█▂▇▆▅▂▄▄▅▄▆▃▅▇▂▃▃▃▃▃▁▃▂▅▅▄▅▂▄▂▅▆▄▄▂
wandb:         train/mil_loss █▆█▆▅▆▇▆▅▇▆▄▄▆▃▆▄▅▂▄▅▃▅▆▄▄▄▄▆▆▄▄▂▃▄▃▁▇▅▄
wandb:      train/policy_loss ▄▁▄▄▄▄▄▄▄▄█▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▄▅▅▅▆▅▅▅▅▅▅▅▆▅▅▁▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.40919
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.75911
wandb:      eval/avg_mil_loss 0.46336
wandb:       eval/ensemble_f1 0.75911
wandb:           train/avg_f1 0.7763
wandb:      train/ensemble_f1 0.7763
wandb:         train/mil_loss 0.85274
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujyw26zj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042335-ujyw26zj/logs
wandb: ERROR Run ujyw26zj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: fmri63jr with config:
wandb: 	actor_learning_rate: 1.4702476432278276e-06
wandb: 	attention_dropout_p: 0.49391657661514593
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05269196843359236
wandb: 	temperature: 0.8004713116696338
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042456-fmri63jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmri63jr
wandb: uploading history steps 64-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆▇█
wandb: best/eval_avg_mil_loss ▅▄█▄▁▃
wandb:  best/eval_ensemble_f1 ▁▁▃▆▇█
wandb:            eval/avg_f1 ▅▃▃▅▆█▄▂▅▆▆▇▄█▆▆▆▅▅▃▆▃▆▃▄▅▁█▄▃▆▄▃▄▆▄▆▅▃▆
wandb:      eval/avg_mil_loss ▃█▇▃▄▁█▄█▃▂▃▅▄▅▅▄▆▃█▄▁▄▅▅▇▅▅▅▇▆▅▄▅▄█▅▆▆▆
wandb:       eval/ensemble_f1 ▅▄▆▆▇▄▅▆▅▇▆▄▇▅▅▅▄▆▆▆▇▃▅▃▄▅▅▁█▄▆▃▄▆▃▆▇▅▄▄
wandb:           train/avg_f1 ▇▅▇█▄▆▆▇▇▆█▆▅█▃▅▆▃▆▃▄▆▂▆▅▃▅▄▅▂▂▅▃▄▆▁▅▁▆▄
wandb:      train/ensemble_f1 ▇▇▇▆▆▇▇▆▆▇▇▅█▃▅▄▆▆▄▆▄▅▆▂▆▃▅▅▅▂▂▅▃▆▂▅▁▆▁▄
wandb:         train/mil_loss ▆▆█▆▆▆▆▆▆▅▅▅▅▅▆▅▄▄▄▅▄▃▄▄▄▃▅▃▄▂▃▂▂▃▃▃▃▁▁▂
wandb:      train/policy_loss ▅▅▅▅▅▃▅▅▅▅▆▅▅█▄▅▅▅▅▇▄▁▅▅▅▅▇▅▅▃▅▅▅▆▅▅▅▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▁▄▅▃▄▄▄▄▄█▆▄▄▄▄▂▄▄▄▄▄▄▆▂▆▄▄▅▄▅▆▄▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82846
wandb: best/eval_avg_mil_loss 0.43649
wandb:  best/eval_ensemble_f1 0.82846
wandb:            eval/avg_f1 0.7992
wandb:      eval/avg_mil_loss 0.49739
wandb:       eval/ensemble_f1 0.7992
wandb:           train/avg_f1 0.77781
wandb:      train/ensemble_f1 0.77781
wandb:         train/mil_loss 1.20729
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmri63jr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042456-fmri63jr/logs
wandb: ERROR Run fmri63jr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	size mismatch for task_model.mlp.0.weight: copying a param with shape torch.Size([128, 20]) from checkpoint, the shape in current model is torch.Size([512, 20]).
wandb: ERROR 	size mismatch for task_model.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
wandb: ERROR 	size mismatch for task_model.mlp.3.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 512]).
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u9afj423 with config:
wandb: 	actor_learning_rate: 4.3258364044489e-05
wandb: 	attention_dropout_p: 0.021448895343702257
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12132423077157696
wandb: 	temperature: 2.9316843489706623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042625-u9afj423
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u9afj423
wandb: uploading history steps 116-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▁▅▄▂▄▆▂█▃▅▃▄▄▃▃▄▅▃▄▆▃▅▆▄▆▁▅▃█▂▃▅▂▇▄▅▆▂▃▅
wandb:      eval/avg_mil_loss ▅▃▂▃▄▄▃▃▃▅▃▃▄▅▄▆▃▆▄▆▁▅▇█▄▂▃▄▄▅▃▂█▂▃█▁▅█▄
wandb:       eval/ensemble_f1 ▅▂▇▅▂▄▅▇▃▆█▄▅▆▅▆▁▄▅▃▅▅▅▄▆▆▅█▃▅▇▄▂▂▇▃▁▇▃▃
wandb:           train/avg_f1 █▅▄▄▄▅▅▄▆▆▅▆▇▃▅▄▃▅▅▃▆▆▄▅▃▄▄▆▆▆▃▄▅▅▁▇▇▅▅▄
wandb:      train/ensemble_f1 ▇▄▄▅▅█▆▄▆▄▇▄▄▃▅▃▅▇▆▄▆▆▄▆▅▄▆▆▅▅▆▃▁▄▇▆▇▅▅▆
wandb:         train/mil_loss ▇█▇▄▂▅▄▅▆▆▆▆▅▇▃▃▆▃▃▂▄▃▆▃▂▂▂▄▄▅▂▅▃▃▁▁▂▃▃▂
wandb:      train/policy_loss ▆▆█▆▆▆▆▆▆▆▆▆▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▆▃▆▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████████▄████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84867
wandb: best/eval_avg_mil_loss 0.37523
wandb:  best/eval_ensemble_f1 0.84867
wandb:            eval/avg_f1 0.79453
wandb:      eval/avg_mil_loss 0.44938
wandb:       eval/ensemble_f1 0.79453
wandb:           train/avg_f1 0.8078
wandb:      train/ensemble_f1 0.8078
wandb:         train/mil_loss 1.98062
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u9afj423
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042625-u9afj423/logs
wandb: ERROR Run u9afj423 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kk5jqzuu with config:
wandb: 	actor_learning_rate: 5.105584249142839e-05
wandb: 	attention_dropout_p: 0.4055533092980569
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.038043439417819624
wandb: 	temperature: 6.174793644363752
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042850-kk5jqzuu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk5jqzuu
wandb: uploading wandb-summary.json
wandb: uploading history steps 72-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▆█
wandb: best/eval_avg_mil_loss ▆▆█▇▁▆
wandb:  best/eval_ensemble_f1 ▁▂▂▄▆█
wandb:            eval/avg_f1 ▅▁▄▂▅▅▅▅▅▁▅▅▆▄▇▄▄▅█▆▅▂▂▆▄▅▅█▄▃▆▄▃▅▆▅▅▃▄▇
wandb:      eval/avg_mil_loss ▄▆▄▆▃▄▄▂▄▅▄▅▂▅▂▅▃▄▃▃▂▄▅▂▅██▇▂▃▁▄▃▂▆▃▅▄▃▃
wandb:       eval/ensemble_f1 ▅▃▅▄▅▅▃▁▆▄▅▃▅▆▇▄▄█▆▂▃▂▂▃▆▄▅▅▄▄▆▄▆▆▃▅▅▄▃▇
wandb:           train/avg_f1 ▅▃▅▄▆█▅▄▅▅▂▂▃▁▃▁▅▇▅▆▃▇▇▂▄▆▄▆▅▄▂▇▅▄▅▆▆▆▃▇
wandb:      train/ensemble_f1 ▅▅▄▅▆▆█▅▅▅▂▂▁▃▆▁▅▅▆▅▆▇▇▅▂▆▅█▅▆▅▄▆▂▅▆▆▆▃▇
wandb:         train/mil_loss ▇▁▃▆▇▅█▆▁▄▄▄▆▆▄▃▅█▅▅▅▄▅▆▄▆▂▁▄▆▇▄▄▃▂▂▃▆▂█
wandb:      train/policy_loss ▁▄▁▄▄▁█▁▁▄▁██▄▁▁▁▄▄▁▄██▁██▄▄▄▁█▄█▄▁█▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▁█▁█▄█▁██▄▁▁▁▄██▄▄▄▄▁▄▄█▄█▁█▄▄▄█▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79558
wandb: best/eval_avg_mil_loss 0.52848
wandb:  best/eval_ensemble_f1 0.79558
wandb:            eval/avg_f1 0.78453
wandb:      eval/avg_mil_loss 0.5145
wandb:       eval/ensemble_f1 0.78453
wandb:           train/avg_f1 0.76925
wandb:      train/ensemble_f1 0.76925
wandb:         train/mil_loss 1.77417
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk5jqzuu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042850-kk5jqzuu/logs
wandb: ERROR Run kk5jqzuu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mssinsh3 with config:
wandb: 	actor_learning_rate: 0.0005569878546349457
wandb: 	attention_dropout_p: 0.1715534132283853
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4233056935286077
wandb: 	temperature: 1.5809924876065884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043018-mssinsh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mssinsh3
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 100-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄█
wandb: best/eval_avg_mil_loss ▂▁█▃
wandb:  best/eval_ensemble_f1 ▁▃▄█
wandb:            eval/avg_f1 ▆▃▁▃▅▄▄▄▅▄▄▅▅▃▅▄▅▄▂▅▅▄▄▅▆▃▆▇▅▄▇▆▄▅▃▅▅█▃▄
wandb:      eval/avg_mil_loss ▂▄▆▆█▂▇▇▆▆▃▅▆▃▅▅▄█▇▆▇▅█▄▆▁██▇▅▇▆▄▆▅▆▂▅▃▇
wandb:       eval/ensemble_f1 ▇▆▃▄▃▅▄▆▁▅▆▆▄▄▄▄▅▄▆▃▄▃▆▄▇▄▂▂█▄▄▄▆▂▄▅▅▆▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▇▅▆▅▆▅▆▅▅▆▃▇▅▇▅▅▆▆▁▅█▆▇▅▅▅▆▆▅█▅▅▆▆▇▅▇
wandb:      train/ensemble_f1 ▆▄▂▄▄▃▄▃▃▅▆▃▅▄▅▂▄▄▄▃▆▅█▁▄▅▄▆▃▄▅▆▅▄▄▇▃▄▅▅
wandb:         train/mil_loss ▄▄▅▅▄▄▅▅▅▅▂▆▃▂▄▆▂█▅▇▃▄▄▅▁▅▄▄▂▅▅▅▄▆▄▄▃▆▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82836
wandb: best/eval_avg_mil_loss 0.4319
wandb:  best/eval_ensemble_f1 0.82836
wandb:            eval/avg_f1 0.76631
wandb:      eval/avg_mil_loss 0.56108
wandb:       eval/ensemble_f1 0.76631
wandb:            test/avg_f1 0.73654
wandb:      test/avg_mil_loss 0.61046
wandb:       test/ensemble_f1 0.73654
wandb:           train/avg_f1 0.77689
wandb:      train/ensemble_f1 0.77689
wandb:         train/mil_loss 1.12979
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mssinsh3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043018-mssinsh3/logs
wandb: Agent Starting Run: e3g08r4h with config:
wandb: 	actor_learning_rate: 0.0004950020675556752
wandb: 	attention_dropout_p: 0.3707570792471581
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4243428396767176
wandb: 	temperature: 2.2064380074959877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043217-e3g08r4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3g08r4h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss ▆█▅▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▁█▆▂▆▁▄▂▃▄▄▃▃▂▃▄▆▆▆▆▅▅▁▄▇▃▆▅▃▂▃▂▄▅▄▄▅▄▆▄
wandb:      eval/avg_mil_loss ▂█▃▂▃▂▄▄▆▄▇▄▅▄▂▆▂▁▃▃▆▄▂▄▁▄▄▆▃▆▂▃▆▃▃▄▃▂▁▄
wandb:       eval/ensemble_f1 ▇█▄▅▆▄▄▄▁▅▅▅▃▁▄▇█▆▂▇▅▁▅█▃▃▇▇▃▄▆▅▅▄▂▁▆▆▄▃
wandb:           train/avg_f1 ▄▄▁▂▅▂▂▂▃▅▅▄▂▃▄▅▄▃▄▅▇▃▂▂▆▁▁▁▄▅█▆▂▆▃▅▇▄▆▇
wandb:      train/ensemble_f1 ▅▃▅▅▆▅▆▇█▇▆▆▅██▆▄▆▄▆▅▅▅▃▇▆▁▆▅▅▄▅█▆▆▄▇▆▅▇
wandb:         train/mil_loss ▅▇██▆▇▄▄▅▅▆▃▃▆▃▅▆▃▂▃▄▆▄▄▃▄▂▆▃▄▁▄▅▃▂▂▁▃▃▂
wandb:      train/policy_loss ▅█▅▅█▁▅█▅▅▁▅▅██▅▁▅▁█▁▁▅▁▁▁▅▁▁▅▅▁██▅▁▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████▁██████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78467
wandb: best/eval_avg_mil_loss 0.48935
wandb:  best/eval_ensemble_f1 0.78467
wandb:            eval/avg_f1 0.72168
wandb:      eval/avg_mil_loss 0.57849
wandb:       eval/ensemble_f1 0.72168
wandb:           train/avg_f1 0.74196
wandb:      train/ensemble_f1 0.74196
wandb:         train/mil_loss 1.57273
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3g08r4h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043217-e3g08r4h/logs
wandb: ERROR Run e3g08r4h errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d7xtyeqc with config:
wandb: 	actor_learning_rate: 0.0001168070343060098
wandb: 	attention_dropout_p: 0.10339965019573484
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4064755113342424
wandb: 	temperature: 3.7817778240201783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043426-d7xtyeqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7xtyeqc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 57-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss ▆▁█▂
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▃▆▅▄▇▆▄▄▁▅▄▄▃▅▆▄▄█▆▆▄▄▇▆▄▄▂▆▁▅▂▆▅▅▆▄▆▄▆▃
wandb:      eval/avg_mil_loss ▂▁▃▃▆▄▂▁▃▄▅█▂▅▂▃▂▂▂▅▆▂▃▃▄▆█▇▂▅▂▃▄▃▄▁▂▅▆▄
wandb:       eval/ensemble_f1 ▆▃▄▆▅▄▇▅▆▆▁▄▄▄▄▆▅▄▄█▄▄▇▄▇▂▆▁▄▅▂▆▅▆▄▆▄▅▆▅
wandb:           train/avg_f1 ▄▆▆▅▅▄▄▄▅▅▆▆▅▅▆▅▅▆▇▅▇▄▄▆█▇▆▆▂▄▁▃██▄▃▆▆▆▇
wandb:      train/ensemble_f1 ▄▇▆▅▅▅▄▄▅▅▆▆▅▅▅▆▅▅▃▆▅▄▇▆▄█▄▇▆▆▆▁▃█▇▃▆▆▄▆
wandb:         train/mil_loss ▅▅▇▄▄▅▄▄▄▄▅▂▄▅▆▅▆▆▆▄▄▄▁▁▆▂██▃▅▄▄▆▄▃▃▇▅▂▃
wandb:      train/policy_loss █████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▁██████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.37032
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.8052
wandb:      eval/avg_mil_loss 0.4414
wandb:       eval/ensemble_f1 0.8052
wandb:           train/avg_f1 0.81251
wandb:      train/ensemble_f1 0.81251
wandb:         train/mil_loss 2.24781
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7xtyeqc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043426-d7xtyeqc/logs
wandb: ERROR Run d7xtyeqc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7o1od0y7 with config:
wandb: 	actor_learning_rate: 0.00012845948431433084
wandb: 	attention_dropout_p: 0.4188261319515624
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0949797593788756
wandb: 	temperature: 5.880363623922037
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043538-7o1od0y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7o1od0y7
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▁█▁
wandb:  best/eval_ensemble_f1 ▁▄▆▇▇█
wandb:            eval/avg_f1 ▄▆▄▅▁▄▄▆▇▃▅▃▅▃▆▇▃▃█▇▅▅▄▅▅▇▄▂▆▆▃▅▄▃▅▄▇▄▆▄
wandb:      eval/avg_mil_loss ▄▃█▅▃▄▅▇▄▅▄▂▅▂▅▆▆▃▄▇▄▅▅▁▆▆▄▆█▅▃▅▅▂▃▅▃▆▅▆
wandb:       eval/ensemble_f1 ▅▄▆▁▇▄▆▄▁▄▅▇▅▄▆▇▂▆▃▅▄▇▆▇▆▆▆▅▅▅▅▆▅█▅▅▂▆▅▇
wandb:           train/avg_f1 ▅█▃▇▅▆▅▃▄▆▃▅▆▅▇▅▅▅▅▄▄▃▄▅▆▃▃▁▅▃▅▃▁▄▆▃▆▄▃▁
wandb:      train/ensemble_f1 ▅▄▅▇█▆▅▇▄▃▃▇▄▆▃▄▅▆▃▄▄▆▄▄▄▅▅▂▄▅▅▃▁▆▂▄▄▃▂▂
wandb:         train/mil_loss ▅▇▆▆▇▆▇▆▅▅▅█▅▅▄▆▄▆▅▃▆▃▃▅▃▄▅▃▃▂▃▃▂▂▃▁▂▁▂▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆█▆▆▁▆▆▆▁▆█▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.38245
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.79197
wandb:      eval/avg_mil_loss 0.4838
wandb:       eval/ensemble_f1 0.79197
wandb:           train/avg_f1 0.78713
wandb:      train/ensemble_f1 0.78713
wandb:         train/mil_loss 1.8385
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7o1od0y7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043538-7o1od0y7/logs
wandb: ERROR Run 7o1od0y7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2gwsc10c with config:
wandb: 	actor_learning_rate: 4.362885906256791e-05
wandb: 	attention_dropout_p: 0.004023745808535373
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5195792679366638
wandb: 	temperature: 0.0868993297928966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043838-2gwsc10c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gwsc10c
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▆█
wandb: best/eval_avg_mil_loss █▆▄▄▄▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▆█
wandb:            eval/avg_f1 ▃▂▄█▃▆▄▆▆▄▃▅▆▃▃▅▅▅▆▅▅▄▆▄▄▅▃▄▆▁▃█▆▄▆▃▆▅▃▅
wandb:      eval/avg_mil_loss ▇▅▄▃▇▇▇▄▁▃█▅▇▅▆▄▅▆▅▆▅▅▄▅▄▆█▃▆▆██▇▄▅▅▅▄▃▅
wandb:       eval/ensemble_f1 ▂▄▂▃▅▁█▄▄▅▃▃▃▄▄▅▃▃▃▄▄▄▅▂▅▃▁▃▂▁▄▅▄▃▄▄▄▁▅▃
wandb:           train/avg_f1 ▅▅▅▅▅▅▄▄▃▆▅▅▅▄▆▅▆▄▄▄▄▇▅▄▃▃▅▃▄▄▄▆▄▅▅▅▃█▁▆
wandb:      train/ensemble_f1 ▅▅▆▄▅▄▃▄▅▄▅▁▄▄▆▄▅▃▆▂▅▅▆▄▅▄▄▅▆▅▄▄▄▅▂▅▃█▁▄
wandb:         train/mil_loss ▆▅▇▃▇▆▇▅▅█▅▅▄▅▅▆▂▆▆▄▆▆▅▆▂█▅▅▅▃▄▄▃▃▁▂▄▃▂▂
wandb:      train/policy_loss █████████████████████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85711
wandb: best/eval_avg_mil_loss 0.40983
wandb:  best/eval_ensemble_f1 0.85711
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.49215
wandb:       eval/ensemble_f1 0.78777
wandb:           train/avg_f1 0.78628
wandb:      train/ensemble_f1 0.78628
wandb:         train/mil_loss 0.96142
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gwsc10c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043838-2gwsc10c/logs
wandb: ERROR Run 2gwsc10c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xlinjumv with config:
wandb: 	actor_learning_rate: 2.1192415468307916e-05
wandb: 	attention_dropout_p: 0.4423450568466878
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7899730163647599
wandb: 	temperature: 0.39095063310307543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044118-xlinjumv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlinjumv
wandb: uploading wandb-summary.json; uploading history steps 42-56, summary
wandb: uploading history steps 42-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▆▆█
wandb: best/eval_avg_mil_loss █▅▃▁▂▃▃
wandb:  best/eval_ensemble_f1 ▁▄▅▆▆▆█
wandb:            eval/avg_f1 ▄▇▃▆▅▆▄▅▁▂▇▄▆▆▅▆▄▄▆▅▇▇▃▇▅▄▃▂▅▅▇▃▅█▄▅▅▇▅▅
wandb:      eval/avg_mil_loss ▇▄▆▃▇▅▃▆▁▆▄▃▆▅▂▄▂▁▄▆▄▄▄▄▂▂▄▃▃▃▅▂▃▃▅▅█▄▃▅
wandb:       eval/ensemble_f1 ▄▇▃▆▄▁▆▄▅▁▇▄▆▅▅▄▄▆▅▅▇▃▅▇▅▄▃▂▅▅▅▇▄█▄▅▅▇▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▆▂▅▇▃▃▃▅▆▅█▆▇█▄▅▄▄▆▆▃▇▆▅▆▆▆█▅▄▆▁▅▅▆▅▃
wandb:      train/ensemble_f1 ▅▆▃▆█▂▇▇▃▃▇▅▆▅▇▇▄▇█▄▄▅▅▃▆▄▆▄▆▆▂▄▇▄▁▄▅▆▅▃
wandb:         train/mil_loss ▃▃▅▆▅▄▃▅▄▂▇▇▄█▇▅█▃▆▅▃▅▇▃▅▅▅▆▁▂▇▆▅▃▄▃▂▃▄█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████████▁████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83576
wandb: best/eval_avg_mil_loss 0.42866
wandb:  best/eval_ensemble_f1 0.83576
wandb:            eval/avg_f1 0.78719
wandb:      eval/avg_mil_loss 0.4975
wandb:       eval/ensemble_f1 0.78719
wandb:            test/avg_f1 0.7505
wandb:      test/avg_mil_loss 0.54696
wandb:       test/ensemble_f1 0.7505
wandb:           train/avg_f1 0.78044
wandb:      train/ensemble_f1 0.78044
wandb:         train/mil_loss 1.41207
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlinjumv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044118-xlinjumv/logs
wandb: Agent Starting Run: uozuohj4 with config:
wandb: 	actor_learning_rate: 1.4230951884895638e-05
wandb: 	attention_dropout_p: 0.18167511095552513
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8129969971537424
wandb: 	temperature: 6.903985313844121
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044225-uozuohj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uozuohj4
wandb: uploading history steps 159-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▇▇█
wandb: best/eval_avg_mil_loss ██▃▄▁
wandb:  best/eval_ensemble_f1 ▁▁▇▇█
wandb:            eval/avg_f1 ▄▅▅▆▅▂▄▆▇▄▆▆▄▄▄▅▆▆▆▅▆▅▅▁▃▅▃▅▃▃▆▄▄▃▅▃▃▄█▄
wandb:      eval/avg_mil_loss ▄▅▁▄▃▃▁▃▄▄▅▄▃▂▃▆▃▆▃▆▃▃▃▅▃▅▄▃▄▅▅▅█▇▅▇▆█▆▅
wandb:       eval/ensemble_f1 ▄▅▅▇▇▅▃▇▅█▇▇▆▇▄▅▆▆▆▅▅▄▇▅▅▃▅▅▃▅▅▂▆▄▅▃█▅▁▆
wandb:           train/avg_f1 ▅▇█▇▅▆▃▇▆▆▅▆▇▇▆▇█▇▇▇▅▆▃▇▃▅▃▅▆█▅▂▂▅▃▁▃▄▂▄
wandb:      train/ensemble_f1 ▅▂▇▇▅▃▂█▄▇▅▇▆▅▅▄▆▅▃▅▃▅▆▃▅▃▂▃▂▂▁▄▂▃▆▂▂▁▁▂
wandb:         train/mil_loss ▇▆▇▇█▇▇▆▄▆▇▆▅█▅▆▅▅▅▅▅▄▅▄▄▄▄▄▄▃▅▃▃▃▂▃▂▁▃▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▅▇▄▄▁▄▄▆▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▃▇▆▆▁▆▆█▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83928
wandb: best/eval_avg_mil_loss 0.38566
wandb:  best/eval_ensemble_f1 0.83928
wandb:            eval/avg_f1 0.80655
wandb:      eval/avg_mil_loss 0.49347
wandb:       eval/ensemble_f1 0.80655
wandb:           train/avg_f1 0.7787
wandb:      train/ensemble_f1 0.7787
wandb:         train/mil_loss 1.14561
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uozuohj4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044225-uozuohj4/logs
wandb: ERROR Run uozuohj4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4j7gc6tq with config:
wandb: 	actor_learning_rate: 0.0005674121974747992
wandb: 	attention_dropout_p: 0.39915425567705953
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3373957405566299
wandb: 	temperature: 8.279865348728677
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044556-4j7gc6tq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j7gc6tq
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 97-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▇█
wandb: best/eval_avg_mil_loss ▆█▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆▇█
wandb:            eval/avg_f1 ▃▃▄▄▆▆▃▇▆▄▇▁▄▇▇▇▇▃▆▄▇▅▄▆▇▅▄█▆▆▅▆▆▄▄▂▇▅▅▆
wandb:      eval/avg_mil_loss ▆▄▄▄▅▆▄▅▅▆▂▄▅▆▃▄▁▄▅▅▅▃▄▅▃▆▇▄▄█▄▅▄▃█▅▃▃▄▄
wandb:       eval/ensemble_f1 ▃▃▃▇▆▄▃▆▄▄▄▆▄▃▆▄▄▄█▇▅█▄▃▄▄▄▅▆█▆▄▄▆▁▆▅▂▆▅
wandb:           train/avg_f1 ▄▃▃▄▃▇▄▄▂▄▇▃▆▆▆▃▆▆▇▁▅▄▅█▂▄▄▅▆▆▇▅▃▅▆▃▃▄▄▂
wandb:      train/ensemble_f1 ▆▇▁▇▄▅▃▄▅▄▅▆▇▄▄▅▃▇█▄▂▅▆▄▇▃▄▅▅▄▆▇▅▅▄▅▄▃▅▇
wandb:         train/mil_loss █▇▅▅▆▅▃▃█▄▃▅▄▅▄▅▄▄▃▅▃▄▂▂▂▂▃▂▁▄▃▁▃▆▁▂▂▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▆▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▅▁█▅▅▁▅▁▁▅▁█▁▅▅█▅▅██▁▅▁▅▅█▅█▁██▁▅▅▁▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83527
wandb: best/eval_avg_mil_loss 0.4176
wandb:  best/eval_ensemble_f1 0.83527
wandb:            eval/avg_f1 0.79925
wandb:      eval/avg_mil_loss 0.40256
wandb:       eval/ensemble_f1 0.79925
wandb:           train/avg_f1 0.78514
wandb:      train/ensemble_f1 0.78514
wandb:         train/mil_loss 1.08143
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j7gc6tq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044556-4j7gc6tq/logs
wandb: ERROR Run 4j7gc6tq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qmte5e3b with config:
wandb: 	actor_learning_rate: 1.6476149639706414e-05
wandb: 	attention_dropout_p: 0.21571507646635468
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6192132837555727
wandb: 	temperature: 1.8470796462715833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044755-qmte5e3b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmte5e3b
wandb: uploading history steps 123-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅▆█
wandb: best/eval_avg_mil_loss █▆▅▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅▆█
wandb:            eval/avg_f1 ▄▆▂▆▇▁▄▃▆▃▅▅█▅▆▆▃▇▅▂▅▄▃▄▃▅▄▆▁▅▄▅█▅▆▂▅▄▇▃
wandb:      eval/avg_mil_loss ▅▄▆▃▃▃▄▁▅▂▇▅▁▃▆▅▃▄▄▅▃▂▃▅▃▅▅▆▄▃▆▄▃▅▂▇▅▆██
wandb:       eval/ensemble_f1 ▆▅▅▇▇▆▆▃▅▃▅▅▆▅▅▄▅▅▃▇▅█▅▂▄▂▄▄▆▅▁▇▅▇▆▆▅▅█▅
wandb:           train/avg_f1 █▄▅▆▂▃▄▆▆▅▄▇▅▅▅▄▅▆▅▄▅▆▆▂▂▃▅▃▅▅▅▂▁▅█▅▆▅▂▅
wandb:      train/ensemble_f1 █▄▅▅▇▅▆▆▆▅▆▃▄▅▄▆▄▄▄▃▆▆▂▂▄▂▄▃▃▆▁▄▁▃▃▄▄▄▄▃
wandb:         train/mil_loss ▇▆▇▆█▆▅▅▇▆▅▅▄▄▅▃▃▅▃▄▃▄▃▃▅▂▄▃▃▄▂▃▄▂▂▂▂▁▃▂
wandb:      train/policy_loss ▂▂▂▂▂▅▆▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▂▂█▂▂▂▂▂▂▂▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86321
wandb: best/eval_avg_mil_loss 0.35817
wandb:  best/eval_ensemble_f1 0.86321
wandb:            eval/avg_f1 0.79195
wandb:      eval/avg_mil_loss 0.44188
wandb:       eval/ensemble_f1 0.79195
wandb:           train/avg_f1 0.8153
wandb:      train/ensemble_f1 0.8153
wandb:         train/mil_loss 1.75461
wandb:      train/policy_loss -0.31494
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.31494
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmte5e3b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044755-qmte5e3b/logs
wandb: ERROR Run qmte5e3b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l11m0awy with config:
wandb: 	actor_learning_rate: 8.681190089133098e-05
wandb: 	attention_dropout_p: 0.3634625521789081
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7071249455443787
wandb: 	temperature: 5.5675804812394425
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045040-l11m0awy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l11m0awy
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆█
wandb: best/eval_avg_mil_loss █▁▇▅▁
wandb:  best/eval_ensemble_f1 ▁▅▅▆█
wandb:            eval/avg_f1 ▇▅▃▆▇▃▄▁▅▇▅█▃▄▇▆▆▇▆▄▅▄█▃▆▆▇▆▇▆▇▅▅▅▅▄▆▆▄▇
wandb:      eval/avg_mil_loss ▅▅▅▇▆▄▇▇▃▃▆▅▅▇▅▁▆▃▄▄▅▆▄▅▅▆▅▄▇▄▅▅▁▆▆▄▂▅▆█
wandb:       eval/ensemble_f1 ▄▅▆▆▅▃▃▆▁▄▁█▃▆▃▅▄▅▄▂▅▆▆▂▃▅▁▅▂▇▃▄▆▆▃▂▂▅▃▅
wandb:           train/avg_f1 ▃▆▄▆▄█▆▇▄▅▅▅▅▃▇▄▅▃▄▅▄▃▄█▄▄▃▆▇▅▄▁▇▄▇▃▅▅▇▃
wandb:      train/ensemble_f1 ▃▆▄▅▅▇▆▄▅█▅▅▃▄▆▂▆▇▆▇▆▄▄▄▄▆▅▅▆▅▅▁▁▇▆▆▅▅▃▃
wandb:         train/mil_loss █▇▆▆▇▂▃▅▄▄▄▄▄▄▄▅▃▃▄▃▄▃▃▃▃▂▁▃▃▁▁▂▄▃▄▃▃▄▂▂
wandb:      train/policy_loss ▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄█▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▆██▁█████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.3725
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.79473
wandb:      eval/avg_mil_loss 0.43238
wandb:       eval/ensemble_f1 0.79473
wandb:           train/avg_f1 0.80181
wandb:      train/ensemble_f1 0.80181
wandb:         train/mil_loss 1.70462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l11m0awy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045040-l11m0awy/logs
wandb: ERROR Run l11m0awy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: izqf8j60 with config:
wandb: 	actor_learning_rate: 0.0004934072574221506
wandb: 	attention_dropout_p: 0.21619109962884497
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5142093750448099
wandb: 	temperature: 6.292056142840586
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045305-izqf8j60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izqf8j60
wandb: uploading history steps 109-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 █▄▄▆▃▄▅▆▃▅▅▂▂▆▅▄█▄▂▃▇▂▆▆▃▇▂█▇█▇▅▃▁▄▇▆▂▄▆
wandb:      eval/avg_mil_loss ▅▃▄▂▃▅▄▅▂▂█▄▂▅▃▅▃▂▄▁▃▄▂▇▄▂▂▂▂▅▄▅▃▄▃▄▅▄▃▂
wandb:       eval/ensemble_f1 ▇▆▄▆▃▇▆█▃▁▆▄▅▅▅▁▅▇▅▂▆▁▃▃▇▂▅██▅▄▂▃▃▅▇▃▃█▄
wandb:           train/avg_f1 ▂▃▃▄▃▃▂█▅▄▇▄▃▅▂▁▂▁▅▃▁▃▂▇▆▃▄▄▅▃▃▇▆▄▅▃▅▄▁▃
wandb:      train/ensemble_f1 ▄▆▅▅▃▅▃▃▇▆▅▄▅█▆▅▄▅▄▅▆▃▅▆▅▇▅▄▄█▄▆▄▁▆▃▆▆▃▆
wandb:         train/mil_loss █▆▇▆▆▄▄▆▅▆▆▄▅▄▄▄▃▃▃▃▂▃▃▂▂▃▂▃▂▂▁▂▂▁▁▂▂▁▁▁
wandb:      train/policy_loss ▆▆▆▆▆▄▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆█▆▆▆▆▆▆▁▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▁▄▄▄▄█▃▄▄▄▄▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82845
wandb: best/eval_avg_mil_loss 0.41242
wandb:  best/eval_ensemble_f1 0.82845
wandb:            eval/avg_f1 0.79175
wandb:      eval/avg_mil_loss 0.38571
wandb:       eval/ensemble_f1 0.79175
wandb:           train/avg_f1 0.78762
wandb:      train/ensemble_f1 0.78762
wandb:         train/mil_loss 0.98824
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izqf8j60
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045305-izqf8j60/logs
wandb: ERROR Run izqf8j60 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o183cqnj with config:
wandb: 	actor_learning_rate: 2.1292500715315783e-06
wandb: 	attention_dropout_p: 0.4832919598867592
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 78
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30014449182172764
wandb: 	temperature: 7.854916982974823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045524-o183cqnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o183cqnj
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss █▁▆▅
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▆█▆▇▄▁▁▃▃▅▅▄▄▂▃▄▄▂▄▆▄▁▆▄▄▅▃▅▃▄▅▄▄▇▂▅▃▂▄▄
wandb:      eval/avg_mil_loss ▅▂▅▃▄▇▆▄▄▃▂▃█▆▄▅▄▃▆▅▆▆▁▄▅▅▅▄▄▅▃▅▅▅▄▅▁▄▂▆
wandb:       eval/ensemble_f1 ▂▄█▆▇▄▄▅▆▆▄▃▄▅█▃▅▅▄▆█▂▆▆▄▅▃▄▅▃▆▅▁▄▃▅▃▇▄▄
wandb:           train/avg_f1 ▅▄▅▅▅▆▅▄▁▅▆▄▃▇▃▄▂▃▇▃▆▄▄▆▅█▄▃▁▆▄▃▆▃▆▅▃▄█▇
wandb:      train/ensemble_f1 ▅▅▆▅▆▄▁▅▄▅▇▅▄▃▃▃▂▄▇▃▆▄▄▂▂▅▅█▄▄▃▆▁▆▄▅▆▃▅▄
wandb:         train/mil_loss █▇██▇▇▇▇▆▆▇▇▆▆▆▅▆▅▅▅▄▅▄▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▁
wandb:      train/policy_loss ▆█▆▆▆▆█▆▆▆▆▆█▆▆▆▄▆▄▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▄▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆▆▆▅▆▆▆█▆▇▆▆▆▆█▆▆▆▄▄▆▆▆▆▆▁▆▆▆▆█▆▆▆▆▆▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82828
wandb: best/eval_avg_mil_loss 0.4767
wandb:  best/eval_ensemble_f1 0.82828
wandb:            eval/avg_f1 0.7755
wandb:      eval/avg_mil_loss 0.43789
wandb:       eval/ensemble_f1 0.7755
wandb:           train/avg_f1 0.79618
wandb:      train/ensemble_f1 0.79618
wandb:         train/mil_loss 1.19133
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o183cqnj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045524-o183cqnj/logs
wandb: ERROR Run o183cqnj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: utxe9hvq with config:
wandb: 	actor_learning_rate: 1.3106081114234778e-05
wandb: 	attention_dropout_p: 0.4178199318688035
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3575912903923837
wandb: 	temperature: 0.18237262447617145
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045656-utxe9hvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utxe9hvq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄█
wandb: best/eval_avg_mil_loss ▇▆█▁
wandb:  best/eval_ensemble_f1 ▁▂▄█
wandb:            eval/avg_f1 ▄▅▆▃▄▅▄▆█▃▁▂▆▂▆▁▃▅▄▅▅▄▁▁▃▆▂▂▂▆▃▃▅▅▅▄▅▆▄▅
wandb:      eval/avg_mil_loss ▄▃▅▆▄▃▅▃▄▁▃▄▁▆▄▇█▄▄▃▅▅▄▄▅▅▆▅▃▄▇▅▄▄▃▃▃▆▄▂
wandb:       eval/ensemble_f1 ▆▇█▇▄▅█▇▅█▆▂█▂█▁▄▆▆▇▆▅▁▁▄█▂▂▃▇▆▇▇▄▄▇██▅▆
wandb:           train/avg_f1 █▄▃▇▄▅▄▆▆▃▃▅▅▄▅▄▃▅▅▆▅▆▅▃▆▆▆▄▇▅▂▆▂▇▄▁▇▅▇▆
wandb:      train/ensemble_f1 █▄▇▄▄▄▆▆▃▆▅▅▄▄▅▄▄▃▅▅▅▅▆▅▃▄▄▆▇▅▂▆▂▇▄▁▇▅▃▆
wandb:         train/mil_loss ▄▄▇▅▅▅▆█▆▅▅▄▆▆▅▃▆█▃▅▄▄▄▁▅▂▅▂▃▂▁▂▂▄▂▃▂▁▂▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▅▆▅▆▆█▆▆▆▆▆▆▆▄▆▆▆▆▆▁▆▃▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▅▆▆██▆▆▆▆▆▆▆▄▆▆▆▆▆▁▆▃▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86343
wandb: best/eval_avg_mil_loss 0.34053
wandb:  best/eval_ensemble_f1 0.86343
wandb:            eval/avg_f1 0.82703
wandb:      eval/avg_mil_loss 0.35768
wandb:       eval/ensemble_f1 0.82703
wandb:           train/avg_f1 0.83104
wandb:      train/ensemble_f1 0.83104
wandb:         train/mil_loss 1.79816
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utxe9hvq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045656-utxe9hvq/logs
wandb: ERROR Run utxe9hvq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tacm7a58 with config:
wandb: 	actor_learning_rate: 2.48268194536367e-05
wandb: 	attention_dropout_p: 0.4721152162619828
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35352565907616285
wandb: 	temperature: 1.2998692428398106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045809-tacm7a58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tacm7a58
wandb: uploading wandb-summary.json
wandb: uploading history steps 122-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▇██
wandb: best/eval_avg_mil_loss ▇▃▅█▆▁
wandb:  best/eval_ensemble_f1 ▁▃▅▇██
wandb:            eval/avg_f1 ▂▅▆▂█▅▄▄▁▅▃▃▂▅▁▄▆▅▄▄▄▆▁▄▃▆▂▇▄▆▂▇▅▅▂▅▇▅▅▄
wandb:      eval/avg_mil_loss ▂▅▃▃▃▄█▅▃▆▅▆▃█▄▆▁▆▆▂▂▅▂▄▅▇▃▂▃▅▇▃▄▁▁▃▃▄▅▄
wandb:       eval/ensemble_f1 ▆▆▇▇▇▆▁▅▃▆▃▆▄▆▄▅▄▆▅▅▃▃▅▇▇▅▇▂█▂█▅▇▅▆▇▄▅▆▆
wandb:           train/avg_f1 ▆▄█▆▆▆▅▁▇▆▇▇▆▄▆▅▆▅█▅▅▅▆▄▆▅█▆▅▇▇▄▆▇▆▅▆▆▇▅
wandb:      train/ensemble_f1 ▅▅▄▆▄▄▄▄▅▄▄▅▅▅▆▄▆▄▄▅▅▁▇▅▃▃▆▅▆▃▇▆▃▆█▃▇▃█▆
wandb:         train/mil_loss ▇▅█▅▅▇▆▅█▅▃▇▅▅▆▆▄▆▆▆▅▆█▄▄▆█▆▅▄▆▅▂▃▅▄▄▁▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.38194
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.79473
wandb:      eval/avg_mil_loss 0.4642
wandb:       eval/ensemble_f1 0.79473
wandb:           train/avg_f1 0.78495
wandb:      train/ensemble_f1 0.78495
wandb:         train/mil_loss 1.03639
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tacm7a58
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045809-tacm7a58/logs
wandb: ERROR Run tacm7a58 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9itywaos with config:
wandb: 	actor_learning_rate: 3.3039393093095394e-05
wandb: 	attention_dropout_p: 0.19466859978668
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25613052705876027
wandb: 	temperature: 3.915733822073123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050038-9itywaos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9itywaos
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇▇█
wandb: best/eval_avg_mil_loss ▆█▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▇▇█
wandb:            eval/avg_f1 ▄▇▅▄▅▄▅▄▄▂▆▇▄█▇▅▂▃▂▄▆▃▆▃▂▃▁▄▄▄▄▄▇▅▂▃▃▅▃▄
wandb:      eval/avg_mil_loss ▄▄▃▁▃▆▃▅▄▅▅▅▇▄▃▅▆▅▆▅▃▃▆▆▃▂▄▃▄▅▄▇▇▄█▆▇▆▄█
wandb:       eval/ensemble_f1 ██▅▆▄▇▅▄█▁▄▄▅▂▁▄▇▄▇▆▇▂▃▃▆▄▆█▅▂▄▅▃▄▂▄▄▂▂▅
wandb:           train/avg_f1 ▆▆▇▇█▆▅▅▆▅▆▇▆▆▆▆▄▄▆▄▆▅▅▅▃▅█▄▇▆▆▁▇▆▁▂▁▃▄▃
wandb:      train/ensemble_f1 ▆█▆▆▇▆▆▅▆▆█▇▆▆▆▆▇▅▆▇▅▆▅▅▄▅▅▄▆▇▆▅▄▄▅▂▃▁▃▅
wandb:         train/mil_loss ▇▇█▇▄▆▆▅▆▅▄▅▆▅▄▇▅▅▄▃▄▅▄▄▃▄▅▂▃▂▄▁▂▁▃▃▃▃▂▁
wandb:      train/policy_loss ▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▁▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▁▆▆▆▅▆▆▆▆█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84231
wandb: best/eval_avg_mil_loss 0.40582
wandb:  best/eval_ensemble_f1 0.84231
wandb:            eval/avg_f1 0.7874
wandb:      eval/avg_mil_loss 0.5079
wandb:       eval/ensemble_f1 0.7874
wandb:           train/avg_f1 0.77509
wandb:      train/ensemble_f1 0.77509
wandb:         train/mil_loss 1.43305
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9itywaos
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050038-9itywaos/logs
wandb: ERROR Run 9itywaos errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: uvyz6hzg with config:
wandb: 	actor_learning_rate: 9.398293186437386e-05
wandb: 	attention_dropout_p: 0.49643982910026246
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6996391789410122
wandb: 	temperature: 0.5599543515548333
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050329-uvyz6hzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvyz6hzg
wandb: uploading history steps 85-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▃█▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▅▅▄▂▅▂▄▄▆▂▂▃▅▅▂▄▄▆█▃▁▅▅▅▆▂▁▇▄▄▃▄▂▃▃▅▃▅█▂
wandb:      eval/avg_mil_loss ▅▅▄▃▂▂▅▄▃▃▆▄▄▆▆▅▄▄▆▄▄▁▅▄█▅▆▃▂▇▅▄▇▆▇▃▃▂▆▅
wandb:       eval/ensemble_f1 ▆▇▅▅▅▅▄▆▅▅▆▄▄▇▇▄▅▃▄▄▄▂▄▆▅▂▇▄▃▁▅▃▃▂▂▃▆▃█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▂▅▆▅▄▃▇▄▆▅▆▇▆▅▄▄▆▄▂▅▇▅▆▅▃▆▅▄▆▁▆▆▅▃▅█▅█
wandb:      train/ensemble_f1 ▄▂▅▆▁▆█▄▂▃▄▂▆▄▄▃▅▃▄▃▅▄▁▄▂▃▃▂▄▇▄▃▃▅▅▄▃▂▄▄
wandb:         train/mil_loss ▇███▇▆▆▆▆▆▅▆▅▅▄▅▅▄▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁
wandb:      train/policy_loss ▇▇▇▇█▇▁▇▇▄▇▇▇▇▄▄▇▇▆▇▇▇▅▇▅▇▇▄▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆█▆▁▆▁▆▆▆▆▆▆▆▆▄▆▆▃▆▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.42316
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.75579
wandb:      eval/avg_mil_loss 0.48431
wandb:       eval/ensemble_f1 0.75579
wandb:            test/avg_f1 0.73312
wandb:      test/avg_mil_loss 0.50998
wandb:       test/ensemble_f1 0.73312
wandb:           train/avg_f1 0.79542
wandb:      train/ensemble_f1 0.79542
wandb:         train/mil_loss 0.7541
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvyz6hzg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050329-uvyz6hzg/logs
wandb: Agent Starting Run: kulijblm with config:
wandb: 	actor_learning_rate: 0.0005078759080245426
wandb: 	attention_dropout_p: 0.2340970435287769
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48601359582334314
wandb: 	temperature: 3.409077305870728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050532-kulijblm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kulijblm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▅██▆▆▄▅▃▂█▇▄▅▄▇▆█▇▇▇▆▆▃█▅▅▅▄▅▅▄▅▃▃▄▁▂▃▂▄
wandb:      eval/avg_mil_loss ▃▂▃▃▂▄▆▄▆▆▇▄▃▅▂▁▄▆▃▂▄▇▆▅▁▂▆▇▄▆▅▆▇▅▄█▇▄▇▃
wandb:       eval/ensemble_f1 █▅▄▄█▄▅▇▅▄▇▆▇▆▇▅▆▃▅▇▃▅▇▇▄▅▂▄▃▄▂▂▃▄▃▃▁▂▁▂
wandb:           train/avg_f1 ▇▆▇▅▇█▆█▆▆▆▅▇▆▄▅▅▇▄▂▄▄▄▅▅▅▃▂▄▃▄▅▆▂▁▄▂▄▄▃
wandb:      train/ensemble_f1 ▆▅▂▅█▄▅▃▇▄▅▅▅▆▄▄▂▄▃▂▄▄▅▅▂▁▂▅▃▄▄▁▅▃▃▃▃▁▂▄
wandb:         train/mil_loss ██▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb:      train/policy_loss ▃▃▃▃▂▂▃▃▃▃▃▁▃▃▃▃▃▂█▃▅▃▁▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82436
wandb: best/eval_avg_mil_loss 0.41687
wandb:  best/eval_ensemble_f1 0.82436
wandb:            eval/avg_f1 0.7787
wandb:      eval/avg_mil_loss 0.4575
wandb:       eval/ensemble_f1 0.7787
wandb:           train/avg_f1 0.76572
wandb:      train/ensemble_f1 0.76572
wandb:         train/mil_loss 0.77265
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kulijblm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050532-kulijblm/logs
wandb: ERROR Run kulijblm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: h2i9ax8t with config:
wandb: 	actor_learning_rate: 0.0006237346821547655
wandb: 	attention_dropout_p: 0.3975625285548117
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2666485270964736
wandb: 	temperature: 4.721765400190035
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050806-h2i9ax8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2i9ax8t
wandb: uploading wandb-summary.json
wandb: uploading history steps 123-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄▅▇█
wandb: best/eval_avg_mil_loss █▇▂▄▂▁▃
wandb:  best/eval_ensemble_f1 ▁▃▄▄▅▇█
wandb:            eval/avg_f1 ▅▆▄▄▂█▂▅▆▆▃▅▃▇▃▄▅▃▄▄▅▅▃▅▄▆▆▅▄▅▂▆▄▅▅▇▁▂▅█
wandb:      eval/avg_mil_loss ▅▄▅▃▃▂▅▅▅▂▆▄▂▂▂█▁▁▄▃▅▄▂▃▅▁▂▂▃▅▇█▃▃▂▅▂▇▄▆
wandb:       eval/ensemble_f1 ▄▇▂▇█▆▇▄▅▃█▆▆▇▂▅▄▄▅▆▅▆▆▃▅▅▆▄▄▂▃▄▅▅▄▇▁▃▅▅
wandb:           train/avg_f1 ▆▆▆▅█▄▆▆▄▅▅▄▄▅▆▅▄▅▇▄▆▄▄▂▅▄▃▃▃▃▄▂▄▂▄▄▄▁▄▁
wandb:      train/ensemble_f1 ▆▄▅▆▆▃▅█▇▆▆▆▃▄▃▅▅▅▃▇▃▄▃▃▅▆▂▂▃▄▃▂▁▃▄▃▄▂▁▂
wandb:         train/mil_loss ▇▇▆▇▇▇▆▅█▆▆▅█▅▅▆▆▅▆▅▅▅▆▃▄▄▄▄▄▅▄▅▃▄▄▄▂▅▁▁
wandb:      train/policy_loss ▃▃▆▁▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▄▄█▅▃▄▄▄▄▄▄▂▆▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.40691
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.78444
wandb:      eval/avg_mil_loss 0.50539
wandb:       eval/ensemble_f1 0.78444
wandb:           train/avg_f1 0.78071
wandb:      train/ensemble_f1 0.78071
wandb:         train/mil_loss 1.42122
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2i9ax8t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050806-h2i9ax8t/logs
wandb: ERROR Run h2i9ax8t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: orw5l0i0 with config:
wandb: 	actor_learning_rate: 0.0007000308772189964
wandb: 	attention_dropout_p: 0.1819238706457177
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17492070860524034
wandb: 	temperature: 4.57485109422596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051042-orw5l0i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orw5l0i0
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 133-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▆▇█
wandb: best/eval_avg_mil_loss ▅▇█▃▁▅▄
wandb:  best/eval_ensemble_f1 ▁▃▄▆▆▇█
wandb:            eval/avg_f1 ▄▄▃▅▅▃▆▆▇▆▂█▆▅▆▆▇▆█▆▅▁▄▇▃▃▅▅▅▅▄▃▇▆▁▇▂▄▇▇
wandb:      eval/avg_mil_loss ▇▁█▄▆▅▄▄▄▇▅▃▅▅▁▇▅▆█▆▅▆▅▆▄▆▅▅▄▆▆▄▅█▁▃▃█▄▃
wandb:       eval/ensemble_f1 ▂▆▃█▆█▇▅▆▇▅▇▇▇▆▂▇▄▃▇▅▃▁▄▅▅▆▄▆▄▅▆▃▅▄▃▇▄▇▂
wandb:           train/avg_f1 ▅▆▂▆▁▆▃▃▃▇▃█▆▆▂▆▆▇▁▇▄▇▃▄▁▂█▄▇▆▂▂▅▅▆▅▃▅▆▃
wandb:      train/ensemble_f1 ▄▅▂▆▅▄▅▄▄█▆▆▃▆▂▄▆▁▆▃▇▇▇▂▄▁▄▄▆▅▃▅▄▄▄▂▃▄█▅
wandb:         train/mil_loss ▇▇█▇█▆▅▆▆▅▅▅▅▆▄▄▄▄▄▄▄▄▄▃▄▃▄▃▃▃▃▂▃▂▃▃▃▂▂▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆█▆▆▆▃▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▄█████████▁███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85352
wandb: best/eval_avg_mil_loss 0.41633
wandb:  best/eval_ensemble_f1 0.85352
wandb:            eval/avg_f1 0.79346
wandb:      eval/avg_mil_loss 0.46806
wandb:       eval/ensemble_f1 0.79346
wandb:           train/avg_f1 0.79981
wandb:      train/ensemble_f1 0.79981
wandb:         train/mil_loss 1.18296
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orw5l0i0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051042-orw5l0i0/logs
wandb: ERROR Run orw5l0i0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: f3d6ugtd with config:
wandb: 	actor_learning_rate: 6.1774795764693725e-06
wandb: 	attention_dropout_p: 0.3095722012357359
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4379535465140952
wandb: 	temperature: 7.813071390806028
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051321-f3d6ugtd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f3d6ugtd
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄██
wandb: best/eval_avg_mil_loss █▄▅▆▁
wandb:  best/eval_ensemble_f1 ▁▁▄██
wandb:            eval/avg_f1 ▂▅▃▆▇▇▄▄▄▄▂▅▅▅▂▂▅▃▄█▃▄▄▄▄▃▄▅▂▅▃▅▇▄▂▄▄▁▅▂
wandb:      eval/avg_mil_loss ▅▃▃▃▁▄▃▄▂▃▄▃▃▅▄▅▄▅▁▅▄▄▄▃█▆▇▇▆▅▅▃▅▆▆▆▆▄▆▅
wandb:       eval/ensemble_f1 ▃▆▅▅▆▇▂▄▃▇▅▃▂▅▆▃▅▆▆█▄▅▂▄▄▄▅▂▂▁▃▇▄▆▅▂▂▄▁▃
wandb:           train/avg_f1 █▆▅▇▆▇█▇▅▇▆▆▇▇▄▇▆▆▅▆▆▆▄▅▇▆▆▆▆▃▃▆▅▆▅▅▁▅▃▄
wandb:      train/ensemble_f1 ▅█▅█▅▇█▆▇▇▆█▆▇▇▅▇▅▇▇▅█▆▆▅▆▄▆▆▃▇▆▃▆▆▁▅▃▆▅
wandb:         train/mil_loss █▆▅▆▇▆▄▅▆▄▅▅▄▃▃▃▃▃▂▃▃▂▃▁▃▂▁▁▂▂▁▂▁▁▂▂▁▁▁▂
wandb:      train/policy_loss ▅▅▅▁▅▅▆▆▅▅▅▅▅█▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▃▃▃▃▃▃▃▃▃▃▆▃▃▃▅▃▃▃▃▃▃█▃▃▃▃▃▆▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83211
wandb: best/eval_avg_mil_loss 0.41276
wandb:  best/eval_ensemble_f1 0.83211
wandb:            eval/avg_f1 0.77723
wandb:      eval/avg_mil_loss 0.49615
wandb:       eval/ensemble_f1 0.77723
wandb:           train/avg_f1 0.77657
wandb:      train/ensemble_f1 0.77657
wandb:         train/mil_loss 0.50375
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f3d6ugtd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051321-f3d6ugtd/logs
wandb: ERROR Run f3d6ugtd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nyzickbc with config:
wandb: 	actor_learning_rate: 2.7942498010978547e-05
wandb: 	attention_dropout_p: 0.4413858557618587
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7333733056742485
wandb: 	temperature: 5.178086249363071
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051703-nyzickbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyzickbc
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss ▇▄▃█▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▂▁▆▇▄▅▅▅▆▄▃▇█▂▄▇▇▂▄▅▅▄▆▅▄▆▄▅▄▅▄██▅▅▄▂▆▆▆
wandb:      eval/avg_mil_loss ▂▆▂▂▃▅▄▂▄▄▃▁█▃▅▃▃▂▄▄▁▃▇▄▃▂▄▄▄▂▂▄▃▄▄▄▄▄▆▄
wandb:       eval/ensemble_f1 ▂▇██▅█▆▃▇▂▆▆▃▆▆▃▆▅▇▇▆▄▅▅▅▃▄▅▅▆▆▅▄▆▆▆▆▄█▁
wandb:           train/avg_f1 ▆▆█▇▆█▆▆▇▅▇▇▅▇▆▆▆▄▇▅▅▆▅▆▆▆▇█▄▆▃▇▇▆▄▇▅▄▄▁
wandb:      train/ensemble_f1 ▇▆█▆▆▇▅▆▄▆▆▅▅█▄▆▆▅▅▄▅▅▆▆▇▅█▇▆▃▆▄▄▄▇▃▇▄▄▁
wandb:         train/mil_loss █▇▆▆▆▄▄▆▄▅▅▄▄▄▄▃▂▄▂▃▃▃▂▂▂▄▂▃▁▃▂▁▃▃▁▂▁▁▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85698
wandb: best/eval_avg_mil_loss 0.37283
wandb:  best/eval_ensemble_f1 0.85698
wandb:            eval/avg_f1 0.78101
wandb:      eval/avg_mil_loss 0.47833
wandb:       eval/ensemble_f1 0.78101
wandb:           train/avg_f1 0.78806
wandb:      train/ensemble_f1 0.78806
wandb:         train/mil_loss 1.36223
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyzickbc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051703-nyzickbc/logs
wandb: ERROR Run nyzickbc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pk5ki4t8 with config:
wandb: 	actor_learning_rate: 1.7809623315757438e-06
wandb: 	attention_dropout_p: 0.44765328790514697
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2882993297541584
wandb: 	temperature: 0.782108023642224
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051954-pk5ki4t8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pk5ki4t8
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss █▄▁▂▂
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▅▆▃▃▇▄▁▆▆▁▂▃▆▅▃▄▆▅▃▅▅▃▄▅▄▄▄▄▄▆▆▆▇▆▃█▅▅▃▅
wandb:      eval/avg_mil_loss ▅▅█▄▆▇▆▂▅▁▂█▂▄▅▃▂▆▆▅▅▃▆▇▅▃▅▃▂▁▅▂▂▃▅▇▆▂▇▃
wandb:       eval/ensemble_f1 ▇▃▄▅▁▇▆▂▃▄▃▅█▅▅▆▃▅▄▆▂▆▁▃▄▄▇▇▆▆██▄▆▄█▄▅▆▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▄▆▂▁▅▄▄▅▅▄█▃▃▃▃▇▂▄▅█▄▁▄▆▆▄▄▅▄▆▄▄▅▅▁▅▄
wandb:      train/ensemble_f1 ▅▅▄▄▅▅▅▂▃▃▄▄█▂▆█▅▃▂▂▅▅▄▆▄▄▄▄▃▂▄▂▁▃▅▅▄▅▅▆
wandb:         train/mil_loss ▇▇█▆▇▆▆▃█▆▇▆▅▄▆▆▅▆▃▄▅▄▃▃▄▃▄▂▄▄▄▃▁▂▃▂▃▁▃▁
wandb:      train/policy_loss █████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁███████▃████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.43733
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.76938
wandb:      eval/avg_mil_loss 0.46507
wandb:       eval/ensemble_f1 0.76938
wandb:            test/avg_f1 0.75536
wandb:      test/avg_mil_loss 0.51682
wandb:       test/ensemble_f1 0.75536
wandb:           train/avg_f1 0.7964
wandb:      train/ensemble_f1 0.7964
wandb:         train/mil_loss 0.89176
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pk5ki4t8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051954-pk5ki4t8/logs
wandb: Agent Starting Run: r4cjgtj0 with config:
wandb: 	actor_learning_rate: 0.0002688124919462178
wandb: 	attention_dropout_p: 0.49976410979864944
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7791799696311482
wandb: 	temperature: 5.687364908819892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052220-r4cjgtj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4cjgtj0
wandb: uploading history steps 96-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅▇█
wandb: best/eval_avg_mil_loss ██▇▇▄▁
wandb:  best/eval_ensemble_f1 ▁▄▅▅▇█
wandb:            eval/avg_f1 ▆▃▆▄▆▄▄▄▃▆▃▆▅▄▄▆▆▅▅▄▄▃▁▄▅▂▆▇▃▆▆▄█▄▇▃█▅▇▄
wandb:      eval/avg_mil_loss ▄▄▅▄▁▇▄▂▄▄▂▄▂▅▄▂▇▃▃▂▆▆▃▅▆▄▄▅▂█▁▅▂▄▂▃▆▅▁▄
wandb:       eval/ensemble_f1 ▆▄▅▄▃▂▆▂▆▅▇▅█▄▃▅▁▆▅▅▄▄▂▆▄█▅▅▅▅▆▃▆▁▆▅█▇▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▁▄▃▅▂▃▂▁▄▄▆▃▅▅▆▁▃▄▂▄▃▁▇▃▂▃▆▄▂▄█▅▇▆▅▄▂▅
wandb:      train/ensemble_f1 ▃▄▇▅▄▅▃▅▅▃▄▄▇▂▃▃▃▃▅▄▂▄▁▃▆▄▄▅▆▄▅▄▅▇▅▄▇▅█▅
wandb:         train/mil_loss ▇██▆▅▆▆▆▇▅▅▄▆▄▆▄▄▄▄▃▄▄▅▃▃▄▃▃▂▂▃▁▂▂▂▂▁▁▃▂
wandb:      train/policy_loss ▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃█▃▁▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81367
wandb: best/eval_avg_mil_loss 0.4433
wandb:  best/eval_ensemble_f1 0.81367
wandb:            eval/avg_f1 0.79509
wandb:      eval/avg_mil_loss 0.50642
wandb:       eval/ensemble_f1 0.79509
wandb:            test/avg_f1 0.77098
wandb:      test/avg_mil_loss 0.51922
wandb:       test/ensemble_f1 0.77098
wandb:           train/avg_f1 0.78497
wandb:      train/ensemble_f1 0.78497
wandb:         train/mil_loss 0.98319
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4cjgtj0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052220-r4cjgtj0/logs
wandb: Agent Starting Run: 9ywu2odz with config:
wandb: 	actor_learning_rate: 0.00020707143941932015
wandb: 	attention_dropout_p: 0.17932348702375128
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5752084088589063
wandb: 	temperature: 2.637764890679024
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052429-9ywu2odz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ywu2odz
wandb: uploading history steps 96-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▄▅▅█
wandb: best/eval_avg_mil_loss █▅▅▇▄▅▁
wandb:  best/eval_ensemble_f1 ▁▄▄▄▅▅█
wandb:            eval/avg_f1 ▃▃▇▃▄▇█▅▃▄▁▇▃▃▇▅▆▆▅▂▇▅▇▄▆▅▇▄▆▆▆█▇▄▆▄█▃▇▆
wandb:      eval/avg_mil_loss ▆▄▆▄▆▅▆▆▆▆▆█▅▆▅▆█▄▅▅▃▄▃▇▅▄▅▅▆▃▄▅▆▅▁▅▅▄▆▅
wandb:       eval/ensemble_f1 ▂▄▃▃▄▃▃▃▁▄▄▅▂▃▃▃▄▃▂▄▃▄▄▅▃▄▄▃▄▄▅▅▂▃█▄▃▃▃▃
wandb:           train/avg_f1 ▃▇▃▁▃▅▃▅▂▆▄▄▄▂▆▆▂▆▆▄▆█▅▂▆▂▆▄▂▆▅▅▆█▄▄▇▅▅▇
wandb:      train/ensemble_f1 ▃▁▅▃▃▄▂▄▃▃▄▆▄▆▂▄▆█▆▅▄▆▆▆▅▄▄▆▅▄▆▃▄▆▆▄▄▄▅▆
wandb:         train/mil_loss ██▇▇██▆█▆▇▆▄▇▅▃▅▅▄▇▄▆▅▃▅▄▂▅▄▄▃▂▄▂▃▃▁▂▂▂▃
wandb:      train/policy_loss ▄▁██▄▄▄█▄▄▄▄▄▄█▄▁▄▁███▄██▁▄▁▁▄▄▄▄██▄█▄▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85766
wandb: best/eval_avg_mil_loss 0.40689
wandb:  best/eval_ensemble_f1 0.85766
wandb:            eval/avg_f1 0.77007
wandb:      eval/avg_mil_loss 0.47187
wandb:       eval/ensemble_f1 0.77007
wandb:           train/avg_f1 0.77109
wandb:      train/ensemble_f1 0.77109
wandb:         train/mil_loss 0.95331
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ywu2odz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052429-9ywu2odz/logs
wandb: ERROR Run 9ywu2odz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o98b6gzr with config:
wandb: 	actor_learning_rate: 0.00013537667231194907
wandb: 	attention_dropout_p: 0.2513906745252931
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1186785001315559
wandb: 	temperature: 5.343178379552761
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052643-o98b6gzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o98b6gzr
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▅█
wandb: best/eval_avg_mil_loss ▄█▅▁▄
wandb:  best/eval_ensemble_f1 ▁▂▅▅█
wandb:            eval/avg_f1 ▅▅▄▄▇▂▃▂▅▂▆▁▅▄▁▁▆▄▇▃▆▅▂▆▂▄▃▁▇▅▄▄▆▁█▂▃▁▃▅
wandb:      eval/avg_mil_loss ▇▄▅▄▅▃▅▄▄▄▄▄▅▃▅▆▅▄▂▃█▅█▂▂▅▄▅▅▅▁▅▂▃▇▆▃▃▅▇
wandb:       eval/ensemble_f1 ▄▄▃▂▃▃▃▅▄▃▄█▆▅▅▄▁▄▄▁▆▄▃▅▆▆▃▃▄▅▂▄▆▁▄▅▄▁▃▅
wandb:           train/avg_f1 ▃▃▄▂▁▄▂▃▅▆▃▂█▅▄▃▂▄▃▇▄▄▃▄▆▆█▅▅▂▇▆▃▇▄▃▄▄▅▃
wandb:      train/ensemble_f1 ▃▆▄▅▆▅▆▇▃▆▆▄▁▆▇▆▃▅█▄▄▄▆▄▅▇▆▃▃▆▅▆▄▄▅▆▄▇▄▄
wandb:         train/mil_loss █▅▆▆▇▅█▇▇▅▆▆▆▄▅▄▃▃▅▇▃▅▂▂▅▃▂▃▄▃▂▆▃▅▃▄▃▃▁▃
wandb:      train/policy_loss ▅▅▅▅▅█▅▅▅▅▅▃▅▅▅▅▅▅▂▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▆▆▆█▆▆▆▆▆▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▇▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.44533
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.76078
wandb:      eval/avg_mil_loss 0.44797
wandb:       eval/ensemble_f1 0.76078
wandb:           train/avg_f1 0.78197
wandb:      train/ensemble_f1 0.78197
wandb:         train/mil_loss 0.60194
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o98b6gzr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052643-o98b6gzr/logs
wandb: ERROR Run o98b6gzr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t8zjkpnk with config:
wandb: 	actor_learning_rate: 2.093643742207313e-06
wandb: 	attention_dropout_p: 0.01373066076535484
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14742653376571624
wandb: 	temperature: 9.309375696593769
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052908-t8zjkpnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t8zjkpnk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▅▁█
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▃▃▄▄▅▇▅█▆▅▆▄▆▁▆▅▄▄█▄▅▇▇▆▆▇▆▆▃▁▃▄▃▃▁▇▅▄▂▃
wandb:      eval/avg_mil_loss ▂▅▆▅▄▄▁▅▃▆▅▁█▄▂▅▃▂▅▅▄▅▂▃▄▂▂▃▆▇▇▅▆▆▄▄▆▆▄█
wandb:       eval/ensemble_f1 ▆▄▄▅▆▆▁▇▅█▆▄▅▇▃▇▅▅▅▄█▇▇▇▅▆▆▅▃▄▅▄▄▃▆▆█▅▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▄▂▄▂▃▂▂▂▅▃▃▁▁▂▃▃▁▆▅▃▁▃▅▄▄▃▃▁▃▂▅▅▅█▄▄▄▂
wandb:      train/ensemble_f1 ▆▂▁▄▂▄▂▃▂▅▃▃▁▁▄▃▃▁▆▅▂▁▃▅▂▅▄▃▃▁▃▂▅▅▅█▄▄▄▂
wandb:         train/mil_loss ▅▆▆▇▇▅▆█▆▆█▆▆▅▅▅▅▅▄▄▃▅▄▃▄▂▄▃▂▃▂▃▄▁▃▂▂▃▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄█▄▇▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▁▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.40934
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.78465
wandb:      eval/avg_mil_loss 0.51206
wandb:       eval/ensemble_f1 0.78465
wandb:            test/avg_f1 0.77799
wandb:      test/avg_mil_loss 0.52653
wandb:       test/ensemble_f1 0.77799
wandb:           train/avg_f1 0.79817
wandb:      train/ensemble_f1 0.79817
wandb:         train/mil_loss 1.03207
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t8zjkpnk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052908-t8zjkpnk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ye9wanfc with config:
wandb: 	actor_learning_rate: 8.860329956290614e-05
wandb: 	attention_dropout_p: 0.39019523133564377
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013188924422265824
wandb: 	temperature: 5.490280064581315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053020-ye9wanfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9wanfc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 █▁▂▇▆▅▅▃▇▆▇▅▃▅▅█▃▆▅▃▆▅▆▇▂▄▂▄▃▆▆▆▂▆▃▅▄▄█▅
wandb:      eval/avg_mil_loss ▃▄▇▅▃▃▃▃▃▆▅▄▃▃▅▅▂▅▇▄▃▅▁▃▄▇▄▆▅▄▇▃▃▄▇▄▅▅▄█
wandb:       eval/ensemble_f1 ▄▆▆▄▅▃▄▅▃▁▃▅▇▅▃▆▃▅▅█▆▆▃▃▄▄▂▆▃▅▄▆▆▅▆▃▃▆▄▇
wandb:           train/avg_f1 ▇▅▄▆▆▆▆▄▅▆▇█▅▆▇▆▇▄▄▄█▅▄▅▆▅▃▆▄▄▇▆▅▄▅▁▄▄▅▄
wandb:      train/ensemble_f1 ▄▅▆▆█▆▃▄▆▇▅▅▄▆▅▇▄▄▆▇▅▄▄▃▅▅▆▆▄▆▃▆▃▆▅▅▆▄▁▃
wandb:         train/mil_loss ▆▅▇▄▆██▅▇▆▅▅▅▅▅▇▅▆▄▆▃▅▆▃▄▃▃▄▄▃▂▃▃▃▃▂▃▁▁▁
wandb:      train/policy_loss ▃▃▃▃▂▃▃▃▃▁▃▃▅▃▃▃▃▅█▃▆▃▃▄▃▅▃▃▃▃▃▃▁▃▃▃▃▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▃▅▅▅▃▅▅▅▅▅▅▅▅▅▁▅▇▅█▅▆▅▇▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85352
wandb: best/eval_avg_mil_loss 0.34642
wandb:  best/eval_ensemble_f1 0.85352
wandb:            eval/avg_f1 0.81013
wandb:      eval/avg_mil_loss 0.56844
wandb:       eval/ensemble_f1 0.81013
wandb:           train/avg_f1 0.7942
wandb:      train/ensemble_f1 0.7942
wandb:         train/mil_loss 1.98155
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9wanfc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053020-ye9wanfc/logs
wandb: ERROR Run ye9wanfc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ilvyukfc with config:
wandb: 	actor_learning_rate: 4.918735111935741e-06
wandb: 	attention_dropout_p: 0.4454214110451173
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13247577771073127
wandb: 	temperature: 1.3391650885673911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053219-ilvyukfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilvyukfc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅█
wandb: best/eval_avg_mil_loss █▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅█
wandb:            eval/avg_f1 ▇▇▅▅▆▇▅▆█▇▄▆▆▅▇▁▇▆▆▅▃▆▃▇▃▄▇▆▆▄▆▅▃▃▄▃▃▃▆▆
wandb:      eval/avg_mil_loss ▃▄▅▆▃▁▃▃▆▆▆▅▂▅▃▅▆▅▇▇▇▇▄▃▄▄▃█▄▇▄▇▆▄▁▅▃▄▅▃
wandb:       eval/ensemble_f1 ▅▄▃▅▇▆▇▄▅▇█▇▆▄▄▄▇██▁▇▃▄▃▆▃▇▆▆▆▄▆▅▇▂▃▂▇▅▄
wandb:           train/avg_f1 ▃▄▅▇▅▅▃▄▃▃▄▅▃▄▇▂█▄▄▄▄▆▁▄▄▃▃▃▃▂▁█▃▁▃▃▂▂▅▄
wandb:      train/ensemble_f1 ▄▆▅▅▄▇▅▅▅▄▄▅▇▅█▅▃▄▅▆▄▆▄▄▂▇▅▄█▅▃▃▄▅▁▆▃▅▅▅
wandb:         train/mil_loss ██▇▇▇▆▅▆▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▆█▅▁▆▆▄▆▆▆▆▆▆▆▆▆▆▄▆▆▆▂▆▅▂▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▄▃█▂▁▄▄▄▄▅▅▄▁▄▄▄▄▄▅▄▄▅▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82478
wandb: best/eval_avg_mil_loss 0.42592
wandb:  best/eval_ensemble_f1 0.82478
wandb:            eval/avg_f1 0.77225
wandb:      eval/avg_mil_loss 0.50084
wandb:       eval/ensemble_f1 0.77225
wandb:           train/avg_f1 0.78307
wandb:      train/ensemble_f1 0.78307
wandb:         train/mil_loss 0.71813
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilvyukfc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053219-ilvyukfc/logs
wandb: ERROR Run ilvyukfc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lhssf6mh with config:
wandb: 	actor_learning_rate: 1.8783403237622008e-06
wandb: 	attention_dropout_p: 0.43262692073957687
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22894306728486524
wandb: 	temperature: 0.23620702130776497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053454-lhssf6mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhssf6mh
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▆▅▇▅▆▆▆▆▆▃▅▄▅▅▆▄▇▄▄▅▄▆▅▇▄▅▅▄▂▃▃▆█▅▄▄▆▁▄
wandb:      eval/avg_mil_loss ▆▃▄▄▅▅▇▄▅▄▇█▃▆▅▅█▇▄▂▄▅▄▂▇▅▅▇▅▆▄▁▂▇▄▃▅▆█▁
wandb:       eval/ensemble_f1 ▅▆█▅▅▆▇▆▇▅▇▆▄▅▅▅▅▅▆▆▆▇▄▇▅▃▆▇▂▅▄▇▆▅▄▅▅▄▁▄
wandb:           train/avg_f1 ▄▅▆▁▄▁▄▄▆▅▄▃▅█▂▅▄▄▄▇▄▆▃▅▄▆▆▅▆▄▄▃▆▅▃▆▃▆▄▅
wandb:      train/ensemble_f1 ▅▅▇▆▄▅█▅▄▁▇▄▆▅▂▅▄█▅▆▅▅█▄█▅▄▇▆▅▃▇▇▄▅▇▆▄▅▆
wandb:         train/mil_loss ▅▇▄▆▄▄▄▇█▄▃▅▄▇▆▅▄▃▇▃▄▅▃▅▂▄▃▃▂▂▄▄▂▂▃▆▁▃▃▂
wandb:      train/policy_loss ▇▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▁▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83575
wandb: best/eval_avg_mil_loss 0.43806
wandb:  best/eval_ensemble_f1 0.83575
wandb:            eval/avg_f1 0.76622
wandb:      eval/avg_mil_loss 0.47578
wandb:       eval/ensemble_f1 0.76622
wandb:           train/avg_f1 0.78721
wandb:      train/ensemble_f1 0.78721
wandb:         train/mil_loss 0.93397
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhssf6mh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053454-lhssf6mh/logs
wandb: ERROR Run lhssf6mh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8kku2tc7 with config:
wandb: 	actor_learning_rate: 0.00011389074779364372
wandb: 	attention_dropout_p: 0.49704549017741384
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8186016267485553
wandb: 	temperature: 6.569020466991271
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053658-8kku2tc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kku2tc7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▇█
wandb: best/eval_avg_mil_loss ▃▅█▁▃
wandb:  best/eval_ensemble_f1 ▁▁▄▇█
wandb:            eval/avg_f1 ▆▆▆▅▆▆▇█▆▇▆▄▅▅▅▆▇▅▆▄▆▅▄▄▅▂▄▂▄▃▆▂▆▃▁▃▄▄▄▄
wandb:      eval/avg_mil_loss ▁▅▃▄▄▁▃▂▄▃▃▅▃▃▃▃▄▃▂▄▇▃▃▅▄▇▅▇▃▆█▅▃▆▅▆▇▅▆█
wandb:       eval/ensemble_f1 ▅▆▆▅▆▅▅█▆▄▅▅▄▅▄▅▅▆▂▆▅▅▄▄▅▄▃▄▅▂▁▄▃▅▄▂▂▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▇▅▆█▇█▆▅█▆▆▆▆█▇▇▅▆▄▅▃▄▅▅▅▅▆▄▂▄▄▂▁▂▃▂▂
wandb:      train/ensemble_f1 ▇█▆█▇▇█▆▆▆██▆▇█▆▇▇▇▆▇▇▆▇▆▇▅▅▆▅▆▆▅▃▃▅▃▃▄▁
wandb:         train/mil_loss ▇▇█▇█▆▆▅▆▆▅▅▆▅▅▄▄▄▃▄▃▃▂▂▂▃▂▃▂▂▂▁▂▂▂▁▁▁▁▁
wandb:      train/policy_loss ▆▆▆▅█▆▆▇▇▆▇▆▆▆▆▆▅▇▅▆▆▆▆▆▆▆▇▆▇▆▆▇▆▇▇▇▇▆▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆█▆▆▆▆▆▆▅▇▆▅▆▆▇▆▆▄▆▆▆▆▆▆▆▆▇▆▆▆▆▇▆▆▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83559
wandb: best/eval_avg_mil_loss 0.41982
wandb:  best/eval_ensemble_f1 0.83559
wandb:            eval/avg_f1 0.76562
wandb:      eval/avg_mil_loss 0.50416
wandb:       eval/ensemble_f1 0.76562
wandb:            test/avg_f1 0.78363
wandb:      test/avg_mil_loss 0.45856
wandb:       test/ensemble_f1 0.78363
wandb:           train/avg_f1 0.75705
wandb:      train/ensemble_f1 0.75705
wandb:         train/mil_loss 0.69258
wandb:      train/policy_loss -0.92756
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.92756
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kku2tc7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053658-8kku2tc7/logs
wandb: Agent Starting Run: 2zklgfjq with config:
wandb: 	actor_learning_rate: 1.2619427258659485e-06
wandb: 	attention_dropout_p: 0.47523634401308473
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40686540113599423
wandb: 	temperature: 1.7196557976425908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053913-2zklgfjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zklgfjq
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▆▇█
wandb: best/eval_avg_mil_loss █▅▆▆▅▆▁▂
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▆▇█
wandb:            eval/avg_f1 ▂▃▆▂▃█▆▅▅▄▇▅▂▆▃▅▅▇▅▆▅▃▅▃▆▂▁▅▆▅▃▅▅▄▂▂▅▂▅▄
wandb:      eval/avg_mil_loss ▅▄▄▇▄▃▄▂▅▄▁▇▅▄▆▅▅▁▃▃▂▆▆█▄▅█▅▂▃▅▄▇▆▂▄█▂▇▆
wandb:       eval/ensemble_f1 ▄▆▆▃▆▇▃▄▄▃▅▂▅▃▃▆▅▅▃▅▂▅▃▂▄▁▆▄▄▅▄▄▆▅▂▅█▅▄▃
wandb:           train/avg_f1 ▆▂▄▅▆▂▅█▅▆▁▃▅▅▃▆▅▅▄▂▅▆▆▇▆▃▄▅▃▄▇▂▁▃▃▂▃▅▃▃
wandb:      train/ensemble_f1 ▅▄▁▄▆▄▆▂▅▅▅▄▅▃█▆▅▅▄▃▅▁▃▄▄▄█▃▃▅▄▁▅▂▄▄▅▆▆▂
wandb:         train/mil_loss ██▇▇▆▆▆▇▆▆▇▇▇▆▆▆▅▆▄▅▄▄▅▄▃▃▃▃▃▃▃▃▃▁▃▁▃▁▂▁
wandb:      train/policy_loss ▆▆▆▆▆▄▆▆▆▆▆▆▅▆▆▆▆▁▆▆▆▆▅▆▆▆▇▆█▆▆▄▆▆▆▆▆▆█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▂▁▅▅▅▅▅▅▅▅▅▇▅█▅▅▃▅▃▅▅▅▁▅█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86456
wandb: best/eval_avg_mil_loss 0.39218
wandb:  best/eval_ensemble_f1 0.86456
wandb:            eval/avg_f1 0.78098
wandb:      eval/avg_mil_loss 0.46386
wandb:       eval/ensemble_f1 0.78098
wandb:           train/avg_f1 0.80394
wandb:      train/ensemble_f1 0.80394
wandb:         train/mil_loss 0.55957
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zklgfjq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053913-2zklgfjq/logs
wandb: ERROR Run 2zklgfjq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jkl51t4g with config:
wandb: 	actor_learning_rate: 1.437327551832472e-06
wandb: 	attention_dropout_p: 0.4896675211942627
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3829685265067505
wandb: 	temperature: 0.7240195179648623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054117-jkl51t4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkl51t4g
wandb: uploading history steps 120-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁█
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▄▄▆▃▃▃▂▅█▄▁▃▅▆▃▇▄▂▂▄▂▃▅▃▄▇▄▇▄▁▄▅▄▅▄▅▄▆▅
wandb:      eval/avg_mil_loss ▅▆▆▃▇▂▃▃▂▄▃▁▂▅▃▂▅▁▆▃▄▄▁▄▃▁▂▃▄▂▃█▃▂▃▄▃▅▃▃
wandb:       eval/ensemble_f1 ▁▅▆▄▅▇▅▃█▂▅▅▆▄▇▃▅▅▃▅▄▅▄▄▄▄▇▅▇▆▂▄▅▃▄▅▅▄▃▃
wandb:           train/avg_f1 ▅▃▃█▅▆▄▅▂▄▄▄█▅▄▆█▅▆▂▄▇▅▅▃▅▃▅▄▄▅▄▆▁▅▂▄▄▅▅
wandb:      train/ensemble_f1 ▃▇▆▄▅▄▄█▄▅█▄▅▄▆▆▅▅▃▅▅▃▆▅▅▅▅▄▄▄▅▄▆▃▁▄▂▄▄▅
wandb:         train/mil_loss ▃▄▂▆▅▅▄▃▄▃▄▅▄▅▄▇▇▅▄▅█▄▃▃▂▃▄▁▂▂▁▃▄▄▃▁▃▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82828
wandb: best/eval_avg_mil_loss 0.45501
wandb:  best/eval_ensemble_f1 0.82828
wandb:            eval/avg_f1 0.76982
wandb:      eval/avg_mil_loss 0.47829
wandb:       eval/ensemble_f1 0.76982
wandb:           train/avg_f1 0.79156
wandb:      train/ensemble_f1 0.79156
wandb:         train/mil_loss 0.8459
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkl51t4g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054117-jkl51t4g/logs
wandb: ERROR Run jkl51t4g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ju3ygnlg with config:
wandb: 	actor_learning_rate: 1.4232219628659748e-05
wandb: 	attention_dropout_p: 0.4398799504994816
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3788791753487471
wandb: 	temperature: 7.639743257853924
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054414-ju3ygnlg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ju3ygnlg
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅█
wandb: best/eval_avg_mil_loss █▆▃▄▁▅▇
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅█
wandb:            eval/avg_f1 ▅▆▆█▇▆▆▇▄█▅▃▇▄▆▆▅▆▄▃▇▄▆▅▅▇▅▃▄▇▅▆▂▄▄▃▃▃▄▁
wandb:      eval/avg_mil_loss ▄▂▃▄▃▇▇▂▃▃▁█▅▄▅▂▂▆▂▂▃▁▁▁▄▄▂▆▄▄▆▄▆▄▃▆▅▃▇▃
wandb:       eval/ensemble_f1 ▄▄▄▄▅▂▅▄▅▃▅▄▅█▄▆▅▅▃▂▃▃▃▄▃▅▅▅▂▂▄▆▃▁▃▂▂▃▃▄
wandb:           train/avg_f1 ▅▇▆▇▅▆▆▆▅▅▆▅█▅▆▃▄▅▄▅▄▆▆▄▄▂▃▅▄▄▄▄▄▄▂▄▅▄▂▁
wandb:      train/ensemble_f1 █▇▆▆▄▇▇▅▄▅▅▅█▅▅▆▃▆▆▇▅▅▄▅▅▇▅▃▄▄▂▄▄▁▂▃▄▂▂▄
wandb:         train/mil_loss ▇▆▇▇█▇▅▆▅▆▆▆▆▅▄▆▄▅▅▄▅▅▅▅▅▄▄▄▃▃▄▁▃▃▄▃▃▃▄▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▄▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▅▆▆▆▆▆▆▆▆▇▆▆▅▆▆▆▆▆▆▆▆▆▆▆▁▆▇▆▆▆▇▆▆█▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86071
wandb: best/eval_avg_mil_loss 0.43396
wandb:  best/eval_ensemble_f1 0.86071
wandb:            eval/avg_f1 0.7773
wandb:      eval/avg_mil_loss 0.59163
wandb:       eval/ensemble_f1 0.7773
wandb:           train/avg_f1 0.77495
wandb:      train/ensemble_f1 0.77495
wandb:         train/mil_loss 1.5913
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ju3ygnlg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054414-ju3ygnlg/logs
wandb: ERROR Run ju3ygnlg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qu1srewc with config:
wandb: 	actor_learning_rate: 4.1287147898707415e-06
wandb: 	attention_dropout_p: 0.08163123265069083
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.940075812445786
wandb: 	temperature: 8.829894153270759
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054723-qu1srewc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu1srewc
wandb: uploading history steps 130-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▄▆█
wandb: best/eval_avg_mil_loss ▄█▄▄▂▁▄
wandb:  best/eval_ensemble_f1 ▁▃▃▄▄▆█
wandb:            eval/avg_f1 ▇▅▅▇▆▃█▅▅▄▆▅▅▂▅▅▃▆▇█▃▇▂▂▃▂▄▃▆▁▅▂▃▅▆▆▄▄▅▆
wandb:      eval/avg_mil_loss ▅▄█▄▅▄▄▄▅▃▆▃▆▄▆▅▂▅▅▆▄▃▆▅▄▅▅▆▇▄▁▃▅▄▄▃▃▃▄▅
wandb:       eval/ensemble_f1 ▇█▅▃▇▅▂▇▅▆▄▃▅▄▄▇█▅▆▅▇▆▃▆▂▆▃▆▆▁▅▂▅▅▅▆▄█▁▂
wandb:           train/avg_f1 ▃█▆▅▇▂▃▇▄▄▅▁▄▅▇▆▅▃▄█▄▄▃▅▅▄▅▂▄▄▆▃▂▅▂▄▂▆▄▃
wandb:      train/ensemble_f1 ▄▆▆▃▅▅▆█▅▆▅▅▁▄█▇▄▅▄▅▆▃▄▄▆▇▄▄▃▅▂▃▃▃▄▃▇▅▇▂
wandb:         train/mil_loss █▇█▇▇█▇▆▇▇▆▅▅▆▄▄▄▃▃▃▃▃▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▂▂▁
wandb:      train/policy_loss ▄▅▄▄▄▅▄█▄▁▄▂▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▆▄▄▄▅▄▁▄▄▄▇█▄█▆▄▇▄▄▄▄▄▅▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84432
wandb: best/eval_avg_mil_loss 0.43543
wandb:  best/eval_ensemble_f1 0.84432
wandb:            eval/avg_f1 0.74794
wandb:      eval/avg_mil_loss 0.4868
wandb:       eval/ensemble_f1 0.74794
wandb:           train/avg_f1 0.79938
wandb:      train/ensemble_f1 0.79938
wandb:         train/mil_loss 0.766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu1srewc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054723-qu1srewc/logs
wandb: ERROR Run qu1srewc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: gbrvk71f with config:
wandb: 	actor_learning_rate: 0.00015004244070969142
wandb: 	attention_dropout_p: 0.06566191492692136
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3703741063706121
wandb: 	temperature: 0.33703300805967507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055028-gbrvk71f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbrvk71f
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▄▅▇█
wandb: best/eval_avg_mil_loss ▃▅█▆▁▆▅
wandb:  best/eval_ensemble_f1 ▁▁▃▄▅▇█
wandb:            eval/avg_f1 ▅▇▆▆▇█▇▄▆▄▆▅▅▇▆▅▃▅▆▆▃▄▇▆▇▆▄▇█▄▅▆▃▇▁▆▅▇▄▃
wandb:      eval/avg_mil_loss ▃▃▇▆▄▂▂▃▃▇▃▅▄▃▅▅▅▅▅▄█▄▂▄▄█▄▆▅▇▄▁▂▅▂▃▆▂▅▂
wandb:       eval/ensemble_f1 ▄▅▃▅▇▆▇▇▃▄▅▆▃▇▅▄▃▂▄▄▅▅▆▅▆▁▆▂▆▇▇▂▂█▇▅▄▃▄▁
wandb:           train/avg_f1 ▄▇▅▃▃▃▅▅▆▆▄▇▆▆▄▆█▂▄▂▇▃▄▄▄▄▁▄▅▅▂▄▃▁▅▅▃▄▄▂
wandb:      train/ensemble_f1 ▅▄▃▅▅▂▇▅▅▅▂▆▅▆▆▆▄▄▆█▄▄▅▆▇▂▃▄▁▄▆▂▄▅▆▃▅▄▅▃
wandb:         train/mil_loss ██▇██▇▇▇▇▆▆▇▆▆▅▆▆▆▅▆▅▆▅▅▅▅▅▄▅▄▃▃▂▂▂▂▂▁▁▁
wandb:      train/policy_loss ▅▅▅▅▅▅▁▅▆▅▅█▅▅▅▅▅▅▅▅▅▇▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▄▄▄▄▄▁▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83513
wandb: best/eval_avg_mil_loss 0.4549
wandb:  best/eval_ensemble_f1 0.83513
wandb:            eval/avg_f1 0.8052
wandb:      eval/avg_mil_loss 0.4285
wandb:       eval/ensemble_f1 0.8052
wandb:           train/avg_f1 0.78531
wandb:      train/ensemble_f1 0.78531
wandb:         train/mil_loss 0.81171
wandb:      train/policy_loss -0.29532
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.29532
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbrvk71f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055028-gbrvk71f/logs
wandb: ERROR Run gbrvk71f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ey2iugz1 with config:
wandb: 	actor_learning_rate: 1.174135853682498e-05
wandb: 	attention_dropout_p: 0.13891657281258962
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7366619824651547
wandb: 	temperature: 4.324322067574401
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055258-ey2iugz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2iugz1
wandb: uploading history steps 79-92, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▃▃▄▅▂▂▄▃▅▃▅▄▄█▃▅▇▅▆█▄▅▇▄▄▄▅▅▅▃▁▇▅▅▅▆▅▆▃
wandb:      eval/avg_mil_loss ▂▅▅▅▆▇▃▄▇▃▄▆▆▄▆█▅▄▂▆▅▅▅▇▆▄▅▇▅▁▃▄▅█▃▇▄▆▅▆
wandb:       eval/ensemble_f1 ▆▂▅▄▅▃▆▂▅▅▄▆▃▇▃▄▇▃▃▄▅▅▃▅▅▅▅▅▁▅▅▃▄▅▇█▆▄▅▅
wandb:           train/avg_f1 ▄▄▆▄▄▇▆▄▃█▅▅▄▃▆▇▄▇▆▇▅▅▅▇▄▅▆▄▇▃▅▃▃▂▅▃▅▄▁▁
wandb:      train/ensemble_f1 ▆▆▇▇▆█▅▅▃▃▃▆▅▇▇▆▃▄█▆▅▃▇▅█▄▄▃▅▆▅▄▄▃▃▄▅▅▁▁
wandb:         train/mil_loss ▅▅█▅▅█▅▆▇▅▆▅▆▄▆▄▆▅▄▆▅▄▃▃▅▂▃▃▂▃▃▂▂▄▄▂▂▂▁▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃▆▃█▁▃▃▃▃▃▃▇▁▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▇▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83571
wandb: best/eval_avg_mil_loss 0.41373
wandb:  best/eval_ensemble_f1 0.83571
wandb:            eval/avg_f1 0.7992
wandb:      eval/avg_mil_loss 0.43286
wandb:       eval/ensemble_f1 0.7992
wandb:           train/avg_f1 0.77217
wandb:      train/ensemble_f1 0.77217
wandb:         train/mil_loss 0.63522
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2iugz1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055258-ey2iugz1/logs
wandb: ERROR Run ey2iugz1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: quyhnbod with config:
wandb: 	actor_learning_rate: 0.0009314612840585808
wandb: 	attention_dropout_p: 0.20246012604245855
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33939124182434033
wandb: 	temperature: 4.779756634460352
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055451-quyhnbod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quyhnbod
wandb: uploading history steps 92-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▅▄▂▆▇▇▄▅▅▅▆▃▄▄▄▆▃▅▅▅▇▆▄▅▄▆▅▅▁▅▅▂▅█▅▅▄▄▁
wandb:      eval/avg_mil_loss ▂▅█▅▅▆▆▅▄▇▃▇▆▇▃▆▄▇▄▁▆▆▅▃▄▅▅▄▅▅▅▃▅▇▆▆▁▄▆▃
wandb:       eval/ensemble_f1 ▄█▄▂▅▄▄▆▆▅▃▂▅▅▆▄▆▃▃▄▆▆▆▅▅▁▅▃▄▂▅▄▅▃▇▇▅▅▄▃
wandb:           train/avg_f1 ▅▄▅▁▆█▆▅▅▂▁▅▃▆▆▅▂▃▆▅▄▅▃▆▆▆▃▆▆▅▄▄▅▅▄▆▃▆▇▂
wandb:      train/ensemble_f1 ▅▄▄▇▂▄▅▅▄▄█▆▅▆▅▂▅▂▅▄▆▁▆▅▆▇▅▄▇▃▅▇▅▅▇▅▆▆▆▇
wandb:         train/mil_loss ▆▅█▇▄█▃▇▄▇▃▅▅▄▆▄▄▄▆▃▂▄▃▃▂▆▅▄▃▃▅▅▃▂▁▂▄▅▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80644
wandb: best/eval_avg_mil_loss 0.45925
wandb:  best/eval_ensemble_f1 0.80644
wandb:            eval/avg_f1 0.71879
wandb:      eval/avg_mil_loss 0.48932
wandb:       eval/ensemble_f1 0.71879
wandb:           train/avg_f1 0.76831
wandb:      train/ensemble_f1 0.76831
wandb:         train/mil_loss 1.26018
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quyhnbod
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055451-quyhnbod/logs
wandb: ERROR Run quyhnbod errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kgwme01f with config:
wandb: 	actor_learning_rate: 2.2785370108265124e-06
wandb: 	attention_dropout_p: 0.3692722263090225
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32498635744907645
wandb: 	temperature: 8.131090555336797
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055657-kgwme01f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgwme01f
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▆▇█
wandb: best/eval_avg_mil_loss ▇█▅▄▁▂▂
wandb:  best/eval_ensemble_f1 ▁▃▄▆▆▇█
wandb:            eval/avg_f1 ▃▂▆▃▃▃▄▆▄██▁▂▁▅▃▃▃▅▃▄▄▃▂▅▅▃▄▇▄▄▅▄▅▆▁▂▅▄▄
wandb:      eval/avg_mil_loss ▅▅▅▁▆▇▅▆█▄▅▆█▅▅▄▃▅▄▅▄▅▆▁▇▆▅▇▆▄▅▇▃▆▂▆▆█▄▅
wandb:       eval/ensemble_f1 ▄▇▃▄▃▄▄▇▅▆▅▄▄▅▃▅▆▃▃▃▅█▆▄▅█▄▄▁▅▃▆▆▅▄▆▃▇▄▅
wandb:           train/avg_f1 ▆▅▇█▄█▆▂▇▅▅▆▇▆▇▄▅▂▄▆▃▅▃▇▄▅▄▄▇▄▄▆▄▅▃▄▅▄▁▆
wandb:      train/ensemble_f1 █▇▅▄▂█▇▄▅▅▆▂█▆▄▃▄▁▃▅▄▄▄▂▇▃▆▄▂▃▄▁▃▅▂▅▂▆▃▅
wandb:         train/mil_loss ▆▄▄▅█▄▆▅▅▆▄▄▆▄▄▆▄▄▄▃▄▄▄▃▄▄▃▃▃▂▁▃▃▂▄▄▂▃▁▂
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.36174
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.79882
wandb:      eval/avg_mil_loss 0.45606
wandb:       eval/ensemble_f1 0.79882
wandb:           train/avg_f1 0.79285
wandb:      train/ensemble_f1 0.79285
wandb:         train/mil_loss 1.63695
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vague-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgwme01f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055657-kgwme01f/logs
wandb: ERROR Run kgwme01f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ablbbamq with config:
wandb: 	actor_learning_rate: 1.5936638151926533e-05
wandb: 	attention_dropout_p: 0.46142917228193847
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3059193000326861
wandb: 	temperature: 2.979060199744655
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055958-ablbbamq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ablbbamq
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅█
wandb: best/eval_avg_mil_loss ▄▅█▂▄▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅█
wandb:            eval/avg_f1 ▂▄▃▅▆▄▄▅▅▄▄▄▅▅▅▅▁▅▅▄▅▄▃▅█▄▄▃▄▄▃▄▅▃▃▅▅▃▃▄
wandb:      eval/avg_mil_loss ▃█▄▅▄▄▅▂▅▅▅▅▄▃▅▆▇▅▃▅▆▄▃▃▄▄▄▁▃▅▄▅▃█▆▆▆▃▇▄
wandb:       eval/ensemble_f1 ▂▃▁▄▄▁▅▅▅▂▅▄▅▄▄▄▃▃▅▄▄▅▃▂▃▄█▅▃▃▃▄█▃▅▅▅▂▃▄
wandb:           train/avg_f1 ▆▆▄▄▄█▄▁▆▄▂▄▆▇██▂▂▃▆▃▅▅▄▆▅▄▄▅▄▂▃▄▄▃▂▃▅▆▄
wandb:      train/ensemble_f1 ▇▆▁▇▇▅▂▃▅▄▇▃▃▆▃▅▅█▄▄█▄▆▅▅▄▄▅▃▃▄▃▅█▃▆▃▅▇▆
wandb:         train/mil_loss ▄▅▁▅█▅▃▄▆▅▃▃▅▄▂▄▂▃▅▂▆▄▄▄▇▃▆▁▁▆▄▄▃▆▅▃▃▅▆▆
wandb:      train/policy_loss █▄▁▄▄█▁▄█▄▄▁▄▄▄▄▁█▁▄▄▄▄▄▄▁▄▄█▄▄▄▄▄█▁▁▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▁▄▄▄▄▄▁▄▄▄█▄▁█▄▁▄█▄▁▄▄▄▄▄▄▄▄▄▄█▄█▄▁▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.38135
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.81717
wandb:      eval/avg_mil_loss 0.4205
wandb:       eval/ensemble_f1 0.81717
wandb:           train/avg_f1 0.78518
wandb:      train/ensemble_f1 0.78518
wandb:         train/mil_loss 0.86663
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ablbbamq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055958-ablbbamq/logs
wandb: ERROR Run ablbbamq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d39drv7f with config:
wandb: 	actor_learning_rate: 2.380854357608749e-06
wandb: 	attention_dropout_p: 0.20204413055540865
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6863133111712968
wandb: 	temperature: 0.280926580720291
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060158-d39drv7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d39drv7f
wandb: uploading history steps 139-146, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆█
wandb: best/eval_avg_mil_loss █▅▅▄▁
wandb:  best/eval_ensemble_f1 ▁▂▄▆█
wandb:            eval/avg_f1 ▆▃▄█▅▆▆▆▅▇▇▇▆▆▃█▄▃▅▅▅█▂▆▄▄▁▃▃▂▂▃▆▃▄▁▃▁▂▃
wandb:      eval/avg_mil_loss ▃▂▄▄▃▅▄▅▅▃▃▁▃▄▄▅▅▃▄▅▆▆▅▆▆▇▅▆▆▆▇▆▆▆▇▇█▇▇▇
wandb:       eval/ensemble_f1 █▇▆█▆▇██▆▇▆█▅▄▇▆▅▄▅▅▅▅▅▄▅▆▆▅▃▅▅▅▇▄▄▃▄▄▂▁
wandb:           train/avg_f1 █▇██▇▇▇▇▆█▇▆▇▇▆▇▆▇▆▅▅▅▅▅▅▅▄▄▃▄▄▃▃▂▁▂▂▂▂▂
wandb:      train/ensemble_f1 ▇█▇██▇█▇█▇▇▇▇██▇▇█▆▇▇▆▆▆▇▆▆▆▆▅▅▅▆▅▄▄▄▁▂▃
wandb:         train/mil_loss ▇▆▇▇█▆▆▅▆▅▆▅▅▄▄▆▅▅▄▅▄▄▄▄▄▃▃▃▃▂▃▃▂▂▃▂▂▂▁▁
wandb:      train/policy_loss ▃▃▃▆▃▃▃▃▃▃▄▃▃▄▁▃▃▃▃▃▃▃▄▅▃▄▃▃█▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▂▂▂▂▂▃▂▂▂▂▆▂▂▃▂▂▂▂▄▂▃▂▁▃▃▂▃▂█▂▂▂▂▂▂▂▂▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84658
wandb: best/eval_avg_mil_loss 0.37244
wandb:  best/eval_ensemble_f1 0.84658
wandb:            eval/avg_f1 0.69421
wandb:      eval/avg_mil_loss 0.66049
wandb:       eval/ensemble_f1 0.69421
wandb:           train/avg_f1 0.71089
wandb:      train/ensemble_f1 0.71089
wandb:         train/mil_loss 1.40409
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d39drv7f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060158-d39drv7f/logs
wandb: ERROR Run d39drv7f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0f8uhovr with config:
wandb: 	actor_learning_rate: 5.204970058178652e-05
wandb: 	attention_dropout_p: 0.04773938984623882
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14213629341388612
wandb: 	temperature: 4.474501944085042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060514-0f8uhovr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0f8uhovr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆▇▇▇█
wandb: best/eval_avg_mil_loss █▄▆▄▃▃▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆▇▇▇█
wandb:            eval/avg_f1 ▅▆▄▄▅▇█▅▃▄▃▅▄▇▅▅▄▅▆▄▃▆▅▄▂▇▅▂▇▂▅▃▄▂▂▃▄▄▂▁
wandb:      eval/avg_mil_loss ▂▄▂▁▂▁▁▃▄▃▃▂▄▁▂▃▃▅▅▄▄▂▅▃▃▇▄█▃▅▅▄▄▆▆▅▇▄▆▇
wandb:       eval/ensemble_f1 ▅▇▄▇▅▇▆▄▄▅▃▄▄▄▅▅█▆▅▄▆▄▄▅▇▅▆▂▅▄▃▂▃▄▄▃▄▆▃▁
wandb:           train/avg_f1 ▇████▇▆█▇█▇▇▆▆▇▆▅▆▅▆▅▅▅▆▄▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁
wandb:      train/ensemble_f1 █▇▇▇▇▆█▇▆█▇▆▆▆▇▆▅▆▆▅▆▅▅▅▅▆▆▄▅▅▄▄▃▃▃▃▁▃▂▁
wandb:         train/mil_loss █▆▆█▇▇▆▅▆▅▅▅▅▆▇▄▄▄▅▅▄▄▆▅▃▃▄▃▄▆▄▄▃▅▂▂▂▃▃▁
wandb:      train/policy_loss ▂▁▁▁▁▁▁▆▁▁▁▁▁▁▁▃▁▂▁▂▁▁▁▁▁▁█▁▁▁▁▁▃▁▁▁▃▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▃▃▃▃▃▃▆▃▃▃▃▃▃▃▃▃▃▄▃▃▁▃▇▃▄▃▃▃▅▄▃▆▃▃▄▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83189
wandb: best/eval_avg_mil_loss 0.42205
wandb:  best/eval_ensemble_f1 0.83189
wandb:            eval/avg_f1 0.72318
wandb:      eval/avg_mil_loss 0.58278
wandb:       eval/ensemble_f1 0.72318
wandb:           train/avg_f1 0.71914
wandb:      train/ensemble_f1 0.71914
wandb:         train/mil_loss 1.07281
wandb:      train/policy_loss 0.04947
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.04947
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0f8uhovr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060514-0f8uhovr/logs
wandb: ERROR Run 0f8uhovr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8bs4q77e with config:
wandb: 	actor_learning_rate: 9.92134792297443e-05
wandb: 	attention_dropout_p: 0.2632114383292347
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9523876051591526
wandb: 	temperature: 8.178011565584857
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060754-8bs4q77e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8bs4q77e
wandb: uploading history steps 81-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ▁█▄
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▆▆▆█▄▇▃▆▅▅▃▄▃▃▅▄▂▄▅▇▅▄▅▆▇▅▅▄▃▃▁▄▃▂▃▅▃▄▅▃
wandb:      eval/avg_mil_loss ▄▃▃▆█▄▆▆▅▃█▆▃▆▄▄█▆▄▅▅▁▇▆▄▅▄▇▅▅▅▆▅▇▇▆▅▆▆▆
wandb:       eval/ensemble_f1 ▆▆▆▆█▇▆▅▇▄▅▃▃▅▅▂▆▆▆▃▇▄▃▅▅▅▇▅▅▄▄▄▆▅▁▃▂▃▅▃
wandb:           train/avg_f1 ▆▆▅█▆▅▇▅▆▃▄▅▇▅▇▄▄▄▂▂▆▅▃██▂▆▄▃▄▅▅▁▆▄▄▃▄▂▄
wandb:      train/ensemble_f1 ▃▅▂▅▆▃▅▅▃▅▄▅▁▅▄▃▅▆▁▃▅▅▅▄▂▇█▅▅▅▂▃▄▃▅▃▃▂▁▁
wandb:         train/mil_loss █▇█▇▇▇▇▇▆▇▆▆▆▆▅▅▄▄▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▂▁▁▂
wandb:      train/policy_loss ▆▆▆▆▆▆▄▆▆▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▁▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆█▂▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆█▁▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.41964
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.77718
wandb:      eval/avg_mil_loss 0.45938
wandb:       eval/ensemble_f1 0.77718
wandb:           train/avg_f1 0.78307
wandb:      train/ensemble_f1 0.78307
wandb:         train/mil_loss 0.99006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8bs4q77e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060754-8bs4q77e/logs
wandb: ERROR Run 8bs4q77e errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uhi9jt5k with config:
wandb: 	actor_learning_rate: 7.82492366606512e-06
wandb: 	attention_dropout_p: 0.41758034318365655
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5227051104888658
wandb: 	temperature: 1.3496901053500676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061004-uhi9jt5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhi9jt5k
wandb: uploading wandb-summary.json
wandb: uploading history steps 129-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▆▆▆▇███
wandb: best/eval_avg_mil_loss ▆▂█▃▃▁▆▄▅▁▂
wandb:  best/eval_ensemble_f1 ▁▄▅▆▆▆▆▇███
wandb:            eval/avg_f1 ▄▆▆▃▅▆█▆▅█▃▅▃▆▅▅█▃▃▅▄▅▂▂▄▄▅▃▃▅▅▄▁▅▆▃▃▄▅▄
wandb:      eval/avg_mil_loss ▅▇▂▆▃▅▆▅▄▃▅▃▇▆▃▅▂▇▄▁▆▆▆█▅▃▄▂▆▅▇▁▄▃▄▃█▂▄▅
wandb:       eval/ensemble_f1 ▄▄▄▅▅▇▅▅█▆▆▅▅▁▄█▁▂▄▅▅▃▄▅▅▂▆▄▄▅▇▆▃▇▃▃▅▅▅▄
wandb:           train/avg_f1 ▃▃▃▄▇▄▅▅▃▆▅▁▃▆▄▆▃▄▄▆▄▃▆▆▂▁▅▆▁▅█▃▄▅▅▃█▅▆▄
wandb:      train/ensemble_f1 ▄▅▄▁▆▅▇▄▃▃▅▅▄▁▅▆▅▆▆▆▃▅▄▃▅▅▅▆▃▄▄▅▃▃█▅▅▆▄▃
wandb:         train/mil_loss █▇▇██▇▆▇▆▆▅▅▅▆▄▅▄▄▄▅▄▄▃▃▄▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁
wandb:      train/policy_loss ▄▄▄▁█▄▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▇▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82448
wandb: best/eval_avg_mil_loss 0.39743
wandb:  best/eval_ensemble_f1 0.82448
wandb:            eval/avg_f1 0.78045
wandb:      eval/avg_mil_loss 0.47571
wandb:       eval/ensemble_f1 0.78045
wandb:           train/avg_f1 0.79168
wandb:      train/ensemble_f1 0.79168
wandb:         train/mil_loss 1.00045
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhi9jt5k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061004-uhi9jt5k/logs
wandb: ERROR Run uhi9jt5k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: m789uulr with config:
wandb: 	actor_learning_rate: 1.12901719197684e-05
wandb: 	attention_dropout_p: 0.2928656846273601
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5527884791010487
wandb: 	temperature: 1.4390628029540542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061244-m789uulr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m789uulr
wandb: uploading history steps 140-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▅▆▇██
wandb: best/eval_avg_mil_loss █▇▃▅▁▆▄▂
wandb:  best/eval_ensemble_f1 ▁▅▅▅▆▇██
wandb:            eval/avg_f1 ▄▅▄▆▅▃▆▇▄▅▅▃▆▄▄▄▃▂▁█▅▄▃▆▅▅▃▄▆▄▂▅▄▄▆▃▅▆▁▄
wandb:      eval/avg_mil_loss ▄▄▃▄▅▁▄▄▃▅▂▄▅▆▅▆▆▃▄▂▆▅▄▅▂▆▆▅▆▆▅▆▄▆▆▅▇█▅▇
wandb:       eval/ensemble_f1 ▄▅▆▅▇▃█▄▆▂▇▃▆▄▆▃▃▅▅▅▆▅▆▅▄▆▄▅▅▃▅▅▄▁▃▂▇▂▄▂
wandb:           train/avg_f1 █▅▆▆▅▆▅▆▅▄█▇▆▇▄▅▇▅▆▅▃▄▅▇▅▅▇▆▃▁▃▄▄▂▇▄▂▂▂▁
wandb:      train/ensemble_f1 ▆▆▆▇▆▇▇▆▅█▆▆█▅▅▅▆▄▅▆▇▆▅▃▄▃▅▄▅▃▂▂▅▄▂▁▁▂▂▂
wandb:         train/mil_loss █▇█▇▆▆▇▅▆▇▅▅▄▄▅▄▅▄▃▃▄▃▄▄▃▄▃▃▃▃▄▁▃▂▂▁▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▆▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▅▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.3841
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.76206
wandb:      eval/avg_mil_loss 0.50219
wandb:       eval/ensemble_f1 0.76206
wandb:           train/avg_f1 0.78966
wandb:      train/ensemble_f1 0.78966
wandb:         train/mil_loss 0.70105
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m789uulr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061244-m789uulr/logs
wandb: ERROR Run m789uulr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 69qbwzpl with config:
wandb: 	actor_learning_rate: 0.00014847561693741578
wandb: 	attention_dropout_p: 0.07847731014366632
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33516101412967847
wandb: 	temperature: 4.650728214720208
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061555-69qbwzpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69qbwzpl
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 125-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇▇██
wandb: best/eval_avg_mil_loss ▅▆█▄▄▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇▇██
wandb:            eval/avg_f1 ▁▄▄▇▆▆▅▆▄▇▇▁▃▅▇▆▅▅▄▇█▅▇▅▄▅▇▄█▆▆▇▃▃▂▂▄▄▅▇
wandb:      eval/avg_mil_loss ▄▆▃▃▂▅▁▅▄▂▆▃▅▇▅▂▃▃▁▂▁▄▅▂▆▄▄█▃▅▄▅▅▆▆█▂▅▅▃
wandb:       eval/ensemble_f1 ▁▅▄▇▁▄▅▄▆▅▁▅▃▄▆▄▁▄▃▄█▄▇▄▅▅▇▄▆▅▅▆▂▄▄▄▄▅▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▄▆▃▄▃▆▆▆▃▅▆▅▅█▅▃▂▃▅▂▅▅▅▃▅▂▇▃█▁▄▅▆▂▅▅▄
wandb:      train/ensemble_f1 ▆▄▅▄▅▆▄▁▃▃▃▅▄▃▆▄▅▁▇▅▅▆▄▇▅▇▇▅▃█▄▆▆▃▇▂▅▅▅▅
wandb:         train/mil_loss ▄█▄▄▆▆▆▄▅▄▂▁▃▃▄▂▆▅▅▅▃▃▄▂▁▃▃▄▃▄▃▄▅▆▃▆▂▃▄█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84175
wandb: best/eval_avg_mil_loss 0.35033
wandb:  best/eval_ensemble_f1 0.84175
wandb:            eval/avg_f1 0.82088
wandb:      eval/avg_mil_loss 0.43167
wandb:       eval/ensemble_f1 0.82088
wandb:            test/avg_f1 0.80336
wandb:      test/avg_mil_loss 0.3985
wandb:       test/ensemble_f1 0.80336
wandb:           train/avg_f1 0.8022
wandb:      train/ensemble_f1 0.8022
wandb:         train/mil_loss 0.54395
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69qbwzpl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061555-69qbwzpl/logs
wandb: Agent Starting Run: lh9n1pbl with config:
wandb: 	actor_learning_rate: 8.730466352448903e-05
wandb: 	attention_dropout_p: 0.2508219013103906
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06040450505889472
wandb: 	temperature: 2.595599481065447
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061825-lh9n1pbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh9n1pbl
wandb: uploading wandb-summary.json
wandb: uploading history steps 131-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss █▂▅▁
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▇▆▄▅▇▃▃▄▇▅▁▇▃▅▄▃▅▆▆▃▅█▂▄█▄▅▆▃▇▄▄█▂▃▃▃▂▅▇
wandb:      eval/avg_mil_loss ▁▇▅▅▃▄▇▃▂▅▄▁▂▃▅▆▂▃▃▆▄▆▅▅▆▃▇▃█▄▁▁▂▄▂▅▇▄▄▄
wandb:       eval/ensemble_f1 █▅▄▆▅▆▅▇▃▆▇▆▄▃▃▅▆▇▅▇▅▇▁▇▅▃▆▅▇█▆▆▆▆▄▄▂█▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▅▇▃▆▇█▃▅▄▆▃▄▅▃▃▇▄▅▄▃▃▄▅▁▄▇▆▆▅▂▅▅▅▄▆▆▆
wandb:      train/ensemble_f1 ▅▄▄▄▄▄▁▅▂▇▃▄█▃▃▄▆▃▆▅▁▃▇▆▆▅▁▅▄▅▅▄▅▄▃▇▄▆▄▄
wandb:         train/mil_loss ▇▆▅▅▆▆▄▅▁▄▄▅██▆▃█▃▄▅▆▅▇▆▃▆▆▂▃▇▆▆▅▆▄▄▅▃▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83817
wandb: best/eval_avg_mil_loss 0.365
wandb:  best/eval_ensemble_f1 0.83817
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.46571
wandb:       eval/ensemble_f1 0.78993
wandb:            test/avg_f1 0.75142
wandb:      test/avg_mil_loss 0.64106
wandb:       test/ensemble_f1 0.75142
wandb:           train/avg_f1 0.79491
wandb:      train/ensemble_f1 0.79491
wandb:         train/mil_loss 1.02249
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh9n1pbl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061825-lh9n1pbl/logs
wandb: Agent Starting Run: 3dq5xvci with config:
wandb: 	actor_learning_rate: 2.46179434474149e-06
wandb: 	attention_dropout_p: 0.4569873040075996
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39905695719498846
wandb: 	temperature: 9.422164437380117
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062101-3dq5xvci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dq5xvci
wandb: uploading history steps 44-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▅▅█
wandb: best/eval_avg_mil_loss ▇▅█▄▆▁
wandb:  best/eval_ensemble_f1 ▁▁▄▅▅█
wandb:            eval/avg_f1 ▂▄▅▃▅▂▅▁▃▃▃▃▅▆▅▃▄▃▅▅▆█▃▅▄▅▅▄▂▂▃▄▃▆▅▁▃▂▅▄
wandb:      eval/avg_mil_loss ▄▃▅▃▅▅▃▃▃▅█▄▃▂▃▃▄▄▃▅▄▂▁▁▃▃▅▃▂█▂▃▅▃▂▃▅▅▃▁
wandb:       eval/ensemble_f1 ▂▂▄▅▃▅▂▅▂▃▁▃▃▅▆▅▃▅▃▅▅▃▆█▅▅▅▄▃▂▃▄▄▆▅▂▄▂▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▄▁▅▅▄█▅▅▄▄▂▄▁▄▂▂▆▃▂▁▆▅▅▃▃▂▃▅▅▄▆▅▅▄▂▅▃
wandb:      train/ensemble_f1 ▂▂▄▄▁▅▅▄█▅▅▄▄▂▄▄▂▂▄▆▃▂▁▃▆▆▅▃▃▂▂▅▄▆▅▅▄▂▅▃
wandb:         train/mil_loss ▃▆▄▇▇▁▃▂█▄▂▅▆▂▂▅▁▂▄▅▅▃▃▃▂▂▅▇▄▄▆▃▄▇▂▆▁▃▄▂
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.39469
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.79808
wandb:      eval/avg_mil_loss 0.38731
wandb:       eval/ensemble_f1 0.79808
wandb:            test/avg_f1 0.81854
wandb:      test/avg_mil_loss 0.44609
wandb:       test/ensemble_f1 0.81854
wandb:           train/avg_f1 0.7968
wandb:      train/ensemble_f1 0.7968
wandb:         train/mil_loss 0.79258
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dq5xvci
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062101-3dq5xvci/logs
wandb: Agent Starting Run: fuiprpm4 with config:
wandb: 	actor_learning_rate: 9.951127144300932e-06
wandb: 	attention_dropout_p: 0.38267827687153544
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22380199965479963
wandb: 	temperature: 7.542860057513248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062158-fuiprpm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fuiprpm4
wandb: uploading history steps 57-72, summary; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 57-72, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▃█▃▄▅▃▆▃▄▃▆▅▄▅▇▃▅▇▆▃▄▆▃▂▄▁▄▆▃▅▅▃▁▄▅▄▃▅▆▆
wandb:      eval/avg_mil_loss ▆▁▃▄▃▄▇▅▃▆█▆▅▆▂█▆█▆▄██▄▅█▆▆▄▂▅▃▇▃▆▄▅▄▁▆▆
wandb:       eval/ensemble_f1 ▃█▄▃▄▅▆▅▃▃▆▃▅▅▄▅▅▇▄▁▃▅▅▄▃▄▆▂▅▅▁▅▄▃▅▇▅▆▃▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▃▅▄▅█▆▄▆▃▄▄▃▁▄▆▇▃▃▆▄▂▁▅▄▃▃▂▄▄▇▇▃▃▅▃▅▆
wandb:      train/ensemble_f1 ▄▅▅▅▅▂▄█▆▄▆▆▄▁▄▅▅▆▃▆▆▂▃▃▆▅▄▃▃▄▅▅▆▄▅▁▅▅▄▆
wandb:         train/mil_loss ▆▄▅▇▅▅▅▃█▃▅▄▄▅▆█▄▄▅▄▄▄▃▃▆▄▂▅▃▅▂▄▅█▃▄▄▆▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁██████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85647
wandb: best/eval_avg_mil_loss 0.31165
wandb:  best/eval_ensemble_f1 0.85647
wandb:            eval/avg_f1 0.82808
wandb:      eval/avg_mil_loss 0.45449
wandb:       eval/ensemble_f1 0.82808
wandb:            test/avg_f1 0.80565
wandb:      test/avg_mil_loss 0.46002
wandb:       test/ensemble_f1 0.80565
wandb:           train/avg_f1 0.81506
wandb:      train/ensemble_f1 0.81506
wandb:         train/mil_loss 0.59039
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fuiprpm4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062158-fuiprpm4/logs
wandb: Agent Starting Run: 9j96y5z1 with config:
wandb: 	actor_learning_rate: 0.00021077856076934945
wandb: 	attention_dropout_p: 0.4062631765403543
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5897798821218809
wandb: 	temperature: 3.812481519503568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062320-9j96y5z1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9j96y5z1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss █▂▆▁
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▆▄▄▅▆▅▅▇█▅█▄▃▅▇▂▆▇▅▅▃▄▄▄▃▃▆▄▅▁▆▃▆▅▇▄▅▃▅▄
wandb:      eval/avg_mil_loss ▄▁▅▅▃▇▅▆▅▃▄▃▅▄▄▄▄██▂▃▅▇▇▇▇▅▄▆▃▆▄▄█▂▃▃▅▂▂
wandb:       eval/ensemble_f1 ▆▄▄▅▃▄▄▇█▄█▃▃▃▄▇▃▂▁▄▁▄▃▃▃▆▄▄▅▅▆▅▆▂▄▅▂▄▄▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▄▆▄▁▅▅▆▆▅▅▅▆▂▂▃▆▆▃▆▄▄▂▆▆▅▃▄▆▂▄▄██▄▆▃▅
wandb:      train/ensemble_f1 ▆▄▇▄▅▃▅▅▃▁▃▆▁▇▄▄▆▄▁▁▃▅▆▄▂▁▅▆▆▂▃▃▁█▅▄▆█▂▄
wandb:         train/mil_loss ▄▃▃▄▁▅▇▆▃▇▃▂▅▇▅█▃▄▆▇█▄▁▃▁▅▅▄▅▂▄▄▄▄▄▁▅▆▄▁
wandb:      train/policy_loss ███████████████▃█████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▃███████████████████████▁███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.38553
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.82011
wandb:      eval/avg_mil_loss 0.40074
wandb:       eval/ensemble_f1 0.82011
wandb:            test/avg_f1 0.79594
wandb:      test/avg_mil_loss 0.46687
wandb:       test/ensemble_f1 0.79594
wandb:           train/avg_f1 0.80391
wandb:      train/ensemble_f1 0.80391
wandb:         train/mil_loss 0.57064
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9j96y5z1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062320-9j96y5z1/logs
wandb: Agent Starting Run: kz3y0sv2 with config:
wandb: 	actor_learning_rate: 4.520138896472358e-06
wandb: 	attention_dropout_p: 0.3330683267811347
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8774666394272624
wandb: 	temperature: 9.791566778344922
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062433-kz3y0sv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kz3y0sv2
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 143-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄█
wandb: best/eval_avg_mil_loss ▄▁▄█
wandb:  best/eval_ensemble_f1 ▁▂▄█
wandb:            eval/avg_f1 ▆▅▂▆▄▂▆▃▄▆▅▃▅▅▁▁▄▅█▃▃▁▇▄▆▄▄▄▄▆▅██▄▂▇▄▅▅▃
wandb:      eval/avg_mil_loss ▅▃▁▄▄▅▅▂▂▅▃▆▇▄▃▄▄▅█▄▅▅▃▂▅▁▅▄▄▂▃▃▅▂▅▅▁▅▅▃
wandb:       eval/ensemble_f1 ▅▆▅▆▃▅▆▅▃▂▄▅▅▃▆▄▄▅▅▁▄▅▄▇▂▅▄▇▆▃▄█▄█▃▇▂▅▄▅
wandb:           train/avg_f1 ▄▄▃▂▆▅▂▅▄▃▅▄▄█▃▄▁▃▂▂▃▂▄▂▃▃▄▅▃▄▆▄▃▃▂▃▅▄▃▄
wandb:      train/ensemble_f1 ▂▄▅▂▁▄▃▂▂▃▄▄▁▅█▅▄▅▃▄▃▂▃▅▂▂▃▁▃▅▆▅▂▂▃▄▃▄▃▄
wandb:         train/mil_loss ▆█▅▄▄▇▆▅▄▄▅▄▃▃▇▃▇▂▄▄▅▅▆▄▃▅▄▅▄▃▃▂▅▅▁▃▄▃▁▃
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83817
wandb: best/eval_avg_mil_loss 0.46073
wandb:  best/eval_ensemble_f1 0.83817
wandb:            eval/avg_f1 0.80266
wandb:      eval/avg_mil_loss 0.40899
wandb:       eval/ensemble_f1 0.80266
wandb:           train/avg_f1 0.80483
wandb:      train/ensemble_f1 0.80483
wandb:         train/mil_loss 0.95166
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kz3y0sv2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062433-kz3y0sv2/logs
wandb: ERROR Run kz3y0sv2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: heud6rav with config:
wandb: 	actor_learning_rate: 1.2557181153536043e-05
wandb: 	attention_dropout_p: 0.16020161256192517
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17858409077708415
wandb: 	temperature: 9.815877183801868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062723-heud6rav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/heud6rav
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▄▄▆▇▇█
wandb: best/eval_avg_mil_loss █▆▅▆▅▄▃▂▁▄▃
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▄▄▆▇▇█
wandb:            eval/avg_f1 ▄▁▅▄▂▂▃▅▃▄▄▂▄▂▃▅▆▄▂▃▅▄▃▄▅▄▂▂▃▃▅▆▅▃▄▂▁▄█▅
wandb:      eval/avg_mil_loss ▇▅▄▄▆▅▃▅███▄▄▄▂▃▄▄▂▅▇▄▁▄▄▅▅▁▅▄▂▃▄▅▅▄▇▅▄▄
wandb:       eval/ensemble_f1 ▁▄▃▁▆▂▅▄▄▃▃▅▂▆▆▃▄▄▆█▆▄▇▅▆▅▄▃▂▇▄▃▅▄▃▁▅▅▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▆▃▅▃▆▂▆▃▄▄▄▇▇▆▃▅▅▃▁▆▂▇▄▅▄▂▁▅▅▅▁▂▇▂▅█▁
wandb:      train/ensemble_f1 ▅▃▂▇▂▃▃▄▄▅▄▄▃▃▃▅█▃▅▅▅▄▇▃▄▄▂▆▃▃▃▁▇▂▃▆▃▆▆█
wandb:         train/mil_loss ▄▄▆▇█▄▁▄▃▇▄▅▃▃▃▄█▄▂▅▂▂▄▅▆▅▃▃▆▃▆▃▂▅▃▄▄▃▆▃
wandb:      train/policy_loss █▄▁██▁▄▄▁▄▄▄▄▁▁██▁▁██▄▁█▄▄▄▁▁▄█▄▄█▁▄▄█▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅█▅▅█▅▅█▅▅▅▅█▅▅▅▁█▁▁█▅▅█▅█▁▅▅█▁▁▅▁▁▅▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84992
wandb: best/eval_avg_mil_loss 0.44411
wandb:  best/eval_ensemble_f1 0.84992
wandb:            eval/avg_f1 0.80266
wandb:      eval/avg_mil_loss 0.44063
wandb:       eval/ensemble_f1 0.80266
wandb:            test/avg_f1 0.76396
wandb:      test/avg_mil_loss 0.523
wandb:       test/ensemble_f1 0.76396
wandb:           train/avg_f1 0.77808
wandb:      train/ensemble_f1 0.77808
wandb:         train/mil_loss 0.52499
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/heud6rav
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062723-heud6rav/logs
wandb: Agent Starting Run: 151ggcwn with config:
wandb: 	actor_learning_rate: 5.5912301105623294e-05
wandb: 	attention_dropout_p: 0.3526568460842181
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18494688738716192
wandb: 	temperature: 7.0336406916672995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063014-151ggcwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/151ggcwn
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▆█
wandb: best/eval_avg_mil_loss ▁▆█▄▅▂▁▄
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▆█
wandb:            eval/avg_f1 ▇▇▇▇▅▇▁▇▇▆▄▄▃▆▄▃▅▅▆▅▄▆▆▅▇█▅█▄▄▆▇▆▄▅▇▇▄▅▄
wandb:      eval/avg_mil_loss ▆▃▃▆▄▆▆▄▆▄▅▇▃▄█▅▆▃▄▅▇▅▇▄▃▅▃▄▂▅▃█▅▁█▄▇▇▅▇
wandb:       eval/ensemble_f1 ▆▅▆▄▃▄▇▅▂█▃▁▄▄▅▂▄▁▄▁▁▃▄▆▅▃▃▃▂▆▅▄▂▆▃▄▄▆▃▄
wandb:           train/avg_f1 ▆▁▄▆▃▆▅▄▄█▃▃▄▆▇▅▆▅▆▄█▇▅▅▃▃▃▄▆▂▅▆▄▄▄▄▅▄▃▄
wandb:      train/ensemble_f1 ▅▁▅▇▆▄▆▄▇▂▅▃▆▇▃▇▇▆▃▆▃▇▇▅█▄▃▇▆█▆▃▄█▆▄▂▄▅▄
wandb:         train/mil_loss ▅▄▆▅▄▆▅▆▆▆▆▁▄▄▄▄▇▆▅▆▆▇▇▇▄▇▆█▅▄▃▃▂▅▅▃▃▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83559
wandb: best/eval_avg_mil_loss 0.42587
wandb:  best/eval_ensemble_f1 0.83559
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.52928
wandb:       eval/ensemble_f1 0.76597
wandb:           train/avg_f1 0.78445
wandb:      train/ensemble_f1 0.78445
wandb:         train/mil_loss 0.8953
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/151ggcwn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063014-151ggcwn/logs
wandb: ERROR Run 151ggcwn errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 931ju4fi with config:
wandb: 	actor_learning_rate: 0.0006476692932926784
wandb: 	attention_dropout_p: 0.4323108039829737
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8053547670838347
wandb: 	temperature: 3.201383490724531
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063308-931ju4fi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/931ju4fi
wandb: uploading history steps 72-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss ██▇▁
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 ▆▅▁▅▂▂▆▃▂█▆▄▅▇▄▆▄▂▆▂▅▃▅▂▆▆▇▅▅▇▅▃▆▅▄▂▆▃▂▄
wandb:      eval/avg_mil_loss ▅▆▆▆▆▄▆▅▅▅█▄▆▃▅▅▂▃▂▆▆▄▃▅▃▁▃▆▅▂▅▃▄▄▅▅▅▄▅▄
wandb:       eval/ensemble_f1 ▂▅▁▅▅▆▃▁▄▅▄▄▅▆▄▆▅▅▆▄█▆█▅▅▅▆▇▅▅▇▄▅▃▆▅▄▄▂▄
wandb:           train/avg_f1 ▅▅▆▄▇▃▆▅▆▅▆▄▆▅▂▄▆▇▆▇▅▄██▆▆▇▆▅▆▅▅▄▃▇▅▄█▁▅
wandb:      train/ensemble_f1 ▅█▆▃▆▆▅▇▆▆▇▄▆▅▃▇▅▄█▇█▆▄▆▅▇▇▅▅▅▃▇█▆▅▁▆▆█▇
wandb:         train/mil_loss ▅▂▄▂▄▃▁▂▃▅▃▆▄▄█▅▃▁▃▄▅▃▄▅▂▁▃▂▁▃▂▁▄▂▂▂▂▂▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83439
wandb: best/eval_avg_mil_loss 0.39699
wandb:  best/eval_ensemble_f1 0.83439
wandb:            eval/avg_f1 0.78609
wandb:      eval/avg_mil_loss 0.45301
wandb:       eval/ensemble_f1 0.78609
wandb:           train/avg_f1 0.80224
wandb:      train/ensemble_f1 0.80224
wandb:         train/mil_loss 0.93845
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/931ju4fi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063308-931ju4fi/logs
wandb: ERROR Run 931ju4fi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hclixsqo with config:
wandb: 	actor_learning_rate: 5.914510853562371e-05
wandb: 	attention_dropout_p: 0.22600975984982105
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28574576652957595
wandb: 	temperature: 7.726110741157771
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063433-hclixsqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hclixsqo
wandb: uploading history steps 160-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆█
wandb: best/eval_avg_mil_loss █▂▁▃▁
wandb:  best/eval_ensemble_f1 ▁▅▅▆█
wandb:            eval/avg_f1 ▆▃▆▃▄▇█▆▆▅▂▅▄▅▂▆▃▆▇▃▆▅▇▇▄▅▇▅▅▄▆▂▄▃▄▃▆▄▄▁
wandb:      eval/avg_mil_loss ▄█▄▄▄▅▃▇▃▅▅▃▆▅▃▄▇▁▆▃▅▇▇▆▃▅▄▆▆▆█▅█▆▅▆▂▄▄▄
wandb:       eval/ensemble_f1 ▇▆▆▁▃█▆▅▅▅▇▁▇▃▅█▅▆▅▅▃▄▅▇▄▃▂▅▆▆▃▄█▆▄▁▄▆▄▄
wandb:           train/avg_f1 ▆▅▅▇▆▆▄▅▆▇▄▆▆▅▃▅▁▅▆▅▅▅▅▅▆▆▂▁▁█▆▄▆▃▂▆▃▆▇▁
wandb:      train/ensemble_f1 ▄▅▄▅▅▂▆▆▇▃█▃▆▇█▅▄▄▅▁▆▅▂▃▄▄▂▂▇▆▄▄▅▄▅▅▁▃▄▆
wandb:         train/mil_loss ▆▅▇▇█▅▆▆▂▆▄▅▆▃▁▄▄▂▃▅▅▃▃▄▄▂▆▇▇▄▃▅▇▅▅▄▅▇▃▅
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁███▁█▄▄██▁▁▄▁▁▄█▁█▁▄▄█▄██▁█▄██▁▁▄█▁▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8493
wandb: best/eval_avg_mil_loss 0.39453
wandb:  best/eval_ensemble_f1 0.8493
wandb:            eval/avg_f1 0.797
wandb:      eval/avg_mil_loss 0.44909
wandb:       eval/ensemble_f1 0.797
wandb:           train/avg_f1 0.77854
wandb:      train/ensemble_f1 0.77854
wandb:         train/mil_loss 0.9806
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hclixsqo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063433-hclixsqo/logs
wandb: ERROR Run hclixsqo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o5l8vugq with config:
wandb: 	actor_learning_rate: 2.0183424795667676e-05
wandb: 	attention_dropout_p: 0.25681844332071047
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33985806655418216
wandb: 	temperature: 4.669701639470377
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063810-o5l8vugq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5l8vugq
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ▇▆▇▃█▆▆▁
wandb:  best/eval_ensemble_f1 ▁▂▅▆▆▇▇█
wandb:            eval/avg_f1 ▃▄▇▅▅▅▃▆▁▄▇▆▆▃▆▅▂▃▆▄▅▄▆▅▁▆▄▆▆▆▇▇▄█▆▄▇█▅▃
wandb:      eval/avg_mil_loss ▁▃▄▂▅▂▂▅▅▃▂▂▃▄▂▃▆▅▄▅▄▂▄▅▃▄▃▄▃▄▃▃▆▂▁▂█▄▂▂
wandb:       eval/ensemble_f1 ▄▆▄▃▄▄▃▇▆▅▆▅▅▇▂▆▄▅▂▃▆▄▅▆▄▄▅▁▄▅▆▅▆▂▆█▆▄▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▅▄▄▃▇▅▆▅▅▇▅▄▃▃▄▄▇█▂▆▂▄▅▆▅▃▆▅▇▆▆▄▆▆▇▃▇▅
wandb:      train/ensemble_f1 ▆▁▆▂▅▂▄▅▇▅██▃▅▄▅▇▃▄▇▃▂▃▅▆▄▆▆▃▆▃▃▆▇▃▅▃▄▆▅
wandb:         train/mil_loss ▅▆▃▇▃▄▆▅▄▄▄▆▄▅▄▇▄▃▃▃▄▆▃▇▃▅▃▅▁▁▄▂▅▂▃▄▄▄▂█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85247
wandb: best/eval_avg_mil_loss 0.31217
wandb:  best/eval_ensemble_f1 0.85247
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.3695
wandb:       eval/ensemble_f1 0.78993
wandb:            test/avg_f1 0.76975
wandb:      test/avg_mil_loss 0.48054
wandb:       test/ensemble_f1 0.76975
wandb:           train/avg_f1 0.81186
wandb:      train/ensemble_f1 0.81186
wandb:         train/mil_loss 0.91526
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5l8vugq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063810-o5l8vugq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7lo89og3 with config:
wandb: 	actor_learning_rate: 0.0004361081684738414
wandb: 	attention_dropout_p: 0.1930354116806438
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.644992633424962
wandb: 	temperature: 8.709440996336351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064015-7lo89og3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lo89og3
wandb: uploading wandb-summary.json
wandb: uploading history steps 99-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄█
wandb: best/eval_avg_mil_loss ▁▇█▇▁
wandb:  best/eval_ensemble_f1 ▁▁▂▄█
wandb:            eval/avg_f1 ▇▇▄▄▅▇▆▆▅▄▄▃▁▃▄▅▂▄▃▃▄▃▆▇▄█▅▃▅▇▃▇▅▆▄▆▅▅▅▄
wandb:      eval/avg_mil_loss ▁▅▄▃▄▆▃▄█▃▄▃▁▅▄▅▅▃▃▄▅▅▆▄▄▃▆▃▄▅▃▂▄▃▃▃▄▃▅▄
wandb:       eval/ensemble_f1 ▇▅▇▇▄▇▄▂▇▇▃▅▆▅▄▆▃▃▃▁▅▆▂▄▄▇▅▅▃▇▅▆▃▃▄▂▄█▅▃
wandb:           train/avg_f1 ▆▃▃▄▃▄▄▃▃▅▅▄▄▄▅▆▄█▄▃▁▄▅▅█▄▃▃▅▂▁▄▄▇▃▆▅▄▄▅
wandb:      train/ensemble_f1 ▆▁▃▄▅▁▂▃▅▅▃▅▄▅▄▄▅▄█▅▄▆▅▄▆▅▆▅▅▃▄▄▂▅▃▅▄▄▂▄
wandb:         train/mil_loss ▃▅▇▅▄█▄▂▆▃▅▅▃▃▆▅▄▄▆▁▃▃▄▅▅▄▁▃▆▆▃▂▄▄▄▄▆▂▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.35353
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.77353
wandb:      eval/avg_mil_loss 0.47789
wandb:       eval/ensemble_f1 0.77353
wandb:           train/avg_f1 0.79451
wandb:      train/ensemble_f1 0.79451
wandb:         train/mil_loss 0.88604
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lo89og3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064015-7lo89og3/logs
wandb: ERROR Run 7lo89og3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0of6iu5d with config:
wandb: 	actor_learning_rate: 2.097169717184536e-06
wandb: 	attention_dropout_p: 0.31340350011156903
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5162390072682925
wandb: 	temperature: 3.6135859708196216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064213-0of6iu5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0of6iu5d
wandb: uploading history steps 128-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▆█
wandb: best/eval_avg_mil_loss █▂▂▁▂
wandb:  best/eval_ensemble_f1 ▁▅▆▆█
wandb:            eval/avg_f1 ▃▂▁▄▄▂▅▃▄▄▇▄▃█▆▂▅▃▅▄▂▂▃▄▅▆▁▆▄▂▃▃▃▁▅▅▆▂▃▄
wandb:      eval/avg_mil_loss ▂▂▃▁▃▃▁▄▃▃▂▂▃▃▅▃▄▁▂▃▃▄▄█▄▃▄▃▂▂▅▃▂▃▂▂▃▃▃▅
wandb:       eval/ensemble_f1 ▃▂▅▅▂▆▃▇▁▄▆▅▇▂▆▇▆▆▃▄▄▅▅▄▆▄▆▅▇▅▆▄▅▃▁█▄▄▃▅
wandb:           train/avg_f1 ▇▁▅▅▃▃▃▇▅▃▁▅▄▆▆▂▃▅▇▃▄▂▃▇▂█▅▂▆▆▆▂▃▆▇▃▆▃▁▃
wandb:      train/ensemble_f1 █▆▄█▃▄▆▅▄▅▅▇▃▇▇▄▅▅▅▄█▄▄▅▄▇▇▇▄▁▆▅▇▇▆▇▄▃▇▃
wandb:         train/mil_loss ▇▇▆▅▆▇▄▆▅▆▅▄▄█▄▄▆▃▅▄▃▄▇▆▃▂▅▃▁▄▂▄▅▅▅▄▁▃▄▂
wandb:      train/policy_loss ▆▁▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▇▇▇▇▇▇▇▇▇▇▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.40438
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.79882
wandb:      eval/avg_mil_loss 0.51525
wandb:       eval/ensemble_f1 0.79882
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 0.52068
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0of6iu5d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064213-0of6iu5d/logs
wandb: ERROR Run 0of6iu5d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: benk1yho with config:
wandb: 	actor_learning_rate: 5.527125683935725e-05
wandb: 	attention_dropout_p: 0.07191464283823917
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8179861764723424
wandb: 	temperature: 5.0353101483172935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064442-benk1yho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/benk1yho
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss ▂█▁▇
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▅▄▇▃▂▂▆▆▄▃▃▇▄▇▆▇▅▅▅▇▅▇▇▄▄▂█▆▅█▅▁▆▃▄▅▆▆▅▇
wandb:      eval/avg_mil_loss ▂▅▄▃▇▄▄▄▄▃▅▄▅▄▆▄▅▅█▆▁▃▂▄▅▄▆▃█▅▆▃▁▅▆▄▅▃▄▂
wandb:       eval/ensemble_f1 ▆▇▇▃▂▂▆▅▆▅▃▄▆▃▇▆▇▅▅▇▅▇▄▄▅▂█▅▅█▅▁▆▆▃▄▅▆▆▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂█▆▇▂▅▅▂▄▃▅▃▃▄▅▆▄▇▄▅▇█▁▄█▆▃▄▃▂▇▇▄▂██▅▆
wandb:      train/ensemble_f1 ▄▁█▆▂▂▆▁▅▁▁▅▅▅▃▃▂█▃▅▇▄▄▄█▆▂▄▇▄▆▃▂▇▃▂█▃▄▆
wandb:         train/mil_loss ▅▄▃▄▆▅▃▅▅▆▆█▄▅▃▄▂▄▁▃▃▅▅▆▆▆▆▆▅▄▆▄▃▃▅▁▅▃▇▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82388
wandb: best/eval_avg_mil_loss 0.45849
wandb:  best/eval_ensemble_f1 0.82388
wandb:            eval/avg_f1 0.81673
wandb:      eval/avg_mil_loss 0.39494
wandb:       eval/ensemble_f1 0.81673
wandb:            test/avg_f1 0.79632
wandb:      test/avg_mil_loss 0.53637
wandb:       test/ensemble_f1 0.79632
wandb:           train/avg_f1 0.80676
wandb:      train/ensemble_f1 0.80676
wandb:         train/mil_loss 0.61293
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/benk1yho
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064442-benk1yho/logs
wandb: Agent Starting Run: 63r5syxc with config:
wandb: 	actor_learning_rate: 1.4952699079472544e-06
wandb: 	attention_dropout_p: 0.02254830223188453
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8678030819170599
wandb: 	temperature: 9.908615621270991
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064555-63r5syxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63r5syxc
wandb: uploading history steps 110-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄█
wandb: best/eval_avg_mil_loss █▆▅▆▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄█
wandb:            eval/avg_f1 ▅▅▆▄▄▆█▅▆▅▆▃▂▄▆▅▄▅▄▆▄▄▄▄▄▆▁▆▆▅▄▇▇▆▅▇▅▃▅▂
wandb:      eval/avg_mil_loss ▆▅▃▁▄▂▄▅▅▂▆▆▃▃▅▂▂▇▃▅▅▆▅▃▅▂▇▇▅▅▃▂▄▅▂▇▅▆▃█
wandb:       eval/ensemble_f1 ▅▄▆▃▅▃▆▃▄▅▆▆▂▂▄▅▄▆▁▅▃▃▄▅▇▆▅▅▇▃█▃▄▄▃▄▇▄▂▅
wandb:           train/avg_f1 ▁▂▄▆▄▅▅▆▃▂█▅▅▅▇▄▅▇▆▆▅▇▄▆▂▄▃▃▃▅▄▇▇▅▁▅▅▆▄▂
wandb:      train/ensemble_f1 █▄▄▅▅▅▄▁▄▅▅▄▂▆▆▃▄▇▄▄▄▄▄▄▅▄▂▅▂▂▃▄▄▃▄▂▄▃▄▄
wandb:         train/mil_loss ▇▇▅█▃▆█▆█▆▅▄▄▃█▃▄▄▆▄▄▃▆▅▇▄▆▄▅▇▁▄▆▇▄█▆▆▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.38176
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.79808
wandb:      eval/avg_mil_loss 0.45142
wandb:       eval/ensemble_f1 0.79808
wandb:           train/avg_f1 0.78334
wandb:      train/ensemble_f1 0.78334
wandb:         train/mil_loss 0.95703
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63r5syxc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064555-63r5syxc/logs
wandb: ERROR Run 63r5syxc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7i5e7nqc with config:
wandb: 	actor_learning_rate: 8.033187984703708e-06
wandb: 	attention_dropout_p: 0.44504025578562834
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44956346630870714
wandb: 	temperature: 8.465640762721304
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064830-7i5e7nqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i5e7nqc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 42-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▁▇▃▅
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▆▃▅▁▁▃▃▆▂▂▄▆▇█▆▆▆▅▇▅▃▄▅▇▇▆▃▅▆▂▂▆▄▆▆█▄█▅▄
wandb:      eval/avg_mil_loss ▅▃▆▄▃█▁▃▆▃▃▅▃▄▇▂▆▄▅▅▆▁▃▃▂▂▃▆▃▅▃▃▄▆▂▃▄▄▇▃
wandb:       eval/ensemble_f1 ▃▅▁▅▃▃▆▃▂▄▇█▆▃▆▅▇▅▁▃▅▇▄▇▆▅▆▂▆▂▄▆▃▆██▄█▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▁▅▄█▅▆▄▂▅▃▅▃▇▁▆▆▄▂▇▇▅▄▃▅▅▄▅▅▅▆▇▅▃▅▆▆▁▅
wandb:      train/ensemble_f1 ▃▁▄▄▅▄▅▆▄▄█▄▃▆▃▅▂▅▃▂▆▆▄▃▃▄▄▅▅▆▅▆▄▃▂▄▅▅▁▄
wandb:         train/mil_loss ▃▃▁▃▄▄▃▃▆▄▂▆▅▄▄▄▃▅▂▂▄▁▄▄▁▃▅▆▅▅▅▁█▃▆▅▆▆▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8348
wandb: best/eval_avg_mil_loss 0.40892
wandb:  best/eval_ensemble_f1 0.8348
wandb:            eval/avg_f1 0.79453
wandb:      eval/avg_mil_loss 0.39308
wandb:       eval/ensemble_f1 0.79453
wandb:            test/avg_f1 0.79863
wandb:      test/avg_mil_loss 0.45095
wandb:       test/ensemble_f1 0.79863
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 0.79692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i5e7nqc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064830-7i5e7nqc/logs
wandb: Agent Starting Run: 4g0uz9x7 with config:
wandb: 	actor_learning_rate: 1.080129141689561e-05
wandb: 	attention_dropout_p: 0.24043351517525616
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.36693036252514144
wandb: 	temperature: 4.5491379103783345
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064932-4g0uz9x7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g0uz9x7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▆▇█
wandb: best/eval_avg_mil_loss ▅▆▄▆█▁
wandb:  best/eval_ensemble_f1 ▁▂▆▆▇█
wandb:            eval/avg_f1 ▂▁▄▃▄▄▆▁▆▃▃▃▅▇▁▄▃▆▆▂▄▆▄▄▂▆▆▃▆▆▄▅█▄▃▂▆▂▅▂
wandb:      eval/avg_mil_loss ▄▅▆▃▅▆▄▅▄▃▃▆▆▆▃▄▃▄▅▇▁▄▃█▄▅▇█▆▁▄▂▆▇▆▃▄▇▄█
wandb:       eval/ensemble_f1 ▆▇▆▁▄▄▅▆█▇▂▅▂▅▅██▇▄▆▆▅▅▃▃▅▆▆▄▇█▆▂▄▅▇▇▅▃▃
wandb:           train/avg_f1 ▁▄▂▅▅▄▃▃▆▆▅█▇▄▇█▃▆▄▅▆▃▄▅▅▅▄▆▄▃▅▅▅▃▇▆▃▄▄▇
wandb:      train/ensemble_f1 ▆▄▆▃▅▆▅▂▃▂▂▇▄█▆▆▄▃▅▃▃▆▅▄▆▅▆█▅▅▇▂▇▆▇█▁▃▂▂
wandb:         train/mil_loss ▅█▅▅▅▁▃▅▃▅▂▄█▅▅▃▅▃▅▅▅▇▃▅▂▄▄▅▅▅▂▃▄▃▄▅█▃▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84911
wandb: best/eval_avg_mil_loss 0.29582
wandb:  best/eval_ensemble_f1 0.84911
wandb:            eval/avg_f1 0.7796
wandb:      eval/avg_mil_loss 0.55434
wandb:       eval/ensemble_f1 0.7796
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 1.04811
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g0uz9x7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064932-4g0uz9x7/logs
wandb: ERROR Run 4g0uz9x7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: c19j8d4v with config:
wandb: 	actor_learning_rate: 0.0001980558358184728
wandb: 	attention_dropout_p: 0.42222804819807
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6287252685648426
wandb: 	temperature: 3.181834864951183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065202-c19j8d4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c19j8d4v
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss ▆█▇▁
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▅▃▅▄█▆▅▃▆▃▅▂▅▆▃▂▆▃▅▅▂▃▂▁▄▄▃▂▁▂▄▅▄▅▃▄█▄▂▅
wandb:      eval/avg_mil_loss ▄▂▅▅█▆▂▄▅▃▅▄▃▃▄▁▇▆▅▂▆▄▇▅▄▄▆▆▃▅▂▄▆▆▅▂▇▆▄▄
wandb:       eval/ensemble_f1 ▅▄▂▅▄▂▅▄▆▅▄▅▅▂▅▆▃▃▆▃▅▅▃▄▂▅▂▄▄▂▂▆▄▅▃▄█▄▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▇▅▃▆▅▆▃▂▄▆▄▂▄▆▂▅▃▄▃▄▂▁▄█▄▅▄▃▃▄▂▇▄▄▆▃▇▄
wandb:      train/ensemble_f1 ▅▃▇▅▄▄▃▅▆▇▅▄▆▄█▄▄▃▄▆▄▃▆▅▄▃▅▃▄▁▂█▃▅▃▆▃▃█▄
wandb:         train/mil_loss ▅▂▅▂▃▃▄▄▄▃▁▃▃▃▅▃▁▄▂▃▄▇▂▆▁▂▄█▃▃▄▅▃▃▃▃▃▃▄▄
wandb:      train/policy_loss ▁▁▁█▁▁▁█▁▁▅▅█▅▅▅█▅▅▅▁▁█▁▁▅▅█▁▅▁▁▅▁▅▅▅▅▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁██▁▅▅▁▅▁▁▅█▅▅▁▅▅▅▅▅▅▁▁▁▅▅█▁▁▁▅▁▅▁▅█▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.39411
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.78045
wandb:      eval/avg_mil_loss 0.44936
wandb:       eval/ensemble_f1 0.78045
wandb:            test/avg_f1 0.79264
wandb:      test/avg_mil_loss 0.51658
wandb:       test/ensemble_f1 0.79264
wandb:           train/avg_f1 0.79726
wandb:      train/ensemble_f1 0.79726
wandb:         train/mil_loss 0.56583
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c19j8d4v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065202-c19j8d4v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8t1bqn58 with config:
wandb: 	actor_learning_rate: 3.0864903179165715e-05
wandb: 	attention_dropout_p: 0.2932568658567633
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.373002710407901
wandb: 	temperature: 3.546095128744138
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065332-8t1bqn58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8t1bqn58
wandb: uploading wandb-summary.json
wandb: uploading history steps 97-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄█
wandb: best/eval_avg_mil_loss ▅█▁▁
wandb:  best/eval_ensemble_f1 ▁▄▄█
wandb:            eval/avg_f1 ▆▃▅▃▄▅▃▄▂▃▅▇▅▄▅▂▃▄▅▄▇▄▅▁▁█▄▄▄▆▃▆▆▄▄▅▅▅▄▄
wandb:      eval/avg_mil_loss ▃▆▃▅▇▇▇▅▅▆▆▁▆▅▆▅▅▆▆▇▇▅█▃▂▆▅▅▄██▅▃▄▅▆▂▄▆▂
wandb:       eval/ensemble_f1 ▆▇▄▅▅▆▃▅▄▆▄▄▆█▅▆▆▆▃▇▆▁▇▅▁▄▄▆▅▇█▅▄▅▅▆▆█▆▆
wandb:           train/avg_f1 ▃▇▁▅▃▅▅▆▆▆▃▅▆▃▃▅▂▅▄▃▃▅▅▄▆▃▄▄▃▄▄▁▃▅▂▄▄▅█▆
wandb:      train/ensemble_f1 ▇▁▃▃▅▆▆▅▅▃▃▅▄▅▄▃▅▃▄▂▄▅▃▆▆▄▃▄▄▃▆▃▃▅▄▅▄▂█▆
wandb:         train/mil_loss ▆▇▆▄▃▆▇▅█▃▃▄▄▇▄▄▅▅▂▇█▆▅▅▅▇▆▄▃▄▅▁▄▆▅▄▆▁▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.38759
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.7876
wandb:      eval/avg_mil_loss 0.45528
wandb:       eval/ensemble_f1 0.7876
wandb:           train/avg_f1 0.78724
wandb:      train/ensemble_f1 0.78724
wandb:         train/mil_loss 0.5237
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8t1bqn58
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065332-8t1bqn58/logs
wandb: ERROR Run 8t1bqn58 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 66umpcxx with config:
wandb: 	actor_learning_rate: 0.00034342152749521044
wandb: 	attention_dropout_p: 0.13881948016593043
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6114425842359235
wandb: 	temperature: 7.453754471777558
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065536-66umpcxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66umpcxx
wandb: uploading history steps 181-183, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss █▆▅▃▇▄▄▁▅
wandb:  best/eval_ensemble_f1 ▁▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▆▆▆▃▄▇▂▄█▅▃▅▄▄▄▃▇▃▁█▅▄▆▄▅▅▅▅▆▅▄▄▇▄▃▅▄▆▃▂
wandb:      eval/avg_mil_loss ▄▄▇▇▇▇▇▇▅█▆▄▁▆▄▆▄▃▅▅▅▄▄▅▆▅▅▅▅▄▅▄▄▅▆▅▅▃▆▆
wandb:       eval/ensemble_f1 ▁▆▅▆▆▅▄▂▆▃▇▆▄▆▇█▃▄▃▇▅▆▇▇▄▅▄▅▄▅▄▆▇▃▇▆▅▃▆▄
wandb:           train/avg_f1 ▇▇▆▇▆▂▄█▃▅▅▁██▃▅▅▇▆▄▃▅▆▃▄▆▄▅▂▅▇▆▄▆▃▆▃▆▇▄
wandb:      train/ensemble_f1 ▆▇▆█▆▅▇▅▄▆▇▆▄▇▆▆▃▃▅▄▆▄▆▅▆▆▃▄▄▄▅▅▁▄▄▄▄▇▆▂
wandb:         train/mil_loss ▄▆▆▇█▆▄▅▆▂▃▆▄▁▄▆▄▂▃▅▆▆▅▅▄▄▄▆▅▄▆▆▄▇▃█▃▇█▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84195
wandb: best/eval_avg_mil_loss 0.4325
wandb:  best/eval_ensemble_f1 0.84195
wandb:            eval/avg_f1 0.79022
wandb:      eval/avg_mil_loss 0.45811
wandb:       eval/ensemble_f1 0.79022
wandb:           train/avg_f1 0.78236
wandb:      train/ensemble_f1 0.78236
wandb:         train/mil_loss 0.95534
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66umpcxx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065536-66umpcxx/logs
wandb: ERROR Run 66umpcxx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: r8zt2q8b with config:
wandb: 	actor_learning_rate: 2.8455568801427784e-05
wandb: 	attention_dropout_p: 0.1895514371234885
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.733912486300657
wandb: 	temperature: 0.30900637331922054
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065927-r8zt2q8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r8zt2q8b
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆▆█
wandb: best/eval_avg_mil_loss ▇▃▇▁█▂▂
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆▆█
wandb:            eval/avg_f1 ▆▆▂▃▃▅▇▃▁▇▅▅▅▂▃▆▃▄▃▇▅▃▄▁▆▄▃▆█▅▆▅▆▆▅▄▅▆▄▅
wandb:      eval/avg_mil_loss ▃▂▅▂▅▅█▁▃▄▅▆▄▄▄▄▅▄▁▃▄▅▃▆▆▃▆▂▄▅▅▃▅▂▄▅▄▄▃▃
wandb:       eval/ensemble_f1 ▄▅▂▇▃▃▂▁▆▅▄▅▃▄▅▃▃▆▃▅▃▇▅▁▆▇▃▃▆▅▁▆▅▃▇█▅▄▅▅
wandb:           train/avg_f1 ▄▄▅▄▆█▄▆▃▇▅▄▅▅▅▆▃▁▄▃▆▄▅▃▃▆▆▃▄▅▆█▆▄▂▃▃▆▆▅
wandb:      train/ensemble_f1 ▆▃▄▃▅▄▃█▇▂▄▅▄▅▆▄▂▇▃▃▇▂▃▅▆▄▅▃▅█▃▁▅▂▅▅▂▅▇▅
wandb:         train/mil_loss ▄▃▃▄▄▄▃█▃▅▇▇▆▄▁▄▆▄█▆▃▄▃▅▁▄▅▄▄▅▄▅▅▅▅▄▅▄▄█
wandb:      train/policy_loss █▁▁██▁▄██▁▄▄▁▄▄██▄▁▄███▁▁█▁▁█▁█▁▄██▁█▁█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁██▅█▁██▁▅██▁▅█▁▅█▁▁▁▁█▁▁▁▁█▁████▁█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84532
wandb: best/eval_avg_mil_loss 0.41637
wandb:  best/eval_ensemble_f1 0.84532
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.41833
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.80591
wandb:      train/ensemble_f1 0.80591
wandb:         train/mil_loss 0.8631
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r8zt2q8b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065927-r8zt2q8b/logs
wandb: ERROR Run r8zt2q8b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 799pte77 with config:
wandb: 	actor_learning_rate: 6.1967504308904e-05
wandb: 	attention_dropout_p: 0.26102927305730284
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8930150470286452
wandb: 	temperature: 7.933579385817893
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070126-799pte77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/799pte77
wandb: uploading history steps 96-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃█
wandb: best/eval_avg_mil_loss ▇▂█▅▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃█
wandb:            eval/avg_f1 ▄▅▆▆▃▆▃▄▅▇▂▅▇▅▃▃▂▁▂▁█▄▆▃▂▁▆▂▃▄▁▅▃▅▄▆▂▂▂▃
wandb:      eval/avg_mil_loss ▁▃▂▄▄▄▄▄▂▂▂▆▅▃▁▂▄▄▁▃▅▅▆▄▅▂█▄▄▄▅▂▃▄▄▇▂▂▂▃
wandb:       eval/ensemble_f1 ▆▆▇▆▅▅▆▇▄█▅▆█▇▅▅▆▅▅▁▆▄▅▅▄▆█▆▄▄▆▅▅▄▄▅▄▅█▅
wandb:           train/avg_f1 ▅▇▆▄▃▃▄▅▆▆▃▅▇▄▄▆▃█▇▃▆▃▄▆▅▄▇▆▃▆▇▅▅▆▆▄▁▆▅▇
wandb:      train/ensemble_f1 ▅▆▆▅▅▂▇▂▃▄▆▇▅▅▂▃▂▃▆▂▄▆▂▄█▁▃▃▃▄▅▄▄▇▅▁▂▄▁▅
wandb:         train/mil_loss ▃▄▄▃▁▅▄▃▅▃▃▆▂▅▄▂▅▂▄▇▆▂▂▄▆▅▅▅▆▅█▂▃█▅▅█▆▂▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▂▄█▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▄▁▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▃▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▁▅▅▇▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.40706
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.76163
wandb:      eval/avg_mil_loss 0.48367
wandb:       eval/ensemble_f1 0.76163
wandb:           train/avg_f1 0.80628
wandb:      train/ensemble_f1 0.80628
wandb:         train/mil_loss 0.99802
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/799pte77
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070126-799pte77/logs
wandb: ERROR Run 799pte77 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mhm98c05 with config:
wandb: 	actor_learning_rate: 2.3091439855447767e-06
wandb: 	attention_dropout_p: 0.4267448702077194
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07535362878752905
wandb: 	temperature: 1.4519759639619878
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070346-mhm98c05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mhm98c05
wandb: uploading wandb-summary.json
wandb: uploading history steps 96-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▆█
wandb: best/eval_avg_mil_loss █▇▁▁▄
wandb:  best/eval_ensemble_f1 ▁▂▆▆█
wandb:            eval/avg_f1 ▁▄▇▄▃▂▄▄▂▄▇▆▅▂▅▂▄▄▇▁▃█▂▃▃▄▆▂▃▂▂▃▅▄▅▅▆▁▃▃
wandb:      eval/avg_mil_loss ▅▆▄▁▃▅█▃▅▂▄▅▅▆▄▁▄▂▅▄▂▆▇▂▂▆▂▅▄▅▄▁▃▂▃█▄▆▁▅
wandb:       eval/ensemble_f1 ▂▅▃▃▅▄▃▅▃▄▁▂▄▅▂▅▃▃▄▅▅▄█▃▄▄▆▄▆▅▄▃▃▅▄▆▃▄▂▇
wandb:           train/avg_f1 ▃▂▅▄▅▅▆▇▄▅▃▄▃▅█▂▄█▄▁▃▄▄▆█▅▄▁▄▅▄▃▂▃▇▃▅▂▃▆
wandb:      train/ensemble_f1 ▅▂▄▄▅▅▅▆▆▂▃▃▄▄▄▆▄▅▄▄▄▅▂▇▇▇▄█▅▄▁▅▇▁▅▁▅█▇▄
wandb:         train/mil_loss ▄▄▂▅▅▄▄▄▇▆▄▅▇▅▄▁▆▇▁▂▃▇▆█▆▃▂▅▃▆▅▅▄▆▄▂▄▅▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.40898
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79545
wandb:      eval/avg_mil_loss 0.4444
wandb:       eval/ensemble_f1 0.79545
wandb:           train/avg_f1 0.79497
wandb:      train/ensemble_f1 0.79497
wandb:         train/mil_loss 0.84981
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mhm98c05
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070346-mhm98c05/logs
wandb: ERROR Run mhm98c05 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: exht1k9z with config:
wandb: 	actor_learning_rate: 0.000193747968707792
wandb: 	attention_dropout_p: 0.34671910350467744
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3118572169766598
wandb: 	temperature: 4.920361012095537
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070615-exht1k9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/exht1k9z
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▇█
wandb: best/eval_avg_mil_loss ██▄▁▅
wandb:  best/eval_ensemble_f1 ▁▃▅▇█
wandb:            eval/avg_f1 ▄▃▅▄▃▅▅▄▃▄▁▄▄▇▁▆▇▄▃▃▄▇█▄▆▄▂▅▆▄▂▄▂▅▆▇▃▅▆█
wandb:      eval/avg_mil_loss ▅▅▄▄▅▃▇▂▆▅▃▂▁▄▄▃▃▃▃█▄▂▄▃▇▄▃▂▅▂▃▅▇▂█▅▂▂▅▅
wandb:       eval/ensemble_f1 ▅▅▁▄▅▅▅▄▅▅▃▄▆▇▄▄▇█▄▃▄▄▆▆▅▄▅▆▅▄▅▄▅▇▄▇▆▆▄▄
wandb:           train/avg_f1 █▁▃▄▂▆▅▇▃▂▅▆▇▂▆▄▂█▄▃▃▁▅▄▃▅▇▅█▇▄▁▇▅▆▃▅▁▃▇
wandb:      train/ensemble_f1 ▁▆█▆▂█▄▄▄▅▆▄▆█▃▇█▃▅▆▅█▄▇▂▅▅▇▇▇▂▁▄▅▄▅▄▅▄█
wandb:         train/mil_loss ▂▄▃▁▆▂▄▁▄▁▁▄▂▁▁▅▃▂▃▆▂▃▄█▁▂▄▃▄▄▃▂▄▄▂▄▂▁█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84867
wandb: best/eval_avg_mil_loss 0.41856
wandb:  best/eval_ensemble_f1 0.84867
wandb:            eval/avg_f1 0.80563
wandb:      eval/avg_mil_loss 0.44318
wandb:       eval/ensemble_f1 0.80563
wandb:           train/avg_f1 0.80901
wandb:      train/ensemble_f1 0.80901
wandb:         train/mil_loss 0.86582
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/exht1k9z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070615-exht1k9z/logs
wandb: ERROR Run exht1k9z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: vhz98u4g with config:
wandb: 	actor_learning_rate: 1.1965889530724692e-05
wandb: 	attention_dropout_p: 0.06381761453587714
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5102986332019012
wandb: 	temperature: 1.4487983370353508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070907-vhz98u4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhz98u4g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆█
wandb: best/eval_avg_mil_loss ▆█▆▆▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆█
wandb:            eval/avg_f1 ▆▆▇▄▄▃▅▅▆█▆▆▃▄▆▆▅▇▃▅▃▅▄▆▁▃▄▂▅▅▆▂▅▅▅▃▆▄▅█
wandb:      eval/avg_mil_loss ▇▅▆▄▆▃▅▇▆█▅▂▅▄▅▃▅▅▅▅▄▆▁▄▇▆▄▅▅▆▄▇▅▅▆▃▆▅▂▆
wandb:       eval/ensemble_f1 ▁▄▂▄▃▆▃▇▇▆▇▆▃▃▅▅▆▅▃▅▅▅█▅▅▅▆▆▅▅▅▄▄▅▅▅▅▅▄▅
wandb:           train/avg_f1 ▆▄▂▂▂▂▄▁▅▅▅▄▅▄▂▄▂▆▃▃▄█▂▄▅▃▂▁▃▄▂█▃▃▁▂▃▄▅▄
wandb:      train/ensemble_f1 ▆▆▃▂▃▆▅▅▆▃▄▆▁▃▄▃▄▃▅▄▄▄▅▃▅▄▅▅▆▃▄▃▂█▂▅▅▆▅▄
wandb:         train/mil_loss ▁▅▇▇▅▄▃▆▄▄▆▅▄▄▅▄▃▅▆█▃▅▅▃▅▃▁▄▅▅▆▅▄▆▇▅▆▅▆▄
wandb:      train/policy_loss █▅▁█▁▁█▁▁▅█▅▅▁▁▅▅▅█▅▁████▁█▁██▅█▁▁█▁▁▅▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▄▁██▁▁▁▁▄▁▁▁▄▄▄▄▁██▄████▁█████▁█▄██▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.38335
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.78804
wandb:      eval/avg_mil_loss 0.51448
wandb:       eval/ensemble_f1 0.78804
wandb:           train/avg_f1 0.79174
wandb:      train/ensemble_f1 0.79174
wandb:         train/mil_loss 0.53728
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhz98u4g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070907-vhz98u4g/logs
wandb: ERROR Run vhz98u4g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xs9s7thr with config:
wandb: 	actor_learning_rate: 3.335586893536953e-05
wandb: 	attention_dropout_p: 0.48901090923168095
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.318249088271953
wandb: 	temperature: 9.7173192104332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071232-xs9s7thr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xs9s7thr
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 83-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▃█▇▅▇▅▆▅▅▅▇▆▄▅▇▃▄▆▆▄▄▅▆▁▅▃▆▆▆▅▅▆▅▅▆▆▄▇▆▆
wandb:      eval/avg_mil_loss ▃▃▄▃▃▃▂▁▄▃▄▆▅▄▃▅▂▅▅▆▃▃▂█▆▄▃▃▅▃▄▄▃▄▄▂▂▁▄▃
wandb:       eval/ensemble_f1 ▃▄▆▅▄▆▄▅▆▆▄▄▄▅▆▄▃▃▄▄▃▆▁▅▆▄▅▅▅▅▄▅▃▆▄▄█▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▅▆▅▅▃▇▇▆▇█▅▇▅█▇█▁▄▂█▆▅▆▆▇▄▄█▅▃▆▅▄▆▆▇▆▇
wandb:      train/ensemble_f1 ▅▅▇▅▅▁▄█▃▆▆▆▅▆▄▄█▆▇▄▅▄▄█▇▆▆▇▄█▆▃▄▄▇▇▅▅▆▇
wandb:         train/mil_loss ▅█▆▆▆█▆▃▇▇▁▆▆▆▄▂▄▇▄▆▆▄▇▃▆█▆▄▆▇▆▃▇▅▄▅▇▅▃▅
wandb:      train/policy_loss ▄▄▄▁▄▁▁▄▁▄▁▁▁▁██▁▄▄▄██▁▄▁▁▁██▄▁▄▄▁▄█▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▅▁█▁▅▁▅▅▁▁▅█▅▅▅▅▅▅▅▁▅▁▅▁█▅▁▁▅█▅▅▅▁▁▁▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.40693
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.78814
wandb:      eval/avg_mil_loss 0.46435
wandb:       eval/ensemble_f1 0.78814
wandb:            test/avg_f1 0.74794
wandb:      test/avg_mil_loss 0.51347
wandb:       test/ensemble_f1 0.74794
wandb:           train/avg_f1 0.7962
wandb:      train/ensemble_f1 0.7962
wandb:         train/mil_loss 0.87942
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xs9s7thr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071232-xs9s7thr/logs
wandb: Agent Starting Run: ux20595d with config:
wandb: 	actor_learning_rate: 3.3877065914155637e-06
wandb: 	attention_dropout_p: 0.2821048576551818
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 95
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34970331331723514
wandb: 	temperature: 3.828340015358415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071411-ux20595d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux20595d
wandb: uploading history steps 94-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅█
wandb: best/eval_avg_mil_loss █▃▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅█
wandb:            eval/avg_f1 ▂█▂▆▂▅▅▅▅▅▆▁▆▅▅▇▆▅▅▄▂▇▃▂▄▅▄▆▄▅▅▆▇▅▁▅▅▄▅▄
wandb:      eval/avg_mil_loss █▅▂▃▁▆▂▃▄▆▅▂▂▅▁▄▃▄▃▂▂▅▃▆▄▂▃▄▅▁▃▄▃▂▆▂▃▃▅▃
wandb:       eval/ensemble_f1 ▁▅▄▅▆▆▅▅▄▆▆▅▅▇▆▇▄▆▆▅▅▄▄▇▄▇▇▆▃▅▄▇▇▅▂▅▆█▃▅
wandb:           train/avg_f1 ▆▆▅▆▅▅▅█▅▆▄▅▅▆▄▆▅▁▅▄▅▅▅▆▄▅▂▇█▃▆▅▅▅▆▄▄▄█▆
wandb:      train/ensemble_f1 ▆▆▆▅▆▄▆▅▇▅▅▆▄▅▆▃▆▄▆█▆▁▄▅▂▄▅█▂▇▄▆▅▄▅▄▄▄▄▆
wandb:         train/mil_loss ▂▃▁▅▆▅▄▆▄▅▁▅▆▅▃▇▆▅▂▅▇▇▄█▄▆▄▁▄▇▄▄▄▅▅▄▆▅▅▅
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▁▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83122
wandb: best/eval_avg_mil_loss 0.42135
wandb:  best/eval_ensemble_f1 0.83122
wandb:            eval/avg_f1 0.78286
wandb:      eval/avg_mil_loss 0.47459
wandb:       eval/ensemble_f1 0.78286
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 1.0059
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux20595d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071411-ux20595d/logs
wandb: ERROR Run ux20595d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: q8a1t1pm with config:
wandb: 	actor_learning_rate: 5.0169961835538096e-05
wandb: 	attention_dropout_p: 0.11201523375187188
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10086408808259884
wandb: 	temperature: 9.96687510216486
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071605-q8a1t1pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8a1t1pm
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss ▃█▁▄
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▆▅▆▁▇▃▁▅▄▅▃▅▆▄▇▇▆▄▅█▄█▅▇▄▃▇▆▅▂▄▇█▆▆▅▅█▇▄
wandb:      eval/avg_mil_loss ▃▆▄▅▄▃▃▃▅▆▄▅▄▇▂▄▁▅▅▄▁▃▅▆▃▆▄▆▅▄▂▆▄▅▇▅▄▂█▆
wandb:       eval/ensemble_f1 ▇▄▃▅▂▅▇▄▄▇▆▄▅▃▇▅▄▄▂▅█▄▄▃▁▃▄▆▅▄▄▃▇▅█▄▇▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▆▃▄█▃▃▆▄▅▃▅▆▅▆▃▃▄▅▂▁▅▇▂▅█▄▆▅▆▂▅▄▃█▆▄▆
wandb:      train/ensemble_f1 ▃▁▁▇▄▄▂▁▂▇▄▇▇▆▇▁█▃▆▂▅▂▃█▁▆▆▅▃▄▂▂▅▄▄▇▂▇▂▂
wandb:         train/mil_loss ▅█▆▆▃▆▂▆▃▆▆▂▇▅▃▆▄▃▆▂▃▆▂▄▅▃▆▆▃▂▄▆▆▆█▁▄▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.36952
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.80849
wandb:      eval/avg_mil_loss 0.40221
wandb:       eval/ensemble_f1 0.80849
wandb:            test/avg_f1 0.77277
wandb:      test/avg_mil_loss 0.58546
wandb:       test/ensemble_f1 0.77277
wandb:           train/avg_f1 0.81186
wandb:      train/ensemble_f1 0.81186
wandb:         train/mil_loss 1.03275
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8a1t1pm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071605-q8a1t1pm/logs
wandb: Agent Starting Run: avwdlrbm with config:
wandb: 	actor_learning_rate: 4.280069760378928e-06
wandb: 	attention_dropout_p: 0.03194984705087395
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7302267201129016
wandb: 	temperature: 0.8316782423312374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071900-avwdlrbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avwdlrbm
wandb: uploading wandb-summary.json
wandb: uploading history steps 93-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇▇█
wandb: best/eval_avg_mil_loss █▅▅▅▁
wandb:  best/eval_ensemble_f1 ▁▂▇▇█
wandb:            eval/avg_f1 ▅▄▅▅▅▄▄▃▃▇▃▄▁▁▆▄▅▅▇▆▆▅▄▄▅▅▅▃▆▆▅▅▆█▄▆▅▃█▅
wandb:      eval/avg_mil_loss ▄▄▂▃▅▃▅▄▃▇▅█▇▆▂▅▅▅▅▅▆▂▄▆▆▅▄▅▂▃▆▆▅▂▄▄▃▁▆▅
wandb:       eval/ensemble_f1 ▄▅█▅▄▅▃▄▅▃▂▂▄▃▂▆▅▆▆█▆▅▅▆▆▆▄▆▇▄▂▅▆▅▄▃▅▁▃▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▂▃▄█▃▂▁█▄▄▄▅▅▆▅▆▄▅▄▅▆▄▅▇▇▄▄▅▆▅▆▇▆▄▅▄▅▆
wandb:      train/ensemble_f1 ▆▇▄▂█▆▁▅▅▄▆█▇▅▅▄▆▅▄▆▄▅▇▅▅▇▆▆▅▃▇▆▅▂▅▆▇▅▆▆
wandb:         train/mil_loss ▁▅▆▇▅▄▄▅▂▃▅▅▄▃▃▂▄▃▂▂▅▄█▅▃▅▆▅▄▄▆▁▂▅▃▄▆▅▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.32014
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.82011
wandb:      eval/avg_mil_loss 0.42689
wandb:       eval/ensemble_f1 0.82011
wandb:            test/avg_f1 0.74532
wandb:      test/avg_mil_loss 0.64021
wandb:       test/ensemble_f1 0.74532
wandb:           train/avg_f1 0.80428
wandb:      train/ensemble_f1 0.80428
wandb:         train/mil_loss 0.52844
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avwdlrbm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071900-avwdlrbm/logs
wandb: Agent Starting Run: gmojmax0 with config:
wandb: 	actor_learning_rate: 1.329067190141449e-06
wandb: 	attention_dropout_p: 0.0978466524051555
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7856778361525443
wandb: 	temperature: 5.144098294307308
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072059-gmojmax0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmojmax0
wandb: uploading history steps 47-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄▅▅▅▇█
wandb: best/eval_avg_mil_loss ▆█▆▇█▇▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▄▅▅▅▇█
wandb:            eval/avg_f1 ▃▅▄▂▅▆▆▅▅▅▆▆▅▄▆▅▆▄█▄▅▆▄▄▆▂▁▄▄▅▄▅▄▄█▃▅▇▃▃
wandb:      eval/avg_mil_loss ▄▅▆▅▅▅▄▅▅▅▄▄▅▅▅▅▃▆▂▆▅▅▃▄▅▄▇█▄█▄▅▆▁▃▅▄▂▇▇
wandb:       eval/ensemble_f1 ▄▅▃▄▂▅▆▆▅▅▆▆▄▆▅▆▄█▄▇▄▆▄▄▆▂▁▄▃▄▅▄▄█▆▃▅▇▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▄▇▅▇▃▄▇▂▂▃▇▃▄▃▃▆▅▂▂▃▁▆▃▆▄▂▃▄▆▂▂▄▂▃▅▆▁▇
wandb:      train/ensemble_f1 █▅▄▇▅▃▄▆▂▃▂▃▄▂▃▅▂▄▄▆▃▁▆▃▄▄▃▄▆▆▂▄▂▃▃▆▁▅▅▇
wandb:         train/mil_loss ▅▃▇▄█▃▃▃▃▃▆▄▃▃▅▁▅▃▅▃▃▃▃▄▃▂▂▃▅▃▃▃▂▁▄▄▄▄▄▁
wandb:      train/policy_loss ▃▅▅▅▅▅▅▅▃▅▅▃▅▅▁▅▅▅▅▅▅▅█▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▃▅▅▅▅▅▁▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8392
wandb: best/eval_avg_mil_loss 0.38028
wandb:  best/eval_ensemble_f1 0.8392
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.52525
wandb:       eval/ensemble_f1 0.76275
wandb:            test/avg_f1 0.74532
wandb:      test/avg_mil_loss 0.53252
wandb:       test/ensemble_f1 0.74532
wandb:           train/avg_f1 0.811
wandb:      train/ensemble_f1 0.811
wandb:         train/mil_loss 0.50841
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmojmax0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072059-gmojmax0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 199dmwab with config:
wandb: 	actor_learning_rate: 2.83179523088204e-06
wandb: 	attention_dropout_p: 0.10446386078010912
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4540484034989728
wandb: 	temperature: 7.379420954043053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072222-199dmwab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/199dmwab
wandb: uploading history steps 47-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▆▄▄▃▃▃▆▇▄▃▂▂▂▂▃▃▃▄▃▄▆▄▃▃▃▁▅▇▄▄▂▃█▅▁▆▂▃▂▄
wandb:      eval/avg_mil_loss ▂▂▄▅▆▃▃▂▄▄▄▄▄▃▆▅▆▂▆▄▃▃▆█▆▃▁▅▄▃▅▁▂▆▅▄▆▆▄▄
wandb:       eval/ensemble_f1 ▆▄▄▂▃▂▆▃▇▃▃▅▁▂▂▂▂▃▃▄▂▆▄▃▃▄▁▅▇▄▅▁▂█▅▅▆▂▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▇▅▃▃▆▂▅▃█▅▅▇▃▅▃▆▅▇▁▄▆▃▆█▃▅▅▃▅▆▅▄▅▆▅▄▂
wandb:      train/ensemble_f1 ▅▆█▅▄▅▃▃▃▆▅▃▅▅▇▅▃▆▅▃▁▄▆▃▇▄▅▅▄▃▆▅▄▃▅▅▅▄▅▅
wandb:         train/mil_loss ▄▅▆▅▅▄▇▇▇▅▄▅▇▃▆▆▆▅▅▆▅▇▂▄▅██▁▆▂▄▅▄▅▃▄▄▃▅▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▁▅▅▅▅▁▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▁▅▅▅▅▅▁▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84911
wandb: best/eval_avg_mil_loss 0.38844
wandb:  best/eval_ensemble_f1 0.84911
wandb:            eval/avg_f1 0.80495
wandb:      eval/avg_mil_loss 0.43883
wandb:       eval/ensemble_f1 0.80495
wandb:            test/avg_f1 0.79318
wandb:      test/avg_mil_loss 0.48358
wandb:       test/ensemble_f1 0.79318
wandb:           train/avg_f1 0.80995
wandb:      train/ensemble_f1 0.80995
wandb:         train/mil_loss 0.87657
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/199dmwab
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072222-199dmwab/logs
wandb: Agent Starting Run: q680z19q with config:
wandb: 	actor_learning_rate: 0.00010518873873883768
wandb: 	attention_dropout_p: 0.11680958493829008
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5232016998897074
wandb: 	temperature: 4.967124587336863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072334-q680z19q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q680z19q
wandb: uploading history steps 82-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss █▇▄▁▃
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▃▆▄▅▆▄▃▄▅▃▂█▄▄▄▁▄▅▂▅▃▅▅▇▃▅▅▄▂▂▆▄▂▄▁▃▂▅▆▅
wandb:      eval/avg_mil_loss ▅▃▄▃▇▂▆█▂▂▃▆▄▅▇▁▅▆▄▄▅▅▅▆▄▂▆▇▅▅▅▃▅▅▅▄▅▁▄▅
wandb:       eval/ensemble_f1 ▁▄▆▇▃▄▆▄▆▆▅▅▄▂▆▅▄▄▄█▄▅▆▄▂▅▄▂▂▇▅▂▂▁▅▄▃▅▅▇
wandb:           train/avg_f1 ▂▆▅▂▆▁▁▅▅▄▄▂▃▄▅▂▆▄▅▅▆▄▇█▄▃▃▆▃▄▆▇▃▆▄▃▃▅▃▇
wandb:      train/ensemble_f1 ▂▆▄▅▅▅▄▆▅▄▅▄▆▄▁▆▄▃▇▆▃▅▃▃▅█▄▅▁▃▃▇▄▇▃▆▄▃█▄
wandb:         train/mil_loss ▃▅▅▄▆▄▇▅█▄▂▄▃▂▃▅▅▃▃▅▃▄▆▂▃▄▃▃▅▃▄▄▃▄▁▂▂▄▁▂
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▆▇▇▇▇▇█▅▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▇▇▇▇▇▇█▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86804
wandb: best/eval_avg_mil_loss 0.40258
wandb:  best/eval_ensemble_f1 0.86804
wandb:            eval/avg_f1 0.75866
wandb:      eval/avg_mil_loss 0.47418
wandb:       eval/ensemble_f1 0.75866
wandb:           train/avg_f1 0.81415
wandb:      train/ensemble_f1 0.81415
wandb:         train/mil_loss 0.9462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q680z19q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072334-q680z19q/logs
wandb: ERROR Run q680z19q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kel8jtfl with config:
wandb: 	actor_learning_rate: 0.000675944814544442
wandb: 	attention_dropout_p: 0.39388678282676415
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47632715543926174
wandb: 	temperature: 5.615274218658858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072545-kel8jtfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kel8jtfl
wandb: uploading history steps 80-81, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▅▆█
wandb: best/eval_avg_mil_loss █▄▃▇▄▁
wandb:  best/eval_ensemble_f1 ▁▅▅▅▆█
wandb:            eval/avg_f1 ▁▅▂▆▂▅▂▁▅▃▂▅▅▄█▃▆▃▄▃▄▆▃▅▂▅▆▅▄▆▃▃▄▅▅▂▃▆▁▃
wandb:      eval/avg_mil_loss ▃▅▂▅▃▅▅▅█▃▄▅▄▅▆▃▆▄▃▅▃▆▂▄▅▅▄▅▅▁▂▁▄▄▅▂▆▃▂▄
wandb:       eval/ensemble_f1 ▅▃▆▂▃▅▆▄▂▄▄▃▄▃▅▁█▃▃▆▃▃▅▆▃▅▆▅▃▇▃▃▃▅▅▆▂▇▄▄
wandb:           train/avg_f1 ▆▄▁▃▃▆▆▇▆▇▄▇▆▄▆▇▃▇▄▇▆▄▄▅▃▅▆▄█▃▇▆▅▄█▅▆▅▆▅
wandb:      train/ensemble_f1 ▅▇▄▁▃▆▇▅▇▇▃▄▆█▅▂▄▇▇▃▆▄▄▅▆▄█▃▅▃▇▄▃▅▅▆▇▅▆▅
wandb:         train/mil_loss ▄▆▅▃▅▇▇▇▆▇▄▆▆▅▇▆▆▄▇▅▄▅▆▅▄▆█▆▂▃▄▁█▅▅▃▃▆▅▆
wandb:      train/policy_loss ▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.35886
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.79097
wandb:      eval/avg_mil_loss 0.49724
wandb:       eval/ensemble_f1 0.79097
wandb:           train/avg_f1 0.79262
wandb:      train/ensemble_f1 0.79262
wandb:         train/mil_loss 1.01165
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kel8jtfl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072545-kel8jtfl/logs
wandb: ERROR Run kel8jtfl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7hrxefkb with config:
wandb: 	actor_learning_rate: 1.5859914190162023e-06
wandb: 	attention_dropout_p: 0.2487455157189292
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08320542120357644
wandb: 	temperature: 7.103595496967182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072723-7hrxefkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hrxefkb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▇▇█
wandb: best/eval_avg_mil_loss █▅▂▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆▇▇█
wandb:            eval/avg_f1 ▁▆▄▄▅▄▇▅▅▄▃▃▃▄▆▅▆▅▆▁█▄▃▆▃█▄▇▂▅▄▃▆▅▅▄▆▅▄▅
wandb:      eval/avg_mil_loss ▆▃▂▄▃▃▄▃▅▃▅▅▆▆▂▅▄▄▄▂▃▃█▄█▄▁▆▄▆▄▃▄▆▄▅▃▅▃▄
wandb:       eval/ensemble_f1 ▅▁▅▅▃▅▅▃▅▂▁▆▅▇▅▁▃▄▄▃▄▅█▃▂▁▃▄▆▄▇▇▃▃▅▇▅▆▄▅
wandb:           train/avg_f1 ▄▄▄▅▇▅▅▅▄█▄▂█▆▆▃▄▅▄▅▄▄▆▆▅▂▅▆▁▂▂▄▄▆▅▂▆▅▆▃
wandb:      train/ensemble_f1 ▃▆▇▇▄▄▄▆▂▅▃▇▃▂▅█▃▃▅▆▃▃▄▅▃▁▆▄▃▄▄▆▂▆▃▃▄▇▅▆
wandb:         train/mil_loss ▃▆▃▃▆▅▆▅▄▃▄█▆▃▆▅▄▆▆▆▄▅▁▅▄▄▄▄▅▃▃▄▃▅▆▆▂▇▂▃
wandb:      train/policy_loss ▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.39011
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.80207
wandb:      eval/avg_mil_loss 0.4538
wandb:       eval/ensemble_f1 0.80207
wandb:           train/avg_f1 0.8125
wandb:      train/ensemble_f1 0.8125
wandb:         train/mil_loss 0.66409
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hrxefkb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072723-7hrxefkb/logs
wandb: ERROR Run 7hrxefkb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4j44282r with config:
wandb: 	actor_learning_rate: 0.0002040247071636301
wandb: 	attention_dropout_p: 0.04656715974368697
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9520017164929436
wandb: 	temperature: 8.39120137787702
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072948-4j44282r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j44282r
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▅▆█
wandb: best/eval_avg_mil_loss ▇█▂▄▁▃▂
wandb:  best/eval_ensemble_f1 ▁▂▄▅▅▆█
wandb:            eval/avg_f1 ▆▄▄▅▅▆▆▇▄▅▃▄▅▁▅▄▁▇▅▅▃▆▄▅▅▄▆▆▆▆▅█▃▄▄▇▆▅▅▅
wandb:      eval/avg_mil_loss ▅▃▅▅▆▄▄▃▄▆▂▃▂█▁▃▆▅▇▁▅▃▃▅▃▃▃▄▃▂▅▂▁▃▂▄▅▃▃▂
wandb:       eval/ensemble_f1 ▄▂▄▅▄▃▄▅▅▃▃▄▅▅▆▅▇▅▂▄▄▃▅▃▄▅▅▃▁▆▃▃▂█▆▆▆▅▅▅
wandb:           train/avg_f1 ▅▅▄▅▄▅▁▄▄▄▆█▄▄▅▅▃▆▂▄▄▆▂▅▁▁▃▇▃▄▅▆▃▅▄▄▄▆▅▁
wandb:      train/ensemble_f1 ▄▃▅▅▅▄▃▄▄▂█▅▄▄▄▅▆▁▆▄▆▄▅█▄▄▆▅▄▁▅▃▄▃▃▂▅▅▄▄
wandb:         train/mil_loss ▄▆▅▄▆▃▄▄█▆▅▃▄▄▄▃▂▄▄▃▃▃▃▃▃▅▄▃▄▃▂▁▂▂▄▁▄▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▁▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86482
wandb: best/eval_avg_mil_loss 0.38338
wandb:  best/eval_ensemble_f1 0.86482
wandb:            eval/avg_f1 0.77985
wandb:      eval/avg_mil_loss 0.44993
wandb:       eval/ensemble_f1 0.77985
wandb:           train/avg_f1 0.78445
wandb:      train/ensemble_f1 0.78445
wandb:         train/mil_loss 0.53517
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j44282r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072948-4j44282r/logs
wandb: ERROR Run 4j44282r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dguokiy3 with config:
wandb: 	actor_learning_rate: 0.0004875503766650218
wandb: 	attention_dropout_p: 0.25903345133559164
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 193
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5657432917324793
wandb: 	temperature: 2.2819406231541564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073305-dguokiy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dguokiy3
wandb: uploading wandb-summary.json
wandb: uploading history steps 186-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆██
wandb: best/eval_avg_mil_loss █▁▃▄▁
wandb:  best/eval_ensemble_f1 ▁▅▆██
wandb:            eval/avg_f1 ▅▁▄▄▆▆▆▄▄▅▅▄▄▅▄▄▅▆▅▄▆▄▄▄█▄▅▅▂▇▇▆▄▅▃▄▆▅▇▇
wandb:      eval/avg_mil_loss ▇▁▄▃▃▂▄▃▇▄▂▅▅▁▂▃▅▆▇▆▅▄▆▄▆▄▃▃▅█▄▃▅▆▆▅▄▂▃▃
wandb:       eval/ensemble_f1 ▄▅▇▆▅▄▃▅▄▆▆▃▅▅▇▅▇█▄▄▆▆▆▅▆▄▂▇▁▅▅█▄▆▆▅▆▄▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▇▃▃▃▅▅▂▆█▄▃▁▆▄▄▃▄▁▄▃▃▄▆▂▅█▄▃▄▂▂▅▄▇▆▂▁
wandb:      train/ensemble_f1 ▆▅▄▃▄▂█▃▁▄▃▄▃▆▃▃▅▃▅▅▂▅▇▆▆▄▇▃▄▇▁▅▄▆▄▆▆▆▄▁
wandb:         train/mil_loss ▁▅▅▅▅▂▃▇▄▃█▄▃▅▆▄▆▅▂▄▃▄▄▅▅▂▂▄▅▄▅▂▆▃▄▅▆▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85682
wandb: best/eval_avg_mil_loss 0.31088
wandb:  best/eval_ensemble_f1 0.85682
wandb:            eval/avg_f1 0.83887
wandb:      eval/avg_mil_loss 0.40433
wandb:       eval/ensemble_f1 0.83887
wandb:            test/avg_f1 0.7846
wandb:      test/avg_mil_loss 0.37569
wandb:       test/ensemble_f1 0.7846
wandb:           train/avg_f1 0.78402
wandb:      train/ensemble_f1 0.78402
wandb:         train/mil_loss 0.56314
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dguokiy3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073305-dguokiy3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ai54lx6s with config:
wandb: 	actor_learning_rate: 0.00028366666431541536
wandb: 	attention_dropout_p: 0.1944564811715236
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.833492459426082
wandb: 	temperature: 6.267835301325139
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073711-ai54lx6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai54lx6s
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▆█
wandb: best/eval_avg_mil_loss █▁▁▁▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆▆█
wandb:            eval/avg_f1 ▄▆▇▇▂▇▃▂▃▅▅▇▇▅▅▃▇▆▂▃▆▃▅▇▅▅▅▇▇▄▆▃█▅▅▃█▅▁▅
wandb:      eval/avg_mil_loss █▃▇▃▃▃▆▄▅▃▁▅▅▆▅▆▇▅▇▄█▆▇▃▃▅▂▆▇▃▆▇▆█▄▆▃▆▂▇
wandb:       eval/ensemble_f1 ▃▇██▄▇▂▁▁▅▆▆▇▃▇▄▂▃▂██▂▅▆▄▅█▂▅▇▃▆▄▆▂▅▂▅▄▄
wandb:           train/avg_f1 ▆▆▃▇▂▇▇█▅█▅▇▆▂▅▄▅▆▄▃▄▄▅▆▆▅▅▁▇▆▅▄▆▇▅▆▃▇▅▅
wandb:      train/ensemble_f1 ▃▄▅▅▅▆▄█▄▃▅▆▇▄▅▅▃▅▃▃▅▅▄▃▂▅▁▄▅▄▇▅▄▃▄▄▂▆▄▄
wandb:         train/mil_loss ▅▆▅▅█▄▆▆█▆▄▅▆▆▅▄▇▅▅▆▄▄▄▅▅▄▂▄▅▅▄▂▄▄▃▄▁▃▃▂
wandb:      train/policy_loss ▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84553
wandb: best/eval_avg_mil_loss 0.41356
wandb:  best/eval_ensemble_f1 0.84553
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.48295
wandb:       eval/ensemble_f1 0.80225
wandb:           train/avg_f1 0.80138
wandb:      train/ensemble_f1 0.80138
wandb:         train/mil_loss 0.51984
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai54lx6s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073711-ai54lx6s/logs
wandb: ERROR Run ai54lx6s errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4rj7ucnq with config:
wandb: 	actor_learning_rate: 9.548083623453328e-05
wandb: 	attention_dropout_p: 0.44801736788708946
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9266503529678556
wandb: 	temperature: 4.129672218106272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073911-4rj7ucnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rj7ucnq
wandb: uploading wandb-summary.json
wandb: uploading history steps 118-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅▅▅█
wandb: best/eval_avg_mil_loss █▂▆▇▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅▅▅█
wandb:            eval/avg_f1 ▅▄▄▄▂▇▄▆▅▂▄▆▅▃▇██▃▃▃▅▅▅▄▅▄▃▅▂▂▅▄▄▂▆█▇▃▁▃
wandb:      eval/avg_mil_loss ▇▂▆▄▅▅▆▄▄▃█▆▃▆▁▆▃▇▅▁▇▃▁▄▂▆▁▇▁▄▆▇▇▁▄▂█▄▄▄
wandb:       eval/ensemble_f1 ▄▂▄▇▇▂▅▃▆▇▅▆▃█▆▅▄▄▇▆▆▆▁▄▆▆▄▃▁▇▇▃▃▆▅▆▄▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▄▄▃▅▂▆▄▅▁▅▁▅▄▆▃▆▅▃▅▄▁▃▃▄▆█▃▆▄▄▅▆▆▄▂█▄
wandb:      train/ensemble_f1 ▇▅▄▃▂▃▅▄▇▅▆▃▄▅▂▅▃▄▄▇▄▅▄▄▄▂▃▃▅▂▁▇▅█▄▅▆▁▃▄
wandb:         train/mil_loss ▇▅▆▂▁▆▅▇▃▅▅▃▅█▄▂▄▃▆▅▇▆▅▄▆▁▇▂▆▁▃▅▇▃▃▄▃▃▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86444
wandb: best/eval_avg_mil_loss 0.3359
wandb:  best/eval_ensemble_f1 0.86444
wandb:            eval/avg_f1 0.79552
wandb:      eval/avg_mil_loss 0.44634
wandb:       eval/ensemble_f1 0.79552
wandb:            test/avg_f1 0.76481
wandb:      test/avg_mil_loss 0.45501
wandb:       test/ensemble_f1 0.76481
wandb:           train/avg_f1 0.78509
wandb:      train/ensemble_f1 0.78509
wandb:         train/mil_loss 0.90435
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rj7ucnq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073911-4rj7ucnq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 95su3yx0 with config:
wandb: 	actor_learning_rate: 2.2879372470340696e-06
wandb: 	attention_dropout_p: 0.11181310180206616
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8436696201152549
wandb: 	temperature: 7.253334785875229
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074145-95su3yx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95su3yx0
wandb: uploading history steps 116-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅█
wandb: best/eval_avg_mil_loss █▆▆▇▄▄▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅█
wandb:            eval/avg_f1 ▆▆▅▄▅▆▆▃▄▄▄▇▃▂▇▄▃▄▂▅▁▃▂▃▆▂▃▁▄▄▃▃▃▃▅▅▄█▇▄
wandb:      eval/avg_mil_loss ▃▄▅▄▆▆▆▃▄▃▅▄▄▇▅▆▄▃▄▆▁▅▇▅▆█▄▆▇▅▃▄▆▇▆▅▄▅▅▆
wandb:       eval/ensemble_f1 ▅▅▄▂▅▂▃▅▃▅▃▆▂▃▅▃▁▄▄▄▁▂▂▃▂▁▅▂▁▂▃▅▄▂▄▄▂▂█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▂▂▁▆▂▂▅▇▅▃▆▄▆▃▁▆▄▆▅▃▅▄▄▅▇▅█▅▃▂▆▃▁▅▅▅▆
wandb:      train/ensemble_f1 ▄▂▅▆▅▆▆▄▄▆▆▅▅▇▃▂█▇▄▆▆▁▄▅▅▅▇▄▄▇▄▃▄▆▃▆▅▄▃▆
wandb:         train/mil_loss █▂▃▇▅▅▃▆▄▅▅▂▄▄▄▁▅▃▅▃▅▄▅▅▂▁▅▄▅▃▂▆▃▃▄▅▄▂▅▂
wandb:      train/policy_loss █▁▅███▅▅▅▅▅▁█▅▁█▁▁▅█▁█▁▁▁▁▁▁▅▅▅█▅▁▅▁▅▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁█▄█████▄▄▄▁█▄█▁▁▁▄█▁▁█▁█▄▄█▁█▁▁█▁▁▄▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.383
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79523
wandb:      eval/avg_mil_loss 0.47318
wandb:       eval/ensemble_f1 0.79523
wandb:            test/avg_f1 0.76109
wandb:      test/avg_mil_loss 0.53466
wandb:       test/ensemble_f1 0.76109
wandb:           train/avg_f1 0.79124
wandb:      train/ensemble_f1 0.79124
wandb:         train/mil_loss 0.85226
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95su3yx0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074145-95su3yx0/logs
wandb: Agent Starting Run: 06jzacjy with config:
wandb: 	actor_learning_rate: 7.093027821025106e-06
wandb: 	attention_dropout_p: 0.2992330258094781
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6541453165852357
wandb: 	temperature: 3.7670415420284655
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074420-06jzacjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06jzacjy
wandb: uploading history steps 170-173, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▄▇█
wandb: best/eval_avg_mil_loss ▂█▆▂▁▃
wandb:  best/eval_ensemble_f1 ▁▄▄▄▇█
wandb:            eval/avg_f1 ▅▆▂▅▆▅▂▃▆▂▂▃▄▆▆▄▅▇█▄▁▄▆▄▄▄▅▅▄▅▆▅▄▄▆▄▅▆▅▄
wandb:      eval/avg_mil_loss ▅▅▃▆▂▆▇▆▄▄▄▁▄▂▆▁▁▃▄▆▅█▇▅▇█▂▄▅▆▃█▇▃▅▂█▂█▂
wandb:       eval/ensemble_f1 ▅▆▇▅█▅█▄▆▆▅▃▅█▅▅█▄▆▅▄▄▇▅▆▆▅▆▁▅▁▆▇▅▅▇▄▄▄▆
wandb:           train/avg_f1 ▅▆▁▅▆▆▄▆▄▆▂▄▂▃▄▄▃▆▃▆▆█▃▃▂▄▄▃▄▇▅▃▄▇▆▅▅▅▃▆
wandb:      train/ensemble_f1 █▄▄▆▁▇▅▆▅▅▅▄▄▄▃▄▆▄▄▄▅▂▅▂▃▃▃▄▄▇▆▄▃▃▃▄▄▆▆▇
wandb:         train/mil_loss █▇▇▅▁▅█▆▄▅▆▅▆██▅▇▄▅▃▇▇▆▆▇▇▆█▆▆▆▃█▇▇▅▅▆▄▆
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84259
wandb: best/eval_avg_mil_loss 0.43914
wandb:  best/eval_ensemble_f1 0.84259
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.46389
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.80769
wandb:      train/ensemble_f1 0.80769
wandb:         train/mil_loss 1.00614
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06jzacjy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074420-06jzacjy/logs
wandb: ERROR Run 06jzacjy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7jydohyb with config:
wandb: 	actor_learning_rate: 1.6437923775707268e-05
wandb: 	attention_dropout_p: 0.4594111440108622
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5907723362042965
wandb: 	temperature: 3.7029214677226903
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074752-7jydohyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jydohyb
wandb: uploading history steps 116-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▄▅▇▃▇█▂▆▇█▄▄▆▁▄▁▂▄▂▄▃▂█▆▄▇▆▃▃▆▁▃▂▇▅▂▅▆▆
wandb:      eval/avg_mil_loss ▄▆▃▇▄▆▄▃▅▃█▃▇▁▅▆▄▆▆▅▄▅▇▄▆▄▄▅▅▄▇▅▄▇▅█▄▇▄█
wandb:       eval/ensemble_f1 █▆▅▁▆▆▆▃▆▃▅█▆▂▇▅▅▄▂▄▆▇▅▂▂▄▅▆▅▃▄▃▆▅▅▅▇▅▃▃
wandb:           train/avg_f1 ▇▅▂▇▁▁▁▅▄▃▄▇▁▁▆▃▁▁▄▆▄▆▆▂▁▆▂█▄▆▃▅▃▄▅▁▂▄▃▅
wandb:      train/ensemble_f1 ▄▃▄▃▇▆▇▄▃█▄▄▇▇▆▆▄▃██▆▇▇▇▆▃▄▄▅▇▇▃▆▆▇▄▆▃▁▆
wandb:         train/mil_loss ▇█▇█▆▆▆▆▅▅▆▆▇▆▅▇▅▇▄▆▅▆▂▃▇▃▃▅▃▃▄▄▅▄▁▂▃▄▃▁
wandb:      train/policy_loss ▁▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▄▃▃▂▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86417
wandb: best/eval_avg_mil_loss 0.38098
wandb:  best/eval_ensemble_f1 0.86417
wandb:            eval/avg_f1 0.82448
wandb:      eval/avg_mil_loss 0.50573
wandb:       eval/ensemble_f1 0.82448
wandb:           train/avg_f1 0.8141
wandb:      train/ensemble_f1 0.8141
wandb:         train/mil_loss 0.57183
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jydohyb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074752-7jydohyb/logs
wandb: ERROR Run 7jydohyb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2wmt5noh with config:
wandb: 	actor_learning_rate: 0.00015730885045754284
wandb: 	attention_dropout_p: 0.38673100281876394
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27759420376381316
wandb: 	temperature: 9.929069175497018
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075048-2wmt5noh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wmt5noh
wandb: uploading history steps 119-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅█
wandb: best/eval_avg_mil_loss ▄█▁▅
wandb:  best/eval_ensemble_f1 ▁▂▅█
wandb:            eval/avg_f1 ▆▅▄▅▄▅▄▄▅▄▃▅▆▅▆▅██▄▅▅▆▆▆▂▄█▅▅▁▆▆▅▄█▃▃▅▄▄
wandb:      eval/avg_mil_loss ▅▆▅▅▃▄▅▆▇█▃▆▃▃█▄▃▂▅▂▂▄▃▅▃▇▂▅▁▅▅▆▇▆▄▂▂▃▇▄
wandb:       eval/ensemble_f1 ▃▇▅▅▃▄▅▄▄▆▄▄▄▁▇██▆▇▅▃▅▄▂▄▂█▅▆▄▇▂█▇▆▃▅▅▂▄
wandb:           train/avg_f1 ▅▄▃▆▁▃▂▄▃▆▇▅▂▄▃▆▃▄▅▂▅▆▄▃▃▄▄█▃▃▂▄▄▁▃▃▄▅▄▄
wandb:      train/ensemble_f1 ▄▄▄▂▄▅▅▄▆▇▅▄▄▅▆▆▂▅▆▄▄█▆▄▅▅▄▄▁▃▅▃▂▆▃▄▆▃▃▄
wandb:         train/mil_loss ▇█▇▅▅▅▆▇▄▆▂▆▃▆▄▄▅▅▇▇▇▆▃▇▇▇▂▇▇▃▂▆▁▆▆▇▂▂▃▄
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.42726
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.4429
wandb:       eval/ensemble_f1 0.79074
wandb:           train/avg_f1 0.78123
wandb:      train/ensemble_f1 0.78123
wandb:         train/mil_loss 0.92933
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wmt5noh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075048-2wmt5noh/logs
wandb: ERROR Run 2wmt5noh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dpqncflf with config:
wandb: 	actor_learning_rate: 4.911716531162975e-05
wandb: 	attention_dropout_p: 0.21501104178046365
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0048492679654191795
wandb: 	temperature: 5.2106707074072
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075318-dpqncflf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpqncflf
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▆█
wandb: best/eval_avg_mil_loss ▂█▆▅▁
wandb:  best/eval_ensemble_f1 ▁▂▃▆█
wandb:            eval/avg_f1 ▄▂▅▄▅▇▄▄▅█▃▅▃▆▃▅▃▄▄▅▅▄▄▄▂▅▆▅▆▃▆▁▁▅▄▃▅▆▅▆
wandb:      eval/avg_mil_loss ▂▃▅▅█▄▄▃▂▁▄█▃▅▂▄▇▄▂▆▂▆▁▄▇▆▃▁▅▅▄▄▅▃▃▂▄▃▅▂
wandb:       eval/ensemble_f1 ▄▄▂▅▄▇▄▅█▃▅▅▃▃▅▅▄▅▅▅▄▂▁▆▅▇▅▆▃▄▁▁▄▅█▃▆▄▅▃
wandb:           train/avg_f1 ▅▅▁▅▆▃▅▅▅█▃▆▄▄▄▄▅▆▆▅▅▆▃▄▃▅▆▅▂▆▇▄▇█▅▆▅▅▃▆
wandb:      train/ensemble_f1 ▄▄▂▄▃█▄▃▁▅▄▅▃▄▅▆▅▄▃▂▃▃▂▆▅▁▆▅▅▇▄▄▆▃▄▆▅▂▃▆
wandb:         train/mil_loss ▅▁▃▆▇▆▅▄▇▂▃▄▆▅▇▃▅█▄▅▆▄▅▅▆▄▃▃▂▄▅▅▄▄▅▁▂▅▅▆
wandb:      train/policy_loss ▅█▁█▅▅▅▁█▅▁▅▁▅▁▁▁▁▁▅█▁▅▁▅▅█▁▅▁▁▅▁█▁▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁█▅▅█▁██▅█▅▅▁█▅▁▁▁▅█▁▁▅▁▅█▅▁█▅▁▁▁█▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8451
wandb: best/eval_avg_mil_loss 0.39566
wandb:  best/eval_ensemble_f1 0.8451
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.41583
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.81151
wandb:      train/ensemble_f1 0.81151
wandb:         train/mil_loss 0.90462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpqncflf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075318-dpqncflf/logs
wandb: ERROR Run dpqncflf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zl96hfmw with config:
wandb: 	actor_learning_rate: 7.69186760673416e-06
wandb: 	attention_dropout_p: 0.07214383280383219
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40378809204465793
wandb: 	temperature: 3.1892127357940514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075441-zl96hfmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl96hfmw
wandb: uploading wandb-summary.json; uploading history steps 53-65, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅█
wandb: best/eval_avg_mil_loss █▃▁▇▇
wandb:  best/eval_ensemble_f1 ▁▃▄▅█
wandb:            eval/avg_f1 ▄▂▂▆▅▅▃▆▅▅▄▄▆▅▃▄▂▃▃▃▃▆▄█▁▄▅▃▂▄▇▄▄▄▅▄▅▆▆▅
wandb:      eval/avg_mil_loss ▄▄▃▄▄▆▆▄▃▅▂▅▃▅▆▄▃▅▃▄▆▃▁▃▄▅▂▄▅▃▄▆█▄▄▄▇▄▁▃
wandb:       eval/ensemble_f1 ▃▁▁▅▄▄▆▂▆▃▅▅▅▂▃▅▄▂▄▁▃▅▂█▂▃▃▁▅▆▄▂▁▄▅▃▃▃▆▄
wandb:           train/avg_f1 ▄▃▁▂▃▂▄▄▆▃▂▅▄▃▆▅▅▆▂▁▂▂▁▇▂▂▂▇▆█▄▇█▅▅▆▂▃▆▇
wandb:      train/ensemble_f1 ▄▃▁▃▃▃▆▃▂▆▄▁▄▃▄▃▆█▅▄▃▅▂▂▇▅▂▂▆▅▄▆▅▇▅▃▆▂▃▆
wandb:         train/mil_loss ▅▅▄▇▅▃▅▆█▅▇▇▅▅▄▇▅▇▄▅▇▃▃▅█▆▁▆▂▇▇▆▇▄▅▅█▆▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86005
wandb: best/eval_avg_mil_loss 0.4914
wandb:  best/eval_ensemble_f1 0.86005
wandb:            eval/avg_f1 0.81586
wandb:      eval/avg_mil_loss 0.36602
wandb:       eval/ensemble_f1 0.81586
wandb:           train/avg_f1 0.81872
wandb:      train/ensemble_f1 0.81872
wandb:         train/mil_loss 0.99519
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl96hfmw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075441-zl96hfmw/logs
wandb: ERROR Run zl96hfmw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8fx2s3sc with config:
wandb: 	actor_learning_rate: 2.52388269751496e-05
wandb: 	attention_dropout_p: 0.33948505856203837
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3812145307526348
wandb: 	temperature: 5.396954040680397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075604-8fx2s3sc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fx2s3sc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 117-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄██
wandb: best/eval_avg_mil_loss ▅█▁▁
wandb:  best/eval_ensemble_f1 ▁▄██
wandb:            eval/avg_f1 ▄▅▇█▅▆▅▄▆█▃▇▄█▁▁▃▅▇▄▆▆▂▅▄▅█▆▅▃▄▆▄▅▆▅▇▇▅▆
wandb:      eval/avg_mil_loss ▆▇▂▂▆▇▆▅▄▃▂▂▄▂▃▆▄▇▃▄█▆▃▇█▁▄▇▃▂▅▅▅▄█▄▆▂▄▃
wandb:       eval/ensemble_f1 ▃▅▇▄▃▅▅▃▅▅▄▁▆▂▄▅▃▅▄▂▃▄▇█▆▆▃▇▄▃▇▆▅▆▄▆▆▆▆▅
wandb:           train/avg_f1 ▃▆▄▄█▄▂▃▄▁▃▇▃▃▂▆▄▃▅▆▄▅▄▅▄▂▇▅▃▄▃▂▂▄▃▇▁▃▃▄
wandb:      train/ensemble_f1 ▅▃▅▇▄▃▅▁▃▅▂▄▃█▂▇▂▆▃▅▄▅▄▅▃▅▄▆▆▂▄▃▃▃▅▇▅▅▄▁
wandb:         train/mil_loss █▆▄▇▆▄▆▇▅▅▂▆▅▄▂▅▄▄▃▅▄▃▆▄▃▃▃▂▃▄▂▂▃▄▄▁▆▄▂▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████████▁████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.42357
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.80019
wandb:      eval/avg_mil_loss 0.40018
wandb:       eval/ensemble_f1 0.80019
wandb:           train/avg_f1 0.78579
wandb:      train/ensemble_f1 0.78579
wandb:         train/mil_loss 0.91761
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fx2s3sc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075604-8fx2s3sc/logs
wandb: ERROR Run 8fx2s3sc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ew8126ib with config:
wandb: 	actor_learning_rate: 1.1911926380922591e-05
wandb: 	attention_dropout_p: 0.023876529543066183
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9446195454384922
wandb: 	temperature: 1.079017977373854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075838-ew8126ib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ew8126ib
wandb: uploading wandb-summary.json
wandb: uploading history steps 105-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▄▆▅▆▃▂▅▆█▂▃▂▅▂▅▂▂▄▆▄▇▇▅▂▅▃▇▂▅▃▃▄▃▃▆▄▁▄▆
wandb:      eval/avg_mil_loss ▁▅█▄▃▇▆▃▅█▇▇▇▆▄▆▄▄▅▃▇▇█▆▂█▂▇▅▇▅▂█▄▄▅▅▃▅▅
wandb:       eval/ensemble_f1 ▇▅▆▅█▁▄█▆▆▄▆▆▄▆▂▆▅▇▅▇▄▄▃▅▇▂▅▄▃▅▃▄▅▅▅▄▆▃▇
wandb:           train/avg_f1 ▅▃▆▃▂▄▆▇▆▃▄▃▄▅▄▅█▅▅▃▇▁▃▆▇▄▃▅▃▃▄▆▂▅▇▅▃▅▅▁
wandb:      train/ensemble_f1 █▄█▇▅▂▄▆▅▇▆▅▅▄▄▅█▅▂▅▅▅▇▆▇▁▄▄▄▇▄▅▄▄▃▅█▅▆▆
wandb:         train/mil_loss ▁▄▅▅▅▃▁▄█▄▂▄▃▅▂▇▄▆▆▃▅▆▄▅▄▅▄▄▆▆▃▄▃▃▅▂▇▅▄▇
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84246
wandb: best/eval_avg_mil_loss 0.40261
wandb:  best/eval_ensemble_f1 0.84246
wandb:            eval/avg_f1 0.80899
wandb:      eval/avg_mil_loss 0.47325
wandb:       eval/ensemble_f1 0.80899
wandb:           train/avg_f1 0.79117
wandb:      train/ensemble_f1 0.79117
wandb:         train/mil_loss 1.01472
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ew8126ib
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075838-ew8126ib/logs
wandb: ERROR Run ew8126ib errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 35rb633n with config:
wandb: 	actor_learning_rate: 1.5045617595875412e-05
wandb: 	attention_dropout_p: 0.2474950184510448
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29590684427490566
wandb: 	temperature: 7.28625284455372
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080058-35rb633n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/35rb633n
wandb: uploading history steps 194-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇▇▇▇██
wandb: best/eval_avg_mil_loss ▆▄▂▃██▃▁▂
wandb:  best/eval_ensemble_f1 ▁▄▅▇▇▇▇██
wandb:            eval/avg_f1 ▇▄▆▅▆▅▄▃▅▃▆▄▃▆▆▄█▃▃▄▃▃▁▆▂▄▆▄▅▄▅▂▃▅▃▃▄▄▆▃
wandb:      eval/avg_mil_loss █▂▃▄▃▃▄▃▅▅▆▁▂▄▁▃▂▃▃▄▃▃▄▄▂▄▆▆▄▃▂▃▅▂▂▃▅▄▄▅
wandb:       eval/ensemble_f1 ▄▆▄▃▃▅▆▇▂▅▃▃▄▅▃▃▆▄▄▅▁▅▅▅█▂▁▂▄▂▄▃▆▂▆▆▂▆▆▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▇▇▄▃▆▄▇▄▄▆▆▄▄▄▄▅▆▇▁▃█▃▄█▇▄▅▄█▃▆▆▆▅▇▆▅▂
wandb:      train/ensemble_f1 ▆▃▄▁▂▆▂▅▄▂▃▄▇▂▂█▃▃▂▆▅▄▄▃█▅▁▁▆▆▃▃▅▃▆▄▆▄▅▁
wandb:         train/mil_loss ▇▇▆▅▅█▆▇▆▄▅▅▆█▇█▄▃▇▄▃▅▆▅▅▅▄▆▄▅▁▃▂▃▃▄▃▂▄▂
wandb:      train/policy_loss ▁▁▅▅█▅▅▁▁▅▅▁▅▅█▅▅▁▁▅▅▁██▁▁▅▁▁▅██▅█▅█▅▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▇███████████████████████▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.37377
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.80599
wandb:      eval/avg_mil_loss 0.46915
wandb:       eval/ensemble_f1 0.80599
wandb:            test/avg_f1 0.8065
wandb:      test/avg_mil_loss 0.45627
wandb:       test/ensemble_f1 0.8065
wandb:           train/avg_f1 0.78969
wandb:      train/ensemble_f1 0.78969
wandb:         train/mil_loss 0.69001
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/35rb633n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080058-35rb633n/logs
wandb: Agent Starting Run: rbl57ok4 with config:
wandb: 	actor_learning_rate: 3.043731862825304e-06
wandb: 	attention_dropout_p: 0.09119523434746007
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08318985674511747
wandb: 	temperature: 2.7806575369437403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080455-rbl57ok4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbl57ok4
wandb: uploading history steps 104-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▅▇█
wandb: best/eval_avg_mil_loss █▅▄▇▄▁▃
wandb:  best/eval_ensemble_f1 ▁▂▄▅▅▇█
wandb:            eval/avg_f1 ▄▅▃▄▆▄▅▁▅▂█▃▅▅▆▇▆▅▆▆▂▅▅▆▅▃▅▄█▄▄▄▆▆▄▃▄▆▅▆
wandb:      eval/avg_mil_loss ▆▄▇▇▄▁▂▅▇▄▄▅▂▇▄▃▆▃▄▄▅▆▄▄▅▄▄▃▄▅▄█▃▃▆▃▅▅▄▃
wandb:       eval/ensemble_f1 ▃▂▁▅▅▆▃▃▄▃▄▁▇▅▄▅█▅▅▁▅▄▅▃▂▄▃▅▇▅▃▄▂▂▃▃▄▅▄▄
wandb:           train/avg_f1 ▂█▄▄▄▄▄▇▂▅▄▄▂▂▅▆▆▃▄▃▃▄▄▂▇▁▄▃▄▂▃▃▂▃▄▃▅▄▅▄
wandb:      train/ensemble_f1 ▅▅▄▄▅▇▄▃▄▅▅▃█▂▃▂▅▃▁▃▃▄▅▃▃█▁▄▃▁▃▅▃█▄▃▄▅▅▄
wandb:         train/mil_loss ▆▄▃▅▄▃▅▄█▅▂▄▁█▆▃▂▆▃▃▄▂█▃▄▇▃▇▆▅▅▃▂▁▂▆▇▇▂▇
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▅▄▃▄▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85743
wandb: best/eval_avg_mil_loss 0.41126
wandb:  best/eval_ensemble_f1 0.85743
wandb:            eval/avg_f1 0.81654
wandb:      eval/avg_mil_loss 0.43069
wandb:       eval/ensemble_f1 0.81654
wandb:           train/avg_f1 0.7936
wandb:      train/ensemble_f1 0.7936
wandb:         train/mil_loss 0.66498
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbl57ok4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080455-rbl57ok4/logs
wandb: ERROR Run rbl57ok4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zokyq3tj with config:
wandb: 	actor_learning_rate: 0.00023080380746894272
wandb: 	attention_dropout_p: 0.189291304995764
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4802763592858651
wandb: 	temperature: 5.30341466922621
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080732-zokyq3tj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zokyq3tj
wandb: uploading history steps 172-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▆▇█
wandb: best/eval_avg_mil_loss █▅▁▄▃▅
wandb:  best/eval_ensemble_f1 ▁▅▆▆▇█
wandb:            eval/avg_f1 ▆▃▁▄▄▅▄▄▂▆▃▇▃▄▄▅▄▃█▄▅▄▂▅▃▄▂▄▂▄▃▂▂▅▁▅▆▄▅▃
wandb:      eval/avg_mil_loss ▃▁▆▂▆▆█▁▄▄▅▅▂▄▆▆▅▂▃▆▃▄▃▂▄▆▃▃▄██▇▄▆▇▅▆▃▆▇
wandb:       eval/ensemble_f1 ▆▄▄▆▂▆▃▄▃▁▂▆▆▄▆▅▄▃▁█▅▅▇▂▄▁▅▃▆▃▂▅▃▆█▅▄▅▃▇
wandb:           train/avg_f1 ▆█▃▇▄▆▄▆▇▇▆▆▆▄█▆▅▆▅▅▆▆▅▃▄█▄▇▄█▆▄▅▂▃▅▁▇▇▁
wandb:      train/ensemble_f1 ▆▇▃▄▁▇▇▆▄▂▃▅▄▁▂▅▅▄█▅▂▅▅▇█▆▇▄▆▄▂▆█▇▁▆▃▄▄▂
wandb:         train/mil_loss ▇▅█▆▇▅▆▅▅▅▄▄▇▅▄▅▄▄▄▆▄▄▄▄▃▅▃▄▃▃▃▃▃▃▃▂▁▂▃▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▆▅▅▅▁▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▇▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86095
wandb: best/eval_avg_mil_loss 0.41932
wandb:  best/eval_ensemble_f1 0.86095
wandb:            eval/avg_f1 0.78828
wandb:      eval/avg_mil_loss 0.49768
wandb:       eval/ensemble_f1 0.78828
wandb:           train/avg_f1 0.78334
wandb:      train/ensemble_f1 0.78334
wandb:         train/mil_loss 0.48139
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zokyq3tj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080732-zokyq3tj/logs
wandb: ERROR Run zokyq3tj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v72zig2t with config:
wandb: 	actor_learning_rate: 4.632730818664001e-06
wandb: 	attention_dropout_p: 0.49407935597509434
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7552653283511163
wandb: 	temperature: 2.0687659592382204
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081130-v72zig2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v72zig2t
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂█
wandb: best/eval_avg_mil_loss █▂▁▂
wandb:  best/eval_ensemble_f1 ▁▂▂█
wandb:            eval/avg_f1 ▅▆▄▆▁▁█▃▂▂▅▅▅▃▅▇▂▃▆▃▄▄▆▄▅▆▁▂▅▂▄▅▄▆▅▅▁▂▆▃
wandb:      eval/avg_mil_loss ▄▂▂▆▄▂▅▂▂▅▃▄▄▅▆▅▂▅█▃▂▄▄▁▄▂▂▄▂▆▅▂▂▄▄▃▅▅▂▂
wandb:       eval/ensemble_f1 ▅▆▆▄▆▅▁█▃▂▅▅▅▃▅▇▂▃▆▃▇▄▄▆▄▅▃▆▁▂▄▅▄▆▅▅▁▂▆▃
wandb:           train/avg_f1 ▂▁▇▅▅▄▄▅▅▆▅▆▅▄▄▅▅▆▅▅▆▃▃▅▄▂▆▆▆█▅▆▄▆▂▅▅▇▄▆
wandb:      train/ensemble_f1 ▂▁▇▅▃▄▄▅▅▆▅▄▆▅▄▄▅▆▃▄█▆▃▅▄▂▆▆▆█▅▆▄▆▂▅▅▇▄▆
wandb:         train/mil_loss ▇▄▂▄▆▁▃▇▅▂▆▆▅▆▇▂▅▁▃▇▃▅▂▂▄▇▂█▃▃▆▄▂▃▃▅▃▁▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.38156
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.78961
wandb:      eval/avg_mil_loss 0.39061
wandb:       eval/ensemble_f1 0.78961
wandb:           train/avg_f1 0.81368
wandb:      train/ensemble_f1 0.81368
wandb:         train/mil_loss 0.55259
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v72zig2t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081130-v72zig2t/logs
wandb: ERROR Run v72zig2t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: sko79bas with config:
wandb: 	actor_learning_rate: 2.9048992990049663e-05
wandb: 	attention_dropout_p: 0.13573839847293084
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8505353246892694
wandb: 	temperature: 6.585166379632875
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081252-sko79bas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sko79bas
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 54-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇██
wandb: best/eval_avg_mil_loss ▂▁▁▄█
wandb:  best/eval_ensemble_f1 ▁▃▇██
wandb:            eval/avg_f1 ▆▄▄▅█▆▅▂▁▁▅▅▅▂▆█▄▄▅▃▃▄▇▆█▂▃▆▄▇▁▃▄▄▂▂▆▆▃▄
wandb:      eval/avg_mil_loss ▅▆▂▁▄█▃▂▅▃▃▄▄▄▂▅▃▆▁▅▃▄▃▃▂▃▃▂▃▁▄▃▅▃▃▅▂▂▁▂
wandb:       eval/ensemble_f1 ▅▆▄▂▄█▆▅█▂▄▄▅▅▂▆▄▄▄▄▃▃▄▄▄█▄▄▅▄▃▆▇▄▁▄▄▆▆▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▄▅▃▅▅▃▅▄▅▄▅▄▃▆▃▁▂▂▇▃▂▇▅▄▄▃▂█▄▇▆▂▄▄▄▂▂
wandb:      train/ensemble_f1 ▄▅▅▅▇▆▃▅▅▄▅▅▅▄▄▃▁▁▂▁▇▃▂▇▅▅▄▃▂█▅▂▅▆▆▄▄▃▆▂
wandb:         train/mil_loss ▃▅▆▄▅▄▄▄▃▃▄▄▄▃▅█▅▅▃▄▄▃▆▅▅▄▄▂▂▅▁▅▄▄▅▃▄▆▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82808
wandb: best/eval_avg_mil_loss 0.42459
wandb:  best/eval_ensemble_f1 0.82808
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.39525
wandb:       eval/ensemble_f1 0.78777
wandb:            test/avg_f1 0.77718
wandb:      test/avg_mil_loss 0.53486
wandb:       test/ensemble_f1 0.77718
wandb:           train/avg_f1 0.78401
wandb:      train/ensemble_f1 0.78401
wandb:         train/mil_loss 0.90701
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run serene-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sko79bas
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081252-sko79bas/logs
wandb: Agent Starting Run: trhe6tzm with config:
wandb: 	actor_learning_rate: 1.7837828017669115e-05
wandb: 	attention_dropout_p: 0.2443419115547802
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6342551333923706
wandb: 	temperature: 2.7877427182464376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081410-trhe6tzm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/trhe6tzm
wandb: uploading wandb-summary.json
wandb: uploading history steps 100-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆█
wandb: best/eval_avg_mil_loss ▁▂█▆▅
wandb:  best/eval_ensemble_f1 ▁▂▄▆█
wandb:            eval/avg_f1 ▄▄▇▄▅▅▅▅▄▆▆▇█▄▅▄▃▆▃▄▅▄▄▇▄▆▃▅█▄▇▅▆▅▆▄▅▅▁▄
wandb:      eval/avg_mil_loss ▃▃▄▄▃▁▄▄▆▄▃▄▄▁▂▄▃▂▄▂▆▄▂▄▅▃▂▂▃▃▄▂▃▂▁▂▃█▃▅
wandb:       eval/ensemble_f1 ▆▇▇▄▆▅█▆▃▆██▅▆▆▄▄▄▄▇▆▇▅▂▄▇▅▆▅▆▃▅▅▅▅▁▅▄▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▇▆▁▃▃▆█▅▅▄▅▅▆▄▃▅▆▂▄▃▄▄▅▆▅▃▇▄▇▄▂▅▃▃▄█▅▆
wandb:      train/ensemble_f1 ▅▁▅▆▄▃▃▅█▅▃▇▃▄▁▅▄▅▅▅▆▆▃▃▄▅▄▄▄▆▇▄▃▇▅▅▂▃▃▆
wandb:         train/mil_loss ▆▅▆▅▅▆▆▅▄▄▅▅▆▄▆▄▅▃▄█▄▃▅▄▄▃▆▅▆▄▄▅▄▃▄▅▂▁▄▂
wandb:      train/policy_loss ▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▄▆▅▆▆▆▆▆▆▁▆▆▆▆▆▆▄▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85224
wandb: best/eval_avg_mil_loss 0.41537
wandb:  best/eval_ensemble_f1 0.85224
wandb:            eval/avg_f1 0.79867
wandb:      eval/avg_mil_loss 0.43428
wandb:       eval/ensemble_f1 0.79867
wandb:            test/avg_f1 0.81707
wandb:      test/avg_mil_loss 0.40195
wandb:       test/ensemble_f1 0.81707
wandb:           train/avg_f1 0.80178
wandb:      train/ensemble_f1 0.80178
wandb:         train/mil_loss 1.65477
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/trhe6tzm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081410-trhe6tzm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gs5np0nw with config:
wandb: 	actor_learning_rate: 3.454535859118679e-05
wandb: 	attention_dropout_p: 0.12561726819171987
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 61
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7228295360403766
wandb: 	temperature: 5.98300893493124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081633-gs5np0nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gs5np0nw
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 59-61, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▅▄▃██▇█▆▅▇▅▄▃▄▆▇▅▃▆▃▇▆▃▅▆▅█▄▃▅▄▅▄▄▆▁▆▆▄
wandb:      eval/avg_mil_loss ▃▆▅▆▆▅▄▆▄▁▃▆▄▆▆▇█▂▄▆▇▆▅▇▇▄▆█▄▃▄▆▄▄▄▅▄▄▄█
wandb:       eval/ensemble_f1 ▄▄▂▇▂▆▄█▅▄▅▃▇▄▃▃▃▅▇▄▂▂▇▄▂▄▅▃▃▂▅▄▃▁▃▄▅▅▅█
wandb:           train/avg_f1 ▄▇▆▇▂█▂▄▁▅▄▅▃▅▅▅▇▄▅▅▂▇▄▃▂▅▇▆▆▃▄▆▃▄▆▅▄▆▄▆
wandb:      train/ensemble_f1 ▃▆▄▇▁▁▃▅▄▄▃▄▂▅▅█▅▇▃▄▃▅▇▃▂▃▇▆▆▂▂▆▄▅▅▄▅▃▄▅
wandb:         train/mil_loss ▅▄▃▇▇▄▃▅▇█▆▆▇▄▂▆▅▇▆▇▆▅▆▄▁▃▇▃▅▇▄▅▇█▅▄▂▇▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.31328
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.83103
wandb:      eval/avg_mil_loss 0.44635
wandb:       eval/ensemble_f1 0.83103
wandb:           train/avg_f1 0.79936
wandb:      train/ensemble_f1 0.79936
wandb:         train/mil_loss 0.87046
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gs5np0nw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081633-gs5np0nw/logs
wandb: ERROR Run gs5np0nw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: m5emcpka with config:
wandb: 	actor_learning_rate: 0.0007136486834394011
wandb: 	attention_dropout_p: 0.4137575832611152
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18387008696357168
wandb: 	temperature: 9.820598221637324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081745-m5emcpka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5emcpka
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▅▆▇█
wandb: best/eval_avg_mil_loss ██▃▅█▅▂▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▅▆▇█
wandb:            eval/avg_f1 ▃▄▅▄▃▄▆▄▅▄█▃▅▅▃█▅▇▆▅▅▅█▆▅▄▁▃▄▆▅▆▄▇▆▆▅▇▅▇
wandb:      eval/avg_mil_loss ▅▂▃▃▃▂▂▃▃▂▄▂▃█▅▂▂▂▄▇▅▆▃▄▃▃▁▄▃▄▆▃▅▅▃▇▄▂▄▄
wandb:       eval/ensemble_f1 ▃▄▆▆▅▄▃▆▅▂▇█▄▃▅▃▁▂▇▄▅▅▆▅▇▃▅▄▃▃▅▅▅▄▄▆▄▆▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄█▄▃▃▆▄▄▆▄▃▁▅▄▂▁▇█▂▄▅▆▆▃▁▅▁▃▆▇▂▅▅▅▃▆▅▃
wandb:      train/ensemble_f1 ▅▁█▁▅▆▄▅▅▅▅▄█▆▅▆▄█▆▆▃▂▇▄▆█▆▄▂▆▇▅▂▄▆▆▂▄▃▇
wandb:         train/mil_loss ▇▆█▆▆▄▄▅▅▇▅▅▂▃▅▄▂▄▄▃▄▄▃▄▃▅▃▄▃▁▄▃▃▄▂▄▅▃▄▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.34881
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.81297
wandb:      eval/avg_mil_loss 0.41856
wandb:       eval/ensemble_f1 0.81297
wandb:            test/avg_f1 0.75658
wandb:      test/avg_mil_loss 0.44604
wandb:       test/ensemble_f1 0.75658
wandb:           train/avg_f1 0.7863
wandb:      train/ensemble_f1 0.7863
wandb:         train/mil_loss 0.72182
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5emcpka
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081745-m5emcpka/logs
wandb: Agent Starting Run: csa2tiob with config:
wandb: 	actor_learning_rate: 6.807133360407079e-06
wandb: 	attention_dropout_p: 0.18587413929303975
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4583167747314902
wandb: 	temperature: 0.4591620649027106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081923-csa2tiob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csa2tiob
wandb: uploading history steps 111-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▆█
wandb: best/eval_avg_mil_loss ██▁▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▅▆▆█
wandb:            eval/avg_f1 ▇▄▃▅▂▂▄▂▅▅▇▅▂▃▅▂▆▃▄▆▅▃▅█▅▄▆█▃▁▃▂▄▁▄▂▆▆▄▁
wandb:      eval/avg_mil_loss ▅▄▃▄▅█▁▂▃▄▄▅▇▅▂▅▅▃▃▄▆▄▄▃▄▇▅▃▆▃▅▂▄▃▂▄▃▅▄▃
wandb:       eval/ensemble_f1 ▄▇▆▄▄▇▃▇▅▁▇▆▃█▆▆▅▄█▄▆▄█▄▇▂▅▇▇▅▃▃▆▆▆▆▃▇▆▃
wandb:           train/avg_f1 ▆▆▅▅▆▆▃▆▇▅▄▃▃▆▃▇▂█▆▅▄▄▄▂▄▂▆▁▆▂▃█▅▅▆▃▇▄▅▃
wandb:      train/ensemble_f1 ▂▇▅▄▇▆▇▄▆▂▇▅▅▄▅▆▄▁▅▄▄▅▅▃▅▅█▆▇▇█▆▅▇▄▇▅▁▆▄
wandb:         train/mil_loss █▇▆▆▇▆▅▅▄▃▃▄▃▃▃▃▂▃▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▃▂▂▁▂▃▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▁██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8348
wandb: best/eval_avg_mil_loss 0.41895
wandb:  best/eval_ensemble_f1 0.8348
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.4491
wandb:       eval/ensemble_f1 0.78993
wandb:           train/avg_f1 0.78627
wandb:      train/ensemble_f1 0.78627
wandb:         train/mil_loss 0.6988
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csa2tiob
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081923-csa2tiob/logs
wandb: ERROR Run csa2tiob errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: rphpo7vu with config:
wandb: 	actor_learning_rate: 1.04161638303107e-06
wandb: 	attention_dropout_p: 0.28276479872580135
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8427731862873684
wandb: 	temperature: 6.509451810143943
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082152-rphpo7vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rphpo7vu
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▄▅▆▇██
wandb: best/eval_avg_mil_loss ▄▇▇▇▁█▄▃▅▂
wandb:  best/eval_ensemble_f1 ▁▁▂▃▄▅▆▇██
wandb:            eval/avg_f1 ▅▃▅▄▅▃▅▆▄▅▄▇▁▄▄▅▃█▇▄▄▆▅▂▄▁▄▂▄▆▆▅▃▄▆▆▁█▄▃
wandb:      eval/avg_mil_loss ▂█▃▆▂▃▂▃▃▂▃▇▄▄▄▅▅▁▅▄▃▆▆▆█▅▇▆▆▆▃█▂▄▃▄▆▄▇█
wandb:       eval/ensemble_f1 ▅▂▅▃▃▅▇▅▃▇▆▅▇▁▃▇▅▄▁█▄▇▆▆▃▄▄▂▂▄▆▄▄▆▅▃▂▁▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▄▆▅▁▃▃▁▅█▅▅▅▃▂▅▃▆▅▇▆▄▅▅▆▅▅▄▃▄▃▅▅▇▃▅▃▄
wandb:      train/ensemble_f1 ▅▅▇▄▃▆▆▁▄█▅▅▄▆▄▆▅▅▃▅▄▅▃▄▄▄▆▅▄▃▆▅▄▁▂▃▃▅█▅
wandb:         train/mil_loss ▅▅▃▄▇█▃▅▃▆▅▃▁▅▆▄▆▇▃▇▆▁▃▃▅▅▅▆▂▃▅▃▆▄▃▁▂▅▃▄
wandb:      train/policy_loss ▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄█▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.36449
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.77651
wandb:      eval/avg_mil_loss 0.53416
wandb:       eval/ensemble_f1 0.77651
wandb:            test/avg_f1 0.77342
wandb:      test/avg_mil_loss 0.59264
wandb:       test/ensemble_f1 0.77342
wandb:           train/avg_f1 0.78966
wandb:      train/ensemble_f1 0.78966
wandb:         train/mil_loss 1.03566
wandb:      train/policy_loss -0.19746
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.19746
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rphpo7vu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082152-rphpo7vu/logs
wandb: Agent Starting Run: s9pe95jb with config:
wandb: 	actor_learning_rate: 4.047154557369688e-05
wandb: 	attention_dropout_p: 0.3561346410376312
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9792704124627496
wandb: 	temperature: 5.8132228788204285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082407-s9pe95jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9pe95jb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▅█▃▇▆█▄▅▆▆▅▇▇▅▇▆▆▄█▆▆▇▇▆▇▅▃▆▁▄▆▃▇▄▅▃▄▇█▆
wandb:      eval/avg_mil_loss ▆▄▅▆▂▆▃▄▃▅▄█▅▅▄▄▃▂▆▂▄▄▅▅▄▇▄▂▅▆▃▄▂▃▄▄▂▃▅▁
wandb:       eval/ensemble_f1 ▅▇▅▃▅▅▆▇▅▅█▅▅▆▄▄▅▇▇▆▅▇▆▇▅▄▃▅▁▅▇█▇▄▆▄▃▆▆▅
wandb:           train/avg_f1 ▁▃▇▃▄▅▄▁▂▃▂▂▃▄▄▃▄▂▄▄▂▄▂▅▂█▃▄▃▂▃▃▃▃▃▃▂▇▁▅
wandb:      train/ensemble_f1 ▅▅▆▄▇▇▅▇▇▅▅▇▃▂▃█▅▆▄█▆▃▇▁▆▂▃▆▂▇▂▅▅▄▂▅▄▆▅▃
wandb:         train/mil_loss ▁▂▂▁▂▃▂▁▂▃▂▂▄▄▃▅▄▄▅▅▆▆▅▄▆▄▆▆▆█▇███▅▇▇█▆▆
wandb:      train/policy_loss ▅▅▅▅▆▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆█▇▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82819
wandb: best/eval_avg_mil_loss 0.39873
wandb:  best/eval_ensemble_f1 0.82819
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.38664
wandb:       eval/ensemble_f1 0.79074
wandb:           train/avg_f1 0.79131
wandb:      train/ensemble_f1 0.79131
wandb:         train/mil_loss 1.4449
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9pe95jb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082407-s9pe95jb/logs
wandb: ERROR Run s9pe95jb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4ci1uwtj with config:
wandb: 	actor_learning_rate: 9.72395866146656e-05
wandb: 	attention_dropout_p: 0.4655741082169558
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.310544121676972
wandb: 	temperature: 3.814809868454656
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082606-4ci1uwtj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ci1uwtj
wandb: uploading history steps 134-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss █▁▁▃
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 ▄▅▅▄▅▅▅▅▆▄█▄▅▄▄▃▃▄▇▄▃▄▄▅▃▆▆▃▅▅▅▅▆▆▁▅▄▃▅▅
wandb:      eval/avg_mil_loss ▄▃▄▃▃▄▄▃▂▆▄▁▄▆▆▆▂▂▄▃▂▆▄▇▄▆▅▃▆▄▅▄▃█▃▃▆▃▂▃
wandb:       eval/ensemble_f1 ▅▄▂▇▆▃▅▁▅▆▃▃▄▃▃▂▅▄█▅▂▂▅▆▇▅▃▃▄▃▆▆▃▂▄▄▄▄▃▂
wandb:           train/avg_f1 ▅▅▆▇▇▃▆▄▇▂▄▄▇▆▅█▇▆▅▃▅▄▆▆▅▃▄▅▆▅▁▁▄▄▆▃▂▁▁▄
wandb:      train/ensemble_f1 ▆▅▃█▇▃█▆▇▄▅▅▆▅▆▄▇▅▆▆▃▄▃▃▄▄▄▆▃▄▇▇▃▃▃▂▅▁▅▁
wandb:         train/mil_loss █▇▇▇▆▇▆▅▅▆▅▆▅▅▅▅▅▄▅▄▄▃▄▄▃▃▄▃▄▂▃▃▃▂▂▃▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▅▄▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆█▆▅▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▇▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.43827
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.76562
wandb:      eval/avg_mil_loss 0.52189
wandb:       eval/ensemble_f1 0.76562
wandb:           train/avg_f1 0.78269
wandb:      train/ensemble_f1 0.78269
wandb:         train/mil_loss 0.59462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ci1uwtj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082606-4ci1uwtj/logs
wandb: ERROR Run 4ci1uwtj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 82vd4r7o with config:
wandb: 	actor_learning_rate: 6.915880841688075e-05
wandb: 	attention_dropout_p: 0.04071409290398137
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7922401677841552
wandb: 	temperature: 2.3416956027571603
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082902-82vd4r7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82vd4r7o
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▆▆▆█
wandb: best/eval_avg_mil_loss ▃▃▁▁▅▄▃█▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▆▆▆█
wandb:            eval/avg_f1 ▅▂▂▆▄▄▄▆▄▇▅▃▄▄▁▄▆▄▅▆▇▂▇▂▅▃▄▂▄▃▅▆█▅▄▁▃▅▁▆
wandb:      eval/avg_mil_loss ▂▁▁▆▆▇▄▅▅▁▃▂▃█▄█▆▃▆▃▆▄▃▄▆▃▅▇▅▃▄▄▄▇▄▄▄▆▄▄
wandb:       eval/ensemble_f1 ▅▃▁▆▅▅▇▆▅▃▄▃▄▅▅▆▃▅▆▄▅▇▃▅▆▅▃▃▃▇▅▄▄▆█▅▂▅▃▆
wandb:           train/avg_f1 ▅▃▅▄▃▅▆▆▅▅▃█▃▇▄▇▄▇▅▃▅▅▃▅▅▄▄▄▁▂▅▆▅▅▇▅▃▄▃▅
wandb:      train/ensemble_f1 ▃▅█▅▃▅▁▅▆▆▄█▃▅▄▄▄▇▅▆▅▆▅▃▄▂▃▄▁▅▂▇▄▃▂▁▂▃▃▅
wandb:         train/mil_loss ▇█▇█▇▆▆█▄▄▅▆▇▅▄▇▅▄▇▅▃▅▆▃▄▄▅▄▄▂▄▄▄▄▄▄▄▂▁▁
wandb:      train/policy_loss ▄▄▄▅▄▄▄▄▄▃▄▄▄▁▄▄▄▄▄▄▄▄▃▄▄█▄▄▄▄▄▄▄▄▄▄▃▃▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▆▃▆▆▆▆▆▆▆▅▆▆▆▆▆▆▁▆▆▆▇▆▆▆▆▆▆██▆▇▆▆▆▆▆▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85751
wandb: best/eval_avg_mil_loss 0.39053
wandb:  best/eval_ensemble_f1 0.85751
wandb:            eval/avg_f1 0.82828
wandb:      eval/avg_mil_loss 0.43144
wandb:       eval/ensemble_f1 0.82828
wandb:           train/avg_f1 0.80677
wandb:      train/ensemble_f1 0.80677
wandb:         train/mil_loss 1.46747
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82vd4r7o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082902-82vd4r7o/logs
wandb: ERROR Run 82vd4r7o errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ujg3awjz with config:
wandb: 	actor_learning_rate: 1.6950158266720278e-06
wandb: 	attention_dropout_p: 0.26225251183396564
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8362366468720691
wandb: 	temperature: 1.0085949762310964
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083126-ujg3awjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujg3awjz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▄█
wandb: best/eval_avg_mil_loss ▅▃█▇▁▃
wandb:  best/eval_ensemble_f1 ▁▂▂▄▄█
wandb:            eval/avg_f1 ▄▄▆▆▆▅▃▁▃▃▁▅▇▇▄▄█▆▆▆▃▅▃▆▆▃█▇▃▄▆▄▆▆▅▅▄▄▇▄
wandb:      eval/avg_mil_loss ▃▄█▁▁▄▅▄▂▃▄▅▂▅▄▄▃▃▃▃▃▃▄▅▁▃▂▇▆▅▂▂▃▃▃▃▄▂▄▄
wandb:       eval/ensemble_f1 ▆▃▅▄▇▃▄▃▇▄▄█▆▄▃▅▃▅▆▁▅▆▄▅▇▃▄▆▆▆▅▆▂▄▃▅▅█▅█
wandb:           train/avg_f1 ▅▅▃▃▆▄█▁▂▆▅▅▂▆▆▇▄▅▇▅▆▇▃▃█▇█▆▇▇▅▇▇▇▆█▇█▅▅
wandb:      train/ensemble_f1 █▄▂▃▆▅▅▆▁▇▃▄▃▄▄▃▅▅▅▇▂▂▄▄▂▅▆▅▄▄▃▆▄▄▅▄▄▄▄▄
wandb:         train/mil_loss ▅▇▆▆▆▇▇██▅▆▃▄▆▆▅▅▇▄▆▄█▆▆▆▃▆▆▁▂▆▃▄▄▄▃▄▄▃▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.35099
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.8348
wandb:      eval/avg_mil_loss 0.4531
wandb:       eval/ensemble_f1 0.8348
wandb:           train/avg_f1 0.80069
wandb:      train/ensemble_f1 0.80069
wandb:         train/mil_loss 1.50001
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujg3awjz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083126-ujg3awjz/logs
wandb: ERROR Run ujg3awjz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: f8iw7psc with config:
wandb: 	actor_learning_rate: 2.821615521516233e-05
wandb: 	attention_dropout_p: 0.15158982032465168
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6229068422418379
wandb: 	temperature: 1.4831479908848522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083351-f8iw7psc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8iw7psc
wandb: uploading wandb-summary.json
wandb: uploading history steps 84-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆█▅▇▆▆▄▅▄▅▄▄▅▅▆▇▆▅▄▇▆▅▅▄▇▅▅█▅█▇▆▃▄▆▅▇▄▆▁
wandb:      eval/avg_mil_loss ▄▅▂▂▅▄▃▄▆▃▄▆▆▆▂▁▄▁▆▃▃▅▄▂▆▆▃▃▄▃▂▅▆▃█▁▄▆▆▅
wandb:       eval/ensemble_f1 ▆▆▅▆▅▅▆▆▄▄▆▇▆██▇▅▄▇▆▆▆▄▅▅▆▇▃▅▅▅▃▇▄▄▆█▅▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▄▁▄▄▅▃▆▄▇▄▆▆▇▆▅▄▅█▇█▅▄▂▆▅▂▅▆▃▅▃▃▅▁▅▄▄
wandb:      train/ensemble_f1 ▄▁▆▆▃▄▄▅▃▅▅▇▅▅▇▆▃▄▅▃▇█▅▅▃▆▃▅▆▆▄▅▃▅▄▅▃▂▆▄
wandb:         train/mil_loss ▁▃▄▄▅▇▂▃▆▄▄▇▆▅▄▇▄█▅▇▇████▇▇█▅▇▅▇█▅▄▇▇▇▆▆
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▁▂▂▂▅▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁█████████████▆█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83513
wandb: best/eval_avg_mil_loss 0.38201
wandb:  best/eval_ensemble_f1 0.83513
wandb:            eval/avg_f1 0.8024
wandb:      eval/avg_mil_loss 0.46912
wandb:       eval/ensemble_f1 0.8024
wandb:            test/avg_f1 0.79946
wandb:      test/avg_mil_loss 0.54889
wandb:       test/ensemble_f1 0.79946
wandb:           train/avg_f1 0.79116
wandb:      train/ensemble_f1 0.79116
wandb:         train/mil_loss 1.24959
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8iw7psc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083351-f8iw7psc/logs
wandb: Agent Starting Run: uycs3dib with config:
wandb: 	actor_learning_rate: 7.245286166375425e-06
wandb: 	attention_dropout_p: 0.3739075106201316
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25157671374393464
wandb: 	temperature: 5.753308171977306
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083539-uycs3dib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uycs3dib
wandb: uploading wandb-summary.json
wandb: uploading history steps 166-178, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▇█
wandb: best/eval_avg_mil_loss ▆▅█▇▁▂
wandb:  best/eval_ensemble_f1 ▁▃▃▄▇█
wandb:            eval/avg_f1 ▅▆▄▃▃▅▆█▄▅▃▅▁▃▃▄▄▃▂▂▄▃▆▅█▁▄▅▂▃▄▄▁▄▄▄▃▆▃▃
wandb:      eval/avg_mil_loss ▆▅█▅▃▆█▆▆▄▅▂▇▂▃▅▁▄▂▆▄▅█▁▅▄▄▄▅▆▅▃▄▅▅▄▆▃▄█
wandb:       eval/ensemble_f1 ▇▄▄▆▅▄▅▄▆▅▅▇▅▆▇▇▅▆▆▁▅▅▆▄▅▆▄▄▅▆▅▆▆▄▅█▆▃▆▇
wandb:           train/avg_f1 ▄▄▆▃▆▄▅▄█▁▅▂▅▄▄▆▄▄▄▂▃▃▄▇▃▅▆▆▃▄▃▅▃▂▄▃▄▃▅▅
wandb:      train/ensemble_f1 ▄▄▅▃▃▄▆▄▄▅▅█▃▃▂▂▃▁▃▄▅▂▆▄▅▃▃▅▃▄▃▃▃▁▁▄▅▅▅▅
wandb:         train/mil_loss ▅█▆▅▆▅▃▅▃▇▇▅▆▁▇▅█▇▆▃▂▄▃▅▅▂▄▄▆▄▂▅▁▅▄▃▂▇▃▄
wandb:      train/policy_loss ▅▇▇▇▇▇▁▇▅▇▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.36164
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.77985
wandb:      eval/avg_mil_loss 0.40217
wandb:       eval/ensemble_f1 0.77985
wandb:           train/avg_f1 0.79452
wandb:      train/ensemble_f1 0.79452
wandb:         train/mil_loss 1.6055
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uycs3dib
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083539-uycs3dib/logs
wandb: ERROR Run uycs3dib errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: z052naqr with config:
wandb: 	actor_learning_rate: 0.00012428263077727446
wandb: 	attention_dropout_p: 0.20274059705509873
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.002870706341875362
wandb: 	temperature: 3.850444853391912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083901-z052naqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z052naqr
wandb: uploading history steps 56-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆█
wandb: best/eval_avg_mil_loss ▂▁▂▅█
wandb:  best/eval_ensemble_f1 ▁▁▃▆█
wandb:            eval/avg_f1 ▅▃▇▅▄▄▆▂▃▁▆▅█▆▄▇▃▄▅▆▁▃▆▆▂▆▃▃▅▅▃▃▅▄▅▄▅▅▅▄
wandb:      eval/avg_mil_loss ▁▁▂▁▄▂▂▅█▅▆▄▅▄▃▃▆▁▆▄▄▇▄▂▇▅▄▄▅▄▄▄▄▆▃▄▃▃▅▄
wandb:       eval/ensemble_f1 ▅▅▆▃▇▄▆▆▄▇▃▅▅▆▄▇▃▅▄▄▆▂▁▃▆▆▅▃▅▄▄▅▄▅▅▃▅█▅▄
wandb:           train/avg_f1 ▆▇▆▄▅▆▄▆▅█▃▆▆▆▄▃▇▅▄▅█▁▆▄▄▅▇▆▆▁▆▄▄▅▅▇▁▅▅▄
wandb:      train/ensemble_f1 ▇▃▆▄▄▃▆▆▅▅▄▃▅▆▄▄▇▆▅▄▅█▄▄▄▇▆▆▁▂▆▇▄▅▄▇▇▅▄▄
wandb:         train/mil_loss ▆▆▅▂▅▃▂▇▆▆▅▆▄▂▆▂▁▃▅▄▄▄▆▄▆▇▄▂▃▇▂▃▄██▅▄▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃█▃▃▃▃▃▃▁▃▃▃▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83856
wandb: best/eval_avg_mil_loss 0.45668
wandb:  best/eval_ensemble_f1 0.83856
wandb:            eval/avg_f1 0.78098
wandb:      eval/avg_mil_loss 0.46595
wandb:       eval/ensemble_f1 0.78098
wandb:           train/avg_f1 0.78898
wandb:      train/ensemble_f1 0.78898
wandb:         train/mil_loss 1.314
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z052naqr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083901-z052naqr/logs
wandb: ERROR Run z052naqr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: caf3b75v with config:
wandb: 	actor_learning_rate: 3.2933364882669914e-05
wandb: 	attention_dropout_p: 0.2811122342513781
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17591791433262527
wandb: 	temperature: 3.4642055616823617
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084019-caf3b75v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caf3b75v
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▄▂▁▃
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▂▆▆▄▄▂▅▄▄▅█▄▅▄▅▄▄▇▄▃▄▆▇▅▆▅▃▁▂▂▆▅▅▅▁▅▄▅▄▆
wandb:      eval/avg_mil_loss ▆▃▃▃▂▄▄▄▂▁▆█▂▆▄▂█▆▆▇▅▅▅▅▃▄▄▆▇▂▆▂▇▇▃▃▅▄▄▅
wandb:       eval/ensemble_f1 ▆▄▆▆▅█▅▄▆▅▇▆▂▅█▆▄▅▅▅▅▄▃▆▇▆▅▇▅▃▆▃▆▆▁▅▄▆▆▇
wandb:           train/avg_f1 ▅▃▃▃▅▃▄▃▄▄▃▇▃▅▅▃▅▂▄▆▁▄▄▄▂▃▃█▅▃▄▄▅▅▄▂▇▄▅█
wandb:      train/ensemble_f1 ▆▆▅▄▃▃▄▅▄▇▆▅▄▅▃▂▅▃▄▄▅▆▇▆▄▇▅▅▇▂▅▄▆▅▅█▁▂▄█
wandb:         train/mil_loss ▆▆█▆▆▅▆▆▆▇▆▄▄▅▅▅▆▄▄▆▆▃▅▃▃▅▄▄▃▃▃▄▃▂▃▁▃▁▃▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃█▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86024
wandb: best/eval_avg_mil_loss 0.38735
wandb:  best/eval_ensemble_f1 0.86024
wandb:            eval/avg_f1 0.82725
wandb:      eval/avg_mil_loss 0.36851
wandb:       eval/ensemble_f1 0.82725
wandb:           train/avg_f1 0.80451
wandb:      train/ensemble_f1 0.80451
wandb:         train/mil_loss 1.28373
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caf3b75v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084019-caf3b75v/logs
wandb: ERROR Run caf3b75v errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ddwol92p with config:
wandb: 	actor_learning_rate: 2.795160047382748e-05
wandb: 	attention_dropout_p: 0.48175513885099974
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5961106569293066
wandb: 	temperature: 7.970817270956694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084208-ddwol92p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddwol92p
wandb: uploading wandb-summary.json
wandb: uploading history steps 97-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▆▃▅▁▄▅▂█▆▅▄▂▃▃▂▄▆█▃▄▆▄▇▆▂▇▃▄▄▇▃▆▄▂▅▆▃▆▄
wandb:      eval/avg_mil_loss ▄▃▆▅▅▂▄▁▆▄▅▂▅▆▃▅▄▄▆▄▄▃▆▃▄▄▇▅▆▆▂▆▅▅█▃▃▄█▃
wandb:       eval/ensemble_f1 ▂▇▅▆▂▅▄█▅▆▂▄▅█▃▁▃▇▅▆▁▇▂▃▄▄▃▂▅▂▄▅▅▅▄▇▄▄▆▄
wandb:           train/avg_f1 ▇▄▅▅▆▇▄▂█▆▅▆▆█▄▁▇▂▅▅▆▅▆▆▄▂▇▆█▃▅▄▆▆▅█▆▄▄▄
wandb:      train/ensemble_f1 ▄▅▆▁▄▄▅▅█▄▃▆▄▄▅▁█▄▅▂▇▅▃▅█▅▆▂▇▄▆█▃▄▇▄▄▆▆▆
wandb:         train/mil_loss ▆██▇▅▆▇▅▇▆▇▄█▅▅▅▃▅▄▄▆▅▄▅▃▄▄▃▆▄▄▄▄▅▅▂▄▂▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▃▅▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.37608
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.80543
wandb:      eval/avg_mil_loss 0.39079
wandb:       eval/ensemble_f1 0.80543
wandb:           train/avg_f1 0.78173
wandb:      train/ensemble_f1 0.78173
wandb:         train/mil_loss 0.77687
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddwol92p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084208-ddwol92p/logs
wandb: ERROR Run ddwol92p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 926ot0x0 with config:
wandb: 	actor_learning_rate: 1.200695335382386e-05
wandb: 	attention_dropout_p: 0.3130579535389906
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.72385748894547
wandb: 	temperature: 6.387493792137045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084407-926ot0x0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/926ot0x0
wandb: uploading history steps 110-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▅▆▇█
wandb: best/eval_avg_mil_loss ▃▂▄▁▁█▁
wandb:  best/eval_ensemble_f1 ▁▄▄▅▆▇█
wandb:            eval/avg_f1 ▆▃▃▆▃▄▃▄▅▇▇▁▆▇▃▇▆▆█▆▆▃▅█▂▄▅▃▅▆▄▆▅▄▄▃▆▃▄▇
wandb:      eval/avg_mil_loss ▃▅▃▃▂▄▄▂▄▁▃▂█▅▄▄▅▅▃▃▄▅▃▅▄▄▂▃▄▅▃▄▆▂▅▃▅▃▄▄
wandb:       eval/ensemble_f1 ▄▆▄█▃▇▂▄▃▆▅█▅█▃▃█▃█▆▂▄▄▄▄▄▅▆▃▁▄▅▅▃█▆▂▄▃▆
wandb:           train/avg_f1 ▄▂▂▃▁▆▅▅▄▃▆▃▇▇▁▄▃▆▆▄▅▁▄▇▅█▇▄▅▄▂▂▆▃▅▇▆▆▄▅
wandb:      train/ensemble_f1 ▄▆█▅▁▄▁▂▃▃▆▇▄▆▆▅▆▅▄▄█▄▄▃▃▄▂▇▅▆▅▃▆▅▅▂▇▄█▄
wandb:         train/mil_loss ▅▇▆▄▆▆▅▆▄▇▇█▅▅▅▆▅▅▇▅▄▅▄▇▄▅▅▅▃▄▅█▄▂▂▄▇▃▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82111
wandb: best/eval_avg_mil_loss 0.42258
wandb:  best/eval_ensemble_f1 0.82111
wandb:            eval/avg_f1 0.77713
wandb:      eval/avg_mil_loss 0.45592
wandb:       eval/ensemble_f1 0.77713
wandb:           train/avg_f1 0.78047
wandb:      train/ensemble_f1 0.78047
wandb:         train/mil_loss 1.61326
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/926ot0x0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084407-926ot0x0/logs
wandb: ERROR Run 926ot0x0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d3u7zvky with config:
wandb: 	actor_learning_rate: 1.3327447520428604e-05
wandb: 	attention_dropout_p: 0.1198528681095688
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6973970519677729
wandb: 	temperature: 3.0186015979359637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084621-d3u7zvky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d3u7zvky
wandb: uploading wandb-summary.json
wandb: uploading history steps 83-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▅▆█
wandb: best/eval_avg_mil_loss █▅▅▄▁▅▄
wandb:  best/eval_ensemble_f1 ▁▃▄▅▅▆█
wandb:            eval/avg_f1 ▃▃▄▄▄▂▅▆▄▄▅▄▃▃▄▄▃▄▃▃▄▃▄▄▆▁▅▄▃▃▄▃▅▃▄█▂▅▆▅
wandb:      eval/avg_mil_loss ▄▃▃▃▆▃▂▄▄▂▆▃█▄▄▄▄▂▅▆▃▁▄▄█▂▃▅▃▄▂▃▅▂▄▄▃▃▃▅
wandb:       eval/ensemble_f1 ▅▁▅▆▇▆▅█▅▃█▅▅▆▃▇▆▅█▄▅▅▄▃▆▅▄▂█▃▄▃▇▇▆▆▆▇▅▆
wandb:           train/avg_f1 ▂▅▅▄▇▅▅▅▅▆▅▇▄▄█▅▂▇▅▃▂▇▅▇▃▄▂▄▇▆▅▄▆▅▁▃▃▃▆▅
wandb:      train/ensemble_f1 ▁▅▄▅▆▄▅▄▄▇▃▆▅▃▃█▁▄█▃▂▁▆▄▁▇▄▃▄▆▅▅▄▄▂▂▃▃▄▆
wandb:         train/mil_loss ▇▅▄▄█▅▄▄▄▆▄▄▄▇▄▅▃▄▅▅▄▅▅▄▆▄▆▂▅▃▁▄▄▃▂▄▂▃▃▂
wandb:      train/policy_loss ▄▁▄█▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▇▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85711
wandb: best/eval_avg_mil_loss 0.38441
wandb:  best/eval_ensemble_f1 0.85711
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.42557
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.81098
wandb:      train/ensemble_f1 0.81098
wandb:         train/mil_loss 1.31371
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d3u7zvky
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084621-d3u7zvky/logs
wandb: ERROR Run d3u7zvky errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9bg4ovp6 with config:
wandb: 	actor_learning_rate: 0.0001132182983665178
wandb: 	attention_dropout_p: 0.413824888986032
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.798128013204268
wandb: 	temperature: 5.637311242963624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084804-9bg4ovp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bg4ovp6
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss █▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▇▅▆█▇▆▃▆▅▆▄▇▄▄▅▅▇▇▇▄▅▅▇▁▆▄▅▄▇▅▅▄▇▅▄▄▃▇▄▄
wandb:      eval/avg_mil_loss ▅▄▅▃▃▆▅▆▆▅▆▁▃▁▅▃▅▆█▅▂▄▅▃▆▅▅▅▃▇▁▄▅▇▂▅▇▄▃▄
wandb:       eval/ensemble_f1 ▆▇▆█▄▅▆█▅▇█▄▇▆▇▆▄▄▄▇▁▄▄▄▂█▅▅▅▅▄▆▅▆▇▆▆▃█▆
wandb:           train/avg_f1 █▆▄▅▆▆▅▂▄▄▄▇▆▄▃▂▅▆▄▄▄▄▆▄▆▅▁▅▅▅▄▅▄▂▅▄▁▃▁▁
wandb:      train/ensemble_f1 ▂▇█▆▅▄▄▄▂▆▂▅▆▃█▄▃▅▅▄▁▄▃▃▆▆▃▂▅▅▂▄▄▅▄▅▅▂▄▂
wandb:         train/mil_loss ▆▆▆▅█▆▅▃█▇▅▃▅▅▆▆▆▄▆▄▂▆▄▄▇▅▃▄▄▄▁▂▃▁▄▂▄▅▃▃
wandb:      train/policy_loss ▇▇▇▇▄▇▇▇▇▇█▇▇▇▇▇▇▇▅▇▇▇▇▇▇▅▇▁▇▇▇▇▇█▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▅▅▅▅▅█▅▅█▅▅▅▅▃▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.39506
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.76642
wandb:      eval/avg_mil_loss 0.47309
wandb:       eval/ensemble_f1 0.76642
wandb:           train/avg_f1 0.77345
wandb:      train/ensemble_f1 0.77345
wandb:         train/mil_loss 0.63824
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bg4ovp6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084804-9bg4ovp6/logs
wandb: ERROR Run 9bg4ovp6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cgd6ap6d with config:
wandb: 	actor_learning_rate: 2.447768425298617e-05
wandb: 	attention_dropout_p: 0.4406108545022694
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7503052425727507
wandb: 	temperature: 6.318862588363647
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085039-cgd6ap6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgd6ap6d
wandb: uploading history steps 129-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▇█
wandb: best/eval_avg_mil_loss ▄▄█▆▁▂
wandb:  best/eval_ensemble_f1 ▁▃▃▄▇█
wandb:            eval/avg_f1 ▅▆▃▆▃▅▂▇▃▅▄█▅▅▄▆▆▄▃▃█▅▅▄▂▇▃▄▅▇▅▇▅▅▁▃▅▁▅▄
wandb:      eval/avg_mil_loss ▃▃▆▄▅▃▄▆▁▇▂▅▃▄▆▂▄▆▅▄▆▄▃▃▂▄▄▇▇▅▆█▆▅▂▃▆█▄▃
wandb:       eval/ensemble_f1 ▆▃█▄▅▇▆▇▂▅▅▃▃▆▅▆▆▅▄▄▄▄▇▃▅▅▄▂▄▆▃▅▄▅█▁▅▂█▁
wandb:           train/avg_f1 █▅▆▆▇▇█▇▄▄█▃▅▄▄▇▆▇▆▅▇▆▆▅▆▄▅▆▂▃▂▆▄▁▂▆▅▂▂▄
wandb:      train/ensemble_f1 ▂▄▃▅▅▆▇▆█▇▅▅▂▄█▄▇▆▅▅▃▆▇▆▅▆▃▆▃▃▄▇▄▇▂▅▆▄▁▂
wandb:         train/mil_loss ▆█▇▆▆█▇▇▆▆▇▆▇█▇█▄▆▆▅▅▄▄▅▆▅▅▄▄▃▃▄▄▄▃▂▄▃▂▁
wandb:      train/policy_loss ▂▂▂▂▂▁▄▂▂▂▂▂▂▂▅▅▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▁▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▇▃▃▃▃▆▃▃▃▃▃▃█▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.40932
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.81743
wandb:      eval/avg_mil_loss 0.44798
wandb:       eval/ensemble_f1 0.81743
wandb:           train/avg_f1 0.79187
wandb:      train/ensemble_f1 0.79187
wandb:         train/mil_loss 1.1612
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgd6ap6d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085039-cgd6ap6d/logs
wandb: ERROR Run cgd6ap6d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ffjwcge4 with config:
wandb: 	actor_learning_rate: 2.2307214350440995e-06
wandb: 	attention_dropout_p: 0.4138098235271976
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7250461160484569
wandb: 	temperature: 8.070684997503106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085335-ffjwcge4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffjwcge4
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 107-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃██
wandb: best/eval_avg_mil_loss █▇▁▇
wandb:  best/eval_ensemble_f1 ▁▃██
wandb:            eval/avg_f1 ▂█▃▄▂▄▂▃▃▃▃▄▂▅▇▂▄▃▁▆▂▂▂▅▆▅▄▇▄▃▇▄▇▂▃█▄▆▂▄
wandb:      eval/avg_mil_loss ▃▃▅▂▂▆▅▄▂▃▄▅▄▄█▃▃▄▂▄▅▂▃▁█▃▃▅▃▃▄▄▄▂▃▄▂▆▃▂
wandb:       eval/ensemble_f1 ▅▃▆▆▄▇▆▅▄▇▇▃▄▆▄▅▄▄▄▂▂▇▄▁▃▆▇▅▅▇▇▄▅▃▆█▅▆▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▇▄▅▃▄▄▂▅▅▄▅▁▁▂▆█▂▅▅▃▄▃▂▃▃▂▃▃▅▃▄▃▁▄▄▃▃▃
wandb:      train/ensemble_f1 ▄▇▅▆▅▆▅▅▁▄█▅▃▆▆▅▄▅▆▅▄▃▃▃█▂▆▄▃▅▄▄▃▅▂▅▆▅▅▄
wandb:         train/mil_loss ▇▄▂▅▅▇▃▅▅▃▅▄▅▄▂▄▃▄▅▄▄▂█▂▄▅▃▂▅▆▄▂▃▁▆▁▆▄▃▅
wandb:      train/policy_loss ███████▇█████████████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▇█████████████████████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83197
wandb: best/eval_avg_mil_loss 0.46262
wandb:  best/eval_ensemble_f1 0.83197
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.39045
wandb:       eval/ensemble_f1 0.80225
wandb:            test/avg_f1 0.77167
wandb:      test/avg_mil_loss 0.56725
wandb:       test/ensemble_f1 0.77167
wandb:           train/avg_f1 0.78167
wandb:      train/ensemble_f1 0.78167
wandb:         train/mil_loss 0.87383
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run snowy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffjwcge4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085335-ffjwcge4/logs
wandb: Agent Starting Run: es09x7z9 with config:
wandb: 	actor_learning_rate: 2.2507775240393835e-05
wandb: 	attention_dropout_p: 0.4501085607746027
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5085317123699222
wandb: 	temperature: 8.324062580201359
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085544-es09x7z9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/es09x7z9
wandb: uploading wandb-summary.json
wandb: uploading history steps 41-52, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▁█▃▅
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▇▆▂▆▅▃▂▆▃▆▇▁▄▇▄▄▇▂▆▅▃▄▅▃▅▅▅▃▄▆█▄▁▄▄▅▅▅▂▆
wandb:      eval/avg_mil_loss ▇▃▅▆▄▅▆▂▅▇▇▇▃▃▆▇▃▆▆▄▃▅▇▆▇█▅▂▁▇▅▆▆▆▄█▇▄▄▅
wandb:       eval/ensemble_f1 ▂▇▆▂▆▅▃▂▆▃▆▇▁▄▇▇▇▂▆▅▃▄▃▅▃▁▅▃▄▆▅█▄▁▄▇▅▅▅▅
wandb:           train/avg_f1 █▄▃▅▄▅▄▇▂▄▄▂▂▅▅▄▄▂▄▄▅▂▃▃▃▅▅▅▁▃▅▆▃▅▃▅▄▅▃▅
wandb:      train/ensemble_f1 █▄▄▅▄▅▄▇▂▄▄▂▂▅▅▄▂▄▄▆▂▃▃▃▅▅▅▁▃▄▆▃▅▄▃▄▅▇▆▅
wandb:         train/mil_loss ▄▆▃▆▇██▇▅▄▇█▇▆▆█▆▆▄▅▂▄▂▄▂▅▇▇▂▅▄▇▃▆▁▃▆▃▄▅
wandb:      train/policy_loss ██████████████▁█████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▁▆█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84153
wandb: best/eval_avg_mil_loss 0.43174
wandb:  best/eval_ensemble_f1 0.84153
wandb:            eval/avg_f1 0.81611
wandb:      eval/avg_mil_loss 0.4328
wandb:       eval/ensemble_f1 0.81611
wandb:           train/avg_f1 0.80677
wandb:      train/ensemble_f1 0.80677
wandb:         train/mil_loss 1.57826
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/es09x7z9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085544-es09x7z9/logs
wandb: ERROR Run es09x7z9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 16eve12c with config:
wandb: 	actor_learning_rate: 9.152333730721236e-06
wandb: 	attention_dropout_p: 0.04195283815682155
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9811830247934484
wandb: 	temperature: 0.9483170292774225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085656-16eve12c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16eve12c
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▆▆██
wandb: best/eval_avg_mil_loss █▆▅▄▃▁▄▄
wandb:  best/eval_ensemble_f1 ▁▃▃▄▆▆██
wandb:            eval/avg_f1 ▆▄▅▆▇▆▅▃▆▅▅▄▇▅█▅█▆▅▆▇█▆▅█▅▅█▆▇▃▆▇▇▇▁▇▅▆▇
wandb:      eval/avg_mil_loss ▃▃▄▆▂▅▄▃▇▃▁▄▄▁▂▄▃▃▄▂▄▂▃▆▇▃▄▅▅▂▄▃▃▄█▅▄▄▆▅
wandb:       eval/ensemble_f1 ▆▃▅▆▄▃▃▃▄▃▂▅▃▄▆▆▄▅▃▆▄▆▆█▃▆▇▅▂▁▆▅▄▃▅▄▂▄▅▄
wandb:           train/avg_f1 ▅▃▆█▂▆▅▆▅▃▄▃▅▆▅▅▃▃▃▇▅▆▄▄▁▁▅▄▆▃▄▁▄▃▄▂▇▄▃▄
wandb:      train/ensemble_f1 ▄▅▅▅▄▃▂▅▄▆▃▄▃▅▇▂▅▄▄▄▃▅▄▂▇▅▅▄▁█▁▄▅▁▃▃▄▇▃▄
wandb:         train/mil_loss ▇█▇▇▆▅▇▆▄▆▃▅▄▄▄▄▄▃▅▃▄▃▄▄▄▃▂▂▂▁▂▃▁▁▁▁▂▄▂▁
wandb:      train/policy_loss ▄▅▅▅▅▅▁▇▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▄▄▆▃▂▄▄▁▇▄▄▅▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄█▄▇▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84992
wandb: best/eval_avg_mil_loss 0.41006
wandb:  best/eval_ensemble_f1 0.84992
wandb:            eval/avg_f1 0.79558
wandb:      eval/avg_mil_loss 0.45787
wandb:       eval/ensemble_f1 0.79558
wandb:           train/avg_f1 0.79591
wandb:      train/ensemble_f1 0.79591
wandb:         train/mil_loss 1.09199
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16eve12c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085656-16eve12c/logs
wandb: ERROR Run 16eve12c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4364z3e7 with config:
wandb: 	actor_learning_rate: 2.7843184321350138e-06
wandb: 	attention_dropout_p: 0.07002589597833836
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7941041976466651
wandb: 	temperature: 9.6659092512839
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085919-4364z3e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4364z3e7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇█
wandb: best/eval_avg_mil_loss █▁▂▅▃
wandb:  best/eval_ensemble_f1 ▁▆▆▇█
wandb:            eval/avg_f1 ▇▃▂▆▃▄█▃▅▃▃▄▄▂▄▇▆▄▆▄▆▄▁▆▃▂▇▄▁▂▄▃▄▅▂▄▄▅▆▃
wandb:      eval/avg_mil_loss ▅▁▅▂▂▂▁▃▃▃▃▁▅▃▂▆▃▃▃▅▄▅▆█▅▆█▅▄▄▅▆▅▆▄▄▁▃▄▂
wandb:       eval/ensemble_f1 ▅▂▅█▆▆▃▆█▂▆▅▅▅▅▃▇▃▄▃▇▄▃▃▂▁▇▆▇▄▆▇▂▃▁▄▃▃▄▆
wandb:           train/avg_f1 ▇█▆▆▆▇▆▅█▆▆█▅▆▆▄▃▅▇▅▅▄▆▃█▆▆▆▆▂▅▆▇▄▄▆▁▃▃▅
wandb:      train/ensemble_f1 ██▅█▃▇▃▅▆▅▅▅▅▄▄▆▆▃▅▄▅▄▃▆▄▃▄▄▃▄▅▄▄▄▁▅▄▆▄▅
wandb:         train/mil_loss ▇▆█▇▆▆▆▅▆▄▅▄▅▅▄▄▄▄▅▂▅▆▅▅▄▄▅▄▄▃▄▃▂▃▄▃▂▂▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▇▅▅▅▅▅▅▅▂▆▅▅▅▅▅▅▅▅▅▅▅▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▃▃▇▃▃█▁▃▃▅▃▃▃▃▃▃▃▃▃▅▃▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84671
wandb: best/eval_avg_mil_loss 0.42352
wandb:  best/eval_ensemble_f1 0.84671
wandb:            eval/avg_f1 0.82115
wandb:      eval/avg_mil_loss 0.44496
wandb:       eval/ensemble_f1 0.82115
wandb:           train/avg_f1 0.78178
wandb:      train/ensemble_f1 0.78178
wandb:         train/mil_loss 0.80126
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4364z3e7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085919-4364z3e7/logs
wandb: ERROR Run 4364z3e7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zx4ghdpz with config:
wandb: 	actor_learning_rate: 4.216207668826228e-05
wandb: 	attention_dropout_p: 0.3043650641210728
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17130590088164543
wandb: 	temperature: 5.818577800826454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090322-zx4ghdpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4ghdpz
wandb: uploading history steps 80-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▆█
wandb: best/eval_avg_mil_loss ▆█▇▂▇▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▆█
wandb:            eval/avg_f1 ▅▅▅▁▆▆▄▆▅▅▄▄▇▆█▄▅▃▆▃▅▅▄▅▄▆▇▆▇▅▅▃▅▄▅▅▄▆▄▅
wandb:      eval/avg_mil_loss ▅▆▅▆▃▇▄▆▂▃▅▄▅▂▅▁▅▇▄▆▅▅▄▇▆█▆▅█▄▄▃▃▄▇▄▄▆▆▅
wandb:       eval/ensemble_f1 ▄▅▃▄▃▆▃▅▆▃▆▂▃▅▅▅▄▆▁▅▅▄▇▃▄▆▄▁▄▁▃▄▄▂▅█▄▁▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▄▃▄▅▃▅▄▄▁█▃▄▄▃▅▇▃▇▆▄▆▆▃▂▅▅▃▂▄▅▃▃▂▃▁▂█
wandb:      train/ensemble_f1 ▅▄▄▂▄▃▄▄▅▄█▂▄▄▄▄▃▅▃▃▆▄▅▄▃▂▇▂▃▂▅▄▃▅▃▃▂▅▁█
wandb:         train/mil_loss ▆█▃▅▇▄▅▄▅▃▆▅▅▅▄▅▄▃▇▃▆▄▄▄▄▆▃▂▅▄▅▂▆▂▃▃▅▃▂▁
wandb:      train/policy_loss ▇▇▇▇▆▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▅▇▇▇▇▇▇▇▇▅▇▇▃▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆█▅▆▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▄▆▆▆▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.37958
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79404
wandb:      eval/avg_mil_loss 0.45426
wandb:       eval/ensemble_f1 0.79404
wandb:            test/avg_f1 0.78852
wandb:      test/avg_mil_loss 0.5729
wandb:       test/ensemble_f1 0.78852
wandb:           train/avg_f1 0.81312
wandb:      train/ensemble_f1 0.81312
wandb:         train/mil_loss 1.48703
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4ghdpz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090322-zx4ghdpz/logs
wandb: Agent Starting Run: jxs2onoy with config:
wandb: 	actor_learning_rate: 1.9292522471704028e-05
wandb: 	attention_dropout_p: 0.4509017745214344
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9633787214234564
wandb: 	temperature: 6.520398936377051
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090505-jxs2onoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxs2onoy
wandb: uploading history steps 54-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▂▅▅▅█▄▅▂▅▄▇▆▃▃▅▃▄▄▃▅▃▆▄▅▄▂▆▅▆▆▁▆▄▅▅▄▄▇▄
wandb:      eval/avg_mil_loss ▃▅▄▄▂▁▃█▅▅▂▃▅█▆▃▁▃▃▃▄▃▄▂▃▄▃▄▇▂▃▄▆▅▄▄▃▂▆▄
wandb:       eval/ensemble_f1 ▆▂▅▅▅█▄▅▂▅▄▇▆▃▃▅▃▄▄▃▆▅▃▆▆▅▆▂▆▅▆▃▁▆▄▄▅▂▄▄
wandb:           train/avg_f1 █▅▃▄▃▂▄▄▅▄▃▅▄▅▄▅▄▄▄▄▃▆▃▃▁▆▆▅▄▄▄▃▃▂▄▁▅▃▅▃
wandb:      train/ensemble_f1 █▅▃▄▅▄▄▅▅▄▃▅▄▃▅▄▅▅▆▄▄▅▃▆▃▁▂▆▆▅▄▃▃▂▄▁▅▃▅▃
wandb:         train/mil_loss ▅▆▇▄▆▆▅█▇▄▄▄▄▅▅▆▂▂▄▇▂▆▃▃▂▅▆▂▃▂▂▆▂▁▂▃▅▃▂▁
wandb:      train/policy_loss ▆▆█▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84759
wandb: best/eval_avg_mil_loss 0.37343
wandb:  best/eval_ensemble_f1 0.84759
wandb:            eval/avg_f1 0.79849
wandb:      eval/avg_mil_loss 0.45208
wandb:       eval/ensemble_f1 0.79849
wandb:           train/avg_f1 0.79713
wandb:      train/ensemble_f1 0.79713
wandb:         train/mil_loss 1.29776
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxs2onoy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090505-jxs2onoy/logs
wandb: ERROR Run jxs2onoy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: eazkx70p with config:
wandb: 	actor_learning_rate: 1.5121644935629266e-05
wandb: 	attention_dropout_p: 0.1890644359919943
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3160559788419818
wandb: 	temperature: 3.0948479689029895
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090613-eazkx70p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eazkx70p
wandb: uploading history steps 144-157, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▇▇██
wandb: best/eval_avg_mil_loss ▆▃▃▁█▂▅▂▂
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▇▇██
wandb:            eval/avg_f1 ▅▅▅▇▅▂▂▆█▃▄▆▆▇▃▅██▆▆▇▆▄▅▆▆▄▇▃▁▅▅▁▇█▇▅▅▆█
wandb:      eval/avg_mil_loss ▅▃▄▅▂▃▄▃▆▄▄▆▁▄▃▄▃▁▂▄▃▅▇▆▆▅▅▂▃█▂▄▄▇▁▃▅▃▃▁
wandb:       eval/ensemble_f1 ▄▃▅▅▂▅▆▃▆▃▆▄▅▂▆▆▄▃▅▃▅▄▅█▂▄▅▅▂▇▇▅▅▅▂▃▆▁▄▅
wandb:           train/avg_f1 ▆▃▃▄▂▅▃▃▅▂▃▃▃▇▃█▄▆▅▅▂▄▆▆▆▁▃▃▇▅▇▃▂▄▂▅▅▂█▇
wandb:      train/ensemble_f1 ▄▄▅▇▄▅▄▄▆▁▆▅▁▃▁▆▅▇▅▇▅█▄▆▃▆█▄█▆▂▅▅▄▃█▆▄▇▆
wandb:         train/mil_loss ▅▇▇█▆▅█▇▆▇▆█▂▆▆▇▄▅▃▅▅▅▅▇█▅▁▃▆▃▃▃▄▁▅▆▆▆▃▃
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▅▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84553
wandb: best/eval_avg_mil_loss 0.36673
wandb:  best/eval_ensemble_f1 0.84553
wandb:            eval/avg_f1 0.8348
wandb:      eval/avg_mil_loss 0.39519
wandb:       eval/ensemble_f1 0.8348
wandb:           train/avg_f1 0.81411
wandb:      train/ensemble_f1 0.81411
wandb:         train/mil_loss 1.81722
wandb:      train/policy_loss -0.39121
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.39121
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eazkx70p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090613-eazkx70p/logs
wandb: ERROR Run eazkx70p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: s9a5a6l9 with config:
wandb: 	actor_learning_rate: 9.558472497488524e-05
wandb: 	attention_dropout_p: 0.2778895377729178
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3217739281755996
wandb: 	temperature: 4.987876867657821
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090919-s9a5a6l9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9a5a6l9
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 93-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▅▅█
wandb: best/eval_avg_mil_loss █▄▅▁▃▇
wandb:  best/eval_ensemble_f1 ▁▄▅▅▅█
wandb:            eval/avg_f1 ▆▁▃▆▄▆▅▇▃▇▄▄▃▄▄▅▆▄▄▃▄▃▂▅▂▄█▆▅▅▅▃▅▃▂▄▆▅▆▃
wandb:      eval/avg_mil_loss ▂▃▃▂▃▁▂▃▄▆▂▅▆▄▅▅▂▃█▂▃▃▂▄▅▄▃▄▂▄▅▄▅▅▂▁▁▄▃▆
wandb:       eval/ensemble_f1 ▅▆▆▃▅▆▃▅▄▄▁▃▄▅▆▃▅▆▂▃▆▅▂█▆▆▆▅▃▂▁▄▅▆▃▅▄▆▃▅
wandb:           train/avg_f1 ▄▆▄▃▆▅▆▂▅▄▁▅▇▅▄▆▆▄▅▄▃▅▇▄▃▂▄▁▂▇▆▅▆▇▂▄█▂▄▃
wandb:      train/ensemble_f1 ▄▁▅▄▅▆▅▄▄▄▅▄▆▅█▅▅▄█▄▅▄▄█▃▃▆▄▂▃▄▁▄▇▄▆▅▃▃▁
wandb:         train/mil_loss ▆█▆▅▅▃▆▃▇▅▆▅▄▃▄▃▄▆▂▅▆▅▇▃▇▅▅▄▅▄▅▄▅▃▆▅▃▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████▁██████████▆█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86321
wandb: best/eval_avg_mil_loss 0.36323
wandb:  best/eval_ensemble_f1 0.86321
wandb:            eval/avg_f1 0.7834
wandb:      eval/avg_mil_loss 0.48285
wandb:       eval/ensemble_f1 0.7834
wandb:           train/avg_f1 0.80731
wandb:      train/ensemble_f1 0.80731
wandb:         train/mil_loss 1.75099
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9a5a6l9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090919-s9a5a6l9/logs
wandb: ERROR Run s9a5a6l9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7h0u3jwo with config:
wandb: 	actor_learning_rate: 0.0003612122854368032
wandb: 	attention_dropout_p: 0.22099678291069824
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4444651733581535
wandb: 	temperature: 2.6110117144661316
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091118-7h0u3jwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7h0u3jwo
wandb: uploading history steps 139-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▇▅█▆▃▄▆▇██▇▅▅█▆█▅▇▂▆▁▆▇▅▃▃▆▇▄▆▃▇▅▄▄▅▅█▅▅
wandb:      eval/avg_mil_loss ▄▅▅▅▄▃▅▅▆▂▅▇▆▆█▂▃▅▃▂▄▆▅▅▆▆█▅█▇▃▅▄▆▄▅▁▄▇▇
wandb:       eval/ensemble_f1 ▄▃▄▄▇▅▆▁▅▄▄▃▆▆▄▄▄▆▅▆▂▅▄▄▃▄▆▄▄█▅▆▃▃▄▅▄▆▄▄
wandb:           train/avg_f1 ▆▃▅▅▁▇▃▃█▅▅▅▄█▇▆▅▆▇▆▇▅▃▅▂▆▅▅█▄▅▄▃▁▅▆▃▆▅▄
wandb:      train/ensemble_f1 ▆▄▅▆▆▂▃▄▇▆▂█▅▅▅▄▄▁▅▄▅▄▇▆▇▄▆▂█▆▅▆█▇▅▂▅▃▆▅
wandb:         train/mil_loss ▇▇▆▅▇█▆▅▅▅▅▅▇▅▅▆▆▄▃▄▂▄▅▃▃▂▄▄▄▃▃▄▂▂▁▃▂▂▂▁
wandb:      train/policy_loss ▄▁▁█▄██▄▁▄▁▁▄▁█▄▄█▄▁█▁█▄▁▁▄▁█▁▄▄▄█▄▄▄▄█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▁▁██▄██▄▄▁▁▁█▄▄▄█▄▁█▄█▁▄█▄▁▄▁▁▁▁█▄██▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.39329
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.76955
wandb:      eval/avg_mil_loss 0.51731
wandb:       eval/ensemble_f1 0.76955
wandb:           train/avg_f1 0.77594
wandb:      train/ensemble_f1 0.77594
wandb:         train/mil_loss 0.80552
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7h0u3jwo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091118-7h0u3jwo/logs
wandb: ERROR Run 7h0u3jwo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 2rljyv41 with config:
wandb: 	actor_learning_rate: 0.0008080621419045549
wandb: 	attention_dropout_p: 0.49954291495981223
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5638688307564026
wandb: 	temperature: 5.227541188343535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091425-2rljyv41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rljyv41
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▇█
wandb: best/eval_avg_mil_loss █▃▂▂▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆▇█
wandb:            eval/avg_f1 ▆▃▆▅▃▅▃▇▆▆█▆▃▇▆▇▆▇▂▆▅██▅▃▃▅▅▃▃▅▆▅▆▁▇▄▄▃▅
wandb:      eval/avg_mil_loss ▃▂▃▃▂▃▂▃▄▃▄█▅▄▆▄▁▆▅▄▄▄▁▃▆▄▇▄▅▄▃▄▁▅▆▄▂▃▇█
wandb:       eval/ensemble_f1 ▅▅▃▃▇▆▄▃▆▅▆▃▅▅▆▄▃▄▆▄▄▇▄▆▅▄▃▄▁▁▄▄▄▃▅▂▄▃█▂
wandb:           train/avg_f1 ▅▆▆▇▄▅█▇▇▆▅▄▄▆▆█▆▄▅█▆▆▄▆▂▃▆▅▇▄▃▁▅▃▄▃▇▃▃▄
wandb:      train/ensemble_f1 ▆▃▇▆▆█▅▄▂▇▅▆▇▇▅▃▅▃▆▄▅▄▅▃▅▂▅▅▃▅▅▅▄▅▂▃▂▂▄▁
wandb:         train/mil_loss █▅▆▅▃▆▄▄▆▇▇▄▄▄▄▇▂▇▅▃▂▄▄▃▃▂▂▅▃▃▃▁▃▄▅▂▂▂▂▃
wandb:      train/policy_loss ▁▃▃▃▃▃▃▃▃▃▃▅▃▂▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▄▃▃▃▃▃▃▃▃█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▅▅▅▅▅▅▅█▅▅▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.41535
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.75521
wandb:      eval/avg_mil_loss 0.55542
wandb:       eval/ensemble_f1 0.75521
wandb:           train/avg_f1 0.78001
wandb:      train/ensemble_f1 0.78001
wandb:         train/mil_loss 0.58645
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rljyv41
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091425-2rljyv41/logs
wandb: ERROR Run 2rljyv41 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ph0onuu5 with config:
wandb: 	actor_learning_rate: 0.00012621286654659897
wandb: 	attention_dropout_p: 0.35433908120729785
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5248998912004862
wandb: 	temperature: 4.774723586181877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091747-ph0onuu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph0onuu5
wandb: uploading history steps 53-65, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇▇█
wandb: best/eval_avg_mil_loss ▆█▄▁▂
wandb:  best/eval_ensemble_f1 ▁▅▇▇█
wandb:            eval/avg_f1 ▅▇▆▄▄█▇▄▆▇▆▆▃▆█▄▅▇▄▅▆▄▅▄▂▆▅▄▅▅▆▇▅▁▅▅▄▄█▄
wandb:      eval/avg_mil_loss █▆▆▅▄▄█▇▅▂▅▆▂▅▅▆▅▅▆▆▁▅▆█▅▆▄▇▄▄▃▅▇▃▃▇▄▆▂▇
wandb:       eval/ensemble_f1 ▅▇▅▄▄▇▇▄▄▅▆▅▆▅▃▆▄▆▅▇▆▄▇▅▄▆█▆▅▄▆▆▅▅▁▅▄▄█▄
wandb:           train/avg_f1 ▄▇▆▅▅▄▂▆▆▇▆▄▄█▄▆▅▃▁▅█▇▃▇▆▇▅▃▅▅▅▅▄▆▆▅▇▄▆▇
wandb:      train/ensemble_f1 ▆▅▅▂▇▄▃▆▄▄▃█▄▅▅▆▅▃▁▄▆▄▇█▃▇▆▅▃▅█▅▅▆▆▅▇▄▆▇
wandb:         train/mil_loss ▅▃█▅▄▆▁▆▃▆▄▇█▅▅▆▄▄▆▅▅▅▆▃▅▅▇▅▃▅█▄▅▇▇▃▁▆▁▆
wandb:      train/policy_loss ▅▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▄▄▄▁▄█▄▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81689
wandb: best/eval_avg_mil_loss 0.42919
wandb:  best/eval_ensemble_f1 0.81689
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.51281
wandb:       eval/ensemble_f1 0.76275
wandb:           train/avg_f1 0.78901
wandb:      train/ensemble_f1 0.78901
wandb:         train/mil_loss 0.80918
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph0onuu5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091747-ph0onuu5/logs
wandb: ERROR Run ph0onuu5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tznkukm1 with config:
wandb: 	actor_learning_rate: 6.436683408786786e-06
wandb: 	attention_dropout_p: 0.34829613480340677
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09201054619129424
wandb: 	temperature: 2.671131305999114
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091908-tznkukm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tznkukm1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▇█
wandb: best/eval_avg_mil_loss ▇█▄▃▁▄
wandb:  best/eval_ensemble_f1 ▁▃▅▆▇█
wandb:            eval/avg_f1 ▂▃▄▃█▄▃▄▂▇▅▄▇▆▃▄▂▄▇▇▁▅▅▅▆▅▅▄▅▅▇▂▃▅▅▆█▄█▆
wandb:      eval/avg_mil_loss ▇▄▄▄▄▇▃▃▃▁▆▄▃▇▄▄▃▃▇▅▅▅▂▃▅▄▅▄▂██▆▄▄▃▄▅▄▃▂
wandb:       eval/ensemble_f1 ▂▄▆▃▃▃▂▃▂▆▄▃▄▃▇▃▂▄▆▆▁▅▄▃▄█▃▅▄▄▁▅▃▅▄▇▅▆▃▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▂▅▇▁▅▆▅▅▇▅▆▆▃▅█▅▆▄▃▅▄▆▄▃▅█▇▆▅▁▄▇▃▆▄▁▃
wandb:      train/ensemble_f1 ▇▃▄▄▂▆▆▁▆▆▄▆▆▃▅▂▄█▄▅▄▅▄▆▅▂▅▅█▅▅▅▅▆▄▃▃▄▁▃
wandb:         train/mil_loss ▇▄▅▆▆▅▄▅▂▄▅▆▅▄▇▃▅▅▂▆█▂▂▅▁▃▃▄▅▁▄▂▇▄▅▄▃▅▃▃
wandb:      train/policy_loss ▅▅▅█▁▅▅▇▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85224
wandb: best/eval_avg_mil_loss 0.44046
wandb:  best/eval_ensemble_f1 0.85224
wandb:            eval/avg_f1 0.81611
wandb:      eval/avg_mil_loss 0.36634
wandb:       eval/ensemble_f1 0.81611
wandb:            test/avg_f1 0.78811
wandb:      test/avg_mil_loss 0.51205
wandb:       test/ensemble_f1 0.78811
wandb:           train/avg_f1 0.80091
wandb:      train/ensemble_f1 0.80091
wandb:         train/mil_loss 1.7069
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tznkukm1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091908-tznkukm1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rfsa60va with config:
wandb: 	actor_learning_rate: 1.988793370684172e-05
wandb: 	attention_dropout_p: 0.061533098075507664
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2995258888807877
wandb: 	temperature: 3.4047901816664696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092101-rfsa60va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfsa60va
wandb: uploading history steps 119-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss █▄▁▃▂
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▅▄▂▇▆▆▁▃▂█▁▂▄▅▅▃▄▄▅▄▄▄▄▅▂▃▅▃▂▄▇▃▄▃▄▇▄▃▄▄
wandb:      eval/avg_mil_loss ▇▄▁▄▅▃▆▅▆▆█▄▅▆▇▄▄▄▅▃▆▆▇▄▆▇▇▃█▆█▃▅▆▄▃▆▇▅▆
wandb:       eval/ensemble_f1 ▆▆▄▇▃█▇▆▄▁▄▂▁█▆▅▅▅▁▄▄▃▄▄▃▄▃▁▇▃▆▃▅▅▄█▅▅▅▇
wandb:           train/avg_f1 ▃▂█▆▂▇▅▅▂▇▂▅▄▃▁▃▃▇▄▅▃▄▅▅▅▇▁▄▄▆▅▃▇▄▄▆▃▅▂▆
wandb:      train/ensemble_f1 ▆▄▆█▅▆▆▅▇▇▄▃▆▅▅▄▇▆▇▃▆▅▄▂██▅▆▆▆▃▁▄▆█▅▄▅▅▆
wandb:         train/mil_loss ▆▇▄▆▃▅█▄▄▅▃▇▆▃▆▅▆▃▆▆▄▄▃▄▃▁▃▇▂▄▃▂▃▃▄▇▃▂▂▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▁▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84964
wandb: best/eval_avg_mil_loss 0.37017
wandb:  best/eval_ensemble_f1 0.84964
wandb:            eval/avg_f1 0.79927
wandb:      eval/avg_mil_loss 0.46532
wandb:       eval/ensemble_f1 0.79927
wandb:           train/avg_f1 0.80588
wandb:      train/ensemble_f1 0.80588
wandb:         train/mil_loss 0.95661
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfsa60va
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092101-rfsa60va/logs
wandb: ERROR Run rfsa60va errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: oobeu8vt with config:
wandb: 	actor_learning_rate: 1.0679616806413308e-05
wandb: 	attention_dropout_p: 0.0534249613980326
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6882895988584318
wandb: 	temperature: 7.417150823007754
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092330-oobeu8vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oobeu8vt
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▅▅▆█
wandb: best/eval_avg_mil_loss █▅█▅▃▁█
wandb:  best/eval_ensemble_f1 ▁▄▄▅▅▆█
wandb:            eval/avg_f1 ▃▁▅▅▆▄▆▄▄▅▆▅▅▅█▄▅▅█▄▃▅▇▄▄▅▄▄▄▅▅▃▅▁▃▂▅▅▅▅
wandb:      eval/avg_mil_loss ▄▅█▄▆▅▁▄▃▃█▅▃▅▄▆▆▆█▆▂▆▄▇▆▄▆▆▅▃▅▅▃▆▇▆▆▃▄█
wandb:       eval/ensemble_f1 ▂▃▂▅▄▆▃▄▄▅▅▆▅▇▃▄▄▄█▅▇▇▅▁▅▃▂▆▅▄▄▅▆▃▇▂▂▂▅▅
wandb:           train/avg_f1 ▆▅▃▄▁▄▅▆█▆▄▆▆▃▆▄▂▄▅▅▇▇▄▇▂▃▄▅▃▆▁▆▆▅▅▅▇▇▅▆
wandb:      train/ensemble_f1 ▆▅▅▃▆▄▄▆▅▄▄▆▃▄▅▆▆█▆▇▄▆▇█▇▁▅▅▇▅▂▂▇▆▂▆▅▆▅▂
wandb:         train/mil_loss ▄▂▆▄▄█▄▄▃▆▄▂▄▄▄▂▅▄▃▁▄▅▄▃▄▅▂▃▂▆▄▃▄▆▃▅▄▄▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84231
wandb: best/eval_avg_mil_loss 0.43767
wandb:  best/eval_ensemble_f1 0.84231
wandb:            eval/avg_f1 0.79429
wandb:      eval/avg_mil_loss 0.37556
wandb:       eval/ensemble_f1 0.79429
wandb:           train/avg_f1 0.79725
wandb:      train/ensemble_f1 0.79725
wandb:         train/mil_loss 0.92284
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oobeu8vt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092330-oobeu8vt/logs
wandb: ERROR Run oobeu8vt errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kwv7nqby with config:
wandb: 	actor_learning_rate: 2.3341768495038804e-05
wandb: 	attention_dropout_p: 0.04172694767539914
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.539897920242467
wandb: 	temperature: 1.8006450064638813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092637-kwv7nqby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwv7nqby
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▅▃█▇▇█▄▆▆▇▆▄▃▄▃▅▅▅▄▇▂▅▅▅▄▇▇▆▃▆▄▆▆▇▄▄▁▅▅
wandb:      eval/avg_mil_loss ▄▃▃▂▆▄▂▃▄▄▄▆▅▂▇▅▆▆▄▆█▆▃▄▅▃▄▃▄▆▃▄▅▃▃▁▁▃▄▄
wandb:       eval/ensemble_f1 ▄█▅▃▆▄▄▆▅▄▆▇▅▄▄▃▅▅▄▁▇▅▅▅▄▇▆▅▅▇▄▆▆▆▄▅▅▄▃▅
wandb:           train/avg_f1 ▄▃▅▆▄▆▄▅▅▃▆▆▅▅▄▃▃▄▁▃▃▄▄▃▆▂▄▄▅▄▄▅▄▅▄█▆▃▆▄
wandb:      train/ensemble_f1 ▄▃▆▆▄▅▅▃▅▄▆▆▅▄▄▃▃▃▄▁▄▄▃▄▄▄▆▂▆▄▄▄▄▄▄▄█▄▃▄
wandb:         train/mil_loss ▂▄▅▂▆▅▆▂▆▆█▄█▇▅▄▇▄▆▂▆▅▄▄▂▅▃▄▄▅▁▅▂▄▆▁▅▂▄▄
wandb:      train/policy_loss ███████████▅██▂█▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▅█▂█▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.38318
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80113
wandb:      eval/avg_mil_loss 0.43567
wandb:       eval/ensemble_f1 0.80113
wandb:           train/avg_f1 0.80756
wandb:      train/ensemble_f1 0.80756
wandb:         train/mil_loss 1.87128
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwv7nqby
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092637-kwv7nqby/logs
wandb: ERROR Run kwv7nqby errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cvns0n1n with config:
wandb: 	actor_learning_rate: 2.4313770996840843e-05
wandb: 	attention_dropout_p: 0.09452399159388249
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0459654977728613
wandb: 	temperature: 0.15842507497190628
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092759-cvns0n1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvns0n1n
wandb: uploading history steps 125-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▅▇█
wandb: best/eval_avg_mil_loss ██▂█▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅▅▇█
wandb:            eval/avg_f1 ▅▅▇▇▅▅▅▅▅▆▃▅▅▇▅▄▅▄▁█▅▅▅▅▆▇▄▆▄▅▄▄▆▆▅▆▄▄▆▅
wandb:      eval/avg_mil_loss ▅▂▂▅▅▂▄▄▄▆▄█▄▅▃▃▄▅▇▄▅▁▄▃▄▆▂█▄▄▃▂█▃▄▄▄▄▄▃
wandb:       eval/ensemble_f1 ▇▃▅▄▄▅▅▄▆▅▅▁█▅▆▅▅▅▅▄▇▄▄▇▆▂▅▄▅▆▅▆▅▆▅▅▃▆▅▅
wandb:           train/avg_f1 ▆▁▃▃▇▄▇▄▃▆▅▂▅▄▄▄▆▇▇▃▄▅▆▅▃█▇▅▇▂▄▄▆▇▆▆▆▃▃▅
wandb:      train/ensemble_f1 ▁▆▄▂▃▂▃▅▁▆▆▆▄▃▂▆▅▄▆▂▄▇▇▇█▄▃▂▃▂▅▄▄▅▃▃▃▁▁▃
wandb:         train/mil_loss ▇█▆▇▆▇██▆▇▆▇▃▃▆▆▅▇▆▅▄▄▅▆▅▅▄▄▃▅▄▃▁▃▃▂▁▄▇▅
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▄▄▁██▁▁▄██▄▁▄▄▁▄▄▁███▁▄▄▄██▁█▄█▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.4302
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.78084
wandb:      eval/avg_mil_loss 0.49248
wandb:       eval/ensemble_f1 0.78084
wandb:           train/avg_f1 0.78615
wandb:      train/ensemble_f1 0.78615
wandb:         train/mil_loss 0.90481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvns0n1n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092759-cvns0n1n/logs
wandb: ERROR Run cvns0n1n errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lf96x4g5 with config:
wandb: 	actor_learning_rate: 0.0003725268044206139
wandb: 	attention_dropout_p: 0.3687567710280643
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28109333223771127
wandb: 	temperature: 5.434496838575493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093101-lf96x4g5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lf96x4g5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄███
wandb: best/eval_avg_mil_loss ▄█▄▁▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄███
wandb:            eval/avg_f1 ▃▅▃▄▃▆▄▅▆▆▄▅▂▆▅▆▇▁▆▃▆▇▅▇▄▆▃▃▇▆▅▃▂▃▄▆▅█▂▄
wandb:      eval/avg_mil_loss ▂▄▂▄▄▆▃▇▃▆▅▅▄▄▅▂▂▁▄▁▃▃▁▂▄▃▂▂▁▃█▇▄▃▄▃▄▄▂▆
wandb:       eval/ensemble_f1 ▅▃▄▃▇▆▇▆▂▅▇▃▇▁▃▃▅▆▇▅▇▄▂▇▆▂▃▂▅█▇▃▁▃▂▂▆▄█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▅▄▅▄▅▃▄▅▆▅▆▅▃▃▄▅▅▅▃▁▄▅▅▅▃▄▆▆▆▄▅▆▅▄▇▄▅▃
wandb:      train/ensemble_f1 ▅█▅▅▄▅▆▅▃▄▃▅▆▅▃▄▅▅▅▂▃▃▅▃▅▁▅▅▄▅▆▄▆▆▄▅▄▇▅▃
wandb:         train/mil_loss ▅▄▇▇▄▅▅▅▅▄██▅▄▅▅▄▄▅▅▆▂▄▃▃▆▅▃▆▁▃▇▄▃▅▆▇▁▅▅
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81717
wandb: best/eval_avg_mil_loss 0.398
wandb:  best/eval_ensemble_f1 0.81717
wandb:            eval/avg_f1 0.77005
wandb:      eval/avg_mil_loss 0.51847
wandb:       eval/ensemble_f1 0.77005
wandb:            test/avg_f1 0.70324
wandb:      test/avg_mil_loss 0.76307
wandb:       test/ensemble_f1 0.70324
wandb:           train/avg_f1 0.76981
wandb:      train/ensemble_f1 0.76981
wandb:         train/mil_loss 0.82818
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lf96x4g5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093101-lf96x4g5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5bcdwj8t with config:
wandb: 	actor_learning_rate: 2.2703022414887176e-05
wandb: 	attention_dropout_p: 0.3710670137872386
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4821765452383525
wandb: 	temperature: 8.976631677247324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093244-5bcdwj8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bcdwj8t
wandb: uploading history steps 170-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆██
wandb: best/eval_avg_mil_loss ▇▂█▇▁
wandb:  best/eval_ensemble_f1 ▁▆▆██
wandb:            eval/avg_f1 ▄▃▅▆▄▅▆▄▆▁▃▇█▁▄▇▇▆▄▂▃▄▃▅▆▇▆▃▇▆▆▂▆▅▁▇▄▄▅▂
wandb:      eval/avg_mil_loss █▅▅▂▁▄▂▇▆▄▃▂▅▆▅▃▄▃▃▃▆▄▇▅▁▃▂▄▂▅▃▂▅▅▆▆▂▇▅▅
wandb:       eval/ensemble_f1 ▃▅▂▄▃▅▅▅▄▆▅▅▄▆▂▇▄▆▆▅▇▅▆▇▅█▆▅▂▃▂█▅▄▄▅▄▄▄▁
wandb:           train/avg_f1 ▅█▂▅▄▆▄▁▇▃▆▆▃▄▅▅▆▇▃▅▇▅▆▆▅█▄▃▅▅▂▅▂▄▆█▇▃▅▄
wandb:      train/ensemble_f1 ▅▂▄█▇▁█▃▆▄▇▄▅▃▅▅▃▇█▅▆▆▁▆▁▅▅▆▂▄▅▄▇▅▂▃▇▃▇▂
wandb:         train/mil_loss ▇██▇▅▅█▇▆▆▆▆▄▇▄▅▄▅▅▅▅▄▄▃▄▆▄▃▃▄▃▃▃▄▃▁▃▂▂▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄█▁▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.40751
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.78467
wandb:      eval/avg_mil_loss 0.48025
wandb:       eval/ensemble_f1 0.78467
wandb:           train/avg_f1 0.78916
wandb:      train/ensemble_f1 0.78916
wandb:         train/mil_loss 0.99803
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bcdwj8t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093244-5bcdwj8t/logs
wandb: ERROR Run 5bcdwj8t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e0t7oo76 with config:
wandb: 	actor_learning_rate: 0.0003717799595309047
wandb: 	attention_dropout_p: 0.35053341892563555
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8628851771120444
wandb: 	temperature: 3.745122796000409
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093653-e0t7oo76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0t7oo76
wandb: uploading history steps 168-180, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▆█
wandb: best/eval_avg_mil_loss █▆▅▅▄▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆▆█
wandb:            eval/avg_f1 ▂▆▄▅▄▂▃▃▄▅▃▁▆▃▅▂▃█▇▄▆▃▂▂▇▁▃▅▅▇▄▄▂▃▆▅▃▃▄▃
wandb:      eval/avg_mil_loss ▅▄▄▄▅▅▃▂▁▃▂▃▁▃▃▂▃▃▄▃▄▃▄▆▅▆▇█▅▂▄▄▃▃▄▆▆▄▄▅
wandb:       eval/ensemble_f1 ▃▆▄▆▅▃▁▂▃▅▇▄▄▃▂▄▆▄█▄▇▅▃▅▅▄▄▇▃▅▂▂▆▆▄▄▅▂▆▅
wandb:           train/avg_f1 ▅▄▆▅▄▃▄▅▄▄▆▄▄▃▂▃▄▃▆▄▄▃▃▆▆▄▃▇▂▅▅▄▅▄▄█▄▆▁▄
wandb:      train/ensemble_f1 ▅▄▄▂▂▅▄▁▁▄▂▃▃▃▄▅▂▇▇▄█▃▃▆▅▇▅▆▄▇▄▅▂▇▅▄▆▃▃▅
wandb:         train/mil_loss ▇▅██▇▆▆▇▇▇▄▅█▅▂▆▆▅▆▅▄▃▄▅▄▄▄▁▄▆▆▄▂▁▃▃▂▃▁▁
wandb:      train/policy_loss ▁▄██▄▄▁█▄▄█▄▄▄██▄▄█▁█▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▁▅▅█▅▁█▅█▁▅▅█▅█▁██▅▁▁██▅█▅▅▅▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84651
wandb: best/eval_avg_mil_loss 0.38252
wandb:  best/eval_ensemble_f1 0.84651
wandb:            eval/avg_f1 0.76611
wandb:      eval/avg_mil_loss 0.48094
wandb:       eval/ensemble_f1 0.76611
wandb:           train/avg_f1 0.78555
wandb:      train/ensemble_f1 0.78555
wandb:         train/mil_loss 1.05442
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0t7oo76
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093653-e0t7oo76/logs
wandb: ERROR Run e0t7oo76 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: go2ky8ti with config:
wandb: 	actor_learning_rate: 6.455372448352759e-05
wandb: 	attention_dropout_p: 0.1903925648261911
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.919630418126012
wandb: 	temperature: 9.34492577994068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094030-go2ky8ti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go2ky8ti
wandb: uploading history steps 148-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇▇▇█
wandb: best/eval_avg_mil_loss █▄▃▃▂▃▁
wandb:  best/eval_ensemble_f1 ▁▄▅▇▇▇█
wandb:            eval/avg_f1 ▁▅▇▄▅▂▇▆▄▇▂█▅▆█▆▇▇▄▅▅▆▆▆█▆▃▄▅▄▇▄▂▆▇▆▃▅▄▂
wandb:      eval/avg_mil_loss ▃▂█▂▅▂▄▂▃▅▁▂▃▅▁▇▂▂▆▇█▂▄▄▂▄▁█▅▃▆▁▄▅▆▅▄▄▄█
wandb:       eval/ensemble_f1 ▁▄▄▇▆▂▂▅▅▄▄▅▄▃█▅▆▃▆▅▃▄▆▆▅▄▆▂▂▄▅▅▆▁▄▄▆▃▃▂
wandb:           train/avg_f1 ▄▇▆▆▅▄▅▅▅▅▆▇▃▅▄▄▆▄▆█▄▃▃▃▄▅▄▅▃▄▃▄▃▃▄▃▂▅▃▁
wandb:      train/ensemble_f1 ▆▄▅▄▅▅▇▃▇▇█▆▄▅▅▃▃▄▃▂▃▃▄▁▃▂▆▂▄▁▂▆▂▃▁▃▂▄▁▃
wandb:         train/mil_loss ▆▇██▄▆▆▄▅▇▅▅▅▆▅▄▄▄▄▃▄▄▃▃▄▄▂▄▄▄▃▃▁▄▂▁▁▂▂▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▄▆▁▆▆▆▅█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▄▅▆▆▆▁▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.41181
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.75901
wandb:      eval/avg_mil_loss 0.54342
wandb:       eval/ensemble_f1 0.75901
wandb:           train/avg_f1 0.77235
wandb:      train/ensemble_f1 0.77235
wandb:         train/mil_loss 1.33766
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go2ky8ti
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094030-go2ky8ti/logs
wandb: ERROR Run go2ky8ti errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ryetyn4a with config:
wandb: 	actor_learning_rate: 2.1049028119794272e-05
wandb: 	attention_dropout_p: 0.2417943868448829
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 179
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.742829260256917
wandb: 	temperature: 3.3588878311495183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094351-ryetyn4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ryetyn4a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▄▇▅█▅▄▆▆▅▄▄▄▄▅▅▅▂▅▄▃▅▅▄█▅▄█▅▅▁▄▅▄▅▅▆▅▄▁▂
wandb:      eval/avg_mil_loss ▃▂▁▂▆▃▂▇▁▃▃▃▄▇▃▃▂▁▂▅█▃▃▅▁▂▃▃▆▃▂▇▇▅▂▆▃▅█▆
wandb:       eval/ensemble_f1 █▇▃▃▄▆▅▂▄▅▄▃▄▅▄▄▅▄▃▄▄▅▆▂▄▅▃▃▂▇▅▅▆▅▃▄▆▅▁▄
wandb:           train/avg_f1 ▇▄▄▅▅██▇▇▅▅▆▇▅▅▇▇▄▅▅▆▄▆▃▅▃▅▅▅▂▅▂▄▂▃▆▂▃▅▁
wandb:      train/ensemble_f1 ▇█▄█▄▆▆▇▄▅▅▆▆▅▆▇▅▅▅▆▆▆▆▅▅▄▃▅▄▄▂▄▂▃▄▅▃▃▅▁
wandb:         train/mil_loss █▇▆▆▆▆▆▅▅▆▅▆▅▅▅▅▃▆▃▄▄▃▄▄▅▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▇▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▃█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▄▃▃▃▄▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▁▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86466
wandb: best/eval_avg_mil_loss 0.37764
wandb:  best/eval_ensemble_f1 0.86466
wandb:            eval/avg_f1 0.77329
wandb:      eval/avg_mil_loss 0.48484
wandb:       eval/ensemble_f1 0.77329
wandb:           train/avg_f1 0.77177
wandb:      train/ensemble_f1 0.77177
wandb:         train/mil_loss 1.37854
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ryetyn4a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094351-ryetyn4a/logs
wandb: ERROR Run ryetyn4a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 6bw89tyh with config:
wandb: 	actor_learning_rate: 5.7206040487497626e-05
wandb: 	attention_dropout_p: 0.4478146437681773
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.990835650418978
wandb: 	temperature: 5.785713433763787
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094754-6bw89tyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6bw89tyh
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄█
wandb: best/eval_avg_mil_loss ▅▁█▇
wandb:  best/eval_ensemble_f1 ▁▄▄█
wandb:            eval/avg_f1 ▅▆▄▃▄▆▃▄▄▁▄▅▄▃▃▂▂▃▄▃▂█▂▄▃▄▅▃▅▄▅▂▁▄▂▁▆▆▅▄
wandb:      eval/avg_mil_loss ▂▁▃▄▃▄▃▆▆▆▄▇▄█▃▃▃▃▆▃▃▃▄▃▂▃▃▅▄▃▂▆▄▃▄▃▃▄▄▅
wandb:       eval/ensemble_f1 ▆▄▄▄▆▄▄▄▂▃▄▅▅▃▆▃▃▄▃▅▄█▃▆▃▁▄▆▆▆▆▆▃▃▄▆▆▅█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▂▄▅▄▅▅▅▇█▅▆▂█▂▇▇▂▆▃▄▅▄▃▆▆▄▄▄▅▄▄▄▇▅▄▃▂▃
wandb:      train/ensemble_f1 ▁▄▆▅▆█▅▇▅▆▅▆▇▃▅▆▃▇▃▆▃▄▆▆▅▆▅▄▄▅▅▄▅█▆▆▂▅▅▄
wandb:         train/mil_loss ▅▁▃▆▅▃▃▄▅▆▁▂▂▃▇▆▆▅▃▅▁▃▄▆▃▅█▄▅▄▅▁▃█▄▄▃▆▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84271
wandb: best/eval_avg_mil_loss 0.40467
wandb:  best/eval_ensemble_f1 0.84271
wandb:            eval/avg_f1 0.79135
wandb:      eval/avg_mil_loss 0.49944
wandb:       eval/ensemble_f1 0.79135
wandb:            test/avg_f1 0.80565
wandb:      test/avg_mil_loss 0.34991
wandb:       test/ensemble_f1 0.80565
wandb:           train/avg_f1 0.78741
wandb:      train/ensemble_f1 0.78741
wandb:         train/mil_loss 0.50651
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6bw89tyh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094754-6bw89tyh/logs
wandb: Agent Starting Run: a2hpmw7g with config:
wandb: 	actor_learning_rate: 6.271835983885393e-06
wandb: 	attention_dropout_p: 0.162731680357456
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1428757180445982
wandb: 	temperature: 3.929845113228454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094922-a2hpmw7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a2hpmw7g
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 130-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▁▃▁▃▃▄▁▂
wandb:  best/eval_ensemble_f1 ▁▄▄▄▅▅▆▇█
wandb:            eval/avg_f1 ▃▁▅▂▃▃▄▅▁▂▆▅▄▄▄▂▂▄▄▄▃▄▄▄▅▆▅▃▅▅▅▃▄▇▄▅▃▃█▄
wandb:      eval/avg_mil_loss ▆▅▂▁▄▂▄▇▅█▃▅▄▅▅▄▅▄▃▅▄▄▄▂▂▃▄▅▂▁▂▃▂▂▄▆▁▅▄▆
wandb:       eval/ensemble_f1 ▆▆▃▇▃▅▇▄▅▄▆▅▅▄▄▅▆▄▆▃▅▃▄▆▄▆▆▆▄▆▅▆▆█▅▁▃▆▄▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▄▆▅▇▃▄▄▅▅▄█▅▄▆▆▅▇▃▅▇▇▆▇▃█▇▇▅▆▅▄▆▇▅▆▇▄▁
wandb:      train/ensemble_f1 ▆▄▄▇▄▇▅▇▆▃▄▄█▄▆▆▅▇▅▅▃▇▅▆▃▄▅▄▄▃▆▇▅▇▅▄▇▆▅▁
wandb:         train/mil_loss ▇▅▇█▆▇▇▄█▃▅█▁▆▄▅▅▆▇▁▅▄▇▄▁▄▅▄▅▅▂▃▃▅▄▁▁▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85665
wandb: best/eval_avg_mil_loss 0.38131
wandb:  best/eval_ensemble_f1 0.85665
wandb:            eval/avg_f1 0.80626
wandb:      eval/avg_mil_loss 0.51365
wandb:       eval/ensemble_f1 0.80626
wandb:            test/avg_f1 0.78256
wandb:      test/avg_mil_loss 0.52837
wandb:       test/ensemble_f1 0.78256
wandb:           train/avg_f1 0.80642
wandb:      train/ensemble_f1 0.80642
wandb:         train/mil_loss 1.31936
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a2hpmw7g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094922-a2hpmw7g/logs
wandb: Agent Starting Run: ue0ksfpo with config:
wandb: 	actor_learning_rate: 2.3995823571604343e-05
wandb: 	attention_dropout_p: 0.0349999094263197
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7377465040014111
wandb: 	temperature: 5.130055860330083
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095208-ue0ksfpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue0ksfpo
wandb: uploading history steps 147-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▇█
wandb: best/eval_avg_mil_loss █▇▅▁▃
wandb:  best/eval_ensemble_f1 ▁▂▄▇█
wandb:            eval/avg_f1 ▃▅▇▄▄▅▆▅▃▅▇█▅▄▁▆▃▆▅▆▅▆▁▆▆▅▅▆▄▇▆▄▃▅▄▄▅▄▆▄
wandb:      eval/avg_mil_loss ▄▄▁▅▄▄▄█▅▄▅▃▃▅▆▄▅▆▄█▄▅▇▄▆▃▅▅▅▆▆▆▆▇▇▆▄█▅▇
wandb:       eval/ensemble_f1 ▃▇▃▆▄▂▄▃▃█▄▃▆▃▆▄█▅▅▃▅▅▆▆▄▂▃▆▅▃▅▇▂▄▅▇▃▁▄▁
wandb:           train/avg_f1 ▅▇█▇▇▆▆▆█▅▅▃▅▇▅▄▆▇█▆▅▆▅▅▅▁▇▃▃▃▅▂▆▃▄▃▂▆▅▁
wandb:      train/ensemble_f1 ▇█▇▅▆▇▆█▆▆▄▇▄▆█▆▅▆▅▆▅▆▆▆▅▄▄▃▃▆▃▄▄▅▃▄▆▄▁▅
wandb:         train/mil_loss █▇▅▆▅▆▇▅▇▆▇▄▄▆▅▆▄▄▃▄▄▃▃▅▄▄▃▃▃▂▂▃▂▂▂▂▁▁▁▁
wandb:      train/policy_loss ▃▃▃▃▃█▃▃▁▃▃▃▃▃▃▃▃▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄█▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▂▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86776
wandb: best/eval_avg_mil_loss 0.35231
wandb:  best/eval_ensemble_f1 0.86776
wandb:            eval/avg_f1 0.82845
wandb:      eval/avg_mil_loss 0.46664
wandb:       eval/ensemble_f1 0.82845
wandb:           train/avg_f1 0.78495
wandb:      train/ensemble_f1 0.78495
wandb:         train/mil_loss 1.24611
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue0ksfpo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095208-ue0ksfpo/logs
wandb: ERROR Run ue0ksfpo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1om9li4k with config:
wandb: 	actor_learning_rate: 8.827857776846184e-06
wandb: 	attention_dropout_p: 0.2568841289569681
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5888996254868109
wandb: 	temperature: 2.6500616352657493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095550-1om9li4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1om9li4k
wandb: uploading wandb-summary.json
wandb: uploading history steps 115-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▆▇█
wandb: best/eval_avg_mil_loss █▁▄▂▃▂
wandb:  best/eval_ensemble_f1 ▁▅▆▆▇█
wandb:            eval/avg_f1 ▄▄▅▁▅▇▃█▄▃▅▂▅▅▄▆▅▃▆▆▅▅▂▄▆▆▅▅█▃▄▆▁▆▃▆▆▆█▃
wandb:      eval/avg_mil_loss ▂▄█▄▂▂▅▄▅▅▁▄▄▃▅▂▁▂▆▄▆▆▄▃▆▂▅▅▂▃▇▃▄▁▅▂▅▅▃▅
wandb:       eval/ensemble_f1 ▄▅▁▅▁▆▆▁▅██▃█▆▇▂▇▁▄▇▅▅▃▂▆▅▆█▆▄▄▃█▂▆▃▇▆▃▁
wandb:           train/avg_f1 ▅▄▅▄█▃▃▅▄▂▄▃▇▇▂▆▂▆▂▃▄▄▅▄▃▅▅▂▁▃▆▅▃▄▄▇▆▁▇▄
wandb:      train/ensemble_f1 ▄▄▄▃▄▆▃▄▅▄▃▄▃▄▅▄▂▄▁▆▃▅▃█▃▅▅▅▄▁▆▄▁▂▅▄▆▄▄▂
wandb:         train/mil_loss ▁▇▄▆█▅▄▆▇▇▄▇▅▅█▂▄▆▅▃▁▄█▇▅▅▅▄▃▇▇▄▆▄▆▃▅▄▇▅
wandb:      train/policy_loss ████████████▁█▅█████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.41467
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.80563
wandb:      eval/avg_mil_loss 0.49054
wandb:       eval/ensemble_f1 0.80563
wandb:           train/avg_f1 0.79166
wandb:      train/ensemble_f1 0.79166
wandb:         train/mil_loss 0.79453
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1om9li4k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095550-1om9li4k/logs
wandb: ERROR Run 1om9li4k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 42acae45 with config:
wandb: 	actor_learning_rate: 6.921185289744615e-05
wandb: 	attention_dropout_p: 0.47295931587037343
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2869752550730136
wandb: 	temperature: 6.924475164568653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095825-42acae45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/42acae45
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆█
wandb: best/eval_avg_mil_loss ▁█▇▂
wandb:  best/eval_ensemble_f1 ▁▄▆█
wandb:            eval/avg_f1 ▄▅▆▇▅▅▄▃▄▄▄▄▅▅▂▅▄▆▄▅▂▄▆▄▅▁▆▂▆▃▆▅▃▃▅▆▄█▄█
wandb:      eval/avg_mil_loss ▂▃▄▁▅▁▂█▂▃▃▂▃▃▄▄▃▂▅▃▃▄▃▃▃▂▃▃▁▃▃▂▂▃▄▂▃▂▃▃
wandb:       eval/ensemble_f1 ▅█▃▆▆▅▇▇▅▆▄▄▄▆▃▅▃▅▅▅▅▆▅▁▇▆▆▇▄▇▄▃▂▆▅▃▆▄▃▆
wandb:           train/avg_f1 ▆▄▇▃▄▆▅▄▆█▄▇▆▆▅▃▁▂▁▅▇▆▇▁▇▄▅█▇▂▃▄▆▅▇▃▇▇▄▅
wandb:      train/ensemble_f1 ▄▆▄▆▇▇▅▆▄▄▁▆▅▂▄▇▃▆▄▆█▅█▆▇▄▄▂▃▅▂▃▅▆▄█▄▇▄▅
wandb:         train/mil_loss ▅▆▇█▂▄▆▅▇▆▅▃▄▄▇▅▄▄▃▆▅▄▃▄▂▄▃▃▄▃▅▆▃▄▅▃▃▅▄▁
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.38115
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.84231
wandb:      eval/avg_mil_loss 0.40029
wandb:       eval/ensemble_f1 0.84231
wandb:           train/avg_f1 0.80761
wandb:      train/ensemble_f1 0.80761
wandb:         train/mil_loss 1.05594
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/42acae45
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095825-42acae45/logs
wandb: ERROR Run 42acae45 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ewzoq9bx with config:
wandb: 	actor_learning_rate: 1.1047573448721348e-06
wandb: 	attention_dropout_p: 0.01218052113661966
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8531304242632609
wandb: 	temperature: 5.2775596102143005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100055-ewzoq9bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewzoq9bx
wandb: uploading history steps 166-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▅▄▅▅▃▃▅▃▅▅▄▃▄▆▄▃▅▂█▄▅▄▂▅▅▂▁▄▅▅▃▃▅▃▂▄▄▅▃
wandb:      eval/avg_mil_loss ▂▃▅▅▅▅▃▄▆▄▅▄▄▄▅▆█▆▆▁▁▄▅█▆▆█▅▄█▃▇▅▇▃▆▂▆▆▄
wandb:       eval/ensemble_f1 █▅▄▅▂▆▄▅▅▃▄▆▄▃▆▁▅▅▅▁▅▅▂▅▅▄▄▆▂▅▄▆▄▄▄▄▅▂▄▄
wandb:           train/avg_f1 ▅▅▄▇▆▂▇▅▃█▅▃▃▃▂▅▅▁▅▃▄▂▆█▇▅▇▅▃▅▅▄▁▃▄▆▆▄▃▇
wandb:      train/ensemble_f1 ▆▇▃▇▂▅▆▆▇▄▅▃▆▁▆▆▅▆▅▅▃▅█▇▆▄▅▅▆▆▄▆▄▄▃▃▁▃▆▆
wandb:         train/mil_loss ▇▇██▇▅▇▆▆▅▇▆▄▆▅▄▄▃▄▄▃▅▅▄▄▂▄▃▃▃▃▁▄▄▁▁▁▃▁▃
wandb:      train/policy_loss ▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▅▆▆▆▆█▆▆▆▆▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄█▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87177
wandb: best/eval_avg_mil_loss 0.42023
wandb:  best/eval_ensemble_f1 0.87177
wandb:            eval/avg_f1 0.77735
wandb:      eval/avg_mil_loss 0.49494
wandb:       eval/ensemble_f1 0.77735
wandb:           train/avg_f1 0.81043
wandb:      train/ensemble_f1 0.81043
wandb:         train/mil_loss 0.90047
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewzoq9bx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100055-ewzoq9bx/logs
wandb: ERROR Run ewzoq9bx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ry2lri89 with config:
wandb: 	actor_learning_rate: 9.188532974331809e-06
wandb: 	attention_dropout_p: 0.2483283145952186
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.004905234464092301
wandb: 	temperature: 3.667645728293559
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100427-ry2lri89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry2lri89
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇▇█
wandb: best/eval_avg_mil_loss █▃▂▃▁
wandb:  best/eval_ensemble_f1 ▁▅▇▇█
wandb:            eval/avg_f1 ▇▂▄▁▇▂▄▅▅▂▆▆▆▇▅▂▄▅▅▃▅▆▄▅▆█▄▅▃█▃▃▆▅▅▁▂▅▄▂
wandb:      eval/avg_mil_loss ▅▄▂▃▁▆▅▂▁▆▂▃▅▃▄▄▄▄▂▄▄▂▄▃▄▅▂▂▃▄▁▆▄▄▅▅▇▄▂█
wandb:       eval/ensemble_f1 ▂▃█▃▂▅▅▆▅▃▄▄▄▅▆▆▃▂▆▃▃▅▅▇█▆▅▆▄▆▄▅▄▆▄▁▄▃▄▃
wandb:           train/avg_f1 ▄▅▃▅▃▅▆▄▄█▃▇▄▅▄▄▄▄▇█▅▄▃▅▄▂▅▆▄▅▄▃▅▃▄▅▃▅▃▁
wandb:      train/ensemble_f1 ▆▅▃▇▅▅▆█▆▅▅▅▆▅▆▅▄▆▆▆▅▅▅▄▅▄▄▄▄▄▄▅▁▅▅▃▂▄▃▂
wandb:         train/mil_loss █▇▆▇▇▆▇▇▆▇▆▅▅▄▅▅▂▅▄▅▄▃▃▃▄▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂
wandb:      train/policy_loss ▅▅█▅▂▅▅▅▅▃▅▅▁▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃█▄▃▄▃▂▃▃▃▃▃▁▃▃▃▃█▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85373
wandb: best/eval_avg_mil_loss 0.3911
wandb:  best/eval_ensemble_f1 0.85373
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.47348
wandb:       eval/ensemble_f1 0.78777
wandb:           train/avg_f1 0.78275
wandb:      train/ensemble_f1 0.78275
wandb:         train/mil_loss 1.37462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry2lri89
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100427-ry2lri89/logs
wandb: ERROR Run ry2lri89 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: csjmw8nx with config:
wandb: 	actor_learning_rate: 7.85889170846697e-05
wandb: 	attention_dropout_p: 0.2189732870365968
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9942279311437396
wandb: 	temperature: 6.084041894178177
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100836-csjmw8nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csjmw8nx
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▆▆█
wandb: best/eval_avg_mil_loss ▄▂▂▄▃█▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆▆▆█
wandb:            eval/avg_f1 ▅▅▆▅▆█▂▃▆▁█▅▇▄▆▄▃▆▇▅▃▅▆▅▆▆▇▅▄▄▃▅▆▄▅▄▇▃▄▅
wandb:      eval/avg_mil_loss ▄▃▅█▄▃▅▇▃▃▅▅█▂▇▁▃▄▃▆▆▇▅▇▂▆▇▅▆█▅▂▇▅▂█▅▄▄▂
wandb:       eval/ensemble_f1 ▆▇▅▇▂▂▁▂▇▄▃█▆▆▆▄█▆▅▂▅▄▇▃▄▄▇▅▅▅▆▄▆▅▃█▂▄▅▆
wandb:           train/avg_f1 ▅█▄▄▆▆▅▄▆█▅▅▇▃▁▃▆▄▆▆▄▆▃▂▃▂▅▅▃▄▆▄▂▄▅▄▃▅▂▅
wandb:      train/ensemble_f1 ▂▄▆▆▅█▃▃▄▇▅▃▄▅▃▃▄█▁▄▅▅▃▄▅▄▂▃▃▃▅▁▃▆▄▄▅▄▅▅
wandb:         train/mil_loss ▆▆▅▅▅▆▄▆▆▄▆▅▆█▄█▂▅▄▃▆▆▆▄▄▄▂▃▃▂▇▅▄▁▂▄▅▄▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.39721
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.78402
wandb:      eval/avg_mil_loss 0.46089
wandb:       eval/ensemble_f1 0.78402
wandb:           train/avg_f1 0.7814
wandb:      train/ensemble_f1 0.7814
wandb:         train/mil_loss 1.33767
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csjmw8nx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100836-csjmw8nx/logs
wandb: ERROR Run csjmw8nx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: euygwwrc with config:
wandb: 	actor_learning_rate: 4.653092146804248e-06
wandb: 	attention_dropout_p: 0.1389782942497042
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.443562802519079
wandb: 	temperature: 2.4643809489578397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101137-euygwwrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/euygwwrc
wandb: uploading history steps 157-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂██
wandb: best/eval_avg_mil_loss █▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂██
wandb:            eval/avg_f1 ▄▅▆▄▄▅█▄▆▁▅▃▇▄█▅▄▅▂▆▄▄▂▅▅▃▄▄▅▃▅▆▃▆▄▅▆▄▆▅
wandb:      eval/avg_mil_loss ▃▁▁▃▂▄▄▃▅▇▆▁▃▁▅▁▅▄▂▄▄▄▂▆▇▆▅▄▃▅▅█▇▃▅▄▆▇▃▆
wandb:       eval/ensemble_f1 ▁▄▃▄▅▃▃▅▆▆▆█▄██▆▅▄▁▁▄▃▆▇▄▂▆▃▂▄▂▅▅▄▆▃▂▁▅▂
wandb:           train/avg_f1 ▃▄▅█▅▃▄▇▅▇▅▅▂▅▆▄▇▆▇▄▅▆▄▄▆▅▃▂▅▁▄▆▃▂▄▂▃▅▂▂
wandb:      train/ensemble_f1 ▃▆██▇▃▅▅▇█▄▇▆▇▄▅▅▄▇▁▆▇▄▆▅▅▄▃▃▄▅▂▄▄▂▅▆▃▅▁
wandb:         train/mil_loss █▇▆▇▆▆▇▅▇▅▆▅▆▅▅▄▄▄▃▄▃▃▃▃▅▃▂▂▂▂▃▁▄▃▂▃▂▂▂▂
wandb:      train/policy_loss █▆▁▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▃▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▁▃▃▃▃▁▃▃▃▃▃▃▃█▃▃▃▃▃▃▆▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.42183
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.77353
wandb:      eval/avg_mil_loss 0.49245
wandb:       eval/ensemble_f1 0.77353
wandb:           train/avg_f1 0.76809
wandb:      train/ensemble_f1 0.76809
wandb:         train/mil_loss 1.09692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run woven-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/euygwwrc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101137-euygwwrc/logs
wandb: ERROR Run euygwwrc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5olo2lek with config:
wandb: 	actor_learning_rate: 0.0004467566680258691
wandb: 	attention_dropout_p: 0.04788477881039099
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5895427245473757
wandb: 	temperature: 0.11097219615949117
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101524-5olo2lek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5olo2lek
wandb: uploading wandb-summary.json
wandb: uploading history steps 77-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▇▄█▆▆▂▆▂▇▃▅▄▄▄▄▄▅▄▅▁█▃▅▄▂▆▅▆▆▆▃▆▅█▆▇▆▅▆▅
wandb:      eval/avg_mil_loss ▃▃▆▆▄▂▃▆▄▄▄▃▁▃▅▆▄▃▃▅█▂▅▄▃▂▃▆▃▃▅▅▄▅▃▂▅▇▁▃
wandb:       eval/ensemble_f1 ▃▇▆▃█▇█▇▇▇▄▃▃▄▅▃▇▆▂▇▄▄▂▇▄▅▅▆▅▅▂▆▁█▅▆▄▆▇▅
wandb:           train/avg_f1 █▆▅▂▅▅▃▅▄▄▄▃▄▆▇▆▆▆▆▆▇▆▇▅▄▅▂▄▇▅▆▅▃▅▅▇▄▅▁▅
wandb:      train/ensemble_f1 █▅▄▁▅▄▂▆▅▅▃▅▆▃▂▂▆▅▇▂▂▅▅▆▅▇▄▄▄▅▇▃▇▄▅▅▅▄▃▆
wandb:         train/mil_loss ▆▂█▅▆▄▂▅▃▄▅▄▃▅▅▃▅▅▅▃▄▃▂▅▅▄▅▅▄▄▁▃▂▂▃▆▁▅▃▃
wandb:      train/policy_loss ██████████████▁█████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83391
wandb: best/eval_avg_mil_loss 0.34803
wandb:  best/eval_ensemble_f1 0.83391
wandb:            eval/avg_f1 0.79376
wandb:      eval/avg_mil_loss 0.40401
wandb:       eval/ensemble_f1 0.79376
wandb:           train/avg_f1 0.80041
wandb:      train/ensemble_f1 0.80041
wandb:         train/mil_loss 1.53951
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5olo2lek
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101524-5olo2lek/logs
wandb: ERROR Run 5olo2lek errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: huzjrnug with config:
wandb: 	actor_learning_rate: 1.349963844542925e-05
wandb: 	attention_dropout_p: 0.3634766506105645
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01488364391785224
wandb: 	temperature: 8.509511453247102
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101738-huzjrnug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huzjrnug
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▄▃▂▃▃▄▅▄▄▅▆▅▅▄▁▅▄▂▅█▁▄▅▃▆▄▆▂▅▂▁▄▆▂▄▃▂▁▃▂
wandb:      eval/avg_mil_loss ▄▃▃▄▄▄▄▂▄▆▆▃▄█▄▃▄▂▄▅▁▃▁▄▄▃▄▄▄▄▃▄█▅▄▇▃▆▆▃
wandb:       eval/ensemble_f1 ▇▅▅▅▂▅▄▄▆▅▆▄▄▂▇▆▆▆▅▇▃▄▁▃█▃▆▆▄▄▅▂▇▄▅▂▃▄▃▃
wandb:           train/avg_f1 ▃▄▄▆▄▅▇▄▂▄█▄▃▄▅▅▃▇▅▅▂▅▄▅▄▇▃▅▄▆▄▄▃▁▄▄▃▄▄▄
wandb:      train/ensemble_f1 ▁▆█▆▅▅▃▆▃▃▂▆▄▄▄▂▄▅▄▄▄▃▄▆▅▆▃▁▃▃▃▁▃▃▂▂▂▃▂▃
wandb:         train/mil_loss ▅▃▅█▆▆█▅█▅▄▆▅▆▇▂▅▇▃▄▃▄▂▃▂▃▂▁▃▆▃▃▄▃▃▄▂▄▂▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86057
wandb: best/eval_avg_mil_loss 0.38146
wandb:  best/eval_ensemble_f1 0.86057
wandb:            eval/avg_f1 0.83179
wandb:      eval/avg_mil_loss 0.42824
wandb:       eval/ensemble_f1 0.83179
wandb:           train/avg_f1 0.80031
wandb:      train/ensemble_f1 0.80031
wandb:         train/mil_loss 1.58649
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huzjrnug
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101738-huzjrnug/logs
wandb: ERROR Run huzjrnug errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lcki6swj with config:
wandb: 	actor_learning_rate: 3.947637578493709e-05
wandb: 	attention_dropout_p: 0.06748629938014855
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22955358021760663
wandb: 	temperature: 7.0548724468625625
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102100-lcki6swj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcki6swj
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄█
wandb: best/eval_avg_mil_loss ▂█▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄█
wandb:            eval/avg_f1 ▆▅▇▄█▆▄▅▇▃▆▅▅▂▄▇▇▆█▇▆▆▇▄▄▄▇▆▂▆▇▃▅▇▁▄▆▅▇▅
wandb:      eval/avg_mil_loss ▄▆▅▃▃▅▅▄▃▅▅▂▄▂▅▃▃▂▇▅▃▄▄▅▄▅▃▂▂▃▄▃▆▄▃▅█▆▁▂
wandb:       eval/ensemble_f1 ▆▅▇▇▇▅▅▇▂▄▆▅▅▄▃▇▃█▃▇▃▅▃▇▃▇▁▆▆▆▅▇▆▆▄▄▄▆▄▇
wandb:           train/avg_f1 ▄▂▅▄▃▆▅▆▆▇▆▁█▅▄▄▃▃▅▂▄▆▃▅▃▄▃▃▅▇▇▆▂▆▃▃▃▃▁▂
wandb:      train/ensemble_f1 ▂▅▃▆▃▇▅▆▆▂▅▃▄▃▆█▃▄▃▄▄▆▄▆▆▄▁▇▂▃▇▇▃▂▃▃▃▅▅▃
wandb:         train/mil_loss ▅▄▅▆█▆▇▅▃▇▆▅▇▄▃▄▅▄▅▆▄▄▄▄▄▄▅▄▆▅▃▁▅▆▄▅▆▅▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.37222
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.78791
wandb:      eval/avg_mil_loss 0.45036
wandb:       eval/ensemble_f1 0.78791
wandb:           train/avg_f1 0.79566
wandb:      train/ensemble_f1 0.79566
wandb:         train/mil_loss 1.77815
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcki6swj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102100-lcki6swj/logs
wandb: ERROR Run lcki6swj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mccrajcu with config:
wandb: 	actor_learning_rate: 0.00012052782135105548
wandb: 	attention_dropout_p: 0.06644071076395414
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3687853088374431
wandb: 	temperature: 0.3493971044521005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102326-mccrajcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mccrajcu
wandb: uploading wandb-summary.json
wandb: uploading history steps 58-70, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ▇█▃▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▃▅▃▅▄▆▆▃▅▄▃▅▄▃▁▄▆▃▅█▆▂▃▃▃▇▅▁▄▃▅▅▂▄▆▅▃▃▄▇
wandb:      eval/avg_mil_loss ▃▄▆▃▆▅▆▂▅▆▄▇▄▅█▄▂▃▄▁▅▃▃▁█▂▆█▄▄▃▅▄▅▄▅▅▅▆▅
wandb:       eval/ensemble_f1 ▄█▆▄▆▃▇▇▁▆▇▅▆▅▇▅▄▆▇▅▅▅▅█▅▆▆▂▅▆▅▇▆▅█▄▄▆▃▆
wandb:           train/avg_f1 ▆▄▇▃▆▆▄▆▃▃▇▄▄▇▅▁▅▃▇▅▆█▇▄▅▅▃▇▄▄▄▂▄▅▅▆▄▄▇▂
wandb:      train/ensemble_f1 ▇▄▄▆▅▄█▄▅▄▆▇▆▇▁▃▇▆▅▅█▄▅▄▆█▅▅▂▄▄▅▇▆▆▅▄▅█▂
wandb:         train/mil_loss ▄▆▆▄▄▅▄▄▅▂▆▁▄▂▃▅▅▅▆▄▅▃█▃▄▄▅▅▅▁▄▄▅▅▃▆▃▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83197
wandb: best/eval_avg_mil_loss 0.3533
wandb:  best/eval_ensemble_f1 0.83197
wandb:            eval/avg_f1 0.79163
wandb:      eval/avg_mil_loss 0.49629
wandb:       eval/ensemble_f1 0.79163
wandb:           train/avg_f1 0.79954
wandb:      train/ensemble_f1 0.79954
wandb:         train/mil_loss 0.8582
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mccrajcu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102326-mccrajcu/logs
wandb: ERROR Run mccrajcu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8pkx4xli with config:
wandb: 	actor_learning_rate: 1.1456795667406212e-05
wandb: 	attention_dropout_p: 0.4371341377090811
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 57
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24912086986569237
wandb: 	temperature: 0.23047350685326817
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102448-8pkx4xli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pkx4xli
wandb: uploading history steps 45-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▄▄▆▁▄▇▄▆▆▅█▅▅▄▄█▄▆▆▅▆▅▅▇▆▄▆▇▆▇▄▅▅▄▅▅▆▃
wandb:      eval/avg_mil_loss ▂▇▆▆█▄▃█▃▃▆▁▃▃▄█▆▄▄▄▁▅▇▆▃█▆▇▂▄▄▃▃▅▆█▆▅▅▂
wandb:       eval/ensemble_f1 ▆▄▄▄▄▆▄▁▄▇▄▆▆▅█▄▄▄█▄▅▆▅▆▆▄▇▆▄▇▇▄▅▅▆▄▅▅▆▃
wandb:           train/avg_f1 ▃▄▄▄▁▄▂▇▁▄▅▄▆▄█▃▂▄▇▃▃▁▇▄▂▄▅▅▂▃▅▄▂█▃▄▆▃▅▃
wandb:      train/ensemble_f1 ▃▅▆▃▄▄▁▃▄▇▄▅▄▂▆█▃▂▄▇▁▇▄▂▃▅▅▂▁▃▅▄▂█▇▄▆▃▅▃
wandb:         train/mil_loss ▅▅▁▄▄▆▂▃▄▂▅▅▃█▂▂▃▃▆▃▃▅▁▄▂▅▇▃▄▆▂▄▃▆▃▂▄▅▅▃
wandb:      train/policy_loss ▁▅▅█▅▅▅▅▁█▅▁▅▅▅█▅█▅▅▅█▅▁▅▅▅▅█▁▅▁▅▅▅▁▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▅▅▅▅▁▅█▁▅▁▅▁▅█▅▅▅▅█▅▁▅▅▅█▅█▁▅▁▅▅█▁▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.44633
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.76224
wandb:      eval/avg_mil_loss 0.49549
wandb:       eval/ensemble_f1 0.76224
wandb:           train/avg_f1 0.79053
wandb:      train/ensemble_f1 0.79053
wandb:         train/mil_loss 0.97487
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pkx4xli
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102448-8pkx4xli/logs
wandb: ERROR Run 8pkx4xli errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v32zsuc9 with config:
wandb: 	actor_learning_rate: 2.4402297497248344e-05
wandb: 	attention_dropout_p: 0.05094599443397618
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4254878875029443
wandb: 	temperature: 7.418178186503739
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102551-v32zsuc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v32zsuc9
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇▇▇█
wandb: best/eval_avg_mil_loss ▃█▁▄▁▃
wandb:  best/eval_ensemble_f1 ▁▄▇▇▇█
wandb:            eval/avg_f1 ▂▂▄▃▄▃▄▁▅▂▅▆▅▅▅▅▅▅▄▅▃▄▇▂▇▂▄▇▄▁▆▅▅█▄▃▃▄▃▅
wandb:      eval/avg_mil_loss ▃▃█▄▃▄█▃▅▃▂▄▅▃▅▄▃▂▅▃▄▆▃▂▆▁▅▄▅▄▄▅▅▂▄▅▃▄▄▆
wandb:       eval/ensemble_f1 ▃▃▅▄▃▅▅▅▅▆▅▄▃▄▄▅▅▅▅▆▄▄▆▄▃▅▄▂▇▁▅▇▂▃▇▅█▆▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆█▄▃▄▁▄▆▅▅▃▁▆▅▂▅▁▅▄▆▄▇▅▁▂▁█▃▂▂▃▄▃▃▄▃▅▃
wandb:      train/ensemble_f1 ▃▃▆█▂▃▄▃▆▄▅▄▁▂▄▂▂▆▄▅▅▂▃▁▅▄▃▃▁▄▄▃▄▄▇▃▅▃▁▄
wandb:         train/mil_loss █▅▅▅▆▅▆▅▅▆▇▅▆▅▆▅▅▄▄▆▅▄▂▅▄▃▅▃▅▂▅▃▃▅▄▁▄▃▄▄
wandb:      train/policy_loss ▄▄▂▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▃▄▄▄▇▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▅██▁▁▁█▁▅▁█▅▁█▅▅▁▁▅▅▅▅██▅██▅▅▅█▅▅▁▁▅██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85307
wandb: best/eval_avg_mil_loss 0.40675
wandb:  best/eval_ensemble_f1 0.85307
wandb:            eval/avg_f1 0.82836
wandb:      eval/avg_mil_loss 0.39805
wandb:       eval/ensemble_f1 0.82836
wandb:            test/avg_f1 0.80336
wandb:      test/avg_mil_loss 0.45047
wandb:       test/ensemble_f1 0.80336
wandb:           train/avg_f1 0.80228
wandb:      train/ensemble_f1 0.80228
wandb:         train/mil_loss 1.75821
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run serene-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v32zsuc9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102551-v32zsuc9/logs
wandb: Agent Starting Run: h5ngy92n with config:
wandb: 	actor_learning_rate: 3.822248796532522e-06
wandb: 	attention_dropout_p: 0.24670745124945348
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.264193522867457
wandb: 	temperature: 2.971641712956341
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102820-h5ngy92n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ngy92n
wandb: uploading history steps 48-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▄▅▆█
wandb: best/eval_avg_mil_loss ▅█▃▄▇▇▁
wandb:  best/eval_ensemble_f1 ▁▁▄▄▅▆█
wandb:            eval/avg_f1 ▅▄▄▃▅▆▅▃▆▆▁▃▃▅▃▃▅▄▅▆▅▆▄▃▆▄▅▁▂▄▃▅▇▃▄▄▅▇▅█
wandb:      eval/avg_mil_loss ▃▅▆▇▅▂▆▆▄▄█▅▃▅██▅▅▄▅▄▃▆▆▄▄▅█▄▇▆▃▄▅█▅▅▄▅▁
wandb:       eval/ensemble_f1 ▅▄▃▂▅▆▄▆▆▄▂▂▇▅▂▃▄▄▅▄▅▆▄▂▆▆▄▆▁▄▃▂▅▇▄▃▄▅█▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▅▂▄▃▇▅▃▆▆▄▅▆▁▆▄▃▆▅▄▃▄▅▄▃▄▅▃▄▂██▆▄▄▄▄▃
wandb:      train/ensemble_f1 ▄▄▄▇▅▁▄▃▇▅▅▆▅▅▆▄▆▄▅▄▆▄▄▃▃▅▁█▃▃▄▃▁██▄▄▃▄▂
wandb:         train/mil_loss █▅▆▆▆▅▇▅▅▃▄▃▆▄▄▄▃▄▃▄▄▅▄▃▁▆▄▃▅▄▄▄▅▃▅▄▂▃▃▅
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▃▅▅▅▄▅▅▅▅▅▅█▅▇▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▃▄▄▄▄▄▄▄█▄▇▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86057
wandb: best/eval_avg_mil_loss 0.37841
wandb:  best/eval_ensemble_f1 0.86057
wandb:            eval/avg_f1 0.86057
wandb:      eval/avg_mil_loss 0.37841
wandb:       eval/ensemble_f1 0.86057
wandb:            test/avg_f1 0.77059
wandb:      test/avg_mil_loss 0.54935
wandb:       test/ensemble_f1 0.77059
wandb:           train/avg_f1 0.79427
wandb:      train/ensemble_f1 0.79427
wandb:         train/mil_loss 2.04495
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ngy92n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102820-h5ngy92n/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w82apwt0 with config:
wandb: 	actor_learning_rate: 7.817203545775061e-06
wandb: 	attention_dropout_p: 0.2207026181968209
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19500002341930325
wandb: 	temperature: 4.319185244705517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102943-w82apwt0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w82apwt0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄█
wandb: best/eval_avg_mil_loss ▅▆█▁
wandb:  best/eval_ensemble_f1 ▁▃▄█
wandb:            eval/avg_f1 ▄▅▃▁▃▄▄▅▄▂▃▃▂█▅▃▄▄▃▅▂▁▃▁▂▄▃▂▆▄▄▃▄▃▆▂▇▃▂▅
wandb:      eval/avg_mil_loss ▂▅▁▂▄█▂▆▃▄▃▅▂▅▄▄▄▇▅▆▅▃▄▄▂▅▆▆▂▁▅▃▃▄▄▄▄▅▃▄
wandb:       eval/ensemble_f1 ▆▃▆▅▄▆▆▂▄▃▄▃▄▃▅▄▄▄▇▆▄▃▂▆▃▅▅▅▆▄▆▇▅▆▇▁▅█▄▅
wandb:           train/avg_f1 ▄▃▄▄▅▃▃▄▆▃▆▃▅█▃▂▅▂▁█▅▂▃▄▁▅▇▆▅▄▄▃▅▅▂▃▃▁▃▁
wandb:      train/ensemble_f1 ▄▅▂▃▁▄▄▅█▇▄▂▂▂▃▆▆▅▂▃▆▃▂▃▄▅▆▄▄▄▅▅▃▇▁▃▄▃▁▁
wandb:         train/mil_loss ▃▅▅▆▄▇▄▅▅▇▄▄▅▆▆▄▅▃▆▃▂▃▅▅▄▄▄▄█▃▃▄▄▃▅▅▄▄▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86071
wandb: best/eval_avg_mil_loss 0.35013
wandb:  best/eval_ensemble_f1 0.86071
wandb:            eval/avg_f1 0.77701
wandb:      eval/avg_mil_loss 0.4804
wandb:       eval/ensemble_f1 0.77701
wandb:           train/avg_f1 0.78624
wandb:      train/ensemble_f1 0.78624
wandb:         train/mil_loss 1.00479
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w82apwt0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102943-w82apwt0/logs
wandb: ERROR Run w82apwt0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a5p5pcih with config:
wandb: 	actor_learning_rate: 0.0005123618864191318
wandb: 	attention_dropout_p: 0.26436086744619347
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.056963693636991386
wandb: 	temperature: 1.010696206111923
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103259-a5p5pcih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5p5pcih
wandb: uploading history steps 68-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▁▃▆▃▂█▄▄▅▁▃█▆▅▃▅▆▆▇▆▄▄▂▇▅▂▄▅▄▄▄▆█▄▃▂▇█
wandb:      eval/avg_mil_loss ▃▄█▆▄▇▃▇▅▆▄▅▆▃▇▁▅▄▂▅▅▃▄▆▅▅▃▄▅▆▄█▆▅▆▃▆▄▆▄
wandb:       eval/ensemble_f1 █▂▁▃█▅▃▅▃▅▃█▆▆▄▆▇█▃▅▆▄▄▃▃▅▄▆▅▅▅▇█▅▅▃▆▅▅▅
wandb:           train/avg_f1 ▁▆▇▇▆▇▇▇▄▅▂▃▄▄▅▂▆▃▃▃▃▃▄▃▅▅▁▅█▇▁▆▄▄▆▄▇▆▆▃
wandb:      train/ensemble_f1 ▂▆█▇▆█▄▆▄▂▅▆▆▃▄▃▆▆▄▅▇▄▅▇▄▂▁▄█▅▅▇▂▆▄▇▅▇▅▇
wandb:         train/mil_loss ▇▄▇▃▅▅▄▄▄▆▅▅▇▁▄▆█▅▄▅▅▁▅▅▅▆▁▆▅▃▃▄▄▃▅▄▃▄▃▃
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄▁▄▁▄▄▁▁▁▄▁▁█▁▄▁▁▄▄█▄█▄▁▄▄▁█▁█▁█▄█▁▄█▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83168
wandb: best/eval_avg_mil_loss 0.42442
wandb:  best/eval_ensemble_f1 0.83168
wandb:            eval/avg_f1 0.79175
wandb:      eval/avg_mil_loss 0.43812
wandb:       eval/ensemble_f1 0.79175
wandb:           train/avg_f1 0.79581
wandb:      train/ensemble_f1 0.79581
wandb:         train/mil_loss 2.0893
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5p5pcih
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103259-a5p5pcih/logs
wandb: ERROR Run a5p5pcih errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n8wrkqkf with config:
wandb: 	actor_learning_rate: 1.7265723933403287e-05
wandb: 	attention_dropout_p: 0.28352705860763194
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7073323371438555
wandb: 	temperature: 1.1467452797170474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103445-n8wrkqkf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8wrkqkf
wandb: uploading history steps 120-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▆█▃▃▄▂▄▇▆▅▄▆▅▄▃▂▄▅▃▅▂▄▄▂▄▃▆▆▃▁▄▇▃▆▅▄▄▄▄▃
wandb:      eval/avg_mil_loss ▃▃▃▂█▄▄▃▃▃▃▂▆▃▅▂▃▆▃▃▃▄▅▂▅▃▃▅▇▁▆▄▄▃▃▄▃▅▂▃
wandb:       eval/ensemble_f1 ▃▅▆▅▄▅▅▅▃▅▅█▅▄▄▃▃▆▅▄▄▄▅▂▄▂▇▅▅▃▆▄▁▄▅▃▆▄▅▆
wandb:           train/avg_f1 █▂▆▆▃▂▅▅▇▄▆▆▇▁▄▃▄▅▅▆▃▁▃▆▆▄▄▅▆▂▅▄▅▃▃▄▃▄▃▆
wandb:      train/ensemble_f1 ▅▄▃▇▄▄▅▆█▆▆▂▇▄▆▄▅▁█▅▄▃▁▅▆▃▄▆▃▄▅▃▄▄▆▁▃▄▆▅
wandb:         train/mil_loss █▆▆▇▇▅█▅▄▅▇▇▇▆▄▄▃▄▃▅▅▆▃▅▅▃▃▅▆▄▃▂▁▂▄▄█▅▃▆
wandb:      train/policy_loss ▁▁██▅▁▅▅██▅▅▅▅▅▅▅▁▅██▅▅▅▅█▁▅▁▅▁█▁▅█▁▅█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▄▁██▁▄▄▁█▄▁██▄▄█▄▄███▁▁▄▄█▄▄▁▁▁▁▄▁▄▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84259
wandb: best/eval_avg_mil_loss 0.41074
wandb:  best/eval_ensemble_f1 0.84259
wandb:            eval/avg_f1 0.79895
wandb:      eval/avg_mil_loss 0.45519
wandb:       eval/ensemble_f1 0.79895
wandb:           train/avg_f1 0.79289
wandb:      train/ensemble_f1 0.79289
wandb:         train/mil_loss 0.84114
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run woven-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8wrkqkf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103445-n8wrkqkf/logs
wandb: ERROR Run n8wrkqkf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cdk5q55y with config:
wandb: 	actor_learning_rate: 0.00036814738797550376
wandb: 	attention_dropout_p: 0.3333833766979361
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.419451899150603
wandb: 	temperature: 7.699161136464024
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103741-cdk5q55y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdk5q55y
wandb: uploading history steps 41-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss █▁█▆▃
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▄▆█▂▃▄▆▅▅▇▃▆▇▆▅▅▄▄▅█▄▇▇▄▅▃▅▅▆▆▄▇▇▇▄▁▂▃▇▆
wandb:      eval/avg_mil_loss ▆▃▆▄▅▄▅▂▃▃▅█▃▄▅▂▃▅▆▂▃▂▃▄▄▃▅▄▃▄▄█▁▅▆▅▆▆▄▂
wandb:       eval/ensemble_f1 ▄▆█▂▃▄▆▄▅▇▃▇▆▅▃▄▄█▆▄▇▇▄▅▁▅▅▆▆▂▇▇▇▄▅▁▂▃▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▄▅▅▃▂▄▆▆▅▅▄▅▅▃▆▃▄▆▅▄▅▁▅▅▄█▄▅▄▆▄▄▇▅▃▇▅
wandb:      train/ensemble_f1 ▅▆▄▄▅▅▃▂▄▆▆▄▅▇▅▆▃▄▆▆▄▅▁▄▃▅▄█▄▃▄▆▄▄▆▅▅▃▇▅
wandb:         train/mil_loss ▄▆▇▅▁▅▆█▆█▃▄▂▃▄▆▆▂▄▄▄▅▃▇▆▅▄▆▆▄▇▃▃▆▄▆▃▁▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.43381
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.8065
wandb:      eval/avg_mil_loss 0.37256
wandb:       eval/ensemble_f1 0.8065
wandb:            test/avg_f1 0.83237
wandb:      test/avg_mil_loss 0.41402
wandb:       test/ensemble_f1 0.83237
wandb:           train/avg_f1 0.80471
wandb:      train/ensemble_f1 0.80471
wandb:         train/mil_loss 2.08537
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdk5q55y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103741-cdk5q55y/logs
wandb: Agent Starting Run: vlr5zqft with config:
wandb: 	actor_learning_rate: 0.000559304652127372
wandb: 	attention_dropout_p: 0.3253236694268936
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08761128637210669
wandb: 	temperature: 7.753714271127684
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103843-vlr5zqft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vlr5zqft
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 50-62, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▅▆█
wandb: best/eval_avg_mil_loss ▇█▆▄▁▄
wandb:  best/eval_ensemble_f1 ▁▁▄▅▆█
wandb:            eval/avg_f1 ▄▄▆▆▅▄▅▅▄▄▄▇▄▅▅▃█▁▂▂▃▅▅▆▅▃▅▆▆▅▂▂▅▄▂▄▇▂▄▆
wandb:      eval/avg_mil_loss ▅▆▇▇▃▅▅▆▅▄▂▄▃▁▄▅▆▄▅▅▃▄▂▃▆▂▂▂▅▆▅▅▃▇▆▆▄█▄▂
wandb:       eval/ensemble_f1 ▄▄▂▆▅▂▅▅▅▄▃▃▇▃▃▅▃█▁▁▁▂▃▅▅▅▂▅▃▆▄▁▁▅▃▃▄▇▁▆
wandb:           train/avg_f1 ▇▅▅▅▆▆▆▆▅▅▅▃▅▃▆▅▅█▆▅▆▄▅▄▆▃▆▁▆▇▅▅▂▆▆▅▃▆▇▆
wandb:      train/ensemble_f1 ▇▅▅▅▆▆▆▆▄▅▂▅▅▃▅▆▅▃▅█▆▄▅▆▇▄▃▆▅▁▇▆▅▄▂▅▅▃▇▆
wandb:         train/mil_loss ▃▄▅▄▄▃▅▃▅▆▅▆█▆▃▅▂▅▁▃▅▂▅▂▄▁▃▆▄▃▃▃▃▆▃▄▅▆▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.41422
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.82076
wandb:      eval/avg_mil_loss 0.38825
wandb:       eval/ensemble_f1 0.82076
wandb:           train/avg_f1 0.79499
wandb:      train/ensemble_f1 0.79499
wandb:         train/mil_loss 0.83011
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vlr5zqft
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103843-vlr5zqft/logs
wandb: ERROR Run vlr5zqft errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wblau8zm with config:
wandb: 	actor_learning_rate: 3.239627722374084e-05
wandb: 	attention_dropout_p: 0.23240096340792205
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6959706464814311
wandb: 	temperature: 0.643466993076135
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104006-wblau8zm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wblau8zm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▇▇▇█
wandb: best/eval_avg_mil_loss ▅▄▄█▃▃▁
wandb:  best/eval_ensemble_f1 ▁▄▄▇▇▇█
wandb:            eval/avg_f1 ▅▇▅▇▄▅▃▄▆▇▅▄▅▄▇▄▇▅▃▅▃▆▅▃▆█▄▆▅▆▄▅▄▂▅▃▃▅▆▁
wandb:      eval/avg_mil_loss ▅▆▃▇▂▂▄▁▅▅▃▃▇▃▄▅▃▆▆▆▁▃▃▄▆▇▇▃▆▄▁▂▆▆▅▃▆█▅▆
wandb:       eval/ensemble_f1 ▅▃▇▃▇▄▆▄▄▆█▄▅▅█▁▇▅▅▂▃▃▆▄▄▄▄▅▅▃▅▄▂▄▆▃▅▃▄█
wandb:           train/avg_f1 ▅▆▁▅█▃▆▄▅▃▃▅▄▅▄▄▅▄█▅▅▄▅▅▃▆▅▁▇▂▃▄█▃▂▇▃▄▄▃
wandb:      train/ensemble_f1 ▃▇▆▅▃▃▆▃▂▄▆▅▄▃▄█▇▄▃▄▅▂▄▄▃▃▁▆▄▅▆▃▆▅▃▅▅▅▂▂
wandb:         train/mil_loss ▇██▅▆▃█▅▆▄▅▆▄▇▆▃▆▅▂▄▅▅▅▃▁▄▃▁▃▂▃▄▃▄▂▃▄▂▃▁
wandb:      train/policy_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.39662
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.76252
wandb:      eval/avg_mil_loss 0.53469
wandb:       eval/ensemble_f1 0.76252
wandb:           train/avg_f1 0.79535
wandb:      train/ensemble_f1 0.79535
wandb:         train/mil_loss 1.83283
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wblau8zm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104006-wblau8zm/logs
wandb: ERROR Run wblau8zm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: r3pfom14 with config:
wandb: 	actor_learning_rate: 9.182080004155924e-05
wandb: 	attention_dropout_p: 0.06866548777808201
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14676004397759412
wandb: 	temperature: 1.445358523263025
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104231-r3pfom14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3pfom14
wandb: uploading history steps 83-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆█
wandb: best/eval_avg_mil_loss █▄▅▅▁
wandb:  best/eval_ensemble_f1 ▁▄▅▆█
wandb:            eval/avg_f1 ▄▂▆▂▄▅▆▇▃▆▄▃▆▃▁▃▃▄▃▃█▅▂▂▂▂▁▁▅▅▃▂▂▃▄▄▅▄▅▃
wandb:      eval/avg_mil_loss ▆▃▄▃▃▄▄▃▅▄▇█▆▆▆▅▄▄▄▇▄▁▄▅▆▅▃▃█▆▂▆▇▂▄▄▃▄▅▄
wandb:       eval/ensemble_f1 ▄▂▅▆▆▇▅▅▆▄▃▆▅▂▁▃▄▃▄▄▄█▆▄▃▄▄▅▃▂▅▅▅▃▅▄▄▆▅▆
wandb:           train/avg_f1 ▃▃█▇▇▄▅▃▇█▄▅▃▇▆▄▃▄▃▅▆▃▅▅▅▅▃▁▆▃▃▅▅▆▂▅█▇▅▅
wandb:      train/ensemble_f1 ▃▂█▄▄▆▄▄▅█▄▃▄▃▆▄▃▄▅▃▅▇▅▅█▃▁▆▅▆▆▃▃▅▄▅▅▇▇▅
wandb:         train/mil_loss █▇▅▅▆▆▅▆▇▇▇█▆▅▄▇▅▅▄▆▁▃▂▆▅▅▆▄▁▃▆▅▇▃▂▅▃▄▂▄
wandb:      train/policy_loss ▄█▄▄▁█▄▄▄▄▄█▄▁▄▄▁▄▄▄█▁█▄▄▄█▁▄▄█▁▄▄▄▁▄▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85398
wandb: best/eval_avg_mil_loss 0.37453
wandb:  best/eval_ensemble_f1 0.85398
wandb:            eval/avg_f1 0.81331
wandb:      eval/avg_mil_loss 0.40727
wandb:       eval/ensemble_f1 0.81331
wandb:           train/avg_f1 0.79542
wandb:      train/ensemble_f1 0.79542
wandb:         train/mil_loss 0.97666
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3pfom14
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104231-r3pfom14/logs
wandb: ERROR Run r3pfom14 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 01bflznv with config:
wandb: 	actor_learning_rate: 0.0009841570730710764
wandb: 	attention_dropout_p: 0.48035199636856674
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38796538583557705
wandb: 	temperature: 8.112274480980991
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104410-01bflznv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/01bflznv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇█
wandb: best/eval_avg_mil_loss ▂█▃▂▁▇
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇█
wandb:            eval/avg_f1 ▂▄▆▅█▃▆▃▃▅▇▃▄▄▅▁▇▆▃▆▂█▆▇▆▆▄▄▁▄▄▅▄▄▆▅▃▅▃▂
wandb:      eval/avg_mil_loss ▅▄▅█▅▅▄▂▅▄▄▄▄▄▄▄▅▃▆▄▄▃▄▅▁▅▅▆▄▆▄▆▅▅▃▄▅▇▅▂
wandb:       eval/ensemble_f1 ▃▄▂▃▆▅█▄▃▆▃▄▁▆▃▂▃▇▅▃▂▂▅▆▃▄▄▃▅▄▄▅▅▄▃▂▅▄▃▂
wandb:           train/avg_f1 ▇▆▇▂▅▄▅▁█▃▇▆▃▄▆▆▇▄▅▆▂▄▄▅█▅▆▇▂▄▆▃▅▄▇▅▄▆▆▆
wandb:      train/ensemble_f1 ▅▁▆▄▃▆▂▅▅▂▂▅▃▅█▅▁▆▂▃▄▅▅▂▂▅▁▅▂▁▂▄▄▂▅▄▃▅▅▆
wandb:         train/mil_loss ▅▇▆▅▅▄█▄█▁▅▄▆▆█▇▆▄▄▇▆█▅▅▅▇▆▇▄▅▅▆▅█▆▄▆▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.47199
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.49836
wandb:       eval/ensemble_f1 0.76597
wandb:           train/avg_f1 0.80837
wandb:      train/ensemble_f1 0.80837
wandb:         train/mil_loss 0.83305
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/01bflznv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104410-01bflznv/logs
wandb: ERROR Run 01bflznv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ix4yif4m with config:
wandb: 	actor_learning_rate: 4.2450905928423065e-06
wandb: 	attention_dropout_p: 0.28898980505506544
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42097114887107634
wandb: 	temperature: 8.50465687704636
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104538-ix4yif4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ix4yif4m
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▆▇█
wandb: best/eval_avg_mil_loss █▅█▁▇▃
wandb:  best/eval_ensemble_f1 ▁▅▆▆▇█
wandb:            eval/avg_f1 ▄█▇▄▇▃▆▅▄▅▅▂▄▃▅▄▄▅▂▃▇▇▃▅▃▄▃▃▆▁▆█▅▅▄▁▄▄▆▃
wandb:      eval/avg_mil_loss ▄▂▅▁▆▄▄▅▅▅▂▇▃▃▄▇▄▆▄▇▅▇▆▄▆▄▆▃█▄▃▂▄█▂▁▇▃▇▄
wandb:       eval/ensemble_f1 ▇▃▅▆▅▅▅▅▃▄▂▂▄▃▅▅█▃▃▄▅▄▆▇█▂▇▆▅▇▂▄▃▅▅▅▁▇▄▄
wandb:           train/avg_f1 ▁▂▅▂▅▅▅▄▆▁█▄▄▂▄▃▄▂▅▅▆▃▄▂▂▃▅▄▅▄▆▆▅▄▁▅▆▅▄▃
wandb:      train/ensemble_f1 ▅▃▆▇▆▄▂▃▆▅▃▇▅█▅▂▇▄█▃▅▄▄▄▇▂▆▇▆▆▆▆▇▇▆▅▄▂▅▁
wandb:         train/mil_loss ▆▆▆▆▅▇▇▆▅▅█▅▅▄▅▅▅▅▄▅▃▃▄▄▄▃▄▄▃▃▃▂▃▂▄▄▅▁▃▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁████████████████████████▃████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.42799
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.77713
wandb:      eval/avg_mil_loss 0.52735
wandb:       eval/ensemble_f1 0.77713
wandb:           train/avg_f1 0.79003
wandb:      train/ensemble_f1 0.79003
wandb:         train/mil_loss 0.85751
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ix4yif4m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104538-ix4yif4m/logs
wandb: ERROR Run ix4yif4m errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wj2iueqb with config:
wandb: 	actor_learning_rate: 3.7745533252201433e-06
wandb: 	attention_dropout_p: 0.26848137548465667
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07077638900556305
wandb: 	temperature: 0.28453097794640225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104936-wj2iueqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj2iueqb
wandb: uploading wandb-summary.json
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss ▆▁█
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▂▅▃▄▅▅▃▄▆▃▆█▇▅▄▂▄▄▂▂▃▃▅▅▅▆▅▃▃▁▆▅█▃▂▇▄▄▅▄
wandb:      eval/avg_mil_loss ▂▆▃▄█▇▆▄▅▆▄▅▇▁▄▇▃▆▂█▇▇▆▇█▆▅▆█▄▄▆▇▅▄▆▄▅▆▅
wandb:       eval/ensemble_f1 ▂▂▅▂▃▅▅▃▂▆▄▄▆▂▅▁▂▄▅▃▁▅▄▆▃▂▆▂▁▄█▆▂▂▄▄▄▆▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▇▆█▇▃▅▄▇▅▅▄▂▇▆▅▂▆█▅▄▄▅▇▄▆▄▄▆█▄▄▆█▇▁▆▇
wandb:      train/ensemble_f1 ▅▄▂▅▁▆▇▆▃█▅▂▂▄▄▇▄▁▄▅▂▂▄▃▆▃█▅▂▅▃▂▄▇▆▅█▃▇▄
wandb:         train/mil_loss ▅█▄▅▃▄▅▃▅▅▇▄▇▅▆▄▇▄▂▇▃▆▅▆▄▄▁▆█▄▄▆▅▄▆▅▄▅▅▃
wandb:      train/policy_loss ▁▄▄▁▁▄██▁█▁▄▁▄▄█▄█▄▄▄▁▄█▁▄▄▄▄██▄██▄▁▁▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▅▅█▁▁█▅█▁▁▅▁█▅▅█▅▅▅▁▅█▅▅▅▅▁▁▅▁▅█▅▁▅▅▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84631
wandb: best/eval_avg_mil_loss 0.43929
wandb:  best/eval_ensemble_f1 0.84631
wandb:            eval/avg_f1 0.77651
wandb:      eval/avg_mil_loss 0.46301
wandb:       eval/ensemble_f1 0.77651
wandb:            test/avg_f1 0.74447
wandb:      test/avg_mil_loss 0.50655
wandb:       test/ensemble_f1 0.74447
wandb:           train/avg_f1 0.80783
wandb:      train/ensemble_f1 0.80783
wandb:         train/mil_loss 0.98909
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj2iueqb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104936-wj2iueqb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k8ihwdsx with config:
wandb: 	actor_learning_rate: 0.0001257445934747285
wandb: 	attention_dropout_p: 0.4598370882172288
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9197816903678576
wandb: 	temperature: 1.370732573104262
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105150-k8ihwdsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8ihwdsx
wandb: uploading history steps 69-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▃
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▅▂▅▆▄▃▂▅▁▆▃▃▆▃█▄▄▆▃▅▄▃▅▆▄▆▃▂▅▆▆▄▇▃▄▇▃▃▄▃
wandb:      eval/avg_mil_loss ▅▅▅▇▇█▅▅▅▅▅▆▆▁▃▇▅▇▇▄▇▄▃▄▅▆▄▂▃▆▁▃▆▃▅▆▃▇▆▅
wandb:       eval/ensemble_f1 ▂▅█▄▃▄▆▄▄▁▅▆▃▃█▁▁▃▅▂▄▅▃▅▃▂▄▆▅▆▇▇▂▅▂▇▆▃▄▃
wandb:           train/avg_f1 ▃▃▃▃▁▃▄▁▅▄▃▃▄▂▁▂▆▃▅▁▄▂▆▃▃▇▄▂▅▄▃▃▃▃▆▃▃▆▂█
wandb:      train/ensemble_f1 ▅▅▅▅▄▃▅▆▆▅▃▅▅▇▆▄▄▇▆▇▅▇▆▇▅▅█▁▄▆▆▆▅▅▄▇▄▃▆▄
wandb:         train/mil_loss ▄▇▅▃▄▆▇▆▅▅▄▅▄▃▆▅▆▃▆█▇▂▄▄▆▅▃▅▆▁▂▄▆▅▅▄▆▅▅▂
wandb:      train/policy_loss ▁▁▅▅▁▅▅▁▅▅▅▅▅██▁▅▁▅▅▁▅██▅█▅▅▁█▁▅▅▁▅█▁▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁█▄▁▄▁▄▄▄▄▄▄██▁▄█▁▄▁▁▄▁▁▄▄█▄▄██▄▄▁▄▄█▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.41358
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.7773
wandb:      eval/avg_mil_loss 0.48001
wandb:       eval/ensemble_f1 0.7773
wandb:           train/avg_f1 0.81803
wandb:      train/ensemble_f1 0.81803
wandb:         train/mil_loss 0.98666
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8ihwdsx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105150-k8ihwdsx/logs
wandb: ERROR Run k8ihwdsx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2mp5ptuo with config:
wandb: 	actor_learning_rate: 1.2027227707656207e-06
wandb: 	attention_dropout_p: 0.1296477672601843
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22948703500530887
wandb: 	temperature: 0.3661073536873738
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105329-2mp5ptuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mp5ptuo
wandb: uploading config.yaml
wandb: uploading history steps 54-61, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▅███
wandb: best/eval_avg_mil_loss █▆▇▇▁█▂▆
wandb:  best/eval_ensemble_f1 ▁▂▂▄▅███
wandb:            eval/avg_f1 ▆▂▅▅▄▅▄▆▃▁▆▇▆▅▃█▆▅▆▄▇▆▄▅▄▄▄▆▄▄█▃▄▆▇▃▆▆▄▇
wandb:      eval/avg_mil_loss ▆▄▅▃▅▅█▂▃▃▂▃▄▅▄▃▃▃▄▃▃▃▂▄▆▆▄▅▁▆▄▂▃▅▅▃▄▃▅▂
wandb:       eval/ensemble_f1 ▆▂▅▅▃▄▆▃▁▆▇▇▆▅▃▆▅▁▅▄▇▆▄▅▄▄▄▅▆▆▅█▃▄▆▅▃▆▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▃▄▅▄▄▆▅▂▂▅▄▆▇▇▁▂▄▄▇▆▆▃▅▄▄▄▄▅▆▂▆▄█▁▄▃▃
wandb:      train/ensemble_f1 ▆▂▃▄▅▄▄▆▅▇▅▄▆▅▇▂▄▄▄▇▃▄▆▃▄▄▄▅▅▄▃▅▆▆▂▄█▁▃▃
wandb:         train/mil_loss ▅▅▅▃█▃▃▃▂▇▂▂▅▄▃▄▂▃▅▂▁▃▄▅▃▃▅▂▂▃▂▄▄▁▅▂▁▆▅▂
wandb:      train/policy_loss ▅▁█▅▁▅▅▁▅█▅▅▅▅▅▁▅█▅█▅▅█▅▁▁█▅▅█▅▅▅█▅▅▅▁▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████▁█████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.42062
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.83168
wandb:      eval/avg_mil_loss 0.41318
wandb:       eval/ensemble_f1 0.83168
wandb:            test/avg_f1 0.75021
wandb:      test/avg_mil_loss 0.60575
wandb:       test/ensemble_f1 0.75021
wandb:           train/avg_f1 0.7958
wandb:      train/ensemble_f1 0.7958
wandb:         train/mil_loss 1.93651
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mp5ptuo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105329-2mp5ptuo/logs
wandb: Agent Starting Run: atnpuhk5 with config:
wandb: 	actor_learning_rate: 7.1780122322134346e-06
wandb: 	attention_dropout_p: 0.07174477101698679
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 84
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8069538453174826
wandb: 	temperature: 9.525351670034585
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105441-atnpuhk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atnpuhk5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇█
wandb: best/eval_avg_mil_loss █▂▁▂
wandb:  best/eval_ensemble_f1 ▁▇▇█
wandb:            eval/avg_f1 █▅▅▄▄▁▆▃▄▄▅▅▃▆▆▇▆▃▁▇█▅▆▆▆▆▄▅▃▅▆▆▅▅▅▆▅▃▅▅
wandb:      eval/avg_mil_loss ▆▆▅▅▃▄▆▄▆▃▆▃▃▄▁▄▇█▄▃▆▄▅▃▄█▄▁▆▅▄▄▃▇█▇▇▁▄▇
wandb:       eval/ensemble_f1 ▄▇▄▄▄▅▃▆▁▄▃▄▄▃▅▆▇▆▆▇▂▅▇▂▆▆▄▁▃▅▅▅▅▆▅▆▄▄▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▂▁▄▆▃▅▄▆▇▅▂▃▃▃▆▁▂▂▄▇▆█▃▄▃▃▂▄▄▅▇▅▇▁▁▂▄▆
wandb:      train/ensemble_f1 ▃▆▂▃▁▄▅▅▄▄▄▄█▃▄▆▂▃▂▃▁▃▄▅▇█▄▅▄▃▃▅▂▄▁▇▅▇▁▆
wandb:         train/mil_loss ▄█▃▄▆▅▅▇█▅▇▄▇▇▂▃▅▇▅▅▅▆▆▅▅▅▄▂▆▅▄▃▇▂▄▁▇▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84605
wandb: best/eval_avg_mil_loss 0.44759
wandb:  best/eval_ensemble_f1 0.84605
wandb:            eval/avg_f1 0.80985
wandb:      eval/avg_mil_loss 0.53108
wandb:       eval/ensemble_f1 0.80985
wandb:            test/avg_f1 0.75308
wandb:      test/avg_mil_loss 0.52707
wandb:       test/ensemble_f1 0.75308
wandb:           train/avg_f1 0.81139
wandb:      train/ensemble_f1 0.81139
wandb:         train/mil_loss 1.94446
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atnpuhk5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105441-atnpuhk5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r0i479qd with config:
wandb: 	actor_learning_rate: 7.641864928262804e-06
wandb: 	attention_dropout_p: 0.14461139588241617
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1353385411198863
wandb: 	temperature: 0.7613163257310196
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105629-r0i479qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0i479qd
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss █▁▂▄
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▆▇▅▂▃▆▅▄▆▁▇▃▃▃▅▆█▅▂▄▃▇▄▇▂▅▅▆▄▄▄▅▃▆▃▂▇▄▆▁
wandb:      eval/avg_mil_loss ▇▁▃▆▆▆▁▂▄▃▄▅▄▆▄▂▄▆▆▂▇█▇▃▆▆▁▆▃▄▇▂▃▄▅▆▇▇▁▆
wandb:       eval/ensemble_f1 ▇▇▅▄▆▇▄▁█▃▆▃▄▇▃▆▅▂▄▇█▇▃▄▂▅▆▄▆▇▃▁▇▆▅▇▆▁▄▁
wandb:           train/avg_f1 ▆▂▁▃▆▅▅▆▆▆▄▇█▆▇▅▅▃▃▆▆▅▅▇▅▄▇▅▄▅▃▆▄▅▄▅█▃▃▅
wandb:      train/ensemble_f1 ▅▂▅▁▂▇▅▆█▄▆▅▅▂▃▄▅▄▆▆▅▃▄▇▇▃▇▃▄▃▁▄▄▃▆▃▂▆▂▅
wandb:         train/mil_loss █▆▅▆▆▅▆▆▂▅▆▅▅▆▆▅▆▅▃▃▅▃▃▄▅▁▅▇▄▅▂▅▄▄▇▇▄▂▃▄
wandb:      train/policy_loss ▆▆▆▆▆▆▆▇▆█▆▇▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.42597
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.76269
wandb:      eval/avg_mil_loss 0.48779
wandb:       eval/ensemble_f1 0.76269
wandb:           train/avg_f1 0.79977
wandb:      train/ensemble_f1 0.79977
wandb:         train/mil_loss 1.89307
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0i479qd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105629-r0i479qd/logs
wandb: ERROR Run r0i479qd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: phgprhij with config:
wandb: 	actor_learning_rate: 3.6976148293554047e-06
wandb: 	attention_dropout_p: 0.3372463359203148
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1677673655981906
wandb: 	temperature: 5.136184295524167
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105854-phgprhij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phgprhij
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ▄█▃▅▂▂▅▂▂▁▃
wandb:  best/eval_ensemble_f1 ▁▂▄▄▆▇▇▇▇██
wandb:            eval/avg_f1 ▅▆▅▆▄▆▅▄▁▃▆▂▆▅▄▅▆▄▆▆▄▆▇▅▃▇▅▇▆▆▄▄▆▅▄▆▆▇▅█
wandb:      eval/avg_mil_loss ▂▄▆▇▄▅▂▄▄▄▂▃▃▄▁█▅▄▂▅▅▆▄█▄▂▅▄▄▅▅▄▄▃▃▆▄▄▄▃
wandb:       eval/ensemble_f1 ▃▅▅▄▇▆▁▃▆▆▃▅▅▇▇▆▅▅▅▅█▅▆▄▅▆▄▄▄▅▆▄▄▆▆▇▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▆▇▅▇▅▇█▆▆▆▃▄▄▄▂▃▅▆▃▃▃▇▆▂▆▂▆▃▇▅▁▆█▅▃▆▇
wandb:      train/ensemble_f1 ▂▃▅▃▆▆▆▆▅▄▄▃█▅▆▄▆▆▃▅▂▆▅▄▆▆▂▅▆▁▄▅▅▆▃█▄▅▃▃
wandb:         train/mil_loss ▆▇▃▄▄▆█▂▆▅▅▆▄▆▅▄▅▃▄▅▄▅▇▁▄▂▅▄▄▃▆▅▄▅▅▃▁▅▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.40816
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80292
wandb:      eval/avg_mil_loss 0.38919
wandb:       eval/ensemble_f1 0.80292
wandb:            test/avg_f1 0.77274
wandb:      test/avg_mil_loss 0.59537
wandb:       test/ensemble_f1 0.77274
wandb:           train/avg_f1 0.79672
wandb:      train/ensemble_f1 0.79672
wandb:         train/mil_loss 0.69131
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phgprhij
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105854-phgprhij/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: omk0hbun with config:
wandb: 	actor_learning_rate: 3.56142674863137e-06
wandb: 	attention_dropout_p: 0.4701773694135774
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6308530474575409
wandb: 	temperature: 5.703681703594614
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110229-omk0hbun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/omk0hbun
wandb: uploading history steps 151-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃██
wandb: best/eval_avg_mil_loss █▆▁▃
wandb:  best/eval_ensemble_f1 ▁▃██
wandb:            eval/avg_f1 ▅▅▃▆▄█▂▃▄▆▆▆▄▄▅▄▃▄▆▅▅▆▄▃▇▇▂▇▅▄▁▂▂▂▂▆▃▃▅▇
wandb:      eval/avg_mil_loss ▃▅▃▁▄▁▅▄▄▄▂▄▂▃▃▄▂▄▃▄▄▄▆▄▆▅▃▄▄▄▃▅▅▂▆▃▆▄▅█
wandb:       eval/ensemble_f1 ▅▅▄▄▃▆▃▄▄▅▅▄█▃▅▆▂▄▃▅▄▄▁▄▄▃▅▁▄▆▂▃▄▄█▆▃▄▃▇
wandb:           train/avg_f1 ▇▅▇▆▃██▇▆▄▅▄▄▅▅▅▄▅▂▄▄▇▅▃▃▁▅▅▁▅▂▅▅▄▄▃▃▂▃▆
wandb:      train/ensemble_f1 ▆▇▆█▆▅█▅▆▇▇▃▃▆▇▅▇▃▆▆▄▄▆▄▅▅▆▄▅▆▃▅▄▅▄▁▅▄▃▅
wandb:         train/mil_loss ▆█▇▇▆█▆▆▆▆▆▆▅▇▅▅▇▄▅▅▄▂▄▅▅▆▄▅▄▃▂▁▄▄▁▃▁▃▂▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅█▅▅▅▅▅▅▁▅▇▅▅▅▅▅▅▅▆▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁██▆████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.41182
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.83208
wandb:      eval/avg_mil_loss 0.40071
wandb:       eval/ensemble_f1 0.83208
wandb:           train/avg_f1 0.80174
wandb:      train/ensemble_f1 0.80174
wandb:         train/mil_loss 1.67872
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/omk0hbun
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110229-omk0hbun/logs
wandb: ERROR Run omk0hbun errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cumu7kh7 with config:
wandb: 	actor_learning_rate: 0.0004796194978835046
wandb: 	attention_dropout_p: 0.4521900236181059
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22944046428201512
wandb: 	temperature: 3.387504536483774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110559-cumu7kh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cumu7kh7
wandb: uploading history steps 85-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss █▅▁▇
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▂▆▃▂▅▄▄▅▃▄▄▆▆█▂▅▄▄▃▄▅▃▄▄▄▅▅▅▆▅▄▄▃▃▅▃▁▄▃▂
wandb:      eval/avg_mil_loss ▂▅▅▄▁▅▂▆▆▇▅▄▃▄▅▂▂▅█▄▃▄▅▁▃▃▃▄▇▅█▃▂▂▄▃▄▂▃▆
wandb:       eval/ensemble_f1 ▄█▅▄▅▃▆▃▄▆▃▇▇▂▅▆█▄▆▃▄▁▃▆▅▆▄▃▄▂▆▆▆▃▃▃█▆▄▁
wandb:           train/avg_f1 ▇▄▆▇▄▇▃▄▄▇▃▂▅▅▄▄▄▇▆▅▄▄▄▅▃▅▆▃▆▆▆▄▁█▆▃▃▃▆▅
wandb:      train/ensemble_f1 ▇▄▆▇▄▃▇▅▇▃▂▅▄▅▄▆▇▆▅▄▅▃▆▆▆▅▇▃▃▄▁█▅▂▅▃▆▇▃▅
wandb:         train/mil_loss ▇▇▅▆▆▆█▅▇▆▆▆▅▆▅▄▄▅▄▅▅▄▄▃▃▅▄▃▃▃▃▄▃▅▄▂▃▄▅▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄█▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▇▄▄▄▁▄▄▁▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄█▄▄▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.45555
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.4823
wandb:       eval/ensemble_f1 0.76275
wandb:           train/avg_f1 0.80315
wandb:      train/ensemble_f1 0.80315
wandb:         train/mil_loss 1.48942
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cumu7kh7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110559-cumu7kh7/logs
wandb: ERROR Run cumu7kh7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hdflq1pq with config:
wandb: 	actor_learning_rate: 1.282056867862572e-06
wandb: 	attention_dropout_p: 0.007092340025441235
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8795213027332583
wandb: 	temperature: 4.021400159954203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110758-hdflq1pq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdflq1pq
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 93-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆█
wandb: best/eval_avg_mil_loss ▇▁▆█▆▃
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆█
wandb:            eval/avg_f1 ▅▄▅▆▅▄▇▇▄▄▅▄▆▁▁▆█▇▃▆▄▆▅▄▅▃▅▄█▄▁▅▄▄▆▃▅▃▅▄
wandb:      eval/avg_mil_loss ▇▁▅▃█▃▃▅▂▇▃▃▂▄▄▅▃▆▆▃▃▃▂▃▆▅▅▆▂██▄▇▅▅▆▂▄▅▅
wandb:       eval/ensemble_f1 ▄▃▆▄▅▄▄▄█▄▃▆▄▅▁▄▃▅▆▄▅▄▅▆▄▅▄▃▄▂▅▄▃▅▅▆▅▄▄▅
wandb:           train/avg_f1 █▃▇▅▆▆▄▄▅▄▆▅▅▅▅▃▅▅▄▄█▃▂▅▇▇▄▅▅▆▆▄▅▆▁▄▂▂▅▄
wandb:      train/ensemble_f1 ▇▅█▄▂▆▂▄▇▃▆▅▆▄▅█▄▃▄▃▂▁▅▇▅▄▆▄▅▆▇▇▅▄▁▂▆▅▃▁
wandb:         train/mil_loss ▂█▇▇▅▂▅▆▅▆▇▇█▆▅▃█▆▄▄▃▇▁▂▄▃▆▄▄█▅▂▃▁▃▃▄▅▅▄
wandb:      train/policy_loss ██████████████████████████▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.39519
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.79895
wandb:      eval/avg_mil_loss 0.47092
wandb:       eval/ensemble_f1 0.79895
wandb:           train/avg_f1 0.78687
wandb:      train/ensemble_f1 0.78687
wandb:         train/mil_loss 2.07335
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdflq1pq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110758-hdflq1pq/logs
wandb: ERROR Run hdflq1pq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gdgrzp50 with config:
wandb: 	actor_learning_rate: 3.4776141595712335e-05
wandb: 	attention_dropout_p: 0.31660266025974587
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15754659828666295
wandb: 	temperature: 1.1234708956833928
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111004-gdgrzp50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdgrzp50
wandb: uploading history steps 130-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▆▆██
wandb: best/eval_avg_mil_loss ▇▅█▂▃▅▁
wandb:  best/eval_ensemble_f1 ▁▂▃▆▆██
wandb:            eval/avg_f1 ▆▇▇▄▃▄▆▆▅▄▄▇▃▅▄▇▆▅▆▇▆▇▆▆▅▇▅▅▂▄▁▄▆▅▅█▁▃▅▄
wandb:      eval/avg_mil_loss ▃▅▁▁▂▆▁▂▄▄▅▅▄▂▇▂▄▅▂▃▃▃▄▃▃▄▁█▄▅▃▃▄▅▄▆▄▄▂▄
wandb:       eval/ensemble_f1 ▇▆▅▇▇▅▅▆▅▇▆█▄▆▁▆▆▇▇▇▆▅█▆▅▇▄▄▅▇▅▆▄▆▄▃▃▆▆▇
wandb:           train/avg_f1 ▃▆▂▆▅▅▅▅█▄▅▆▅▄▆▁▅▅█▅▅▅▅▃▃▇▂▆▅▄▅▄▅▆▆▃▆▄▆▅
wandb:      train/ensemble_f1 ▄▃▁▄▃█▄▇▇▆▆▅▇▄▄▂▇▄▆▇▃▄▇▆▄▃▂▄▅▂▇▂▄▄▅▄▆▃▂▂
wandb:         train/mil_loss █▇▄▇▄▇▄▄▅▅▄▄▅▅▄▅▃▃▃▃▃▂▅▂▁▃▃▄▄▂▄▁▄▃▄▃▁▂▁▂
wandb:      train/policy_loss ██████▄███▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85743
wandb: best/eval_avg_mil_loss 0.3956
wandb:  best/eval_ensemble_f1 0.85743
wandb:            eval/avg_f1 0.80985
wandb:      eval/avg_mil_loss 0.42643
wandb:       eval/ensemble_f1 0.80985
wandb:           train/avg_f1 0.80415
wandb:      train/ensemble_f1 0.80415
wandb:         train/mil_loss 1.80612
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdgrzp50
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111004-gdgrzp50/logs
wandb: ERROR Run gdgrzp50 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: j5axwzdc with config:
wandb: 	actor_learning_rate: 2.7731314587883893e-05
wandb: 	attention_dropout_p: 0.017215823515158435
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4331975330047764
wandb: 	temperature: 1.7860947967932683
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111311-j5axwzdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5axwzdc
wandb: uploading wandb-summary.json
wandb: uploading history steps 187-198, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▆██
wandb: best/eval_avg_mil_loss ▅█▅▃▆▃▄▁▄
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▆██
wandb:            eval/avg_f1 ▄▅▅▃▇▅▇▆▃▅▂▂▄▂▃▄▄▄▄▆▃▃▃▅▅▃▅█▄▄▃▇▃▄▃▃▆▁▆▁
wandb:      eval/avg_mil_loss ▅▃▃▆▅▂▅▄▆▅▅▄▃▅▁▆▄▄▆▇▇▄▄▃▅▆▅██▄▇▂▄▇▅▂▅▄▅▆
wandb:       eval/ensemble_f1 ▁▄█▆▆▃▄█▄▅▂▂▅▄▆▅▅▃▄▃▃▄▄▆▃▆▄▆▅█▅▄▆▄▃▁▇▄▇▂
wandb:           train/avg_f1 ▇▇▇▄█▄▆▇▇▃▄▇▆▇▆▇▃▃▆▇▄▅▆▄▅▇▇▆▆▅▁▃▆▇▃▅▆▇▄▃
wandb:      train/ensemble_f1 ▆▄▅▃▅▆█▃▆▆▅▆▅▄▇▅▆▇▅▃█▅▆▂▂▇▅▃▇▅▂▁▄▁▇▅▃▄▇▄
wandb:         train/mil_loss ▃▄▄▃▄▆▄▃▆▃▃█▅▆▄▆▃▃▄▃▄▃▅▆▂▃▁▂▃▂▂▂▁▂▄▂▃▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.44378
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.75866
wandb:      eval/avg_mil_loss 0.52247
wandb:       eval/ensemble_f1 0.75866
wandb:           train/avg_f1 0.787
wandb:      train/ensemble_f1 0.787
wandb:         train/mil_loss 1.65833
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5axwzdc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111311-j5axwzdc/logs
wandb: ERROR Run j5axwzdc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4642847l with config:
wandb: 	actor_learning_rate: 0.00013406808635676036
wandb: 	attention_dropout_p: 0.43775283725521497
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5695376421570829
wandb: 	temperature: 9.507744133718816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111703-4642847l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4642847l
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▇█
wandb: best/eval_avg_mil_loss ▇█▁▆▂▂
wandb:  best/eval_ensemble_f1 ▁▂▅▆▇█
wandb:            eval/avg_f1 ▇▆▄▆▅▄▆▆▄▃▂▅▄▅▆▅▆▄▄▃▆▇▆▃▂▃▂▁▄▅▁▇▅▄█▆█▂▃▅
wandb:      eval/avg_mil_loss ▅▆▂▄▆▄▅▃▁▆▃▁█▆▃▄▃▃▄▃▅▆▇▆██▇▂▄▅▅▇▂▄▇▇▅▅▄▄
wandb:       eval/ensemble_f1 ▄▂▇▁█▆▅▆▅▃▇▆▃▅▇▇▄▃▅▃█▃▅▄▅▆▆▃▄▄▅▅▆▃▄▄▇▅▅▄
wandb:           train/avg_f1 ▅▄▄▆▆▂▅▅▂▅▇▃▄▄▃▆▄▃▃▇▅▄█▄▁▅▄▃▃▂▃▂▄▅▃▄▄▂▃▁
wandb:      train/ensemble_f1 ▇█▇▇▇▇▆▅▅▅▅▅▇▅▇▅▅▆▅█▆▇▇▇▆▅▇▅▄▆▃▄▁▅▄▅▆▆▄▇
wandb:         train/mil_loss ▆▂▆▃▇▄▄█▄▆▅▇▄▆▆▅▅▃▅▅▂▄▂▃▂▂▁▂▃▂▃▃▂▂▃▂▃▁▁▁
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁█▅▁▁█▁███▅▁▅▅▅▁▅▅█▁▅█▅▅▅▁▅▁▅▅▅▁▅▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8612
wandb: best/eval_avg_mil_loss 0.41062
wandb:  best/eval_ensemble_f1 0.8612
wandb:            eval/avg_f1 0.81018
wandb:      eval/avg_mil_loss 0.47015
wandb:       eval/ensemble_f1 0.81018
wandb:           train/avg_f1 0.78193
wandb:      train/ensemble_f1 0.78193
wandb:         train/mil_loss 0.86015
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4642847l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111703-4642847l/logs
wandb: ERROR Run 4642847l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g38qv44n with config:
wandb: 	actor_learning_rate: 6.470389095244708e-05
wandb: 	attention_dropout_p: 0.030584772148790296
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4248910948267475
wandb: 	temperature: 3.3234385623170315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112125-g38qv44n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g38qv44n
wandb: uploading history steps 53-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▇█
wandb: best/eval_avg_mil_loss █▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▅▆▇█
wandb:            eval/avg_f1 ▂▅▄▇▆▅█▆▄▃▄▁▆▅▇▅▃▂▇▃▂▆▄█▇▆▇▅▆▆▄▆▄▄▄▃▄▆▇▄
wandb:      eval/avg_mil_loss ▇▄▅▃▂▁▃▁▆▄▅▅▂▃▄▆▅▅▆▄▄▅▇▁▃▄▅█▃▃▂▇▄▅▆▅▇▄▄▄
wandb:       eval/ensemble_f1 ▂▅▄▆▇▅█▆▄▃▄▁▆▅▇▅▅▃▂▇▄▂▆▄█▄▆▇▅▆▄▆▄▄▄▃▄▆▃▆
wandb:           train/avg_f1 ▄▅▅▅▃▂▂▄▃▄▅▅▅▄▂▇▁▆▄▂▄▅█▂▃▆▃▅▅▆▆▆▆▄▅▇▃█▃▅
wandb:      train/ensemble_f1 ▄▅▅▃▆▂▃▃▄▅▅▅▅▄▂▇▁▆▄▄▄▅█▂▃▃▆▆▃▅▅▆▆▄▅▇▃▅▃▅
wandb:         train/mil_loss ▄▆█▃▅█▅▅▄▇▆▄▇▃▄▇▅▆█▇▅▄▆▁▅▅▄▄▃▄▆▆▄▅▅▆▆▆▂█
wandb:      train/policy_loss █████████████████████████████▁██████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████▁███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.38367
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.7876
wandb:      eval/avg_mil_loss 0.44102
wandb:       eval/ensemble_f1 0.7876
wandb:           train/avg_f1 0.80785
wandb:      train/ensemble_f1 0.80785
wandb:         train/mil_loss 2.31027
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g38qv44n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112125-g38qv44n/logs
wandb: ERROR Run g38qv44n errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xxzspc0m with config:
wandb: 	actor_learning_rate: 2.9291422422123893e-05
wandb: 	attention_dropout_p: 0.14570051850046778
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48966088877892067
wandb: 	temperature: 8.01936330487695
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112232-xxzspc0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxzspc0m
wandb: uploading history steps 81-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄█
wandb: best/eval_avg_mil_loss ▄▁█▆
wandb:  best/eval_ensemble_f1 ▁▃▄█
wandb:            eval/avg_f1 ▆▄▅▆▂▂▄█▄▅▃▃▃▂▆▃▇█▄▂▆▄▇█▅▆▆▄▄▆▅▆▅▅▄▁▆▇▃▅
wandb:      eval/avg_mil_loss ▃▆▇▅▅▄▇▄▆▅▅▄▇▄▅▅▂▅▆▃▄▁▅▆▆▇▁█▅▆▅▆▄▇▅▆▄█▃▆
wandb:       eval/ensemble_f1 ▅▄▅▃▂▃█▅▄▅▁▃▃▃▆▄▇█▅▅▃▅▃▇▃▄▅▅▅▄▄▆▄▃▆▇▄▂▄▂
wandb:           train/avg_f1 ▃▆▅█▂▅█▅▆▄▁▅▆▄▇▃█▄▃▁▄▄▄▆▆▃▄▇▅█▅▂▅▂▅▇▅▃▁▁
wandb:      train/ensemble_f1 ▃▅▅▅▅▄▆▄▃▅▄▅▄▁▄▆▃▁▅▃▁▃▃▃▆█▇▃▆▂▄▂▄▅▂▅▄▁▆▁
wandb:         train/mil_loss █▄▆▇▂▄▆▅▄▆▇▅▄▁▇▆▄▄▅▆▆▆▆▆▃▆▆▄▅▄▅▃▅▂▄▃▄▅▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▁▁▄▄▁█▄▄▄▄▄▄▁▁▁▄▄▄▄█▁▄▄▄▄▄█▄█▄▄▄▄██▄▄█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83527
wandb: best/eval_avg_mil_loss 0.4477
wandb:  best/eval_ensemble_f1 0.83527
wandb:            eval/avg_f1 0.77723
wandb:      eval/avg_mil_loss 0.47474
wandb:       eval/ensemble_f1 0.77723
wandb:           train/avg_f1 0.79809
wandb:      train/ensemble_f1 0.79809
wandb:         train/mil_loss 1.67806
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxzspc0m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112232-xxzspc0m/logs
wandb: ERROR Run xxzspc0m errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9eayb0sr with config:
wandb: 	actor_learning_rate: 1.747656813554055e-06
wandb: 	attention_dropout_p: 0.05880625832594161
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.720793186157382
wandb: 	temperature: 6.491613356735899
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112415-9eayb0sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9eayb0sr
wandb: uploading history steps 148-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▁▇
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▆▄▁▆▂▁█▅▆▄▆▆▆█▆▄▅▃▇▆▆▅▇▇▆▄▂▆▅▇▆▂▅▄▆▄▃█▄█
wandb:      eval/avg_mil_loss ▃▂▂▇▅▅▄▄▄▆▆▃▅▆▄▅▃▂▅▅▄▁▂▁█▃▂█▂▃▅▃▆▂▄▃▆▂▂▆
wandb:       eval/ensemble_f1 ▅▃▃▂▅▁▃▁▅▃▆▇▅█▆▃▂▂▄▂▅▆▂▆▅▄▅▅▃▅▅▃▄▅▆▅▆▄▃▃
wandb:           train/avg_f1 ▁▇█▇▇▄▅▆▅▆▇▆▆▅▆▆▇▇▆▅▇▆▇▅▅▅▆▆▅▆▃▅▇▅▆▄▅▆▂▅
wandb:      train/ensemble_f1 ▅▇███▅▆█▅▆▆▅▆▅▆▇▁▅▇▇▆▇▆▅▇▆▆▇▆▇▇▇▅▅▆▇▅▃▅▆
wandb:         train/mil_loss ▅▆▆▆▅▅▅▆▇▃▃█▅▅▇▅▃▃▄▅▅▃▃▄▃▄▃▃▄▄▃▇▄▂▄▄▄▄▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.43276
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79535
wandb:      eval/avg_mil_loss 0.49353
wandb:       eval/ensemble_f1 0.79535
wandb:           train/avg_f1 0.8031
wandb:      train/ensemble_f1 0.8031
wandb:         train/mil_loss 1.94972
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9eayb0sr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112415-9eayb0sr/logs
wandb: ERROR Run 9eayb0sr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lu8jtmb8 with config:
wandb: 	actor_learning_rate: 9.395452484173451e-05
wandb: 	attention_dropout_p: 0.1759659927938505
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.692485725045909
wandb: 	temperature: 9.99003522937436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112726-lu8jtmb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lu8jtmb8
wandb: uploading history steps 139-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆▇██
wandb: best/eval_avg_mil_loss ▇▅█▇▅▁▂
wandb:  best/eval_ensemble_f1 ▁▃▃▆▇██
wandb:            eval/avg_f1 ▄▄▅▆▄▄▄▅▃█▃▆▆▅▅▃▆▆▅▆▅▇▅▆▂▇▃▁▅▅▄▅▆▆▂▆▆▂▅▄
wandb:      eval/avg_mil_loss ▃▂▄▄▃▄▇▃▅▇▂▄▂▅▄▄▄▇▂▇▅▅▄▅▃▅▃▄▅▇▃▄▃▄▂█▄▆▁▅
wandb:       eval/ensemble_f1 ▅▄▅▄▆▃▃▅▇▄▆█▆▁▅▄▄▇▅▄▇▂▃▅█▄▅▆▆▅▂▆▄▄▄▆▁█▆▄
wandb:           train/avg_f1 ▅▁█▅▅▅▄▂▆▂▄▆▆▄▅▃▅▂▃▃▃▅▃▂▂▄▃▄▁▂▂▆▄▁▂▅▅▃▃▁
wandb:      train/ensemble_f1 ▃▂▆▅▆▅▃▂▇▆▇▃▆▅█▅▇▁▄▅▄▄▂▂▂▅▃▅▅▅▄▅▅▄▆▂▅▄▃▂
wandb:         train/mil_loss ▆▆█▇▆▆▆▆▅▇▅▆▆▄▅▆▆▄▃▄▄▅▆▄▃▃▅▅▃▃▄▃▁▆▃▂▁▂▂▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▃▆▆█▆▆▁▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▂▆▆▆▆▇▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.41174
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.78467
wandb:      eval/avg_mil_loss 0.47472
wandb:       eval/ensemble_f1 0.78467
wandb:           train/avg_f1 0.79231
wandb:      train/ensemble_f1 0.79231
wandb:         train/mil_loss 1.77049
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lu8jtmb8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112726-lu8jtmb8/logs
wandb: ERROR Run lu8jtmb8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: u47jcnd4 with config:
wandb: 	actor_learning_rate: 1.7260353012441365e-05
wandb: 	attention_dropout_p: 0.42647724389064245
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.999434566468568
wandb: 	temperature: 6.356491465303029
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113033-u47jcnd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u47jcnd4
wandb: uploading history steps 131-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆▇█
wandb: best/eval_avg_mil_loss ▇█▂▅▁▃
wandb:  best/eval_ensemble_f1 ▁▅▅▆▇█
wandb:            eval/avg_f1 ▅▃▄▄▅▅▃▇▆▃▄▄▄▄█▆▁▅▄▅▄██▅▁▅▅▃▅▅▄▅▃▄▆▆▄▅▅▄
wandb:      eval/avg_mil_loss ▃▆▄▁▅▂▃▄▄▇▃▅▃▄▃▅▄▅▂▂█▃▂▃▁▅▄▇▄▄▂▇▄▃▃▃▂▅▄▄
wandb:       eval/ensemble_f1 ▅▄▇▅▅▃▁▅▄▅▃▇▄▃▄▅▆▄▆█▁▄▅▅▄▅▄▃▄▄▅▄▅▃▆▄▄▄▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▁▆▃▆▆▆▇▆▅▃▅▂▂▇▆▇▄▃▆▃█▆▆▇▅▇▄▇█▇▆▆▆▅▇▅▅▇
wandb:      train/ensemble_f1 ▇▆▂▁▅▃▆▅▅▇▅▆▇▆██▃▅▆▅▆▇▆▇▇▆█▃▅▅▅▇▅▃▇▇▅▆▄▇
wandb:         train/mil_loss ▅▆▅▅▅▄▂▂▃▆█▅▄▂▆▅▆▄▄▆▃▁▄▂▆▂▆▇█▄▂▅▂▅▆▅▂▄▆▄
wandb:      train/policy_loss █▅▁▅▅▅▁▅▅▅▅▅██▅▁██▅▅█▅█▅▅▅▁▁█▅▅▅▁▅█▅▁▁▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄▄█▄▁▁▄▁▄▁▄▁▄▄▄█▄▄▁▄▄█▄█▄▄▄▄█▁▁▄█▄▄█▄██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.41366
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.49385
wandb:       eval/ensemble_f1 0.79074
wandb:            test/avg_f1 0.77225
wandb:      test/avg_mil_loss 0.49931
wandb:       test/ensemble_f1 0.77225
wandb:           train/avg_f1 0.79856
wandb:      train/ensemble_f1 0.79856
wandb:         train/mil_loss 0.97237
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u47jcnd4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113033-u47jcnd4/logs
wandb: Agent Starting Run: 7qz7etct with config:
wandb: 	actor_learning_rate: 6.396679067789122e-05
wandb: 	attention_dropout_p: 0.4328019748566976
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6674384927087627
wandb: 	temperature: 9.130044299255776
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113318-7qz7etct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qz7etct
wandb: uploading wandb-summary.json
wandb: uploading history steps 39-50, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▆▆█
wandb: best/eval_avg_mil_loss █▃█▃▁▄
wandb:  best/eval_ensemble_f1 ▁▄▆▆▆█
wandb:            eval/avg_f1 ▁▄▃▄▄▃▆▆▃▅▄▃▅▃▃▅▄▆▆▄█▂▆▃▆▅▄▁▅▆▄▄▂▄▄▅▆▂▃▄
wandb:      eval/avg_mil_loss ▄▃▆▂▆▄▃▃▆▇▇▂▄▂▆▆▅▁▅▁▃▂▇▆▆▅█▃▃▃▅▅▃▄▁▅▆▅▅▇
wandb:       eval/ensemble_f1 ▄▂▄▄▃▆▆▂▅▃▂▅▂▆▃▅▄▆▆▄█▁▆▃▆▅▄▅▅▄▄▁▃▄▅▆▂▃▃▃
wandb:           train/avg_f1 ▃▄▇▄▅▄▄▆▃▇██▄▄▅▅▄▅▅▄▃▄▄▅▇▄▅▃▆▆▆▂▃▁▃▅▃▁▇▅
wandb:      train/ensemble_f1 ▃▄▇▄▅▄▄▆▃▇██▄▄▅▄▅▅▄▁▄▄▄▅▇▄▅▃▆▆▆▂▃▁▄▂▅▁▇▅
wandb:         train/mil_loss ▆▅▄▅▃▅▇▃▅▄▄▆▆▄█▃▅▇▄▅▅▅▅▅▄▇▁▅▅█▇▃▇▄▄▆▃▄▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.43301
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.78453
wandb:      eval/avg_mil_loss 0.53259
wandb:       eval/ensemble_f1 0.78453
wandb:           train/avg_f1 0.79581
wandb:      train/ensemble_f1 0.79581
wandb:         train/mil_loss 0.64689
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qz7etct
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113318-7qz7etct/logs
wandb: ERROR Run 7qz7etct errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1zz2ms6h with config:
wandb: 	actor_learning_rate: 0.0003171430341435999
wandb: 	attention_dropout_p: 0.2511303760481841
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6377816583732581
wandb: 	temperature: 0.6971902685262932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113431-1zz2ms6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zz2ms6h
wandb: uploading history steps 64-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▆▇█
wandb: best/eval_avg_mil_loss ██▂▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▆▇█
wandb:            eval/avg_f1 ▄▂▅▄▂▃▄▅▄▂█▄▃▁▇▄▅▅▅▅█▄▇▅█▅▄▇▃▃▆▅▂▅▄▂▄▄▆▄
wandb:      eval/avg_mil_loss █▅█▄▅▄▂▃█▃▃▅▅▇▃▅▄▇▁▄▄▁▄▁▄▅▃▄▄▅▄▂▆▆▇▅▃▅▃▅
wandb:       eval/ensemble_f1 ▄▂▄▄▄▄▂▅▅▇▄▃▂▆▁▄▃▅▅▅▄▆▄▅▄▄▅▄▆▃▃▄▅█▄▂▅▂▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▆▂▅▄▇▅▆▄▁▅▃▆▆▅▆▄▃▆▆▃▂▂▄▆▆▂▆█▃▅▆▄▆▂▄▅▄▂
wandb:      train/ensemble_f1 ▇▃▁▇▆▆▅▅█▅▂▄▅▆▆▅▇▄▅▇▄▄▇▃▃▇▆▃▇▅▆▆▆▇▁▅▅▅▅▃
wandb:         train/mil_loss ▆▆▆▆█▄█▄▅▇▅▇▇▄▆▅▃▃▅▇▂▆▅▆▅▄▂▄▃▁▁▃▁▇▆▆▄▄▂▁
wandb:      train/policy_loss ▅██▅▁█▅▅▅▅▁▅████▅▅▁██▁▅▁▁▅▅█▁▁███▅▅█▁▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.40383
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.78791
wandb:      eval/avg_mil_loss 0.48409
wandb:       eval/ensemble_f1 0.78791
wandb:            test/avg_f1 0.72143
wandb:      test/avg_mil_loss 0.51444
wandb:       test/ensemble_f1 0.72143
wandb:           train/avg_f1 0.78492
wandb:      train/ensemble_f1 0.78492
wandb:         train/mil_loss 0.83567
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zz2ms6h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113431-1zz2ms6h/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.237.4:38758->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 2m7kh7n7 with config:
wandb: 	actor_learning_rate: 0.00021634689368203207
wandb: 	attention_dropout_p: 0.39801730541160985
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7530687964902101
wandb: 	temperature: 8.598249097384103
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113622-2m7kh7n7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2m7kh7n7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▃█
wandb: best/eval_avg_mil_loss █▃▁▄█
wandb:  best/eval_ensemble_f1 ▁▁▁▃█
wandb:            eval/avg_f1 ▄▂▇▅▅▄▃▄▁▄▃▅▇█▂▂▂▃▁▄▃▂▄▅▄▅▂▄▂▄▁▆▄▇▂▇▄▂▆▇
wandb:      eval/avg_mil_loss ▅▁▅▅▇▄▃▄▄▆▁▅▁▁▅▃▄▅▃▅██▄▅▂▆▂▂▃▆▃▂▆▆▆▃▅▇▂▇
wandb:       eval/ensemble_f1 █▅▂█▇▆▅▇▆▃▆█▆▅█▃▃▃▅▃▄▅▅▄█▆█▄▁▄▅▅▁▁▄▃█▂▅▃
wandb:           train/avg_f1 ▆▄█▅▆▅▃▅▄▅▃▃▁▂▄▂▄▃▆▇▃▅▇▆▃▄▅▄▄▆▆▅▄▄▅▃▃█▇▅
wandb:      train/ensemble_f1 ▄█▂▄▄▅▃▅▄▅▃▂▃▇▃▆▂▇▃█▄▂▂▄▄▆▂▄▅▇▅▃▅▃▂▁▅█▇▅
wandb:         train/mil_loss ▆▅▅▅▃█▆▇▇▄▆▇▅▄▄▅▆▅▅▅▃▄▆▆▃▅▄▇▅▄▁▃▄▄▃▅▄▂▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86444
wandb: best/eval_avg_mil_loss 0.46935
wandb:  best/eval_ensemble_f1 0.86444
wandb:            eval/avg_f1 0.83197
wandb:      eval/avg_mil_loss 0.43522
wandb:       eval/ensemble_f1 0.83197
wandb:           train/avg_f1 0.79994
wandb:      train/ensemble_f1 0.79994
wandb:         train/mil_loss 1.77124
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2m7kh7n7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113622-2m7kh7n7/logs
wandb: ERROR Run 2m7kh7n7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xg2ha0r7 with config:
wandb: 	actor_learning_rate: 4.9116010226028515e-05
wandb: 	attention_dropout_p: 0.006057471123719349
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4432980385683328
wandb: 	temperature: 9.772311247050869
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113843-xg2ha0r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xg2ha0r7
wandb: uploading history steps 104-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃█
wandb: best/eval_avg_mil_loss █▄█▁
wandb:  best/eval_ensemble_f1 ▁▂▃█
wandb:            eval/avg_f1 ▂▃▆▅▆▇▄▁█▅▆▃▄▄▂▄▄▃▅▆▆▅▅█▄▅▄▃▇▆▂▄▄▂▅▃▃▁▂▆
wandb:      eval/avg_mil_loss ▅▇▇▅▅▅▅▄▇▄▆▃▄▃▄▄▅▄▆▅▁▂▄▇▆▄▆▁▆▄▄▅▆▆▅█▃▅▆▅
wandb:       eval/ensemble_f1 ▃▃▅▁▆▃▅▆▅▄▃█▅▄▅▆▆▅▄▅▄▅▆▃▁▅▆▅▄▅▇▄▂▄▅▁▆▃▆▅
wandb:           train/avg_f1 ▃▆▄▄▄▆█▅▅█▆▇▄▃▅▆▄▂▇▂▅▄▄▄▆▅▄▆▆▆▆▄▄▅▇▅▆▃▅▁
wandb:      train/ensemble_f1 ▅▄▄▆▆▅▅▃▄▃▇▅▄█▄▄▄▆▄▃▅▄▄▄▁▃▅▁▃▅▄▄▃▅▄▂▃▄▃▂
wandb:         train/mil_loss ▅▇▆▇█▄▆▅▅▄▄█▇▇▆▆▇▅▅▂▇▇▅▅▅▄▃▃▄▄▄▅▄▃▁▃▂▄▅▁
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁█▁▁▁▁▁▁▁▁▁▄████▁▄█▄▁██▁█▁█▁▄▁▁█▁▄▁▄▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.39899
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.46691
wandb:       eval/ensemble_f1 0.80225
wandb:           train/avg_f1 0.78401
wandb:      train/ensemble_f1 0.78401
wandb:         train/mil_loss 1.0205
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xg2ha0r7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113843-xg2ha0r7/logs
wandb: ERROR Run xg2ha0r7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bmld7qb9 with config:
wandb: 	actor_learning_rate: 0.0004915588657792863
wandb: 	attention_dropout_p: 0.49008641585536344
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9153492703077404
wandb: 	temperature: 5.9804651261094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114118-bmld7qb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmld7qb9
wandb: uploading history steps 127-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇▇█
wandb: best/eval_avg_mil_loss ▂▄██▂█▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇▇█
wandb:            eval/avg_f1 ▃▂▆▁▅▃▅▅▆▃▂▆█▆▅▇█▅▃▆▃▆▂▆▆▅▅▂█▆▃▇▆▅▅▂▅▄▆▄
wandb:      eval/avg_mil_loss ▁▆▃▄█▄▆▅▅▃▆▂▄▃▆▅▂▃▅▄▃▃▄▃▇▄▁▅▄▇▄▄▃▄▃▅▄▆▅▂
wandb:       eval/ensemble_f1 ▆▂▅▁▃▆▆▅▆▆▆▂▄▄▃▄▆▃▃▇▅▆▃▅▂▆▅▃▃▃▅▅▅▆▆▄▆▇▄█
wandb:           train/avg_f1 ▅▆▅▆▄▇▁▅▄▆▅▆▅▆▅▅▇▆▇▅▇▅▆▆▃▆▆▃▇▆▆▆▅▆▃▆█▄▆▇
wandb:      train/ensemble_f1 ▅██▅▆▇▁▄▅▇▆▅▆▆▅▆█▅▆▆▇▆▇█▅▅▄▇▆▆▅▄▆█▆▄▆▇▇▆
wandb:         train/mil_loss ▆▅▄▆█▄▇██▆▆▅▇▄▆▄▅▇▅▆▅▅▅▁▆▃▇▄▅▅▂▅▇▆▅▅▂▄▃▄
wandb:      train/policy_loss █▁▅▁█▁▅█▅▁▅██▅▁▅█▁▅▅▅█▁▅█▁▁████▅█▁█▅█▁█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▁█▅▁█▅█▅▅█▁▁█▁▅▁▅▅▅█▁▅█▁▁▅▁██▅▅▅▅▅█▁█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.39762
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.8355
wandb:      eval/avg_mil_loss 0.42277
wandb:       eval/ensemble_f1 0.8355
wandb:           train/avg_f1 0.80078
wandb:      train/ensemble_f1 0.80078
wandb:         train/mil_loss 0.52389
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmld7qb9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114118-bmld7qb9/logs
wandb: ERROR Run bmld7qb9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: to09pela with config:
wandb: 	actor_learning_rate: 0.0001408134134789785
wandb: 	attention_dropout_p: 0.30193196026705876
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29868743261865005
wandb: 	temperature: 5.295504636595391
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114424-to09pela
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to09pela
wandb: uploading wandb-summary.json
wandb: uploading history steps 143-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅███
wandb: best/eval_avg_mil_loss █▄▂▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅███
wandb:            eval/avg_f1 ▆▅▇▂▃▅▅▆▄▅▄▄█▃▄▇▅▅▁▃▅▄▄▂▃▃▄▄▇▆▅▂▄▁▄▄▄▃▄▄
wandb:      eval/avg_mil_loss ▆▃▃▇▃▅▄▅▃▃▃▅▄▃▄▃▄▅▇▆▅▅▁▃▂▄▅▅█▄▄▃▄▄▄▄█▆▂▃
wandb:       eval/ensemble_f1 █▅▆▆▄▁█▁▄▆██▅▁▅▆█▆▁▅▁▇▂▅▆▃▇▂█▃▅▃▇▅▁▄▇▆▅▆
wandb:           train/avg_f1 ▃▃▁▇▆▄▂▆▆▇▆▂▆▅▃▆▅▇▆▇▃▇▄▃▆▅▁▇▆▇▅▂▃▃▇▆▇▃▅█
wandb:      train/ensemble_f1 ▃▄▂▄▃▅▅▄█▄▆▅▇▅▇▂▅▃▅▆▅▇▅▃▅▅▄▂▅▃▃█▅▁▆▇▅▄▄▂
wandb:         train/mil_loss ▅▅▅▂▃▅▆▆▃▇▆▄▆▄▇▃▂▃▄▆▅▃▂▃█▅▃▅▅▆▂▃▄▆▄▅▆▃▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.38961
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.77274
wandb:      eval/avg_mil_loss 0.40714
wandb:       eval/ensemble_f1 0.77274
wandb:           train/avg_f1 0.81184
wandb:      train/ensemble_f1 0.81184
wandb:         train/mil_loss 0.83239
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to09pela
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114424-to09pela/logs
wandb: ERROR Run to09pela errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 566xln5z with config:
wandb: 	actor_learning_rate: 3.9197873240016366e-05
wandb: 	attention_dropout_p: 0.04287035086175056
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19566146978017052
wandb: 	temperature: 3.474112456244449
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114726-566xln5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/566xln5z
wandb: uploading wandb-summary.json; uploading history steps 40-52, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▃▄▅▁▅
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▇▇▆▄▄▇▄▇▆▆▇▇▆▆██▅▇▆▆▅▅▇▇▆▇▆▇▅▆▆▅▅▆▇▁▇▆▇▆
wandb:      eval/avg_mil_loss ▆▂█▅▅▅█▃▅▄▄▄▅▄▇▆▁▄▃▇▃▆▅▄▇▅▃▅▃▄▆▄▄▄▃▆▃▃▃▄
wandb:       eval/ensemble_f1 ▇▇▆▄▄▇▄▇▆▆█▅▇▆▃█▆▇▆▇▅▇▇▆▄▆▇▅▆▅▅▅▆▆▆▆▁▇▇▆
wandb:           train/avg_f1 ▆▅▅▆▃▄█▂▄▄▁▆▇▄▃▆▅▃▃▅▄▆▂▅▃▃▅▃▄▄▃▃▄▄▃▄▅▅▃▃
wandb:      train/ensemble_f1 ▆▆▇▇▅▃▂▄▅▁█▅▃▅▆▃▃▆▅▄▃▃▆▃▄▅▃▄▇▄▄▄▄▄▃▅▆▄▄▅
wandb:         train/mil_loss ▅▆▂▅█▅▄▁▃▃▆▁▄▇▄▆▇▄▄▅▁▂▄▂▂▃▂▃▂▃▂▃▅▃▂▆▂▆▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.44515
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.79523
wandb:      eval/avg_mil_loss 0.43669
wandb:       eval/ensemble_f1 0.79523
wandb:           train/avg_f1 0.80146
wandb:      train/ensemble_f1 0.80146
wandb:         train/mil_loss 0.66426
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/566xln5z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114726-566xln5z/logs
wandb: ERROR Run 566xln5z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qn720xor with config:
wandb: 	actor_learning_rate: 0.00035524435304393903
wandb: 	attention_dropout_p: 0.359669959844059
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5205948274922481
wandb: 	temperature: 5.6344762239915624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114833-qn720xor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qn720xor
wandb: uploading wandb-summary.json
wandb: uploading history steps 51-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▆█
wandb: best/eval_avg_mil_loss ██▁▄▆
wandb:  best/eval_ensemble_f1 ▁▃▆▆█
wandb:            eval/avg_f1 ▃▄▅▅▆▅▇▃▅▃▂▄▁▄▅▃▃▄▅▂▅▂▅▅▃█▄▄▅▁▃▁▃▅▄▃▄▅▅▂
wandb:      eval/avg_mil_loss ▅▅▅▄▃▆▄▃▅▂▅▅▄▇▄▃▃▃▁▇▂▅▅▁▄▄▃▅▅▂█▂▄▅█▁▃▃▃▅
wandb:       eval/ensemble_f1 ▅█▃▆▇█▄▅▆▂▄▁▄▆▄▃▄▅▆▆▄▂▆▆▇▅▄▅▇▁▇▃▁▃▆▃▄▅▄▄
wandb:           train/avg_f1 ▅▄▄▃▅▆▇▇▂▃▅▇▇▄▆▁▃▂▆▅▇▆▄▃▆▅▄▁▄▄█▃▅▆▆▄▇▅▅▃
wandb:      train/ensemble_f1 ▄▃▂▃▂▄▆▆▅▂▃▄▄▆▆▄▁▃█▅▅▅▃▅▅▂▄▁▄▃▂▃▃▄▅▃▄▄▄▂
wandb:         train/mil_loss ▂▃▆▄▂▄▃▂▄▇▆▂▄▃▁▂▃▄▅▄▂▅▂▅▃▄▄█▃▆▁▃▄▂▃▁▄▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85363
wandb: best/eval_avg_mil_loss 0.45877
wandb:  best/eval_ensemble_f1 0.85363
wandb:            eval/avg_f1 0.78027
wandb:      eval/avg_mil_loss 0.49533
wandb:       eval/ensemble_f1 0.78027
wandb:           train/avg_f1 0.79088
wandb:      train/ensemble_f1 0.79088
wandb:         train/mil_loss 1.73677
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vague-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qn720xor
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114833-qn720xor/logs
wandb: ERROR Run qn720xor errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dw2qsrmp with config:
wandb: 	actor_learning_rate: 8.064001901344729e-06
wandb: 	attention_dropout_p: 0.4576596313405458
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7203802076841308
wandb: 	temperature: 1.9549080846968911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114951-dw2qsrmp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2qsrmp
wandb: uploading history steps 103-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇██
wandb: best/eval_avg_mil_loss █▅▄▁▄
wandb:  best/eval_ensemble_f1 ▁▅▇██
wandb:            eval/avg_f1 ▄▆▄▄▅▇▄▄▃▂▆▄▅▅▄▅▄▆▇█▅▇▅▆▆▆▂▃▁█▅▄▃▆▅▆▂▃▄▅
wandb:      eval/avg_mil_loss ▇▆▅▇▅▇▅█▄▄▄█▆▅▆▅▅█▆▅▅▅▂▁▄▆▃▃▅▃▆▇▄▅▅▄▆█▄▅
wandb:       eval/ensemble_f1 ▅▆▃▄▅▇▅▅▃▄▂▅▅▃▄▅▄▅▅▂▅█▆▇▆▆▅▇▃▇▅▃▁█▅▆▂▄▅▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▆▃▅▄▅▂▃▄▄▄▆▅▁▅▃▄▄▇█▃▁▂▁▅▆▃▅▄▄█▇▅▃▁▃▅▄
wandb:      train/ensemble_f1 ▆▂▂▃▄▄▄▅▆▄▃▄▆█▄▅▄▆▇▂▅▁▅▅▅▃▅█▆▂▆▆▃▅▃▁▃▅▅▅
wandb:         train/mil_loss ▃▅█▄▅▄▅▅▆▅▆▆▄▅▄▄▃▄▆▃▆▂▆▅▇▅▇▄▅▅▅▃▄▄▅█▃▅▁▆
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▁▅▁▅██▁▁▁█▅█▅██▁██▁▅▁▁▁▁▁▅▁███▁█▁▁█▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.44154
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.49631
wandb:       eval/ensemble_f1 0.76597
wandb:            test/avg_f1 0.78891
wandb:      test/avg_mil_loss 0.49459
wandb:       test/ensemble_f1 0.78891
wandb:           train/avg_f1 0.79995
wandb:      train/ensemble_f1 0.79995
wandb:         train/mil_loss 0.9934
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2qsrmp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114951-dw2qsrmp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rws58g0f with config:
wandb: 	actor_learning_rate: 9.708523383978746e-06
wandb: 	attention_dropout_p: 0.07706330303167197
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20525116165155344
wandb: 	temperature: 2.437511719416958
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115255-rws58g0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rws58g0f
wandb: uploading history steps 142-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆██
wandb: best/eval_avg_mil_loss █▇▇▇▃▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆██
wandb:            eval/avg_f1 ▅▅▅▅▃▆▁▅▃▄▄▅▁▅▃▄▆█▄▄▃▅▄▅▆▂▆▆▅▇▄▅▄▄▄▇▄▂█▅
wandb:      eval/avg_mil_loss ▅▄▆▄▄▃▃▂▇▅▂▅█▂▁▂▂▇▄▅▂▃▄▂▃▃▅▆▃▃▄▃▄▅▃▄▅▅▄▃
wandb:       eval/ensemble_f1 ▅▅▆▇▃▆▃▅▅▂▄▇▇▅▆▇▃▃▆▁▇▅▇▆▅▆█▅▅▆▄▆▇█▄▆▂▆▂▃
wandb:           train/avg_f1 ▆▅▇▃▅▇▄▇▅▅▅▆▃▄▆▂▅▆▆▆█▇▅▇▄▅▅▆▅▂▅▅▅▄▁▅▅▃▅▆
wandb:      train/ensemble_f1 ▅▂▄▅█▅▅█▅▄▅▄▅▅▇▇▅▁▃▄▅▆▆▇▄▆▇▅▅▅▅▇▄▅▇▆▅▃▅▆
wandb:         train/mil_loss ▄▂▆▅▃▆█▅▅▄▅▆▃▃▆▁▄▆▅▇▄▄▄▃▃▃▄▄▅▅▅▂▃▄▃▅▆▄▄▃
wandb:      train/policy_loss ▄▁▄▄▁▁▁▁▁▁█▄▄▁█▁▁▁█▄▄▄▄▄▄▁▄█▄▄▄▄█▄▄▁▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▄▄▄█▄▁█▄▄▄▄▄▄▄▄▄▁▄▄▄███▄█▄█▄███▄▄█▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84195
wandb: best/eval_avg_mil_loss 0.4123
wandb:  best/eval_ensemble_f1 0.84195
wandb:            eval/avg_f1 0.82458
wandb:      eval/avg_mil_loss 0.44659
wandb:       eval/ensemble_f1 0.82458
wandb:           train/avg_f1 0.80217
wandb:      train/ensemble_f1 0.80217
wandb:         train/mil_loss 0.8263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rws58g0f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115255-rws58g0f/logs
wandb: ERROR Run rws58g0f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: yohthy2v with config:
wandb: 	actor_learning_rate: 1.0063986890021735e-06
wandb: 	attention_dropout_p: 0.07621648635192729
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6902872670760987
wandb: 	temperature: 2.6471426918837637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115556-yohthy2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yohthy2v
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 127-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄██
wandb: best/eval_avg_mil_loss ▇██▁▃
wandb:  best/eval_ensemble_f1 ▁▃▄██
wandb:            eval/avg_f1 ▃▂▄▅▆▃▄▆▄▂█▅▆▁▄▅▃▅▆▄▄▇▃▅▄▅▃▄▅▁▆▆▆▇▅▅▃▆▄▅
wandb:      eval/avg_mil_loss ▃▃▆▂▄▄▄▄▄▅▃▂▂▅▃▄▂▅▅▄▂▃▅▅▄▃▃▄▁▆▆█▃▂▄▄▅▃▆▂
wandb:       eval/ensemble_f1 ▄▂▄▃█▆▄▆▄▄▁▄▄▅▅▄▄▄▅▅▄▄▃▆▁▆▄▆▄▄▄▅▅▆▇▅▆▆▄▅
wandb:           train/avg_f1 ▁▅▅▄█▄▄▆▆▇▆▄▅▆▃▄█▃▇▄▄▇▃▂▄▄▂▃▃▄▆▇▅▄▃▃▃▅▃▄
wandb:      train/ensemble_f1 ▆▄▅▄▆█▇▅▆▇▇▄▆▆▇▅▇▃▃▅▄▇▄█▂▆▃▅▂▁▆▅▆█▆▆▄▆▅▆
wandb:         train/mil_loss █▄▅▅▆▅▅▄▂▄▆▅▆▃▅▇▅▄▃▄▆▆█▂▆▂▅▂▄▄▆▄▇▅▄▃▁▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86084
wandb: best/eval_avg_mil_loss 0.39617
wandb:  best/eval_ensemble_f1 0.86084
wandb:            eval/avg_f1 0.81689
wandb:      eval/avg_mil_loss 0.38823
wandb:       eval/ensemble_f1 0.81689
wandb:           train/avg_f1 0.80566
wandb:      train/ensemble_f1 0.80566
wandb:         train/mil_loss 1.67008
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yohthy2v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115556-yohthy2v/logs
wandb: ERROR Run yohthy2v errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tj748om8 with config:
wandb: 	actor_learning_rate: 0.0008957230648063887
wandb: 	attention_dropout_p: 0.20556831295466388
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24065646661940976
wandb: 	temperature: 9.07892470762046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115841-tj748om8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tj748om8
wandb: uploading history steps 125-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇██
wandb: best/eval_avg_mil_loss ▃█▁▃▃
wandb:  best/eval_ensemble_f1 ▁▂▇██
wandb:            eval/avg_f1 ▃▂▇▆▁▇▄▅▅▅▃▅█▂▆▂▄▂▃▅▅▅▇▅▄▄▆▃█▄▇▄█▆▅▄▄▅▄▃
wandb:      eval/avg_mil_loss ▇▃▂▆▃▅▅▃▃▄▃▅▃▅▅▁▆▆▂█▃▄▃▆▄▂▄▅▃▁▆▄▄▃▃▅▄▄▃▆
wandb:       eval/ensemble_f1 ▄▃▅▂▂█▅▅▆▅▅▃▂▁▄▄▅█▅▆▆▃▆▆▅▄█▃▃▃▇█▆▃▅▅▄█▆▄
wandb:           train/avg_f1 ▅▅█▄▅▃▅▃▂▃▁▃▅▂▄▆▂▂▃▃▁▄▂▂▄▆▅▄▄▆▂▃▃▆▂▄▂▁▁▄
wandb:      train/ensemble_f1 ▇▄▆▇▅▃▇▅▂▅▂▃▅▂▅▇▄▃▄▃▃▄▇▆▄▃▄▄█▇▆▇▇▅▅▅▃▅▁▄
wandb:         train/mil_loss ▄▄▄▄▆█▅▄▃▅▇▄▄▅▅▄▆▄▆▄▁▁▂▃▄▃▃▂▄▃▂▃▄▄▃▃▂▅▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.43632
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.78092
wandb:      eval/avg_mil_loss 0.45203
wandb:       eval/ensemble_f1 0.78092
wandb:           train/avg_f1 0.79469
wandb:      train/ensemble_f1 0.79469
wandb:         train/mil_loss 0.50863
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tj748om8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115841-tj748om8/logs
wandb: ERROR Run tj748om8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: j60apo51 with config:
wandb: 	actor_learning_rate: 5.669584278242621e-05
wandb: 	attention_dropout_p: 0.032594949661134964
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9001055361581723
wandb: 	temperature: 6.519042164853652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120137-j60apo51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j60apo51
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▅▁▅▁▂▇▆▄▄▇▃▅▄▇▄▅▄▇▄▂▆▄▆▄▆▅█▄▄▂▆▅█▅▇▁▃▆▄
wandb:      eval/avg_mil_loss ▂▇▅▅▅█▅▄▆▃▆▄▁▃▇▃▃▄▃█▅▃▅▆▄▄▂▁▄▁▃▃▄▃▅▃▅▄▅▅
wandb:       eval/ensemble_f1 ▄▂▃▆▆▃▃▃▁▆▃▆▄▄█▄▃▃▃▄▁▄▄▄▅▇▆▃▆▄▅▆▁▆▃▂▂▄▂▃
wandb:           train/avg_f1 ▇▂▆▂▁▅▆▄▇▅▃▄▃▁▃▅▃▂▆▄▃▅▃▃▃▅▅▄█▄▂▅▅▄▃▆▅▅▅▂
wandb:      train/ensemble_f1 ▄▃▄▆▅▆▅▄▄▇▆▃▇▂▅▃▅▃▇▅▄▄▅▅▄▁▅▅▅▅▄█▅▄▆▄▅▄▇▃
wandb:         train/mil_loss ▆▅▂▃▅▃█▂▃▃▄▅▄▄▆▂▆▇▃█▂▄▄▇▃▃▄▃▅▇▁▇▇▆▄▁▄▆▇▄
wandb:      train/policy_loss ▅▅█▅█▁▅▅▅▁█▅▁▁██▅▅▅▅▁▅█▁▁████▅▁▅█▅█▅▅▁▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄▄▁▄▄▄▄▄▄▄▁██▄▄▄▁▄▄████▄▄██▁█▄█▁▁▁▄▁▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85373
wandb: best/eval_avg_mil_loss 0.38759
wandb:  best/eval_ensemble_f1 0.85373
wandb:            eval/avg_f1 0.79914
wandb:      eval/avg_mil_loss 0.46677
wandb:       eval/ensemble_f1 0.79914
wandb:           train/avg_f1 0.79843
wandb:      train/ensemble_f1 0.79843
wandb:         train/mil_loss 0.84915
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j60apo51
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120137-j60apo51/logs
wandb: ERROR Run j60apo51 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: np59qy50 with config:
wandb: 	actor_learning_rate: 2.3730400557761267e-06
wandb: 	attention_dropout_p: 0.20110840832569857
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9264135842672416
wandb: 	temperature: 1.2360547974859892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120433-np59qy50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np59qy50
wandb: uploading history steps 104-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▅▅▄▄▄▂▄▅▄▂▂▃▆▅▄▅▄▆▁▃▂▃▃█▃▅▄▄▃▂▂▅▃▅▃▅▄▁▄▄
wandb:      eval/avg_mil_loss ▂▂▅▄▁▅▅▄▃▁▃▅▅▃▂▅▅▂▃▃▃▅▁▄▅▃▅▅▃█▃▃▂▃▆▆▅▃▃▄
wandb:       eval/ensemble_f1 ▅▇▄▄▅▄▂▄▃▅▆▄▅▄▂▅▅▄▆▁▄▄▅▄▃▄▃▂▃█▆▅▆▆▅▂▂▁▄▂
wandb:           train/avg_f1 ▆▅▅█▇▅▃▅▁▄▆▆▄▆▅█▃█▅▆▆▅▆▇▆▄▃▆▄▅▆▅▆▆▃▅▅▆▅▃
wandb:      train/ensemble_f1 ▃▆▆█▅▄▆▅▅▁▅▆█▅▄▅▃▇▇▄▇▆▄▇▅▃▂▆▆▆▃▃▆▆▄▂▅▅▄▄
wandb:         train/mil_loss █▄▅▃▆▅▇▃▅▇▇▃▅▃▁▅▄▄▄▁▂▂▃▁▁▃▃▄▃▁▂▂▄▃▃▁▃▂▂▂
wandb:      train/policy_loss █▅▅▁▁█▅█▅▅▅▅▅█▅▅▅▅▁█▅▅▅█▅▁▅█▅▁█▅▅▁▁▁▅█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆█▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▁▇▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.37356
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79492
wandb:      eval/avg_mil_loss 0.4581
wandb:       eval/ensemble_f1 0.79492
wandb:           train/avg_f1 0.78648
wandb:      train/ensemble_f1 0.78648
wandb:         train/mil_loss 1.55026
wandb:      train/policy_loss 0.46391
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.46391
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np59qy50
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120433-np59qy50/logs
wandb: ERROR Run np59qy50 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: rme4kynf with config:
wandb: 	actor_learning_rate: 1.7979723582273274e-06
wandb: 	attention_dropout_p: 0.4081120796257889
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06777522420390436
wandb: 	temperature: 7.631636938866009
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120653-rme4kynf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rme4kynf
wandb: uploading history steps 92-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss ▄█▆▅▁
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▆▆▇▄▃▅▃▇▄▄▄▆▆▄▆▃▃▂▃▅▆▅▅▃▃▁▃▆▄▁█▃█▄▆▃▄▃▇▇
wandb:      eval/avg_mil_loss ▂▂█▅▄▄▃▆▁▃▂▄▄▅▅▆▃▆█▅▃▅▃▅█▅▄▆▆▅▆▃▂▂▅█▅▂▂▂
wandb:       eval/ensemble_f1 ▆▅▁▃▆▃▇▅▄▃▃▆▃▃▂▃▆▃▆▅▆▅▅▆▂▃▁▆▅▅▃█▅▄▅▄▇▄▁▆
wandb:           train/avg_f1 ▁▆▄▆▅▆▃▄▅▃▅█▆▅▅▂▃▄▄▆▅▅▂▃▆▄▄▄▃▇█▃▇▄▇▄▃▆▄▅
wandb:      train/ensemble_f1 ▇▃▅▆▅▇▆▆▆▄▅█▆▇█▃▆▃▂▅▄▆▆▆▃▆▇▇▅▅▇▇▆▇▇▅▆█▇▁
wandb:         train/mil_loss ▂▃▃▄▄▃█▅▄▅▂▆▆▄▄▂▃▁▄▅▄▆▄▆▃▃▄▄▄▇▆▃▅▃▃▃▄▆▇▆
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▁██▁▁▁██▄▄▁▁▄▁▄▄▁█▁██▁▁██▁██▁▄█▄█▄▁▄██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.41726
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.81331
wandb:      eval/avg_mil_loss 0.4348
wandb:       eval/ensemble_f1 0.81331
wandb:           train/avg_f1 0.78735
wandb:      train/ensemble_f1 0.78735
wandb:         train/mil_loss 0.96757
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rme4kynf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120653-rme4kynf/logs
wandb: ERROR Run rme4kynf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ucju3ny6 with config:
wandb: 	actor_learning_rate: 1.2323572872089547e-05
wandb: 	attention_dropout_p: 0.28900285778086604
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4397813910170526
wandb: 	temperature: 9.905731190790116
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120912-ucju3ny6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucju3ny6
wandb: uploading history steps 114-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▁▃▆
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 █▄▇▅▇█▅▅▄▆▅▄▆▅▅▄▅▆▄▃▄▁▆▄▆▅▆▆▂▇▆▅▃▃▄▃▃▂▅▅
wandb:      eval/avg_mil_loss ▂▄▁▅▆▄▂▅▇▅▅▇▅▅▅▄▅▃▄▅▁▄▃▆▆▇▆▆▄▄▄▄▅▆█▄▆▇▄▆
wandb:       eval/ensemble_f1 ▇▄▄▅▄▅▅▆▅▅█▅▇▆▅▅▇▅▇▄▄▄▅█▆▅█▆▆▆▄▇▇▁▄▆▄▇▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃█▄▇▅▃▆▂▃▄▃▄▅▃▅▆▃█▄▃▄▅▃▆▆▂▆▄▂▄▄▃▄▃▃▄▆▄
wandb:      train/ensemble_f1 ▂█▇▆▆▇▃▄█▄▆▆▅▇▄▇▄▄▄▃▆▃▅▇▅▅▄█▅▃▄▁▄▅▂▅▅▆▇▆
wandb:         train/mil_loss ▄▅▇█▇▇▇▅▅▅█▆▅▅▅▆▆▅▇▅▃▆▅▅▄▃▆▃▄▃▄▄▃▅▃▃▃▃▁▄
wandb:      train/policy_loss ████████████████████████████████▁███████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83571
wandb: best/eval_avg_mil_loss 0.41435
wandb:  best/eval_ensemble_f1 0.83571
wandb:            eval/avg_f1 0.80291
wandb:      eval/avg_mil_loss 0.46798
wandb:       eval/ensemble_f1 0.80291
wandb:            test/avg_f1 0.76541
wandb:      test/avg_mil_loss 0.55479
wandb:       test/ensemble_f1 0.76541
wandb:           train/avg_f1 0.79593
wandb:      train/ensemble_f1 0.79593
wandb:         train/mil_loss 1.71852
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucju3ny6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120912-ucju3ny6/logs
wandb: Agent Starting Run: fu4rjp6z with config:
wandb: 	actor_learning_rate: 7.513378626992665e-05
wandb: 	attention_dropout_p: 0.10602774871258148
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3098368165004557
wandb: 	temperature: 7.538445805616156
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121158-fu4rjp6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu4rjp6z
wandb: uploading history steps 172-179, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ▇█▆▇▄▂▆▅▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▅▆▇▇█
wandb:            eval/avg_f1 ▂▂▇▃▁▇▁▅▄▅▆▅▅▆▅▇▄▄▆▃▆▇▅▅▄▄▆▂▃▃▄█▆▅▃▅▄▂▃▅
wandb:      eval/avg_mil_loss ▅▆▆▇▅▃▃▅▆▅▆▄▃▆▅▄▆▃▅▃▅█▄▂▄▃▅▃▂▁▃▇▅▃▄▅▂▅▁▄
wandb:       eval/ensemble_f1 ▅▆▃▅▆▆▂▅▄█▅▄▅▂▆▅▆▆▆▅▅▅▆▅▁▅▇▇▆▄▃▅▄▅▄▄▂▅▄▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▃█▄▂▁▃▅▃▁▅▂▅▆▄▂▃▅▃▃▃▃▃▃▄▄▂▃▃▄▃▃▅▅▅▅▄▄
wandb:      train/ensemble_f1 ▄▃█▂▄▂▄▃▁▄▂▄▂▄▄▅▄▄▂▃▄▃▂▃▃▆▂▂▂▃▅▃▂▃▅▂▂▂▅▃
wandb:         train/mil_loss █▆▅▇▅▇▆▅▄▄▅▄▄▃▃▆▅▆▆▄▃▅▅▂▄▆▆▄▃▁▅▆▂▄▄▂▃▄▃▇
wandb:      train/policy_loss ▁▁██▅▅█▅▁██▅█▅▅▁▅█▅██▅▁█▁▅▅▅▅▅▁▁█▅█▁▅█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▅▁▅██▅▅██▁▅█▁▅▅▅▅██▅▅▁██▁▁▁▅█▁▁█▁▅█▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.41286
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.77701
wandb:      eval/avg_mil_loss 0.51132
wandb:       eval/ensemble_f1 0.77701
wandb:            test/avg_f1 0.77485
wandb:      test/avg_mil_loss 0.52183
wandb:       test/ensemble_f1 0.77485
wandb:           train/avg_f1 0.80673
wandb:      train/ensemble_f1 0.80673
wandb:         train/mil_loss 0.59589
wandb:      train/policy_loss -0.12498
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.12498
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu4rjp6z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121158-fu4rjp6z/logs
wandb: Agent Starting Run: 86wgu7uc with config:
wandb: 	actor_learning_rate: 0.0007334296893241583
wandb: 	attention_dropout_p: 0.327322112412064
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2999772007007121
wandb: 	temperature: 4.012646296956399
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121556-86wgu7uc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86wgu7uc
wandb: uploading history steps 127-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇▇▇█
wandb: best/eval_avg_mil_loss █▇▃▁▂▅▁
wandb:  best/eval_ensemble_f1 ▁▆▆▇▇▇█
wandb:            eval/avg_f1 ▇▃▆▅▄▁▄▄▄▆▇▆▄▆▅▂▃▃▅▅▇▃▆▂▆▅▄█▄▅▄▆▄▂█▅▄▅▇▅
wandb:      eval/avg_mil_loss ▄▂▄▆▂▃▅▂▅▆▃▂▅▃▃▅▄▆▅▆▄▂▅▅█▅▄▄▅▃▃▄▁▄▅▄▄▅▃▃
wandb:       eval/ensemble_f1 ▄▇▆▄▄▄▅▅▃▄▅▆▄▇▅▆▄▅▅▁▁▅▃▅▇▃▄▇▅▅▄▄▅▄██▄▄▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▆▅▅▆▆▄▆▇█▆▇▇▄▄▆▆▄▃▆▃▅▆▆▇▄▄▆▆▂▂▆█▄▁▄▄▆▆
wandb:      train/ensemble_f1 ▅▅▃▅▂▃▄▄▄▅▆▃▂▇█▅▇▄▅▅▅▅▄▅▇▂▃▄▆▅▅▅▁▁▄▃▇▃▅▅
wandb:         train/mil_loss ▄▆▆▄▇▅█▆▄▅▇▅▄▅▇▇▅▇▆▆▅▆▃▅▁▅▆▅▅▅▄▅▇▄▃▇▅▅▄▇
wandb:      train/policy_loss ▄▁█▁▄▁▁█▄▄▄▁▄▄▁▄███▄█▁██████▄▁▁▁▄█▄▁▄█▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▁██▁▁▁█▅█▅█▁▁█▁█▅▁███▅▁██▅▅▅▅▅▅█▁▅▁▁█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.41254
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80495
wandb:      eval/avg_mil_loss 0.45059
wandb:       eval/ensemble_f1 0.80495
wandb:            test/avg_f1 0.77225
wandb:      test/avg_mil_loss 0.49896
wandb:       test/ensemble_f1 0.77225
wandb:           train/avg_f1 0.79863
wandb:      train/ensemble_f1 0.79863
wandb:         train/mil_loss 0.93991
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86wgu7uc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121556-86wgu7uc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
