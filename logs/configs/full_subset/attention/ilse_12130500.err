wandb: Agent Starting Run: zxzvx83j with config:
wandb: 	actor_learning_rate: 7.785972984755701e-05
wandb: 	attention_dropout_p: 0.0023236273311059708
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27718320989541256
wandb: 	temperature: 1.6770086602967538
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041917-zxzvx83j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxzvx83j
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–…â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ƒâ–‡â–ˆâ–†â–„â–ƒâ–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–…â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–†â–†â–…â–†â–†â–†â–‡â–â–…â–„â–‡â–ˆâ–„â–†â–†â–…â–„â–„â–‡â–„â–…â–…â–â–ƒâ–ƒâ–ƒâ–…â–†â–‡â–„â–ƒâ–…â–…â–‡â–ƒâ–„â–ƒ
wandb:      eval/avg_mil_loss â–…â–‚â–…â–„â–…â–…â–„â–ƒâ–…â–†â–…â–‚â–…â–…â–…â–…â–…â–„â–ƒâ–‡â–„â–ƒâ–…â–†â–†â–ƒâ–ˆâ–†â–…â–†â–ƒâ–â–ƒâ–‡â–„â–â–…â–ˆâ–ˆâ–ˆ
wandb:       eval/ensemble_f1 â–…â–†â–„â–„â–†â–„â–…â–…â–†â–†â–‡â–‡â–â–…â–„â–†â–ˆâ–ƒâ–„â–†â–„â–…â–„â–‡â–„â–…â–â–ƒâ–ƒâ–…â–†â–‡â–„â–ƒâ–…â–…â–‡â–ƒâ–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–ƒâ–†â–ƒâ–…â–„â–…â–ƒâ–†â–„â–…â–„â–„â–ƒâ–â–ƒâ–â–ˆâ–„â–ƒâ–„â–„â–…â–…â–ƒâ–ƒâ–‡â–„â–…â–…â–ƒâ–„â–…â–„â–„â–‚â–„â–„â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–†â–ƒâ–†â–„â–…â–…â–ƒâ–†â–„â–…â–„â–„â–ƒâ–ƒâ–â–ƒâ–ˆâ–ƒâ–‡â–ƒâ–„â–…â–…â–„â–‚â–‡â–ƒâ–…â–…â–„â–ƒâ–ƒâ–…â–†â–†â–‚â–„â–†
wandb:         train/mil_loss â–†â–†â–†â–ƒâ–ˆâ–…â–ˆâ–ƒâ–†â–„â–…â–†â–ˆâ–†â–ƒâ–ƒâ–…â–†â–ƒâ–†â–â–‚â–†â–‡â–…â–‚â–‡â–†â–‚â–„â–…â–â–‚â–‡â–„â–‚â–…â–…â–…â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–‡â–…â–â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–‡â–ˆâ–…â–…â–…â–„â–…â–‚â–‡â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–ˆâ–†â–â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–„â–†â–‚â–ˆâ–†â–†â–‡â–†â–†â–†â–‡â–„â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82836
wandb: best/eval_avg_mil_loss 0.43542
wandb:  best/eval_ensemble_f1 0.82836
wandb:            eval/avg_f1 0.77005
wandb:      eval/avg_mil_loss 0.53374
wandb:       eval/ensemble_f1 0.77005
wandb:            test/avg_f1 0.77274
wandb:      test/avg_mil_loss 0.51198
wandb:       test/ensemble_f1 0.77274
wandb:           train/avg_f1 0.79876
wandb:      train/ensemble_f1 0.79876
wandb:         train/mil_loss 1.2984
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smooth-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxzvx83j
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041917-zxzvx83j/logs
wandb: Agent Starting Run: sw6go1o5 with config:
wandb: 	actor_learning_rate: 1.0218385501048948e-06
wandb: 	attention_dropout_p: 0.48121419969755674
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8554077793051938
wandb: 	temperature: 7.303572845926196
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042024-sw6go1o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sw6go1o5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–…â–…â–…â–†â–‡â–„â–ƒâ–„â–…â–…â–†â–ƒâ–ˆâ–ƒâ–†â–ƒâ–„â–†â–„â–„â–„â–ˆâ–†â–„â–â–‚â–‚â–„â–ƒâ–„â–ƒâ–‚â–„â–‚â–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–‡â–â–†â–„â–â–‚â–„â–…â–„â–‚â–„â–„â–ƒâ–„â–‚â–„â–ƒâ–…â–‚â–ƒâ–…â–…â–ƒâ–†â–†â–„â–…â–„â–ƒâ–‚â–ƒâ–ˆâ–†â–„
wandb:       eval/ensemble_f1 â–†â–„â–…â–‡â–…â–ƒâ–…â–†â–‚â–‡â–…â–…â–†â–„â–…â–„â–„â–ƒâ–„â–‚â–†â–„â–ƒâ–‡â–„â–ƒâ–‡â–ˆâ–ƒâ–„â–â–‡â–„â–‚â–ƒâ–ƒâ–…â–…â–†â–ƒ
wandb:           train/avg_f1 â–‡â–ˆâ–†â–…â–†â–ˆâ–†â–…â–…â–„â–‡â–ˆâ–‡â–‡â–‡â–…â–ƒâ–‡â–„â–‡â–†â–„â–†â–„â–†â–…â–„â–‚â–„â–â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb:      train/ensemble_f1 â–‡â–†â–‡â–‡â–…â–†â–ˆâ–†â–…â–‡â–†â–‡â–ˆâ–…â–‡â–‡â–‡â–„â–‡â–„â–ƒâ–†â–†â–‡â–…â–„â–ƒâ–†â–ƒâ–…â–‚â–ƒâ–…â–…â–ƒâ–ƒâ–„â–â–ƒâ–
wandb:         train/mil_loss â–†â–ˆâ–†â–‡â–ˆâ–†â–…â–…â–‡â–‡â–†â–†â–‡â–‡â–…â–†â–†â–†â–…â–…â–…â–…â–…â–„â–â–„â–„â–„â–„â–…â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–„â–„â–
wandb:      train/policy_loss â–„â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–…â–„â–„â–„â–…â–„â–„â–„â–…â–†â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.47211
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.77371
wandb:      eval/avg_mil_loss 0.4699
wandb:       eval/ensemble_f1 0.77371
wandb:           train/avg_f1 0.76244
wandb:      train/ensemble_f1 0.76244
wandb:         train/mil_loss 1.86037
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sw6go1o5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042024-sw6go1o5/logs
wandb: ERROR Run sw6go1o5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ujyw26zj with config:
wandb: 	actor_learning_rate: 3.6247589881007986e-05
wandb: 	attention_dropout_p: 0.3833739748252211
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8833137213637785
wandb: 	temperature: 1.6608634365301178
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042335-ujyw26zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujyw26zj
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–ƒâ–†â–„â–…â–…â–„â–†â–„â–„â–†â–‡â–„â–†â–…â–„â–ƒâ–„â–‚â–„â–…â–†â–ƒâ–…â–„â–†â–…â–„â–ˆâ–ƒâ–…â–†â–ƒâ–„â–â–…â–„â–‚â–‚
wandb:      eval/avg_mil_loss â–†â–„â–…â–ƒâ–…â–„â–†â–â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–…â–‡â–ƒâ–…â–ƒâ–…â–ƒâ–„â–„â–ƒâ–„â–â–†â–†â–ˆâ–ƒâ–ƒâ–…â–„â–…â–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–‡â–†â–„â–„â–„â–†â–…â–…â–†â–…â–…â–…â–†â–‡â–ˆâ–…â–„â–„â–ƒâ–…â–‡â–…â–…â–„â–…â–‡â–†â–â–‡â–†â–„â–†â–‡â–ˆâ–„â–„â–…â–†â–„â–‚
wandb:           train/avg_f1 â–†â–…â–†â–ˆâ–…â–‡â–ˆâ–†â–…â–‡â–„â–„â–„â–…â–„â–ˆâ–‡â–†â–„â–ˆâ–„â–ƒâ–ƒâ–‡â–â–†â–†â–…â–…â–…â–…â–„â–ƒâ–†â–†â–…â–„â–‚â–â–‚
wandb:      train/ensemble_f1 â–„â–…â–„â–„â–„â–ˆâ–‚â–‡â–†â–…â–‚â–„â–„â–…â–„â–†â–ƒâ–…â–‡â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–…â–…â–„â–…â–‚â–„â–‚â–…â–†â–„â–„â–‚
wandb:         train/mil_loss â–ˆâ–†â–ˆâ–†â–…â–†â–‡â–†â–…â–‡â–†â–„â–„â–†â–ƒâ–†â–„â–…â–‚â–„â–…â–ƒâ–…â–†â–„â–„â–„â–„â–†â–†â–„â–„â–‚â–ƒâ–„â–ƒâ–â–‡â–…â–„
wandb:      train/policy_loss â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.40919
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.75911
wandb:      eval/avg_mil_loss 0.46336
wandb:       eval/ensemble_f1 0.75911
wandb:           train/avg_f1 0.7763
wandb:      train/ensemble_f1 0.7763
wandb:         train/mil_loss 0.85274
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujyw26zj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042335-ujyw26zj/logs
wandb: ERROR Run ujyw26zj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: fmri63jr with config:
wandb: 	actor_learning_rate: 1.4702476432278276e-06
wandb: 	attention_dropout_p: 0.49391657661514593
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05269196843359236
wandb: 	temperature: 0.8004713116696338
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042456-fmri63jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmri63jr
wandb: uploading history steps 64-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–„â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–ƒâ–…â–†â–ˆâ–„â–‚â–…â–†â–†â–‡â–„â–ˆâ–†â–†â–†â–…â–…â–ƒâ–†â–ƒâ–†â–ƒâ–„â–…â–â–ˆâ–„â–ƒâ–†â–„â–ƒâ–„â–†â–„â–†â–…â–ƒâ–†
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–‡â–ƒâ–„â–â–ˆâ–„â–ˆâ–ƒâ–‚â–ƒâ–…â–„â–…â–…â–„â–†â–ƒâ–ˆâ–„â–â–„â–…â–…â–‡â–…â–…â–…â–‡â–†â–…â–„â–…â–„â–ˆâ–…â–†â–†â–†
wandb:       eval/ensemble_f1 â–…â–„â–†â–†â–‡â–„â–…â–†â–…â–‡â–†â–„â–‡â–…â–…â–…â–„â–†â–†â–†â–‡â–ƒâ–…â–ƒâ–„â–…â–…â–â–ˆâ–„â–†â–ƒâ–„â–†â–ƒâ–†â–‡â–…â–„â–„
wandb:           train/avg_f1 â–‡â–…â–‡â–ˆâ–„â–†â–†â–‡â–‡â–†â–ˆâ–†â–…â–ˆâ–ƒâ–…â–†â–ƒâ–†â–ƒâ–„â–†â–‚â–†â–…â–ƒâ–…â–„â–…â–‚â–‚â–…â–ƒâ–„â–†â–â–…â–â–†â–„
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–…â–ˆâ–ƒâ–…â–„â–†â–†â–„â–†â–„â–…â–†â–‚â–†â–ƒâ–…â–…â–…â–‚â–‚â–…â–ƒâ–†â–‚â–…â–â–†â–â–„
wandb:         train/mil_loss â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–†â–…â–„â–„â–„â–…â–„â–ƒâ–„â–„â–„â–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–†â–…â–…â–ˆâ–„â–…â–…â–…â–…â–‡â–„â–â–…â–…â–…â–…â–‡â–…â–…â–ƒâ–…â–…â–…â–†â–…â–…â–…â–ƒâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–â–„â–…â–ƒâ–„â–„â–„â–„â–„â–ˆâ–†â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–†â–‚â–†â–„â–„â–…â–„â–…â–†â–„â–‚â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82846
wandb: best/eval_avg_mil_loss 0.43649
wandb:  best/eval_ensemble_f1 0.82846
wandb:            eval/avg_f1 0.7992
wandb:      eval/avg_mil_loss 0.49739
wandb:       eval/ensemble_f1 0.7992
wandb:           train/avg_f1 0.77781
wandb:      train/ensemble_f1 0.77781
wandb:         train/mil_loss 1.20729
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run noble-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fmri63jr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042456-fmri63jr/logs
wandb: ERROR Run fmri63jr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	size mismatch for task_model.mlp.0.weight: copying a param with shape torch.Size([128, 20]) from checkpoint, the shape in current model is torch.Size([512, 20]).
wandb: ERROR 	size mismatch for task_model.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
wandb: ERROR 	size mismatch for task_model.mlp.3.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 512]).
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u9afj423 with config:
wandb: 	actor_learning_rate: 4.3258364044489e-05
wandb: 	attention_dropout_p: 0.021448895343702257
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12132423077157696
wandb: 	temperature: 2.9316843489706623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042625-u9afj423
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u9afj423
wandb: uploading history steps 116-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–â–…â–„â–‚â–„â–†â–‚â–ˆâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–ƒâ–„â–…â–ƒâ–„â–†â–ƒâ–…â–†â–„â–†â–â–…â–ƒâ–ˆâ–‚â–ƒâ–…â–‚â–‡â–„â–…â–†â–‚â–ƒâ–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–…â–„â–†â–ƒâ–†â–„â–†â–â–…â–‡â–ˆâ–„â–‚â–ƒâ–„â–„â–…â–ƒâ–‚â–ˆâ–‚â–ƒâ–ˆâ–â–…â–ˆâ–„
wandb:       eval/ensemble_f1 â–…â–‚â–‡â–…â–‚â–„â–…â–‡â–ƒâ–†â–ˆâ–„â–…â–†â–…â–†â–â–„â–…â–ƒâ–…â–…â–…â–„â–†â–†â–…â–ˆâ–ƒâ–…â–‡â–„â–‚â–‚â–‡â–ƒâ–â–‡â–ƒâ–ƒ
wandb:           train/avg_f1 â–ˆâ–…â–„â–„â–„â–…â–…â–„â–†â–†â–…â–†â–‡â–ƒâ–…â–„â–ƒâ–…â–…â–ƒâ–†â–†â–„â–…â–ƒâ–„â–„â–†â–†â–†â–ƒâ–„â–…â–…â–â–‡â–‡â–…â–…â–„
wandb:      train/ensemble_f1 â–‡â–„â–„â–…â–…â–ˆâ–†â–„â–†â–„â–‡â–„â–„â–ƒâ–…â–ƒâ–…â–‡â–†â–„â–†â–†â–„â–†â–…â–„â–†â–†â–…â–…â–†â–ƒâ–â–„â–‡â–†â–‡â–…â–…â–†
wandb:         train/mil_loss â–‡â–ˆâ–‡â–„â–‚â–…â–„â–…â–†â–†â–†â–†â–…â–‡â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–„â–ƒâ–†â–ƒâ–‚â–‚â–‚â–„â–„â–…â–‚â–…â–ƒâ–ƒâ–â–â–‚â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–ƒâ–†â–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84867
wandb: best/eval_avg_mil_loss 0.37523
wandb:  best/eval_ensemble_f1 0.84867
wandb:            eval/avg_f1 0.79453
wandb:      eval/avg_mil_loss 0.44938
wandb:       eval/ensemble_f1 0.79453
wandb:           train/avg_f1 0.8078
wandb:      train/ensemble_f1 0.8078
wandb:         train/mil_loss 1.98062
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eternal-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u9afj423
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042625-u9afj423/logs
wandb: ERROR Run u9afj423 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kk5jqzuu with config:
wandb: 	actor_learning_rate: 5.105584249142839e-05
wandb: 	attention_dropout_p: 0.4055533092980569
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.038043439417819624
wandb: 	temperature: 6.174793644363752
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042850-kk5jqzuu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk5jqzuu
wandb: uploading wandb-summary.json
wandb: uploading history steps 72-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–†â–ˆâ–‡â–â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–â–„â–‚â–…â–…â–…â–…â–…â–â–…â–…â–†â–„â–‡â–„â–„â–…â–ˆâ–†â–…â–‚â–‚â–†â–„â–…â–…â–ˆâ–„â–ƒâ–†â–„â–ƒâ–…â–†â–…â–…â–ƒâ–„â–‡
wandb:      eval/avg_mil_loss â–„â–†â–„â–†â–ƒâ–„â–„â–‚â–„â–…â–„â–…â–‚â–…â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–…â–‚â–…â–ˆâ–ˆâ–‡â–‚â–ƒâ–â–„â–ƒâ–‚â–†â–ƒâ–…â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–„â–…â–…â–ƒâ–â–†â–„â–…â–ƒâ–…â–†â–‡â–„â–„â–ˆâ–†â–‚â–ƒâ–‚â–‚â–ƒâ–†â–„â–…â–…â–„â–„â–†â–„â–†â–†â–ƒâ–…â–…â–„â–ƒâ–‡
wandb:           train/avg_f1 â–…â–ƒâ–…â–„â–†â–ˆâ–…â–„â–…â–…â–‚â–‚â–ƒâ–â–ƒâ–â–…â–‡â–…â–†â–ƒâ–‡â–‡â–‚â–„â–†â–„â–†â–…â–„â–‚â–‡â–…â–„â–…â–†â–†â–†â–ƒâ–‡
wandb:      train/ensemble_f1 â–…â–…â–„â–…â–†â–†â–ˆâ–…â–…â–…â–‚â–‚â–â–ƒâ–†â–â–…â–…â–†â–…â–†â–‡â–‡â–…â–‚â–†â–…â–ˆâ–…â–†â–…â–„â–†â–‚â–…â–†â–†â–†â–ƒâ–‡
wandb:         train/mil_loss â–‡â–â–ƒâ–†â–‡â–…â–ˆâ–†â–â–„â–„â–„â–†â–†â–„â–ƒâ–…â–ˆâ–…â–…â–…â–„â–…â–†â–„â–†â–‚â–â–„â–†â–‡â–„â–„â–ƒâ–‚â–‚â–ƒâ–†â–‚â–ˆ
wandb:      train/policy_loss â–â–„â–â–„â–„â–â–ˆâ–â–â–„â–â–ˆâ–ˆâ–„â–â–â–â–„â–„â–â–„â–ˆâ–ˆâ–â–ˆâ–ˆâ–„â–„â–„â–â–ˆâ–„â–ˆâ–„â–â–ˆâ–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–â–ˆâ–â–ˆâ–„â–ˆâ–â–ˆâ–ˆâ–„â–â–â–â–„â–ˆâ–ˆâ–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–ˆâ–â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79558
wandb: best/eval_avg_mil_loss 0.52848
wandb:  best/eval_ensemble_f1 0.79558
wandb:            eval/avg_f1 0.78453
wandb:      eval/avg_mil_loss 0.5145
wandb:       eval/ensemble_f1 0.78453
wandb:           train/avg_f1 0.76925
wandb:      train/ensemble_f1 0.76925
wandb:         train/mil_loss 1.77417
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sandy-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk5jqzuu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042850-kk5jqzuu/logs
wandb: ERROR Run kk5jqzuu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mssinsh3 with config:
wandb: 	actor_learning_rate: 0.0005569878546349457
wandb: 	attention_dropout_p: 0.1715534132283853
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4233056935286077
wandb: 	temperature: 1.5809924876065884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043018-mssinsh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mssinsh3
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 100-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–â–ˆâ–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–â–ƒâ–…â–„â–„â–„â–…â–„â–„â–…â–…â–ƒâ–…â–„â–…â–„â–‚â–…â–…â–„â–„â–…â–†â–ƒâ–†â–‡â–…â–„â–‡â–†â–„â–…â–ƒâ–…â–…â–ˆâ–ƒâ–„
wandb:      eval/avg_mil_loss â–‚â–„â–†â–†â–ˆâ–‚â–‡â–‡â–†â–†â–ƒâ–…â–†â–ƒâ–…â–…â–„â–ˆâ–‡â–†â–‡â–…â–ˆâ–„â–†â–â–ˆâ–ˆâ–‡â–…â–‡â–†â–„â–†â–…â–†â–‚â–…â–ƒâ–‡
wandb:       eval/ensemble_f1 â–‡â–†â–ƒâ–„â–ƒâ–…â–„â–†â–â–…â–†â–†â–„â–„â–„â–„â–…â–„â–†â–ƒâ–„â–ƒâ–†â–„â–‡â–„â–‚â–‚â–ˆâ–„â–„â–„â–†â–‚â–„â–…â–…â–†â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–‡â–‡â–…â–†â–…â–†â–…â–†â–…â–…â–†â–ƒâ–‡â–…â–‡â–…â–…â–†â–†â–â–…â–ˆâ–†â–‡â–…â–…â–…â–†â–†â–…â–ˆâ–…â–…â–†â–†â–‡â–…â–‡
wandb:      train/ensemble_f1 â–†â–„â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–†â–ƒâ–…â–„â–…â–‚â–„â–„â–„â–ƒâ–†â–…â–ˆâ–â–„â–…â–„â–†â–ƒâ–„â–…â–†â–…â–„â–„â–‡â–ƒâ–„â–…â–…
wandb:         train/mil_loss â–„â–„â–…â–…â–„â–„â–…â–…â–…â–…â–‚â–†â–ƒâ–‚â–„â–†â–‚â–ˆâ–…â–‡â–ƒâ–„â–„â–…â–â–…â–„â–„â–‚â–…â–…â–…â–„â–†â–„â–„â–ƒâ–†â–…â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82836
wandb: best/eval_avg_mil_loss 0.4319
wandb:  best/eval_ensemble_f1 0.82836
wandb:            eval/avg_f1 0.76631
wandb:      eval/avg_mil_loss 0.56108
wandb:       eval/ensemble_f1 0.76631
wandb:            test/avg_f1 0.73654
wandb:      test/avg_mil_loss 0.61046
wandb:       test/ensemble_f1 0.73654
wandb:           train/avg_f1 0.77689
wandb:      train/ensemble_f1 0.77689
wandb:         train/mil_loss 1.12979
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run graceful-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mssinsh3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043018-mssinsh3/logs
wandb: Agent Starting Run: e3g08r4h with config:
wandb: 	actor_learning_rate: 0.0004950020675556752
wandb: 	attention_dropout_p: 0.3707570792471581
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4243428396767176
wandb: 	temperature: 2.2064380074959877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043217-e3g08r4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3g08r4h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–â–ˆâ–†â–‚â–†â–â–„â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–†â–†â–†â–†â–…â–…â–â–„â–‡â–ƒâ–†â–…â–ƒâ–‚â–ƒâ–‚â–„â–…â–„â–„â–…â–„â–†â–„
wandb:      eval/avg_mil_loss â–‚â–ˆâ–ƒâ–‚â–ƒâ–‚â–„â–„â–†â–„â–‡â–„â–…â–„â–‚â–†â–‚â–â–ƒâ–ƒâ–†â–„â–‚â–„â–â–„â–„â–†â–ƒâ–†â–‚â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–‚â–â–„
wandb:       eval/ensemble_f1 â–‡â–ˆâ–„â–…â–†â–„â–„â–„â–â–…â–…â–…â–ƒâ–â–„â–‡â–ˆâ–†â–‚â–‡â–…â–â–…â–ˆâ–ƒâ–ƒâ–‡â–‡â–ƒâ–„â–†â–…â–…â–„â–‚â–â–†â–†â–„â–ƒ
wandb:           train/avg_f1 â–„â–„â–â–‚â–…â–‚â–‚â–‚â–ƒâ–…â–…â–„â–‚â–ƒâ–„â–…â–„â–ƒâ–„â–…â–‡â–ƒâ–‚â–‚â–†â–â–â–â–„â–…â–ˆâ–†â–‚â–†â–ƒâ–…â–‡â–„â–†â–‡
wandb:      train/ensemble_f1 â–…â–ƒâ–…â–…â–†â–…â–†â–‡â–ˆâ–‡â–†â–†â–…â–ˆâ–ˆâ–†â–„â–†â–„â–†â–…â–…â–…â–ƒâ–‡â–†â–â–†â–…â–…â–„â–…â–ˆâ–†â–†â–„â–‡â–†â–…â–‡
wandb:         train/mil_loss â–…â–‡â–ˆâ–ˆâ–†â–‡â–„â–„â–…â–…â–†â–ƒâ–ƒâ–†â–ƒâ–…â–†â–ƒâ–‚â–ƒâ–„â–†â–„â–„â–ƒâ–„â–‚â–†â–ƒâ–„â–â–„â–…â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–…â–ˆâ–…â–…â–ˆâ–â–…â–ˆâ–…â–…â–â–…â–…â–ˆâ–ˆâ–…â–â–…â–â–ˆâ–â–â–…â–â–â–â–…â–â–â–…â–…â–â–ˆâ–ˆâ–…â–â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78467
wandb: best/eval_avg_mil_loss 0.48935
wandb:  best/eval_ensemble_f1 0.78467
wandb:            eval/avg_f1 0.72168
wandb:      eval/avg_mil_loss 0.57849
wandb:       eval/ensemble_f1 0.72168
wandb:           train/avg_f1 0.74196
wandb:      train/ensemble_f1 0.74196
wandb:         train/mil_loss 1.57273
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deep-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3g08r4h
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043217-e3g08r4h/logs
wandb: ERROR Run e3g08r4h errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d7xtyeqc with config:
wandb: 	actor_learning_rate: 0.0001168070343060098
wandb: 	attention_dropout_p: 0.10339965019573484
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4064755113342424
wandb: 	temperature: 3.7817778240201783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043426-d7xtyeqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7xtyeqc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 57-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–†â–â–ˆâ–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–ƒâ–†â–…â–„â–‡â–†â–„â–„â–â–…â–„â–„â–ƒâ–…â–†â–„â–„â–ˆâ–†â–†â–„â–„â–‡â–†â–„â–„â–‚â–†â–â–…â–‚â–†â–…â–…â–†â–„â–†â–„â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–â–ƒâ–ƒâ–†â–„â–‚â–â–ƒâ–„â–…â–ˆâ–‚â–…â–‚â–ƒâ–‚â–‚â–‚â–…â–†â–‚â–ƒâ–ƒâ–„â–†â–ˆâ–‡â–‚â–…â–‚â–ƒâ–„â–ƒâ–„â–â–‚â–…â–†â–„
wandb:       eval/ensemble_f1 â–†â–ƒâ–„â–†â–…â–„â–‡â–…â–†â–†â–â–„â–„â–„â–„â–†â–…â–„â–„â–ˆâ–„â–„â–‡â–„â–‡â–‚â–†â–â–„â–…â–‚â–†â–…â–†â–„â–†â–„â–…â–†â–…
wandb:           train/avg_f1 â–„â–†â–†â–…â–…â–„â–„â–„â–…â–…â–†â–†â–…â–…â–†â–…â–…â–†â–‡â–…â–‡â–„â–„â–†â–ˆâ–‡â–†â–†â–‚â–„â–â–ƒâ–ˆâ–ˆâ–„â–ƒâ–†â–†â–†â–‡
wandb:      train/ensemble_f1 â–„â–‡â–†â–…â–…â–…â–„â–„â–…â–…â–†â–†â–…â–…â–…â–†â–…â–…â–ƒâ–†â–…â–„â–‡â–†â–„â–ˆâ–„â–‡â–†â–†â–†â–â–ƒâ–ˆâ–‡â–ƒâ–†â–†â–„â–†
wandb:         train/mil_loss â–…â–…â–‡â–„â–„â–…â–„â–„â–„â–„â–…â–‚â–„â–…â–†â–…â–†â–†â–†â–„â–„â–„â–â–â–†â–‚â–ˆâ–ˆâ–ƒâ–…â–„â–„â–†â–„â–ƒâ–ƒâ–‡â–…â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.37032
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.8052
wandb:      eval/avg_mil_loss 0.4414
wandb:       eval/ensemble_f1 0.8052
wandb:           train/avg_f1 0.81251
wandb:      train/ensemble_f1 0.81251
wandb:         train/mil_loss 2.24781
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7xtyeqc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043426-d7xtyeqc/logs
wandb: ERROR Run d7xtyeqc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7o1od0y7 with config:
wandb: 	actor_learning_rate: 0.00012845948431433084
wandb: 	attention_dropout_p: 0.4188261319515624
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0949797593788756
wandb: 	temperature: 5.880363623922037
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043538-7o1od0y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7o1od0y7
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‡â–â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–…â–â–„â–„â–†â–‡â–ƒâ–…â–ƒâ–…â–ƒâ–†â–‡â–ƒâ–ƒâ–ˆâ–‡â–…â–…â–„â–…â–…â–‡â–„â–‚â–†â–†â–ƒâ–…â–„â–ƒâ–…â–„â–‡â–„â–†â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–ˆâ–…â–ƒâ–„â–…â–‡â–„â–…â–„â–‚â–…â–‚â–…â–†â–†â–ƒâ–„â–‡â–„â–…â–…â–â–†â–†â–„â–†â–ˆâ–…â–ƒâ–…â–…â–‚â–ƒâ–…â–ƒâ–†â–…â–†
wandb:       eval/ensemble_f1 â–…â–„â–†â–â–‡â–„â–†â–„â–â–„â–…â–‡â–…â–„â–†â–‡â–‚â–†â–ƒâ–…â–„â–‡â–†â–‡â–†â–†â–†â–…â–…â–…â–…â–†â–…â–ˆâ–…â–…â–‚â–†â–…â–‡
wandb:           train/avg_f1 â–…â–ˆâ–ƒâ–‡â–…â–†â–…â–ƒâ–„â–†â–ƒâ–…â–†â–…â–‡â–…â–…â–…â–…â–„â–„â–ƒâ–„â–…â–†â–ƒâ–ƒâ–â–…â–ƒâ–…â–ƒâ–â–„â–†â–ƒâ–†â–„â–ƒâ–
wandb:      train/ensemble_f1 â–…â–„â–…â–‡â–ˆâ–†â–…â–‡â–„â–ƒâ–ƒâ–‡â–„â–†â–ƒâ–„â–…â–†â–ƒâ–„â–„â–†â–„â–„â–„â–…â–…â–‚â–„â–…â–…â–ƒâ–â–†â–‚â–„â–„â–ƒâ–‚â–‚
wandb:         train/mil_loss â–…â–‡â–†â–†â–‡â–†â–‡â–†â–…â–…â–…â–ˆâ–…â–…â–„â–†â–„â–†â–…â–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–â–‚â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–â–†â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.38245
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.79197
wandb:      eval/avg_mil_loss 0.4838
wandb:       eval/ensemble_f1 0.79197
wandb:           train/avg_f1 0.78713
wandb:      train/ensemble_f1 0.78713
wandb:         train/mil_loss 1.8385
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run celestial-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7o1od0y7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043538-7o1od0y7/logs
wandb: ERROR Run 7o1od0y7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2gwsc10c with config:
wandb: 	actor_learning_rate: 4.362885906256791e-05
wandb: 	attention_dropout_p: 0.004023745808535373
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5195792679366638
wandb: 	temperature: 0.0868993297928966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043838-2gwsc10c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gwsc10c
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–„â–ˆâ–ƒâ–†â–„â–†â–†â–„â–ƒâ–…â–†â–ƒâ–ƒâ–…â–…â–…â–†â–…â–…â–„â–†â–„â–„â–…â–ƒâ–„â–†â–â–ƒâ–ˆâ–†â–„â–†â–ƒâ–†â–…â–ƒâ–…
wandb:      eval/avg_mil_loss â–‡â–…â–„â–ƒâ–‡â–‡â–‡â–„â–â–ƒâ–ˆâ–…â–‡â–…â–†â–„â–…â–†â–…â–†â–…â–…â–„â–…â–„â–†â–ˆâ–ƒâ–†â–†â–ˆâ–ˆâ–‡â–„â–…â–…â–…â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–‚â–„â–‚â–ƒâ–…â–â–ˆâ–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–‚â–…â–ƒâ–â–ƒâ–‚â–â–„â–…â–„â–ƒâ–„â–„â–„â–â–…â–ƒ
wandb:           train/avg_f1 â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–†â–…â–…â–…â–„â–†â–…â–†â–„â–„â–„â–„â–‡â–…â–„â–ƒâ–ƒâ–…â–ƒâ–„â–„â–„â–†â–„â–…â–…â–…â–ƒâ–ˆâ–â–†
wandb:      train/ensemble_f1 â–…â–…â–†â–„â–…â–„â–ƒâ–„â–…â–„â–…â–â–„â–„â–†â–„â–…â–ƒâ–†â–‚â–…â–…â–†â–„â–…â–„â–„â–…â–†â–…â–„â–„â–„â–…â–‚â–…â–ƒâ–ˆâ–â–„
wandb:         train/mil_loss â–†â–…â–‡â–ƒâ–‡â–†â–‡â–…â–…â–ˆâ–…â–…â–„â–…â–…â–†â–‚â–†â–†â–„â–†â–†â–…â–†â–‚â–ˆâ–…â–…â–…â–ƒâ–„â–„â–ƒâ–ƒâ–â–‚â–„â–ƒâ–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85711
wandb: best/eval_avg_mil_loss 0.40983
wandb:  best/eval_ensemble_f1 0.85711
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.49215
wandb:       eval/ensemble_f1 0.78777
wandb:           train/avg_f1 0.78628
wandb:      train/ensemble_f1 0.78628
wandb:         train/mil_loss 0.96142
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2gwsc10c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043838-2gwsc10c/logs
wandb: ERROR Run 2gwsc10c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xlinjumv with config:
wandb: 	actor_learning_rate: 2.1192415468307916e-05
wandb: 	attention_dropout_p: 0.4423450568466878
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7899730163647599
wandb: 	temperature: 0.39095063310307543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044118-xlinjumv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlinjumv
wandb: uploading wandb-summary.json; uploading history steps 42-56, summary
wandb: uploading history steps 42-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–â–‚â–ƒâ–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–ƒâ–†â–…â–†â–„â–…â–â–‚â–‡â–„â–†â–†â–…â–†â–„â–„â–†â–…â–‡â–‡â–ƒâ–‡â–…â–„â–ƒâ–‚â–…â–…â–‡â–ƒâ–…â–ˆâ–„â–…â–…â–‡â–…â–…
wandb:      eval/avg_mil_loss â–‡â–„â–†â–ƒâ–‡â–…â–ƒâ–†â–â–†â–„â–ƒâ–†â–…â–‚â–„â–‚â–â–„â–†â–„â–„â–„â–„â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–…â–…â–ˆâ–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–‡â–ƒâ–†â–„â–â–†â–„â–…â–â–‡â–„â–†â–…â–…â–„â–„â–†â–…â–…â–‡â–ƒâ–…â–‡â–…â–„â–ƒâ–‚â–…â–…â–…â–‡â–„â–ˆâ–„â–…â–…â–‡â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ƒâ–†â–‚â–…â–‡â–ƒâ–ƒâ–ƒâ–…â–†â–…â–ˆâ–†â–‡â–ˆâ–„â–…â–„â–„â–†â–†â–ƒâ–‡â–†â–…â–†â–†â–†â–ˆâ–…â–„â–†â–â–…â–…â–†â–…â–ƒ
wandb:      train/ensemble_f1 â–…â–†â–ƒâ–†â–ˆâ–‚â–‡â–‡â–ƒâ–ƒâ–‡â–…â–†â–…â–‡â–‡â–„â–‡â–ˆâ–„â–„â–…â–…â–ƒâ–†â–„â–†â–„â–†â–†â–‚â–„â–‡â–„â–â–„â–…â–†â–…â–ƒ
wandb:         train/mil_loss â–ƒâ–ƒâ–…â–†â–…â–„â–ƒâ–…â–„â–‚â–‡â–‡â–„â–ˆâ–‡â–…â–ˆâ–ƒâ–†â–…â–ƒâ–…â–‡â–ƒâ–…â–…â–…â–†â–â–‚â–‡â–†â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–ˆ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83576
wandb: best/eval_avg_mil_loss 0.42866
wandb:  best/eval_ensemble_f1 0.83576
wandb:            eval/avg_f1 0.78719
wandb:      eval/avg_mil_loss 0.4975
wandb:       eval/ensemble_f1 0.78719
wandb:            test/avg_f1 0.7505
wandb:      test/avg_mil_loss 0.54696
wandb:       test/ensemble_f1 0.7505
wandb:           train/avg_f1 0.78044
wandb:      train/ensemble_f1 0.78044
wandb:         train/mil_loss 1.41207
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fallen-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlinjumv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044118-xlinjumv/logs
wandb: Agent Starting Run: uozuohj4 with config:
wandb: 	actor_learning_rate: 1.4230951884895638e-05
wandb: 	attention_dropout_p: 0.18167511095552513
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8129969971537424
wandb: 	temperature: 6.903985313844121
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044225-uozuohj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uozuohj4
wandb: uploading history steps 159-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ƒâ–„â–
wandb:  best/eval_ensemble_f1 â–â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–†â–…â–‚â–„â–†â–‡â–„â–†â–†â–„â–„â–„â–…â–†â–†â–†â–…â–†â–…â–…â–â–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–†â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–ˆâ–„
wandb:      eval/avg_mil_loss â–„â–…â–â–„â–ƒâ–ƒâ–â–ƒâ–„â–„â–…â–„â–ƒâ–‚â–ƒâ–†â–ƒâ–†â–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–„â–ƒâ–„â–…â–…â–…â–ˆâ–‡â–…â–‡â–†â–ˆâ–†â–…
wandb:       eval/ensemble_f1 â–„â–…â–…â–‡â–‡â–…â–ƒâ–‡â–…â–ˆâ–‡â–‡â–†â–‡â–„â–…â–†â–†â–†â–…â–…â–„â–‡â–…â–…â–ƒâ–…â–…â–ƒâ–…â–…â–‚â–†â–„â–…â–ƒâ–ˆâ–…â–â–†
wandb:           train/avg_f1 â–…â–‡â–ˆâ–‡â–…â–†â–ƒâ–‡â–†â–†â–…â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–…â–†â–ƒâ–‡â–ƒâ–…â–ƒâ–…â–†â–ˆâ–…â–‚â–‚â–…â–ƒâ–â–ƒâ–„â–‚â–„
wandb:      train/ensemble_f1 â–…â–‚â–‡â–‡â–…â–ƒâ–‚â–ˆâ–„â–‡â–…â–‡â–†â–…â–…â–„â–†â–…â–ƒâ–…â–ƒâ–…â–†â–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–‚â–â–„â–‚â–ƒâ–†â–‚â–‚â–â–â–‚
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–†â–„â–†â–‡â–†â–…â–ˆâ–…â–†â–…â–…â–…â–…â–…â–„â–…â–„â–„â–„â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–…â–‡â–„â–„â–â–„â–„â–†â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–ƒâ–‡â–†â–†â–â–†â–†â–ˆâ–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83928
wandb: best/eval_avg_mil_loss 0.38566
wandb:  best/eval_ensemble_f1 0.83928
wandb:            eval/avg_f1 0.80655
wandb:      eval/avg_mil_loss 0.49347
wandb:       eval/ensemble_f1 0.80655
wandb:           train/avg_f1 0.7787
wandb:      train/ensemble_f1 0.7787
wandb:         train/mil_loss 1.14561
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fragrant-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uozuohj4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044225-uozuohj4/logs
wandb: ERROR Run uozuohj4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4j7gc6tq with config:
wandb: 	actor_learning_rate: 0.0005674121974747992
wandb: 	attention_dropout_p: 0.39915425567705953
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3373957405566299
wandb: 	temperature: 8.279865348728677
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044556-4j7gc6tq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j7gc6tq
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 97-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–…â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–„â–†â–†â–ƒâ–‡â–†â–„â–‡â–â–„â–‡â–‡â–‡â–‡â–ƒâ–†â–„â–‡â–…â–„â–†â–‡â–…â–„â–ˆâ–†â–†â–…â–†â–†â–„â–„â–‚â–‡â–…â–…â–†
wandb:      eval/avg_mil_loss â–†â–„â–„â–„â–…â–†â–„â–…â–…â–†â–‚â–„â–…â–†â–ƒâ–„â–â–„â–…â–…â–…â–ƒâ–„â–…â–ƒâ–†â–‡â–„â–„â–ˆâ–„â–…â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–ƒâ–‡â–†â–„â–ƒâ–†â–„â–„â–„â–†â–„â–ƒâ–†â–„â–„â–„â–ˆâ–‡â–…â–ˆâ–„â–ƒâ–„â–„â–„â–…â–†â–ˆâ–†â–„â–„â–†â–â–†â–…â–‚â–†â–…
wandb:           train/avg_f1 â–„â–ƒâ–ƒâ–„â–ƒâ–‡â–„â–„â–‚â–„â–‡â–ƒâ–†â–†â–†â–ƒâ–†â–†â–‡â–â–…â–„â–…â–ˆâ–‚â–„â–„â–…â–†â–†â–‡â–…â–ƒâ–…â–†â–ƒâ–ƒâ–„â–„â–‚
wandb:      train/ensemble_f1 â–†â–‡â–â–‡â–„â–…â–ƒâ–„â–…â–„â–…â–†â–‡â–„â–„â–…â–ƒâ–‡â–ˆâ–„â–‚â–…â–†â–„â–‡â–ƒâ–„â–…â–…â–„â–†â–‡â–…â–…â–„â–…â–„â–ƒâ–…â–‡
wandb:         train/mil_loss â–ˆâ–‡â–…â–…â–†â–…â–ƒâ–ƒâ–ˆâ–„â–ƒâ–…â–„â–…â–„â–…â–„â–„â–ƒâ–…â–ƒâ–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–„â–ƒâ–â–ƒâ–†â–â–‚â–‚â–‚â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–†â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–…â–â–ˆâ–…â–…â–â–…â–â–â–…â–â–ˆâ–â–…â–…â–ˆâ–…â–…â–ˆâ–ˆâ–â–…â–â–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–â–…â–…â–â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83527
wandb: best/eval_avg_mil_loss 0.4176
wandb:  best/eval_ensemble_f1 0.83527
wandb:            eval/avg_f1 0.79925
wandb:      eval/avg_mil_loss 0.40256
wandb:       eval/ensemble_f1 0.79925
wandb:           train/avg_f1 0.78514
wandb:      train/ensemble_f1 0.78514
wandb:         train/mil_loss 1.08143
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run scarlet-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j7gc6tq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044556-4j7gc6tq/logs
wandb: ERROR Run 4j7gc6tq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qmte5e3b with config:
wandb: 	actor_learning_rate: 1.6476149639706414e-05
wandb: 	attention_dropout_p: 0.21571507646635468
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6192132837555727
wandb: 	temperature: 1.8470796462715833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044755-qmte5e3b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmte5e3b
wandb: uploading history steps 123-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–ƒâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–†â–‚â–†â–‡â–â–„â–ƒâ–†â–ƒâ–…â–…â–ˆâ–…â–†â–†â–ƒâ–‡â–…â–‚â–…â–„â–ƒâ–„â–ƒâ–…â–„â–†â–â–…â–„â–…â–ˆâ–…â–†â–‚â–…â–„â–‡â–ƒ
wandb:      eval/avg_mil_loss â–…â–„â–†â–ƒâ–ƒâ–ƒâ–„â–â–…â–‚â–‡â–…â–â–ƒâ–†â–…â–ƒâ–„â–„â–…â–ƒâ–‚â–ƒâ–…â–ƒâ–…â–…â–†â–„â–ƒâ–†â–„â–ƒâ–…â–‚â–‡â–…â–†â–ˆâ–ˆ
wandb:       eval/ensemble_f1 â–†â–…â–…â–‡â–‡â–†â–†â–ƒâ–…â–ƒâ–…â–…â–†â–…â–…â–„â–…â–…â–ƒâ–‡â–…â–ˆâ–…â–‚â–„â–‚â–„â–„â–†â–…â–â–‡â–…â–‡â–†â–†â–…â–…â–ˆâ–…
wandb:           train/avg_f1 â–ˆâ–„â–…â–†â–‚â–ƒâ–„â–†â–†â–…â–„â–‡â–…â–…â–…â–„â–…â–†â–…â–„â–…â–†â–†â–‚â–‚â–ƒâ–…â–ƒâ–…â–…â–…â–‚â–â–…â–ˆâ–…â–†â–…â–‚â–…
wandb:      train/ensemble_f1 â–ˆâ–„â–…â–…â–‡â–…â–†â–†â–†â–…â–†â–ƒâ–„â–…â–„â–†â–„â–„â–„â–ƒâ–†â–†â–‚â–‚â–„â–‚â–„â–ƒâ–ƒâ–†â–â–„â–â–ƒâ–ƒâ–„â–„â–„â–„â–ƒ
wandb:         train/mil_loss â–‡â–†â–‡â–†â–ˆâ–†â–…â–…â–‡â–†â–…â–…â–„â–„â–…â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…â–‚â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–‚â–‚â–‚â–‚â–â–ƒâ–‚
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–…â–†â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86321
wandb: best/eval_avg_mil_loss 0.35817
wandb:  best/eval_ensemble_f1 0.86321
wandb:            eval/avg_f1 0.79195
wandb:      eval/avg_mil_loss 0.44188
wandb:       eval/ensemble_f1 0.79195
wandb:           train/avg_f1 0.8153
wandb:      train/ensemble_f1 0.8153
wandb:         train/mil_loss 1.75461
wandb:      train/policy_loss -0.31494
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.31494
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cosmic-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qmte5e3b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044755-qmte5e3b/logs
wandb: ERROR Run qmte5e3b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l11m0awy with config:
wandb: 	actor_learning_rate: 8.681190089133098e-05
wandb: 	attention_dropout_p: 0.3634625521789081
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7071249455443787
wandb: 	temperature: 5.5675804812394425
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045040-l11m0awy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l11m0awy
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–…â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–ƒâ–†â–‡â–ƒâ–„â–â–…â–‡â–…â–ˆâ–ƒâ–„â–‡â–†â–†â–‡â–†â–„â–…â–„â–ˆâ–ƒâ–†â–†â–‡â–†â–‡â–†â–‡â–…â–…â–…â–…â–„â–†â–†â–„â–‡
wandb:      eval/avg_mil_loss â–…â–…â–…â–‡â–†â–„â–‡â–‡â–ƒâ–ƒâ–†â–…â–…â–‡â–…â–â–†â–ƒâ–„â–„â–…â–†â–„â–…â–…â–†â–…â–„â–‡â–„â–…â–…â–â–†â–†â–„â–‚â–…â–†â–ˆ
wandb:       eval/ensemble_f1 â–„â–…â–†â–†â–…â–ƒâ–ƒâ–†â–â–„â–â–ˆâ–ƒâ–†â–ƒâ–…â–„â–…â–„â–‚â–…â–†â–†â–‚â–ƒâ–…â–â–…â–‚â–‡â–ƒâ–„â–†â–†â–ƒâ–‚â–‚â–…â–ƒâ–…
wandb:           train/avg_f1 â–ƒâ–†â–„â–†â–„â–ˆâ–†â–‡â–„â–…â–…â–…â–…â–ƒâ–‡â–„â–…â–ƒâ–„â–…â–„â–ƒâ–„â–ˆâ–„â–„â–ƒâ–†â–‡â–…â–„â–â–‡â–„â–‡â–ƒâ–…â–…â–‡â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–†â–„â–…â–…â–‡â–†â–„â–…â–ˆâ–…â–…â–ƒâ–„â–†â–‚â–†â–‡â–†â–‡â–†â–„â–„â–„â–„â–†â–…â–…â–†â–…â–…â–â–â–‡â–†â–†â–…â–…â–ƒâ–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–‡â–‚â–ƒâ–…â–„â–„â–„â–„â–„â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–â–â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.3725
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.79473
wandb:      eval/avg_mil_loss 0.43238
wandb:       eval/ensemble_f1 0.79473
wandb:           train/avg_f1 0.80181
wandb:      train/ensemble_f1 0.80181
wandb:         train/mil_loss 1.70462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l11m0awy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045040-l11m0awy/logs
wandb: ERROR Run l11m0awy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: izqf8j60 with config:
wandb: 	actor_learning_rate: 0.0004934072574221506
wandb: 	attention_dropout_p: 0.21619109962884497
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5142093750448099
wandb: 	temperature: 6.292056142840586
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045305-izqf8j60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izqf8j60
wandb: uploading history steps 109-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–„â–†â–ƒâ–„â–…â–†â–ƒâ–…â–…â–‚â–‚â–†â–…â–„â–ˆâ–„â–‚â–ƒâ–‡â–‚â–†â–†â–ƒâ–‡â–‚â–ˆâ–‡â–ˆâ–‡â–…â–ƒâ–â–„â–‡â–†â–‚â–„â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–‚â–ƒâ–…â–„â–…â–‚â–‚â–ˆâ–„â–‚â–…â–ƒâ–…â–ƒâ–‚â–„â–â–ƒâ–„â–‚â–‡â–„â–‚â–‚â–‚â–‚â–…â–„â–…â–ƒâ–„â–ƒâ–„â–…â–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‡â–†â–„â–†â–ƒâ–‡â–†â–ˆâ–ƒâ–â–†â–„â–…â–…â–…â–â–…â–‡â–…â–‚â–†â–â–ƒâ–ƒâ–‡â–‚â–…â–ˆâ–ˆâ–…â–„â–‚â–ƒâ–ƒâ–…â–‡â–ƒâ–ƒâ–ˆâ–„
wandb:           train/avg_f1 â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ˆâ–…â–„â–‡â–„â–ƒâ–…â–‚â–â–‚â–â–…â–ƒâ–â–ƒâ–‚â–‡â–†â–ƒâ–„â–„â–…â–ƒâ–ƒâ–‡â–†â–„â–…â–ƒâ–…â–„â–â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–…â–…â–ƒâ–…â–ƒâ–ƒâ–‡â–†â–…â–„â–…â–ˆâ–†â–…â–„â–…â–„â–…â–†â–ƒâ–…â–†â–…â–‡â–…â–„â–„â–ˆâ–„â–†â–„â–â–†â–ƒâ–†â–†â–ƒâ–†
wandb:         train/mil_loss â–ˆâ–†â–‡â–†â–†â–„â–„â–†â–…â–†â–†â–„â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–â–„â–„â–„â–„â–ˆâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82845
wandb: best/eval_avg_mil_loss 0.41242
wandb:  best/eval_ensemble_f1 0.82845
wandb:            eval/avg_f1 0.79175
wandb:      eval/avg_mil_loss 0.38571
wandb:       eval/ensemble_f1 0.79175
wandb:           train/avg_f1 0.78762
wandb:      train/ensemble_f1 0.78762
wandb:         train/mil_loss 0.98824
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/izqf8j60
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045305-izqf8j60/logs
wandb: ERROR Run izqf8j60 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o183cqnj with config:
wandb: 	actor_learning_rate: 2.1292500715315783e-06
wandb: 	attention_dropout_p: 0.4832919598867592
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 78
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30014449182172764
wandb: 	temperature: 7.854916982974823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045524-o183cqnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o183cqnj
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–†â–…
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–†â–‡â–„â–â–â–ƒâ–ƒâ–…â–…â–„â–„â–‚â–ƒâ–„â–„â–‚â–„â–†â–„â–â–†â–„â–„â–…â–ƒâ–…â–ƒâ–„â–…â–„â–„â–‡â–‚â–…â–ƒâ–‚â–„â–„
wandb:      eval/avg_mil_loss â–…â–‚â–…â–ƒâ–„â–‡â–†â–„â–„â–ƒâ–‚â–ƒâ–ˆâ–†â–„â–…â–„â–ƒâ–†â–…â–†â–†â–â–„â–…â–…â–…â–„â–„â–…â–ƒâ–…â–…â–…â–„â–…â–â–„â–‚â–†
wandb:       eval/ensemble_f1 â–‚â–„â–ˆâ–†â–‡â–„â–„â–…â–†â–†â–„â–ƒâ–„â–…â–ˆâ–ƒâ–…â–…â–„â–†â–ˆâ–‚â–†â–†â–„â–…â–ƒâ–„â–…â–ƒâ–†â–…â–â–„â–ƒâ–…â–ƒâ–‡â–„â–„
wandb:           train/avg_f1 â–…â–„â–…â–…â–…â–†â–…â–„â–â–…â–†â–„â–ƒâ–‡â–ƒâ–„â–‚â–ƒâ–‡â–ƒâ–†â–„â–„â–†â–…â–ˆâ–„â–ƒâ–â–†â–„â–ƒâ–†â–ƒâ–†â–…â–ƒâ–„â–ˆâ–‡
wandb:      train/ensemble_f1 â–…â–…â–†â–…â–†â–„â–â–…â–„â–…â–‡â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–‡â–ƒâ–†â–„â–„â–‚â–‚â–…â–…â–ˆâ–„â–„â–ƒâ–†â–â–†â–„â–…â–†â–ƒâ–…â–„
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–†â–†â–…â–†â–…â–…â–…â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:      train/policy_loss â–†â–ˆâ–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–„â–†â–„â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–ˆâ–†â–†â–†â–…â–†â–†â–†â–ˆâ–†â–‡â–†â–†â–†â–†â–ˆâ–†â–†â–†â–„â–„â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–„â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82828
wandb: best/eval_avg_mil_loss 0.4767
wandb:  best/eval_ensemble_f1 0.82828
wandb:            eval/avg_f1 0.7755
wandb:      eval/avg_mil_loss 0.43789
wandb:       eval/ensemble_f1 0.7755
wandb:           train/avg_f1 0.79618
wandb:      train/ensemble_f1 0.79618
wandb:         train/mil_loss 1.19133
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cosmic-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o183cqnj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045524-o183cqnj/logs
wandb: ERROR Run o183cqnj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: utxe9hvq with config:
wandb: 	actor_learning_rate: 1.3106081114234778e-05
wandb: 	attention_dropout_p: 0.4178199318688035
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3575912903923837
wandb: 	temperature: 0.18237262447617145
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045656-utxe9hvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utxe9hvq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–„â–…â–†â–ƒâ–„â–…â–„â–†â–ˆâ–ƒâ–â–‚â–†â–‚â–†â–â–ƒâ–…â–„â–…â–…â–„â–â–â–ƒâ–†â–‚â–‚â–‚â–†â–ƒâ–ƒâ–…â–…â–…â–„â–…â–†â–„â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–…â–†â–„â–ƒâ–…â–ƒâ–„â–â–ƒâ–„â–â–†â–„â–‡â–ˆâ–„â–„â–ƒâ–…â–…â–„â–„â–…â–…â–†â–…â–ƒâ–„â–‡â–…â–„â–„â–ƒâ–ƒâ–ƒâ–†â–„â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–ˆâ–‡â–„â–…â–ˆâ–‡â–…â–ˆâ–†â–‚â–ˆâ–‚â–ˆâ–â–„â–†â–†â–‡â–†â–…â–â–â–„â–ˆâ–‚â–‚â–ƒâ–‡â–†â–‡â–‡â–„â–„â–‡â–ˆâ–ˆâ–…â–†
wandb:           train/avg_f1 â–ˆâ–„â–ƒâ–‡â–„â–…â–„â–†â–†â–ƒâ–ƒâ–…â–…â–„â–…â–„â–ƒâ–…â–…â–†â–…â–†â–…â–ƒâ–†â–†â–†â–„â–‡â–…â–‚â–†â–‚â–‡â–„â–â–‡â–…â–‡â–†
wandb:      train/ensemble_f1 â–ˆâ–„â–‡â–„â–„â–„â–†â–†â–ƒâ–†â–…â–…â–„â–„â–…â–„â–„â–ƒâ–…â–…â–…â–…â–†â–…â–ƒâ–„â–„â–†â–‡â–…â–‚â–†â–‚â–‡â–„â–â–‡â–…â–ƒâ–†
wandb:         train/mil_loss â–„â–„â–‡â–…â–…â–…â–†â–ˆâ–†â–…â–…â–„â–†â–†â–…â–ƒâ–†â–ˆâ–ƒâ–…â–„â–„â–„â–â–…â–‚â–…â–‚â–ƒâ–‚â–â–‚â–‚â–„â–‚â–ƒâ–‚â–â–‚â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–…â–†â–…â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–â–†â–ƒâ–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–â–†â–ƒâ–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86343
wandb: best/eval_avg_mil_loss 0.34053
wandb:  best/eval_ensemble_f1 0.86343
wandb:            eval/avg_f1 0.82703
wandb:      eval/avg_mil_loss 0.35768
wandb:       eval/ensemble_f1 0.82703
wandb:           train/avg_f1 0.83104
wandb:      train/ensemble_f1 0.83104
wandb:         train/mil_loss 1.79816
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zany-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utxe9hvq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045656-utxe9hvq/logs
wandb: ERROR Run utxe9hvq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tacm7a58 with config:
wandb: 	actor_learning_rate: 2.48268194536367e-05
wandb: 	attention_dropout_p: 0.4721152162619828
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35352565907616285
wandb: 	temperature: 1.2998692428398106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045809-tacm7a58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tacm7a58
wandb: uploading wandb-summary.json
wandb: uploading history steps 122-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ƒâ–…â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–†â–‚â–ˆâ–…â–„â–„â–â–…â–ƒâ–ƒâ–‚â–…â–â–„â–†â–…â–„â–„â–„â–†â–â–„â–ƒâ–†â–‚â–‡â–„â–†â–‚â–‡â–…â–…â–‚â–…â–‡â–…â–…â–„
wandb:      eval/avg_mil_loss â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–ˆâ–…â–ƒâ–†â–…â–†â–ƒâ–ˆâ–„â–†â–â–†â–†â–‚â–‚â–…â–‚â–„â–…â–‡â–ƒâ–‚â–ƒâ–…â–‡â–ƒâ–„â–â–â–ƒâ–ƒâ–„â–…â–„
wandb:       eval/ensemble_f1 â–†â–†â–‡â–‡â–‡â–†â–â–…â–ƒâ–†â–ƒâ–†â–„â–†â–„â–…â–„â–†â–…â–…â–ƒâ–ƒâ–…â–‡â–‡â–…â–‡â–‚â–ˆâ–‚â–ˆâ–…â–‡â–…â–†â–‡â–„â–…â–†â–†
wandb:           train/avg_f1 â–†â–„â–ˆâ–†â–†â–†â–…â–â–‡â–†â–‡â–‡â–†â–„â–†â–…â–†â–…â–ˆâ–…â–…â–…â–†â–„â–†â–…â–ˆâ–†â–…â–‡â–‡â–„â–†â–‡â–†â–…â–†â–†â–‡â–…
wandb:      train/ensemble_f1 â–…â–…â–„â–†â–„â–„â–„â–„â–…â–„â–„â–…â–…â–…â–†â–„â–†â–„â–„â–…â–…â–â–‡â–…â–ƒâ–ƒâ–†â–…â–†â–ƒâ–‡â–†â–ƒâ–†â–ˆâ–ƒâ–‡â–ƒâ–ˆâ–†
wandb:         train/mil_loss â–‡â–…â–ˆâ–…â–…â–‡â–†â–…â–ˆâ–…â–ƒâ–‡â–…â–…â–†â–†â–„â–†â–†â–†â–…â–†â–ˆâ–„â–„â–†â–ˆâ–†â–…â–„â–†â–…â–‚â–ƒâ–…â–„â–„â–â–„â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.38194
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.79473
wandb:      eval/avg_mil_loss 0.4642
wandb:       eval/ensemble_f1 0.79473
wandb:           train/avg_f1 0.78495
wandb:      train/ensemble_f1 0.78495
wandb:         train/mil_loss 1.03639
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dutiful-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tacm7a58
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045809-tacm7a58/logs
wandb: ERROR Run tacm7a58 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9itywaos with config:
wandb: 	actor_learning_rate: 3.3039393093095394e-05
wandb: 	attention_dropout_p: 0.19466859978668
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25613052705876027
wandb: 	temperature: 3.915733822073123
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050038-9itywaos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9itywaos
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–…â–„â–…â–„â–…â–„â–„â–‚â–†â–‡â–„â–ˆâ–‡â–…â–‚â–ƒâ–‚â–„â–†â–ƒâ–†â–ƒâ–‚â–ƒâ–â–„â–„â–„â–„â–„â–‡â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–„
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–â–ƒâ–†â–ƒâ–…â–„â–…â–…â–…â–‡â–„â–ƒâ–…â–†â–…â–†â–…â–ƒâ–ƒâ–†â–†â–ƒâ–‚â–„â–ƒâ–„â–…â–„â–‡â–‡â–„â–ˆâ–†â–‡â–†â–„â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–…â–†â–„â–‡â–…â–„â–ˆâ–â–„â–„â–…â–‚â–â–„â–‡â–„â–‡â–†â–‡â–‚â–ƒâ–ƒâ–†â–„â–†â–ˆâ–…â–‚â–„â–…â–ƒâ–„â–‚â–„â–„â–‚â–‚â–…
wandb:           train/avg_f1 â–†â–†â–‡â–‡â–ˆâ–†â–…â–…â–†â–…â–†â–‡â–†â–†â–†â–†â–„â–„â–†â–„â–†â–…â–…â–…â–ƒâ–…â–ˆâ–„â–‡â–†â–†â–â–‡â–†â–â–‚â–â–ƒâ–„â–ƒ
wandb:      train/ensemble_f1 â–†â–ˆâ–†â–†â–‡â–†â–†â–…â–†â–†â–ˆâ–‡â–†â–†â–†â–†â–‡â–…â–†â–‡â–…â–†â–…â–…â–„â–…â–…â–„â–†â–‡â–†â–…â–„â–„â–…â–‚â–ƒâ–â–ƒâ–…
wandb:         train/mil_loss â–‡â–‡â–ˆâ–‡â–„â–†â–†â–…â–†â–…â–„â–…â–†â–…â–„â–‡â–…â–…â–„â–ƒâ–„â–…â–„â–„â–ƒâ–„â–…â–‚â–ƒâ–‚â–„â–â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–…â–†â–†â–†â–†â–ˆâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84231
wandb: best/eval_avg_mil_loss 0.40582
wandb:  best/eval_ensemble_f1 0.84231
wandb:            eval/avg_f1 0.7874
wandb:      eval/avg_mil_loss 0.5079
wandb:       eval/ensemble_f1 0.7874
wandb:           train/avg_f1 0.77509
wandb:      train/ensemble_f1 0.77509
wandb:         train/mil_loss 1.43305
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hearty-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9itywaos
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050038-9itywaos/logs
wandb: ERROR Run 9itywaos errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: uvyz6hzg with config:
wandb: 	actor_learning_rate: 9.398293186437386e-05
wandb: 	attention_dropout_p: 0.49643982910026246
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6996391789410122
wandb: 	temperature: 0.5599543515548333
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050329-uvyz6hzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvyz6hzg
wandb: uploading history steps 85-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–‚â–…â–‚â–„â–„â–†â–‚â–‚â–ƒâ–…â–…â–‚â–„â–„â–†â–ˆâ–ƒâ–â–…â–…â–…â–†â–‚â–â–‡â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–ˆâ–‚
wandb:      eval/avg_mil_loss â–…â–…â–„â–ƒâ–‚â–‚â–…â–„â–ƒâ–ƒâ–†â–„â–„â–†â–†â–…â–„â–„â–†â–„â–„â–â–…â–„â–ˆâ–…â–†â–ƒâ–‚â–‡â–…â–„â–‡â–†â–‡â–ƒâ–ƒâ–‚â–†â–…
wandb:       eval/ensemble_f1 â–†â–‡â–…â–…â–…â–…â–„â–†â–…â–…â–†â–„â–„â–‡â–‡â–„â–…â–ƒâ–„â–„â–„â–‚â–„â–†â–…â–‚â–‡â–„â–ƒâ–â–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–‚â–…â–†â–…â–„â–ƒâ–‡â–„â–†â–…â–†â–‡â–†â–…â–„â–„â–†â–„â–‚â–…â–‡â–…â–†â–…â–ƒâ–†â–…â–„â–†â–â–†â–†â–…â–ƒâ–…â–ˆâ–…â–ˆ
wandb:      train/ensemble_f1 â–„â–‚â–…â–†â–â–†â–ˆâ–„â–‚â–ƒâ–„â–‚â–†â–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–…â–„â–â–„â–‚â–ƒâ–ƒâ–‚â–„â–‡â–„â–ƒâ–ƒâ–…â–…â–„â–ƒâ–‚â–„â–„
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–…â–†â–…â–…â–„â–…â–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–ˆâ–‡â–â–‡â–‡â–„â–‡â–‡â–‡â–‡â–„â–„â–‡â–‡â–†â–‡â–‡â–‡â–…â–‡â–…â–‡â–‡â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–ˆâ–†â–â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–ƒâ–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.42316
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.75579
wandb:      eval/avg_mil_loss 0.48431
wandb:       eval/ensemble_f1 0.75579
wandb:            test/avg_f1 0.73312
wandb:      test/avg_mil_loss 0.50998
wandb:       test/ensemble_f1 0.73312
wandb:           train/avg_f1 0.79542
wandb:      train/ensemble_f1 0.79542
wandb:         train/mil_loss 0.7541
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uvyz6hzg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050329-uvyz6hzg/logs
wandb: Agent Starting Run: kulijblm with config:
wandb: 	actor_learning_rate: 0.0005078759080245426
wandb: 	attention_dropout_p: 0.2340970435287769
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48601359582334314
wandb: 	temperature: 3.409077305870728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050532-kulijblm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kulijblm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–ˆâ–†â–†â–„â–…â–ƒâ–‚â–ˆâ–‡â–„â–…â–„â–‡â–†â–ˆâ–‡â–‡â–‡â–†â–†â–ƒâ–ˆâ–…â–…â–…â–„â–…â–…â–„â–…â–ƒâ–ƒâ–„â–â–‚â–ƒâ–‚â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–†â–„â–†â–†â–‡â–„â–ƒâ–…â–‚â–â–„â–†â–ƒâ–‚â–„â–‡â–†â–…â–â–‚â–†â–‡â–„â–†â–…â–†â–‡â–…â–„â–ˆâ–‡â–„â–‡â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–…â–„â–„â–ˆâ–„â–…â–‡â–…â–„â–‡â–†â–‡â–†â–‡â–…â–†â–ƒâ–…â–‡â–ƒâ–…â–‡â–‡â–„â–…â–‚â–„â–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–â–‚
wandb:           train/avg_f1 â–‡â–†â–‡â–…â–‡â–ˆâ–†â–ˆâ–†â–†â–†â–…â–‡â–†â–„â–…â–…â–‡â–„â–‚â–„â–„â–„â–…â–…â–…â–ƒâ–‚â–„â–ƒâ–„â–…â–†â–‚â–â–„â–‚â–„â–„â–ƒ
wandb:      train/ensemble_f1 â–†â–…â–‚â–…â–ˆâ–„â–…â–ƒâ–‡â–„â–…â–…â–…â–†â–„â–„â–‚â–„â–ƒâ–‚â–„â–„â–…â–…â–‚â–â–‚â–…â–ƒâ–„â–„â–â–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–„
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ˆâ–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82436
wandb: best/eval_avg_mil_loss 0.41687
wandb:  best/eval_ensemble_f1 0.82436
wandb:            eval/avg_f1 0.7787
wandb:      eval/avg_mil_loss 0.4575
wandb:       eval/ensemble_f1 0.7787
wandb:           train/avg_f1 0.76572
wandb:      train/ensemble_f1 0.76572
wandb:         train/mil_loss 0.77265
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eager-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kulijblm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050532-kulijblm/logs
wandb: ERROR Run kulijblm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: h2i9ax8t with config:
wandb: 	actor_learning_rate: 0.0006237346821547655
wandb: 	attention_dropout_p: 0.3975625285548117
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2666485270964736
wandb: 	temperature: 4.721765400190035
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050806-h2i9ax8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2i9ax8t
wandb: uploading wandb-summary.json
wandb: uploading history steps 123-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‚â–„â–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–„â–‚â–ˆâ–‚â–…â–†â–†â–ƒâ–…â–ƒâ–‡â–ƒâ–„â–…â–ƒâ–„â–„â–…â–…â–ƒâ–…â–„â–†â–†â–…â–„â–…â–‚â–†â–„â–…â–…â–‡â–â–‚â–…â–ˆ
wandb:      eval/avg_mil_loss â–…â–„â–…â–ƒâ–ƒâ–‚â–…â–…â–…â–‚â–†â–„â–‚â–‚â–‚â–ˆâ–â–â–„â–ƒâ–…â–„â–‚â–ƒâ–…â–â–‚â–‚â–ƒâ–…â–‡â–ˆâ–ƒâ–ƒâ–‚â–…â–‚â–‡â–„â–†
wandb:       eval/ensemble_f1 â–„â–‡â–‚â–‡â–ˆâ–†â–‡â–„â–…â–ƒâ–ˆâ–†â–†â–‡â–‚â–…â–„â–„â–…â–†â–…â–†â–†â–ƒâ–…â–…â–†â–„â–„â–‚â–ƒâ–„â–…â–…â–„â–‡â–â–ƒâ–…â–…
wandb:           train/avg_f1 â–†â–†â–†â–…â–ˆâ–„â–†â–†â–„â–…â–…â–„â–„â–…â–†â–…â–„â–…â–‡â–„â–†â–„â–„â–‚â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–„â–‚â–„â–„â–„â–â–„â–
wandb:      train/ensemble_f1 â–†â–„â–…â–†â–†â–ƒâ–…â–ˆâ–‡â–†â–†â–†â–ƒâ–„â–ƒâ–…â–…â–…â–ƒâ–‡â–ƒâ–„â–ƒâ–ƒâ–…â–†â–‚â–‚â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–ƒâ–„â–‚â–â–‚
wandb:         train/mil_loss â–‡â–‡â–†â–‡â–‡â–‡â–†â–…â–ˆâ–†â–†â–…â–ˆâ–…â–…â–†â–†â–…â–†â–…â–…â–…â–†â–ƒâ–„â–„â–„â–„â–„â–…â–„â–…â–ƒâ–„â–„â–„â–‚â–…â–â–
wandb:      train/policy_loss â–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ƒâ–„â–„â–„â–ˆâ–…â–ƒâ–„â–„â–„â–„â–„â–„â–‚â–†â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.40691
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.78444
wandb:      eval/avg_mil_loss 0.50539
wandb:       eval/ensemble_f1 0.78444
wandb:           train/avg_f1 0.78071
wandb:      train/ensemble_f1 0.78071
wandb:         train/mil_loss 1.42122
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2i9ax8t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050806-h2i9ax8t/logs
wandb: ERROR Run h2i9ax8t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: orw5l0i0 with config:
wandb: 	actor_learning_rate: 0.0007000308772189964
wandb: 	attention_dropout_p: 0.1819238706457177
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17492070860524034
wandb: 	temperature: 4.57485109422596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051042-orw5l0i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orw5l0i0
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 133-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–ˆâ–ƒâ–â–…â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–ƒâ–…â–…â–ƒâ–†â–†â–‡â–†â–‚â–ˆâ–†â–…â–†â–†â–‡â–†â–ˆâ–†â–…â–â–„â–‡â–ƒâ–ƒâ–…â–…â–…â–…â–„â–ƒâ–‡â–†â–â–‡â–‚â–„â–‡â–‡
wandb:      eval/avg_mil_loss â–‡â–â–ˆâ–„â–†â–…â–„â–„â–„â–‡â–…â–ƒâ–…â–…â–â–‡â–…â–†â–ˆâ–†â–…â–†â–…â–†â–„â–†â–…â–…â–„â–†â–†â–„â–…â–ˆâ–â–ƒâ–ƒâ–ˆâ–„â–ƒ
wandb:       eval/ensemble_f1 â–‚â–†â–ƒâ–ˆâ–†â–ˆâ–‡â–…â–†â–‡â–…â–‡â–‡â–‡â–†â–‚â–‡â–„â–ƒâ–‡â–…â–ƒâ–â–„â–…â–…â–†â–„â–†â–„â–…â–†â–ƒâ–…â–„â–ƒâ–‡â–„â–‡â–‚
wandb:           train/avg_f1 â–…â–†â–‚â–†â–â–†â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ˆâ–†â–†â–‚â–†â–†â–‡â–â–‡â–„â–‡â–ƒâ–„â–â–‚â–ˆâ–„â–‡â–†â–‚â–‚â–…â–…â–†â–…â–ƒâ–…â–†â–ƒ
wandb:      train/ensemble_f1 â–„â–…â–‚â–†â–…â–„â–…â–„â–„â–ˆâ–†â–†â–ƒâ–†â–‚â–„â–†â–â–†â–ƒâ–‡â–‡â–‡â–‚â–„â–â–„â–„â–†â–…â–ƒâ–…â–„â–„â–„â–‚â–ƒâ–„â–ˆâ–…
wandb:         train/mil_loss â–‡â–‡â–ˆâ–‡â–ˆâ–†â–…â–†â–†â–…â–…â–…â–…â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85352
wandb: best/eval_avg_mil_loss 0.41633
wandb:  best/eval_ensemble_f1 0.85352
wandb:            eval/avg_f1 0.79346
wandb:      eval/avg_mil_loss 0.46806
wandb:       eval/ensemble_f1 0.79346
wandb:           train/avg_f1 0.79981
wandb:      train/ensemble_f1 0.79981
wandb:         train/mil_loss 1.18296
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orw5l0i0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051042-orw5l0i0/logs
wandb: ERROR Run orw5l0i0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: f3d6ugtd with config:
wandb: 	actor_learning_rate: 6.1774795764693725e-06
wandb: 	attention_dropout_p: 0.3095722012357359
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4379535465140952
wandb: 	temperature: 7.813071390806028
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051321-f3d6ugtd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f3d6ugtd
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–†â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–ƒâ–†â–‡â–‡â–„â–„â–„â–„â–‚â–…â–…â–…â–‚â–‚â–…â–ƒâ–„â–ˆâ–ƒâ–„â–„â–„â–„â–ƒâ–„â–…â–‚â–…â–ƒâ–…â–‡â–„â–‚â–„â–„â–â–…â–‚
wandb:      eval/avg_mil_loss â–…â–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–„â–…â–„â–…â–â–…â–„â–„â–„â–ƒâ–ˆâ–†â–‡â–‡â–†â–…â–…â–ƒâ–…â–†â–†â–†â–†â–„â–†â–…
wandb:       eval/ensemble_f1 â–ƒâ–†â–…â–…â–†â–‡â–‚â–„â–ƒâ–‡â–…â–ƒâ–‚â–…â–†â–ƒâ–…â–†â–†â–ˆâ–„â–…â–‚â–„â–„â–„â–…â–‚â–‚â–â–ƒâ–‡â–„â–†â–…â–‚â–‚â–„â–â–ƒ
wandb:           train/avg_f1 â–ˆâ–†â–…â–‡â–†â–‡â–ˆâ–‡â–…â–‡â–†â–†â–‡â–‡â–„â–‡â–†â–†â–…â–†â–†â–†â–„â–…â–‡â–†â–†â–†â–†â–ƒâ–ƒâ–†â–…â–†â–…â–…â–â–…â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–ˆâ–…â–ˆâ–…â–‡â–ˆâ–†â–‡â–‡â–†â–ˆâ–†â–‡â–‡â–…â–‡â–…â–‡â–‡â–…â–ˆâ–†â–†â–…â–†â–„â–†â–†â–ƒâ–‡â–†â–ƒâ–†â–†â–â–…â–ƒâ–†â–…
wandb:         train/mil_loss â–ˆâ–†â–…â–†â–‡â–†â–„â–…â–†â–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–‚
wandb:      train/policy_loss â–…â–…â–…â–â–…â–…â–†â–†â–…â–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83211
wandb: best/eval_avg_mil_loss 0.41276
wandb:  best/eval_ensemble_f1 0.83211
wandb:            eval/avg_f1 0.77723
wandb:      eval/avg_mil_loss 0.49615
wandb:       eval/ensemble_f1 0.77723
wandb:           train/avg_f1 0.77657
wandb:      train/ensemble_f1 0.77657
wandb:         train/mil_loss 0.50375
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run youthful-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f3d6ugtd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051321-f3d6ugtd/logs
wandb: ERROR Run f3d6ugtd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nyzickbc with config:
wandb: 	actor_learning_rate: 2.7942498010978547e-05
wandb: 	attention_dropout_p: 0.4413858557618587
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7333733056742485
wandb: 	temperature: 5.178086249363071
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051703-nyzickbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyzickbc
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–„â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–â–†â–‡â–„â–…â–…â–…â–†â–„â–ƒâ–‡â–ˆâ–‚â–„â–‡â–‡â–‚â–„â–…â–…â–„â–†â–…â–„â–†â–„â–…â–„â–…â–„â–ˆâ–ˆâ–…â–…â–„â–‚â–†â–†â–†
wandb:      eval/avg_mil_loss â–‚â–†â–‚â–‚â–ƒâ–…â–„â–‚â–„â–„â–ƒâ–â–ˆâ–ƒâ–…â–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–‡â–„â–ƒâ–‚â–„â–„â–„â–‚â–‚â–„â–ƒâ–„â–„â–„â–„â–„â–†â–„
wandb:       eval/ensemble_f1 â–‚â–‡â–ˆâ–ˆâ–…â–ˆâ–†â–ƒâ–‡â–‚â–†â–†â–ƒâ–†â–†â–ƒâ–†â–…â–‡â–‡â–†â–„â–…â–…â–…â–ƒâ–„â–…â–…â–†â–†â–…â–„â–†â–†â–†â–†â–„â–ˆâ–
wandb:           train/avg_f1 â–†â–†â–ˆâ–‡â–†â–ˆâ–†â–†â–‡â–…â–‡â–‡â–…â–‡â–†â–†â–†â–„â–‡â–…â–…â–†â–…â–†â–†â–†â–‡â–ˆâ–„â–†â–ƒâ–‡â–‡â–†â–„â–‡â–…â–„â–„â–
wandb:      train/ensemble_f1 â–‡â–†â–ˆâ–†â–†â–‡â–…â–†â–„â–†â–†â–…â–…â–ˆâ–„â–†â–†â–…â–…â–„â–…â–…â–†â–†â–‡â–…â–ˆâ–‡â–†â–ƒâ–†â–„â–„â–„â–‡â–ƒâ–‡â–„â–„â–
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–†â–„â–„â–†â–„â–…â–…â–„â–„â–„â–„â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–ƒâ–â–‚â–â–â–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85698
wandb: best/eval_avg_mil_loss 0.37283
wandb:  best/eval_ensemble_f1 0.85698
wandb:            eval/avg_f1 0.78101
wandb:      eval/avg_mil_loss 0.47833
wandb:       eval/ensemble_f1 0.78101
wandb:           train/avg_f1 0.78806
wandb:      train/ensemble_f1 0.78806
wandb:         train/mil_loss 1.36223
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyzickbc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051703-nyzickbc/logs
wandb: ERROR Run nyzickbc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pk5ki4t8 with config:
wandb: 	actor_learning_rate: 1.7809623315757438e-06
wandb: 	attention_dropout_p: 0.44765328790514697
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2882993297541584
wandb: 	temperature: 0.782108023642224
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051954-pk5ki4t8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pk5ki4t8
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–ƒâ–ƒâ–‡â–„â–â–†â–†â–â–‚â–ƒâ–†â–…â–ƒâ–„â–†â–…â–ƒâ–…â–…â–ƒâ–„â–…â–„â–„â–„â–„â–„â–†â–†â–†â–‡â–†â–ƒâ–ˆâ–…â–…â–ƒâ–…
wandb:      eval/avg_mil_loss â–…â–…â–ˆâ–„â–†â–‡â–†â–‚â–…â–â–‚â–ˆâ–‚â–„â–…â–ƒâ–‚â–†â–†â–…â–…â–ƒâ–†â–‡â–…â–ƒâ–…â–ƒâ–‚â–â–…â–‚â–‚â–ƒâ–…â–‡â–†â–‚â–‡â–ƒ
wandb:       eval/ensemble_f1 â–‡â–ƒâ–„â–…â–â–‡â–†â–‚â–ƒâ–„â–ƒâ–…â–ˆâ–…â–…â–†â–ƒâ–…â–„â–†â–‚â–†â–â–ƒâ–„â–„â–‡â–‡â–†â–†â–ˆâ–ˆâ–„â–†â–„â–ˆâ–„â–…â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–†â–„â–†â–‚â–â–…â–„â–„â–…â–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–‚â–„â–…â–ˆâ–„â–â–„â–†â–†â–„â–„â–…â–„â–†â–„â–„â–…â–…â–â–…â–„
wandb:      train/ensemble_f1 â–…â–…â–„â–„â–…â–…â–…â–‚â–ƒâ–ƒâ–„â–„â–ˆâ–‚â–†â–ˆâ–…â–ƒâ–‚â–‚â–…â–…â–„â–†â–„â–„â–„â–„â–ƒâ–‚â–„â–‚â–â–ƒâ–…â–…â–„â–…â–…â–†
wandb:         train/mil_loss â–‡â–‡â–ˆâ–†â–‡â–†â–†â–ƒâ–ˆâ–†â–‡â–†â–…â–„â–†â–†â–…â–†â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–„â–„â–„â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.43733
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.76938
wandb:      eval/avg_mil_loss 0.46507
wandb:       eval/ensemble_f1 0.76938
wandb:            test/avg_f1 0.75536
wandb:      test/avg_mil_loss 0.51682
wandb:       test/ensemble_f1 0.75536
wandb:           train/avg_f1 0.7964
wandb:      train/ensemble_f1 0.7964
wandb:         train/mil_loss 0.89176
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pk5ki4t8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051954-pk5ki4t8/logs
wandb: Agent Starting Run: r4cjgtj0 with config:
wandb: 	actor_learning_rate: 0.0002688124919462178
wandb: 	attention_dropout_p: 0.49976410979864944
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7791799696311482
wandb: 	temperature: 5.687364908819892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052220-r4cjgtj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4cjgtj0
wandb: uploading history steps 96-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‡â–‡â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–†â–„â–†â–„â–„â–„â–ƒâ–†â–ƒâ–†â–…â–„â–„â–†â–†â–…â–…â–„â–„â–ƒâ–â–„â–…â–‚â–†â–‡â–ƒâ–†â–†â–„â–ˆâ–„â–‡â–ƒâ–ˆâ–…â–‡â–„
wandb:      eval/avg_mil_loss â–„â–„â–…â–„â–â–‡â–„â–‚â–„â–„â–‚â–„â–‚â–…â–„â–‚â–‡â–ƒâ–ƒâ–‚â–†â–†â–ƒâ–…â–†â–„â–„â–…â–‚â–ˆâ–â–…â–‚â–„â–‚â–ƒâ–†â–…â–â–„
wandb:       eval/ensemble_f1 â–†â–„â–…â–„â–ƒâ–‚â–†â–‚â–†â–…â–‡â–…â–ˆâ–„â–ƒâ–…â–â–†â–…â–…â–„â–„â–‚â–†â–„â–ˆâ–…â–…â–…â–…â–†â–ƒâ–†â–â–†â–…â–ˆâ–‡â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–†â–â–„â–ƒâ–…â–‚â–ƒâ–‚â–â–„â–„â–†â–ƒâ–…â–…â–†â–â–ƒâ–„â–‚â–„â–ƒâ–â–‡â–ƒâ–‚â–ƒâ–†â–„â–‚â–„â–ˆâ–…â–‡â–†â–…â–„â–‚â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–‡â–…â–„â–…â–ƒâ–…â–…â–ƒâ–„â–„â–‡â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–‚â–„â–â–ƒâ–†â–„â–„â–…â–†â–„â–…â–„â–…â–‡â–…â–„â–‡â–…â–ˆâ–…
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–†â–…â–†â–†â–†â–‡â–…â–…â–„â–†â–„â–†â–„â–„â–„â–„â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚
wandb:      train/policy_loss â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81367
wandb: best/eval_avg_mil_loss 0.4433
wandb:  best/eval_ensemble_f1 0.81367
wandb:            eval/avg_f1 0.79509
wandb:      eval/avg_mil_loss 0.50642
wandb:       eval/ensemble_f1 0.79509
wandb:            test/avg_f1 0.77098
wandb:      test/avg_mil_loss 0.51922
wandb:       test/ensemble_f1 0.77098
wandb:           train/avg_f1 0.78497
wandb:      train/ensemble_f1 0.78497
wandb:         train/mil_loss 0.98319
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lemon-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r4cjgtj0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052220-r4cjgtj0/logs
wandb: Agent Starting Run: 9ywu2odz with config:
wandb: 	actor_learning_rate: 0.00020707143941932015
wandb: 	attention_dropout_p: 0.17932348702375128
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5752084088589063
wandb: 	temperature: 2.637764890679024
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052429-9ywu2odz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ywu2odz
wandb: uploading history steps 96-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–„â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–‡â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–„â–…â–…â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–‡â–ƒâ–„â–‡â–ˆâ–…â–ƒâ–„â–â–‡â–ƒâ–ƒâ–‡â–…â–†â–†â–…â–‚â–‡â–…â–‡â–„â–†â–…â–‡â–„â–†â–†â–†â–ˆâ–‡â–„â–†â–„â–ˆâ–ƒâ–‡â–†
wandb:      eval/avg_mil_loss â–†â–„â–†â–„â–†â–…â–†â–†â–†â–†â–†â–ˆâ–…â–†â–…â–†â–ˆâ–„â–…â–…â–ƒâ–„â–ƒâ–‡â–…â–„â–…â–…â–†â–ƒâ–„â–…â–†â–…â–â–…â–…â–„â–†â–…
wandb:       eval/ensemble_f1 â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–„â–„â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–„â–„â–…â–ƒâ–„â–„â–ƒâ–„â–„â–…â–…â–‚â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb:           train/avg_f1 â–ƒâ–‡â–ƒâ–â–ƒâ–…â–ƒâ–…â–‚â–†â–„â–„â–„â–‚â–†â–†â–‚â–†â–†â–„â–†â–ˆâ–…â–‚â–†â–‚â–†â–„â–‚â–†â–…â–…â–†â–ˆâ–„â–„â–‡â–…â–…â–‡
wandb:      train/ensemble_f1 â–ƒâ–â–…â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–„â–†â–„â–†â–‚â–„â–†â–ˆâ–†â–…â–„â–†â–†â–†â–…â–„â–„â–†â–…â–„â–†â–ƒâ–„â–†â–†â–„â–„â–„â–…â–†
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–†â–ˆâ–†â–‡â–†â–„â–‡â–…â–ƒâ–…â–…â–„â–‡â–„â–†â–…â–ƒâ–…â–„â–‚â–…â–„â–„â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–ƒ
wandb:      train/policy_loss â–„â–â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–â–„â–â–â–„â–„â–„â–„â–ˆâ–ˆâ–„â–ˆâ–„â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85766
wandb: best/eval_avg_mil_loss 0.40689
wandb:  best/eval_ensemble_f1 0.85766
wandb:            eval/avg_f1 0.77007
wandb:      eval/avg_mil_loss 0.47187
wandb:       eval/ensemble_f1 0.77007
wandb:           train/avg_f1 0.77109
wandb:      train/ensemble_f1 0.77109
wandb:         train/mil_loss 0.95331
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misty-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ywu2odz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052429-9ywu2odz/logs
wandb: ERROR Run 9ywu2odz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o98b6gzr with config:
wandb: 	actor_learning_rate: 0.00013537667231194907
wandb: 	attention_dropout_p: 0.2513906745252931
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1186785001315559
wandb: 	temperature: 5.343178379552761
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052643-o98b6gzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o98b6gzr
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–…â–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–„â–‡â–‚â–ƒâ–‚â–…â–‚â–†â–â–…â–„â–â–â–†â–„â–‡â–ƒâ–†â–…â–‚â–†â–‚â–„â–ƒâ–â–‡â–…â–„â–„â–†â–â–ˆâ–‚â–ƒâ–â–ƒâ–…
wandb:      eval/avg_mil_loss â–‡â–„â–…â–„â–…â–ƒâ–…â–„â–„â–„â–„â–„â–…â–ƒâ–…â–†â–…â–„â–‚â–ƒâ–ˆâ–…â–ˆâ–‚â–‚â–…â–„â–…â–…â–…â–â–…â–‚â–ƒâ–‡â–†â–ƒâ–ƒâ–…â–‡
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–ˆâ–†â–…â–…â–„â–â–„â–„â–â–†â–„â–ƒâ–…â–†â–†â–ƒâ–ƒâ–„â–…â–‚â–„â–†â–â–„â–…â–„â–â–ƒâ–…
wandb:           train/avg_f1 â–ƒâ–ƒâ–„â–‚â–â–„â–‚â–ƒâ–…â–†â–ƒâ–‚â–ˆâ–…â–„â–ƒâ–‚â–„â–ƒâ–‡â–„â–„â–ƒâ–„â–†â–†â–ˆâ–…â–…â–‚â–‡â–†â–ƒâ–‡â–„â–ƒâ–„â–„â–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–†â–„â–…â–†â–…â–†â–‡â–ƒâ–†â–†â–„â–â–†â–‡â–†â–ƒâ–…â–ˆâ–„â–„â–„â–†â–„â–…â–‡â–†â–ƒâ–ƒâ–†â–…â–†â–„â–„â–…â–†â–„â–‡â–„â–„
wandb:         train/mil_loss â–ˆâ–…â–†â–†â–‡â–…â–ˆâ–‡â–‡â–…â–†â–†â–†â–„â–…â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–…â–‚â–‚â–…â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–†â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–„â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.44533
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.76078
wandb:      eval/avg_mil_loss 0.44797
wandb:       eval/ensemble_f1 0.76078
wandb:           train/avg_f1 0.78197
wandb:      train/ensemble_f1 0.78197
wandb:         train/mil_loss 0.60194
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o98b6gzr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052643-o98b6gzr/logs
wandb: ERROR Run o98b6gzr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t8zjkpnk with config:
wandb: 	actor_learning_rate: 2.093643742207313e-06
wandb: 	attention_dropout_p: 0.01373066076535484
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14742653376571624
wandb: 	temperature: 9.309375696593769
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052908-t8zjkpnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t8zjkpnk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–„â–…â–‡â–…â–ˆâ–†â–…â–†â–„â–†â–â–†â–…â–„â–„â–ˆâ–„â–…â–‡â–‡â–†â–†â–‡â–†â–†â–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–â–‡â–…â–„â–‚â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–†â–…â–„â–„â–â–…â–ƒâ–†â–…â–â–ˆâ–„â–‚â–…â–ƒâ–‚â–…â–…â–„â–…â–‚â–ƒâ–„â–‚â–‚â–ƒâ–†â–‡â–‡â–…â–†â–†â–„â–„â–†â–†â–„â–ˆ
wandb:       eval/ensemble_f1 â–†â–„â–„â–…â–†â–†â–â–‡â–…â–ˆâ–†â–„â–…â–‡â–ƒâ–‡â–…â–…â–…â–„â–ˆâ–‡â–‡â–‡â–…â–†â–†â–…â–ƒâ–„â–…â–„â–„â–ƒâ–†â–†â–ˆâ–…â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–â–„â–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–…â–ƒâ–ƒâ–â–â–‚â–ƒâ–ƒâ–â–†â–…â–ƒâ–â–ƒâ–…â–„â–„â–ƒâ–ƒâ–â–ƒâ–‚â–…â–…â–…â–ˆâ–„â–„â–„â–‚
wandb:      train/ensemble_f1 â–†â–‚â–â–„â–‚â–„â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–â–â–„â–ƒâ–ƒâ–â–†â–…â–‚â–â–ƒâ–…â–‚â–…â–„â–ƒâ–ƒâ–â–ƒâ–‚â–…â–…â–…â–ˆâ–„â–„â–„â–‚
wandb:         train/mil_loss â–…â–†â–†â–‡â–‡â–…â–†â–ˆâ–†â–†â–ˆâ–†â–†â–…â–…â–…â–…â–…â–„â–„â–ƒâ–…â–„â–ƒâ–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–â–ƒâ–‚â–‚â–ƒâ–‚â–
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.40934
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.78465
wandb:      eval/avg_mil_loss 0.51206
wandb:       eval/ensemble_f1 0.78465
wandb:            test/avg_f1 0.77799
wandb:      test/avg_mil_loss 0.52653
wandb:       test/ensemble_f1 0.77799
wandb:           train/avg_f1 0.79817
wandb:      train/ensemble_f1 0.79817
wandb:         train/mil_loss 1.03207
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dulcet-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t8zjkpnk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052908-t8zjkpnk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ye9wanfc with config:
wandb: 	actor_learning_rate: 8.860329956290614e-05
wandb: 	attention_dropout_p: 0.39019523133564377
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013188924422265824
wandb: 	temperature: 5.490280064581315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053020-ye9wanfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9wanfc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–ˆâ–â–‚â–‡â–†â–…â–…â–ƒâ–‡â–†â–‡â–…â–ƒâ–…â–…â–ˆâ–ƒâ–†â–…â–ƒâ–†â–…â–†â–‡â–‚â–„â–‚â–„â–ƒâ–†â–†â–†â–‚â–†â–ƒâ–…â–„â–„â–ˆâ–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–„â–ƒâ–ƒâ–…â–…â–‚â–…â–‡â–„â–ƒâ–…â–â–ƒâ–„â–‡â–„â–†â–…â–„â–‡â–ƒâ–ƒâ–„â–‡â–„â–…â–…â–„â–ˆ
wandb:       eval/ensemble_f1 â–„â–†â–†â–„â–…â–ƒâ–„â–…â–ƒâ–â–ƒâ–…â–‡â–…â–ƒâ–†â–ƒâ–…â–…â–ˆâ–†â–†â–ƒâ–ƒâ–„â–„â–‚â–†â–ƒâ–…â–„â–†â–†â–…â–†â–ƒâ–ƒâ–†â–„â–‡
wandb:           train/avg_f1 â–‡â–…â–„â–†â–†â–†â–†â–„â–…â–†â–‡â–ˆâ–…â–†â–‡â–†â–‡â–„â–„â–„â–ˆâ–…â–„â–…â–†â–…â–ƒâ–†â–„â–„â–‡â–†â–…â–„â–…â–â–„â–„â–…â–„
wandb:      train/ensemble_f1 â–„â–…â–†â–†â–ˆâ–†â–ƒâ–„â–†â–‡â–…â–…â–„â–†â–…â–‡â–„â–„â–†â–‡â–…â–„â–„â–ƒâ–…â–…â–†â–†â–„â–†â–ƒâ–†â–ƒâ–†â–…â–…â–†â–„â–â–ƒ
wandb:         train/mil_loss â–†â–…â–‡â–„â–†â–ˆâ–ˆâ–…â–‡â–†â–…â–…â–…â–…â–…â–‡â–…â–†â–„â–†â–ƒâ–…â–†â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ˆâ–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–‡â–…â–ˆâ–…â–†â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85352
wandb: best/eval_avg_mil_loss 0.34642
wandb:  best/eval_ensemble_f1 0.85352
wandb:            eval/avg_f1 0.81013
wandb:      eval/avg_mil_loss 0.56844
wandb:       eval/ensemble_f1 0.81013
wandb:           train/avg_f1 0.7942
wandb:      train/ensemble_f1 0.7942
wandb:         train/mil_loss 1.98155
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run effortless-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9wanfc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053020-ye9wanfc/logs
wandb: ERROR Run ye9wanfc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ilvyukfc with config:
wandb: 	actor_learning_rate: 4.918735111935741e-06
wandb: 	attention_dropout_p: 0.4454214110451173
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13247577771073127
wandb: 	temperature: 1.3391650885673911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053219-ilvyukfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilvyukfc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–…â–†â–‡â–…â–†â–ˆâ–‡â–„â–†â–†â–…â–‡â–â–‡â–†â–†â–…â–ƒâ–†â–ƒâ–‡â–ƒâ–„â–‡â–†â–†â–„â–†â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–†â–ƒâ–â–ƒâ–ƒâ–†â–†â–†â–…â–‚â–…â–ƒâ–…â–†â–…â–‡â–‡â–‡â–‡â–„â–ƒâ–„â–„â–ƒâ–ˆâ–„â–‡â–„â–‡â–†â–„â–â–…â–ƒâ–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–ƒâ–…â–‡â–†â–‡â–„â–…â–‡â–ˆâ–‡â–†â–„â–„â–„â–‡â–ˆâ–ˆâ–â–‡â–ƒâ–„â–ƒâ–†â–ƒâ–‡â–†â–†â–†â–„â–†â–…â–‡â–‚â–ƒâ–‚â–‡â–…â–„
wandb:           train/avg_f1 â–ƒâ–„â–…â–‡â–…â–…â–ƒâ–„â–ƒâ–ƒâ–„â–…â–ƒâ–„â–‡â–‚â–ˆâ–„â–„â–„â–„â–†â–â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ˆâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–…â–„
wandb:      train/ensemble_f1 â–„â–†â–…â–…â–„â–‡â–…â–…â–…â–„â–„â–…â–‡â–…â–ˆâ–…â–ƒâ–„â–…â–†â–„â–†â–„â–„â–‚â–‡â–…â–„â–ˆâ–…â–ƒâ–ƒâ–„â–…â–â–†â–ƒâ–…â–…â–…
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–…â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/policy_loss â–†â–ˆâ–…â–â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–‚â–†â–…â–‚â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ƒâ–„â–„â–ƒâ–ˆâ–‚â–â–„â–„â–„â–„â–…â–…â–„â–â–„â–„â–„â–„â–„â–…â–„â–„â–…â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82478
wandb: best/eval_avg_mil_loss 0.42592
wandb:  best/eval_ensemble_f1 0.82478
wandb:            eval/avg_f1 0.77225
wandb:      eval/avg_mil_loss 0.50084
wandb:       eval/ensemble_f1 0.77225
wandb:           train/avg_f1 0.78307
wandb:      train/ensemble_f1 0.78307
wandb:         train/mil_loss 0.71813
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run divine-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ilvyukfc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053219-ilvyukfc/logs
wandb: ERROR Run ilvyukfc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lhssf6mh with config:
wandb: 	actor_learning_rate: 1.8783403237622008e-06
wandb: 	attention_dropout_p: 0.43262692073957687
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 112
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22894306728486524
wandb: 	temperature: 0.23620702130776497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053454-lhssf6mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhssf6mh
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–†â–…â–‡â–…â–†â–†â–†â–†â–†â–ƒâ–…â–„â–…â–…â–†â–„â–‡â–„â–„â–…â–„â–†â–…â–‡â–„â–…â–…â–„â–‚â–ƒâ–ƒâ–†â–ˆâ–…â–„â–„â–†â–â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–„â–„â–…â–…â–‡â–„â–…â–„â–‡â–ˆâ–ƒâ–†â–…â–…â–ˆâ–‡â–„â–‚â–„â–…â–„â–‚â–‡â–…â–…â–‡â–…â–†â–„â–â–‚â–‡â–„â–ƒâ–…â–†â–ˆâ–
wandb:       eval/ensemble_f1 â–…â–†â–ˆâ–…â–…â–†â–‡â–†â–‡â–…â–‡â–†â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–„â–‡â–…â–ƒâ–†â–‡â–‚â–…â–„â–‡â–†â–…â–„â–…â–…â–„â–â–„
wandb:           train/avg_f1 â–„â–…â–†â–â–„â–â–„â–„â–†â–…â–„â–ƒâ–…â–ˆâ–‚â–…â–„â–„â–„â–‡â–„â–†â–ƒâ–…â–„â–†â–†â–…â–†â–„â–„â–ƒâ–†â–…â–ƒâ–†â–ƒâ–†â–„â–…
wandb:      train/ensemble_f1 â–…â–…â–‡â–†â–„â–…â–ˆâ–…â–„â–â–‡â–„â–†â–…â–‚â–…â–„â–ˆâ–…â–†â–…â–…â–ˆâ–„â–ˆâ–…â–„â–‡â–†â–…â–ƒâ–‡â–‡â–„â–…â–‡â–†â–„â–…â–†
wandb:         train/mil_loss â–…â–‡â–„â–†â–„â–„â–„â–‡â–ˆâ–„â–ƒâ–…â–„â–‡â–†â–…â–„â–ƒâ–‡â–ƒâ–„â–…â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–‚â–‚â–ƒâ–†â–â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–‡â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83575
wandb: best/eval_avg_mil_loss 0.43806
wandb:  best/eval_ensemble_f1 0.83575
wandb:            eval/avg_f1 0.76622
wandb:      eval/avg_mil_loss 0.47578
wandb:       eval/ensemble_f1 0.76622
wandb:           train/avg_f1 0.78721
wandb:      train/ensemble_f1 0.78721
wandb:         train/mil_loss 0.93397
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lhssf6mh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053454-lhssf6mh/logs
wandb: ERROR Run lhssf6mh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8kku2tc7 with config:
wandb: 	actor_learning_rate: 0.00011389074779364372
wandb: 	attention_dropout_p: 0.49704549017741384
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8186016267485553
wandb: 	temperature: 6.569020466991271
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053658-8kku2tc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kku2tc7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–…â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–…â–†â–†â–‡â–ˆâ–†â–‡â–†â–„â–…â–…â–…â–†â–‡â–…â–†â–„â–†â–…â–„â–„â–…â–‚â–„â–‚â–„â–ƒâ–†â–‚â–†â–ƒâ–â–ƒâ–„â–„â–„â–„
wandb:      eval/avg_mil_loss â–â–…â–ƒâ–„â–„â–â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–‡â–ƒâ–ƒâ–…â–„â–‡â–…â–‡â–ƒâ–†â–ˆâ–…â–ƒâ–†â–…â–†â–‡â–…â–†â–ˆ
wandb:       eval/ensemble_f1 â–…â–†â–†â–…â–†â–…â–…â–ˆâ–†â–„â–…â–…â–„â–…â–„â–…â–…â–†â–‚â–†â–…â–…â–„â–„â–…â–„â–ƒâ–„â–…â–‚â–â–„â–ƒâ–…â–„â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‡â–‡â–‡â–…â–†â–ˆâ–‡â–ˆâ–†â–…â–ˆâ–†â–†â–†â–†â–ˆâ–‡â–‡â–…â–†â–„â–…â–ƒâ–„â–…â–…â–…â–…â–†â–„â–‚â–„â–„â–‚â–â–‚â–ƒâ–‚â–‚
wandb:      train/ensemble_f1 â–‡â–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–†â–†â–†â–ˆâ–ˆâ–†â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–…â–…â–†â–…â–†â–†â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–
wandb:         train/mil_loss â–‡â–‡â–ˆâ–‡â–ˆâ–†â–†â–…â–†â–†â–…â–…â–†â–…â–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:      train/policy_loss â–†â–†â–†â–…â–ˆâ–†â–†â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–…â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–‡â–†â–…â–†â–†â–‡â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–‡â–†â–†â–†â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83559
wandb: best/eval_avg_mil_loss 0.41982
wandb:  best/eval_ensemble_f1 0.83559
wandb:            eval/avg_f1 0.76562
wandb:      eval/avg_mil_loss 0.50416
wandb:       eval/ensemble_f1 0.76562
wandb:            test/avg_f1 0.78363
wandb:      test/avg_mil_loss 0.45856
wandb:       test/ensemble_f1 0.78363
wandb:           train/avg_f1 0.75705
wandb:      train/ensemble_f1 0.75705
wandb:         train/mil_loss 0.69258
wandb:      train/policy_loss -0.92756
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.92756
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run super-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kku2tc7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053658-8kku2tc7/logs
wandb: Agent Starting Run: 2zklgfjq with config:
wandb: 	actor_learning_rate: 1.2619427258659485e-06
wandb: 	attention_dropout_p: 0.47523634401308473
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40686540113599423
wandb: 	temperature: 1.7196557976425908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053913-2zklgfjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zklgfjq
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–†â–†â–…â–†â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–†â–‚â–ƒâ–ˆâ–†â–…â–…â–„â–‡â–…â–‚â–†â–ƒâ–…â–…â–‡â–…â–†â–…â–ƒâ–…â–ƒâ–†â–‚â–â–…â–†â–…â–ƒâ–…â–…â–„â–‚â–‚â–…â–‚â–…â–„
wandb:      eval/avg_mil_loss â–…â–„â–„â–‡â–„â–ƒâ–„â–‚â–…â–„â–â–‡â–…â–„â–†â–…â–…â–â–ƒâ–ƒâ–‚â–†â–†â–ˆâ–„â–…â–ˆâ–…â–‚â–ƒâ–…â–„â–‡â–†â–‚â–„â–ˆâ–‚â–‡â–†
wandb:       eval/ensemble_f1 â–„â–†â–†â–ƒâ–†â–‡â–ƒâ–„â–„â–ƒâ–…â–‚â–…â–ƒâ–ƒâ–†â–…â–…â–ƒâ–…â–‚â–…â–ƒâ–‚â–„â–â–†â–„â–„â–…â–„â–„â–†â–…â–‚â–…â–ˆâ–…â–„â–ƒ
wandb:           train/avg_f1 â–†â–‚â–„â–…â–†â–‚â–…â–ˆâ–…â–†â–â–ƒâ–…â–…â–ƒâ–†â–…â–…â–„â–‚â–…â–†â–†â–‡â–†â–ƒâ–„â–…â–ƒâ–„â–‡â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–…â–„â–â–„â–†â–„â–†â–‚â–…â–…â–…â–„â–…â–ƒâ–ˆâ–†â–…â–…â–„â–ƒâ–…â–â–ƒâ–„â–„â–„â–ˆâ–ƒâ–ƒâ–…â–„â–â–…â–‚â–„â–„â–…â–†â–†â–‚
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–†â–†â–…â–†â–„â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–â–ƒâ–â–‚â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–†â–ˆâ–†â–†â–„â–†â–†â–†â–†â–†â–†â–ˆâ–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–ˆâ–…â–…â–ƒâ–…â–ƒâ–…â–…â–…â–â–…â–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86456
wandb: best/eval_avg_mil_loss 0.39218
wandb:  best/eval_ensemble_f1 0.86456
wandb:            eval/avg_f1 0.78098
wandb:      eval/avg_mil_loss 0.46386
wandb:       eval/ensemble_f1 0.78098
wandb:           train/avg_f1 0.80394
wandb:      train/ensemble_f1 0.80394
wandb:         train/mil_loss 0.55957
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zklgfjq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053913-2zklgfjq/logs
wandb: ERROR Run 2zklgfjq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jkl51t4g with config:
wandb: 	actor_learning_rate: 1.437327551832472e-06
wandb: 	attention_dropout_p: 0.4896675211942627
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3829685265067505
wandb: 	temperature: 0.7240195179648623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054117-jkl51t4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkl51t4g
wandb: uploading history steps 120-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–†â–ƒâ–ƒâ–ƒâ–‚â–…â–ˆâ–„â–â–ƒâ–…â–†â–ƒâ–‡â–„â–‚â–‚â–„â–‚â–ƒâ–…â–ƒâ–„â–‡â–„â–‡â–„â–â–„â–…â–„â–…â–„â–…â–„â–†â–…
wandb:      eval/avg_mil_loss â–…â–†â–†â–ƒâ–‡â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–â–‚â–…â–ƒâ–‚â–…â–â–†â–ƒâ–„â–„â–â–„â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–â–…â–†â–„â–…â–‡â–…â–ƒâ–ˆâ–‚â–…â–…â–†â–„â–‡â–ƒâ–…â–…â–ƒâ–…â–„â–…â–„â–„â–„â–„â–‡â–…â–‡â–†â–‚â–„â–…â–ƒâ–„â–…â–…â–„â–ƒâ–ƒ
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–ˆâ–…â–†â–„â–…â–‚â–„â–„â–„â–ˆâ–…â–„â–†â–ˆâ–…â–†â–‚â–„â–‡â–…â–…â–ƒâ–…â–ƒâ–…â–„â–„â–…â–„â–†â–â–…â–‚â–„â–„â–…â–…
wandb:      train/ensemble_f1 â–ƒâ–‡â–†â–„â–…â–„â–„â–ˆâ–„â–…â–ˆâ–„â–…â–„â–†â–†â–…â–…â–ƒâ–…â–…â–ƒâ–†â–…â–…â–…â–…â–„â–„â–„â–…â–„â–†â–ƒâ–â–„â–‚â–„â–„â–…
wandb:         train/mil_loss â–ƒâ–„â–‚â–†â–…â–…â–„â–ƒâ–„â–ƒâ–„â–…â–„â–…â–„â–‡â–‡â–…â–„â–…â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–â–‚â–‚â–â–ƒâ–„â–„â–ƒâ–â–ƒâ–ƒâ–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82828
wandb: best/eval_avg_mil_loss 0.45501
wandb:  best/eval_ensemble_f1 0.82828
wandb:            eval/avg_f1 0.76982
wandb:      eval/avg_mil_loss 0.47829
wandb:       eval/ensemble_f1 0.76982
wandb:           train/avg_f1 0.79156
wandb:      train/ensemble_f1 0.79156
wandb:         train/mil_loss 0.8459
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run confused-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkl51t4g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054117-jkl51t4g/logs
wandb: ERROR Run jkl51t4g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ju3ygnlg with config:
wandb: 	actor_learning_rate: 1.4232219628659748e-05
wandb: 	attention_dropout_p: 0.4398799504994816
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3788791753487471
wandb: 	temperature: 7.639743257853924
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054414-ju3ygnlg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ju3ygnlg
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–ƒâ–„â–â–…â–‡
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–…â–ˆ
wandb:            eval/avg_f1 â–…â–†â–†â–ˆâ–‡â–†â–†â–‡â–„â–ˆâ–…â–ƒâ–‡â–„â–†â–†â–…â–†â–„â–ƒâ–‡â–„â–†â–…â–…â–‡â–…â–ƒâ–„â–‡â–…â–†â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–„â–
wandb:      eval/avg_mil_loss â–„â–‚â–ƒâ–„â–ƒâ–‡â–‡â–‚â–ƒâ–ƒâ–â–ˆâ–…â–„â–…â–‚â–‚â–†â–‚â–‚â–ƒâ–â–â–â–„â–„â–‚â–†â–„â–„â–†â–„â–†â–„â–ƒâ–†â–…â–ƒâ–‡â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–„â–„â–…â–‚â–…â–„â–…â–ƒâ–…â–„â–…â–ˆâ–„â–†â–…â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–…â–…â–‚â–‚â–„â–†â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–„
wandb:           train/avg_f1 â–…â–‡â–†â–‡â–…â–†â–†â–†â–…â–…â–†â–…â–ˆâ–…â–†â–ƒâ–„â–…â–„â–…â–„â–†â–†â–„â–„â–‚â–ƒâ–…â–„â–„â–„â–„â–„â–„â–‚â–„â–…â–„â–‚â–
wandb:      train/ensemble_f1 â–ˆâ–‡â–†â–†â–„â–‡â–‡â–…â–„â–…â–…â–…â–ˆâ–…â–…â–†â–ƒâ–†â–†â–‡â–…â–…â–„â–…â–…â–‡â–…â–ƒâ–„â–„â–‚â–„â–„â–â–‚â–ƒâ–„â–‚â–‚â–„
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–ˆâ–‡â–…â–†â–…â–†â–†â–†â–†â–…â–„â–†â–„â–…â–…â–„â–…â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–‡â–†â–†â–†â–‡â–†â–†â–ˆâ–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86071
wandb: best/eval_avg_mil_loss 0.43396
wandb:  best/eval_ensemble_f1 0.86071
wandb:            eval/avg_f1 0.7773
wandb:      eval/avg_mil_loss 0.59163
wandb:       eval/ensemble_f1 0.7773
wandb:           train/avg_f1 0.77495
wandb:      train/ensemble_f1 0.77495
wandb:         train/mil_loss 1.5913
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run autumn-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ju3ygnlg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054414-ju3ygnlg/logs
wandb: ERROR Run ju3ygnlg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qu1srewc with config:
wandb: 	actor_learning_rate: 4.1287147898707415e-06
wandb: 	attention_dropout_p: 0.08163123265069083
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.940075812445786
wandb: 	temperature: 8.829894153270759
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054723-qu1srewc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu1srewc
wandb: uploading history steps 130-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–„â–„â–‚â–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–„â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–…â–‡â–†â–ƒâ–ˆâ–…â–…â–„â–†â–…â–…â–‚â–…â–…â–ƒâ–†â–‡â–ˆâ–ƒâ–‡â–‚â–‚â–ƒâ–‚â–„â–ƒâ–†â–â–…â–‚â–ƒâ–…â–†â–†â–„â–„â–…â–†
wandb:      eval/avg_mil_loss â–…â–„â–ˆâ–„â–…â–„â–„â–„â–…â–ƒâ–†â–ƒâ–†â–„â–†â–…â–‚â–…â–…â–†â–„â–ƒâ–†â–…â–„â–…â–…â–†â–‡â–„â–â–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–…
wandb:       eval/ensemble_f1 â–‡â–ˆâ–…â–ƒâ–‡â–…â–‚â–‡â–…â–†â–„â–ƒâ–…â–„â–„â–‡â–ˆâ–…â–†â–…â–‡â–†â–ƒâ–†â–‚â–†â–ƒâ–†â–†â–â–…â–‚â–…â–…â–…â–†â–„â–ˆâ–â–‚
wandb:           train/avg_f1 â–ƒâ–ˆâ–†â–…â–‡â–‚â–ƒâ–‡â–„â–„â–…â–â–„â–…â–‡â–†â–…â–ƒâ–„â–ˆâ–„â–„â–ƒâ–…â–…â–„â–…â–‚â–„â–„â–†â–ƒâ–‚â–…â–‚â–„â–‚â–†â–„â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–†â–ƒâ–…â–…â–†â–ˆâ–…â–†â–…â–…â–â–„â–ˆâ–‡â–„â–…â–„â–…â–†â–ƒâ–„â–„â–†â–‡â–„â–„â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‡â–…â–‡â–‚
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–†â–…â–…â–†â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–
wandb:      train/policy_loss â–„â–…â–„â–„â–„â–…â–„â–ˆâ–„â–â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–†â–„â–„â–„â–…â–„â–â–„â–„â–„â–‡â–ˆâ–„â–ˆâ–†â–„â–‡â–„â–„â–„â–„â–„â–…â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84432
wandb: best/eval_avg_mil_loss 0.43543
wandb:  best/eval_ensemble_f1 0.84432
wandb:            eval/avg_f1 0.74794
wandb:      eval/avg_mil_loss 0.4868
wandb:       eval/ensemble_f1 0.74794
wandb:           train/avg_f1 0.79938
wandb:      train/ensemble_f1 0.79938
wandb:         train/mil_loss 0.766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fearless-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu1srewc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054723-qu1srewc/logs
wandb: ERROR Run qu1srewc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: gbrvk71f with config:
wandb: 	actor_learning_rate: 0.00015004244070969142
wandb: 	attention_dropout_p: 0.06566191492692136
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3703741063706121
wandb: 	temperature: 0.33703300805967507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055028-gbrvk71f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbrvk71f
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–…â–ˆâ–†â–â–†â–…
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–†â–‡â–ˆâ–‡â–„â–†â–„â–†â–…â–…â–‡â–†â–…â–ƒâ–…â–†â–†â–ƒâ–„â–‡â–†â–‡â–†â–„â–‡â–ˆâ–„â–…â–†â–ƒâ–‡â–â–†â–…â–‡â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–‡â–†â–„â–‚â–‚â–ƒâ–ƒâ–‡â–ƒâ–…â–„â–ƒâ–…â–…â–…â–…â–…â–„â–ˆâ–„â–‚â–„â–„â–ˆâ–„â–†â–…â–‡â–„â–â–‚â–…â–‚â–ƒâ–†â–‚â–…â–‚
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–…â–‡â–†â–‡â–‡â–ƒâ–„â–…â–†â–ƒâ–‡â–…â–„â–ƒâ–‚â–„â–„â–…â–…â–†â–…â–†â–â–†â–‚â–†â–‡â–‡â–‚â–‚â–ˆâ–‡â–…â–„â–ƒâ–„â–
wandb:           train/avg_f1 â–„â–‡â–…â–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–„â–‡â–†â–†â–„â–†â–ˆâ–‚â–„â–‚â–‡â–ƒâ–„â–„â–„â–„â–â–„â–…â–…â–‚â–„â–ƒâ–â–…â–…â–ƒâ–„â–„â–‚
wandb:      train/ensemble_f1 â–…â–„â–ƒâ–…â–…â–‚â–‡â–…â–…â–…â–‚â–†â–…â–†â–†â–†â–„â–„â–†â–ˆâ–„â–„â–…â–†â–‡â–‚â–ƒâ–„â–â–„â–†â–‚â–„â–…â–†â–ƒâ–…â–„â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–†â–†â–†â–…â–†â–…â–†â–…â–…â–…â–…â–…â–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–â–…â–†â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83513
wandb: best/eval_avg_mil_loss 0.4549
wandb:  best/eval_ensemble_f1 0.83513
wandb:            eval/avg_f1 0.8052
wandb:      eval/avg_mil_loss 0.4285
wandb:       eval/ensemble_f1 0.8052
wandb:           train/avg_f1 0.78531
wandb:      train/ensemble_f1 0.78531
wandb:         train/mil_loss 0.81171
wandb:      train/policy_loss -0.29532
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.29532
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbrvk71f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055028-gbrvk71f/logs
wandb: ERROR Run gbrvk71f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ey2iugz1 with config:
wandb: 	actor_learning_rate: 1.174135853682498e-05
wandb: 	attention_dropout_p: 0.13891657281258962
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7366619824651547
wandb: 	temperature: 4.324322067574401
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055258-ey2iugz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2iugz1
wandb: uploading history steps 79-92, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–ƒâ–„â–…â–‚â–‚â–„â–ƒâ–…â–ƒâ–…â–„â–„â–ˆâ–ƒâ–…â–‡â–…â–†â–ˆâ–„â–…â–‡â–„â–„â–„â–…â–…â–…â–ƒâ–â–‡â–…â–…â–…â–†â–…â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–…â–…â–†â–‡â–ƒâ–„â–‡â–ƒâ–„â–†â–†â–„â–†â–ˆâ–…â–„â–‚â–†â–…â–…â–…â–‡â–†â–„â–…â–‡â–…â–â–ƒâ–„â–…â–ˆâ–ƒâ–‡â–„â–†â–…â–†
wandb:       eval/ensemble_f1 â–†â–‚â–…â–„â–…â–ƒâ–†â–‚â–…â–…â–„â–†â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–ƒâ–„â–…â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–ƒâ–„â–…â–‡â–ˆâ–†â–„â–…â–…
wandb:           train/avg_f1 â–„â–„â–†â–„â–„â–‡â–†â–„â–ƒâ–ˆâ–…â–…â–„â–ƒâ–†â–‡â–„â–‡â–†â–‡â–…â–…â–…â–‡â–„â–…â–†â–„â–‡â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–ƒâ–…â–„â–â–
wandb:      train/ensemble_f1 â–†â–†â–‡â–‡â–†â–ˆâ–…â–…â–ƒâ–ƒâ–ƒâ–†â–…â–‡â–‡â–†â–ƒâ–„â–ˆâ–†â–…â–ƒâ–‡â–…â–ˆâ–„â–„â–ƒâ–…â–†â–…â–„â–„â–ƒâ–ƒâ–„â–…â–…â–â–
wandb:         train/mil_loss â–…â–…â–ˆâ–…â–…â–ˆâ–…â–†â–‡â–…â–†â–…â–†â–„â–†â–„â–†â–…â–„â–†â–…â–„â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–„â–‚â–‚â–‚â–â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–†â–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–â–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83571
wandb: best/eval_avg_mil_loss 0.41373
wandb:  best/eval_ensemble_f1 0.83571
wandb:            eval/avg_f1 0.7992
wandb:      eval/avg_mil_loss 0.43286
wandb:       eval/ensemble_f1 0.7992
wandb:           train/avg_f1 0.77217
wandb:      train/ensemble_f1 0.77217
wandb:         train/mil_loss 0.63522
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run still-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ey2iugz1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055258-ey2iugz1/logs
wandb: ERROR Run ey2iugz1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: quyhnbod with config:
wandb: 	actor_learning_rate: 0.0009314612840585808
wandb: 	attention_dropout_p: 0.20246012604245855
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 156
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33939124182434033
wandb: 	temperature: 4.779756634460352
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055451-quyhnbod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quyhnbod
wandb: uploading history steps 92-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–…â–„â–‚â–†â–‡â–‡â–„â–…â–…â–…â–†â–ƒâ–„â–„â–„â–†â–ƒâ–…â–…â–…â–‡â–†â–„â–…â–„â–†â–…â–…â–â–…â–…â–‚â–…â–ˆâ–…â–…â–„â–„â–
wandb:      eval/avg_mil_loss â–‚â–…â–ˆâ–…â–…â–†â–†â–…â–„â–‡â–ƒâ–‡â–†â–‡â–ƒâ–†â–„â–‡â–„â–â–†â–†â–…â–ƒâ–„â–…â–…â–„â–…â–…â–…â–ƒâ–…â–‡â–†â–†â–â–„â–†â–ƒ
wandb:       eval/ensemble_f1 â–„â–ˆâ–„â–‚â–…â–„â–„â–†â–†â–…â–ƒâ–‚â–…â–…â–†â–„â–†â–ƒâ–ƒâ–„â–†â–†â–†â–…â–…â–â–…â–ƒâ–„â–‚â–…â–„â–…â–ƒâ–‡â–‡â–…â–…â–„â–ƒ
wandb:           train/avg_f1 â–…â–„â–…â–â–†â–ˆâ–†â–…â–…â–‚â–â–…â–ƒâ–†â–†â–…â–‚â–ƒâ–†â–…â–„â–…â–ƒâ–†â–†â–†â–ƒâ–†â–†â–…â–„â–„â–…â–…â–„â–†â–ƒâ–†â–‡â–‚
wandb:      train/ensemble_f1 â–…â–„â–„â–‡â–‚â–„â–…â–…â–„â–„â–ˆâ–†â–…â–†â–…â–‚â–…â–‚â–…â–„â–†â–â–†â–…â–†â–‡â–…â–„â–‡â–ƒâ–…â–‡â–…â–…â–‡â–…â–†â–†â–†â–‡
wandb:         train/mil_loss â–†â–…â–ˆâ–‡â–„â–ˆâ–ƒâ–‡â–„â–‡â–ƒâ–…â–…â–„â–†â–„â–„â–„â–†â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–†â–…â–„â–ƒâ–ƒâ–…â–…â–ƒâ–‚â–â–‚â–„â–…â–ƒâ–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80644
wandb: best/eval_avg_mil_loss 0.45925
wandb:  best/eval_ensemble_f1 0.80644
wandb:            eval/avg_f1 0.71879
wandb:      eval/avg_mil_loss 0.48932
wandb:       eval/ensemble_f1 0.71879
wandb:           train/avg_f1 0.76831
wandb:      train/ensemble_f1 0.76831
wandb:         train/mil_loss 1.26018
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run azure-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/quyhnbod
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055451-quyhnbod/logs
wandb: ERROR Run quyhnbod errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kgwme01f with config:
wandb: 	actor_learning_rate: 2.2785370108265124e-06
wandb: 	attention_dropout_p: 0.3692722263090225
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32498635744907645
wandb: 	temperature: 8.131090555336797
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055657-kgwme01f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgwme01f
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–„â–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–„â–†â–„â–ˆâ–ˆâ–â–‚â–â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–‚â–…â–…â–ƒâ–„â–‡â–„â–„â–…â–„â–…â–†â–â–‚â–…â–„â–„
wandb:      eval/avg_mil_loss â–…â–…â–…â–â–†â–‡â–…â–†â–ˆâ–„â–…â–†â–ˆâ–…â–…â–„â–ƒâ–…â–„â–…â–„â–…â–†â–â–‡â–†â–…â–‡â–†â–„â–…â–‡â–ƒâ–†â–‚â–†â–†â–ˆâ–„â–…
wandb:       eval/ensemble_f1 â–„â–‡â–ƒâ–„â–ƒâ–„â–„â–‡â–…â–†â–…â–„â–„â–…â–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–…â–ˆâ–†â–„â–…â–ˆâ–„â–„â–â–…â–ƒâ–†â–†â–…â–„â–†â–ƒâ–‡â–„â–…
wandb:           train/avg_f1 â–†â–…â–‡â–ˆâ–„â–ˆâ–†â–‚â–‡â–…â–…â–†â–‡â–†â–‡â–„â–…â–‚â–„â–†â–ƒâ–…â–ƒâ–‡â–„â–…â–„â–„â–‡â–„â–„â–†â–„â–…â–ƒâ–„â–…â–„â–â–†
wandb:      train/ensemble_f1 â–ˆâ–‡â–…â–„â–‚â–ˆâ–‡â–„â–…â–…â–†â–‚â–ˆâ–†â–„â–ƒâ–„â–â–ƒâ–…â–„â–„â–„â–‚â–‡â–ƒâ–†â–„â–‚â–ƒâ–„â–â–ƒâ–…â–‚â–…â–‚â–†â–ƒâ–…
wandb:         train/mil_loss â–†â–„â–„â–…â–ˆâ–„â–†â–…â–…â–†â–„â–„â–†â–„â–„â–†â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–„â–„â–‚â–ƒâ–â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.36174
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.79882
wandb:      eval/avg_mil_loss 0.45606
wandb:       eval/ensemble_f1 0.79882
wandb:           train/avg_f1 0.79285
wandb:      train/ensemble_f1 0.79285
wandb:         train/mil_loss 1.63695
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgwme01f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055657-kgwme01f/logs
wandb: ERROR Run kgwme01f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ablbbamq with config:
wandb: 	actor_learning_rate: 1.5936638151926533e-05
wandb: 	attention_dropout_p: 0.46142917228193847
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3059193000326861
wandb: 	temperature: 2.979060199744655
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055958-ablbbamq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ablbbamq
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–…â–ˆâ–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–ƒâ–…â–†â–„â–„â–…â–…â–„â–„â–„â–…â–…â–…â–…â–â–…â–…â–„â–…â–„â–ƒâ–…â–ˆâ–„â–„â–ƒâ–„â–„â–ƒâ–„â–…â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–„
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–„â–…â–„â–„â–…â–‚â–…â–…â–…â–…â–„â–ƒâ–…â–†â–‡â–…â–ƒâ–…â–†â–„â–ƒâ–ƒâ–„â–„â–„â–â–ƒâ–…â–„â–…â–ƒâ–ˆâ–†â–†â–†â–ƒâ–‡â–„
wandb:       eval/ensemble_f1 â–‚â–ƒâ–â–„â–„â–â–…â–…â–…â–‚â–…â–„â–…â–„â–„â–„â–ƒâ–ƒâ–…â–„â–„â–…â–ƒâ–‚â–ƒâ–„â–ˆâ–…â–ƒâ–ƒâ–ƒâ–„â–ˆâ–ƒâ–…â–…â–…â–‚â–ƒâ–„
wandb:           train/avg_f1 â–†â–†â–„â–„â–„â–ˆâ–„â–â–†â–„â–‚â–„â–†â–‡â–ˆâ–ˆâ–‚â–‚â–ƒâ–†â–ƒâ–…â–…â–„â–†â–…â–„â–„â–…â–„â–‚â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–…â–†â–„
wandb:      train/ensemble_f1 â–‡â–†â–â–‡â–‡â–…â–‚â–ƒâ–…â–„â–‡â–ƒâ–ƒâ–†â–ƒâ–…â–…â–ˆâ–„â–„â–ˆâ–„â–†â–…â–…â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–…â–ˆâ–ƒâ–†â–ƒâ–…â–‡â–†
wandb:         train/mil_loss â–„â–…â–â–…â–ˆâ–…â–ƒâ–„â–†â–…â–ƒâ–ƒâ–…â–„â–‚â–„â–‚â–ƒâ–…â–‚â–†â–„â–„â–„â–‡â–ƒâ–†â–â–â–†â–„â–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–†â–†
wandb:      train/policy_loss â–ˆâ–„â–â–„â–„â–ˆâ–â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–â–ˆâ–â–„â–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–â–„â–„â–„â–„â–„â–â–„â–„â–„â–ˆâ–„â–â–ˆâ–„â–â–„â–ˆâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.38135
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.81717
wandb:      eval/avg_mil_loss 0.4205
wandb:       eval/ensemble_f1 0.81717
wandb:           train/avg_f1 0.78518
wandb:      train/ensemble_f1 0.78518
wandb:         train/mil_loss 0.86663
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run autumn-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ablbbamq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055958-ablbbamq/logs
wandb: ERROR Run ablbbamq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d39drv7f with config:
wandb: 	actor_learning_rate: 2.380854357608749e-06
wandb: 	attention_dropout_p: 0.20204413055540865
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6863133111712968
wandb: 	temperature: 0.280926580720291
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060158-d39drv7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d39drv7f
wandb: uploading history steps 139-146, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–„â–ˆâ–…â–†â–†â–†â–…â–‡â–‡â–‡â–†â–†â–ƒâ–ˆâ–„â–ƒâ–…â–…â–…â–ˆâ–‚â–†â–„â–„â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–„â–â–ƒâ–â–‚â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–‚â–„â–„â–ƒâ–…â–„â–…â–…â–ƒâ–ƒâ–â–ƒâ–„â–„â–…â–…â–ƒâ–„â–…â–†â–†â–…â–†â–†â–‡â–…â–†â–†â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:       eval/ensemble_f1 â–ˆâ–‡â–†â–ˆâ–†â–‡â–ˆâ–ˆâ–†â–‡â–†â–ˆâ–…â–„â–‡â–†â–…â–„â–…â–…â–…â–…â–…â–„â–…â–†â–†â–…â–ƒâ–…â–…â–…â–‡â–„â–„â–ƒâ–„â–„â–‚â–
wandb:           train/avg_f1 â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:      train/ensemble_f1 â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–…â–…â–…â–†â–…â–„â–„â–„â–â–‚â–ƒ
wandb:         train/mil_loss â–‡â–†â–‡â–‡â–ˆâ–†â–†â–…â–†â–…â–†â–…â–…â–„â–„â–†â–…â–…â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–†â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84658
wandb: best/eval_avg_mil_loss 0.37244
wandb:  best/eval_ensemble_f1 0.84658
wandb:            eval/avg_f1 0.69421
wandb:      eval/avg_mil_loss 0.66049
wandb:       eval/ensemble_f1 0.69421
wandb:           train/avg_f1 0.71089
wandb:      train/ensemble_f1 0.71089
wandb:         train/mil_loss 1.40409
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sunny-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d39drv7f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060158-d39drv7f/logs
wandb: ERROR Run d39drv7f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0f8uhovr with config:
wandb: 	actor_learning_rate: 5.204970058178652e-05
wandb: 	attention_dropout_p: 0.04773938984623882
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14213629341388612
wandb: 	temperature: 4.474501944085042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060514-0f8uhovr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0f8uhovr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–†â–„â–ƒâ–ƒâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–„â–…â–‡â–ˆâ–…â–ƒâ–„â–ƒâ–…â–„â–‡â–…â–…â–„â–…â–†â–„â–ƒâ–†â–…â–„â–‚â–‡â–…â–‚â–‡â–‚â–…â–ƒâ–„â–‚â–‚â–ƒâ–„â–„â–‚â–
wandb:      eval/avg_mil_loss â–‚â–„â–‚â–â–‚â–â–â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–â–‚â–ƒâ–ƒâ–…â–…â–„â–„â–‚â–…â–ƒâ–ƒâ–‡â–„â–ˆâ–ƒâ–…â–…â–„â–„â–†â–†â–…â–‡â–„â–†â–‡
wandb:       eval/ensemble_f1 â–…â–‡â–„â–‡â–…â–‡â–†â–„â–„â–…â–ƒâ–„â–„â–„â–…â–…â–ˆâ–†â–…â–„â–†â–„â–„â–…â–‡â–…â–†â–‚â–…â–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„â–†â–ƒâ–
wandb:           train/avg_f1 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–‡â–ˆâ–‡â–‡â–†â–†â–‡â–†â–…â–†â–…â–†â–…â–…â–…â–†â–„â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:      train/ensemble_f1 â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–†â–ˆâ–‡â–†â–†â–†â–‡â–†â–…â–†â–†â–…â–†â–…â–…â–…â–…â–†â–†â–„â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–
wandb:         train/mil_loss â–ˆâ–†â–†â–ˆâ–‡â–‡â–†â–…â–†â–…â–…â–…â–…â–†â–‡â–„â–„â–„â–…â–…â–„â–„â–†â–…â–ƒâ–ƒâ–„â–ƒâ–„â–†â–„â–„â–ƒâ–…â–‚â–‚â–‚â–ƒâ–ƒâ–
wandb:      train/policy_loss â–‚â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–ƒâ–â–‚â–â–‚â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ƒâ–â–â–â–ƒâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–‡â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83189
wandb: best/eval_avg_mil_loss 0.42205
wandb:  best/eval_ensemble_f1 0.83189
wandb:            eval/avg_f1 0.72318
wandb:      eval/avg_mil_loss 0.58278
wandb:       eval/ensemble_f1 0.72318
wandb:           train/avg_f1 0.71914
wandb:      train/ensemble_f1 0.71914
wandb:         train/mil_loss 1.07281
wandb:      train/policy_loss 0.04947
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.04947
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run helpful-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0f8uhovr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060514-0f8uhovr/logs
wandb: ERROR Run 0f8uhovr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8bs4q77e with config:
wandb: 	actor_learning_rate: 9.92134792297443e-05
wandb: 	attention_dropout_p: 0.2632114383292347
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9523876051591526
wandb: 	temperature: 8.178011565584857
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060754-8bs4q77e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8bs4q77e
wandb: uploading history steps 81-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–ˆâ–„â–‡â–ƒâ–†â–…â–…â–ƒâ–„â–ƒâ–ƒâ–…â–„â–‚â–„â–…â–‡â–…â–„â–…â–†â–‡â–…â–…â–„â–ƒâ–ƒâ–â–„â–ƒâ–‚â–ƒâ–…â–ƒâ–„â–…â–ƒ
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–†â–ˆâ–„â–†â–†â–…â–ƒâ–ˆâ–†â–ƒâ–†â–„â–„â–ˆâ–†â–„â–…â–…â–â–‡â–†â–„â–…â–„â–‡â–…â–…â–…â–†â–…â–‡â–‡â–†â–…â–†â–†â–†
wandb:       eval/ensemble_f1 â–†â–†â–†â–†â–ˆâ–‡â–†â–…â–‡â–„â–…â–ƒâ–ƒâ–…â–…â–‚â–†â–†â–†â–ƒâ–‡â–„â–ƒâ–…â–…â–…â–‡â–…â–…â–„â–„â–„â–†â–…â–â–ƒâ–‚â–ƒâ–…â–ƒ
wandb:           train/avg_f1 â–†â–†â–…â–ˆâ–†â–…â–‡â–…â–†â–ƒâ–„â–…â–‡â–…â–‡â–„â–„â–„â–‚â–‚â–†â–…â–ƒâ–ˆâ–ˆâ–‚â–†â–„â–ƒâ–„â–…â–…â–â–†â–„â–„â–ƒâ–„â–‚â–„
wandb:      train/ensemble_f1 â–ƒâ–…â–‚â–…â–†â–ƒâ–…â–…â–ƒâ–…â–„â–…â–â–…â–„â–ƒâ–…â–†â–â–ƒâ–…â–…â–…â–„â–‚â–‡â–ˆâ–…â–…â–…â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–‚â–â–
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–„â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–‚â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.41964
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.77718
wandb:      eval/avg_mil_loss 0.45938
wandb:       eval/ensemble_f1 0.77718
wandb:           train/avg_f1 0.78307
wandb:      train/ensemble_f1 0.78307
wandb:         train/mil_loss 0.99006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earthy-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8bs4q77e
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060754-8bs4q77e/logs
wandb: ERROR Run 8bs4q77e errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uhi9jt5k with config:
wandb: 	actor_learning_rate: 7.82492366606512e-06
wandb: 	attention_dropout_p: 0.41758034318365655
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5227051104888658
wandb: 	temperature: 1.3496901053500676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061004-uhi9jt5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhi9jt5k
wandb: uploading wandb-summary.json
wandb: uploading history steps 129-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–‚â–ˆâ–ƒâ–ƒâ–â–†â–„â–…â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–†â–ƒâ–…â–†â–ˆâ–†â–…â–ˆâ–ƒâ–…â–ƒâ–†â–…â–…â–ˆâ–ƒâ–ƒâ–…â–„â–…â–‚â–‚â–„â–„â–…â–ƒâ–ƒâ–…â–…â–„â–â–…â–†â–ƒâ–ƒâ–„â–…â–„
wandb:      eval/avg_mil_loss â–…â–‡â–‚â–†â–ƒâ–…â–†â–…â–„â–ƒâ–…â–ƒâ–‡â–†â–ƒâ–…â–‚â–‡â–„â–â–†â–†â–†â–ˆâ–…â–ƒâ–„â–‚â–†â–…â–‡â–â–„â–ƒâ–„â–ƒâ–ˆâ–‚â–„â–…
wandb:       eval/ensemble_f1 â–„â–„â–„â–…â–…â–‡â–…â–…â–ˆâ–†â–†â–…â–…â–â–„â–ˆâ–â–‚â–„â–…â–…â–ƒâ–„â–…â–…â–‚â–†â–„â–„â–…â–‡â–†â–ƒâ–‡â–ƒâ–ƒâ–…â–…â–…â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–„â–‡â–„â–…â–…â–ƒâ–†â–…â–â–ƒâ–†â–„â–†â–ƒâ–„â–„â–†â–„â–ƒâ–†â–†â–‚â–â–…â–†â–â–…â–ˆâ–ƒâ–„â–…â–…â–ƒâ–ˆâ–…â–†â–„
wandb:      train/ensemble_f1 â–„â–…â–„â–â–†â–…â–‡â–„â–ƒâ–ƒâ–…â–…â–„â–â–…â–†â–…â–†â–†â–†â–ƒâ–…â–„â–ƒâ–…â–…â–…â–†â–ƒâ–„â–„â–…â–ƒâ–ƒâ–ˆâ–…â–…â–†â–„â–ƒ
wandb:         train/mil_loss â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–†â–†â–…â–…â–…â–†â–„â–…â–„â–„â–„â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:      train/policy_loss â–„â–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82448
wandb: best/eval_avg_mil_loss 0.39743
wandb:  best/eval_ensemble_f1 0.82448
wandb:            eval/avg_f1 0.78045
wandb:      eval/avg_mil_loss 0.47571
wandb:       eval/ensemble_f1 0.78045
wandb:           train/avg_f1 0.79168
wandb:      train/ensemble_f1 0.79168
wandb:         train/mil_loss 1.00045
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fearless-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhi9jt5k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061004-uhi9jt5k/logs
wandb: ERROR Run uhi9jt5k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: m789uulr with config:
wandb: 	actor_learning_rate: 1.12901719197684e-05
wandb: 	attention_dropout_p: 0.2928656846273601
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5527884791010487
wandb: 	temperature: 1.4390628029540542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061244-m789uulr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6jyv4xg9
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m789uulr
wandb: uploading history steps 140-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–…â–â–†â–„â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–…â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–„â–†â–…â–ƒâ–†â–‡â–„â–…â–…â–ƒâ–†â–„â–„â–„â–ƒâ–‚â–â–ˆâ–…â–„â–ƒâ–†â–…â–…â–ƒâ–„â–†â–„â–‚â–…â–„â–„â–†â–ƒâ–…â–†â–â–„
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–„â–…â–â–„â–„â–ƒâ–…â–‚â–„â–…â–†â–…â–†â–†â–ƒâ–„â–‚â–†â–…â–„â–…â–‚â–†â–†â–…â–†â–†â–…â–†â–„â–†â–†â–…â–‡â–ˆâ–…â–‡
wandb:       eval/ensemble_f1 â–„â–…â–†â–…â–‡â–ƒâ–ˆâ–„â–†â–‚â–‡â–ƒâ–†â–„â–†â–ƒâ–ƒâ–…â–…â–…â–†â–…â–†â–…â–„â–†â–„â–…â–…â–ƒâ–…â–…â–„â–â–ƒâ–‚â–‡â–‚â–„â–‚
wandb:           train/avg_f1 â–ˆâ–…â–†â–†â–…â–†â–…â–†â–…â–„â–ˆâ–‡â–†â–‡â–„â–…â–‡â–…â–†â–…â–ƒâ–„â–…â–‡â–…â–…â–‡â–†â–ƒâ–â–ƒâ–„â–„â–‚â–‡â–„â–‚â–‚â–‚â–
wandb:      train/ensemble_f1 â–†â–†â–†â–‡â–†â–‡â–‡â–†â–…â–ˆâ–†â–†â–ˆâ–…â–…â–…â–†â–„â–…â–†â–‡â–†â–…â–ƒâ–„â–ƒâ–…â–„â–…â–ƒâ–‚â–‚â–…â–„â–‚â–â–â–‚â–‚â–‚
wandb:         train/mil_loss â–ˆâ–‡â–ˆâ–‡â–†â–†â–‡â–…â–†â–‡â–…â–…â–„â–„â–…â–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.3841
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.76206
wandb:      eval/avg_mil_loss 0.50219
wandb:       eval/ensemble_f1 0.76206
wandb:           train/avg_f1 0.78966
wandb:      train/ensemble_f1 0.78966
wandb:         train/mil_loss 0.70105
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweepy-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m789uulr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061244-m789uulr/logs
wandb: ERROR Run m789uulr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 69qbwzpl with config:
wandb: 	actor_learning_rate: 0.00014847561693741578
wandb: 	attention_dropout_p: 0.07847731014366632
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33516101412967847
wandb: 	temperature: 4.650728214720208
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061555-69qbwzpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69qbwzpl
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 125-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–ˆâ–„â–„â–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–„â–„â–‡â–†â–†â–…â–†â–„â–‡â–‡â–â–ƒâ–…â–‡â–†â–…â–…â–„â–‡â–ˆâ–…â–‡â–…â–„â–…â–‡â–„â–ˆâ–†â–†â–‡â–ƒâ–ƒâ–‚â–‚â–„â–„â–…â–‡
wandb:      eval/avg_mil_loss â–„â–†â–ƒâ–ƒâ–‚â–…â–â–…â–„â–‚â–†â–ƒâ–…â–‡â–…â–‚â–ƒâ–ƒâ–â–‚â–â–„â–…â–‚â–†â–„â–„â–ˆâ–ƒâ–…â–„â–…â–…â–†â–†â–ˆâ–‚â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–â–…â–„â–‡â–â–„â–…â–„â–†â–…â–â–…â–ƒâ–„â–†â–„â–â–„â–ƒâ–„â–ˆâ–„â–‡â–„â–…â–…â–‡â–„â–†â–…â–…â–†â–‚â–„â–„â–„â–„â–…â–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–…â–„â–†â–ƒâ–„â–ƒâ–†â–†â–†â–ƒâ–…â–†â–…â–…â–ˆâ–…â–ƒâ–‚â–ƒâ–…â–‚â–…â–…â–…â–ƒâ–…â–‚â–‡â–ƒâ–ˆâ–â–„â–…â–†â–‚â–…â–…â–„
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–…â–†â–„â–â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–†â–„â–…â–â–‡â–…â–…â–†â–„â–‡â–…â–‡â–‡â–…â–ƒâ–ˆâ–„â–†â–†â–ƒâ–‡â–‚â–…â–…â–…â–…
wandb:         train/mil_loss â–„â–ˆâ–„â–„â–†â–†â–†â–„â–…â–„â–‚â–â–ƒâ–ƒâ–„â–‚â–†â–…â–…â–…â–ƒâ–ƒâ–„â–‚â–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–…â–†â–ƒâ–†â–‚â–ƒâ–„â–ˆ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84175
wandb: best/eval_avg_mil_loss 0.35033
wandb:  best/eval_ensemble_f1 0.84175
wandb:            eval/avg_f1 0.82088
wandb:      eval/avg_mil_loss 0.43167
wandb:       eval/ensemble_f1 0.82088
wandb:            test/avg_f1 0.80336
wandb:      test/avg_mil_loss 0.3985
wandb:       test/ensemble_f1 0.80336
wandb:           train/avg_f1 0.8022
wandb:      train/ensemble_f1 0.8022
wandb:         train/mil_loss 0.54395
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/69qbwzpl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061555-69qbwzpl/logs
wandb: Agent Starting Run: lh9n1pbl with config:
wandb: 	actor_learning_rate: 8.730466352448903e-05
wandb: 	attention_dropout_p: 0.2508219013103906
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06040450505889472
wandb: 	temperature: 2.595599481065447
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061825-lh9n1pbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh9n1pbl
wandb: uploading wandb-summary.json
wandb: uploading history steps 131-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–…â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–„â–…â–‡â–ƒâ–ƒâ–„â–‡â–…â–â–‡â–ƒâ–…â–„â–ƒâ–…â–†â–†â–ƒâ–…â–ˆâ–‚â–„â–ˆâ–„â–…â–†â–ƒâ–‡â–„â–„â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–…â–‡
wandb:      eval/avg_mil_loss â–â–‡â–…â–…â–ƒâ–„â–‡â–ƒâ–‚â–…â–„â–â–‚â–ƒâ–…â–†â–‚â–ƒâ–ƒâ–†â–„â–†â–…â–…â–†â–ƒâ–‡â–ƒâ–ˆâ–„â–â–â–‚â–„â–‚â–…â–‡â–„â–„â–„
wandb:       eval/ensemble_f1 â–ˆâ–…â–„â–†â–…â–†â–…â–‡â–ƒâ–†â–‡â–†â–„â–ƒâ–ƒâ–…â–†â–‡â–…â–‡â–…â–‡â–â–‡â–…â–ƒâ–†â–…â–‡â–ˆâ–†â–†â–†â–†â–„â–„â–‚â–ˆâ–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–ƒâ–…â–‡â–ƒâ–†â–‡â–ˆâ–ƒâ–…â–„â–†â–ƒâ–„â–…â–ƒâ–ƒâ–‡â–„â–…â–„â–ƒâ–ƒâ–„â–…â–â–„â–‡â–†â–†â–…â–‚â–…â–…â–…â–„â–†â–†â–†
wandb:      train/ensemble_f1 â–…â–„â–„â–„â–„â–„â–â–…â–‚â–‡â–ƒâ–„â–ˆâ–ƒâ–ƒâ–„â–†â–ƒâ–†â–…â–â–ƒâ–‡â–†â–†â–…â–â–…â–„â–…â–…â–„â–…â–„â–ƒâ–‡â–„â–†â–„â–„
wandb:         train/mil_loss â–‡â–†â–…â–…â–†â–†â–„â–…â–â–„â–„â–…â–ˆâ–ˆâ–†â–ƒâ–ˆâ–ƒâ–„â–…â–†â–…â–‡â–†â–ƒâ–†â–†â–‚â–ƒâ–‡â–†â–†â–…â–†â–„â–„â–…â–ƒâ–„â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83817
wandb: best/eval_avg_mil_loss 0.365
wandb:  best/eval_ensemble_f1 0.83817
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.46571
wandb:       eval/ensemble_f1 0.78993
wandb:            test/avg_f1 0.75142
wandb:      test/avg_mil_loss 0.64106
wandb:       test/ensemble_f1 0.75142
wandb:           train/avg_f1 0.79491
wandb:      train/ensemble_f1 0.79491
wandb:         train/mil_loss 1.02249
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lh9n1pbl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061825-lh9n1pbl/logs
wandb: Agent Starting Run: 3dq5xvci with config:
wandb: 	actor_learning_rate: 2.46179434474149e-06
wandb: 	attention_dropout_p: 0.4569873040075996
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39905695719498846
wandb: 	temperature: 9.422164437380117
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062101-3dq5xvci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dq5xvci
wandb: uploading history steps 44-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–ˆâ–„â–†â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–…â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–…â–ƒâ–…â–‚â–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–…â–ƒâ–„â–ƒâ–…â–…â–†â–ˆâ–ƒâ–…â–„â–…â–…â–„â–‚â–‚â–ƒâ–„â–ƒâ–†â–…â–â–ƒâ–‚â–…â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–…â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–…â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–‚â–â–â–ƒâ–ƒâ–…â–ƒâ–‚â–ˆâ–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–
wandb:       eval/ensemble_f1 â–‚â–‚â–„â–…â–ƒâ–…â–‚â–…â–‚â–ƒâ–â–ƒâ–ƒâ–…â–†â–…â–ƒâ–…â–ƒâ–…â–…â–ƒâ–†â–ˆâ–…â–…â–…â–„â–ƒâ–‚â–ƒâ–„â–„â–†â–…â–‚â–„â–‚â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–‚â–„â–„â–â–…â–…â–„â–ˆâ–…â–…â–„â–„â–‚â–„â–â–„â–‚â–‚â–†â–ƒâ–‚â–â–†â–…â–…â–ƒâ–ƒâ–‚â–ƒâ–…â–…â–„â–†â–…â–…â–„â–‚â–…â–ƒ
wandb:      train/ensemble_f1 â–‚â–‚â–„â–„â–â–…â–…â–„â–ˆâ–…â–…â–„â–„â–‚â–„â–„â–‚â–‚â–„â–†â–ƒâ–‚â–â–ƒâ–†â–†â–…â–ƒâ–ƒâ–‚â–‚â–…â–„â–†â–…â–…â–„â–‚â–…â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–„â–‡â–‡â–â–ƒâ–‚â–ˆâ–„â–‚â–…â–†â–‚â–‚â–…â–â–‚â–„â–…â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–‡â–„â–„â–†â–ƒâ–„â–‡â–‚â–†â–â–ƒâ–„â–‚
wandb:      train/policy_loss â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.39469
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.79808
wandb:      eval/avg_mil_loss 0.38731
wandb:       eval/ensemble_f1 0.79808
wandb:            test/avg_f1 0.81854
wandb:      test/avg_mil_loss 0.44609
wandb:       test/ensemble_f1 0.81854
wandb:           train/avg_f1 0.7968
wandb:      train/ensemble_f1 0.7968
wandb:         train/mil_loss 0.79258
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run daily-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dq5xvci
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062101-3dq5xvci/logs
wandb: Agent Starting Run: fuiprpm4 with config:
wandb: 	actor_learning_rate: 9.951127144300932e-06
wandb: 	attention_dropout_p: 0.38267827687153544
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22380199965479963
wandb: 	temperature: 7.542860057513248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062158-fuiprpm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fuiprpm4
wandb: uploading history steps 57-72, summary; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 57-72, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–ƒâ–„â–…â–ƒâ–†â–ƒâ–„â–ƒâ–†â–…â–„â–…â–‡â–ƒâ–…â–‡â–†â–ƒâ–„â–†â–ƒâ–‚â–„â–â–„â–†â–ƒâ–…â–…â–ƒâ–â–„â–…â–„â–ƒâ–…â–†â–†
wandb:      eval/avg_mil_loss â–†â–â–ƒâ–„â–ƒâ–„â–‡â–…â–ƒâ–†â–ˆâ–†â–…â–†â–‚â–ˆâ–†â–ˆâ–†â–„â–ˆâ–ˆâ–„â–…â–ˆâ–†â–†â–„â–‚â–…â–ƒâ–‡â–ƒâ–†â–„â–…â–„â–â–†â–†
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–„â–ƒâ–„â–…â–†â–…â–ƒâ–ƒâ–†â–ƒâ–…â–…â–„â–…â–…â–‡â–„â–â–ƒâ–…â–…â–„â–ƒâ–„â–†â–‚â–…â–…â–â–…â–„â–ƒâ–…â–‡â–…â–†â–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–…â–ƒâ–…â–„â–…â–ˆâ–†â–„â–†â–ƒâ–„â–„â–ƒâ–â–„â–†â–‡â–ƒâ–ƒâ–†â–„â–‚â–â–…â–„â–ƒâ–ƒâ–‚â–„â–„â–‡â–‡â–ƒâ–ƒâ–…â–ƒâ–…â–†
wandb:      train/ensemble_f1 â–„â–…â–…â–…â–…â–‚â–„â–ˆâ–†â–„â–†â–†â–„â–â–„â–…â–…â–†â–ƒâ–†â–†â–‚â–ƒâ–ƒâ–†â–…â–„â–ƒâ–ƒâ–„â–…â–…â–†â–„â–…â–â–…â–…â–„â–†
wandb:         train/mil_loss â–†â–„â–…â–‡â–…â–…â–…â–ƒâ–ˆâ–ƒâ–…â–„â–„â–…â–†â–ˆâ–„â–„â–…â–„â–„â–„â–ƒâ–ƒâ–†â–„â–‚â–…â–ƒâ–…â–‚â–„â–…â–ˆâ–ƒâ–„â–„â–†â–ƒâ–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85647
wandb: best/eval_avg_mil_loss 0.31165
wandb:  best/eval_ensemble_f1 0.85647
wandb:            eval/avg_f1 0.82808
wandb:      eval/avg_mil_loss 0.45449
wandb:       eval/ensemble_f1 0.82808
wandb:            test/avg_f1 0.80565
wandb:      test/avg_mil_loss 0.46002
wandb:       test/ensemble_f1 0.80565
wandb:           train/avg_f1 0.81506
wandb:      train/ensemble_f1 0.81506
wandb:         train/mil_loss 0.59039
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run neat-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fuiprpm4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062158-fuiprpm4/logs
wandb: Agent Starting Run: 9j96y5z1 with config:
wandb: 	actor_learning_rate: 0.00021077856076934945
wandb: 	attention_dropout_p: 0.4062631765403543
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5897798821218809
wandb: 	temperature: 3.812481519503568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062320-9j96y5z1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9j96y5z1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–†â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–„â–„â–…â–†â–…â–…â–‡â–ˆâ–…â–ˆâ–„â–ƒâ–…â–‡â–‚â–†â–‡â–…â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–†â–„â–…â–â–†â–ƒâ–†â–…â–‡â–„â–…â–ƒâ–…â–„
wandb:      eval/avg_mil_loss â–„â–â–…â–…â–ƒâ–‡â–…â–†â–…â–ƒâ–„â–ƒâ–…â–„â–„â–„â–„â–ˆâ–ˆâ–‚â–ƒâ–…â–‡â–‡â–‡â–‡â–…â–„â–†â–ƒâ–†â–„â–„â–ˆâ–‚â–ƒâ–ƒâ–…â–‚â–‚
wandb:       eval/ensemble_f1 â–†â–„â–„â–…â–ƒâ–„â–„â–‡â–ˆâ–„â–ˆâ–ƒâ–ƒâ–ƒâ–„â–‡â–ƒâ–‚â–â–„â–â–„â–ƒâ–ƒâ–ƒâ–†â–„â–„â–…â–…â–†â–…â–†â–‚â–„â–…â–‚â–„â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‡â–„â–†â–„â–â–…â–…â–†â–†â–…â–…â–…â–†â–‚â–‚â–ƒâ–†â–†â–ƒâ–†â–„â–„â–‚â–†â–†â–…â–ƒâ–„â–†â–‚â–„â–„â–ˆâ–ˆâ–„â–†â–ƒâ–…
wandb:      train/ensemble_f1 â–†â–„â–‡â–„â–…â–ƒâ–…â–…â–ƒâ–â–ƒâ–†â–â–‡â–„â–„â–†â–„â–â–â–ƒâ–…â–†â–„â–‚â–â–…â–†â–†â–‚â–ƒâ–ƒâ–â–ˆâ–…â–„â–†â–ˆâ–‚â–„
wandb:         train/mil_loss â–„â–ƒâ–ƒâ–„â–â–…â–‡â–†â–ƒâ–‡â–ƒâ–‚â–…â–‡â–…â–ˆâ–ƒâ–„â–†â–‡â–ˆâ–„â–â–ƒâ–â–…â–…â–„â–…â–‚â–„â–„â–„â–„â–„â–â–…â–†â–„â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.38553
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.82011
wandb:      eval/avg_mil_loss 0.40074
wandb:       eval/ensemble_f1 0.82011
wandb:            test/avg_f1 0.79594
wandb:      test/avg_mil_loss 0.46687
wandb:       test/ensemble_f1 0.79594
wandb:           train/avg_f1 0.80391
wandb:      train/ensemble_f1 0.80391
wandb:         train/mil_loss 0.57064
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run scarlet-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9j96y5z1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062320-9j96y5z1/logs
wandb: Agent Starting Run: kz3y0sv2 with config:
wandb: 	actor_learning_rate: 4.520138896472358e-06
wandb: 	attention_dropout_p: 0.3330683267811347
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8774666394272624
wandb: 	temperature: 9.791566778344922
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062433-kz3y0sv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kz3y0sv2
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 143-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–†â–…â–‚â–†â–„â–‚â–†â–ƒâ–„â–†â–…â–ƒâ–…â–…â–â–â–„â–…â–ˆâ–ƒâ–ƒâ–â–‡â–„â–†â–„â–„â–„â–„â–†â–…â–ˆâ–ˆâ–„â–‚â–‡â–„â–…â–…â–ƒ
wandb:      eval/avg_mil_loss â–…â–ƒâ–â–„â–„â–…â–…â–‚â–‚â–…â–ƒâ–†â–‡â–„â–ƒâ–„â–„â–…â–ˆâ–„â–…â–…â–ƒâ–‚â–…â–â–…â–„â–„â–‚â–ƒâ–ƒâ–…â–‚â–…â–…â–â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–†â–…â–†â–ƒâ–…â–†â–…â–ƒâ–‚â–„â–…â–…â–ƒâ–†â–„â–„â–…â–…â–â–„â–…â–„â–‡â–‚â–…â–„â–‡â–†â–ƒâ–„â–ˆâ–„â–ˆâ–ƒâ–‡â–‚â–…â–„â–…
wandb:           train/avg_f1 â–„â–„â–ƒâ–‚â–†â–…â–‚â–…â–„â–ƒâ–…â–„â–„â–ˆâ–ƒâ–„â–â–ƒâ–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–„â–…â–ƒâ–„â–†â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–‚â–„â–…â–‚â–â–„â–ƒâ–‚â–‚â–ƒâ–„â–„â–â–…â–ˆâ–…â–„â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–‚â–‚â–ƒâ–â–ƒâ–…â–†â–…â–‚â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„
wandb:         train/mil_loss â–†â–ˆâ–…â–„â–„â–‡â–†â–…â–„â–„â–…â–„â–ƒâ–ƒâ–‡â–ƒâ–‡â–‚â–„â–„â–…â–…â–†â–„â–ƒâ–…â–„â–…â–„â–ƒâ–ƒâ–‚â–…â–…â–â–ƒâ–„â–ƒâ–â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83817
wandb: best/eval_avg_mil_loss 0.46073
wandb:  best/eval_ensemble_f1 0.83817
wandb:            eval/avg_f1 0.80266
wandb:      eval/avg_mil_loss 0.40899
wandb:       eval/ensemble_f1 0.80266
wandb:           train/avg_f1 0.80483
wandb:      train/ensemble_f1 0.80483
wandb:         train/mil_loss 0.95166
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run resilient-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kz3y0sv2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062433-kz3y0sv2/logs
wandb: ERROR Run kz3y0sv2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: heud6rav with config:
wandb: 	actor_learning_rate: 1.2557181153536043e-05
wandb: 	attention_dropout_p: 0.16020161256192517
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17858409077708415
wandb: 	temperature: 9.815877183801868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062723-heud6rav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/heud6rav
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–†â–…â–„â–ƒâ–‚â–â–„â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–â–…â–„â–‚â–‚â–ƒâ–…â–ƒâ–„â–„â–‚â–„â–‚â–ƒâ–…â–†â–„â–‚â–ƒâ–…â–„â–ƒâ–„â–…â–„â–‚â–‚â–ƒâ–ƒâ–…â–†â–…â–ƒâ–„â–‚â–â–„â–ˆâ–…
wandb:      eval/avg_mil_loss â–‡â–…â–„â–„â–†â–…â–ƒâ–…â–ˆâ–ˆâ–ˆâ–„â–„â–„â–‚â–ƒâ–„â–„â–‚â–…â–‡â–„â–â–„â–„â–…â–…â–â–…â–„â–‚â–ƒâ–„â–…â–…â–„â–‡â–…â–„â–„
wandb:       eval/ensemble_f1 â–â–„â–ƒâ–â–†â–‚â–…â–„â–„â–ƒâ–ƒâ–…â–‚â–†â–†â–ƒâ–„â–„â–†â–ˆâ–†â–„â–‡â–…â–†â–…â–„â–ƒâ–‚â–‡â–„â–ƒâ–…â–„â–ƒâ–â–…â–…â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–…â–†â–ƒâ–…â–ƒâ–†â–‚â–†â–ƒâ–„â–„â–„â–‡â–‡â–†â–ƒâ–…â–…â–ƒâ–â–†â–‚â–‡â–„â–…â–„â–‚â–â–…â–…â–…â–â–‚â–‡â–‚â–…â–ˆâ–
wandb:      train/ensemble_f1 â–…â–ƒâ–‚â–‡â–‚â–ƒâ–ƒâ–„â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–…â–ˆâ–ƒâ–…â–…â–…â–„â–‡â–ƒâ–„â–„â–‚â–†â–ƒâ–ƒâ–ƒâ–â–‡â–‚â–ƒâ–†â–ƒâ–†â–†â–ˆ
wandb:         train/mil_loss â–„â–„â–†â–‡â–ˆâ–„â–â–„â–ƒâ–‡â–„â–…â–ƒâ–ƒâ–ƒâ–„â–ˆâ–„â–‚â–…â–‚â–‚â–„â–…â–†â–…â–ƒâ–ƒâ–†â–ƒâ–†â–ƒâ–‚â–…â–ƒâ–„â–„â–ƒâ–†â–ƒ
wandb:      train/policy_loss â–ˆâ–„â–â–ˆâ–ˆâ–â–„â–„â–â–„â–„â–„â–„â–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–„â–â–ˆâ–„â–„â–„â–â–â–„â–ˆâ–„â–„â–ˆâ–â–„â–„â–ˆâ–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…â–…â–…â–â–ˆâ–â–â–ˆâ–…â–…â–ˆâ–…â–ˆâ–â–…â–…â–ˆâ–â–â–…â–â–â–…â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84992
wandb: best/eval_avg_mil_loss 0.44411
wandb:  best/eval_ensemble_f1 0.84992
wandb:            eval/avg_f1 0.80266
wandb:      eval/avg_mil_loss 0.44063
wandb:       eval/ensemble_f1 0.80266
wandb:            test/avg_f1 0.76396
wandb:      test/avg_mil_loss 0.523
wandb:       test/ensemble_f1 0.76396
wandb:           train/avg_f1 0.77808
wandb:      train/ensemble_f1 0.77808
wandb:         train/mil_loss 0.52499
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/heud6rav
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062723-heud6rav/logs
wandb: Agent Starting Run: 151ggcwn with config:
wandb: 	actor_learning_rate: 5.5912301105623294e-05
wandb: 	attention_dropout_p: 0.3526568460842181
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18494688738716192
wandb: 	temperature: 7.0336406916672995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063014-151ggcwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/151ggcwn
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–†â–ˆâ–„â–…â–‚â–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–…â–‡â–â–‡â–‡â–†â–„â–„â–ƒâ–†â–„â–ƒâ–…â–…â–†â–…â–„â–†â–†â–…â–‡â–ˆâ–…â–ˆâ–„â–„â–†â–‡â–†â–„â–…â–‡â–‡â–„â–…â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–†â–„â–†â–†â–„â–†â–„â–…â–‡â–ƒâ–„â–ˆâ–…â–†â–ƒâ–„â–…â–‡â–…â–‡â–„â–ƒâ–…â–ƒâ–„â–‚â–…â–ƒâ–ˆâ–…â–â–ˆâ–„â–‡â–‡â–…â–‡
wandb:       eval/ensemble_f1 â–†â–…â–†â–„â–ƒâ–„â–‡â–…â–‚â–ˆâ–ƒâ–â–„â–„â–…â–‚â–„â–â–„â–â–â–ƒâ–„â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–†â–…â–„â–‚â–†â–ƒâ–„â–„â–†â–ƒâ–„
wandb:           train/avg_f1 â–†â–â–„â–†â–ƒâ–†â–…â–„â–„â–ˆâ–ƒâ–ƒâ–„â–†â–‡â–…â–†â–…â–†â–„â–ˆâ–‡â–…â–…â–ƒâ–ƒâ–ƒâ–„â–†â–‚â–…â–†â–„â–„â–„â–„â–…â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–â–…â–‡â–†â–„â–†â–„â–‡â–‚â–…â–ƒâ–†â–‡â–ƒâ–‡â–‡â–†â–ƒâ–†â–ƒâ–‡â–‡â–…â–ˆâ–„â–ƒâ–‡â–†â–ˆâ–†â–ƒâ–„â–ˆâ–†â–„â–‚â–„â–…â–„
wandb:         train/mil_loss â–…â–„â–†â–…â–„â–†â–…â–†â–†â–†â–†â–â–„â–„â–„â–„â–‡â–†â–…â–†â–†â–‡â–‡â–‡â–„â–‡â–†â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–…â–…â–ƒâ–ƒâ–„â–†â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83559
wandb: best/eval_avg_mil_loss 0.42587
wandb:  best/eval_ensemble_f1 0.83559
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.52928
wandb:       eval/ensemble_f1 0.76597
wandb:           train/avg_f1 0.78445
wandb:      train/ensemble_f1 0.78445
wandb:         train/mil_loss 0.8953
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rosy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/151ggcwn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063014-151ggcwn/logs
wandb: ERROR Run 151ggcwn errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 931ju4fi with config:
wandb: 	actor_learning_rate: 0.0006476692932926784
wandb: 	attention_dropout_p: 0.4323108039829737
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8053547670838347
wandb: 	temperature: 3.201383490724531
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063308-931ju4fi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/931ju4fi
wandb: uploading history steps 72-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–â–…â–‚â–‚â–†â–ƒâ–‚â–ˆâ–†â–„â–…â–‡â–„â–†â–„â–‚â–†â–‚â–…â–ƒâ–…â–‚â–†â–†â–‡â–…â–…â–‡â–…â–ƒâ–†â–…â–„â–‚â–†â–ƒâ–‚â–„
wandb:      eval/avg_mil_loss â–…â–†â–†â–†â–†â–„â–†â–…â–…â–…â–ˆâ–„â–†â–ƒâ–…â–…â–‚â–ƒâ–‚â–†â–†â–„â–ƒâ–…â–ƒâ–â–ƒâ–†â–…â–‚â–…â–ƒâ–„â–„â–…â–…â–…â–„â–…â–„
wandb:       eval/ensemble_f1 â–‚â–…â–â–…â–…â–†â–ƒâ–â–„â–…â–„â–„â–…â–†â–„â–†â–…â–…â–†â–„â–ˆâ–†â–ˆâ–…â–…â–…â–†â–‡â–…â–…â–‡â–„â–…â–ƒâ–†â–…â–„â–„â–‚â–„
wandb:           train/avg_f1 â–…â–…â–†â–„â–‡â–ƒâ–†â–…â–†â–…â–†â–„â–†â–…â–‚â–„â–†â–‡â–†â–‡â–…â–„â–ˆâ–ˆâ–†â–†â–‡â–†â–…â–†â–…â–…â–„â–ƒâ–‡â–…â–„â–ˆâ–â–…
wandb:      train/ensemble_f1 â–…â–ˆâ–†â–ƒâ–†â–†â–…â–‡â–†â–†â–‡â–„â–†â–…â–ƒâ–‡â–…â–„â–ˆâ–‡â–ˆâ–†â–„â–†â–…â–‡â–‡â–…â–…â–…â–ƒâ–‡â–ˆâ–†â–…â–â–†â–†â–ˆâ–‡
wandb:         train/mil_loss â–…â–‚â–„â–‚â–„â–ƒâ–â–‚â–ƒâ–…â–ƒâ–†â–„â–„â–ˆâ–…â–ƒâ–â–ƒâ–„â–…â–ƒâ–„â–…â–‚â–â–ƒâ–‚â–â–ƒâ–‚â–â–„â–‚â–‚â–‚â–‚â–‚â–„â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83439
wandb: best/eval_avg_mil_loss 0.39699
wandb:  best/eval_ensemble_f1 0.83439
wandb:            eval/avg_f1 0.78609
wandb:      eval/avg_mil_loss 0.45301
wandb:       eval/ensemble_f1 0.78609
wandb:           train/avg_f1 0.80224
wandb:      train/ensemble_f1 0.80224
wandb:         train/mil_loss 0.93845
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/931ju4fi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063308-931ju4fi/logs
wandb: ERROR Run 931ju4fi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hclixsqo with config:
wandb: 	actor_learning_rate: 5.914510853562371e-05
wandb: 	attention_dropout_p: 0.22600975984982105
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28574576652957595
wandb: 	temperature: 7.726110741157771
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063433-hclixsqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hclixsqo
wandb: uploading history steps 160-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–†â–ƒâ–„â–‡â–ˆâ–†â–†â–…â–‚â–…â–„â–…â–‚â–†â–ƒâ–†â–‡â–ƒâ–†â–…â–‡â–‡â–„â–…â–‡â–…â–…â–„â–†â–‚â–„â–ƒâ–„â–ƒâ–†â–„â–„â–
wandb:      eval/avg_mil_loss â–„â–ˆâ–„â–„â–„â–…â–ƒâ–‡â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–„â–‡â–â–†â–ƒâ–…â–‡â–‡â–†â–ƒâ–…â–„â–†â–†â–†â–ˆâ–…â–ˆâ–†â–…â–†â–‚â–„â–„â–„
wandb:       eval/ensemble_f1 â–‡â–†â–†â–â–ƒâ–ˆâ–†â–…â–…â–…â–‡â–â–‡â–ƒâ–…â–ˆâ–…â–†â–…â–…â–ƒâ–„â–…â–‡â–„â–ƒâ–‚â–…â–†â–†â–ƒâ–„â–ˆâ–†â–„â–â–„â–†â–„â–„
wandb:           train/avg_f1 â–†â–…â–…â–‡â–†â–†â–„â–…â–†â–‡â–„â–†â–†â–…â–ƒâ–…â–â–…â–†â–…â–…â–…â–…â–…â–†â–†â–‚â–â–â–ˆâ–†â–„â–†â–ƒâ–‚â–†â–ƒâ–†â–‡â–
wandb:      train/ensemble_f1 â–„â–…â–„â–…â–…â–‚â–†â–†â–‡â–ƒâ–ˆâ–ƒâ–†â–‡â–ˆâ–…â–„â–„â–…â–â–†â–…â–‚â–ƒâ–„â–„â–‚â–‚â–‡â–†â–„â–„â–…â–„â–…â–…â–â–ƒâ–„â–†
wandb:         train/mil_loss â–†â–…â–‡â–‡â–ˆâ–…â–†â–†â–‚â–†â–„â–…â–†â–ƒâ–â–„â–„â–‚â–ƒâ–…â–…â–ƒâ–ƒâ–„â–„â–‚â–†â–‡â–‡â–„â–ƒâ–…â–‡â–…â–…â–„â–…â–‡â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–„â–„â–ˆâ–ˆâ–â–â–„â–â–â–„â–ˆâ–â–ˆâ–â–„â–„â–ˆâ–„â–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–ˆâ–â–â–„â–ˆâ–â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8493
wandb: best/eval_avg_mil_loss 0.39453
wandb:  best/eval_ensemble_f1 0.8493
wandb:            eval/avg_f1 0.797
wandb:      eval/avg_mil_loss 0.44909
wandb:       eval/ensemble_f1 0.797
wandb:           train/avg_f1 0.77854
wandb:      train/ensemble_f1 0.77854
wandb:         train/mil_loss 0.9806
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run treasured-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hclixsqo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063433-hclixsqo/logs
wandb: ERROR Run hclixsqo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: o5l8vugq with config:
wandb: 	actor_learning_rate: 2.0183424795667676e-05
wandb: 	attention_dropout_p: 0.25681844332071047
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33985806655418216
wandb: 	temperature: 4.669701639470377
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063810-o5l8vugq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5l8vugq
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–‡â–ƒâ–ˆâ–†â–†â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‡â–…â–…â–…â–ƒâ–†â–â–„â–‡â–†â–†â–ƒâ–†â–…â–‚â–ƒâ–†â–„â–…â–„â–†â–…â–â–†â–„â–†â–†â–†â–‡â–‡â–„â–ˆâ–†â–„â–‡â–ˆâ–…â–ƒ
wandb:      eval/avg_mil_loss â–â–ƒâ–„â–‚â–…â–‚â–‚â–…â–…â–ƒâ–‚â–‚â–ƒâ–„â–‚â–ƒâ–†â–…â–„â–…â–„â–‚â–„â–…â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–†â–‚â–â–‚â–ˆâ–„â–‚â–‚
wandb:       eval/ensemble_f1 â–„â–†â–„â–ƒâ–„â–„â–ƒâ–‡â–†â–…â–†â–…â–…â–‡â–‚â–†â–„â–…â–‚â–ƒâ–†â–„â–…â–†â–„â–„â–…â–â–„â–…â–†â–…â–†â–‚â–†â–ˆâ–†â–„â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–â–…â–„â–„â–ƒâ–‡â–…â–†â–…â–…â–‡â–…â–„â–ƒâ–ƒâ–„â–„â–‡â–ˆâ–‚â–†â–‚â–„â–…â–†â–…â–ƒâ–†â–…â–‡â–†â–†â–„â–†â–†â–‡â–ƒâ–‡â–…
wandb:      train/ensemble_f1 â–†â–â–†â–‚â–…â–‚â–„â–…â–‡â–…â–ˆâ–ˆâ–ƒâ–…â–„â–…â–‡â–ƒâ–„â–‡â–ƒâ–‚â–ƒâ–…â–†â–„â–†â–†â–ƒâ–†â–ƒâ–ƒâ–†â–‡â–ƒâ–…â–ƒâ–„â–†â–…
wandb:         train/mil_loss â–…â–†â–ƒâ–‡â–ƒâ–„â–†â–…â–„â–„â–„â–†â–„â–…â–„â–‡â–„â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–‡â–ƒâ–…â–ƒâ–…â–â–â–„â–‚â–…â–‚â–ƒâ–„â–„â–„â–‚â–ˆ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85247
wandb: best/eval_avg_mil_loss 0.31217
wandb:  best/eval_ensemble_f1 0.85247
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.3695
wandb:       eval/ensemble_f1 0.78993
wandb:            test/avg_f1 0.76975
wandb:      test/avg_mil_loss 0.48054
wandb:       test/ensemble_f1 0.76975
wandb:           train/avg_f1 0.81186
wandb:      train/ensemble_f1 0.81186
wandb:         train/mil_loss 0.91526
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o5l8vugq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063810-o5l8vugq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7lo89og3 with config:
wandb: 	actor_learning_rate: 0.0004361081684738414
wandb: 	attention_dropout_p: 0.1930354116806438
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.644992633424962
wandb: 	temperature: 8.709440996336351
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064015-7lo89og3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lo89og3
wandb: uploading wandb-summary.json
wandb: uploading history steps 99-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–â–‡â–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–„â–„â–…â–‡â–†â–†â–…â–„â–„â–ƒâ–â–ƒâ–„â–…â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–†â–‡â–„â–ˆâ–…â–ƒâ–…â–‡â–ƒâ–‡â–…â–†â–„â–†â–…â–…â–…â–„
wandb:      eval/avg_mil_loss â–â–…â–„â–ƒâ–„â–†â–ƒâ–„â–ˆâ–ƒâ–„â–ƒâ–â–…â–„â–…â–…â–ƒâ–ƒâ–„â–…â–…â–†â–„â–„â–ƒâ–†â–ƒâ–„â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–‡â–…â–‡â–‡â–„â–‡â–„â–‚â–‡â–‡â–ƒâ–…â–†â–…â–„â–†â–ƒâ–ƒâ–ƒâ–â–…â–†â–‚â–„â–„â–‡â–…â–…â–ƒâ–‡â–…â–†â–ƒâ–ƒâ–„â–‚â–„â–ˆâ–…â–ƒ
wandb:           train/avg_f1 â–†â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–…â–„â–„â–„â–…â–†â–„â–ˆâ–„â–ƒâ–â–„â–…â–…â–ˆâ–„â–ƒâ–ƒâ–…â–‚â–â–„â–„â–‡â–ƒâ–†â–…â–„â–„â–…
wandb:      train/ensemble_f1 â–†â–â–ƒâ–„â–…â–â–‚â–ƒâ–…â–…â–ƒâ–…â–„â–…â–„â–„â–…â–„â–ˆâ–…â–„â–†â–…â–„â–†â–…â–†â–…â–…â–ƒâ–„â–„â–‚â–…â–ƒâ–…â–„â–„â–‚â–„
wandb:         train/mil_loss â–ƒâ–…â–‡â–…â–„â–ˆâ–„â–‚â–†â–ƒâ–…â–…â–ƒâ–ƒâ–†â–…â–„â–„â–†â–â–ƒâ–ƒâ–„â–…â–…â–„â–â–ƒâ–†â–†â–ƒâ–‚â–„â–„â–„â–„â–†â–‚â–â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.35353
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.77353
wandb:      eval/avg_mil_loss 0.47789
wandb:       eval/ensemble_f1 0.77353
wandb:           train/avg_f1 0.79451
wandb:      train/ensemble_f1 0.79451
wandb:         train/mil_loss 0.88604
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lo89og3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064015-7lo89og3/logs
wandb: ERROR Run 7lo89og3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 0of6iu5d with config:
wandb: 	actor_learning_rate: 2.097169717184536e-06
wandb: 	attention_dropout_p: 0.31340350011156903
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5162390072682925
wandb: 	temperature: 3.6135859708196216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064213-0of6iu5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0of6iu5d
wandb: uploading history steps 128-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–â–„â–„â–‚â–…â–ƒâ–„â–„â–‡â–„â–ƒâ–ˆâ–†â–‚â–…â–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–…â–†â–â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–â–…â–…â–†â–‚â–ƒâ–„
wandb:      eval/avg_mil_loss â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–â–‚â–ƒâ–ƒâ–„â–„â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–‚â–…â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–ƒâ–‚â–…â–…â–‚â–†â–ƒâ–‡â–â–„â–†â–…â–‡â–‚â–†â–‡â–†â–†â–ƒâ–„â–„â–…â–…â–„â–†â–„â–†â–…â–‡â–…â–†â–„â–…â–ƒâ–â–ˆâ–„â–„â–ƒâ–…
wandb:           train/avg_f1 â–‡â–â–…â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–ƒâ–â–…â–„â–†â–†â–‚â–ƒâ–…â–‡â–ƒâ–„â–‚â–ƒâ–‡â–‚â–ˆâ–…â–‚â–†â–†â–†â–‚â–ƒâ–†â–‡â–ƒâ–†â–ƒâ–â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–†â–„â–ˆâ–ƒâ–„â–†â–…â–„â–…â–…â–‡â–ƒâ–‡â–‡â–„â–…â–…â–…â–„â–ˆâ–„â–„â–…â–„â–‡â–‡â–‡â–„â–â–†â–…â–‡â–‡â–†â–‡â–„â–ƒâ–‡â–ƒ
wandb:         train/mil_loss â–‡â–‡â–†â–…â–†â–‡â–„â–†â–…â–†â–…â–„â–„â–ˆâ–„â–„â–†â–ƒâ–…â–„â–ƒâ–„â–‡â–†â–ƒâ–‚â–…â–ƒâ–â–„â–‚â–„â–…â–…â–…â–„â–â–ƒâ–„â–‚
wandb:      train/policy_loss â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.40438
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.79882
wandb:      eval/avg_mil_loss 0.51525
wandb:       eval/ensemble_f1 0.79882
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 0.52068
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vital-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0of6iu5d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064213-0of6iu5d/logs
wandb: ERROR Run 0of6iu5d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: benk1yho with config:
wandb: 	actor_learning_rate: 5.527125683935725e-05
wandb: 	attention_dropout_p: 0.07191464283823917
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8179861764723424
wandb: 	temperature: 5.0353101483172935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064442-benk1yho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/benk1yho
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–â–‡
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–‡â–ƒâ–‚â–‚â–†â–†â–„â–ƒâ–ƒâ–‡â–„â–‡â–†â–‡â–…â–…â–…â–‡â–…â–‡â–‡â–„â–„â–‚â–ˆâ–†â–…â–ˆâ–…â–â–†â–ƒâ–„â–…â–†â–†â–…â–‡
wandb:      eval/avg_mil_loss â–‚â–…â–„â–ƒâ–‡â–„â–„â–„â–„â–ƒâ–…â–„â–…â–„â–†â–„â–…â–…â–ˆâ–†â–â–ƒâ–‚â–„â–…â–„â–†â–ƒâ–ˆâ–…â–†â–ƒâ–â–…â–†â–„â–…â–ƒâ–„â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–ƒâ–‚â–‚â–†â–…â–†â–…â–ƒâ–„â–†â–ƒâ–‡â–†â–‡â–…â–…â–‡â–…â–‡â–„â–„â–…â–‚â–ˆâ–…â–…â–ˆâ–…â–â–†â–†â–ƒâ–„â–…â–†â–†â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–‚â–ˆâ–†â–‡â–‚â–…â–…â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–„â–…â–†â–„â–‡â–„â–…â–‡â–ˆâ–â–„â–ˆâ–†â–ƒâ–„â–ƒâ–‚â–‡â–‡â–„â–‚â–ˆâ–ˆâ–…â–†
wandb:      train/ensemble_f1 â–„â–â–ˆâ–†â–‚â–‚â–†â–â–…â–â–â–…â–…â–…â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–…â–‡â–„â–„â–„â–ˆâ–†â–‚â–„â–‡â–„â–†â–ƒâ–‚â–‡â–ƒâ–‚â–ˆâ–ƒâ–„â–†
wandb:         train/mil_loss â–…â–„â–ƒâ–„â–†â–…â–ƒâ–…â–…â–†â–†â–ˆâ–„â–…â–ƒâ–„â–‚â–„â–â–ƒâ–ƒâ–…â–…â–†â–†â–†â–†â–†â–…â–„â–†â–„â–ƒâ–ƒâ–…â–â–…â–ƒâ–‡â–‡
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82388
wandb: best/eval_avg_mil_loss 0.45849
wandb:  best/eval_ensemble_f1 0.82388
wandb:            eval/avg_f1 0.81673
wandb:      eval/avg_mil_loss 0.39494
wandb:       eval/ensemble_f1 0.81673
wandb:            test/avg_f1 0.79632
wandb:      test/avg_mil_loss 0.53637
wandb:       test/ensemble_f1 0.79632
wandb:           train/avg_f1 0.80676
wandb:      train/ensemble_f1 0.80676
wandb:         train/mil_loss 0.61293
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sandy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/benk1yho
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064442-benk1yho/logs
wandb: Agent Starting Run: 63r5syxc with config:
wandb: 	actor_learning_rate: 1.4952699079472544e-06
wandb: 	attention_dropout_p: 0.02254830223188453
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8678030819170599
wandb: 	temperature: 9.908615621270991
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064555-63r5syxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63r5syxc
wandb: uploading history steps 110-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–†â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–…â–…â–†â–„â–„â–†â–ˆâ–…â–†â–…â–†â–ƒâ–‚â–„â–†â–…â–„â–…â–„â–†â–„â–„â–„â–„â–„â–†â–â–†â–†â–…â–„â–‡â–‡â–†â–…â–‡â–…â–ƒâ–…â–‚
wandb:      eval/avg_mil_loss â–†â–…â–ƒâ–â–„â–‚â–„â–…â–…â–‚â–†â–†â–ƒâ–ƒâ–…â–‚â–‚â–‡â–ƒâ–…â–…â–†â–…â–ƒâ–…â–‚â–‡â–‡â–…â–…â–ƒâ–‚â–„â–…â–‚â–‡â–…â–†â–ƒâ–ˆ
wandb:       eval/ensemble_f1 â–…â–„â–†â–ƒâ–…â–ƒâ–†â–ƒâ–„â–…â–†â–†â–‚â–‚â–„â–…â–„â–†â–â–…â–ƒâ–ƒâ–„â–…â–‡â–†â–…â–…â–‡â–ƒâ–ˆâ–ƒâ–„â–„â–ƒâ–„â–‡â–„â–‚â–…
wandb:           train/avg_f1 â–â–‚â–„â–†â–„â–…â–…â–†â–ƒâ–‚â–ˆâ–…â–…â–…â–‡â–„â–…â–‡â–†â–†â–…â–‡â–„â–†â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–„â–‡â–‡â–…â–â–…â–…â–†â–„â–‚
wandb:      train/ensemble_f1 â–ˆâ–„â–„â–…â–…â–…â–„â–â–„â–…â–…â–„â–‚â–†â–†â–ƒâ–„â–‡â–„â–„â–„â–„â–„â–„â–…â–„â–‚â–…â–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–„
wandb:         train/mil_loss â–‡â–‡â–…â–ˆâ–ƒâ–†â–ˆâ–†â–ˆâ–†â–…â–„â–„â–ƒâ–ˆâ–ƒâ–„â–„â–†â–„â–„â–ƒâ–†â–…â–‡â–„â–†â–„â–…â–‡â–â–„â–†â–‡â–„â–ˆâ–†â–†â–†â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.38176
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.79808
wandb:      eval/avg_mil_loss 0.45142
wandb:       eval/ensemble_f1 0.79808
wandb:           train/avg_f1 0.78334
wandb:      train/ensemble_f1 0.78334
wandb:         train/mil_loss 0.95703
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dry-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63r5syxc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064555-63r5syxc/logs
wandb: ERROR Run 63r5syxc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7i5e7nqc with config:
wandb: 	actor_learning_rate: 8.033187984703708e-06
wandb: 	attention_dropout_p: 0.44504025578562834
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44956346630870714
wandb: 	temperature: 8.465640762721304
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064830-7i5e7nqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i5e7nqc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 42-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–…â–â–â–ƒâ–ƒâ–†â–‚â–‚â–„â–†â–‡â–ˆâ–†â–†â–†â–…â–‡â–…â–ƒâ–„â–…â–‡â–‡â–†â–ƒâ–…â–†â–‚â–‚â–†â–„â–†â–†â–ˆâ–„â–ˆâ–…â–„
wandb:      eval/avg_mil_loss â–…â–ƒâ–†â–„â–ƒâ–ˆâ–â–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–„â–‡â–‚â–†â–„â–…â–…â–†â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–„â–†â–‚â–ƒâ–„â–„â–‡â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–â–…â–ƒâ–ƒâ–†â–ƒâ–‚â–„â–‡â–ˆâ–†â–ƒâ–†â–…â–‡â–…â–â–ƒâ–…â–‡â–„â–‡â–†â–…â–†â–‚â–†â–‚â–„â–†â–ƒâ–†â–ˆâ–ˆâ–„â–ˆâ–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–â–…â–„â–ˆâ–…â–†â–„â–‚â–…â–ƒâ–…â–ƒâ–‡â–â–†â–†â–„â–‚â–‡â–‡â–…â–„â–ƒâ–…â–…â–„â–…â–…â–…â–†â–‡â–…â–ƒâ–…â–†â–†â–â–…
wandb:      train/ensemble_f1 â–ƒâ–â–„â–„â–…â–„â–…â–†â–„â–„â–ˆâ–„â–ƒâ–†â–ƒâ–…â–‚â–…â–ƒâ–‚â–†â–†â–„â–ƒâ–ƒâ–„â–„â–…â–…â–†â–…â–†â–„â–ƒâ–‚â–„â–…â–…â–â–„
wandb:         train/mil_loss â–ƒâ–ƒâ–â–ƒâ–„â–„â–ƒâ–ƒâ–†â–„â–‚â–†â–…â–„â–„â–„â–ƒâ–…â–‚â–‚â–„â–â–„â–„â–â–ƒâ–…â–†â–…â–…â–…â–â–ˆâ–ƒâ–†â–…â–†â–†â–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8348
wandb: best/eval_avg_mil_loss 0.40892
wandb:  best/eval_ensemble_f1 0.8348
wandb:            eval/avg_f1 0.79453
wandb:      eval/avg_mil_loss 0.39308
wandb:       eval/ensemble_f1 0.79453
wandb:            test/avg_f1 0.79863
wandb:      test/avg_mil_loss 0.45095
wandb:       test/ensemble_f1 0.79863
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 0.79692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7i5e7nqc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064830-7i5e7nqc/logs
wandb: Agent Starting Run: 4g0uz9x7 with config:
wandb: 	actor_learning_rate: 1.080129141689561e-05
wandb: 	attention_dropout_p: 0.24043351517525616
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.36693036252514144
wandb: 	temperature: 4.5491379103783345
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064932-4g0uz9x7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g0uz9x7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–„â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–â–„â–ƒâ–„â–„â–†â–â–†â–ƒâ–ƒâ–ƒâ–…â–‡â–â–„â–ƒâ–†â–†â–‚â–„â–†â–„â–„â–‚â–†â–†â–ƒâ–†â–†â–„â–…â–ˆâ–„â–ƒâ–‚â–†â–‚â–…â–‚
wandb:      eval/avg_mil_loss â–„â–…â–†â–ƒâ–…â–†â–„â–…â–„â–ƒâ–ƒâ–†â–†â–†â–ƒâ–„â–ƒâ–„â–…â–‡â–â–„â–ƒâ–ˆâ–„â–…â–‡â–ˆâ–†â–â–„â–‚â–†â–‡â–†â–ƒâ–„â–‡â–„â–ˆ
wandb:       eval/ensemble_f1 â–†â–‡â–†â–â–„â–„â–…â–†â–ˆâ–‡â–‚â–…â–‚â–…â–…â–ˆâ–ˆâ–‡â–„â–†â–†â–…â–…â–ƒâ–ƒâ–…â–†â–†â–„â–‡â–ˆâ–†â–‚â–„â–…â–‡â–‡â–…â–ƒâ–ƒ
wandb:           train/avg_f1 â–â–„â–‚â–…â–…â–„â–ƒâ–ƒâ–†â–†â–…â–ˆâ–‡â–„â–‡â–ˆâ–ƒâ–†â–„â–…â–†â–ƒâ–„â–…â–…â–…â–„â–†â–„â–ƒâ–…â–…â–…â–ƒâ–‡â–†â–ƒâ–„â–„â–‡
wandb:      train/ensemble_f1 â–†â–„â–†â–ƒâ–…â–†â–…â–‚â–ƒâ–‚â–‚â–‡â–„â–ˆâ–†â–†â–„â–ƒâ–…â–ƒâ–ƒâ–†â–…â–„â–†â–…â–†â–ˆâ–…â–…â–‡â–‚â–‡â–†â–‡â–ˆâ–â–ƒâ–‚â–‚
wandb:         train/mil_loss â–…â–ˆâ–…â–…â–…â–â–ƒâ–…â–ƒâ–…â–‚â–„â–ˆâ–…â–…â–ƒâ–…â–ƒâ–…â–…â–…â–‡â–ƒâ–…â–‚â–„â–„â–…â–…â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–ˆâ–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84911
wandb: best/eval_avg_mil_loss 0.29582
wandb:  best/eval_ensemble_f1 0.84911
wandb:            eval/avg_f1 0.7796
wandb:      eval/avg_mil_loss 0.55434
wandb:       eval/ensemble_f1 0.7796
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 1.04811
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run winter-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g0uz9x7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064932-4g0uz9x7/logs
wandb: ERROR Run 4g0uz9x7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: c19j8d4v with config:
wandb: 	actor_learning_rate: 0.0001980558358184728
wandb: 	attention_dropout_p: 0.42222804819807
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6287252685648426
wandb: 	temperature: 3.181834864951183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065202-c19j8d4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c19j8d4v
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–…â–„â–ˆâ–†â–…â–ƒâ–†â–ƒâ–…â–‚â–…â–†â–ƒâ–‚â–†â–ƒâ–…â–…â–‚â–ƒâ–‚â–â–„â–„â–ƒâ–‚â–â–‚â–„â–…â–„â–…â–ƒâ–„â–ˆâ–„â–‚â–…
wandb:      eval/avg_mil_loss â–„â–‚â–…â–…â–ˆâ–†â–‚â–„â–…â–ƒâ–…â–„â–ƒâ–ƒâ–„â–â–‡â–†â–…â–‚â–†â–„â–‡â–…â–„â–„â–†â–†â–ƒâ–…â–‚â–„â–†â–†â–…â–‚â–‡â–†â–„â–„
wandb:       eval/ensemble_f1 â–…â–„â–‚â–…â–„â–‚â–…â–„â–†â–…â–„â–…â–…â–‚â–…â–†â–ƒâ–ƒâ–†â–ƒâ–…â–…â–ƒâ–„â–‚â–…â–‚â–„â–„â–‚â–‚â–†â–„â–…â–ƒâ–„â–ˆâ–„â–ƒâ–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–‡â–…â–ƒâ–†â–…â–†â–ƒâ–‚â–„â–†â–„â–‚â–„â–†â–‚â–…â–ƒâ–„â–ƒâ–„â–‚â–â–„â–ˆâ–„â–…â–„â–ƒâ–ƒâ–„â–‚â–‡â–„â–„â–†â–ƒâ–‡â–„
wandb:      train/ensemble_f1 â–…â–ƒâ–‡â–…â–„â–„â–ƒâ–…â–†â–‡â–…â–„â–†â–„â–ˆâ–„â–„â–ƒâ–„â–†â–„â–ƒâ–†â–…â–„â–ƒâ–…â–ƒâ–„â–â–‚â–ˆâ–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–ˆâ–„
wandb:         train/mil_loss â–…â–‚â–…â–‚â–ƒâ–ƒâ–„â–„â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–„â–‚â–ƒâ–„â–‡â–‚â–†â–â–‚â–„â–ˆâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„
wandb:      train/policy_loss â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–â–ˆâ–â–â–…â–…â–ˆâ–â–…â–â–â–…â–â–…â–…â–…â–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ˆâ–ˆâ–â–…â–…â–â–…â–â–â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–â–â–â–…â–…â–ˆâ–â–â–â–…â–â–…â–â–…â–ˆâ–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.39411
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.78045
wandb:      eval/avg_mil_loss 0.44936
wandb:       eval/ensemble_f1 0.78045
wandb:            test/avg_f1 0.79264
wandb:      test/avg_mil_loss 0.51658
wandb:       test/ensemble_f1 0.79264
wandb:           train/avg_f1 0.79726
wandb:      train/ensemble_f1 0.79726
wandb:         train/mil_loss 0.56583
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c19j8d4v
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065202-c19j8d4v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8t1bqn58 with config:
wandb: 	actor_learning_rate: 3.0864903179165715e-05
wandb: 	attention_dropout_p: 0.2932568658567633
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.373002710407901
wandb: 	temperature: 3.546095128744138
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065332-8t1bqn58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8t1bqn58
wandb: uploading wandb-summary.json
wandb: uploading history steps 97-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–…â–ƒâ–„â–…â–ƒâ–„â–‚â–ƒâ–…â–‡â–…â–„â–…â–‚â–ƒâ–„â–…â–„â–‡â–„â–…â–â–â–ˆâ–„â–„â–„â–†â–ƒâ–†â–†â–„â–„â–…â–…â–…â–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–†â–ƒâ–…â–‡â–‡â–‡â–…â–…â–†â–†â–â–†â–…â–†â–…â–…â–†â–†â–‡â–‡â–…â–ˆâ–ƒâ–‚â–†â–…â–…â–„â–ˆâ–ˆâ–…â–ƒâ–„â–…â–†â–‚â–„â–†â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–„â–…â–…â–†â–ƒâ–…â–„â–†â–„â–„â–†â–ˆâ–…â–†â–†â–†â–ƒâ–‡â–†â–â–‡â–…â–â–„â–„â–†â–…â–‡â–ˆâ–…â–„â–…â–…â–†â–†â–ˆâ–†â–†
wandb:           train/avg_f1 â–ƒâ–‡â–â–…â–ƒâ–…â–…â–†â–†â–†â–ƒâ–…â–†â–ƒâ–ƒâ–…â–‚â–…â–„â–ƒâ–ƒâ–…â–…â–„â–†â–ƒâ–„â–„â–ƒâ–„â–„â–â–ƒâ–…â–‚â–„â–„â–…â–ˆâ–†
wandb:      train/ensemble_f1 â–‡â–â–ƒâ–ƒâ–…â–†â–†â–…â–…â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–…â–ƒâ–„â–‚â–„â–…â–ƒâ–†â–†â–„â–ƒâ–„â–„â–ƒâ–†â–ƒâ–ƒâ–…â–„â–…â–„â–‚â–ˆâ–†
wandb:         train/mil_loss â–†â–‡â–†â–„â–ƒâ–†â–‡â–…â–ˆâ–ƒâ–ƒâ–„â–„â–‡â–„â–„â–…â–…â–‚â–‡â–ˆâ–†â–…â–…â–…â–‡â–†â–„â–ƒâ–„â–…â–â–„â–†â–…â–„â–†â–â–…â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.38759
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.7876
wandb:      eval/avg_mil_loss 0.45528
wandb:       eval/ensemble_f1 0.7876
wandb:           train/avg_f1 0.78724
wandb:      train/ensemble_f1 0.78724
wandb:         train/mil_loss 0.5237
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8t1bqn58
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065332-8t1bqn58/logs
wandb: ERROR Run 8t1bqn58 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 66umpcxx with config:
wandb: 	actor_learning_rate: 0.00034342152749521044
wandb: 	attention_dropout_p: 0.13881948016593043
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6114425842359235
wandb: 	temperature: 7.453754471777558
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065536-66umpcxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66umpcxx
wandb: uploading history steps 181-183, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–ƒâ–‡â–„â–„â–â–…
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–ƒâ–„â–‡â–‚â–„â–ˆâ–…â–ƒâ–…â–„â–„â–„â–ƒâ–‡â–ƒâ–â–ˆâ–…â–„â–†â–„â–…â–…â–…â–…â–†â–…â–„â–„â–‡â–„â–ƒâ–…â–„â–†â–ƒâ–‚
wandb:      eval/avg_mil_loss â–„â–„â–‡â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–†â–„â–â–†â–„â–†â–„â–ƒâ–…â–…â–…â–„â–„â–…â–†â–…â–…â–…â–…â–„â–…â–„â–„â–…â–†â–…â–…â–ƒâ–†â–†
wandb:       eval/ensemble_f1 â–â–†â–…â–†â–†â–…â–„â–‚â–†â–ƒâ–‡â–†â–„â–†â–‡â–ˆâ–ƒâ–„â–ƒâ–‡â–…â–†â–‡â–‡â–„â–…â–„â–…â–„â–…â–„â–†â–‡â–ƒâ–‡â–†â–…â–ƒâ–†â–„
wandb:           train/avg_f1 â–‡â–‡â–†â–‡â–†â–‚â–„â–ˆâ–ƒâ–…â–…â–â–ˆâ–ˆâ–ƒâ–…â–…â–‡â–†â–„â–ƒâ–…â–†â–ƒâ–„â–†â–„â–…â–‚â–…â–‡â–†â–„â–†â–ƒâ–†â–ƒâ–†â–‡â–„
wandb:      train/ensemble_f1 â–†â–‡â–†â–ˆâ–†â–…â–‡â–…â–„â–†â–‡â–†â–„â–‡â–†â–†â–ƒâ–ƒâ–…â–„â–†â–„â–†â–…â–†â–†â–ƒâ–„â–„â–„â–…â–…â–â–„â–„â–„â–„â–‡â–†â–‚
wandb:         train/mil_loss â–„â–†â–†â–‡â–ˆâ–†â–„â–…â–†â–‚â–ƒâ–†â–„â–â–„â–†â–„â–‚â–ƒâ–…â–†â–†â–…â–…â–„â–„â–„â–†â–…â–„â–†â–†â–„â–‡â–ƒâ–ˆâ–ƒâ–‡â–ˆâ–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84195
wandb: best/eval_avg_mil_loss 0.4325
wandb:  best/eval_ensemble_f1 0.84195
wandb:            eval/avg_f1 0.79022
wandb:      eval/avg_mil_loss 0.45811
wandb:       eval/ensemble_f1 0.79022
wandb:           train/avg_f1 0.78236
wandb:      train/ensemble_f1 0.78236
wandb:         train/mil_loss 0.95534
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66umpcxx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065536-66umpcxx/logs
wandb: ERROR Run 66umpcxx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: r8zt2q8b with config:
wandb: 	actor_learning_rate: 2.8455568801427784e-05
wandb: 	attention_dropout_p: 0.1895514371234885
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.733912486300657
wandb: 	temperature: 0.30900637331922054
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065927-r8zt2q8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r8zt2q8b
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ƒâ–‡â–â–ˆâ–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–†â–‚â–ƒâ–ƒâ–…â–‡â–ƒâ–â–‡â–…â–…â–…â–‚â–ƒâ–†â–ƒâ–„â–ƒâ–‡â–…â–ƒâ–„â–â–†â–„â–ƒâ–†â–ˆâ–…â–†â–…â–†â–†â–…â–„â–…â–†â–„â–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–…â–‚â–…â–…â–ˆâ–â–ƒâ–„â–…â–†â–„â–„â–„â–„â–…â–„â–â–ƒâ–„â–…â–ƒâ–†â–†â–ƒâ–†â–‚â–„â–…â–…â–ƒâ–…â–‚â–„â–…â–„â–„â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–…â–‚â–‡â–ƒâ–ƒâ–‚â–â–†â–…â–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–‡â–…â–â–†â–‡â–ƒâ–ƒâ–†â–…â–â–†â–…â–ƒâ–‡â–ˆâ–…â–„â–…â–…
wandb:           train/avg_f1 â–„â–„â–…â–„â–†â–ˆâ–„â–†â–ƒâ–‡â–…â–„â–…â–…â–…â–†â–ƒâ–â–„â–ƒâ–†â–„â–…â–ƒâ–ƒâ–†â–†â–ƒâ–„â–…â–†â–ˆâ–†â–„â–‚â–ƒâ–ƒâ–†â–†â–…
wandb:      train/ensemble_f1 â–†â–ƒâ–„â–ƒâ–…â–„â–ƒâ–ˆâ–‡â–‚â–„â–…â–„â–…â–†â–„â–‚â–‡â–ƒâ–ƒâ–‡â–‚â–ƒâ–…â–†â–„â–…â–ƒâ–…â–ˆâ–ƒâ–â–…â–‚â–…â–…â–‚â–…â–‡â–…
wandb:         train/mil_loss â–„â–ƒâ–ƒâ–„â–„â–„â–ƒâ–ˆâ–ƒâ–…â–‡â–‡â–†â–„â–â–„â–†â–„â–ˆâ–†â–ƒâ–„â–ƒâ–…â–â–„â–…â–„â–„â–…â–„â–…â–…â–…â–…â–„â–…â–„â–„â–ˆ
wandb:      train/policy_loss â–ˆâ–â–â–ˆâ–ˆâ–â–„â–ˆâ–ˆâ–â–„â–„â–â–„â–„â–ˆâ–ˆâ–„â–â–„â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–â–ˆâ–â–„â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–ˆâ–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–â–…â–ˆâ–ˆâ–â–…â–ˆâ–â–…â–ˆâ–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84532
wandb: best/eval_avg_mil_loss 0.41637
wandb:  best/eval_ensemble_f1 0.84532
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.41833
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.80591
wandb:      train/ensemble_f1 0.80591
wandb:         train/mil_loss 0.8631
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r8zt2q8b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065927-r8zt2q8b/logs
wandb: ERROR Run r8zt2q8b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 799pte77 with config:
wandb: 	actor_learning_rate: 6.1967504308904e-05
wandb: 	attention_dropout_p: 0.26102927305730284
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8930150470286452
wandb: 	temperature: 7.933579385817893
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070126-799pte77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/799pte77
wandb: uploading history steps 96-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‚â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–†â–†â–ƒâ–†â–ƒâ–„â–…â–‡â–‚â–…â–‡â–…â–ƒâ–ƒâ–‚â–â–‚â–â–ˆâ–„â–†â–ƒâ–‚â–â–†â–‚â–ƒâ–„â–â–…â–ƒâ–…â–„â–†â–‚â–‚â–‚â–ƒ
wandb:      eval/avg_mil_loss â–â–ƒâ–‚â–„â–„â–„â–„â–„â–‚â–‚â–‚â–†â–…â–ƒâ–â–‚â–„â–„â–â–ƒâ–…â–…â–†â–„â–…â–‚â–ˆâ–„â–„â–„â–…â–‚â–ƒâ–„â–„â–‡â–‚â–‚â–‚â–ƒ
wandb:       eval/ensemble_f1 â–†â–†â–‡â–†â–…â–…â–†â–‡â–„â–ˆâ–…â–†â–ˆâ–‡â–…â–…â–†â–…â–…â–â–†â–„â–…â–…â–„â–†â–ˆâ–†â–„â–„â–†â–…â–…â–„â–„â–…â–„â–…â–ˆâ–…
wandb:           train/avg_f1 â–…â–‡â–†â–„â–ƒâ–ƒâ–„â–…â–†â–†â–ƒâ–…â–‡â–„â–„â–†â–ƒâ–ˆâ–‡â–ƒâ–†â–ƒâ–„â–†â–…â–„â–‡â–†â–ƒâ–†â–‡â–…â–…â–†â–†â–„â–â–†â–…â–‡
wandb:      train/ensemble_f1 â–…â–†â–†â–…â–…â–‚â–‡â–‚â–ƒâ–„â–†â–‡â–…â–…â–‚â–ƒâ–‚â–ƒâ–†â–‚â–„â–†â–‚â–„â–ˆâ–â–ƒâ–ƒâ–ƒâ–„â–…â–„â–„â–‡â–…â–â–‚â–„â–â–…
wandb:         train/mil_loss â–ƒâ–„â–„â–ƒâ–â–…â–„â–ƒâ–…â–ƒâ–ƒâ–†â–‚â–…â–„â–‚â–…â–‚â–„â–‡â–†â–‚â–‚â–„â–†â–…â–…â–…â–†â–…â–ˆâ–‚â–ƒâ–ˆâ–…â–…â–ˆâ–†â–‚â–ƒ
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–ˆâ–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–‡â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.40706
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.76163
wandb:      eval/avg_mil_loss 0.48367
wandb:       eval/ensemble_f1 0.76163
wandb:           train/avg_f1 0.80628
wandb:      train/ensemble_f1 0.80628
wandb:         train/mil_loss 0.99802
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misunderstood-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/799pte77
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070126-799pte77/logs
wandb: ERROR Run 799pte77 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mhm98c05 with config:
wandb: 	actor_learning_rate: 2.3091439855447767e-06
wandb: 	attention_dropout_p: 0.4267448702077194
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07535362878752905
wandb: 	temperature: 1.4519759639619878
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070346-mhm98c05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mhm98c05
wandb: uploading wandb-summary.json
wandb: uploading history steps 96-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–†â–ˆ
wandb:            eval/avg_f1 â–â–„â–‡â–„â–ƒâ–‚â–„â–„â–‚â–„â–‡â–†â–…â–‚â–…â–‚â–„â–„â–‡â–â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–„â–†â–‚â–ƒâ–‚â–‚â–ƒâ–…â–„â–…â–…â–†â–â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–…â–†â–„â–â–ƒâ–…â–ˆâ–ƒâ–…â–‚â–„â–…â–…â–†â–„â–â–„â–‚â–…â–„â–‚â–†â–‡â–‚â–‚â–†â–‚â–…â–„â–…â–„â–â–ƒâ–‚â–ƒâ–ˆâ–„â–†â–â–…
wandb:       eval/ensemble_f1 â–‚â–…â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–„â–â–‚â–„â–…â–‚â–…â–ƒâ–ƒâ–„â–…â–…â–„â–ˆâ–ƒâ–„â–„â–†â–„â–†â–…â–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–„â–‚â–‡
wandb:           train/avg_f1 â–ƒâ–‚â–…â–„â–…â–…â–†â–‡â–„â–…â–ƒâ–„â–ƒâ–…â–ˆâ–‚â–„â–ˆâ–„â–â–ƒâ–„â–„â–†â–ˆâ–…â–„â–â–„â–…â–„â–ƒâ–‚â–ƒâ–‡â–ƒâ–…â–‚â–ƒâ–†
wandb:      train/ensemble_f1 â–…â–‚â–„â–„â–…â–…â–…â–†â–†â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–„â–…â–„â–„â–„â–…â–‚â–‡â–‡â–‡â–„â–ˆâ–…â–„â–â–…â–‡â–â–…â–â–…â–ˆâ–‡â–„
wandb:         train/mil_loss â–„â–„â–‚â–…â–…â–„â–„â–„â–‡â–†â–„â–…â–‡â–…â–„â–â–†â–‡â–â–‚â–ƒâ–‡â–†â–ˆâ–†â–ƒâ–‚â–…â–ƒâ–†â–…â–…â–„â–†â–„â–‚â–„â–…â–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.40898
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79545
wandb:      eval/avg_mil_loss 0.4444
wandb:       eval/ensemble_f1 0.79545
wandb:           train/avg_f1 0.79497
wandb:      train/ensemble_f1 0.79497
wandb:         train/mil_loss 0.84981
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mhm98c05
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070346-mhm98c05/logs
wandb: ERROR Run mhm98c05 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: exht1k9z with config:
wandb: 	actor_learning_rate: 0.000193747968707792
wandb: 	attention_dropout_p: 0.34671910350467744
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3118572169766598
wandb: 	temperature: 4.920361012095537
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070615-exht1k9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/exht1k9z
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–„â–â–…
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–…â–„â–ƒâ–…â–…â–„â–ƒâ–„â–â–„â–„â–‡â–â–†â–‡â–„â–ƒâ–ƒâ–„â–‡â–ˆâ–„â–†â–„â–‚â–…â–†â–„â–‚â–„â–‚â–…â–†â–‡â–ƒâ–…â–†â–ˆ
wandb:      eval/avg_mil_loss â–…â–…â–„â–„â–…â–ƒâ–‡â–‚â–†â–…â–ƒâ–‚â–â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–„â–ƒâ–‡â–„â–ƒâ–‚â–…â–‚â–ƒâ–…â–‡â–‚â–ˆâ–…â–‚â–‚â–…â–…
wandb:       eval/ensemble_f1 â–…â–…â–â–„â–…â–…â–…â–„â–…â–…â–ƒâ–„â–†â–‡â–„â–„â–‡â–ˆâ–„â–ƒâ–„â–„â–†â–†â–…â–„â–…â–†â–…â–„â–…â–„â–…â–‡â–„â–‡â–†â–†â–„â–„
wandb:           train/avg_f1 â–ˆâ–â–ƒâ–„â–‚â–†â–…â–‡â–ƒâ–‚â–…â–†â–‡â–‚â–†â–„â–‚â–ˆâ–„â–ƒâ–ƒâ–â–…â–„â–ƒâ–…â–‡â–…â–ˆâ–‡â–„â–â–‡â–…â–†â–ƒâ–…â–â–ƒâ–‡
wandb:      train/ensemble_f1 â–â–†â–ˆâ–†â–‚â–ˆâ–„â–„â–„â–…â–†â–„â–†â–ˆâ–ƒâ–‡â–ˆâ–ƒâ–…â–†â–…â–ˆâ–„â–‡â–‚â–…â–…â–‡â–‡â–‡â–‚â–â–„â–…â–„â–…â–„â–…â–„â–ˆ
wandb:         train/mil_loss â–‚â–„â–ƒâ–â–†â–‚â–„â–â–„â–â–â–„â–‚â–â–â–…â–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–„â–ˆâ–â–‚â–„â–ƒâ–„â–„â–ƒâ–‚â–„â–„â–‚â–„â–‚â–â–ˆâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84867
wandb: best/eval_avg_mil_loss 0.41856
wandb:  best/eval_ensemble_f1 0.84867
wandb:            eval/avg_f1 0.80563
wandb:      eval/avg_mil_loss 0.44318
wandb:       eval/ensemble_f1 0.80563
wandb:           train/avg_f1 0.80901
wandb:      train/ensemble_f1 0.80901
wandb:         train/mil_loss 0.86582
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweet-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/exht1k9z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070615-exht1k9z/logs
wandb: ERROR Run exht1k9z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: vhz98u4g with config:
wandb: 	actor_learning_rate: 1.1965889530724692e-05
wandb: 	attention_dropout_p: 0.06381761453587714
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5102986332019012
wandb: 	temperature: 1.4487983370353508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070907-vhz98u4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhz98u4g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–†â–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–†â–‡â–„â–„â–ƒâ–…â–…â–†â–ˆâ–†â–†â–ƒâ–„â–†â–†â–…â–‡â–ƒâ–…â–ƒâ–…â–„â–†â–â–ƒâ–„â–‚â–…â–…â–†â–‚â–…â–…â–…â–ƒâ–†â–„â–…â–ˆ
wandb:      eval/avg_mil_loss â–‡â–…â–†â–„â–†â–ƒâ–…â–‡â–†â–ˆâ–…â–‚â–…â–„â–…â–ƒâ–…â–…â–…â–…â–„â–†â–â–„â–‡â–†â–„â–…â–…â–†â–„â–‡â–…â–…â–†â–ƒâ–†â–…â–‚â–†
wandb:       eval/ensemble_f1 â–â–„â–‚â–„â–ƒâ–†â–ƒâ–‡â–‡â–†â–‡â–†â–ƒâ–ƒâ–…â–…â–†â–…â–ƒâ–…â–…â–…â–ˆâ–…â–…â–…â–†â–†â–…â–…â–…â–„â–„â–…â–…â–…â–…â–…â–„â–…
wandb:           train/avg_f1 â–†â–„â–‚â–‚â–‚â–‚â–„â–â–…â–…â–…â–„â–…â–„â–‚â–„â–‚â–†â–ƒâ–ƒâ–„â–ˆâ–‚â–„â–…â–ƒâ–‚â–â–ƒâ–„â–‚â–ˆâ–ƒâ–ƒâ–â–‚â–ƒâ–„â–…â–„
wandb:      train/ensemble_f1 â–†â–†â–ƒâ–‚â–ƒâ–†â–…â–…â–†â–ƒâ–„â–†â–â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–„â–„â–…â–ƒâ–…â–„â–…â–…â–†â–ƒâ–„â–ƒâ–‚â–ˆâ–‚â–…â–…â–†â–…â–„
wandb:         train/mil_loss â–â–…â–‡â–‡â–…â–„â–ƒâ–†â–„â–„â–†â–…â–„â–„â–…â–„â–ƒâ–…â–†â–ˆâ–ƒâ–…â–…â–ƒâ–…â–ƒâ–â–„â–…â–…â–†â–…â–„â–†â–‡â–…â–†â–…â–†â–„
wandb:      train/policy_loss â–ˆâ–…â–â–ˆâ–â–â–ˆâ–â–â–…â–ˆâ–…â–…â–â–â–…â–…â–…â–ˆâ–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–â–â–ˆâ–â–â–…â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–„â–â–ˆâ–ˆâ–â–â–â–â–„â–â–â–â–„â–„â–„â–„â–â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–ˆâ–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.38335
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.78804
wandb:      eval/avg_mil_loss 0.51448
wandb:       eval/ensemble_f1 0.78804
wandb:           train/avg_f1 0.79174
wandb:      train/ensemble_f1 0.79174
wandb:         train/mil_loss 0.53728
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run astral-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vhz98u4g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070907-vhz98u4g/logs
wandb: ERROR Run vhz98u4g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xs9s7thr with config:
wandb: 	actor_learning_rate: 3.335586893536953e-05
wandb: 	attention_dropout_p: 0.48901090923168095
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.318249088271953
wandb: 	temperature: 9.7173192104332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071232-xs9s7thr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xs9s7thr
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 83-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–‡â–…â–‡â–…â–†â–…â–…â–…â–‡â–†â–„â–…â–‡â–ƒâ–„â–†â–†â–„â–„â–…â–†â–â–…â–ƒâ–†â–†â–†â–…â–…â–†â–…â–…â–†â–†â–„â–‡â–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–„â–ƒâ–„â–†â–…â–„â–ƒâ–…â–‚â–…â–…â–†â–ƒâ–ƒâ–‚â–ˆâ–†â–„â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–„â–„â–‚â–‚â–â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–„â–†â–…â–„â–†â–„â–…â–†â–†â–„â–„â–„â–…â–†â–„â–ƒâ–ƒâ–„â–„â–ƒâ–†â–â–…â–†â–„â–…â–…â–…â–…â–„â–…â–ƒâ–†â–„â–„â–ˆâ–…â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–…â–†â–…â–…â–ƒâ–‡â–‡â–†â–‡â–ˆâ–…â–‡â–…â–ˆâ–‡â–ˆâ–â–„â–‚â–ˆâ–†â–…â–†â–†â–‡â–„â–„â–ˆâ–…â–ƒâ–†â–…â–„â–†â–†â–‡â–†â–‡
wandb:      train/ensemble_f1 â–…â–…â–‡â–…â–…â–â–„â–ˆâ–ƒâ–†â–†â–†â–…â–†â–„â–„â–ˆâ–†â–‡â–„â–…â–„â–„â–ˆâ–‡â–†â–†â–‡â–„â–ˆâ–†â–ƒâ–„â–„â–‡â–‡â–…â–…â–†â–‡
wandb:         train/mil_loss â–…â–ˆâ–†â–†â–†â–ˆâ–†â–ƒâ–‡â–‡â–â–†â–†â–†â–„â–‚â–„â–‡â–„â–†â–†â–„â–‡â–ƒâ–†â–ˆâ–†â–„â–†â–‡â–†â–ƒâ–‡â–…â–„â–…â–‡â–…â–ƒâ–…
wandb:      train/policy_loss â–„â–„â–„â–â–„â–â–â–„â–â–„â–â–â–â–â–ˆâ–ˆâ–â–„â–„â–„â–ˆâ–ˆâ–â–„â–â–â–â–ˆâ–ˆâ–„â–â–„â–„â–â–„â–ˆâ–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–…â–â–ˆâ–â–…â–â–…â–…â–â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–…â–â–…â–â–ˆâ–…â–â–â–…â–ˆâ–…â–…â–…â–â–â–â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.40693
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.78814
wandb:      eval/avg_mil_loss 0.46435
wandb:       eval/ensemble_f1 0.78814
wandb:            test/avg_f1 0.74794
wandb:      test/avg_mil_loss 0.51347
wandb:       test/ensemble_f1 0.74794
wandb:           train/avg_f1 0.7962
wandb:      train/ensemble_f1 0.7962
wandb:         train/mil_loss 0.87942
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glowing-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xs9s7thr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071232-xs9s7thr/logs
wandb: Agent Starting Run: ux20595d with config:
wandb: 	actor_learning_rate: 3.3877065914155637e-06
wandb: 	attention_dropout_p: 0.2821048576551818
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 95
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34970331331723514
wandb: 	temperature: 3.828340015358415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071411-ux20595d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux20595d
wandb: uploading history steps 94-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆ
wandb:            eval/avg_f1 â–‚â–ˆâ–‚â–†â–‚â–…â–…â–…â–…â–…â–†â–â–†â–…â–…â–‡â–†â–…â–…â–„â–‚â–‡â–ƒâ–‚â–„â–…â–„â–†â–„â–…â–…â–†â–‡â–…â–â–…â–…â–„â–…â–„
wandb:      eval/avg_mil_loss â–ˆâ–…â–‚â–ƒâ–â–†â–‚â–ƒâ–„â–†â–…â–‚â–‚â–…â–â–„â–ƒâ–„â–ƒâ–‚â–‚â–…â–ƒâ–†â–„â–‚â–ƒâ–„â–…â–â–ƒâ–„â–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–…â–ƒ
wandb:       eval/ensemble_f1 â–â–…â–„â–…â–†â–†â–…â–…â–„â–†â–†â–…â–…â–‡â–†â–‡â–„â–†â–†â–…â–…â–„â–„â–‡â–„â–‡â–‡â–†â–ƒâ–…â–„â–‡â–‡â–…â–‚â–…â–†â–ˆâ–ƒâ–…
wandb:           train/avg_f1 â–†â–†â–…â–†â–…â–…â–…â–ˆâ–…â–†â–„â–…â–…â–†â–„â–†â–…â–â–…â–„â–…â–…â–…â–†â–„â–…â–‚â–‡â–ˆâ–ƒâ–†â–…â–…â–…â–†â–„â–„â–„â–ˆâ–†
wandb:      train/ensemble_f1 â–†â–†â–†â–…â–†â–„â–†â–…â–‡â–…â–…â–†â–„â–…â–†â–ƒâ–†â–„â–†â–ˆâ–†â–â–„â–…â–‚â–„â–…â–ˆâ–‚â–‡â–„â–†â–…â–„â–…â–„â–„â–„â–„â–†
wandb:         train/mil_loss â–‚â–ƒâ–â–…â–†â–…â–„â–†â–„â–…â–â–…â–†â–…â–ƒâ–‡â–†â–…â–‚â–…â–‡â–‡â–„â–ˆâ–„â–†â–„â–â–„â–‡â–„â–„â–„â–…â–…â–„â–†â–…â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83122
wandb: best/eval_avg_mil_loss 0.42135
wandb:  best/eval_ensemble_f1 0.83122
wandb:            eval/avg_f1 0.78286
wandb:      eval/avg_mil_loss 0.47459
wandb:       eval/ensemble_f1 0.78286
wandb:           train/avg_f1 0.80137
wandb:      train/ensemble_f1 0.80137
wandb:         train/mil_loss 1.0059
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ux20595d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071411-ux20595d/logs
wandb: ERROR Run ux20595d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: q8a1t1pm with config:
wandb: 	actor_learning_rate: 5.0169961835538096e-05
wandb: 	attention_dropout_p: 0.11201523375187188
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10086408808259884
wandb: 	temperature: 9.96687510216486
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071605-q8a1t1pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8a1t1pm
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–â–„
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–â–‡â–ƒâ–â–…â–„â–…â–ƒâ–…â–†â–„â–‡â–‡â–†â–„â–…â–ˆâ–„â–ˆâ–…â–‡â–„â–ƒâ–‡â–†â–…â–‚â–„â–‡â–ˆâ–†â–†â–…â–…â–ˆâ–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–†â–„â–…â–„â–ƒâ–ƒâ–ƒâ–…â–†â–„â–…â–„â–‡â–‚â–„â–â–…â–…â–„â–â–ƒâ–…â–†â–ƒâ–†â–„â–†â–…â–„â–‚â–†â–„â–…â–‡â–…â–„â–‚â–ˆâ–†
wandb:       eval/ensemble_f1 â–‡â–„â–ƒâ–…â–‚â–…â–‡â–„â–„â–‡â–†â–„â–…â–ƒâ–‡â–…â–„â–„â–‚â–…â–ˆâ–„â–„â–ƒâ–â–ƒâ–„â–†â–…â–„â–„â–ƒâ–‡â–…â–ˆâ–„â–‡â–†â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–…â–†â–ƒâ–„â–ˆâ–ƒâ–ƒâ–†â–„â–…â–ƒâ–…â–†â–…â–†â–ƒâ–ƒâ–„â–…â–‚â–â–…â–‡â–‚â–…â–ˆâ–„â–†â–…â–†â–‚â–…â–„â–ƒâ–ˆâ–†â–„â–†
wandb:      train/ensemble_f1 â–ƒâ–â–â–‡â–„â–„â–‚â–â–‚â–‡â–„â–‡â–‡â–†â–‡â–â–ˆâ–ƒâ–†â–‚â–…â–‚â–ƒâ–ˆâ–â–†â–†â–…â–ƒâ–„â–‚â–‚â–…â–„â–„â–‡â–‚â–‡â–‚â–‚
wandb:         train/mil_loss â–…â–ˆâ–†â–†â–ƒâ–†â–‚â–†â–ƒâ–†â–†â–‚â–‡â–…â–ƒâ–†â–„â–ƒâ–†â–‚â–ƒâ–†â–‚â–„â–…â–ƒâ–†â–†â–ƒâ–‚â–„â–†â–†â–†â–ˆâ–â–„â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.36952
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.80849
wandb:      eval/avg_mil_loss 0.40221
wandb:       eval/ensemble_f1 0.80849
wandb:            test/avg_f1 0.77277
wandb:      test/avg_mil_loss 0.58546
wandb:       test/ensemble_f1 0.77277
wandb:           train/avg_f1 0.81186
wandb:      train/ensemble_f1 0.81186
wandb:         train/mil_loss 1.03275
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q8a1t1pm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071605-q8a1t1pm/logs
wandb: Agent Starting Run: avwdlrbm with config:
wandb: 	actor_learning_rate: 4.280069760378928e-06
wandb: 	attention_dropout_p: 0.03194984705087395
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7302267201129016
wandb: 	temperature: 0.8316782423312374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071900-avwdlrbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avwdlrbm
wandb: uploading wandb-summary.json
wandb: uploading history steps 93-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‡â–ƒâ–„â–â–â–†â–„â–…â–…â–‡â–†â–†â–…â–„â–„â–…â–…â–…â–ƒâ–†â–†â–…â–…â–†â–ˆâ–„â–†â–…â–ƒâ–ˆâ–…
wandb:      eval/avg_mil_loss â–„â–„â–‚â–ƒâ–…â–ƒâ–…â–„â–ƒâ–‡â–…â–ˆâ–‡â–†â–‚â–…â–…â–…â–…â–…â–†â–‚â–„â–†â–†â–…â–„â–…â–‚â–ƒâ–†â–†â–…â–‚â–„â–„â–ƒâ–â–†â–…
wandb:       eval/ensemble_f1 â–„â–…â–ˆâ–…â–„â–…â–ƒâ–„â–…â–ƒâ–‚â–‚â–„â–ƒâ–‚â–†â–…â–†â–†â–ˆâ–†â–…â–…â–†â–†â–†â–„â–†â–‡â–„â–‚â–…â–†â–…â–„â–ƒâ–…â–â–ƒâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–‚â–ƒâ–„â–ˆâ–ƒâ–‚â–â–ˆâ–„â–„â–„â–…â–…â–†â–…â–†â–„â–…â–„â–…â–†â–„â–…â–‡â–‡â–„â–„â–…â–†â–…â–†â–‡â–†â–„â–…â–„â–…â–†
wandb:      train/ensemble_f1 â–†â–‡â–„â–‚â–ˆâ–†â–â–…â–…â–„â–†â–ˆâ–‡â–…â–…â–„â–†â–…â–„â–†â–„â–…â–‡â–…â–…â–‡â–†â–†â–…â–ƒâ–‡â–†â–…â–‚â–…â–†â–‡â–…â–†â–†
wandb:         train/mil_loss â–â–…â–†â–‡â–…â–„â–„â–…â–‚â–ƒâ–…â–…â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–…â–„â–ˆâ–…â–ƒâ–…â–†â–…â–„â–„â–†â–â–‚â–…â–ƒâ–„â–†â–…â–„â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.32014
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.82011
wandb:      eval/avg_mil_loss 0.42689
wandb:       eval/ensemble_f1 0.82011
wandb:            test/avg_f1 0.74532
wandb:      test/avg_mil_loss 0.64021
wandb:       test/ensemble_f1 0.74532
wandb:           train/avg_f1 0.80428
wandb:      train/ensemble_f1 0.80428
wandb:         train/mil_loss 0.52844
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avwdlrbm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071900-avwdlrbm/logs
wandb: Agent Starting Run: gmojmax0 with config:
wandb: 	actor_learning_rate: 1.329067190141449e-06
wandb: 	attention_dropout_p: 0.0978466524051555
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7856778361525443
wandb: 	temperature: 5.144098294307308
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072059-gmojmax0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmojmax0
wandb: uploading history steps 47-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–„â–…â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–†â–‡â–ˆâ–‡â–…â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–„â–…â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–„â–‚â–…â–†â–†â–…â–…â–…â–†â–†â–…â–„â–†â–…â–†â–„â–ˆâ–„â–…â–†â–„â–„â–†â–‚â–â–„â–„â–…â–„â–…â–„â–„â–ˆâ–ƒâ–…â–‡â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–„â–…â–†â–…â–…â–…â–„â–…â–…â–…â–„â–„â–…â–…â–…â–…â–ƒâ–†â–‚â–†â–…â–…â–ƒâ–„â–…â–„â–‡â–ˆâ–„â–ˆâ–„â–…â–†â–â–ƒâ–…â–„â–‚â–‡â–‡
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–„â–‚â–…â–†â–†â–…â–…â–†â–†â–„â–†â–…â–†â–„â–ˆâ–„â–‡â–„â–†â–„â–„â–†â–‚â–â–„â–ƒâ–„â–…â–„â–„â–ˆâ–†â–ƒâ–…â–‡â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–„â–‡â–…â–‡â–ƒâ–„â–‡â–‚â–‚â–ƒâ–‡â–ƒâ–„â–ƒâ–ƒâ–†â–…â–‚â–‚â–ƒâ–â–†â–ƒâ–†â–„â–‚â–ƒâ–„â–†â–‚â–‚â–„â–‚â–ƒâ–…â–†â–â–‡
wandb:      train/ensemble_f1 â–ˆâ–…â–„â–‡â–…â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–…â–‚â–„â–„â–†â–ƒâ–â–†â–ƒâ–„â–„â–ƒâ–„â–†â–†â–‚â–„â–‚â–ƒâ–ƒâ–†â–â–…â–…â–‡
wandb:         train/mil_loss â–…â–ƒâ–‡â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–„â–ƒâ–ƒâ–…â–â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–â–„â–„â–„â–„â–„â–
wandb:      train/policy_loss â–ƒâ–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–ƒâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8392
wandb: best/eval_avg_mil_loss 0.38028
wandb:  best/eval_ensemble_f1 0.8392
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.52525
wandb:       eval/ensemble_f1 0.76275
wandb:            test/avg_f1 0.74532
wandb:      test/avg_mil_loss 0.53252
wandb:       test/ensemble_f1 0.74532
wandb:           train/avg_f1 0.811
wandb:      train/ensemble_f1 0.811
wandb:         train/mil_loss 0.50841
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run unique-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gmojmax0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072059-gmojmax0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 199dmwab with config:
wandb: 	actor_learning_rate: 2.83179523088204e-06
wandb: 	attention_dropout_p: 0.10446386078010912
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4540484034989728
wandb: 	temperature: 7.379420954043053
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072222-199dmwab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/199dmwab
wandb: uploading history steps 47-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–†â–„â–„â–ƒâ–ƒâ–ƒâ–†â–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–†â–„â–ƒâ–ƒâ–ƒâ–â–…â–‡â–„â–„â–‚â–ƒâ–ˆâ–…â–â–†â–‚â–ƒâ–‚â–„
wandb:      eval/avg_mil_loss â–‚â–‚â–„â–…â–†â–ƒâ–ƒâ–‚â–„â–„â–„â–„â–„â–ƒâ–†â–…â–†â–‚â–†â–„â–ƒâ–ƒâ–†â–ˆâ–†â–ƒâ–â–…â–„â–ƒâ–…â–â–‚â–†â–…â–„â–†â–†â–„â–„
wandb:       eval/ensemble_f1 â–†â–„â–„â–‚â–ƒâ–‚â–†â–ƒâ–‡â–ƒâ–ƒâ–…â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–‚â–†â–„â–ƒâ–ƒâ–„â–â–…â–‡â–„â–…â–â–‚â–ˆâ–…â–…â–†â–‚â–‚â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–„â–‡â–…â–ƒâ–ƒâ–†â–‚â–…â–ƒâ–ˆâ–…â–…â–‡â–ƒâ–…â–ƒâ–†â–…â–‡â–â–„â–†â–ƒâ–†â–ˆâ–ƒâ–…â–…â–ƒâ–…â–†â–…â–„â–…â–†â–…â–„â–‚
wandb:      train/ensemble_f1 â–…â–†â–ˆâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–…â–…â–‡â–…â–ƒâ–†â–…â–ƒâ–â–„â–†â–ƒâ–‡â–„â–…â–…â–„â–ƒâ–†â–…â–„â–ƒâ–…â–…â–…â–„â–…â–…
wandb:         train/mil_loss â–„â–…â–†â–…â–…â–„â–‡â–‡â–‡â–…â–„â–…â–‡â–ƒâ–†â–†â–†â–…â–…â–†â–…â–‡â–‚â–„â–…â–ˆâ–ˆâ–â–†â–‚â–„â–…â–„â–…â–ƒâ–„â–„â–ƒâ–…â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84911
wandb: best/eval_avg_mil_loss 0.38844
wandb:  best/eval_ensemble_f1 0.84911
wandb:            eval/avg_f1 0.80495
wandb:      eval/avg_mil_loss 0.43883
wandb:       eval/ensemble_f1 0.80495
wandb:            test/avg_f1 0.79318
wandb:      test/avg_mil_loss 0.48358
wandb:       test/ensemble_f1 0.79318
wandb:           train/avg_f1 0.80995
wandb:      train/ensemble_f1 0.80995
wandb:         train/mil_loss 0.87657
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/199dmwab
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072222-199dmwab/logs
wandb: Agent Starting Run: q680z19q with config:
wandb: 	actor_learning_rate: 0.00010518873873883768
wandb: 	attention_dropout_p: 0.11680958493829008
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5232016998897074
wandb: 	temperature: 4.967124587336863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072334-q680z19q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q680z19q
wandb: uploading history steps 82-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–†â–„â–…â–†â–„â–ƒâ–„â–…â–ƒâ–‚â–ˆâ–„â–„â–„â–â–„â–…â–‚â–…â–ƒâ–…â–…â–‡â–ƒâ–…â–…â–„â–‚â–‚â–†â–„â–‚â–„â–â–ƒâ–‚â–…â–†â–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–ƒâ–‡â–‚â–†â–ˆâ–‚â–‚â–ƒâ–†â–„â–…â–‡â–â–…â–†â–„â–„â–…â–…â–…â–†â–„â–‚â–†â–‡â–…â–…â–…â–ƒâ–…â–…â–…â–„â–…â–â–„â–…
wandb:       eval/ensemble_f1 â–â–„â–†â–‡â–ƒâ–„â–†â–„â–†â–†â–…â–…â–„â–‚â–†â–…â–„â–„â–„â–ˆâ–„â–…â–†â–„â–‚â–…â–„â–‚â–‚â–‡â–…â–‚â–‚â–â–…â–„â–ƒâ–…â–…â–‡
wandb:           train/avg_f1 â–‚â–†â–…â–‚â–†â–â–â–…â–…â–„â–„â–‚â–ƒâ–„â–…â–‚â–†â–„â–…â–…â–†â–„â–‡â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–†â–‡â–ƒâ–†â–„â–ƒâ–ƒâ–…â–ƒâ–‡
wandb:      train/ensemble_f1 â–‚â–†â–„â–…â–…â–…â–„â–†â–…â–„â–…â–„â–†â–„â–â–†â–„â–ƒâ–‡â–†â–ƒâ–…â–ƒâ–ƒâ–…â–ˆâ–„â–…â–â–ƒâ–ƒâ–‡â–„â–‡â–ƒâ–†â–„â–ƒâ–ˆâ–„
wandb:         train/mil_loss â–ƒâ–…â–…â–„â–†â–„â–‡â–…â–ˆâ–„â–‚â–„â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–ƒâ–…â–ƒâ–„â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–„â–â–‚â–‚â–„â–â–‚
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86804
wandb: best/eval_avg_mil_loss 0.40258
wandb:  best/eval_ensemble_f1 0.86804
wandb:            eval/avg_f1 0.75866
wandb:      eval/avg_mil_loss 0.47418
wandb:       eval/ensemble_f1 0.75866
wandb:           train/avg_f1 0.81415
wandb:      train/ensemble_f1 0.81415
wandb:         train/mil_loss 0.9462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ethereal-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q680z19q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072334-q680z19q/logs
wandb: ERROR Run q680z19q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kel8jtfl with config:
wandb: 	actor_learning_rate: 0.000675944814544442
wandb: 	attention_dropout_p: 0.39388678282676415
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47632715543926174
wandb: 	temperature: 5.615274218658858
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072545-kel8jtfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kel8jtfl
wandb: uploading history steps 80-81, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–‡â–„â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–â–…â–‚â–†â–‚â–…â–‚â–â–…â–ƒâ–‚â–…â–…â–„â–ˆâ–ƒâ–†â–ƒâ–„â–ƒâ–„â–†â–ƒâ–…â–‚â–…â–†â–…â–„â–†â–ƒâ–ƒâ–„â–…â–…â–‚â–ƒâ–†â–â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–…â–‚â–…â–ƒâ–…â–…â–…â–ˆâ–ƒâ–„â–…â–„â–…â–†â–ƒâ–†â–„â–ƒâ–…â–ƒâ–†â–‚â–„â–…â–…â–„â–…â–…â–â–‚â–â–„â–„â–…â–‚â–†â–ƒâ–‚â–„
wandb:       eval/ensemble_f1 â–…â–ƒâ–†â–‚â–ƒâ–…â–†â–„â–‚â–„â–„â–ƒâ–„â–ƒâ–…â–â–ˆâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–†â–ƒâ–…â–†â–…â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–…â–…â–†â–‚â–‡â–„â–„
wandb:           train/avg_f1 â–†â–„â–â–ƒâ–ƒâ–†â–†â–‡â–†â–‡â–„â–‡â–†â–„â–†â–‡â–ƒâ–‡â–„â–‡â–†â–„â–„â–…â–ƒâ–…â–†â–„â–ˆâ–ƒâ–‡â–†â–…â–„â–ˆâ–…â–†â–…â–†â–…
wandb:      train/ensemble_f1 â–…â–‡â–„â–â–ƒâ–†â–‡â–…â–‡â–‡â–ƒâ–„â–†â–ˆâ–…â–‚â–„â–‡â–‡â–ƒâ–†â–„â–„â–…â–†â–„â–ˆâ–ƒâ–…â–ƒâ–‡â–„â–ƒâ–…â–…â–†â–‡â–…â–†â–…
wandb:         train/mil_loss â–„â–†â–…â–ƒâ–…â–‡â–‡â–‡â–†â–‡â–„â–†â–†â–…â–‡â–†â–†â–„â–‡â–…â–„â–…â–†â–…â–„â–†â–ˆâ–†â–‚â–ƒâ–„â–â–ˆâ–…â–…â–ƒâ–ƒâ–†â–…â–†
wandb:      train/policy_loss â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.35886
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.79097
wandb:      eval/avg_mil_loss 0.49724
wandb:       eval/ensemble_f1 0.79097
wandb:           train/avg_f1 0.79262
wandb:      train/ensemble_f1 0.79262
wandb:         train/mil_loss 1.01165
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vital-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kel8jtfl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072545-kel8jtfl/logs
wandb: ERROR Run kel8jtfl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7hrxefkb with config:
wandb: 	actor_learning_rate: 1.5859914190162023e-06
wandb: 	attention_dropout_p: 0.2487455157189292
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08320542120357644
wandb: 	temperature: 7.103595496967182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072723-7hrxefkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hrxefkb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‚â–ƒâ–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–†â–„â–„â–…â–„â–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–†â–…â–†â–…â–†â–â–ˆâ–„â–ƒâ–†â–ƒâ–ˆâ–„â–‡â–‚â–…â–„â–ƒâ–†â–…â–…â–„â–†â–…â–„â–…
wandb:      eval/avg_mil_loss â–†â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–…â–…â–†â–†â–‚â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–ˆâ–„â–ˆâ–„â–â–†â–„â–†â–„â–ƒâ–„â–†â–„â–…â–ƒâ–…â–ƒâ–„
wandb:       eval/ensemble_f1 â–…â–â–…â–…â–ƒâ–…â–…â–ƒâ–…â–‚â–â–†â–…â–‡â–…â–â–ƒâ–„â–„â–ƒâ–„â–…â–ˆâ–ƒâ–‚â–â–ƒâ–„â–†â–„â–‡â–‡â–ƒâ–ƒâ–…â–‡â–…â–†â–„â–…
wandb:           train/avg_f1 â–„â–„â–„â–…â–‡â–…â–…â–…â–„â–ˆâ–„â–‚â–ˆâ–†â–†â–ƒâ–„â–…â–„â–…â–„â–„â–†â–†â–…â–‚â–…â–†â–â–‚â–‚â–„â–„â–†â–…â–‚â–†â–…â–†â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–†â–‡â–‡â–„â–„â–„â–†â–‚â–…â–ƒâ–‡â–ƒâ–‚â–…â–ˆâ–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–„â–…â–ƒâ–â–†â–„â–ƒâ–„â–„â–†â–‚â–†â–ƒâ–ƒâ–„â–‡â–…â–†
wandb:         train/mil_loss â–ƒâ–†â–ƒâ–ƒâ–†â–…â–†â–…â–„â–ƒâ–„â–ˆâ–†â–ƒâ–†â–…â–„â–†â–†â–†â–„â–…â–â–…â–„â–„â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–…â–†â–†â–‚â–‡â–‚â–ƒ
wandb:      train/policy_loss â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.39011
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.80207
wandb:      eval/avg_mil_loss 0.4538
wandb:       eval/ensemble_f1 0.80207
wandb:           train/avg_f1 0.8125
wandb:      train/ensemble_f1 0.8125
wandb:         train/mil_loss 0.66409
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run toasty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7hrxefkb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072723-7hrxefkb/logs
wandb: ERROR Run 7hrxefkb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4j44282r with config:
wandb: 	actor_learning_rate: 0.0002040247071636301
wandb: 	attention_dropout_p: 0.04656715974368697
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9520017164929436
wandb: 	temperature: 8.39120137787702
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072948-4j44282r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j44282r
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‚â–„â–â–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–„â–„â–…â–…â–†â–†â–‡â–„â–…â–ƒâ–„â–…â–â–…â–„â–â–‡â–…â–…â–ƒâ–†â–„â–…â–…â–„â–†â–†â–†â–†â–…â–ˆâ–ƒâ–„â–„â–‡â–†â–…â–…â–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–…â–…â–†â–„â–„â–ƒâ–„â–†â–‚â–ƒâ–‚â–ˆâ–â–ƒâ–†â–…â–‡â–â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–…â–‚â–â–ƒâ–‚â–„â–…â–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–‚â–„â–…â–„â–ƒâ–„â–…â–…â–ƒâ–ƒâ–„â–…â–…â–†â–…â–‡â–…â–‚â–„â–„â–ƒâ–…â–ƒâ–„â–…â–…â–ƒâ–â–†â–ƒâ–ƒâ–‚â–ˆâ–†â–†â–†â–…â–…â–…
wandb:           train/avg_f1 â–…â–…â–„â–…â–„â–…â–â–„â–„â–„â–†â–ˆâ–„â–„â–…â–…â–ƒâ–†â–‚â–„â–„â–†â–‚â–…â–â–â–ƒâ–‡â–ƒâ–„â–…â–†â–ƒâ–…â–„â–„â–„â–†â–…â–
wandb:      train/ensemble_f1 â–„â–ƒâ–…â–…â–…â–„â–ƒâ–„â–„â–‚â–ˆâ–…â–„â–„â–„â–…â–†â–â–†â–„â–†â–„â–…â–ˆâ–„â–„â–†â–…â–„â–â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–…â–…â–„â–„
wandb:         train/mil_loss â–„â–†â–…â–„â–†â–ƒâ–„â–„â–ˆâ–†â–…â–ƒâ–„â–„â–„â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–„â–â–„â–â–ƒâ–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86482
wandb: best/eval_avg_mil_loss 0.38338
wandb:  best/eval_ensemble_f1 0.86482
wandb:            eval/avg_f1 0.77985
wandb:      eval/avg_mil_loss 0.44993
wandb:       eval/ensemble_f1 0.77985
wandb:           train/avg_f1 0.78445
wandb:      train/ensemble_f1 0.78445
wandb:         train/mil_loss 0.53517
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4j44282r
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072948-4j44282r/logs
wandb: ERROR Run 4j44282r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dguokiy3 with config:
wandb: 	actor_learning_rate: 0.0004875503766650218
wandb: 	attention_dropout_p: 0.25903345133559164
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 193
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5657432917324793
wandb: 	temperature: 2.2819406231541564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073305-dguokiy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dguokiy3
wandb: uploading wandb-summary.json
wandb: uploading history steps 186-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–„â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–â–„â–„â–†â–†â–†â–„â–„â–…â–…â–„â–„â–…â–„â–„â–…â–†â–…â–„â–†â–„â–„â–„â–ˆâ–„â–…â–…â–‚â–‡â–‡â–†â–„â–…â–ƒâ–„â–†â–…â–‡â–‡
wandb:      eval/avg_mil_loss â–‡â–â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‡â–„â–‚â–…â–…â–â–‚â–ƒâ–…â–†â–‡â–†â–…â–„â–†â–„â–†â–„â–ƒâ–ƒâ–…â–ˆâ–„â–ƒâ–…â–†â–†â–…â–„â–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–…â–‡â–†â–…â–„â–ƒâ–…â–„â–†â–†â–ƒâ–…â–…â–‡â–…â–‡â–ˆâ–„â–„â–†â–†â–†â–…â–†â–„â–‚â–‡â–â–…â–…â–ˆâ–„â–†â–†â–…â–†â–„â–â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–…â–…â–‚â–†â–ˆâ–„â–ƒâ–â–†â–„â–„â–ƒâ–„â–â–„â–ƒâ–ƒâ–„â–†â–‚â–…â–ˆâ–„â–ƒâ–„â–‚â–‚â–…â–„â–‡â–†â–‚â–
wandb:      train/ensemble_f1 â–†â–…â–„â–ƒâ–„â–‚â–ˆâ–ƒâ–â–„â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–…â–…â–‚â–…â–‡â–†â–†â–„â–‡â–ƒâ–„â–‡â–â–…â–„â–†â–„â–†â–†â–†â–„â–
wandb:         train/mil_loss â–â–…â–…â–…â–…â–‚â–ƒâ–‡â–„â–ƒâ–ˆâ–„â–ƒâ–…â–†â–„â–†â–…â–‚â–„â–ƒâ–„â–„â–…â–…â–‚â–‚â–„â–…â–„â–…â–‚â–†â–ƒâ–„â–…â–†â–„â–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85682
wandb: best/eval_avg_mil_loss 0.31088
wandb:  best/eval_ensemble_f1 0.85682
wandb:            eval/avg_f1 0.83887
wandb:      eval/avg_mil_loss 0.40433
wandb:       eval/ensemble_f1 0.83887
wandb:            test/avg_f1 0.7846
wandb:      test/avg_mil_loss 0.37569
wandb:       test/ensemble_f1 0.7846
wandb:           train/avg_f1 0.78402
wandb:      train/ensemble_f1 0.78402
wandb:         train/mil_loss 0.56314
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dguokiy3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073305-dguokiy3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ai54lx6s with config:
wandb: 	actor_learning_rate: 0.00028366666431541536
wandb: 	attention_dropout_p: 0.1944564811715236
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.833492459426082
wandb: 	temperature: 6.267835301325139
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073711-ai54lx6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai54lx6s
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–†â–‡â–‡â–‚â–‡â–ƒâ–‚â–ƒâ–…â–…â–‡â–‡â–…â–…â–ƒâ–‡â–†â–‚â–ƒâ–†â–ƒâ–…â–‡â–…â–…â–…â–‡â–‡â–„â–†â–ƒâ–ˆâ–…â–…â–ƒâ–ˆâ–…â–â–…
wandb:      eval/avg_mil_loss â–ˆâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–†â–„â–…â–ƒâ–â–…â–…â–†â–…â–†â–‡â–…â–‡â–„â–ˆâ–†â–‡â–ƒâ–ƒâ–…â–‚â–†â–‡â–ƒâ–†â–‡â–†â–ˆâ–„â–†â–ƒâ–†â–‚â–‡
wandb:       eval/ensemble_f1 â–ƒâ–‡â–ˆâ–ˆâ–„â–‡â–‚â–â–â–…â–†â–†â–‡â–ƒâ–‡â–„â–‚â–ƒâ–‚â–ˆâ–ˆâ–‚â–…â–†â–„â–…â–ˆâ–‚â–…â–‡â–ƒâ–†â–„â–†â–‚â–…â–‚â–…â–„â–„
wandb:           train/avg_f1 â–†â–†â–ƒâ–‡â–‚â–‡â–‡â–ˆâ–…â–ˆâ–…â–‡â–†â–‚â–…â–„â–…â–†â–„â–ƒâ–„â–„â–…â–†â–†â–…â–…â–â–‡â–†â–…â–„â–†â–‡â–…â–†â–ƒâ–‡â–…â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–…â–…â–†â–„â–ˆâ–„â–ƒâ–…â–†â–‡â–„â–…â–…â–ƒâ–…â–ƒâ–ƒâ–…â–…â–„â–ƒâ–‚â–…â–â–„â–…â–„â–‡â–…â–„â–ƒâ–„â–„â–‚â–†â–„â–„
wandb:         train/mil_loss â–…â–†â–…â–…â–ˆâ–„â–†â–†â–ˆâ–†â–„â–…â–†â–†â–…â–„â–‡â–…â–…â–†â–„â–„â–„â–…â–…â–„â–‚â–„â–…â–…â–„â–‚â–„â–„â–ƒâ–„â–â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84553
wandb: best/eval_avg_mil_loss 0.41356
wandb:  best/eval_ensemble_f1 0.84553
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.48295
wandb:       eval/ensemble_f1 0.80225
wandb:           train/avg_f1 0.80138
wandb:      train/ensemble_f1 0.80138
wandb:         train/mil_loss 0.51984
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silvery-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ai54lx6s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073711-ai54lx6s/logs
wandb: ERROR Run ai54lx6s errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4rj7ucnq with config:
wandb: 	actor_learning_rate: 9.548083623453328e-05
wandb: 	attention_dropout_p: 0.44801736788708946
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9266503529678556
wandb: 	temperature: 4.129672218106272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073911-4rj7ucnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rj7ucnq
wandb: uploading wandb-summary.json
wandb: uploading history steps 118-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–†â–‡â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–…â–…â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–„â–‚â–‡â–„â–†â–…â–‚â–„â–†â–…â–ƒâ–‡â–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–„â–…â–„â–ƒâ–…â–‚â–‚â–…â–„â–„â–‚â–†â–ˆâ–‡â–ƒâ–â–ƒ
wandb:      eval/avg_mil_loss â–‡â–‚â–†â–„â–…â–…â–†â–„â–„â–ƒâ–ˆâ–†â–ƒâ–†â–â–†â–ƒâ–‡â–…â–â–‡â–ƒâ–â–„â–‚â–†â–â–‡â–â–„â–†â–‡â–‡â–â–„â–‚â–ˆâ–„â–„â–„
wandb:       eval/ensemble_f1 â–„â–‚â–„â–‡â–‡â–‚â–…â–ƒâ–†â–‡â–…â–†â–ƒâ–ˆâ–†â–…â–„â–„â–‡â–†â–†â–†â–â–„â–†â–†â–„â–ƒâ–â–‡â–‡â–ƒâ–ƒâ–†â–…â–†â–„â–†â–ƒâ–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–…â–„â–„â–ƒâ–…â–‚â–†â–„â–…â–â–…â–â–…â–„â–†â–ƒâ–†â–…â–ƒâ–…â–„â–â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–†â–„â–„â–…â–†â–†â–„â–‚â–ˆâ–„
wandb:      train/ensemble_f1 â–‡â–…â–„â–ƒâ–‚â–ƒâ–…â–„â–‡â–…â–†â–ƒâ–„â–…â–‚â–…â–ƒâ–„â–„â–‡â–„â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–…â–‚â–â–‡â–…â–ˆâ–„â–…â–†â–â–ƒâ–„
wandb:         train/mil_loss â–‡â–…â–†â–‚â–â–†â–…â–‡â–ƒâ–…â–…â–ƒâ–…â–ˆâ–„â–‚â–„â–ƒâ–†â–…â–‡â–†â–…â–„â–†â–â–‡â–‚â–†â–â–ƒâ–…â–‡â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86444
wandb: best/eval_avg_mil_loss 0.3359
wandb:  best/eval_ensemble_f1 0.86444
wandb:            eval/avg_f1 0.79552
wandb:      eval/avg_mil_loss 0.44634
wandb:       eval/ensemble_f1 0.79552
wandb:            test/avg_f1 0.76481
wandb:      test/avg_mil_loss 0.45501
wandb:       test/ensemble_f1 0.76481
wandb:           train/avg_f1 0.78509
wandb:      train/ensemble_f1 0.78509
wandb:         train/mil_loss 0.90435
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run azure-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rj7ucnq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073911-4rj7ucnq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 95su3yx0 with config:
wandb: 	actor_learning_rate: 2.2879372470340696e-06
wandb: 	attention_dropout_p: 0.11181310180206616
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8436696201152549
wandb: 	temperature: 7.253334785875229
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074145-95su3yx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95su3yx0
wandb: uploading history steps 116-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–‡â–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–„â–…â–ˆ
wandb:            eval/avg_f1 â–†â–†â–…â–„â–…â–†â–†â–ƒâ–„â–„â–„â–‡â–ƒâ–‚â–‡â–„â–ƒâ–„â–‚â–…â–â–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–„â–ˆâ–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–„â–†â–†â–†â–ƒâ–„â–ƒâ–…â–„â–„â–‡â–…â–†â–„â–ƒâ–„â–†â–â–…â–‡â–…â–†â–ˆâ–„â–†â–‡â–…â–ƒâ–„â–†â–‡â–†â–…â–„â–…â–…â–†
wandb:       eval/ensemble_f1 â–…â–…â–„â–‚â–…â–‚â–ƒâ–…â–ƒâ–…â–ƒâ–†â–‚â–ƒâ–…â–ƒâ–â–„â–„â–„â–â–‚â–‚â–ƒâ–‚â–â–…â–‚â–â–‚â–ƒâ–…â–„â–‚â–„â–„â–‚â–‚â–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–„â–‚â–‚â–â–†â–‚â–‚â–…â–‡â–…â–ƒâ–†â–„â–†â–ƒâ–â–†â–„â–†â–…â–ƒâ–…â–„â–„â–…â–‡â–…â–ˆâ–…â–ƒâ–‚â–†â–ƒâ–â–…â–…â–…â–†
wandb:      train/ensemble_f1 â–„â–‚â–…â–†â–…â–†â–†â–„â–„â–†â–†â–…â–…â–‡â–ƒâ–‚â–ˆâ–‡â–„â–†â–†â–â–„â–…â–…â–…â–‡â–„â–„â–‡â–„â–ƒâ–„â–†â–ƒâ–†â–…â–„â–ƒâ–†
wandb:         train/mil_loss â–ˆâ–‚â–ƒâ–‡â–…â–…â–ƒâ–†â–„â–…â–…â–‚â–„â–„â–„â–â–…â–ƒâ–…â–ƒâ–…â–„â–…â–…â–‚â–â–…â–„â–…â–ƒâ–‚â–†â–ƒâ–ƒâ–„â–…â–„â–‚â–…â–‚
wandb:      train/policy_loss â–ˆâ–â–…â–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–â–ˆâ–…â–â–ˆâ–â–â–…â–ˆâ–â–ˆâ–â–â–â–â–â–â–…â–…â–…â–ˆâ–…â–â–…â–â–…â–…â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–â–ˆâ–„â–ˆâ–â–â–â–„â–ˆâ–â–â–ˆâ–â–ˆâ–„â–„â–ˆâ–â–ˆâ–â–â–ˆâ–â–â–„â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.383
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79523
wandb:      eval/avg_mil_loss 0.47318
wandb:       eval/ensemble_f1 0.79523
wandb:            test/avg_f1 0.76109
wandb:      test/avg_mil_loss 0.53466
wandb:       test/ensemble_f1 0.76109
wandb:           train/avg_f1 0.79124
wandb:      train/ensemble_f1 0.79124
wandb:         train/mil_loss 0.85226
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/95su3yx0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074145-95su3yx0/logs
wandb: Agent Starting Run: 06jzacjy with config:
wandb: 	actor_learning_rate: 7.093027821025106e-06
wandb: 	attention_dropout_p: 0.2992330258094781
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6541453165852357
wandb: 	temperature: 3.7670415420284655
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074420-06jzacjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06jzacjy
wandb: uploading history steps 170-173, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–†â–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–„â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–‚â–…â–†â–…â–‚â–ƒâ–†â–‚â–‚â–ƒâ–„â–†â–†â–„â–…â–‡â–ˆâ–„â–â–„â–†â–„â–„â–„â–…â–…â–„â–…â–†â–…â–„â–„â–†â–„â–…â–†â–…â–„
wandb:      eval/avg_mil_loss â–…â–…â–ƒâ–†â–‚â–†â–‡â–†â–„â–„â–„â–â–„â–‚â–†â–â–â–ƒâ–„â–†â–…â–ˆâ–‡â–…â–‡â–ˆâ–‚â–„â–…â–†â–ƒâ–ˆâ–‡â–ƒâ–…â–‚â–ˆâ–‚â–ˆâ–‚
wandb:       eval/ensemble_f1 â–…â–†â–‡â–…â–ˆâ–…â–ˆâ–„â–†â–†â–…â–ƒâ–…â–ˆâ–…â–…â–ˆâ–„â–†â–…â–„â–„â–‡â–…â–†â–†â–…â–†â–â–…â–â–†â–‡â–…â–…â–‡â–„â–„â–„â–†
wandb:           train/avg_f1 â–…â–†â–â–…â–†â–†â–„â–†â–„â–†â–‚â–„â–‚â–ƒâ–„â–„â–ƒâ–†â–ƒâ–†â–†â–ˆâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–„â–‡â–…â–ƒâ–„â–‡â–†â–…â–…â–…â–ƒâ–†
wandb:      train/ensemble_f1 â–ˆâ–„â–„â–†â–â–‡â–…â–†â–…â–…â–…â–„â–„â–„â–ƒâ–„â–†â–„â–„â–„â–…â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–‡â–†â–„â–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–‡
wandb:         train/mil_loss â–ˆâ–‡â–‡â–…â–â–…â–ˆâ–†â–„â–…â–†â–…â–†â–ˆâ–ˆâ–…â–‡â–„â–…â–ƒâ–‡â–‡â–†â–†â–‡â–‡â–†â–ˆâ–†â–†â–†â–ƒâ–ˆâ–‡â–‡â–…â–…â–†â–„â–†
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84259
wandb: best/eval_avg_mil_loss 0.43914
wandb:  best/eval_ensemble_f1 0.84259
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.46389
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.80769
wandb:      train/ensemble_f1 0.80769
wandb:         train/mil_loss 1.00614
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06jzacjy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074420-06jzacjy/logs
wandb: ERROR Run 06jzacjy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7jydohyb with config:
wandb: 	actor_learning_rate: 1.6437923775707268e-05
wandb: 	attention_dropout_p: 0.4594111440108622
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5907723362042965
wandb: 	temperature: 3.7029214677226903
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074752-7jydohyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jydohyb
wandb: uploading history steps 116-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–…â–‡â–ƒâ–‡â–ˆâ–‚â–†â–‡â–ˆâ–„â–„â–†â–â–„â–â–‚â–„â–‚â–„â–ƒâ–‚â–ˆâ–†â–„â–‡â–†â–ƒâ–ƒâ–†â–â–ƒâ–‚â–‡â–…â–‚â–…â–†â–†
wandb:      eval/avg_mil_loss â–„â–†â–ƒâ–‡â–„â–†â–„â–ƒâ–…â–ƒâ–ˆâ–ƒâ–‡â–â–…â–†â–„â–†â–†â–…â–„â–…â–‡â–„â–†â–„â–„â–…â–…â–„â–‡â–…â–„â–‡â–…â–ˆâ–„â–‡â–„â–ˆ
wandb:       eval/ensemble_f1 â–ˆâ–†â–…â–â–†â–†â–†â–ƒâ–†â–ƒâ–…â–ˆâ–†â–‚â–‡â–…â–…â–„â–‚â–„â–†â–‡â–…â–‚â–‚â–„â–…â–†â–…â–ƒâ–„â–ƒâ–†â–…â–…â–…â–‡â–…â–ƒâ–ƒ
wandb:           train/avg_f1 â–‡â–…â–‚â–‡â–â–â–â–…â–„â–ƒâ–„â–‡â–â–â–†â–ƒâ–â–â–„â–†â–„â–†â–†â–‚â–â–†â–‚â–ˆâ–„â–†â–ƒâ–…â–ƒâ–„â–…â–â–‚â–„â–ƒâ–…
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–ƒâ–‡â–†â–‡â–„â–ƒâ–ˆâ–„â–„â–‡â–‡â–†â–†â–„â–ƒâ–ˆâ–ˆâ–†â–‡â–‡â–‡â–†â–ƒâ–„â–„â–…â–‡â–‡â–ƒâ–†â–†â–‡â–„â–†â–ƒâ–â–†
wandb:         train/mil_loss â–‡â–ˆâ–‡â–ˆâ–†â–†â–†â–†â–…â–…â–†â–†â–‡â–†â–…â–‡â–…â–‡â–„â–†â–…â–†â–‚â–ƒâ–‡â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–…â–„â–â–‚â–ƒâ–„â–ƒâ–
wandb:      train/policy_loss â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86417
wandb: best/eval_avg_mil_loss 0.38098
wandb:  best/eval_ensemble_f1 0.86417
wandb:            eval/avg_f1 0.82448
wandb:      eval/avg_mil_loss 0.50573
wandb:       eval/ensemble_f1 0.82448
wandb:           train/avg_f1 0.8141
wandb:      train/ensemble_f1 0.8141
wandb:         train/mil_loss 0.57183
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fancy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7jydohyb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074752-7jydohyb/logs
wandb: ERROR Run 7jydohyb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2wmt5noh with config:
wandb: 	actor_learning_rate: 0.00015730885045754284
wandb: 	attention_dropout_p: 0.38673100281876394
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27759420376381316
wandb: 	temperature: 9.929069175497018
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075048-2wmt5noh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wmt5noh
wandb: uploading history steps 119-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–ˆ
wandb:            eval/avg_f1 â–†â–…â–„â–…â–„â–…â–„â–„â–…â–„â–ƒâ–…â–†â–…â–†â–…â–ˆâ–ˆâ–„â–…â–…â–†â–†â–†â–‚â–„â–ˆâ–…â–…â–â–†â–†â–…â–„â–ˆâ–ƒâ–ƒâ–…â–„â–„
wandb:      eval/avg_mil_loss â–…â–†â–…â–…â–ƒâ–„â–…â–†â–‡â–ˆâ–ƒâ–†â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚â–…â–‚â–‚â–„â–ƒâ–…â–ƒâ–‡â–‚â–…â–â–…â–…â–†â–‡â–†â–„â–‚â–‚â–ƒâ–‡â–„
wandb:       eval/ensemble_f1 â–ƒâ–‡â–…â–…â–ƒâ–„â–…â–„â–„â–†â–„â–„â–„â–â–‡â–ˆâ–ˆâ–†â–‡â–…â–ƒâ–…â–„â–‚â–„â–‚â–ˆâ–…â–†â–„â–‡â–‚â–ˆâ–‡â–†â–ƒâ–…â–…â–‚â–„
wandb:           train/avg_f1 â–…â–„â–ƒâ–†â–â–ƒâ–‚â–„â–ƒâ–†â–‡â–…â–‚â–„â–ƒâ–†â–ƒâ–„â–…â–‚â–…â–†â–„â–ƒâ–ƒâ–„â–„â–ˆâ–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–„â–…â–„â–„
wandb:      train/ensemble_f1 â–„â–„â–„â–‚â–„â–…â–…â–„â–†â–‡â–…â–„â–„â–…â–†â–†â–‚â–…â–†â–„â–„â–ˆâ–†â–„â–…â–…â–„â–„â–â–ƒâ–…â–ƒâ–‚â–†â–ƒâ–„â–†â–ƒâ–ƒâ–„
wandb:         train/mil_loss â–‡â–ˆâ–‡â–…â–…â–…â–†â–‡â–„â–†â–‚â–†â–ƒâ–†â–„â–„â–…â–…â–‡â–‡â–‡â–†â–ƒâ–‡â–‡â–‡â–‚â–‡â–‡â–ƒâ–‚â–†â–â–†â–†â–‡â–‚â–‚â–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.42726
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.4429
wandb:       eval/ensemble_f1 0.79074
wandb:           train/avg_f1 0.78123
wandb:      train/ensemble_f1 0.78123
wandb:         train/mil_loss 0.92933
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run peach-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wmt5noh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075048-2wmt5noh/logs
wandb: ERROR Run 2wmt5noh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dpqncflf with config:
wandb: 	actor_learning_rate: 4.911716531162975e-05
wandb: 	attention_dropout_p: 0.21501104178046365
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0048492679654191795
wandb: 	temperature: 5.2106707074072
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075318-dpqncflf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpqncflf
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–…â–„â–…â–‡â–„â–„â–…â–ˆâ–ƒâ–…â–ƒâ–†â–ƒâ–…â–ƒâ–„â–„â–…â–…â–„â–„â–„â–‚â–…â–†â–…â–†â–ƒâ–†â–â–â–…â–„â–ƒâ–…â–†â–…â–†
wandb:      eval/avg_mil_loss â–‚â–ƒâ–…â–…â–ˆâ–„â–„â–ƒâ–‚â–â–„â–ˆâ–ƒâ–…â–‚â–„â–‡â–„â–‚â–†â–‚â–†â–â–„â–‡â–†â–ƒâ–â–…â–…â–„â–„â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–‚
wandb:       eval/ensemble_f1 â–„â–„â–‚â–…â–„â–‡â–„â–…â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–…â–…â–„â–…â–…â–…â–„â–‚â–â–†â–…â–‡â–…â–†â–ƒâ–„â–â–â–„â–…â–ˆâ–ƒâ–†â–„â–…â–ƒ
wandb:           train/avg_f1 â–…â–…â–â–…â–†â–ƒâ–…â–…â–…â–ˆâ–ƒâ–†â–„â–„â–„â–„â–…â–†â–†â–…â–…â–†â–ƒâ–„â–ƒâ–…â–†â–…â–‚â–†â–‡â–„â–‡â–ˆâ–…â–†â–…â–…â–ƒâ–†
wandb:      train/ensemble_f1 â–„â–„â–‚â–„â–ƒâ–ˆâ–„â–ƒâ–â–…â–„â–…â–ƒâ–„â–…â–†â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–†â–…â–â–†â–…â–…â–‡â–„â–„â–†â–ƒâ–„â–†â–…â–‚â–ƒâ–†
wandb:         train/mil_loss â–…â–â–ƒâ–†â–‡â–†â–…â–„â–‡â–‚â–ƒâ–„â–†â–…â–‡â–ƒâ–…â–ˆâ–„â–…â–†â–„â–…â–…â–†â–„â–ƒâ–ƒâ–‚â–„â–…â–…â–„â–„â–…â–â–‚â–…â–…â–†
wandb:      train/policy_loss â–…â–ˆâ–â–ˆâ–…â–…â–…â–â–ˆâ–…â–â–…â–â–…â–â–â–â–â–â–…â–ˆâ–â–…â–â–…â–…â–ˆâ–â–…â–â–â–…â–â–ˆâ–â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–ˆâ–…â–…â–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–…â–…â–â–ˆâ–…â–â–â–â–…â–ˆâ–â–â–…â–â–…â–ˆâ–…â–â–ˆâ–…â–â–â–â–ˆâ–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8451
wandb: best/eval_avg_mil_loss 0.39566
wandb:  best/eval_ensemble_f1 0.8451
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.41583
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.81151
wandb:      train/ensemble_f1 0.81151
wandb:         train/mil_loss 0.90462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run generous-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpqncflf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075318-dpqncflf/logs
wandb: ERROR Run dpqncflf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zl96hfmw with config:
wandb: 	actor_learning_rate: 7.69186760673416e-06
wandb: 	attention_dropout_p: 0.07214383280383219
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.40378809204465793
wandb: 	temperature: 3.1892127357940514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075441-zl96hfmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl96hfmw
wandb: uploading wandb-summary.json; uploading history steps 53-65, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‡â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–‚â–†â–…â–…â–ƒâ–†â–…â–…â–„â–„â–†â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–†â–„â–ˆâ–â–„â–…â–ƒâ–‚â–„â–‡â–„â–„â–„â–…â–„â–…â–†â–†â–…
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–„â–„â–†â–†â–„â–ƒâ–…â–‚â–…â–ƒâ–…â–†â–„â–ƒâ–…â–ƒâ–„â–†â–ƒâ–â–ƒâ–„â–…â–‚â–„â–…â–ƒâ–„â–†â–ˆâ–„â–„â–„â–‡â–„â–â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–â–â–…â–„â–„â–†â–‚â–†â–ƒâ–…â–…â–…â–‚â–ƒâ–…â–„â–‚â–„â–â–ƒâ–…â–‚â–ˆâ–‚â–ƒâ–ƒâ–â–…â–†â–„â–‚â–â–„â–…â–ƒâ–ƒâ–ƒâ–†â–„
wandb:           train/avg_f1 â–„â–ƒâ–â–‚â–ƒâ–‚â–„â–„â–†â–ƒâ–‚â–…â–„â–ƒâ–†â–…â–…â–†â–‚â–â–‚â–‚â–â–‡â–‚â–‚â–‚â–‡â–†â–ˆâ–„â–‡â–ˆâ–…â–…â–†â–‚â–ƒâ–†â–‡
wandb:      train/ensemble_f1 â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–†â–„â–â–„â–ƒâ–„â–ƒâ–†â–ˆâ–…â–„â–ƒâ–…â–‚â–‚â–‡â–…â–‚â–‚â–†â–…â–„â–†â–…â–‡â–…â–ƒâ–†â–‚â–ƒâ–†
wandb:         train/mil_loss â–…â–…â–„â–‡â–…â–ƒâ–…â–†â–ˆâ–…â–‡â–‡â–…â–…â–„â–‡â–…â–‡â–„â–…â–‡â–ƒâ–ƒâ–…â–ˆâ–†â–â–†â–‚â–‡â–‡â–†â–‡â–„â–…â–…â–ˆâ–†â–…â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86005
wandb: best/eval_avg_mil_loss 0.4914
wandb:  best/eval_ensemble_f1 0.86005
wandb:            eval/avg_f1 0.81586
wandb:      eval/avg_mil_loss 0.36602
wandb:       eval/ensemble_f1 0.81586
wandb:           train/avg_f1 0.81872
wandb:      train/ensemble_f1 0.81872
wandb:         train/mil_loss 0.99519
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run neat-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl96hfmw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075441-zl96hfmw/logs
wandb: ERROR Run zl96hfmw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8fx2s3sc with config:
wandb: 	actor_learning_rate: 2.52388269751496e-05
wandb: 	attention_dropout_p: 0.33948505856203837
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3812145307526348
wandb: 	temperature: 5.396954040680397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075604-8fx2s3sc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fx2s3sc
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 117-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–‡â–ˆâ–…â–†â–…â–„â–†â–ˆâ–ƒâ–‡â–„â–ˆâ–â–â–ƒâ–…â–‡â–„â–†â–†â–‚â–…â–„â–…â–ˆâ–†â–…â–ƒâ–„â–†â–„â–…â–†â–…â–‡â–‡â–…â–†
wandb:      eval/avg_mil_loss â–†â–‡â–‚â–‚â–†â–‡â–†â–…â–„â–ƒâ–‚â–‚â–„â–‚â–ƒâ–†â–„â–‡â–ƒâ–„â–ˆâ–†â–ƒâ–‡â–ˆâ–â–„â–‡â–ƒâ–‚â–…â–…â–…â–„â–ˆâ–„â–†â–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–‡â–„â–ƒâ–…â–…â–ƒâ–…â–…â–„â–â–†â–‚â–„â–…â–ƒâ–…â–„â–‚â–ƒâ–„â–‡â–ˆâ–†â–†â–ƒâ–‡â–„â–ƒâ–‡â–†â–…â–†â–„â–†â–†â–†â–†â–…
wandb:           train/avg_f1 â–ƒâ–†â–„â–„â–ˆâ–„â–‚â–ƒâ–„â–â–ƒâ–‡â–ƒâ–ƒâ–‚â–†â–„â–ƒâ–…â–†â–„â–…â–„â–…â–„â–‚â–‡â–…â–ƒâ–„â–ƒâ–‚â–‚â–„â–ƒâ–‡â–â–ƒâ–ƒâ–„
wandb:      train/ensemble_f1 â–…â–ƒâ–…â–‡â–„â–ƒâ–…â–â–ƒâ–…â–‚â–„â–ƒâ–ˆâ–‚â–‡â–‚â–†â–ƒâ–…â–„â–…â–„â–…â–ƒâ–…â–„â–†â–†â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–‡â–…â–…â–„â–
wandb:         train/mil_loss â–ˆâ–†â–„â–‡â–†â–„â–†â–‡â–…â–…â–‚â–†â–…â–„â–‚â–…â–„â–„â–ƒâ–…â–„â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–„â–„â–â–†â–„â–‚â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.42357
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.80019
wandb:      eval/avg_mil_loss 0.40018
wandb:       eval/ensemble_f1 0.80019
wandb:           train/avg_f1 0.78579
wandb:      train/ensemble_f1 0.78579
wandb:         train/mil_loss 0.91761
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stilted-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8fx2s3sc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075604-8fx2s3sc/logs
wandb: ERROR Run 8fx2s3sc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ew8126ib with config:
wandb: 	actor_learning_rate: 1.1911926380922591e-05
wandb: 	attention_dropout_p: 0.023876529543066183
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9446195454384922
wandb: 	temperature: 1.079017977373854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075838-ew8126ib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ew8126ib
wandb: uploading wandb-summary.json
wandb: uploading history steps 105-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–†â–…â–†â–ƒâ–‚â–…â–†â–ˆâ–‚â–ƒâ–‚â–…â–‚â–…â–‚â–‚â–„â–†â–„â–‡â–‡â–…â–‚â–…â–ƒâ–‡â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–†â–„â–â–„â–†
wandb:      eval/avg_mil_loss â–â–…â–ˆâ–„â–ƒâ–‡â–†â–ƒâ–…â–ˆâ–‡â–‡â–‡â–†â–„â–†â–„â–„â–…â–ƒâ–‡â–‡â–ˆâ–†â–‚â–ˆâ–‚â–‡â–…â–‡â–…â–‚â–ˆâ–„â–„â–…â–…â–ƒâ–…â–…
wandb:       eval/ensemble_f1 â–‡â–…â–†â–…â–ˆâ–â–„â–ˆâ–†â–†â–„â–†â–†â–„â–†â–‚â–†â–…â–‡â–…â–‡â–„â–„â–ƒâ–…â–‡â–‚â–…â–„â–ƒâ–…â–ƒâ–„â–…â–…â–…â–„â–†â–ƒâ–‡
wandb:           train/avg_f1 â–…â–ƒâ–†â–ƒâ–‚â–„â–†â–‡â–†â–ƒâ–„â–ƒâ–„â–…â–„â–…â–ˆâ–…â–…â–ƒâ–‡â–â–ƒâ–†â–‡â–„â–ƒâ–…â–ƒâ–ƒâ–„â–†â–‚â–…â–‡â–…â–ƒâ–…â–…â–
wandb:      train/ensemble_f1 â–ˆâ–„â–ˆâ–‡â–…â–‚â–„â–†â–…â–‡â–†â–…â–…â–„â–„â–…â–ˆâ–…â–‚â–…â–…â–…â–‡â–†â–‡â–â–„â–„â–„â–‡â–„â–…â–„â–„â–ƒâ–…â–ˆâ–…â–†â–†
wandb:         train/mil_loss â–â–„â–…â–…â–…â–ƒâ–â–„â–ˆâ–„â–‚â–„â–ƒâ–…â–‚â–‡â–„â–†â–†â–ƒâ–…â–†â–„â–…â–„â–…â–„â–„â–†â–†â–ƒâ–„â–ƒâ–ƒâ–…â–‚â–‡â–…â–„â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84246
wandb: best/eval_avg_mil_loss 0.40261
wandb:  best/eval_ensemble_f1 0.84246
wandb:            eval/avg_f1 0.80899
wandb:      eval/avg_mil_loss 0.47325
wandb:       eval/ensemble_f1 0.80899
wandb:           train/avg_f1 0.79117
wandb:      train/ensemble_f1 0.79117
wandb:         train/mil_loss 1.01472
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glad-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ew8126ib
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075838-ew8126ib/logs
wandb: ERROR Run ew8126ib errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 35rb633n with config:
wandb: 	actor_learning_rate: 1.5045617595875412e-05
wandb: 	attention_dropout_p: 0.2474950184510448
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29590684427490566
wandb: 	temperature: 7.28625284455372
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080058-35rb633n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/35rb633n
wandb: uploading history steps 194-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–„â–‚â–ƒâ–ˆâ–ˆâ–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–„â–†â–…â–†â–…â–„â–ƒâ–…â–ƒâ–†â–„â–ƒâ–†â–†â–„â–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–†â–‚â–„â–†â–„â–…â–„â–…â–‚â–ƒâ–…â–ƒâ–ƒâ–„â–„â–†â–ƒ
wandb:      eval/avg_mil_loss â–ˆâ–‚â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–…â–…â–†â–â–‚â–„â–â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚â–„â–†â–†â–„â–ƒâ–‚â–ƒâ–…â–‚â–‚â–ƒâ–…â–„â–„â–…
wandb:       eval/ensemble_f1 â–„â–†â–„â–ƒâ–ƒâ–…â–†â–‡â–‚â–…â–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–†â–„â–„â–…â–â–…â–…â–…â–ˆâ–‚â–â–‚â–„â–‚â–„â–ƒâ–†â–‚â–†â–†â–‚â–†â–†â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–‡â–‡â–„â–ƒâ–†â–„â–‡â–„â–„â–†â–†â–„â–„â–„â–„â–…â–†â–‡â–â–ƒâ–ˆâ–ƒâ–„â–ˆâ–‡â–„â–…â–„â–ˆâ–ƒâ–†â–†â–†â–…â–‡â–†â–…â–‚
wandb:      train/ensemble_f1 â–†â–ƒâ–„â–â–‚â–†â–‚â–…â–„â–‚â–ƒâ–„â–‡â–‚â–‚â–ˆâ–ƒâ–ƒâ–‚â–†â–…â–„â–„â–ƒâ–ˆâ–…â–â–â–†â–†â–ƒâ–ƒâ–…â–ƒâ–†â–„â–†â–„â–…â–
wandb:         train/mil_loss â–‡â–‡â–†â–…â–…â–ˆâ–†â–‡â–†â–„â–…â–…â–†â–ˆâ–‡â–ˆâ–„â–ƒâ–‡â–„â–ƒâ–…â–†â–…â–…â–…â–„â–†â–„â–…â–â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–‚
wandb:      train/policy_loss â–â–â–…â–…â–ˆâ–…â–…â–â–â–…â–…â–â–…â–…â–ˆâ–…â–…â–â–â–…â–…â–â–ˆâ–ˆâ–â–â–…â–â–â–…â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–…â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.37377
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.80599
wandb:      eval/avg_mil_loss 0.46915
wandb:       eval/ensemble_f1 0.80599
wandb:            test/avg_f1 0.8065
wandb:      test/avg_mil_loss 0.45627
wandb:       test/ensemble_f1 0.8065
wandb:           train/avg_f1 0.78969
wandb:      train/ensemble_f1 0.78969
wandb:         train/mil_loss 0.69001
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sunny-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/35rb633n
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080058-35rb633n/logs
wandb: Agent Starting Run: rbl57ok4 with config:
wandb: 	actor_learning_rate: 3.043731862825304e-06
wandb: 	attention_dropout_p: 0.09119523434746007
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08318985674511747
wandb: 	temperature: 2.7806575369437403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080455-rbl57ok4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbl57ok4
wandb: uploading history steps 104-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–„â–‡â–„â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–ƒâ–„â–†â–„â–…â–â–…â–‚â–ˆâ–ƒâ–…â–…â–†â–‡â–†â–…â–†â–†â–‚â–…â–…â–†â–…â–ƒâ–…â–„â–ˆâ–„â–„â–„â–†â–†â–„â–ƒâ–„â–†â–…â–†
wandb:      eval/avg_mil_loss â–†â–„â–‡â–‡â–„â–â–‚â–…â–‡â–„â–„â–…â–‚â–‡â–„â–ƒâ–†â–ƒâ–„â–„â–…â–†â–„â–„â–…â–„â–„â–ƒâ–„â–…â–„â–ˆâ–ƒâ–ƒâ–†â–ƒâ–…â–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–‚â–â–…â–…â–†â–ƒâ–ƒâ–„â–ƒâ–„â–â–‡â–…â–„â–…â–ˆâ–…â–…â–â–…â–„â–…â–ƒâ–‚â–„â–ƒâ–…â–‡â–…â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–„â–…â–„â–„
wandb:           train/avg_f1 â–‚â–ˆâ–„â–„â–„â–„â–„â–‡â–‚â–…â–„â–„â–‚â–‚â–…â–†â–†â–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚â–‡â–â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–…â–„â–…â–„
wandb:      train/ensemble_f1 â–…â–…â–„â–„â–…â–‡â–„â–ƒâ–„â–…â–…â–ƒâ–ˆâ–‚â–ƒâ–‚â–…â–ƒâ–â–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–ˆâ–â–„â–ƒâ–â–ƒâ–…â–ƒâ–ˆâ–„â–ƒâ–„â–…â–…â–„
wandb:         train/mil_loss â–†â–„â–ƒâ–…â–„â–ƒâ–…â–„â–ˆâ–…â–‚â–„â–â–ˆâ–†â–ƒâ–‚â–†â–ƒâ–ƒâ–„â–‚â–ˆâ–ƒâ–„â–‡â–ƒâ–‡â–†â–…â–…â–ƒâ–‚â–â–‚â–†â–‡â–‡â–‚â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–…â–„â–ƒâ–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85743
wandb: best/eval_avg_mil_loss 0.41126
wandb:  best/eval_ensemble_f1 0.85743
wandb:            eval/avg_f1 0.81654
wandb:      eval/avg_mil_loss 0.43069
wandb:       eval/ensemble_f1 0.81654
wandb:           train/avg_f1 0.7936
wandb:      train/ensemble_f1 0.7936
wandb:         train/mil_loss 0.66498
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wandering-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbl57ok4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080455-rbl57ok4/logs
wandb: ERROR Run rbl57ok4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zokyq3tj with config:
wandb: 	actor_learning_rate: 0.00023080380746894272
wandb: 	attention_dropout_p: 0.189291304995764
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4802763592858651
wandb: 	temperature: 5.30341466922621
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080732-zokyq3tj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zokyq3tj
wandb: uploading history steps 172-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–„â–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–â–„â–„â–…â–„â–„â–‚â–†â–ƒâ–‡â–ƒâ–„â–„â–…â–„â–ƒâ–ˆâ–„â–…â–„â–‚â–…â–ƒâ–„â–‚â–„â–‚â–„â–ƒâ–‚â–‚â–…â–â–…â–†â–„â–…â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–â–†â–‚â–†â–†â–ˆâ–â–„â–„â–…â–…â–‚â–„â–†â–†â–…â–‚â–ƒâ–†â–ƒâ–„â–ƒâ–‚â–„â–†â–ƒâ–ƒâ–„â–ˆâ–ˆâ–‡â–„â–†â–‡â–…â–†â–ƒâ–†â–‡
wandb:       eval/ensemble_f1 â–†â–„â–„â–†â–‚â–†â–ƒâ–„â–ƒâ–â–‚â–†â–†â–„â–†â–…â–„â–ƒâ–â–ˆâ–…â–…â–‡â–‚â–„â–â–…â–ƒâ–†â–ƒâ–‚â–…â–ƒâ–†â–ˆâ–…â–„â–…â–ƒâ–‡
wandb:           train/avg_f1 â–†â–ˆâ–ƒâ–‡â–„â–†â–„â–†â–‡â–‡â–†â–†â–†â–„â–ˆâ–†â–…â–†â–…â–…â–†â–†â–…â–ƒâ–„â–ˆâ–„â–‡â–„â–ˆâ–†â–„â–…â–‚â–ƒâ–…â–â–‡â–‡â–
wandb:      train/ensemble_f1 â–†â–‡â–ƒâ–„â–â–‡â–‡â–†â–„â–‚â–ƒâ–…â–„â–â–‚â–…â–…â–„â–ˆâ–…â–‚â–…â–…â–‡â–ˆâ–†â–‡â–„â–†â–„â–‚â–†â–ˆâ–‡â–â–†â–ƒâ–„â–„â–‚
wandb:         train/mil_loss â–‡â–…â–ˆâ–†â–‡â–…â–†â–…â–…â–…â–„â–„â–‡â–…â–„â–…â–„â–„â–„â–†â–„â–„â–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–†â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86095
wandb: best/eval_avg_mil_loss 0.41932
wandb:  best/eval_ensemble_f1 0.86095
wandb:            eval/avg_f1 0.78828
wandb:      eval/avg_mil_loss 0.49768
wandb:       eval/ensemble_f1 0.78828
wandb:           train/avg_f1 0.78334
wandb:      train/ensemble_f1 0.78334
wandb:         train/mil_loss 0.48139
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zokyq3tj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080732-zokyq3tj/logs
wandb: ERROR Run zokyq3tj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v72zig2t with config:
wandb: 	actor_learning_rate: 4.632730818664001e-06
wandb: 	attention_dropout_p: 0.49407935597509434
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7552653283511163
wandb: 	temperature: 2.0687659592382204
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081130-v72zig2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/fobtzvoi
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v72zig2t
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–†â–â–â–ˆâ–ƒâ–‚â–‚â–…â–…â–…â–ƒâ–…â–‡â–‚â–ƒâ–†â–ƒâ–„â–„â–†â–„â–…â–†â–â–‚â–…â–‚â–„â–…â–„â–†â–…â–…â–â–‚â–†â–ƒ
wandb:      eval/avg_mil_loss â–„â–‚â–‚â–†â–„â–‚â–…â–‚â–‚â–…â–ƒâ–„â–„â–…â–†â–…â–‚â–…â–ˆâ–ƒâ–‚â–„â–„â–â–„â–‚â–‚â–„â–‚â–†â–…â–‚â–‚â–„â–„â–ƒâ–…â–…â–‚â–‚
wandb:       eval/ensemble_f1 â–…â–†â–†â–„â–†â–…â–â–ˆâ–ƒâ–‚â–…â–…â–…â–ƒâ–…â–‡â–‚â–ƒâ–†â–ƒâ–‡â–„â–„â–†â–„â–…â–ƒâ–†â–â–‚â–„â–…â–„â–†â–…â–…â–â–‚â–†â–ƒ
wandb:           train/avg_f1 â–‚â–â–‡â–…â–…â–„â–„â–…â–…â–†â–…â–†â–…â–„â–„â–…â–…â–†â–…â–…â–†â–ƒâ–ƒâ–…â–„â–‚â–†â–†â–†â–ˆâ–…â–†â–„â–†â–‚â–…â–…â–‡â–„â–†
wandb:      train/ensemble_f1 â–‚â–â–‡â–…â–ƒâ–„â–„â–…â–…â–†â–…â–„â–†â–…â–„â–„â–…â–†â–ƒâ–„â–ˆâ–†â–ƒâ–…â–„â–‚â–†â–†â–†â–ˆâ–…â–†â–„â–†â–‚â–…â–…â–‡â–„â–†
wandb:         train/mil_loss â–‡â–„â–‚â–„â–†â–â–ƒâ–‡â–…â–‚â–†â–†â–…â–†â–‡â–‚â–…â–â–ƒâ–‡â–ƒâ–…â–‚â–‚â–„â–‡â–‚â–ˆâ–ƒâ–ƒâ–†â–„â–‚â–ƒâ–ƒâ–…â–ƒâ–â–†â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.38156
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.78961
wandb:      eval/avg_mil_loss 0.39061
wandb:       eval/ensemble_f1 0.78961
wandb:           train/avg_f1 0.81368
wandb:      train/ensemble_f1 0.81368
wandb:         train/mil_loss 0.55259
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v72zig2t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081130-v72zig2t/logs
wandb: ERROR Run v72zig2t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: sko79bas with config:
wandb: 	actor_learning_rate: 2.9048992990049663e-05
wandb: 	attention_dropout_p: 0.13573839847293084
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8505353246892694
wandb: 	temperature: 6.585166379632875
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081252-sko79bas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sko79bas
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 54-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‚â–â–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–„â–„â–…â–ˆâ–†â–…â–‚â–â–â–…â–…â–…â–‚â–†â–ˆâ–„â–„â–…â–ƒâ–ƒâ–„â–‡â–†â–ˆâ–‚â–ƒâ–†â–„â–‡â–â–ƒâ–„â–„â–‚â–‚â–†â–†â–ƒâ–„
wandb:      eval/avg_mil_loss â–…â–†â–‚â–â–„â–ˆâ–ƒâ–‚â–…â–ƒâ–ƒâ–„â–„â–„â–‚â–…â–ƒâ–†â–â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–„â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–â–‚
wandb:       eval/ensemble_f1 â–…â–†â–„â–‚â–„â–ˆâ–†â–…â–ˆâ–‚â–„â–„â–…â–…â–‚â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–ˆâ–„â–„â–…â–„â–ƒâ–†â–‡â–„â–â–„â–„â–†â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–…â–„â–…â–ƒâ–…â–…â–ƒâ–…â–„â–…â–„â–…â–„â–ƒâ–†â–ƒâ–â–‚â–‚â–‡â–ƒâ–‚â–‡â–…â–„â–„â–ƒâ–‚â–ˆâ–„â–‡â–†â–‚â–„â–„â–„â–‚â–‚
wandb:      train/ensemble_f1 â–„â–…â–…â–…â–‡â–†â–ƒâ–…â–…â–„â–…â–…â–…â–„â–„â–ƒâ–â–â–‚â–â–‡â–ƒâ–‚â–‡â–…â–…â–„â–ƒâ–‚â–ˆâ–…â–‚â–…â–†â–†â–„â–„â–ƒâ–†â–‚
wandb:         train/mil_loss â–ƒâ–…â–†â–„â–…â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–ƒâ–…â–ˆâ–…â–…â–ƒâ–„â–„â–ƒâ–†â–…â–…â–„â–„â–‚â–‚â–…â–â–…â–„â–„â–…â–ƒâ–„â–†â–†â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82808
wandb: best/eval_avg_mil_loss 0.42459
wandb:  best/eval_ensemble_f1 0.82808
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.39525
wandb:       eval/ensemble_f1 0.78777
wandb:            test/avg_f1 0.77718
wandb:      test/avg_mil_loss 0.53486
wandb:       test/ensemble_f1 0.77718
wandb:           train/avg_f1 0.78401
wandb:      train/ensemble_f1 0.78401
wandb:         train/mil_loss 0.90701
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run serene-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sko79bas
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081252-sko79bas/logs
wandb: Agent Starting Run: trhe6tzm with config:
wandb: 	actor_learning_rate: 1.7837828017669115e-05
wandb: 	attention_dropout_p: 0.2443419115547802
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6342551333923706
wandb: 	temperature: 2.7877427182464376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081410-trhe6tzm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/trhe6tzm
wandb: uploading wandb-summary.json
wandb: uploading history steps 100-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–ˆâ–†â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–†â–ˆ
wandb:            eval/avg_f1 â–„â–„â–‡â–„â–…â–…â–…â–…â–„â–†â–†â–‡â–ˆâ–„â–…â–„â–ƒâ–†â–ƒâ–„â–…â–„â–„â–‡â–„â–†â–ƒâ–…â–ˆâ–„â–‡â–…â–†â–…â–†â–„â–…â–…â–â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–„â–ƒâ–â–„â–„â–†â–„â–ƒâ–„â–„â–â–‚â–„â–ƒâ–‚â–„â–‚â–†â–„â–‚â–„â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–ƒâ–ˆâ–ƒâ–…
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–„â–†â–…â–ˆâ–†â–ƒâ–†â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–‡â–†â–‡â–…â–‚â–„â–‡â–…â–†â–…â–†â–ƒâ–…â–…â–…â–…â–â–…â–„â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–‚â–‡â–†â–â–ƒâ–ƒâ–†â–ˆâ–…â–…â–„â–…â–…â–†â–„â–ƒâ–…â–†â–‚â–„â–ƒâ–„â–„â–…â–†â–…â–ƒâ–‡â–„â–‡â–„â–‚â–…â–ƒâ–ƒâ–„â–ˆâ–…â–†
wandb:      train/ensemble_f1 â–…â–â–…â–†â–„â–ƒâ–ƒâ–…â–ˆâ–…â–ƒâ–‡â–ƒâ–„â–â–…â–„â–…â–…â–…â–†â–†â–ƒâ–ƒâ–„â–…â–„â–„â–„â–†â–‡â–„â–ƒâ–‡â–…â–…â–‚â–ƒâ–ƒâ–†
wandb:         train/mil_loss â–†â–…â–†â–…â–…â–†â–†â–…â–„â–„â–…â–…â–†â–„â–†â–„â–…â–ƒâ–„â–ˆâ–„â–ƒâ–…â–„â–„â–ƒâ–†â–…â–†â–„â–„â–…â–„â–ƒâ–„â–…â–‚â–â–„â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–„â–†â–…â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–„â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85224
wandb: best/eval_avg_mil_loss 0.41537
wandb:  best/eval_ensemble_f1 0.85224
wandb:            eval/avg_f1 0.79867
wandb:      eval/avg_mil_loss 0.43428
wandb:       eval/ensemble_f1 0.79867
wandb:            test/avg_f1 0.81707
wandb:      test/avg_mil_loss 0.40195
wandb:       test/ensemble_f1 0.81707
wandb:           train/avg_f1 0.80178
wandb:      train/ensemble_f1 0.80178
wandb:         train/mil_loss 1.65477
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/trhe6tzm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081410-trhe6tzm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gs5np0nw with config:
wandb: 	actor_learning_rate: 3.454535859118679e-05
wandb: 	attention_dropout_p: 0.12561726819171987
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 61
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7228295360403766
wandb: 	temperature: 5.98300893493124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081633-gs5np0nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gs5np0nw
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 59-61, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–ƒâ–ˆâ–ˆâ–‡â–ˆâ–†â–…â–‡â–…â–„â–ƒâ–„â–†â–‡â–…â–ƒâ–†â–ƒâ–‡â–†â–ƒâ–…â–†â–…â–ˆâ–„â–ƒâ–…â–„â–…â–„â–„â–†â–â–†â–†â–„
wandb:      eval/avg_mil_loss â–ƒâ–†â–…â–†â–†â–…â–„â–†â–„â–â–ƒâ–†â–„â–†â–†â–‡â–ˆâ–‚â–„â–†â–‡â–†â–…â–‡â–‡â–„â–†â–ˆâ–„â–ƒâ–„â–†â–„â–„â–„â–…â–„â–„â–„â–ˆ
wandb:       eval/ensemble_f1 â–„â–„â–‚â–‡â–‚â–†â–„â–ˆâ–…â–„â–…â–ƒâ–‡â–„â–ƒâ–ƒâ–ƒâ–…â–‡â–„â–‚â–‚â–‡â–„â–‚â–„â–…â–ƒâ–ƒâ–‚â–…â–„â–ƒâ–â–ƒâ–„â–…â–…â–…â–ˆ
wandb:           train/avg_f1 â–„â–‡â–†â–‡â–‚â–ˆâ–‚â–„â–â–…â–„â–…â–ƒâ–…â–…â–…â–‡â–„â–…â–…â–‚â–‡â–„â–ƒâ–‚â–…â–‡â–†â–†â–ƒâ–„â–†â–ƒâ–„â–†â–…â–„â–†â–„â–†
wandb:      train/ensemble_f1 â–ƒâ–†â–„â–‡â–â–â–ƒâ–…â–„â–„â–ƒâ–„â–‚â–…â–…â–ˆâ–…â–‡â–ƒâ–„â–ƒâ–…â–‡â–ƒâ–‚â–ƒâ–‡â–†â–†â–‚â–‚â–†â–„â–…â–…â–„â–…â–ƒâ–„â–…
wandb:         train/mil_loss â–…â–„â–ƒâ–‡â–‡â–„â–ƒâ–…â–‡â–ˆâ–†â–†â–‡â–„â–‚â–†â–…â–‡â–†â–‡â–†â–…â–†â–„â–â–ƒâ–‡â–ƒâ–…â–‡â–„â–…â–‡â–ˆâ–…â–„â–‚â–‡â–…â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.31328
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.83103
wandb:      eval/avg_mil_loss 0.44635
wandb:       eval/ensemble_f1 0.83103
wandb:           train/avg_f1 0.79936
wandb:      train/ensemble_f1 0.79936
wandb:         train/mil_loss 0.87046
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run upbeat-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gs5np0nw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081633-gs5np0nw/logs
wandb: ERROR Run gs5np0nw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: m5emcpka with config:
wandb: 	actor_learning_rate: 0.0007136486834394011
wandb: 	attention_dropout_p: 0.4137575832611152
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18387008696357168
wandb: 	temperature: 9.820598221637324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081745-m5emcpka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5emcpka
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–…â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ƒâ–…â–ˆâ–…â–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–…â–„â–ƒâ–„â–†â–„â–…â–„â–ˆâ–ƒâ–…â–…â–ƒâ–ˆâ–…â–‡â–†â–…â–…â–…â–ˆâ–†â–…â–„â–â–ƒâ–„â–†â–…â–†â–„â–‡â–†â–†â–…â–‡â–…â–‡
wandb:      eval/avg_mil_loss â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ˆâ–…â–‚â–‚â–‚â–„â–‡â–…â–†â–ƒâ–„â–ƒâ–ƒâ–â–„â–ƒâ–„â–†â–ƒâ–…â–…â–ƒâ–‡â–„â–‚â–„â–„
wandb:       eval/ensemble_f1 â–ƒâ–„â–†â–†â–…â–„â–ƒâ–†â–…â–‚â–‡â–ˆâ–„â–ƒâ–…â–ƒâ–â–‚â–‡â–„â–…â–…â–†â–…â–‡â–ƒâ–…â–„â–ƒâ–ƒâ–…â–…â–…â–„â–„â–†â–„â–†â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–„â–ˆâ–„â–ƒâ–ƒâ–†â–„â–„â–†â–„â–ƒâ–â–…â–„â–‚â–â–‡â–ˆâ–‚â–„â–…â–†â–†â–ƒâ–â–…â–â–ƒâ–†â–‡â–‚â–…â–…â–…â–ƒâ–†â–…â–ƒ
wandb:      train/ensemble_f1 â–…â–â–ˆâ–â–…â–†â–„â–…â–…â–…â–…â–„â–ˆâ–†â–…â–†â–„â–ˆâ–†â–†â–ƒâ–‚â–‡â–„â–†â–ˆâ–†â–„â–‚â–†â–‡â–…â–‚â–„â–†â–†â–‚â–„â–ƒâ–‡
wandb:         train/mil_loss â–‡â–†â–ˆâ–†â–†â–„â–„â–…â–…â–‡â–…â–…â–‚â–ƒâ–…â–„â–‚â–„â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–â–„â–ƒâ–ƒâ–„â–‚â–„â–…â–ƒâ–„â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.34881
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.81297
wandb:      eval/avg_mil_loss 0.41856
wandb:       eval/ensemble_f1 0.81297
wandb:            test/avg_f1 0.75658
wandb:      test/avg_mil_loss 0.44604
wandb:       test/ensemble_f1 0.75658
wandb:           train/avg_f1 0.7863
wandb:      train/ensemble_f1 0.7863
wandb:         train/mil_loss 0.72182
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5emcpka
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081745-m5emcpka/logs
wandb: Agent Starting Run: csa2tiob with config:
wandb: 	actor_learning_rate: 6.807133360407079e-06
wandb: 	attention_dropout_p: 0.18587413929303975
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4583167747314902
wandb: 	temperature: 0.4591620649027106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081923-csa2tiob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csa2tiob
wandb: uploading history steps 111-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–ƒâ–…â–‚â–‚â–„â–‚â–…â–…â–‡â–…â–‚â–ƒâ–…â–‚â–†â–ƒâ–„â–†â–…â–ƒâ–…â–ˆâ–…â–„â–†â–ˆâ–ƒâ–â–ƒâ–‚â–„â–â–„â–‚â–†â–†â–„â–
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–„â–…â–ˆâ–â–‚â–ƒâ–„â–„â–…â–‡â–…â–‚â–…â–…â–ƒâ–ƒâ–„â–†â–„â–„â–ƒâ–„â–‡â–…â–ƒâ–†â–ƒâ–…â–‚â–„â–ƒâ–‚â–„â–ƒâ–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–†â–„â–„â–‡â–ƒâ–‡â–…â–â–‡â–†â–ƒâ–ˆâ–†â–†â–…â–„â–ˆâ–„â–†â–„â–ˆâ–„â–‡â–‚â–…â–‡â–‡â–…â–ƒâ–ƒâ–†â–†â–†â–†â–ƒâ–‡â–†â–ƒ
wandb:           train/avg_f1 â–†â–†â–…â–…â–†â–†â–ƒâ–†â–‡â–…â–„â–ƒâ–ƒâ–†â–ƒâ–‡â–‚â–ˆâ–†â–…â–„â–„â–„â–‚â–„â–‚â–†â–â–†â–‚â–ƒâ–ˆâ–…â–…â–†â–ƒâ–‡â–„â–…â–ƒ
wandb:      train/ensemble_f1 â–‚â–‡â–…â–„â–‡â–†â–‡â–„â–†â–‚â–‡â–…â–…â–„â–…â–†â–„â–â–…â–„â–„â–…â–…â–ƒâ–…â–…â–ˆâ–†â–‡â–‡â–ˆâ–†â–…â–‡â–„â–‡â–…â–â–†â–„
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8348
wandb: best/eval_avg_mil_loss 0.41895
wandb:  best/eval_ensemble_f1 0.8348
wandb:            eval/avg_f1 0.78993
wandb:      eval/avg_mil_loss 0.4491
wandb:       eval/ensemble_f1 0.78993
wandb:           train/avg_f1 0.78627
wandb:      train/ensemble_f1 0.78627
wandb:         train/mil_loss 0.6988
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csa2tiob
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081923-csa2tiob/logs
wandb: ERROR Run csa2tiob errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: rphpo7vu with config:
wandb: 	actor_learning_rate: 1.04161638303107e-06
wandb: 	attention_dropout_p: 0.28276479872580135
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8427731862873684
wandb: 	temperature: 6.509451810143943
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082152-rphpo7vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rphpo7vu
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–‡â–‡â–‡â–â–ˆâ–„â–ƒâ–…â–‚
wandb:  best/eval_ensemble_f1 â–â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–…â–„â–…â–ƒâ–…â–†â–„â–…â–„â–‡â–â–„â–„â–…â–ƒâ–ˆâ–‡â–„â–„â–†â–…â–‚â–„â–â–„â–‚â–„â–†â–†â–…â–ƒâ–„â–†â–†â–â–ˆâ–„â–ƒ
wandb:      eval/avg_mil_loss â–‚â–ˆâ–ƒâ–†â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‡â–„â–„â–„â–…â–…â–â–…â–„â–ƒâ–†â–†â–†â–ˆâ–…â–‡â–†â–†â–†â–ƒâ–ˆâ–‚â–„â–ƒâ–„â–†â–„â–‡â–ˆ
wandb:       eval/ensemble_f1 â–…â–‚â–…â–ƒâ–ƒâ–…â–‡â–…â–ƒâ–‡â–†â–…â–‡â–â–ƒâ–‡â–…â–„â–â–ˆâ–„â–‡â–†â–†â–ƒâ–„â–„â–‚â–‚â–„â–†â–„â–„â–†â–…â–ƒâ–‚â–â–‚â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–…â–„â–†â–…â–â–ƒâ–ƒâ–â–…â–ˆâ–…â–…â–…â–ƒâ–‚â–…â–ƒâ–†â–…â–‡â–†â–„â–…â–…â–†â–…â–…â–„â–ƒâ–„â–ƒâ–…â–…â–‡â–ƒâ–…â–ƒâ–„
wandb:      train/ensemble_f1 â–…â–…â–‡â–„â–ƒâ–†â–†â–â–„â–ˆâ–…â–…â–„â–†â–„â–†â–…â–…â–ƒâ–…â–„â–…â–ƒâ–„â–„â–„â–†â–…â–„â–ƒâ–†â–…â–„â–â–‚â–ƒâ–ƒâ–…â–ˆâ–…
wandb:         train/mil_loss â–…â–…â–ƒâ–„â–‡â–ˆâ–ƒâ–…â–ƒâ–†â–…â–ƒâ–â–…â–†â–„â–†â–‡â–ƒâ–‡â–†â–â–ƒâ–ƒâ–…â–…â–…â–†â–‚â–ƒâ–…â–ƒâ–†â–„â–ƒâ–â–‚â–…â–ƒâ–„
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.36449
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.77651
wandb:      eval/avg_mil_loss 0.53416
wandb:       eval/ensemble_f1 0.77651
wandb:            test/avg_f1 0.77342
wandb:      test/avg_mil_loss 0.59264
wandb:       test/ensemble_f1 0.77342
wandb:           train/avg_f1 0.78966
wandb:      train/ensemble_f1 0.78966
wandb:         train/mil_loss 1.03566
wandb:      train/policy_loss -0.19746
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.19746
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rphpo7vu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082152-rphpo7vu/logs
wandb: Agent Starting Run: s9pe95jb with config:
wandb: 	actor_learning_rate: 4.047154557369688e-05
wandb: 	attention_dropout_p: 0.3561346410376312
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9792704124627496
wandb: 	temperature: 5.8132228788204285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082407-s9pe95jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9pe95jb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–ƒâ–‡â–†â–ˆâ–„â–…â–†â–†â–…â–‡â–‡â–…â–‡â–†â–†â–„â–ˆâ–†â–†â–‡â–‡â–†â–‡â–…â–ƒâ–†â–â–„â–†â–ƒâ–‡â–„â–…â–ƒâ–„â–‡â–ˆâ–†
wandb:      eval/avg_mil_loss â–†â–„â–…â–†â–‚â–†â–ƒâ–„â–ƒâ–…â–„â–ˆâ–…â–…â–„â–„â–ƒâ–‚â–†â–‚â–„â–„â–…â–…â–„â–‡â–„â–‚â–…â–†â–ƒâ–„â–‚â–ƒâ–„â–„â–‚â–ƒâ–…â–
wandb:       eval/ensemble_f1 â–…â–‡â–…â–ƒâ–…â–…â–†â–‡â–…â–…â–ˆâ–…â–…â–†â–„â–„â–…â–‡â–‡â–†â–…â–‡â–†â–‡â–…â–„â–ƒâ–…â–â–…â–‡â–ˆâ–‡â–„â–†â–„â–ƒâ–†â–†â–…
wandb:           train/avg_f1 â–â–ƒâ–‡â–ƒâ–„â–…â–„â–â–‚â–ƒâ–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–„â–„â–‚â–„â–‚â–…â–‚â–ˆâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‡â–â–…
wandb:      train/ensemble_f1 â–…â–…â–†â–„â–‡â–‡â–…â–‡â–‡â–…â–…â–‡â–ƒâ–‚â–ƒâ–ˆâ–…â–†â–„â–ˆâ–†â–ƒâ–‡â–â–†â–‚â–ƒâ–†â–‚â–‡â–‚â–…â–…â–„â–‚â–…â–„â–†â–…â–ƒ
wandb:         train/mil_loss â–â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–„â–„â–ƒâ–…â–„â–„â–…â–…â–†â–†â–…â–„â–†â–„â–†â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–…â–‡â–‡â–ˆâ–†â–†
wandb:      train/policy_loss â–…â–…â–…â–…â–†â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82819
wandb: best/eval_avg_mil_loss 0.39873
wandb:  best/eval_ensemble_f1 0.82819
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.38664
wandb:       eval/ensemble_f1 0.79074
wandb:           train/avg_f1 0.79131
wandb:      train/ensemble_f1 0.79131
wandb:         train/mil_loss 1.4449
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fancy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9pe95jb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082407-s9pe95jb/logs
wandb: ERROR Run s9pe95jb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4ci1uwtj with config:
wandb: 	actor_learning_rate: 9.72395866146656e-05
wandb: 	attention_dropout_p: 0.4655741082169558
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.310544121676972
wandb: 	temperature: 3.814809868454656
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082606-4ci1uwtj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ci1uwtj
wandb: uploading history steps 134-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–„â–…â–…â–…â–…â–†â–„â–ˆâ–„â–…â–„â–„â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–„â–„â–…â–ƒâ–†â–†â–ƒâ–…â–…â–…â–…â–†â–†â–â–…â–„â–ƒâ–…â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–†â–„â–â–„â–†â–†â–†â–‚â–‚â–„â–ƒâ–‚â–†â–„â–‡â–„â–†â–…â–ƒâ–†â–„â–…â–„â–ƒâ–ˆâ–ƒâ–ƒâ–†â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–‚â–‡â–†â–ƒâ–…â–â–…â–†â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–…â–„â–ˆâ–…â–‚â–‚â–…â–†â–‡â–…â–ƒâ–ƒâ–„â–ƒâ–†â–†â–ƒâ–‚â–„â–„â–„â–„â–ƒâ–‚
wandb:           train/avg_f1 â–…â–…â–†â–‡â–‡â–ƒâ–†â–„â–‡â–‚â–„â–„â–‡â–†â–…â–ˆâ–‡â–†â–…â–ƒâ–…â–„â–†â–†â–…â–ƒâ–„â–…â–†â–…â–â–â–„â–„â–†â–ƒâ–‚â–â–â–„
wandb:      train/ensemble_f1 â–†â–…â–ƒâ–ˆâ–‡â–ƒâ–ˆâ–†â–‡â–„â–…â–…â–†â–…â–†â–„â–‡â–…â–†â–†â–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–†â–ƒâ–„â–‡â–‡â–ƒâ–ƒâ–ƒâ–‚â–…â–â–…â–
wandb:         train/mil_loss â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–…â–…â–†â–…â–†â–…â–…â–…â–…â–…â–„â–…â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–…â–„â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–†â–…â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.43827
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.76562
wandb:      eval/avg_mil_loss 0.52189
wandb:       eval/ensemble_f1 0.76562
wandb:           train/avg_f1 0.78269
wandb:      train/ensemble_f1 0.78269
wandb:         train/mil_loss 0.59462
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4ci1uwtj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082606-4ci1uwtj/logs
wandb: ERROR Run 4ci1uwtj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 82vd4r7o with config:
wandb: 	actor_learning_rate: 6.915880841688075e-05
wandb: 	attention_dropout_p: 0.04071409290398137
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7922401677841552
wandb: 	temperature: 2.3416956027571603
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082902-82vd4r7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82vd4r7o
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ƒâ–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ƒâ–â–â–…â–„â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–‚â–‚â–†â–„â–„â–„â–†â–„â–‡â–…â–ƒâ–„â–„â–â–„â–†â–„â–…â–†â–‡â–‚â–‡â–‚â–…â–ƒâ–„â–‚â–„â–ƒâ–…â–†â–ˆâ–…â–„â–â–ƒâ–…â–â–†
wandb:      eval/avg_mil_loss â–‚â–â–â–†â–†â–‡â–„â–…â–…â–â–ƒâ–‚â–ƒâ–ˆâ–„â–ˆâ–†â–ƒâ–†â–ƒâ–†â–„â–ƒâ–„â–†â–ƒâ–…â–‡â–…â–ƒâ–„â–„â–„â–‡â–„â–„â–„â–†â–„â–„
wandb:       eval/ensemble_f1 â–…â–ƒâ–â–†â–…â–…â–‡â–†â–…â–ƒâ–„â–ƒâ–„â–…â–…â–†â–ƒâ–…â–†â–„â–…â–‡â–ƒâ–…â–†â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–„â–„â–†â–ˆâ–…â–‚â–…â–ƒâ–†
wandb:           train/avg_f1 â–…â–ƒâ–…â–„â–ƒâ–…â–†â–†â–…â–…â–ƒâ–ˆâ–ƒâ–‡â–„â–‡â–„â–‡â–…â–ƒâ–…â–…â–ƒâ–…â–…â–„â–„â–„â–â–‚â–…â–†â–…â–…â–‡â–…â–ƒâ–„â–ƒâ–…
wandb:      train/ensemble_f1 â–ƒâ–…â–ˆâ–…â–ƒâ–…â–â–…â–†â–†â–„â–ˆâ–ƒâ–…â–„â–„â–„â–‡â–…â–†â–…â–†â–…â–ƒâ–„â–‚â–ƒâ–„â–â–…â–‚â–‡â–„â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–…
wandb:         train/mil_loss â–‡â–ˆâ–‡â–ˆâ–‡â–†â–†â–ˆâ–„â–„â–…â–†â–‡â–…â–„â–‡â–…â–„â–‡â–…â–ƒâ–…â–†â–ƒâ–„â–„â–…â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–‚â–â–
wandb:      train/policy_loss â–„â–„â–„â–…â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–†â–‡â–†â–†â–†â–†â–†â–…â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85751
wandb: best/eval_avg_mil_loss 0.39053
wandb:  best/eval_ensemble_f1 0.85751
wandb:            eval/avg_f1 0.82828
wandb:      eval/avg_mil_loss 0.43144
wandb:       eval/ensemble_f1 0.82828
wandb:           train/avg_f1 0.80677
wandb:      train/ensemble_f1 0.80677
wandb:         train/mil_loss 1.46747
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run major-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82vd4r7o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082902-82vd4r7o/logs
wandb: ERROR Run 82vd4r7o errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ujg3awjz with config:
wandb: 	actor_learning_rate: 1.6950158266720278e-06
wandb: 	attention_dropout_p: 0.26225251183396564
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8362366468720691
wandb: 	temperature: 1.0085949762310964
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083126-ujg3awjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujg3awjz
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ƒâ–ˆâ–‡â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–„â–„â–ˆ
wandb:            eval/avg_f1 â–„â–„â–†â–†â–†â–…â–ƒâ–â–ƒâ–ƒâ–â–…â–‡â–‡â–„â–„â–ˆâ–†â–†â–†â–ƒâ–…â–ƒâ–†â–†â–ƒâ–ˆâ–‡â–ƒâ–„â–†â–„â–†â–†â–…â–…â–„â–„â–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–„â–ˆâ–â–â–„â–…â–„â–‚â–ƒâ–„â–…â–‚â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–â–ƒâ–‚â–‡â–†â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–„â–„
wandb:       eval/ensemble_f1 â–†â–ƒâ–…â–„â–‡â–ƒâ–„â–ƒâ–‡â–„â–„â–ˆâ–†â–„â–ƒâ–…â–ƒâ–…â–†â–â–…â–†â–„â–…â–‡â–ƒâ–„â–†â–†â–†â–…â–†â–‚â–„â–ƒâ–…â–…â–ˆâ–…â–ˆ
wandb:           train/avg_f1 â–…â–…â–ƒâ–ƒâ–†â–„â–ˆâ–â–‚â–†â–…â–…â–‚â–†â–†â–‡â–„â–…â–‡â–…â–†â–‡â–ƒâ–ƒâ–ˆâ–‡â–ˆâ–†â–‡â–‡â–…â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–…â–…
wandb:      train/ensemble_f1 â–ˆâ–„â–‚â–ƒâ–†â–…â–…â–†â–â–‡â–ƒâ–„â–ƒâ–„â–„â–ƒâ–…â–…â–…â–‡â–‚â–‚â–„â–„â–‚â–…â–†â–…â–„â–„â–ƒâ–†â–„â–„â–…â–„â–„â–„â–„â–„
wandb:         train/mil_loss â–…â–‡â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–…â–†â–ƒâ–„â–†â–†â–…â–…â–‡â–„â–†â–„â–ˆâ–†â–†â–†â–ƒâ–†â–†â–â–‚â–†â–ƒâ–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8489
wandb: best/eval_avg_mil_loss 0.35099
wandb:  best/eval_ensemble_f1 0.8489
wandb:            eval/avg_f1 0.8348
wandb:      eval/avg_mil_loss 0.4531
wandb:       eval/ensemble_f1 0.8348
wandb:           train/avg_f1 0.80069
wandb:      train/ensemble_f1 0.80069
wandb:         train/mil_loss 1.50001
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run grateful-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ujg3awjz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083126-ujg3awjz/logs
wandb: ERROR Run ujg3awjz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: f8iw7psc with config:
wandb: 	actor_learning_rate: 2.821615521516233e-05
wandb: 	attention_dropout_p: 0.15158982032465168
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6229068422418379
wandb: 	temperature: 1.4831479908848522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083351-f8iw7psc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8iw7psc
wandb: uploading wandb-summary.json
wandb: uploading history steps 84-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–…â–‡â–†â–†â–„â–…â–„â–…â–„â–„â–…â–…â–†â–‡â–†â–…â–„â–‡â–†â–…â–…â–„â–‡â–…â–…â–ˆâ–…â–ˆâ–‡â–†â–ƒâ–„â–†â–…â–‡â–„â–†â–
wandb:      eval/avg_mil_loss â–„â–…â–‚â–‚â–…â–„â–ƒâ–„â–†â–ƒâ–„â–†â–†â–†â–‚â–â–„â–â–†â–ƒâ–ƒâ–…â–„â–‚â–†â–†â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–†â–ƒâ–ˆâ–â–„â–†â–†â–…
wandb:       eval/ensemble_f1 â–†â–†â–…â–†â–…â–…â–†â–†â–„â–„â–†â–‡â–†â–ˆâ–ˆâ–‡â–…â–„â–‡â–†â–†â–†â–„â–…â–…â–†â–‡â–ƒâ–…â–…â–…â–ƒâ–‡â–„â–„â–†â–ˆâ–…â–‡â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–…â–„â–â–„â–„â–…â–ƒâ–†â–„â–‡â–„â–†â–†â–‡â–†â–…â–„â–…â–ˆâ–‡â–ˆâ–…â–„â–‚â–†â–…â–‚â–…â–†â–ƒâ–…â–ƒâ–ƒâ–…â–â–…â–„â–„
wandb:      train/ensemble_f1 â–„â–â–†â–†â–ƒâ–„â–„â–…â–ƒâ–…â–…â–‡â–…â–…â–‡â–†â–ƒâ–„â–…â–ƒâ–‡â–ˆâ–…â–…â–ƒâ–†â–ƒâ–…â–†â–†â–„â–…â–ƒâ–…â–„â–…â–ƒâ–‚â–†â–„
wandb:         train/mil_loss â–â–ƒâ–„â–„â–…â–‡â–‚â–ƒâ–†â–„â–„â–‡â–†â–…â–„â–‡â–„â–ˆâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–…â–‡â–…â–‡â–ˆâ–…â–„â–‡â–‡â–‡â–†â–†
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–…â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83513
wandb: best/eval_avg_mil_loss 0.38201
wandb:  best/eval_ensemble_f1 0.83513
wandb:            eval/avg_f1 0.8024
wandb:      eval/avg_mil_loss 0.46912
wandb:       eval/ensemble_f1 0.8024
wandb:            test/avg_f1 0.79946
wandb:      test/avg_mil_loss 0.54889
wandb:       test/ensemble_f1 0.79946
wandb:           train/avg_f1 0.79116
wandb:      train/ensemble_f1 0.79116
wandb:         train/mil_loss 1.24959
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run genial-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8iw7psc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083351-f8iw7psc/logs
wandb: Agent Starting Run: uycs3dib with config:
wandb: 	actor_learning_rate: 7.245286166375425e-06
wandb: 	attention_dropout_p: 0.3739075106201316
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25157671374393464
wandb: 	temperature: 5.753308171977306
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083539-uycs3dib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uycs3dib
wandb: uploading wandb-summary.json
wandb: uploading history steps 166-178, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–…â–ˆâ–‡â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–ƒâ–ƒâ–…â–†â–ˆâ–„â–…â–ƒâ–…â–â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–„â–ƒâ–†â–…â–ˆâ–â–„â–…â–‚â–ƒâ–„â–„â–â–„â–„â–„â–ƒâ–†â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–†â–…â–ˆâ–…â–ƒâ–†â–ˆâ–†â–†â–„â–…â–‚â–‡â–‚â–ƒâ–…â–â–„â–‚â–†â–„â–…â–ˆâ–â–…â–„â–„â–„â–…â–†â–…â–ƒâ–„â–…â–…â–„â–†â–ƒâ–„â–ˆ
wandb:       eval/ensemble_f1 â–‡â–„â–„â–†â–…â–„â–…â–„â–†â–…â–…â–‡â–…â–†â–‡â–‡â–…â–†â–†â–â–…â–…â–†â–„â–…â–†â–„â–„â–…â–†â–…â–†â–†â–„â–…â–ˆâ–†â–ƒâ–†â–‡
wandb:           train/avg_f1 â–„â–„â–†â–ƒâ–†â–„â–…â–„â–ˆâ–â–…â–‚â–…â–„â–„â–†â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–‡â–ƒâ–…â–†â–†â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–…â–…
wandb:      train/ensemble_f1 â–„â–„â–…â–ƒâ–ƒâ–„â–†â–„â–„â–…â–…â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–„â–…â–‚â–†â–„â–…â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–â–„â–…â–…â–…â–…
wandb:         train/mil_loss â–…â–ˆâ–†â–…â–†â–…â–ƒâ–…â–ƒâ–‡â–‡â–…â–†â–â–‡â–…â–ˆâ–‡â–†â–ƒâ–‚â–„â–ƒâ–…â–…â–‚â–„â–„â–†â–„â–‚â–…â–â–…â–„â–ƒâ–‚â–‡â–ƒâ–„
wandb:      train/policy_loss â–…â–‡â–‡â–‡â–‡â–‡â–â–‡â–…â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.36164
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.77985
wandb:      eval/avg_mil_loss 0.40217
wandb:       eval/ensemble_f1 0.77985
wandb:           train/avg_f1 0.79452
wandb:      train/ensemble_f1 0.79452
wandb:         train/mil_loss 1.6055
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uycs3dib
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083539-uycs3dib/logs
wandb: ERROR Run uycs3dib errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: z052naqr with config:
wandb: 	actor_learning_rate: 0.00012428263077727446
wandb: 	attention_dropout_p: 0.20274059705509873
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.002870706341875362
wandb: 	temperature: 3.850444853391912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083901-z052naqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z052naqr
wandb: uploading history steps 56-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–â–‚â–…â–ˆ
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–‡â–…â–„â–„â–†â–‚â–ƒâ–â–†â–…â–ˆâ–†â–„â–‡â–ƒâ–„â–…â–†â–â–ƒâ–†â–†â–‚â–†â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–…â–„â–…â–„â–…â–…â–…â–„
wandb:      eval/avg_mil_loss â–â–â–‚â–â–„â–‚â–‚â–…â–ˆâ–…â–†â–„â–…â–„â–ƒâ–ƒâ–†â–â–†â–„â–„â–‡â–„â–‚â–‡â–…â–„â–„â–…â–„â–„â–„â–„â–†â–ƒâ–„â–ƒâ–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–…â–…â–†â–ƒâ–‡â–„â–†â–†â–„â–‡â–ƒâ–…â–…â–†â–„â–‡â–ƒâ–…â–„â–„â–†â–‚â–â–ƒâ–†â–†â–…â–ƒâ–…â–„â–„â–…â–„â–…â–…â–ƒâ–…â–ˆâ–…â–„
wandb:           train/avg_f1 â–†â–‡â–†â–„â–…â–†â–„â–†â–…â–ˆâ–ƒâ–†â–†â–†â–„â–ƒâ–‡â–…â–„â–…â–ˆâ–â–†â–„â–„â–…â–‡â–†â–†â–â–†â–„â–„â–…â–…â–‡â–â–…â–…â–„
wandb:      train/ensemble_f1 â–‡â–ƒâ–†â–„â–„â–ƒâ–†â–†â–…â–…â–„â–ƒâ–…â–†â–„â–„â–‡â–†â–…â–„â–…â–ˆâ–„â–„â–„â–‡â–†â–†â–â–‚â–†â–‡â–„â–…â–„â–‡â–‡â–…â–„â–„
wandb:         train/mil_loss â–†â–†â–…â–‚â–…â–ƒâ–‚â–‡â–†â–†â–…â–†â–„â–‚â–†â–‚â–â–ƒâ–…â–„â–„â–„â–†â–„â–†â–‡â–„â–‚â–ƒâ–‡â–‚â–ƒâ–„â–ˆâ–ˆâ–…â–„â–‚â–‚â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83856
wandb: best/eval_avg_mil_loss 0.45668
wandb:  best/eval_ensemble_f1 0.83856
wandb:            eval/avg_f1 0.78098
wandb:      eval/avg_mil_loss 0.46595
wandb:       eval/ensemble_f1 0.78098
wandb:           train/avg_f1 0.78898
wandb:      train/ensemble_f1 0.78898
wandb:         train/mil_loss 1.314
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sleek-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z052naqr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083901-z052naqr/logs
wandb: ERROR Run z052naqr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: caf3b75v with config:
wandb: 	actor_learning_rate: 3.2933364882669914e-05
wandb: 	attention_dropout_p: 0.2811122342513781
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17591791433262527
wandb: 	temperature: 3.4642055616823617
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084019-caf3b75v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caf3b75v
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–†â–„â–„â–‚â–…â–„â–„â–…â–ˆâ–„â–…â–„â–…â–„â–„â–‡â–„â–ƒâ–„â–†â–‡â–…â–†â–…â–ƒâ–â–‚â–‚â–†â–…â–…â–…â–â–…â–„â–…â–„â–†
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–„â–‚â–â–†â–ˆâ–‚â–†â–„â–‚â–ˆâ–†â–†â–‡â–…â–…â–…â–…â–ƒâ–„â–„â–†â–‡â–‚â–†â–‚â–‡â–‡â–ƒâ–ƒâ–…â–„â–„â–…
wandb:       eval/ensemble_f1 â–†â–„â–†â–†â–…â–ˆâ–…â–„â–†â–…â–‡â–†â–‚â–…â–ˆâ–†â–„â–…â–…â–…â–…â–„â–ƒâ–†â–‡â–†â–…â–‡â–…â–ƒâ–†â–ƒâ–†â–†â–â–…â–„â–†â–†â–‡
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–ƒâ–‡â–ƒâ–…â–…â–ƒâ–…â–‚â–„â–†â–â–„â–„â–„â–‚â–ƒâ–ƒâ–ˆâ–…â–ƒâ–„â–„â–…â–…â–„â–‚â–‡â–„â–…â–ˆ
wandb:      train/ensemble_f1 â–†â–†â–…â–„â–ƒâ–ƒâ–„â–…â–„â–‡â–†â–…â–„â–…â–ƒâ–‚â–…â–ƒâ–„â–„â–…â–†â–‡â–†â–„â–‡â–…â–…â–‡â–‚â–…â–„â–†â–…â–…â–ˆâ–â–‚â–„â–ˆ
wandb:         train/mil_loss â–†â–†â–ˆâ–†â–†â–…â–†â–†â–†â–‡â–†â–„â–„â–…â–…â–…â–†â–„â–„â–†â–†â–ƒâ–…â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86024
wandb: best/eval_avg_mil_loss 0.38735
wandb:  best/eval_ensemble_f1 0.86024
wandb:            eval/avg_f1 0.82725
wandb:      eval/avg_mil_loss 0.36851
wandb:       eval/ensemble_f1 0.82725
wandb:           train/avg_f1 0.80451
wandb:      train/ensemble_f1 0.80451
wandb:         train/mil_loss 1.28373
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/caf3b75v
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084019-caf3b75v/logs
wandb: ERROR Run caf3b75v errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ddwol92p with config:
wandb: 	actor_learning_rate: 2.795160047382748e-05
wandb: 	attention_dropout_p: 0.48175513885099974
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5961106569293066
wandb: 	temperature: 7.970817270956694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084208-ddwol92p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddwol92p
wandb: uploading wandb-summary.json
wandb: uploading history steps 97-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–†â–ƒâ–…â–â–„â–…â–‚â–ˆâ–†â–…â–„â–‚â–ƒâ–ƒâ–‚â–„â–†â–ˆâ–ƒâ–„â–†â–„â–‡â–†â–‚â–‡â–ƒâ–„â–„â–‡â–ƒâ–†â–„â–‚â–…â–†â–ƒâ–†â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–…â–…â–‚â–„â–â–†â–„â–…â–‚â–…â–†â–ƒâ–…â–„â–„â–†â–„â–„â–ƒâ–†â–ƒâ–„â–„â–‡â–…â–†â–†â–‚â–†â–…â–…â–ˆâ–ƒâ–ƒâ–„â–ˆâ–ƒ
wandb:       eval/ensemble_f1 â–‚â–‡â–…â–†â–‚â–…â–„â–ˆâ–…â–†â–‚â–„â–…â–ˆâ–ƒâ–â–ƒâ–‡â–…â–†â–â–‡â–‚â–ƒâ–„â–„â–ƒâ–‚â–…â–‚â–„â–…â–…â–…â–„â–‡â–„â–„â–†â–„
wandb:           train/avg_f1 â–‡â–„â–…â–…â–†â–‡â–„â–‚â–ˆâ–†â–…â–†â–†â–ˆâ–„â–â–‡â–‚â–…â–…â–†â–…â–†â–†â–„â–‚â–‡â–†â–ˆâ–ƒâ–…â–„â–†â–†â–…â–ˆâ–†â–„â–„â–„
wandb:      train/ensemble_f1 â–„â–…â–†â–â–„â–„â–…â–…â–ˆâ–„â–ƒâ–†â–„â–„â–…â–â–ˆâ–„â–…â–‚â–‡â–…â–ƒâ–…â–ˆâ–…â–†â–‚â–‡â–„â–†â–ˆâ–ƒâ–„â–‡â–„â–„â–†â–†â–†
wandb:         train/mil_loss â–†â–ˆâ–ˆâ–‡â–…â–†â–‡â–…â–‡â–†â–‡â–„â–ˆâ–…â–…â–…â–ƒâ–…â–„â–„â–†â–…â–„â–…â–ƒâ–„â–„â–ƒâ–†â–„â–„â–„â–„â–…â–…â–‚â–„â–‚â–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–ƒâ–…â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.37608
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.80543
wandb:      eval/avg_mil_loss 0.39079
wandb:       eval/ensemble_f1 0.80543
wandb:           train/avg_f1 0.78173
wandb:      train/ensemble_f1 0.78173
wandb:         train/mil_loss 0.77687
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run efficient-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ddwol92p
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084208-ddwol92p/logs
wandb: ERROR Run ddwol92p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 926ot0x0 with config:
wandb: 	actor_learning_rate: 1.200695335382386e-05
wandb: 	attention_dropout_p: 0.3130579535389906
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.72385748894547
wandb: 	temperature: 6.387493792137045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084407-926ot0x0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/926ot0x0
wandb: uploading history steps 110-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–‚â–„â–â–â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–„â–…â–‡â–‡â–â–†â–‡â–ƒâ–‡â–†â–†â–ˆâ–†â–†â–ƒâ–…â–ˆâ–‚â–„â–…â–ƒâ–…â–†â–„â–†â–…â–„â–„â–ƒâ–†â–ƒâ–„â–‡
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–ƒâ–‚â–„â–„â–‚â–„â–â–ƒâ–‚â–ˆâ–…â–„â–„â–…â–…â–ƒâ–ƒâ–„â–…â–ƒâ–…â–„â–„â–‚â–ƒâ–„â–…â–ƒâ–„â–†â–‚â–…â–ƒâ–…â–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–„â–†â–„â–ˆâ–ƒâ–‡â–‚â–„â–ƒâ–†â–…â–ˆâ–…â–ˆâ–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–†â–‚â–„â–„â–„â–„â–„â–…â–†â–ƒâ–â–„â–…â–…â–ƒâ–ˆâ–†â–‚â–„â–ƒâ–†
wandb:           train/avg_f1 â–„â–‚â–‚â–ƒâ–â–†â–…â–…â–„â–ƒâ–†â–ƒâ–‡â–‡â–â–„â–ƒâ–†â–†â–„â–…â–â–„â–‡â–…â–ˆâ–‡â–„â–…â–„â–‚â–‚â–†â–ƒâ–…â–‡â–†â–†â–„â–…
wandb:      train/ensemble_f1 â–„â–†â–ˆâ–…â–â–„â–â–‚â–ƒâ–ƒâ–†â–‡â–„â–†â–†â–…â–†â–…â–„â–„â–ˆâ–„â–„â–ƒâ–ƒâ–„â–‚â–‡â–…â–†â–…â–ƒâ–†â–…â–…â–‚â–‡â–„â–ˆâ–„
wandb:         train/mil_loss â–…â–‡â–†â–„â–†â–†â–…â–†â–„â–‡â–‡â–ˆâ–…â–…â–…â–†â–…â–…â–‡â–…â–„â–…â–„â–‡â–„â–…â–…â–…â–ƒâ–„â–…â–ˆâ–„â–‚â–‚â–„â–‡â–ƒâ–â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82111
wandb: best/eval_avg_mil_loss 0.42258
wandb:  best/eval_ensemble_f1 0.82111
wandb:            eval/avg_f1 0.77713
wandb:      eval/avg_mil_loss 0.45592
wandb:       eval/ensemble_f1 0.77713
wandb:           train/avg_f1 0.78047
wandb:      train/ensemble_f1 0.78047
wandb:         train/mil_loss 1.61326
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run helpful-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/926ot0x0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084407-926ot0x0/logs
wandb: ERROR Run 926ot0x0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: d3u7zvky with config:
wandb: 	actor_learning_rate: 1.3327447520428604e-05
wandb: 	attention_dropout_p: 0.1198528681095688
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6973970519677729
wandb: 	temperature: 3.0186015979359637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084621-d3u7zvky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d3u7zvky
wandb: uploading wandb-summary.json
wandb: uploading history steps 83-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–„â–â–…â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–„â–„â–‚â–…â–†â–„â–„â–…â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–†â–â–…â–„â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–„â–ˆâ–‚â–…â–†â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–„â–„â–‚â–†â–ƒâ–ˆâ–„â–„â–„â–„â–‚â–…â–†â–ƒâ–â–„â–„â–ˆâ–‚â–ƒâ–…â–ƒâ–„â–‚â–ƒâ–…â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–…â–â–…â–†â–‡â–†â–…â–ˆâ–…â–ƒâ–ˆâ–…â–…â–†â–ƒâ–‡â–†â–…â–ˆâ–„â–…â–…â–„â–ƒâ–†â–…â–„â–‚â–ˆâ–ƒâ–„â–ƒâ–‡â–‡â–†â–†â–†â–‡â–…â–†
wandb:           train/avg_f1 â–‚â–…â–…â–„â–‡â–…â–…â–…â–…â–†â–…â–‡â–„â–„â–ˆâ–…â–‚â–‡â–…â–ƒâ–‚â–‡â–…â–‡â–ƒâ–„â–‚â–„â–‡â–†â–…â–„â–†â–…â–â–ƒâ–ƒâ–ƒâ–†â–…
wandb:      train/ensemble_f1 â–â–…â–„â–…â–†â–„â–…â–„â–„â–‡â–ƒâ–†â–…â–ƒâ–ƒâ–ˆâ–â–„â–ˆâ–ƒâ–‚â–â–†â–„â–â–‡â–„â–ƒâ–„â–†â–…â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–„â–†
wandb:         train/mil_loss â–‡â–…â–„â–„â–ˆâ–…â–„â–„â–„â–†â–„â–„â–„â–‡â–„â–…â–ƒâ–„â–…â–…â–„â–…â–…â–„â–†â–„â–†â–‚â–…â–ƒâ–â–„â–„â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85711
wandb: best/eval_avg_mil_loss 0.38441
wandb:  best/eval_ensemble_f1 0.85711
wandb:            eval/avg_f1 0.80875
wandb:      eval/avg_mil_loss 0.42557
wandb:       eval/ensemble_f1 0.80875
wandb:           train/avg_f1 0.81098
wandb:      train/ensemble_f1 0.81098
wandb:         train/mil_loss 1.31371
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run different-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d3u7zvky
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084621-d3u7zvky/logs
wandb: ERROR Run d3u7zvky errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9bg4ovp6 with config:
wandb: 	actor_learning_rate: 0.0001132182983665178
wandb: 	attention_dropout_p: 0.413824888986032
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.798128013204268
wandb: 	temperature: 5.637311242963624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084804-9bg4ovp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bg4ovp6
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–†â–ˆâ–‡â–†â–ƒâ–†â–…â–†â–„â–‡â–„â–„â–…â–…â–‡â–‡â–‡â–„â–…â–…â–‡â–â–†â–„â–…â–„â–‡â–…â–…â–„â–‡â–…â–„â–„â–ƒâ–‡â–„â–„
wandb:      eval/avg_mil_loss â–…â–„â–…â–ƒâ–ƒâ–†â–…â–†â–†â–…â–†â–â–ƒâ–â–…â–ƒâ–…â–†â–ˆâ–…â–‚â–„â–…â–ƒâ–†â–…â–…â–…â–ƒâ–‡â–â–„â–…â–‡â–‚â–…â–‡â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–†â–‡â–†â–ˆâ–„â–…â–†â–ˆâ–…â–‡â–ˆâ–„â–‡â–†â–‡â–†â–„â–„â–„â–‡â–â–„â–„â–„â–‚â–ˆâ–…â–…â–…â–…â–„â–†â–…â–†â–‡â–†â–†â–ƒâ–ˆâ–†
wandb:           train/avg_f1 â–ˆâ–†â–„â–…â–†â–†â–…â–‚â–„â–„â–„â–‡â–†â–„â–ƒâ–‚â–…â–†â–„â–„â–„â–„â–†â–„â–†â–…â–â–…â–…â–…â–„â–…â–„â–‚â–…â–„â–â–ƒâ–â–
wandb:      train/ensemble_f1 â–‚â–‡â–ˆâ–†â–…â–„â–„â–„â–‚â–†â–‚â–…â–†â–ƒâ–ˆâ–„â–ƒâ–…â–…â–„â–â–„â–ƒâ–ƒâ–†â–†â–ƒâ–‚â–…â–…â–‚â–„â–„â–…â–„â–…â–…â–‚â–„â–‚
wandb:         train/mil_loss â–†â–†â–†â–…â–ˆâ–†â–…â–ƒâ–ˆâ–‡â–…â–ƒâ–…â–…â–†â–†â–†â–„â–†â–„â–‚â–†â–„â–„â–‡â–…â–ƒâ–„â–„â–„â–â–‚â–ƒâ–â–„â–‚â–„â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–„â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.39506
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.76642
wandb:      eval/avg_mil_loss 0.47309
wandb:       eval/ensemble_f1 0.76642
wandb:           train/avg_f1 0.77345
wandb:      train/ensemble_f1 0.77345
wandb:         train/mil_loss 0.63824
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bg4ovp6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084804-9bg4ovp6/logs
wandb: ERROR Run 9bg4ovp6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cgd6ap6d with config:
wandb: 	actor_learning_rate: 2.447768425298617e-05
wandb: 	attention_dropout_p: 0.4406108545022694
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7503052425727507
wandb: 	temperature: 6.318862588363647
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085039-cgd6ap6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgd6ap6d
wandb: uploading history steps 129-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–„â–ˆâ–†â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–ƒâ–†â–ƒâ–…â–‚â–‡â–ƒâ–…â–„â–ˆâ–…â–…â–„â–†â–†â–„â–ƒâ–ƒâ–ˆâ–…â–…â–„â–‚â–‡â–ƒâ–„â–…â–‡â–…â–‡â–…â–…â–â–ƒâ–…â–â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–†â–â–‡â–‚â–…â–ƒâ–„â–†â–‚â–„â–†â–…â–„â–†â–„â–ƒâ–ƒâ–‚â–„â–„â–‡â–‡â–…â–†â–ˆâ–†â–…â–‚â–ƒâ–†â–ˆâ–„â–ƒ
wandb:       eval/ensemble_f1 â–†â–ƒâ–ˆâ–„â–…â–‡â–†â–‡â–‚â–…â–…â–ƒâ–ƒâ–†â–…â–†â–†â–…â–„â–„â–„â–„â–‡â–ƒâ–…â–…â–„â–‚â–„â–†â–ƒâ–…â–„â–…â–ˆâ–â–…â–‚â–ˆâ–
wandb:           train/avg_f1 â–ˆâ–…â–†â–†â–‡â–‡â–ˆâ–‡â–„â–„â–ˆâ–ƒâ–…â–„â–„â–‡â–†â–‡â–†â–…â–‡â–†â–†â–…â–†â–„â–…â–†â–‚â–ƒâ–‚â–†â–„â–â–‚â–†â–…â–‚â–‚â–„
wandb:      train/ensemble_f1 â–‚â–„â–ƒâ–…â–…â–†â–‡â–†â–ˆâ–‡â–…â–…â–‚â–„â–ˆâ–„â–‡â–†â–…â–…â–ƒâ–†â–‡â–†â–…â–†â–ƒâ–†â–ƒâ–ƒâ–„â–‡â–„â–‡â–‚â–…â–†â–„â–â–‚
wandb:         train/mil_loss â–†â–ˆâ–‡â–†â–†â–ˆâ–‡â–‡â–†â–†â–‡â–†â–‡â–ˆâ–‡â–ˆâ–„â–†â–†â–…â–…â–„â–„â–…â–†â–…â–…â–„â–„â–ƒâ–ƒâ–„â–„â–„â–ƒâ–‚â–„â–ƒâ–‚â–
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.40932
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.81743
wandb:      eval/avg_mil_loss 0.44798
wandb:       eval/ensemble_f1 0.81743
wandb:           train/avg_f1 0.79187
wandb:      train/ensemble_f1 0.79187
wandb:         train/mil_loss 1.1612
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deft-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgd6ap6d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085039-cgd6ap6d/logs
wandb: ERROR Run cgd6ap6d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ffjwcge4 with config:
wandb: 	actor_learning_rate: 2.2307214350440995e-06
wandb: 	attention_dropout_p: 0.4138098235271976
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7250461160484569
wandb: 	temperature: 8.070684997503106
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085335-ffjwcge4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffjwcge4
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 107-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–ˆâ–ƒâ–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–…â–‡â–‚â–„â–ƒâ–â–†â–‚â–‚â–‚â–…â–†â–…â–„â–‡â–„â–ƒâ–‡â–„â–‡â–‚â–ƒâ–ˆâ–„â–†â–‚â–„
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–‚â–‚â–†â–…â–„â–‚â–ƒâ–„â–…â–„â–„â–ˆâ–ƒâ–ƒâ–„â–‚â–„â–…â–‚â–ƒâ–â–ˆâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–„â–‚â–ƒâ–„â–‚â–†â–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–ƒâ–†â–†â–„â–‡â–†â–…â–„â–‡â–‡â–ƒâ–„â–†â–„â–…â–„â–„â–„â–‚â–‚â–‡â–„â–â–ƒâ–†â–‡â–…â–…â–‡â–‡â–„â–…â–ƒâ–†â–ˆâ–…â–†â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–‡â–„â–…â–ƒâ–„â–„â–‚â–…â–…â–„â–…â–â–â–‚â–†â–ˆâ–‚â–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–â–„â–„â–ƒâ–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–‡â–…â–†â–…â–†â–…â–…â–â–„â–ˆâ–…â–ƒâ–†â–†â–…â–„â–…â–†â–…â–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–†â–„â–ƒâ–…â–„â–„â–ƒâ–…â–‚â–…â–†â–…â–…â–„
wandb:         train/mil_loss â–‡â–„â–‚â–…â–…â–‡â–ƒâ–…â–…â–ƒâ–…â–„â–…â–„â–‚â–„â–ƒâ–„â–…â–„â–„â–‚â–ˆâ–‚â–„â–…â–ƒâ–‚â–…â–†â–„â–‚â–ƒâ–â–†â–â–†â–„â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83197
wandb: best/eval_avg_mil_loss 0.46262
wandb:  best/eval_ensemble_f1 0.83197
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.39045
wandb:       eval/ensemble_f1 0.80225
wandb:            test/avg_f1 0.77167
wandb:      test/avg_mil_loss 0.56725
wandb:       test/ensemble_f1 0.77167
wandb:           train/avg_f1 0.78167
wandb:      train/ensemble_f1 0.78167
wandb:         train/mil_loss 0.87383
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ffjwcge4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085335-ffjwcge4/logs
wandb: Agent Starting Run: es09x7z9 with config:
wandb: 	actor_learning_rate: 2.2507775240393835e-05
wandb: 	attention_dropout_p: 0.4501085607746027
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5085317123699222
wandb: 	temperature: 8.324062580201359
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085544-es09x7z9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/es09x7z9
wandb: uploading wandb-summary.json
wandb: uploading history steps 41-52, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆâ–ƒâ–…
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–‚â–†â–…â–ƒâ–‚â–†â–ƒâ–†â–‡â–â–„â–‡â–„â–„â–‡â–‚â–†â–…â–ƒâ–„â–…â–ƒâ–…â–…â–…â–ƒâ–„â–†â–ˆâ–„â–â–„â–„â–…â–…â–…â–‚â–†
wandb:      eval/avg_mil_loss â–‡â–ƒâ–…â–†â–„â–…â–†â–‚â–…â–‡â–‡â–‡â–ƒâ–ƒâ–†â–‡â–ƒâ–†â–†â–„â–ƒâ–…â–‡â–†â–‡â–ˆâ–…â–‚â–â–‡â–…â–†â–†â–†â–„â–ˆâ–‡â–„â–„â–…
wandb:       eval/ensemble_f1 â–‚â–‡â–†â–‚â–†â–…â–ƒâ–‚â–†â–ƒâ–†â–‡â–â–„â–‡â–‡â–‡â–‚â–†â–…â–ƒâ–„â–ƒâ–…â–ƒâ–â–…â–ƒâ–„â–†â–…â–ˆâ–„â–â–„â–‡â–…â–…â–…â–…
wandb:           train/avg_f1 â–ˆâ–„â–ƒâ–…â–„â–…â–„â–‡â–‚â–„â–„â–‚â–‚â–…â–…â–„â–„â–‚â–„â–„â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–…â–â–ƒâ–…â–†â–ƒâ–…â–ƒâ–…â–„â–…â–ƒâ–…
wandb:      train/ensemble_f1 â–ˆâ–„â–„â–…â–„â–…â–„â–‡â–‚â–„â–„â–‚â–‚â–…â–…â–„â–‚â–„â–„â–†â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–…â–â–ƒâ–„â–†â–ƒâ–…â–„â–ƒâ–„â–…â–‡â–†â–…
wandb:         train/mil_loss â–„â–†â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–…â–„â–‡â–ˆâ–‡â–†â–†â–ˆâ–†â–†â–„â–…â–‚â–„â–‚â–„â–‚â–…â–‡â–‡â–‚â–…â–„â–‡â–ƒâ–†â–â–ƒâ–†â–ƒâ–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84153
wandb: best/eval_avg_mil_loss 0.43174
wandb:  best/eval_ensemble_f1 0.84153
wandb:            eval/avg_f1 0.81611
wandb:      eval/avg_mil_loss 0.4328
wandb:       eval/ensemble_f1 0.81611
wandb:           train/avg_f1 0.80677
wandb:      train/ensemble_f1 0.80677
wandb:         train/mil_loss 1.57826
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/es09x7z9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085544-es09x7z9/logs
wandb: ERROR Run es09x7z9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 16eve12c with config:
wandb: 	actor_learning_rate: 9.152333730721236e-06
wandb: 	attention_dropout_p: 0.04195283815682155
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9811830247934484
wandb: 	temperature: 0.9483170292774225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085656-16eve12c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16eve12c
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–„â–ƒâ–â–„â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–„â–…â–†â–‡â–†â–…â–ƒâ–†â–…â–…â–„â–‡â–…â–ˆâ–…â–ˆâ–†â–…â–†â–‡â–ˆâ–†â–…â–ˆâ–…â–…â–ˆâ–†â–‡â–ƒâ–†â–‡â–‡â–‡â–â–‡â–…â–†â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–„â–†â–‚â–…â–„â–ƒâ–‡â–ƒâ–â–„â–„â–â–‚â–„â–ƒâ–ƒâ–„â–‚â–„â–‚â–ƒâ–†â–‡â–ƒâ–„â–…â–…â–‚â–„â–ƒâ–ƒâ–„â–ˆâ–…â–„â–„â–†â–…
wandb:       eval/ensemble_f1 â–†â–ƒâ–…â–†â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–…â–ƒâ–„â–†â–†â–„â–…â–ƒâ–†â–„â–†â–†â–ˆâ–ƒâ–†â–‡â–…â–‚â–â–†â–…â–„â–ƒâ–…â–„â–‚â–„â–…â–„
wandb:           train/avg_f1 â–…â–ƒâ–†â–ˆâ–‚â–†â–…â–†â–…â–ƒâ–„â–ƒâ–…â–†â–…â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–†â–„â–„â–â–â–…â–„â–†â–ƒâ–„â–â–„â–ƒâ–„â–‚â–‡â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–„â–…â–…â–…â–„â–ƒâ–‚â–…â–„â–†â–ƒâ–„â–ƒâ–…â–‡â–‚â–…â–„â–„â–„â–ƒâ–…â–„â–‚â–‡â–…â–…â–„â–â–ˆâ–â–„â–…â–â–ƒâ–ƒâ–„â–‡â–ƒâ–„
wandb:         train/mil_loss â–‡â–ˆâ–‡â–‡â–†â–…â–‡â–†â–„â–†â–ƒâ–…â–„â–„â–„â–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–â–â–â–â–‚â–„â–‚â–
wandb:      train/policy_loss â–„â–…â–…â–…â–…â–…â–â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–„â–„â–„â–†â–ƒâ–‚â–„â–„â–â–‡â–„â–„â–…â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–ˆâ–„â–‡â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84992
wandb: best/eval_avg_mil_loss 0.41006
wandb:  best/eval_ensemble_f1 0.84992
wandb:            eval/avg_f1 0.79558
wandb:      eval/avg_mil_loss 0.45787
wandb:       eval/ensemble_f1 0.79558
wandb:           train/avg_f1 0.79591
wandb:      train/ensemble_f1 0.79591
wandb:         train/mil_loss 1.09199
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run breezy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16eve12c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085656-16eve12c/logs
wandb: ERROR Run 16eve12c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4364z3e7 with config:
wandb: 	actor_learning_rate: 2.7843184321350138e-06
wandb: 	attention_dropout_p: 0.07002589597833836
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7941041976466651
wandb: 	temperature: 9.6659092512839
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085919-4364z3e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4364z3e7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–…â–ƒ
wandb:  best/eval_ensemble_f1 â–â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–‚â–†â–ƒâ–„â–ˆâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–‚â–„â–‡â–†â–„â–†â–„â–†â–„â–â–†â–ƒâ–‚â–‡â–„â–â–‚â–„â–ƒâ–„â–…â–‚â–„â–„â–…â–†â–ƒ
wandb:      eval/avg_mil_loss â–…â–â–…â–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–â–…â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–…â–„â–…â–†â–ˆâ–…â–†â–ˆâ–…â–„â–„â–…â–†â–…â–†â–„â–„â–â–ƒâ–„â–‚
wandb:       eval/ensemble_f1 â–…â–‚â–…â–ˆâ–†â–†â–ƒâ–†â–ˆâ–‚â–†â–…â–…â–…â–…â–ƒâ–‡â–ƒâ–„â–ƒâ–‡â–„â–ƒâ–ƒâ–‚â–â–‡â–†â–‡â–„â–†â–‡â–‚â–ƒâ–â–„â–ƒâ–ƒâ–„â–†
wandb:           train/avg_f1 â–‡â–ˆâ–†â–†â–†â–‡â–†â–…â–ˆâ–†â–†â–ˆâ–…â–†â–†â–„â–ƒâ–…â–‡â–…â–…â–„â–†â–ƒâ–ˆâ–†â–†â–†â–†â–‚â–…â–†â–‡â–„â–„â–†â–â–ƒâ–ƒâ–…
wandb:      train/ensemble_f1 â–ˆâ–ˆâ–…â–ˆâ–ƒâ–‡â–ƒâ–…â–†â–…â–…â–…â–…â–„â–„â–†â–†â–ƒâ–…â–„â–…â–„â–ƒâ–†â–„â–ƒâ–„â–„â–ƒâ–„â–…â–„â–„â–„â–â–…â–„â–†â–„â–…
wandb:         train/mil_loss â–‡â–†â–ˆâ–‡â–†â–†â–†â–…â–†â–„â–…â–„â–…â–…â–„â–„â–„â–„â–…â–‚â–…â–†â–…â–…â–„â–„â–…â–„â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–‚â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–…â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84671
wandb: best/eval_avg_mil_loss 0.42352
wandb:  best/eval_ensemble_f1 0.84671
wandb:            eval/avg_f1 0.82115
wandb:      eval/avg_mil_loss 0.44496
wandb:       eval/ensemble_f1 0.82115
wandb:           train/avg_f1 0.78178
wandb:      train/ensemble_f1 0.78178
wandb:         train/mil_loss 0.80126
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4364z3e7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085919-4364z3e7/logs
wandb: ERROR Run 4364z3e7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zx4ghdpz with config:
wandb: 	actor_learning_rate: 4.216207668826228e-05
wandb: 	attention_dropout_p: 0.3043650641210728
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17130590088164543
wandb: 	temperature: 5.818577800826454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090322-zx4ghdpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4ghdpz
wandb: uploading history steps 80-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‡â–‚â–‡â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–â–†â–†â–„â–†â–…â–…â–„â–„â–‡â–†â–ˆâ–„â–…â–ƒâ–†â–ƒâ–…â–…â–„â–…â–„â–†â–‡â–†â–‡â–…â–…â–ƒâ–…â–„â–…â–…â–„â–†â–„â–…
wandb:      eval/avg_mil_loss â–…â–†â–…â–†â–ƒâ–‡â–„â–†â–‚â–ƒâ–…â–„â–…â–‚â–…â–â–…â–‡â–„â–†â–…â–…â–„â–‡â–†â–ˆâ–†â–…â–ˆâ–„â–„â–ƒâ–ƒâ–„â–‡â–„â–„â–†â–†â–…
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–„â–ƒâ–†â–ƒâ–…â–†â–ƒâ–†â–‚â–ƒâ–…â–…â–…â–„â–†â–â–…â–…â–„â–‡â–ƒâ–„â–†â–„â–â–„â–â–ƒâ–„â–„â–‚â–…â–ˆâ–„â–â–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–„â–„â–ƒâ–„â–…â–ƒâ–…â–„â–„â–â–ˆâ–ƒâ–„â–„â–ƒâ–…â–‡â–ƒâ–‡â–†â–„â–†â–†â–ƒâ–‚â–…â–…â–ƒâ–‚â–„â–…â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ˆ
wandb:      train/ensemble_f1 â–…â–„â–„â–‚â–„â–ƒâ–„â–„â–…â–„â–ˆâ–‚â–„â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–†â–„â–…â–„â–ƒâ–‚â–‡â–‚â–ƒâ–‚â–…â–„â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–â–ˆ
wandb:         train/mil_loss â–†â–ˆâ–ƒâ–…â–‡â–„â–…â–„â–…â–ƒâ–†â–…â–…â–…â–„â–…â–„â–ƒâ–‡â–ƒâ–†â–„â–„â–„â–„â–†â–ƒâ–‚â–…â–„â–…â–‚â–†â–‚â–ƒâ–ƒâ–…â–ƒâ–‚â–
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–ƒâ–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–ˆâ–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–ƒâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.37958
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79404
wandb:      eval/avg_mil_loss 0.45426
wandb:       eval/ensemble_f1 0.79404
wandb:            test/avg_f1 0.78852
wandb:      test/avg_mil_loss 0.5729
wandb:       test/ensemble_f1 0.78852
wandb:           train/avg_f1 0.81312
wandb:      train/ensemble_f1 0.81312
wandb:         train/mil_loss 1.48703
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx4ghdpz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090322-zx4ghdpz/logs
wandb: Agent Starting Run: jxs2onoy with config:
wandb: 	actor_learning_rate: 1.9292522471704028e-05
wandb: 	attention_dropout_p: 0.4509017745214344
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9633787214234564
wandb: 	temperature: 6.520398936377051
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090505-jxs2onoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxs2onoy
wandb: uploading history steps 54-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–…â–…â–…â–ˆâ–„â–…â–‚â–…â–„â–‡â–†â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–…â–ƒâ–†â–„â–…â–„â–‚â–†â–…â–†â–†â–â–†â–„â–…â–…â–„â–„â–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–…â–„â–„â–‚â–â–ƒâ–ˆâ–…â–…â–‚â–ƒâ–…â–ˆâ–†â–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–„â–‡â–‚â–ƒâ–„â–†â–…â–„â–„â–ƒâ–‚â–†â–„
wandb:       eval/ensemble_f1 â–†â–‚â–…â–…â–…â–ˆâ–„â–…â–‚â–…â–„â–‡â–†â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–†â–…â–ƒâ–†â–†â–…â–†â–‚â–†â–…â–†â–ƒâ–â–†â–„â–„â–…â–‚â–„â–„
wandb:           train/avg_f1 â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–„â–„â–…â–„â–ƒâ–…â–„â–…â–„â–…â–„â–„â–„â–„â–ƒâ–†â–ƒâ–ƒâ–â–†â–†â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–„â–â–…â–ƒâ–…â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–ƒâ–„â–…â–„â–„â–…â–…â–„â–ƒâ–…â–„â–ƒâ–…â–„â–…â–…â–†â–„â–„â–…â–ƒâ–†â–ƒâ–â–‚â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–„â–â–…â–ƒâ–…â–ƒ
wandb:         train/mil_loss â–…â–†â–‡â–„â–†â–†â–…â–ˆâ–‡â–„â–„â–„â–„â–…â–…â–†â–‚â–‚â–„â–‡â–‚â–†â–ƒâ–ƒâ–‚â–…â–†â–‚â–ƒâ–‚â–‚â–†â–‚â–â–‚â–ƒâ–…â–ƒâ–‚â–
wandb:      train/policy_loss â–†â–†â–ˆâ–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–ˆâ–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84759
wandb: best/eval_avg_mil_loss 0.37343
wandb:  best/eval_ensemble_f1 0.84759
wandb:            eval/avg_f1 0.79849
wandb:      eval/avg_mil_loss 0.45208
wandb:       eval/ensemble_f1 0.79849
wandb:           train/avg_f1 0.79713
wandb:      train/ensemble_f1 0.79713
wandb:         train/mil_loss 1.29776
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run clean-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jxs2onoy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090505-jxs2onoy/logs
wandb: ERROR Run jxs2onoy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: eazkx70p with config:
wandb: 	actor_learning_rate: 1.5121644935629266e-05
wandb: 	attention_dropout_p: 0.1890644359919943
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3160559788419818
wandb: 	temperature: 3.0948479689029895
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090613-eazkx70p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eazkx70p
wandb: uploading history steps 144-157, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ƒâ–ƒâ–â–ˆâ–‚â–…â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–‡â–…â–‚â–‚â–†â–ˆâ–ƒâ–„â–†â–†â–‡â–ƒâ–…â–ˆâ–ˆâ–†â–†â–‡â–†â–„â–…â–†â–†â–„â–‡â–ƒâ–â–…â–…â–â–‡â–ˆâ–‡â–…â–…â–†â–ˆ
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–…â–‚â–ƒâ–„â–ƒâ–†â–„â–„â–†â–â–„â–ƒâ–„â–ƒâ–â–‚â–„â–ƒâ–…â–‡â–†â–†â–…â–…â–‚â–ƒâ–ˆâ–‚â–„â–„â–‡â–â–ƒâ–…â–ƒâ–ƒâ–
wandb:       eval/ensemble_f1 â–„â–ƒâ–…â–…â–‚â–…â–†â–ƒâ–†â–ƒâ–†â–„â–…â–‚â–†â–†â–„â–ƒâ–…â–ƒâ–…â–„â–…â–ˆâ–‚â–„â–…â–…â–‚â–‡â–‡â–…â–…â–…â–‚â–ƒâ–†â–â–„â–…
wandb:           train/avg_f1 â–†â–ƒâ–ƒâ–„â–‚â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ˆâ–„â–†â–…â–…â–‚â–„â–†â–†â–†â–â–ƒâ–ƒâ–‡â–…â–‡â–ƒâ–‚â–„â–‚â–…â–…â–‚â–ˆâ–‡
wandb:      train/ensemble_f1 â–„â–„â–…â–‡â–„â–…â–„â–„â–†â–â–†â–…â–â–ƒâ–â–†â–…â–‡â–…â–‡â–…â–ˆâ–„â–†â–ƒâ–†â–ˆâ–„â–ˆâ–†â–‚â–…â–…â–„â–ƒâ–ˆâ–†â–„â–‡â–†
wandb:         train/mil_loss â–…â–‡â–‡â–ˆâ–†â–…â–ˆâ–‡â–†â–‡â–†â–ˆâ–‚â–†â–†â–‡â–„â–…â–ƒâ–…â–…â–…â–…â–‡â–ˆâ–…â–â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–â–…â–†â–†â–†â–ƒâ–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84553
wandb: best/eval_avg_mil_loss 0.36673
wandb:  best/eval_ensemble_f1 0.84553
wandb:            eval/avg_f1 0.8348
wandb:      eval/avg_mil_loss 0.39519
wandb:       eval/ensemble_f1 0.8348
wandb:           train/avg_f1 0.81411
wandb:      train/ensemble_f1 0.81411
wandb:         train/mil_loss 1.81722
wandb:      train/policy_loss -0.39121
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.39121
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run mild-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eazkx70p
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090613-eazkx70p/logs
wandb: ERROR Run eazkx70p errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: s9a5a6l9 with config:
wandb: 	actor_learning_rate: 9.558472497488524e-05
wandb: 	attention_dropout_p: 0.2778895377729178
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3217739281755996
wandb: 	temperature: 4.987876867657821
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090919-s9a5a6l9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9a5a6l9
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 93-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–â–ƒâ–‡
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–…â–ˆ
wandb:            eval/avg_f1 â–†â–â–ƒâ–†â–„â–†â–…â–‡â–ƒâ–‡â–„â–„â–ƒâ–„â–„â–…â–†â–„â–„â–ƒâ–„â–ƒâ–‚â–…â–‚â–„â–ˆâ–†â–…â–…â–…â–ƒâ–…â–ƒâ–‚â–„â–†â–…â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–„â–†â–‚â–…â–†â–„â–…â–…â–‚â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–„â–…â–„â–ƒâ–„â–‚â–„â–…â–„â–…â–…â–‚â–â–â–„â–ƒâ–†
wandb:       eval/ensemble_f1 â–…â–†â–†â–ƒâ–…â–†â–ƒâ–…â–„â–„â–â–ƒâ–„â–…â–†â–ƒâ–…â–†â–‚â–ƒâ–†â–…â–‚â–ˆâ–†â–†â–†â–…â–ƒâ–‚â–â–„â–…â–†â–ƒâ–…â–„â–†â–ƒâ–…
wandb:           train/avg_f1 â–„â–†â–„â–ƒâ–†â–…â–†â–‚â–…â–„â–â–…â–‡â–…â–„â–†â–†â–„â–…â–„â–ƒâ–…â–‡â–„â–ƒâ–‚â–„â–â–‚â–‡â–†â–…â–†â–‡â–‚â–„â–ˆâ–‚â–„â–ƒ
wandb:      train/ensemble_f1 â–„â–â–…â–„â–…â–†â–…â–„â–„â–„â–…â–„â–†â–…â–ˆâ–…â–…â–„â–ˆâ–„â–…â–„â–„â–ˆâ–ƒâ–ƒâ–†â–„â–‚â–ƒâ–„â–â–„â–‡â–„â–†â–…â–ƒâ–ƒâ–
wandb:         train/mil_loss â–†â–ˆâ–†â–…â–…â–ƒâ–†â–ƒâ–‡â–…â–†â–…â–„â–ƒâ–„â–ƒâ–„â–†â–‚â–…â–†â–…â–‡â–ƒâ–‡â–…â–…â–„â–…â–„â–…â–„â–…â–ƒâ–†â–…â–ƒâ–â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86321
wandb: best/eval_avg_mil_loss 0.36323
wandb:  best/eval_ensemble_f1 0.86321
wandb:            eval/avg_f1 0.7834
wandb:      eval/avg_mil_loss 0.48285
wandb:       eval/ensemble_f1 0.7834
wandb:           train/avg_f1 0.80731
wandb:      train/ensemble_f1 0.80731
wandb:         train/mil_loss 1.75099
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s9a5a6l9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090919-s9a5a6l9/logs
wandb: ERROR Run s9a5a6l9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7h0u3jwo with config:
wandb: 	actor_learning_rate: 0.0003612122854368032
wandb: 	attention_dropout_p: 0.22099678291069824
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4444651733581535
wandb: 	temperature: 2.6110117144661316
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091118-7h0u3jwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7h0u3jwo
wandb: uploading history steps 139-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–ˆâ–†â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–‡â–…â–…â–ˆâ–†â–ˆâ–…â–‡â–‚â–†â–â–†â–‡â–…â–ƒâ–ƒâ–†â–‡â–„â–†â–ƒâ–‡â–…â–„â–„â–…â–…â–ˆâ–…â–…
wandb:      eval/avg_mil_loss â–„â–…â–…â–…â–„â–ƒâ–…â–…â–†â–‚â–…â–‡â–†â–†â–ˆâ–‚â–ƒâ–…â–ƒâ–‚â–„â–†â–…â–…â–†â–†â–ˆâ–…â–ˆâ–‡â–ƒâ–…â–„â–†â–„â–…â–â–„â–‡â–‡
wandb:       eval/ensemble_f1 â–„â–ƒâ–„â–„â–‡â–…â–†â–â–…â–„â–„â–ƒâ–†â–†â–„â–„â–„â–†â–…â–†â–‚â–…â–„â–„â–ƒâ–„â–†â–„â–„â–ˆâ–…â–†â–ƒâ–ƒâ–„â–…â–„â–†â–„â–„
wandb:           train/avg_f1 â–†â–ƒâ–…â–…â–â–‡â–ƒâ–ƒâ–ˆâ–…â–…â–…â–„â–ˆâ–‡â–†â–…â–†â–‡â–†â–‡â–…â–ƒâ–…â–‚â–†â–…â–…â–ˆâ–„â–…â–„â–ƒâ–â–…â–†â–ƒâ–†â–…â–„
wandb:      train/ensemble_f1 â–†â–„â–…â–†â–†â–‚â–ƒâ–„â–‡â–†â–‚â–ˆâ–…â–…â–…â–„â–„â–â–…â–„â–…â–„â–‡â–†â–‡â–„â–†â–‚â–ˆâ–†â–…â–†â–ˆâ–‡â–…â–‚â–…â–ƒâ–†â–…
wandb:         train/mil_loss â–‡â–‡â–†â–…â–‡â–ˆâ–†â–…â–…â–…â–…â–…â–‡â–…â–…â–†â–†â–„â–ƒâ–„â–‚â–„â–…â–ƒâ–ƒâ–‚â–„â–„â–„â–ƒâ–ƒâ–„â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–
wandb:      train/policy_loss â–„â–â–â–ˆâ–„â–ˆâ–ˆâ–„â–â–„â–â–â–„â–â–ˆâ–„â–„â–ˆâ–„â–â–ˆâ–â–ˆâ–„â–â–â–„â–â–ˆâ–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–â–â–ˆâ–ˆâ–„â–ˆâ–ˆâ–„â–„â–â–â–â–ˆâ–„â–„â–„â–ˆâ–„â–â–ˆâ–„â–ˆâ–â–„â–ˆâ–„â–â–„â–â–â–â–â–ˆâ–„â–ˆâ–ˆâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.39329
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.76955
wandb:      eval/avg_mil_loss 0.51731
wandb:       eval/ensemble_f1 0.76955
wandb:           train/avg_f1 0.77594
wandb:      train/ensemble_f1 0.77594
wandb:         train/mil_loss 0.80552
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dulcet-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7h0u3jwo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091118-7h0u3jwo/logs
wandb: ERROR Run 7h0u3jwo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 2rljyv41 with config:
wandb: 	actor_learning_rate: 0.0008080621419045549
wandb: 	attention_dropout_p: 0.49954291495981223
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5638688307564026
wandb: 	temperature: 5.227541188343535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091425-2rljyv41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rljyv41
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–†â–…â–ƒâ–…â–ƒâ–‡â–†â–†â–ˆâ–†â–ƒâ–‡â–†â–‡â–†â–‡â–‚â–†â–…â–ˆâ–ˆâ–…â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–…â–†â–…â–†â–â–‡â–„â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–ˆâ–…â–„â–†â–„â–â–†â–…â–„â–„â–„â–â–ƒâ–†â–„â–‡â–„â–…â–„â–ƒâ–„â–â–…â–†â–„â–‚â–ƒâ–‡â–ˆ
wandb:       eval/ensemble_f1 â–…â–…â–ƒâ–ƒâ–‡â–†â–„â–ƒâ–†â–…â–†â–ƒâ–…â–…â–†â–„â–ƒâ–„â–†â–„â–„â–‡â–„â–†â–…â–„â–ƒâ–„â–â–â–„â–„â–„â–ƒâ–…â–‚â–„â–ƒâ–ˆâ–‚
wandb:           train/avg_f1 â–…â–†â–†â–‡â–„â–…â–ˆâ–‡â–‡â–†â–…â–„â–„â–†â–†â–ˆâ–†â–„â–…â–ˆâ–†â–†â–„â–†â–‚â–ƒâ–†â–…â–‡â–„â–ƒâ–â–…â–ƒâ–„â–ƒâ–‡â–ƒâ–ƒâ–„
wandb:      train/ensemble_f1 â–†â–ƒâ–‡â–†â–†â–ˆâ–…â–„â–‚â–‡â–…â–†â–‡â–‡â–…â–ƒâ–…â–ƒâ–†â–„â–…â–„â–…â–ƒâ–…â–‚â–…â–…â–ƒâ–…â–…â–…â–„â–…â–‚â–ƒâ–‚â–‚â–„â–
wandb:         train/mil_loss â–ˆâ–…â–†â–…â–ƒâ–†â–„â–„â–†â–‡â–‡â–„â–„â–„â–„â–‡â–‚â–‡â–…â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–…â–‚â–‚â–‚â–‚â–ƒ
wandb:      train/policy_loss â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.41535
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.75521
wandb:      eval/avg_mil_loss 0.55542
wandb:       eval/ensemble_f1 0.75521
wandb:           train/avg_f1 0.78001
wandb:      train/ensemble_f1 0.78001
wandb:         train/mil_loss 0.58645
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rljyv41
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091425-2rljyv41/logs
wandb: ERROR Run 2rljyv41 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ph0onuu5 with config:
wandb: 	actor_learning_rate: 0.00012621286654659897
wandb: 	attention_dropout_p: 0.35433908120729785
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5248998912004862
wandb: 	temperature: 4.774723586181877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091747-ph0onuu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph0onuu5
wandb: uploading history steps 53-65, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–„â–â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–„â–„â–ˆâ–‡â–„â–†â–‡â–†â–†â–ƒâ–†â–ˆâ–„â–…â–‡â–„â–…â–†â–„â–…â–„â–‚â–†â–…â–„â–…â–…â–†â–‡â–…â–â–…â–…â–„â–„â–ˆâ–„
wandb:      eval/avg_mil_loss â–ˆâ–†â–†â–…â–„â–„â–ˆâ–‡â–…â–‚â–…â–†â–‚â–…â–…â–†â–…â–…â–†â–†â–â–…â–†â–ˆâ–…â–†â–„â–‡â–„â–„â–ƒâ–…â–‡â–ƒâ–ƒâ–‡â–„â–†â–‚â–‡
wandb:       eval/ensemble_f1 â–…â–‡â–…â–„â–„â–‡â–‡â–„â–„â–…â–†â–…â–†â–…â–ƒâ–†â–„â–†â–…â–‡â–†â–„â–‡â–…â–„â–†â–ˆâ–†â–…â–„â–†â–†â–…â–…â–â–…â–„â–„â–ˆâ–„
wandb:           train/avg_f1 â–„â–‡â–†â–…â–…â–„â–‚â–†â–†â–‡â–†â–„â–„â–ˆâ–„â–†â–…â–ƒâ–â–…â–ˆâ–‡â–ƒâ–‡â–†â–‡â–…â–ƒâ–…â–…â–…â–…â–„â–†â–†â–…â–‡â–„â–†â–‡
wandb:      train/ensemble_f1 â–†â–…â–…â–‚â–‡â–„â–ƒâ–†â–„â–„â–ƒâ–ˆâ–„â–…â–…â–†â–…â–ƒâ–â–„â–†â–„â–‡â–ˆâ–ƒâ–‡â–†â–…â–ƒâ–…â–ˆâ–…â–…â–†â–†â–…â–‡â–„â–†â–‡
wandb:         train/mil_loss â–…â–ƒâ–ˆâ–…â–„â–†â–â–†â–ƒâ–†â–„â–‡â–ˆâ–…â–…â–†â–„â–„â–†â–…â–…â–…â–†â–ƒâ–…â–…â–‡â–…â–ƒâ–…â–ˆâ–„â–…â–‡â–‡â–ƒâ–â–†â–â–†
wandb:      train/policy_loss â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81689
wandb: best/eval_avg_mil_loss 0.42919
wandb:  best/eval_ensemble_f1 0.81689
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.51281
wandb:       eval/ensemble_f1 0.76275
wandb:           train/avg_f1 0.78901
wandb:      train/ensemble_f1 0.78901
wandb:         train/mil_loss 0.80918
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fancy-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ph0onuu5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091747-ph0onuu5/logs
wandb: ERROR Run ph0onuu5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tznkukm1 with config:
wandb: 	actor_learning_rate: 6.436683408786786e-06
wandb: 	attention_dropout_p: 0.34829613480340677
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09201054619129424
wandb: 	temperature: 2.671131305999114
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091908-tznkukm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tznkukm1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–„â–ƒâ–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–„â–‚â–‡â–…â–„â–‡â–†â–ƒâ–„â–‚â–„â–‡â–‡â–â–…â–…â–…â–†â–…â–…â–„â–…â–…â–‡â–‚â–ƒâ–…â–…â–†â–ˆâ–„â–ˆâ–†
wandb:      eval/avg_mil_loss â–‡â–„â–„â–„â–„â–‡â–ƒâ–ƒâ–ƒâ–â–†â–„â–ƒâ–‡â–„â–„â–ƒâ–ƒâ–‡â–…â–…â–…â–‚â–ƒâ–…â–„â–…â–„â–‚â–ˆâ–ˆâ–†â–„â–„â–ƒâ–„â–…â–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–‚â–„â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–†â–„â–ƒâ–„â–ƒâ–‡â–ƒâ–‚â–„â–†â–†â–â–…â–„â–ƒâ–„â–ˆâ–ƒâ–…â–„â–„â–â–…â–ƒâ–…â–„â–‡â–…â–†â–ƒâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‚â–…â–‚â–…â–‡â–â–…â–†â–…â–…â–‡â–…â–†â–†â–ƒâ–…â–ˆâ–…â–†â–„â–ƒâ–…â–„â–†â–„â–ƒâ–…â–ˆâ–‡â–†â–…â–â–„â–‡â–ƒâ–†â–„â–â–ƒ
wandb:      train/ensemble_f1 â–‡â–ƒâ–„â–„â–‚â–†â–†â–â–†â–†â–„â–†â–†â–ƒâ–…â–‚â–„â–ˆâ–„â–…â–„â–…â–„â–†â–…â–‚â–…â–…â–ˆâ–…â–…â–…â–…â–†â–„â–ƒâ–ƒâ–„â–â–ƒ
wandb:         train/mil_loss â–‡â–„â–…â–†â–†â–…â–„â–…â–‚â–„â–…â–†â–…â–„â–‡â–ƒâ–…â–…â–‚â–†â–ˆâ–‚â–‚â–…â–â–ƒâ–ƒâ–„â–…â–â–„â–‚â–‡â–„â–…â–„â–ƒâ–…â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–…â–ˆâ–â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–†â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85224
wandb: best/eval_avg_mil_loss 0.44046
wandb:  best/eval_ensemble_f1 0.85224
wandb:            eval/avg_f1 0.81611
wandb:      eval/avg_mil_loss 0.36634
wandb:       eval/ensemble_f1 0.81611
wandb:            test/avg_f1 0.78811
wandb:      test/avg_mil_loss 0.51205
wandb:       test/ensemble_f1 0.78811
wandb:           train/avg_f1 0.80091
wandb:      train/ensemble_f1 0.80091
wandb:         train/mil_loss 1.7069
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tznkukm1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091908-tznkukm1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rfsa60va with config:
wandb: 	actor_learning_rate: 1.988793370684172e-05
wandb: 	attention_dropout_p: 0.061533098075507664
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2995258888807877
wandb: 	temperature: 3.4047901816664696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092101-rfsa60va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfsa60va
wandb: uploading history steps 119-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–‚â–‡â–†â–†â–â–ƒâ–‚â–ˆâ–â–‚â–„â–…â–…â–ƒâ–„â–„â–…â–„â–„â–„â–„â–…â–‚â–ƒâ–…â–ƒâ–‚â–„â–‡â–ƒâ–„â–ƒâ–„â–‡â–„â–ƒâ–„â–„
wandb:      eval/avg_mil_loss â–‡â–„â–â–„â–…â–ƒâ–†â–…â–†â–†â–ˆâ–„â–…â–†â–‡â–„â–„â–„â–…â–ƒâ–†â–†â–‡â–„â–†â–‡â–‡â–ƒâ–ˆâ–†â–ˆâ–ƒâ–…â–†â–„â–ƒâ–†â–‡â–…â–†
wandb:       eval/ensemble_f1 â–†â–†â–„â–‡â–ƒâ–ˆâ–‡â–†â–„â–â–„â–‚â–â–ˆâ–†â–…â–…â–…â–â–„â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–â–‡â–ƒâ–†â–ƒâ–…â–…â–„â–ˆâ–…â–…â–…â–‡
wandb:           train/avg_f1 â–ƒâ–‚â–ˆâ–†â–‚â–‡â–…â–…â–‚â–‡â–‚â–…â–„â–ƒâ–â–ƒâ–ƒâ–‡â–„â–…â–ƒâ–„â–…â–…â–…â–‡â–â–„â–„â–†â–…â–ƒâ–‡â–„â–„â–†â–ƒâ–…â–‚â–†
wandb:      train/ensemble_f1 â–†â–„â–†â–ˆâ–…â–†â–†â–…â–‡â–‡â–„â–ƒâ–†â–…â–…â–„â–‡â–†â–‡â–ƒâ–†â–…â–„â–‚â–ˆâ–ˆâ–…â–†â–†â–†â–ƒâ–â–„â–†â–ˆâ–…â–„â–…â–…â–†
wandb:         train/mil_loss â–†â–‡â–„â–†â–ƒâ–…â–ˆâ–„â–„â–…â–ƒâ–‡â–†â–ƒâ–†â–…â–†â–ƒâ–†â–†â–„â–„â–ƒâ–„â–ƒâ–â–ƒâ–‡â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–‡â–ƒâ–‚â–‚â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84964
wandb: best/eval_avg_mil_loss 0.37017
wandb:  best/eval_ensemble_f1 0.84964
wandb:            eval/avg_f1 0.79927
wandb:      eval/avg_mil_loss 0.46532
wandb:       eval/ensemble_f1 0.79927
wandb:           train/avg_f1 0.80588
wandb:      train/ensemble_f1 0.80588
wandb:         train/mil_loss 0.95661
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfsa60va
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092101-rfsa60va/logs
wandb: ERROR Run rfsa60va errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: oobeu8vt with config:
wandb: 	actor_learning_rate: 1.0679616806413308e-05
wandb: 	attention_dropout_p: 0.0534249613980326
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6882895988584318
wandb: 	temperature: 7.417150823007754
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092330-oobeu8vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oobeu8vt
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ˆâ–…â–ƒâ–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–â–…â–…â–†â–„â–†â–„â–„â–…â–†â–…â–…â–…â–ˆâ–„â–…â–…â–ˆâ–„â–ƒâ–…â–‡â–„â–„â–…â–„â–„â–„â–…â–…â–ƒâ–…â–â–ƒâ–‚â–…â–…â–…â–…
wandb:      eval/avg_mil_loss â–„â–…â–ˆâ–„â–†â–…â–â–„â–ƒâ–ƒâ–ˆâ–…â–ƒâ–…â–„â–†â–†â–†â–ˆâ–†â–‚â–†â–„â–‡â–†â–„â–†â–†â–…â–ƒâ–…â–…â–ƒâ–†â–‡â–†â–†â–ƒâ–„â–ˆ
wandb:       eval/ensemble_f1 â–‚â–ƒâ–‚â–…â–„â–†â–ƒâ–„â–„â–…â–…â–†â–…â–‡â–ƒâ–„â–„â–„â–ˆâ–…â–‡â–‡â–…â–â–…â–ƒâ–‚â–†â–…â–„â–„â–…â–†â–ƒâ–‡â–‚â–‚â–‚â–…â–…
wandb:           train/avg_f1 â–†â–…â–ƒâ–„â–â–„â–…â–†â–ˆâ–†â–„â–†â–†â–ƒâ–†â–„â–‚â–„â–…â–…â–‡â–‡â–„â–‡â–‚â–ƒâ–„â–…â–ƒâ–†â–â–†â–†â–…â–…â–…â–‡â–‡â–…â–†
wandb:      train/ensemble_f1 â–†â–…â–…â–ƒâ–†â–„â–„â–†â–…â–„â–„â–†â–ƒâ–„â–…â–†â–†â–ˆâ–†â–‡â–„â–†â–‡â–ˆâ–‡â–â–…â–…â–‡â–…â–‚â–‚â–‡â–†â–‚â–†â–…â–†â–…â–‚
wandb:         train/mil_loss â–„â–‚â–†â–„â–„â–ˆâ–„â–„â–ƒâ–†â–„â–‚â–„â–„â–„â–‚â–…â–„â–ƒâ–â–„â–…â–„â–ƒâ–„â–…â–‚â–ƒâ–‚â–†â–„â–ƒâ–„â–†â–ƒâ–…â–„â–„â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84231
wandb: best/eval_avg_mil_loss 0.43767
wandb:  best/eval_ensemble_f1 0.84231
wandb:            eval/avg_f1 0.79429
wandb:      eval/avg_mil_loss 0.37556
wandb:       eval/ensemble_f1 0.79429
wandb:           train/avg_f1 0.79725
wandb:      train/ensemble_f1 0.79725
wandb:         train/mil_loss 0.92284
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rosy-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oobeu8vt
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092330-oobeu8vt/logs
wandb: ERROR Run oobeu8vt errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kwv7nqby with config:
wandb: 	actor_learning_rate: 2.3341768495038804e-05
wandb: 	attention_dropout_p: 0.04172694767539914
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.539897920242467
wandb: 	temperature: 1.8006450064638813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092637-kwv7nqby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwv7nqby
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–…â–ƒâ–ˆâ–‡â–‡â–ˆâ–„â–†â–†â–‡â–†â–„â–ƒâ–„â–ƒâ–…â–…â–…â–„â–‡â–‚â–…â–…â–…â–„â–‡â–‡â–†â–ƒâ–†â–„â–†â–†â–‡â–„â–„â–â–…â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–‚â–†â–„â–‚â–ƒâ–„â–„â–„â–†â–…â–‚â–‡â–…â–†â–†â–„â–†â–ˆâ–†â–ƒâ–„â–…â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–…â–ƒâ–ƒâ–â–â–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–„â–ˆâ–…â–ƒâ–†â–„â–„â–†â–…â–„â–†â–‡â–…â–„â–„â–ƒâ–…â–…â–„â–â–‡â–…â–…â–…â–„â–‡â–†â–…â–…â–‡â–„â–†â–†â–†â–„â–…â–…â–„â–ƒâ–…
wandb:           train/avg_f1 â–„â–ƒâ–…â–†â–„â–†â–„â–…â–…â–ƒâ–†â–†â–…â–…â–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–„â–„â–ƒâ–†â–‚â–„â–„â–…â–„â–„â–…â–„â–…â–„â–ˆâ–†â–ƒâ–†â–„
wandb:      train/ensemble_f1 â–„â–ƒâ–†â–†â–„â–…â–…â–ƒâ–…â–„â–†â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–â–„â–„â–ƒâ–„â–„â–„â–†â–‚â–†â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–ƒâ–„
wandb:         train/mil_loss â–‚â–„â–…â–‚â–†â–…â–†â–‚â–†â–†â–ˆâ–„â–ˆâ–‡â–…â–„â–‡â–„â–†â–‚â–†â–…â–„â–„â–‚â–…â–ƒâ–„â–„â–…â–â–…â–‚â–„â–†â–â–…â–‚â–„â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.38318
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80113
wandb:      eval/avg_mil_loss 0.43567
wandb:       eval/ensemble_f1 0.80113
wandb:           train/avg_f1 0.80756
wandb:      train/ensemble_f1 0.80756
wandb:         train/mil_loss 1.87128
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run earthy-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kwv7nqby
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092637-kwv7nqby/logs
wandb: ERROR Run kwv7nqby errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cvns0n1n with config:
wandb: 	actor_learning_rate: 2.4313770996840843e-05
wandb: 	attention_dropout_p: 0.09452399159388249
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0459654977728613
wandb: 	temperature: 0.15842507497190628
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092759-cvns0n1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvns0n1n
wandb: uploading history steps 125-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‚â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–‡â–…â–…â–…â–…â–…â–†â–ƒâ–…â–…â–‡â–…â–„â–…â–„â–â–ˆâ–…â–…â–…â–…â–†â–‡â–„â–†â–„â–…â–„â–„â–†â–†â–…â–†â–„â–„â–†â–…
wandb:      eval/avg_mil_loss â–…â–‚â–‚â–…â–…â–‚â–„â–„â–„â–†â–„â–ˆâ–„â–…â–ƒâ–ƒâ–„â–…â–‡â–„â–…â–â–„â–ƒâ–„â–†â–‚â–ˆâ–„â–„â–ƒâ–‚â–ˆâ–ƒâ–„â–„â–„â–„â–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–ƒâ–…â–„â–„â–…â–…â–„â–†â–…â–…â–â–ˆâ–…â–†â–…â–…â–…â–…â–„â–‡â–„â–„â–‡â–†â–‚â–…â–„â–…â–†â–…â–†â–…â–†â–…â–…â–ƒâ–†â–…â–…
wandb:           train/avg_f1 â–†â–â–ƒâ–ƒâ–‡â–„â–‡â–„â–ƒâ–†â–…â–‚â–…â–„â–„â–„â–†â–‡â–‡â–ƒâ–„â–…â–†â–…â–ƒâ–ˆâ–‡â–…â–‡â–‚â–„â–„â–†â–‡â–†â–†â–†â–ƒâ–ƒâ–…
wandb:      train/ensemble_f1 â–â–†â–„â–‚â–ƒâ–‚â–ƒâ–…â–â–†â–†â–†â–„â–ƒâ–‚â–†â–…â–„â–†â–‚â–„â–‡â–‡â–‡â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–â–â–ƒ
wandb:         train/mil_loss â–‡â–ˆâ–†â–‡â–†â–‡â–ˆâ–ˆâ–†â–‡â–†â–‡â–ƒâ–ƒâ–†â–†â–…â–‡â–†â–…â–„â–„â–…â–†â–…â–…â–„â–„â–ƒâ–…â–„â–ƒâ–â–ƒâ–ƒâ–‚â–â–„â–‡â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–ˆâ–â–„â–„â–â–ˆâ–ˆâ–â–â–„â–ˆâ–ˆâ–„â–â–„â–„â–â–„â–„â–â–ˆâ–ˆâ–ˆâ–â–„â–„â–„â–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–â–ˆâ–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8354
wandb: best/eval_avg_mil_loss 0.4302
wandb:  best/eval_ensemble_f1 0.8354
wandb:            eval/avg_f1 0.78084
wandb:      eval/avg_mil_loss 0.49248
wandb:       eval/ensemble_f1 0.78084
wandb:           train/avg_f1 0.78615
wandb:      train/ensemble_f1 0.78615
wandb:         train/mil_loss 0.90481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run expert-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvns0n1n
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092759-cvns0n1n/logs
wandb: ERROR Run cvns0n1n errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lf96x4g5 with config:
wandb: 	actor_learning_rate: 0.0003725268044206139
wandb: 	attention_dropout_p: 0.3687567710280643
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28109333223771127
wandb: 	temperature: 5.434496838575493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093101-lf96x4g5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lf96x4g5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–„â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–ƒâ–„â–ƒâ–†â–„â–…â–†â–†â–„â–…â–‚â–†â–…â–†â–‡â–â–†â–ƒâ–†â–‡â–…â–‡â–„â–†â–ƒâ–ƒâ–‡â–†â–…â–ƒâ–‚â–ƒâ–„â–†â–…â–ˆâ–‚â–„
wandb:      eval/avg_mil_loss â–‚â–„â–‚â–„â–„â–†â–ƒâ–‡â–ƒâ–†â–…â–…â–„â–„â–…â–‚â–‚â–â–„â–â–ƒâ–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–â–ƒâ–ˆâ–‡â–„â–ƒâ–„â–ƒâ–„â–„â–‚â–†
wandb:       eval/ensemble_f1 â–…â–ƒâ–„â–ƒâ–‡â–†â–‡â–†â–‚â–…â–‡â–ƒâ–‡â–â–ƒâ–ƒâ–…â–†â–‡â–…â–‡â–„â–‚â–‡â–†â–‚â–ƒâ–‚â–…â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–‚â–†â–„â–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ˆâ–…â–„â–…â–„â–…â–ƒâ–„â–…â–†â–…â–†â–…â–ƒâ–ƒâ–„â–…â–…â–…â–ƒâ–â–„â–…â–…â–…â–ƒâ–„â–†â–†â–†â–„â–…â–†â–…â–„â–‡â–„â–…â–ƒ
wandb:      train/ensemble_f1 â–…â–ˆâ–…â–…â–„â–…â–†â–…â–ƒâ–„â–ƒâ–…â–†â–…â–ƒâ–„â–…â–…â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–â–…â–…â–„â–…â–†â–„â–†â–†â–„â–…â–„â–‡â–…â–ƒ
wandb:         train/mil_loss â–…â–„â–‡â–‡â–„â–…â–…â–…â–…â–„â–ˆâ–ˆâ–…â–„â–…â–…â–„â–„â–…â–…â–†â–‚â–„â–ƒâ–ƒâ–†â–…â–ƒâ–†â–â–ƒâ–‡â–„â–ƒâ–…â–†â–‡â–â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81717
wandb: best/eval_avg_mil_loss 0.398
wandb:  best/eval_ensemble_f1 0.81717
wandb:            eval/avg_f1 0.77005
wandb:      eval/avg_mil_loss 0.51847
wandb:       eval/ensemble_f1 0.77005
wandb:            test/avg_f1 0.70324
wandb:      test/avg_mil_loss 0.76307
wandb:       test/ensemble_f1 0.70324
wandb:           train/avg_f1 0.76981
wandb:      train/ensemble_f1 0.76981
wandb:         train/mil_loss 0.82818
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lf96x4g5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093101-lf96x4g5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5bcdwj8t with config:
wandb: 	actor_learning_rate: 2.2703022414887176e-05
wandb: 	attention_dropout_p: 0.3710670137872386
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4821765452383525
wandb: 	temperature: 8.976631677247324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093244-5bcdwj8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bcdwj8t
wandb: uploading history steps 170-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‚â–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–…â–†â–„â–…â–†â–„â–†â–â–ƒâ–‡â–ˆâ–â–„â–‡â–‡â–†â–„â–‚â–ƒâ–„â–ƒâ–…â–†â–‡â–†â–ƒâ–‡â–†â–†â–‚â–†â–…â–â–‡â–„â–„â–…â–‚
wandb:      eval/avg_mil_loss â–ˆâ–…â–…â–‚â–â–„â–‚â–‡â–†â–„â–ƒâ–‚â–…â–†â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–„â–‡â–…â–â–ƒâ–‚â–„â–‚â–…â–ƒâ–‚â–…â–…â–†â–†â–‚â–‡â–…â–…
wandb:       eval/ensemble_f1 â–ƒâ–…â–‚â–„â–ƒâ–…â–…â–…â–„â–†â–…â–…â–„â–†â–‚â–‡â–„â–†â–†â–…â–‡â–…â–†â–‡â–…â–ˆâ–†â–…â–‚â–ƒâ–‚â–ˆâ–…â–„â–„â–…â–„â–„â–„â–
wandb:           train/avg_f1 â–…â–ˆâ–‚â–…â–„â–†â–„â–â–‡â–ƒâ–†â–†â–ƒâ–„â–…â–…â–†â–‡â–ƒâ–…â–‡â–…â–†â–†â–…â–ˆâ–„â–ƒâ–…â–…â–‚â–…â–‚â–„â–†â–ˆâ–‡â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–…â–‚â–„â–ˆâ–‡â–â–ˆâ–ƒâ–†â–„â–‡â–„â–…â–ƒâ–…â–…â–ƒâ–‡â–ˆâ–…â–†â–†â–â–†â–â–…â–…â–†â–‚â–„â–…â–„â–‡â–…â–‚â–ƒâ–‡â–ƒâ–‡â–‚
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–‡â–…â–…â–ˆâ–‡â–†â–†â–†â–†â–„â–‡â–„â–…â–„â–…â–…â–…â–…â–„â–„â–ƒâ–„â–†â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–‚â–‚â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8355
wandb: best/eval_avg_mil_loss 0.40751
wandb:  best/eval_ensemble_f1 0.8355
wandb:            eval/avg_f1 0.78467
wandb:      eval/avg_mil_loss 0.48025
wandb:       eval/ensemble_f1 0.78467
wandb:           train/avg_f1 0.78916
wandb:      train/ensemble_f1 0.78916
wandb:         train/mil_loss 0.99803
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5bcdwj8t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093244-5bcdwj8t/logs
wandb: ERROR Run 5bcdwj8t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e0t7oo76 with config:
wandb: 	actor_learning_rate: 0.0003717799595309047
wandb: 	attention_dropout_p: 0.35053341892563555
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8628851771120444
wandb: 	temperature: 3.745122796000409
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093653-e0t7oo76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0t7oo76
wandb: uploading history steps 168-180, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–…â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–„â–…â–„â–‚â–ƒâ–ƒâ–„â–…â–ƒâ–â–†â–ƒâ–…â–‚â–ƒâ–ˆâ–‡â–„â–†â–ƒâ–‚â–‚â–‡â–â–ƒâ–…â–…â–‡â–„â–„â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–„â–ƒ
wandb:      eval/avg_mil_loss â–…â–„â–„â–„â–…â–…â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–†â–…â–†â–‡â–ˆâ–…â–‚â–„â–„â–ƒâ–ƒâ–„â–†â–†â–„â–„â–…
wandb:       eval/ensemble_f1 â–ƒâ–†â–„â–†â–…â–ƒâ–â–‚â–ƒâ–…â–‡â–„â–„â–ƒâ–‚â–„â–†â–„â–ˆâ–„â–‡â–…â–ƒâ–…â–…â–„â–„â–‡â–ƒâ–…â–‚â–‚â–†â–†â–„â–„â–…â–‚â–†â–…
wandb:           train/avg_f1 â–…â–„â–†â–…â–„â–ƒâ–„â–…â–„â–„â–†â–„â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–„â–„â–ƒâ–ƒâ–†â–†â–„â–ƒâ–‡â–‚â–…â–…â–„â–…â–„â–„â–ˆâ–„â–†â–â–„
wandb:      train/ensemble_f1 â–…â–„â–„â–‚â–‚â–…â–„â–â–â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–‡â–‡â–„â–ˆâ–ƒâ–ƒâ–†â–…â–‡â–…â–†â–„â–‡â–„â–…â–‚â–‡â–…â–„â–†â–ƒâ–ƒâ–…
wandb:         train/mil_loss â–‡â–…â–ˆâ–ˆâ–‡â–†â–†â–‡â–‡â–‡â–„â–…â–ˆâ–…â–‚â–†â–†â–…â–†â–…â–„â–ƒâ–„â–…â–„â–„â–„â–â–„â–†â–†â–„â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–â–
wandb:      train/policy_loss â–â–„â–ˆâ–ˆâ–„â–„â–â–ˆâ–„â–„â–ˆâ–„â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–â–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–ˆâ–…â–â–ˆâ–…â–ˆâ–â–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–…â–â–â–ˆâ–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84651
wandb: best/eval_avg_mil_loss 0.38252
wandb:  best/eval_ensemble_f1 0.84651
wandb:            eval/avg_f1 0.76611
wandb:      eval/avg_mil_loss 0.48094
wandb:       eval/ensemble_f1 0.76611
wandb:           train/avg_f1 0.78555
wandb:      train/ensemble_f1 0.78555
wandb:         train/mil_loss 1.05442
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0t7oo76
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093653-e0t7oo76/logs
wandb: ERROR Run e0t7oo76 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: go2ky8ti with config:
wandb: 	actor_learning_rate: 6.455372448352759e-05
wandb: 	attention_dropout_p: 0.1903925648261911
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.919630418126012
wandb: 	temperature: 9.34492577994068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094030-go2ky8ti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go2ky8ti
wandb: uploading history steps 148-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–…â–‡â–„â–…â–‚â–‡â–†â–„â–‡â–‚â–ˆâ–…â–†â–ˆâ–†â–‡â–‡â–„â–…â–…â–†â–†â–†â–ˆâ–†â–ƒâ–„â–…â–„â–‡â–„â–‚â–†â–‡â–†â–ƒâ–…â–„â–‚
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ˆâ–‚â–…â–‚â–„â–‚â–ƒâ–…â–â–‚â–ƒâ–…â–â–‡â–‚â–‚â–†â–‡â–ˆâ–‚â–„â–„â–‚â–„â–â–ˆâ–…â–ƒâ–†â–â–„â–…â–†â–…â–„â–„â–„â–ˆ
wandb:       eval/ensemble_f1 â–â–„â–„â–‡â–†â–‚â–‚â–…â–…â–„â–„â–…â–„â–ƒâ–ˆâ–…â–†â–ƒâ–†â–…â–ƒâ–„â–†â–†â–…â–„â–†â–‚â–‚â–„â–…â–…â–†â–â–„â–„â–†â–ƒâ–ƒâ–‚
wandb:           train/avg_f1 â–„â–‡â–†â–†â–…â–„â–…â–…â–…â–…â–†â–‡â–ƒâ–…â–„â–„â–†â–„â–†â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–…â–„â–…â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–ƒâ–
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–…â–…â–‡â–ƒâ–‡â–‡â–ˆâ–†â–„â–…â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–„â–â–ƒâ–‚â–†â–‚â–„â–â–‚â–†â–‚â–ƒâ–â–ƒâ–‚â–„â–â–ƒ
wandb:         train/mil_loss â–†â–‡â–ˆâ–ˆâ–„â–†â–†â–„â–…â–‡â–…â–…â–…â–†â–…â–„â–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–„â–ƒâ–ƒâ–â–„â–‚â–â–â–‚â–‚â–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–„â–†â–â–†â–†â–†â–…â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–…â–„â–…â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84572
wandb: best/eval_avg_mil_loss 0.41181
wandb:  best/eval_ensemble_f1 0.84572
wandb:            eval/avg_f1 0.75901
wandb:      eval/avg_mil_loss 0.54342
wandb:       eval/ensemble_f1 0.75901
wandb:           train/avg_f1 0.77235
wandb:      train/ensemble_f1 0.77235
wandb:         train/mil_loss 1.33766
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fancy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/go2ky8ti
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094030-go2ky8ti/logs
wandb: ERROR Run go2ky8ti errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ryetyn4a with config:
wandb: 	actor_learning_rate: 2.1049028119794272e-05
wandb: 	attention_dropout_p: 0.2417943868448829
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 179
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.742829260256917
wandb: 	temperature: 3.3588878311495183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094351-ryetyn4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ryetyn4a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–…â–ˆâ–…â–„â–†â–†â–…â–„â–„â–„â–„â–…â–…â–…â–‚â–…â–„â–ƒâ–…â–…â–„â–ˆâ–…â–„â–ˆâ–…â–…â–â–„â–…â–„â–…â–…â–†â–…â–„â–â–‚
wandb:      eval/avg_mil_loss â–ƒâ–‚â–â–‚â–†â–ƒâ–‚â–‡â–â–ƒâ–ƒâ–ƒâ–„â–‡â–ƒâ–ƒâ–‚â–â–‚â–…â–ˆâ–ƒâ–ƒâ–…â–â–‚â–ƒâ–ƒâ–†â–ƒâ–‚â–‡â–‡â–…â–‚â–†â–ƒâ–…â–ˆâ–†
wandb:       eval/ensemble_f1 â–ˆâ–‡â–ƒâ–ƒâ–„â–†â–…â–‚â–„â–…â–„â–ƒâ–„â–…â–„â–„â–…â–„â–ƒâ–„â–„â–…â–†â–‚â–„â–…â–ƒâ–ƒâ–‚â–‡â–…â–…â–†â–…â–ƒâ–„â–†â–…â–â–„
wandb:           train/avg_f1 â–‡â–„â–„â–…â–…â–ˆâ–ˆâ–‡â–‡â–…â–…â–†â–‡â–…â–…â–‡â–‡â–„â–…â–…â–†â–„â–†â–ƒâ–…â–ƒâ–…â–…â–…â–‚â–…â–‚â–„â–‚â–ƒâ–†â–‚â–ƒâ–…â–
wandb:      train/ensemble_f1 â–‡â–ˆâ–„â–ˆâ–„â–†â–†â–‡â–„â–…â–…â–†â–†â–…â–†â–‡â–…â–…â–…â–†â–†â–†â–†â–…â–…â–„â–ƒâ–…â–„â–„â–‚â–„â–‚â–ƒâ–„â–…â–ƒâ–ƒâ–…â–
wandb:         train/mil_loss â–ˆâ–‡â–†â–†â–†â–†â–†â–…â–…â–†â–…â–†â–…â–…â–…â–…â–ƒâ–†â–ƒâ–„â–„â–ƒâ–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86466
wandb: best/eval_avg_mil_loss 0.37764
wandb:  best/eval_ensemble_f1 0.86466
wandb:            eval/avg_f1 0.77329
wandb:      eval/avg_mil_loss 0.48484
wandb:       eval/ensemble_f1 0.77329
wandb:           train/avg_f1 0.77177
wandb:      train/ensemble_f1 0.77177
wandb:         train/mil_loss 1.37854
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run colorful-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ryetyn4a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094351-ryetyn4a/logs
wandb: ERROR Run ryetyn4a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 6bw89tyh with config:
wandb: 	actor_learning_rate: 5.7206040487497626e-05
wandb: 	attention_dropout_p: 0.4478146437681773
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.990835650418978
wandb: 	temperature: 5.785713433763787
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094754-6bw89tyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6bw89tyh
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–â–ˆâ–‡
wandb:  best/eval_ensemble_f1 â–â–„â–„â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–ƒâ–„â–†â–ƒâ–„â–„â–â–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚â–ˆâ–‚â–„â–ƒâ–„â–…â–ƒâ–…â–„â–…â–‚â–â–„â–‚â–â–†â–†â–…â–„
wandb:      eval/avg_mil_loss â–‚â–â–ƒâ–„â–ƒâ–„â–ƒâ–†â–†â–†â–„â–‡â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–†â–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…
wandb:       eval/ensemble_f1 â–†â–„â–„â–„â–†â–„â–„â–„â–‚â–ƒâ–„â–…â–…â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–…â–„â–ˆâ–ƒâ–†â–ƒâ–â–„â–†â–†â–†â–†â–†â–ƒâ–ƒâ–„â–†â–†â–…â–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–†â–‚â–„â–…â–„â–…â–…â–…â–‡â–ˆâ–…â–†â–‚â–ˆâ–‚â–‡â–‡â–‚â–†â–ƒâ–„â–…â–„â–ƒâ–†â–†â–„â–„â–„â–…â–„â–„â–„â–‡â–…â–„â–ƒâ–‚â–ƒ
wandb:      train/ensemble_f1 â–â–„â–†â–…â–†â–ˆâ–…â–‡â–…â–†â–…â–†â–‡â–ƒâ–…â–†â–ƒâ–‡â–ƒâ–†â–ƒâ–„â–†â–†â–…â–†â–…â–„â–„â–…â–…â–„â–…â–ˆâ–†â–†â–‚â–…â–…â–„
wandb:         train/mil_loss â–…â–â–ƒâ–†â–…â–ƒâ–ƒâ–„â–…â–†â–â–‚â–‚â–ƒâ–‡â–†â–†â–…â–ƒâ–…â–â–ƒâ–„â–†â–ƒâ–…â–ˆâ–„â–…â–„â–…â–â–ƒâ–ˆâ–„â–„â–ƒâ–†â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84271
wandb: best/eval_avg_mil_loss 0.40467
wandb:  best/eval_ensemble_f1 0.84271
wandb:            eval/avg_f1 0.79135
wandb:      eval/avg_mil_loss 0.49944
wandb:       eval/ensemble_f1 0.79135
wandb:            test/avg_f1 0.80565
wandb:      test/avg_mil_loss 0.34991
wandb:       test/ensemble_f1 0.80565
wandb:           train/avg_f1 0.78741
wandb:      train/ensemble_f1 0.78741
wandb:         train/mil_loss 0.50651
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6bw89tyh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094754-6bw89tyh/logs
wandb: Agent Starting Run: a2hpmw7g with config:
wandb: 	actor_learning_rate: 6.271835983885393e-06
wandb: 	attention_dropout_p: 0.162731680357456
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1428757180445982
wandb: 	temperature: 3.929845113228454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094922-a2hpmw7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a2hpmw7g
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 130-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–„â–…â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–â–ƒâ–ƒâ–„â–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–„â–„â–…â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–â–…â–‚â–ƒâ–ƒâ–„â–…â–â–‚â–†â–…â–„â–„â–„â–‚â–‚â–„â–„â–„â–ƒâ–„â–„â–„â–…â–†â–…â–ƒâ–…â–…â–…â–ƒâ–„â–‡â–„â–…â–ƒâ–ƒâ–ˆâ–„
wandb:      eval/avg_mil_loss â–†â–…â–‚â–â–„â–‚â–„â–‡â–…â–ˆâ–ƒâ–…â–„â–…â–…â–„â–…â–„â–ƒâ–…â–„â–„â–„â–‚â–‚â–ƒâ–„â–…â–‚â–â–‚â–ƒâ–‚â–‚â–„â–†â–â–…â–„â–†
wandb:       eval/ensemble_f1 â–†â–†â–ƒâ–‡â–ƒâ–…â–‡â–„â–…â–„â–†â–…â–…â–„â–„â–…â–†â–„â–†â–ƒâ–…â–ƒâ–„â–†â–„â–†â–†â–†â–„â–†â–…â–†â–†â–ˆâ–…â–â–ƒâ–†â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–…â–„â–†â–…â–‡â–ƒâ–„â–„â–…â–…â–„â–ˆâ–…â–„â–†â–†â–…â–‡â–ƒâ–…â–‡â–‡â–†â–‡â–ƒâ–ˆâ–‡â–‡â–…â–†â–…â–„â–†â–‡â–…â–†â–‡â–„â–
wandb:      train/ensemble_f1 â–†â–„â–„â–‡â–„â–‡â–…â–‡â–†â–ƒâ–„â–„â–ˆâ–„â–†â–†â–…â–‡â–…â–…â–ƒâ–‡â–…â–†â–ƒâ–„â–…â–„â–„â–ƒâ–†â–‡â–…â–‡â–…â–„â–‡â–†â–…â–
wandb:         train/mil_loss â–‡â–…â–‡â–ˆâ–†â–‡â–‡â–„â–ˆâ–ƒâ–…â–ˆâ–â–†â–„â–…â–…â–†â–‡â–â–…â–„â–‡â–„â–â–„â–…â–„â–…â–…â–‚â–ƒâ–ƒâ–…â–„â–â–â–ƒâ–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85665
wandb: best/eval_avg_mil_loss 0.38131
wandb:  best/eval_ensemble_f1 0.85665
wandb:            eval/avg_f1 0.80626
wandb:      eval/avg_mil_loss 0.51365
wandb:       eval/ensemble_f1 0.80626
wandb:            test/avg_f1 0.78256
wandb:      test/avg_mil_loss 0.52837
wandb:       test/ensemble_f1 0.78256
wandb:           train/avg_f1 0.80642
wandb:      train/ensemble_f1 0.80642
wandb:         train/mil_loss 1.31936
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run trim-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a2hpmw7g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094922-a2hpmw7g/logs
wandb: Agent Starting Run: ue0ksfpo with config:
wandb: 	actor_learning_rate: 2.3995823571604343e-05
wandb: 	attention_dropout_p: 0.0349999094263197
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7377465040014111
wandb: 	temperature: 5.130055860330083
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095208-ue0ksfpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue0ksfpo
wandb: uploading history steps 147-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–…â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–‡â–„â–„â–…â–†â–…â–ƒâ–…â–‡â–ˆâ–…â–„â–â–†â–ƒâ–†â–…â–†â–…â–†â–â–†â–†â–…â–…â–†â–„â–‡â–†â–„â–ƒâ–…â–„â–„â–…â–„â–†â–„
wandb:      eval/avg_mil_loss â–„â–„â–â–…â–„â–„â–„â–ˆâ–…â–„â–…â–ƒâ–ƒâ–…â–†â–„â–…â–†â–„â–ˆâ–„â–…â–‡â–„â–†â–ƒâ–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–†â–„â–ˆâ–…â–‡
wandb:       eval/ensemble_f1 â–ƒâ–‡â–ƒâ–†â–„â–‚â–„â–ƒâ–ƒâ–ˆâ–„â–ƒâ–†â–ƒâ–†â–„â–ˆâ–…â–…â–ƒâ–…â–…â–†â–†â–„â–‚â–ƒâ–†â–…â–ƒâ–…â–‡â–‚â–„â–…â–‡â–ƒâ–â–„â–
wandb:           train/avg_f1 â–…â–‡â–ˆâ–‡â–‡â–†â–†â–†â–ˆâ–…â–…â–ƒâ–…â–‡â–…â–„â–†â–‡â–ˆâ–†â–…â–†â–…â–…â–…â–â–‡â–ƒâ–ƒâ–ƒâ–…â–‚â–†â–ƒâ–„â–ƒâ–‚â–†â–…â–
wandb:      train/ensemble_f1 â–‡â–ˆâ–‡â–…â–†â–‡â–†â–ˆâ–†â–†â–„â–‡â–„â–†â–ˆâ–†â–…â–†â–…â–†â–…â–†â–†â–†â–…â–„â–„â–ƒâ–ƒâ–†â–ƒâ–„â–„â–…â–ƒâ–„â–†â–„â–â–…
wandb:         train/mil_loss â–ˆâ–‡â–…â–†â–…â–†â–‡â–…â–‡â–†â–‡â–„â–„â–†â–…â–†â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–‚â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86776
wandb: best/eval_avg_mil_loss 0.35231
wandb:  best/eval_ensemble_f1 0.86776
wandb:            eval/avg_f1 0.82845
wandb:      eval/avg_mil_loss 0.46664
wandb:       eval/ensemble_f1 0.82845
wandb:           train/avg_f1 0.78495
wandb:      train/ensemble_f1 0.78495
wandb:         train/mil_loss 1.24611
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sweet-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ue0ksfpo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095208-ue0ksfpo/logs
wandb: ERROR Run ue0ksfpo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1om9li4k with config:
wandb: 	actor_learning_rate: 8.827857776846184e-06
wandb: 	attention_dropout_p: 0.2568841289569681
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5888996254868109
wandb: 	temperature: 2.6500616352657493
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095550-1om9li4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1om9li4k
wandb: uploading wandb-summary.json
wandb: uploading history steps 115-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–‚â–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–„â–…â–â–…â–‡â–ƒâ–ˆâ–„â–ƒâ–…â–‚â–…â–…â–„â–†â–…â–ƒâ–†â–†â–…â–…â–‚â–„â–†â–†â–…â–…â–ˆâ–ƒâ–„â–†â–â–†â–ƒâ–†â–†â–†â–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–‚â–„â–ˆâ–„â–‚â–‚â–…â–„â–…â–…â–â–„â–„â–ƒâ–…â–‚â–â–‚â–†â–„â–†â–†â–„â–ƒâ–†â–‚â–…â–…â–‚â–ƒâ–‡â–ƒâ–„â–â–…â–‚â–…â–…â–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–…â–â–…â–â–†â–†â–â–…â–ˆâ–ˆâ–ƒâ–ˆâ–†â–‡â–‚â–‡â–â–„â–‡â–…â–…â–ƒâ–‚â–†â–…â–†â–ˆâ–†â–„â–„â–ƒâ–ˆâ–‚â–†â–ƒâ–‡â–†â–ƒâ–
wandb:           train/avg_f1 â–…â–„â–…â–„â–ˆâ–ƒâ–ƒâ–…â–„â–‚â–„â–ƒâ–‡â–‡â–‚â–†â–‚â–†â–‚â–ƒâ–„â–„â–…â–„â–ƒâ–…â–…â–‚â–â–ƒâ–†â–…â–ƒâ–„â–„â–‡â–†â–â–‡â–„
wandb:      train/ensemble_f1 â–„â–„â–„â–ƒâ–„â–†â–ƒâ–„â–…â–„â–ƒâ–„â–ƒâ–„â–…â–„â–‚â–„â–â–†â–ƒâ–…â–ƒâ–ˆâ–ƒâ–…â–…â–…â–„â–â–†â–„â–â–‚â–…â–„â–†â–„â–„â–‚
wandb:         train/mil_loss â–â–‡â–„â–†â–ˆâ–…â–„â–†â–‡â–‡â–„â–‡â–…â–…â–ˆâ–‚â–„â–†â–…â–ƒâ–â–„â–ˆâ–‡â–…â–…â–…â–„â–ƒâ–‡â–‡â–„â–†â–„â–†â–ƒâ–…â–„â–‡â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83497
wandb: best/eval_avg_mil_loss 0.41467
wandb:  best/eval_ensemble_f1 0.83497
wandb:            eval/avg_f1 0.80563
wandb:      eval/avg_mil_loss 0.49054
wandb:       eval/ensemble_f1 0.80563
wandb:           train/avg_f1 0.79166
wandb:      train/ensemble_f1 0.79166
wandb:         train/mil_loss 0.79453
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run elated-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1om9li4k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095550-1om9li4k/logs
wandb: ERROR Run 1om9li4k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 42acae45 with config:
wandb: 	actor_learning_rate: 6.921185289744615e-05
wandb: 	attention_dropout_p: 0.47295931587037343
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2869752550730136
wandb: 	temperature: 6.924475164568653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095825-42acae45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/42acae45
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–‡â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–„â–…â–†â–‡â–…â–…â–„â–ƒâ–„â–„â–„â–„â–…â–…â–‚â–…â–„â–†â–„â–…â–‚â–„â–†â–„â–…â–â–†â–‚â–†â–ƒâ–†â–…â–ƒâ–ƒâ–…â–†â–„â–ˆâ–„â–ˆ
wandb:      eval/avg_mil_loss â–‚â–ƒâ–„â–â–…â–â–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–ˆâ–ƒâ–†â–†â–…â–‡â–‡â–…â–†â–„â–„â–„â–†â–ƒâ–…â–ƒâ–…â–…â–…â–…â–†â–…â–â–‡â–†â–†â–‡â–„â–‡â–„â–ƒâ–‚â–†â–…â–ƒâ–†â–„â–ƒâ–†
wandb:           train/avg_f1 â–†â–„â–‡â–ƒâ–„â–†â–…â–„â–†â–ˆâ–„â–‡â–†â–†â–…â–ƒâ–â–‚â–â–…â–‡â–†â–‡â–â–‡â–„â–…â–ˆâ–‡â–‚â–ƒâ–„â–†â–…â–‡â–ƒâ–‡â–‡â–„â–…
wandb:      train/ensemble_f1 â–„â–†â–„â–†â–‡â–‡â–…â–†â–„â–„â–â–†â–…â–‚â–„â–‡â–ƒâ–†â–„â–†â–ˆâ–…â–ˆâ–†â–‡â–„â–„â–‚â–ƒâ–…â–‚â–ƒâ–…â–†â–„â–ˆâ–„â–‡â–„â–…
wandb:         train/mil_loss â–…â–†â–‡â–ˆâ–‚â–„â–†â–…â–‡â–†â–…â–ƒâ–„â–„â–‡â–…â–„â–„â–ƒâ–†â–…â–„â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–…â–†â–ƒâ–„â–…â–ƒâ–ƒâ–…â–„â–
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.38115
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.84231
wandb:      eval/avg_mil_loss 0.40029
wandb:       eval/ensemble_f1 0.84231
wandb:           train/avg_f1 0.80761
wandb:      train/ensemble_f1 0.80761
wandb:         train/mil_loss 1.05594
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run different-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/42acae45
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095825-42acae45/logs
wandb: ERROR Run 42acae45 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ewzoq9bx with config:
wandb: 	actor_learning_rate: 1.1047573448721348e-06
wandb: 	attention_dropout_p: 0.01218052113661966
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8531304242632609
wandb: 	temperature: 5.2775596102143005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100055-ewzoq9bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewzoq9bx
wandb: uploading history steps 166-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–…â–…â–ƒâ–ƒâ–…â–ƒâ–…â–…â–„â–ƒâ–„â–†â–„â–ƒâ–…â–‚â–ˆâ–„â–…â–„â–‚â–…â–…â–‚â–â–„â–…â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–„â–…â–ƒ
wandb:      eval/avg_mil_loss â–‚â–ƒâ–…â–…â–…â–…â–ƒâ–„â–†â–„â–…â–„â–„â–„â–…â–†â–ˆâ–†â–†â–â–â–„â–…â–ˆâ–†â–†â–ˆâ–…â–„â–ˆâ–ƒâ–‡â–…â–‡â–ƒâ–†â–‚â–†â–†â–„
wandb:       eval/ensemble_f1 â–ˆâ–…â–„â–…â–‚â–†â–„â–…â–…â–ƒâ–„â–†â–„â–ƒâ–†â–â–…â–…â–…â–â–…â–…â–‚â–…â–…â–„â–„â–†â–‚â–…â–„â–†â–„â–„â–„â–„â–…â–‚â–„â–„
wandb:           train/avg_f1 â–…â–…â–„â–‡â–†â–‚â–‡â–…â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–‚â–…â–…â–â–…â–ƒâ–„â–‚â–†â–ˆâ–‡â–…â–‡â–…â–ƒâ–…â–…â–„â–â–ƒâ–„â–†â–†â–„â–ƒâ–‡
wandb:      train/ensemble_f1 â–†â–‡â–ƒâ–‡â–‚â–…â–†â–†â–‡â–„â–…â–ƒâ–†â–â–†â–†â–…â–†â–…â–…â–ƒâ–…â–ˆâ–‡â–†â–„â–…â–…â–†â–†â–„â–†â–„â–„â–ƒâ–ƒâ–â–ƒâ–†â–†
wandb:         train/mil_loss â–‡â–‡â–ˆâ–ˆâ–‡â–…â–‡â–†â–†â–…â–‡â–†â–„â–†â–…â–„â–„â–ƒâ–„â–„â–ƒâ–…â–…â–„â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–„â–„â–â–â–â–ƒâ–â–ƒ
wandb:      train/policy_loss â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–…â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87177
wandb: best/eval_avg_mil_loss 0.42023
wandb:  best/eval_ensemble_f1 0.87177
wandb:            eval/avg_f1 0.77735
wandb:      eval/avg_mil_loss 0.49494
wandb:       eval/ensemble_f1 0.77735
wandb:           train/avg_f1 0.81043
wandb:      train/ensemble_f1 0.81043
wandb:         train/mil_loss 0.90047
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comic-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ewzoq9bx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100055-ewzoq9bx/logs
wandb: ERROR Run ewzoq9bx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ry2lri89 with config:
wandb: 	actor_learning_rate: 9.188532974331809e-06
wandb: 	attention_dropout_p: 0.2483283145952186
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.004905234464092301
wandb: 	temperature: 3.667645728293559
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100427-ry2lri89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry2lri89
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‚â–„â–â–‡â–‚â–„â–…â–…â–‚â–†â–†â–†â–‡â–…â–‚â–„â–…â–…â–ƒâ–…â–†â–„â–…â–†â–ˆâ–„â–…â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–…â–â–‚â–…â–„â–‚
wandb:      eval/avg_mil_loss â–…â–„â–‚â–ƒâ–â–†â–…â–‚â–â–†â–‚â–ƒâ–…â–ƒâ–„â–„â–„â–„â–‚â–„â–„â–‚â–„â–ƒâ–„â–…â–‚â–‚â–ƒâ–„â–â–†â–„â–„â–…â–…â–‡â–„â–‚â–ˆ
wandb:       eval/ensemble_f1 â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–…â–†â–…â–ƒâ–„â–„â–„â–…â–†â–†â–ƒâ–‚â–†â–ƒâ–ƒâ–…â–…â–‡â–ˆâ–†â–…â–†â–„â–†â–„â–…â–„â–†â–„â–â–„â–ƒâ–„â–ƒ
wandb:           train/avg_f1 â–„â–…â–ƒâ–…â–ƒâ–…â–†â–„â–„â–ˆâ–ƒâ–‡â–„â–…â–„â–„â–„â–„â–‡â–ˆâ–…â–„â–ƒâ–…â–„â–‚â–…â–†â–„â–…â–„â–ƒâ–…â–ƒâ–„â–…â–ƒâ–…â–ƒâ–
wandb:      train/ensemble_f1 â–†â–…â–ƒâ–‡â–…â–…â–†â–ˆâ–†â–…â–…â–…â–†â–…â–†â–…â–„â–†â–†â–†â–…â–…â–…â–„â–…â–„â–„â–„â–„â–„â–„â–…â–â–…â–…â–ƒâ–‚â–„â–ƒâ–‚
wandb:         train/mil_loss â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–…â–…â–„â–…â–…â–‚â–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:      train/policy_loss â–…â–…â–ˆâ–…â–‚â–…â–…â–…â–…â–ƒâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ˆâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85373
wandb: best/eval_avg_mil_loss 0.3911
wandb:  best/eval_ensemble_f1 0.85373
wandb:            eval/avg_f1 0.78777
wandb:      eval/avg_mil_loss 0.47348
wandb:       eval/ensemble_f1 0.78777
wandb:           train/avg_f1 0.78275
wandb:      train/ensemble_f1 0.78275
wandb:         train/mil_loss 1.37462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry2lri89
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100427-ry2lri89/logs
wandb: ERROR Run ry2lri89 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: csjmw8nx with config:
wandb: 	actor_learning_rate: 7.85889170846697e-05
wandb: 	attention_dropout_p: 0.2189732870365968
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9942279311437396
wandb: 	temperature: 6.084041894178177
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100836-csjmw8nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csjmw8nx
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–‚â–„â–ƒâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–†â–…â–†â–ˆâ–‚â–ƒâ–†â–â–ˆâ–…â–‡â–„â–†â–„â–ƒâ–†â–‡â–…â–ƒâ–…â–†â–…â–†â–†â–‡â–…â–„â–„â–ƒâ–…â–†â–„â–…â–„â–‡â–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–„â–ƒâ–…â–ˆâ–„â–ƒâ–…â–‡â–ƒâ–ƒâ–…â–…â–ˆâ–‚â–‡â–â–ƒâ–„â–ƒâ–†â–†â–‡â–…â–‡â–‚â–†â–‡â–…â–†â–ˆâ–…â–‚â–‡â–…â–‚â–ˆâ–…â–„â–„â–‚
wandb:       eval/ensemble_f1 â–†â–‡â–…â–‡â–‚â–‚â–â–‚â–‡â–„â–ƒâ–ˆâ–†â–†â–†â–„â–ˆâ–†â–…â–‚â–…â–„â–‡â–ƒâ–„â–„â–‡â–…â–…â–…â–†â–„â–†â–…â–ƒâ–ˆâ–‚â–„â–…â–†
wandb:           train/avg_f1 â–…â–ˆâ–„â–„â–†â–†â–…â–„â–†â–ˆâ–…â–…â–‡â–ƒâ–â–ƒâ–†â–„â–†â–†â–„â–†â–ƒâ–‚â–ƒâ–‚â–…â–…â–ƒâ–„â–†â–„â–‚â–„â–…â–„â–ƒâ–…â–‚â–…
wandb:      train/ensemble_f1 â–‚â–„â–†â–†â–…â–ˆâ–ƒâ–ƒâ–„â–‡â–…â–ƒâ–„â–…â–ƒâ–ƒâ–„â–ˆâ–â–„â–…â–…â–ƒâ–„â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–â–ƒâ–†â–„â–„â–…â–„â–…â–…
wandb:         train/mil_loss â–†â–†â–…â–…â–…â–†â–„â–†â–†â–„â–†â–…â–†â–ˆâ–„â–ˆâ–‚â–…â–„â–ƒâ–†â–†â–†â–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–‡â–…â–„â–â–‚â–„â–…â–„â–…â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.39721
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.78402
wandb:      eval/avg_mil_loss 0.46089
wandb:       eval/ensemble_f1 0.78402
wandb:           train/avg_f1 0.7814
wandb:      train/ensemble_f1 0.7814
wandb:         train/mil_loss 1.33767
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run colorful-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/csjmw8nx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100836-csjmw8nx/logs
wandb: ERROR Run csjmw8nx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: euygwwrc with config:
wandb: 	actor_learning_rate: 4.653092146804248e-06
wandb: 	attention_dropout_p: 0.1389782942497042
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.443562802519079
wandb: 	temperature: 2.4643809489578397
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101137-euygwwrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/euygwwrc
wandb: uploading history steps 157-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–†â–„â–„â–…â–ˆâ–„â–†â–â–…â–ƒâ–‡â–„â–ˆâ–…â–„â–…â–‚â–†â–„â–„â–‚â–…â–…â–ƒâ–„â–„â–…â–ƒâ–…â–†â–ƒâ–†â–„â–…â–†â–„â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–â–â–ƒâ–‚â–„â–„â–ƒâ–…â–‡â–†â–â–ƒâ–â–…â–â–…â–„â–‚â–„â–„â–„â–‚â–†â–‡â–†â–…â–„â–ƒâ–…â–…â–ˆâ–‡â–ƒâ–…â–„â–†â–‡â–ƒâ–†
wandb:       eval/ensemble_f1 â–â–„â–ƒâ–„â–…â–ƒâ–ƒâ–…â–†â–†â–†â–ˆâ–„â–ˆâ–ˆâ–†â–…â–„â–â–â–„â–ƒâ–†â–‡â–„â–‚â–†â–ƒâ–‚â–„â–‚â–…â–…â–„â–†â–ƒâ–‚â–â–…â–‚
wandb:           train/avg_f1 â–ƒâ–„â–…â–ˆâ–…â–ƒâ–„â–‡â–…â–‡â–…â–…â–‚â–…â–†â–„â–‡â–†â–‡â–„â–…â–†â–„â–„â–†â–…â–ƒâ–‚â–…â–â–„â–†â–ƒâ–‚â–„â–‚â–ƒâ–…â–‚â–‚
wandb:      train/ensemble_f1 â–ƒâ–†â–ˆâ–ˆâ–‡â–ƒâ–…â–…â–‡â–ˆâ–„â–‡â–†â–‡â–„â–…â–…â–„â–‡â–â–†â–‡â–„â–†â–…â–…â–„â–ƒâ–ƒâ–„â–…â–‚â–„â–„â–‚â–…â–†â–ƒâ–…â–
wandb:         train/mil_loss â–ˆâ–‡â–†â–‡â–†â–†â–‡â–…â–‡â–…â–†â–…â–†â–…â–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:      train/policy_loss â–ˆâ–†â–â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.42183
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.77353
wandb:      eval/avg_mil_loss 0.49245
wandb:       eval/ensemble_f1 0.77353
wandb:           train/avg_f1 0.76809
wandb:      train/ensemble_f1 0.76809
wandb:         train/mil_loss 1.09692
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/euygwwrc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101137-euygwwrc/logs
wandb: ERROR Run euygwwrc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5olo2lek with config:
wandb: 	actor_learning_rate: 0.0004467566680258691
wandb: 	attention_dropout_p: 0.04788477881039099
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5895427245473757
wandb: 	temperature: 0.11097219615949117
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101524-5olo2lek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/nbpdybv8
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5olo2lek
wandb: uploading wandb-summary.json
wandb: uploading history steps 77-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–ˆâ–†â–†â–‚â–†â–‚â–‡â–ƒâ–…â–„â–„â–„â–„â–„â–…â–„â–…â–â–ˆâ–ƒâ–…â–„â–‚â–†â–…â–†â–†â–†â–ƒâ–†â–…â–ˆâ–†â–‡â–†â–…â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–†â–„â–‚â–ƒâ–†â–„â–„â–„â–ƒâ–â–ƒâ–…â–†â–„â–ƒâ–ƒâ–…â–ˆâ–‚â–…â–„â–ƒâ–‚â–ƒâ–†â–ƒâ–ƒâ–…â–…â–„â–…â–ƒâ–‚â–…â–‡â–â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–‡â–†â–ƒâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–„â–ƒâ–ƒâ–„â–…â–ƒâ–‡â–†â–‚â–‡â–„â–„â–‚â–‡â–„â–…â–…â–†â–…â–…â–‚â–†â–â–ˆâ–…â–†â–„â–†â–‡â–…
wandb:           train/avg_f1 â–ˆâ–†â–…â–‚â–…â–…â–ƒâ–…â–„â–„â–„â–ƒâ–„â–†â–‡â–†â–†â–†â–†â–†â–‡â–†â–‡â–…â–„â–…â–‚â–„â–‡â–…â–†â–…â–ƒâ–…â–…â–‡â–„â–…â–â–…
wandb:      train/ensemble_f1 â–ˆâ–…â–„â–â–…â–„â–‚â–†â–…â–…â–ƒâ–…â–†â–ƒâ–‚â–‚â–†â–…â–‡â–‚â–‚â–…â–…â–†â–…â–‡â–„â–„â–„â–…â–‡â–ƒâ–‡â–„â–…â–…â–…â–„â–ƒâ–†
wandb:         train/mil_loss â–†â–‚â–ˆâ–…â–†â–„â–‚â–…â–ƒâ–„â–…â–„â–ƒâ–…â–…â–ƒâ–…â–…â–…â–ƒâ–„â–ƒâ–‚â–…â–…â–„â–…â–…â–„â–„â–â–ƒâ–‚â–‚â–ƒâ–†â–â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83391
wandb: best/eval_avg_mil_loss 0.34803
wandb:  best/eval_ensemble_f1 0.83391
wandb:            eval/avg_f1 0.79376
wandb:      eval/avg_mil_loss 0.40401
wandb:       eval/ensemble_f1 0.79376
wandb:           train/avg_f1 0.80041
wandb:      train/ensemble_f1 0.80041
wandb:         train/mil_loss 1.53951
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vivid-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5olo2lek
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101524-5olo2lek/logs
wandb: ERROR Run 5olo2lek errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: huzjrnug with config:
wandb: 	actor_learning_rate: 1.349963844542925e-05
wandb: 	attention_dropout_p: 0.3634766506105645
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01488364391785224
wandb: 	temperature: 8.509511453247102
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101738-huzjrnug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huzjrnug
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–…â–„â–„â–…â–†â–…â–…â–„â–â–…â–„â–‚â–…â–ˆâ–â–„â–…â–ƒâ–†â–„â–†â–‚â–…â–‚â–â–„â–†â–‚â–„â–ƒâ–‚â–â–ƒâ–‚
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–„â–„â–„â–„â–‚â–„â–†â–†â–ƒâ–„â–ˆâ–„â–ƒâ–„â–‚â–„â–…â–â–ƒâ–â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–ˆâ–…â–„â–‡â–ƒâ–†â–†â–ƒ
wandb:       eval/ensemble_f1 â–‡â–…â–…â–…â–‚â–…â–„â–„â–†â–…â–†â–„â–„â–‚â–‡â–†â–†â–†â–…â–‡â–ƒâ–„â–â–ƒâ–ˆâ–ƒâ–†â–†â–„â–„â–…â–‚â–‡â–„â–…â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:           train/avg_f1 â–ƒâ–„â–„â–†â–„â–…â–‡â–„â–‚â–„â–ˆâ–„â–ƒâ–„â–…â–…â–ƒâ–‡â–…â–…â–‚â–…â–„â–…â–„â–‡â–ƒâ–…â–„â–†â–„â–„â–ƒâ–â–„â–„â–ƒâ–„â–„â–„
wandb:      train/ensemble_f1 â–â–†â–ˆâ–†â–…â–…â–ƒâ–†â–ƒâ–ƒâ–‚â–†â–„â–„â–„â–‚â–„â–…â–„â–„â–„â–ƒâ–„â–†â–…â–†â–ƒâ–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒ
wandb:         train/mil_loss â–…â–ƒâ–…â–ˆâ–†â–†â–ˆâ–…â–ˆâ–…â–„â–†â–…â–†â–‡â–‚â–…â–‡â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–‚â–„â–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86057
wandb: best/eval_avg_mil_loss 0.38146
wandb:  best/eval_ensemble_f1 0.86057
wandb:            eval/avg_f1 0.83179
wandb:      eval/avg_mil_loss 0.42824
wandb:       eval/ensemble_f1 0.83179
wandb:           train/avg_f1 0.80031
wandb:      train/ensemble_f1 0.80031
wandb:         train/mil_loss 1.58649
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smooth-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/huzjrnug
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101738-huzjrnug/logs
wandb: ERROR Run huzjrnug errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lcki6swj with config:
wandb: 	actor_learning_rate: 3.947637578493709e-05
wandb: 	attention_dropout_p: 0.06748629938014855
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22955358021760663
wandb: 	temperature: 7.0548724468625625
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102100-lcki6swj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcki6swj
wandb: uploading wandb-summary.json
wandb: uploading history steps 114-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–„â–ˆâ–†â–„â–…â–‡â–ƒâ–†â–…â–…â–‚â–„â–‡â–‡â–†â–ˆâ–‡â–†â–†â–‡â–„â–„â–„â–‡â–†â–‚â–†â–‡â–ƒâ–…â–‡â–â–„â–†â–…â–‡â–…
wandb:      eval/avg_mil_loss â–„â–†â–…â–ƒâ–ƒâ–…â–…â–„â–ƒâ–…â–…â–‚â–„â–‚â–…â–ƒâ–ƒâ–‚â–‡â–…â–ƒâ–„â–„â–…â–„â–…â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–†â–„â–ƒâ–…â–ˆâ–†â–â–‚
wandb:       eval/ensemble_f1 â–†â–…â–‡â–‡â–‡â–…â–…â–‡â–‚â–„â–†â–…â–…â–„â–ƒâ–‡â–ƒâ–ˆâ–ƒâ–‡â–ƒâ–…â–ƒâ–‡â–ƒâ–‡â–â–†â–†â–†â–…â–‡â–†â–†â–„â–„â–„â–†â–„â–‡
wandb:           train/avg_f1 â–„â–‚â–…â–„â–ƒâ–†â–…â–†â–†â–‡â–†â–â–ˆâ–…â–„â–„â–ƒâ–ƒâ–…â–‚â–„â–†â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–…â–‡â–‡â–†â–‚â–†â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚
wandb:      train/ensemble_f1 â–‚â–…â–ƒâ–†â–ƒâ–‡â–…â–†â–†â–‚â–…â–ƒâ–„â–ƒâ–†â–ˆâ–ƒâ–„â–ƒâ–„â–„â–†â–„â–†â–†â–„â–â–‡â–‚â–ƒâ–‡â–‡â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–…â–ƒ
wandb:         train/mil_loss â–…â–„â–…â–†â–ˆâ–†â–‡â–…â–ƒâ–‡â–†â–…â–‡â–„â–ƒâ–„â–…â–„â–…â–†â–„â–„â–„â–„â–„â–„â–…â–„â–†â–…â–ƒâ–â–…â–†â–„â–…â–†â–…â–‡â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.37222
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.78791
wandb:      eval/avg_mil_loss 0.45036
wandb:       eval/ensemble_f1 0.78791
wandb:           train/avg_f1 0.79566
wandb:      train/ensemble_f1 0.79566
wandb:         train/mil_loss 1.77815
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lcki6swj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102100-lcki6swj/logs
wandb: ERROR Run lcki6swj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mccrajcu with config:
wandb: 	actor_learning_rate: 0.00012052782135105548
wandb: 	attention_dropout_p: 0.06644071076395414
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3687853088374431
wandb: 	temperature: 0.3493971044521005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102326-mccrajcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mccrajcu
wandb: uploading wandb-summary.json
wandb: uploading history steps 58-70, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–ƒâ–…â–„â–†â–†â–ƒâ–…â–„â–ƒâ–…â–„â–ƒâ–â–„â–†â–ƒâ–…â–ˆâ–†â–‚â–ƒâ–ƒâ–ƒâ–‡â–…â–â–„â–ƒâ–…â–…â–‚â–„â–†â–…â–ƒâ–ƒâ–„â–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–†â–ƒâ–†â–…â–†â–‚â–…â–†â–„â–‡â–„â–…â–ˆâ–„â–‚â–ƒâ–„â–â–…â–ƒâ–ƒâ–â–ˆâ–‚â–†â–ˆâ–„â–„â–ƒâ–…â–„â–…â–„â–…â–…â–…â–†â–…
wandb:       eval/ensemble_f1 â–„â–ˆâ–†â–„â–†â–ƒâ–‡â–‡â–â–†â–‡â–…â–†â–…â–‡â–…â–„â–†â–‡â–…â–…â–…â–…â–ˆâ–…â–†â–†â–‚â–…â–†â–…â–‡â–†â–…â–ˆâ–„â–„â–†â–ƒâ–†
wandb:           train/avg_f1 â–†â–„â–‡â–ƒâ–†â–†â–„â–†â–ƒâ–ƒâ–‡â–„â–„â–‡â–…â–â–…â–ƒâ–‡â–…â–†â–ˆâ–‡â–„â–…â–…â–ƒâ–‡â–„â–„â–„â–‚â–„â–…â–…â–†â–„â–„â–‡â–‚
wandb:      train/ensemble_f1 â–‡â–„â–„â–†â–…â–„â–ˆâ–„â–…â–„â–†â–‡â–†â–‡â–â–ƒâ–‡â–†â–…â–…â–ˆâ–„â–…â–„â–†â–ˆâ–…â–…â–‚â–„â–„â–…â–‡â–†â–†â–…â–„â–…â–ˆâ–‚
wandb:         train/mil_loss â–„â–†â–†â–„â–„â–…â–„â–„â–…â–‚â–†â–â–„â–‚â–ƒâ–…â–…â–…â–†â–„â–…â–ƒâ–ˆâ–ƒâ–„â–„â–…â–…â–…â–â–„â–„â–…â–…â–ƒâ–†â–ƒâ–„â–„â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83197
wandb: best/eval_avg_mil_loss 0.3533
wandb:  best/eval_ensemble_f1 0.83197
wandb:            eval/avg_f1 0.79163
wandb:      eval/avg_mil_loss 0.49629
wandb:       eval/ensemble_f1 0.79163
wandb:           train/avg_f1 0.79954
wandb:      train/ensemble_f1 0.79954
wandb:         train/mil_loss 0.8582
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mccrajcu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102326-mccrajcu/logs
wandb: ERROR Run mccrajcu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8pkx4xli with config:
wandb: 	actor_learning_rate: 1.1456795667406212e-05
wandb: 	attention_dropout_p: 0.4371341377090811
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 57
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24912086986569237
wandb: 	temperature: 0.23047350685326817
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102448-8pkx4xli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pkx4xli
wandb: uploading history steps 45-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–„â–„â–†â–â–„â–‡â–„â–†â–†â–…â–ˆâ–…â–…â–„â–„â–ˆâ–„â–†â–†â–…â–†â–…â–…â–‡â–†â–„â–†â–‡â–†â–‡â–„â–…â–…â–„â–…â–…â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–‡â–†â–†â–ˆâ–„â–ƒâ–ˆâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–„â–ˆâ–†â–„â–„â–„â–â–…â–‡â–†â–ƒâ–ˆâ–†â–‡â–‚â–„â–„â–ƒâ–ƒâ–…â–†â–ˆâ–†â–…â–…â–‚
wandb:       eval/ensemble_f1 â–†â–„â–„â–„â–„â–†â–„â–â–„â–‡â–„â–†â–†â–…â–ˆâ–„â–„â–„â–ˆâ–„â–…â–†â–…â–†â–†â–„â–‡â–†â–„â–‡â–‡â–„â–…â–…â–†â–„â–…â–…â–†â–ƒ
wandb:           train/avg_f1 â–ƒâ–„â–„â–„â–â–„â–‚â–‡â–â–„â–…â–„â–†â–„â–ˆâ–ƒâ–‚â–„â–‡â–ƒâ–ƒâ–â–‡â–„â–‚â–„â–…â–…â–‚â–ƒâ–…â–„â–‚â–ˆâ–ƒâ–„â–†â–ƒâ–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–…â–†â–ƒâ–„â–„â–â–ƒâ–„â–‡â–„â–…â–„â–‚â–†â–ˆâ–ƒâ–‚â–„â–‡â–â–‡â–„â–‚â–ƒâ–…â–…â–‚â–â–ƒâ–…â–„â–‚â–ˆâ–‡â–„â–†â–ƒâ–…â–ƒ
wandb:         train/mil_loss â–…â–…â–â–„â–„â–†â–‚â–ƒâ–„â–‚â–…â–…â–ƒâ–ˆâ–‚â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–â–„â–‚â–…â–‡â–ƒâ–„â–†â–‚â–„â–ƒâ–†â–ƒâ–‚â–„â–…â–…â–ƒ
wandb:      train/policy_loss â–â–…â–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–…â–â–…â–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–ˆâ–â–…â–â–…â–…â–…â–â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–â–…â–â–…â–â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–ˆâ–…â–ˆâ–â–…â–â–…â–…â–ˆâ–â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.44633
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.76224
wandb:      eval/avg_mil_loss 0.49549
wandb:       eval/ensemble_f1 0.76224
wandb:           train/avg_f1 0.79053
wandb:      train/ensemble_f1 0.79053
wandb:         train/mil_loss 0.97487
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run light-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8pkx4xli
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102448-8pkx4xli/logs
wandb: ERROR Run 8pkx4xli errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: v32zsuc9 with config:
wandb: 	actor_learning_rate: 2.4402297497248344e-05
wandb: 	attention_dropout_p: 0.05094599443397618
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4254878875029443
wandb: 	temperature: 7.418178186503739
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102551-v32zsuc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v32zsuc9
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–â–„â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–‚â–„â–ƒâ–„â–ƒâ–„â–â–…â–‚â–…â–†â–…â–…â–…â–…â–…â–…â–„â–…â–ƒâ–„â–‡â–‚â–‡â–‚â–„â–‡â–„â–â–†â–…â–…â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ˆâ–„â–ƒâ–„â–ˆâ–ƒâ–…â–ƒâ–‚â–„â–…â–ƒâ–…â–„â–ƒâ–‚â–…â–ƒâ–„â–†â–ƒâ–‚â–†â–â–…â–„â–…â–„â–„â–…â–…â–‚â–„â–…â–ƒâ–„â–„â–†
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–…â–„â–ƒâ–…â–…â–…â–…â–†â–…â–„â–ƒâ–„â–„â–…â–…â–…â–…â–†â–„â–„â–†â–„â–ƒâ–…â–„â–‚â–‡â–â–…â–‡â–‚â–ƒâ–‡â–…â–ˆâ–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ƒâ–†â–ˆâ–„â–ƒâ–„â–â–„â–†â–…â–…â–ƒâ–â–†â–…â–‚â–…â–â–…â–„â–†â–„â–‡â–…â–â–‚â–â–ˆâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–†â–ˆâ–‚â–ƒâ–„â–ƒâ–†â–„â–…â–„â–â–‚â–„â–‚â–‚â–†â–„â–…â–…â–‚â–ƒâ–â–…â–„â–ƒâ–ƒâ–â–„â–„â–ƒâ–„â–„â–‡â–ƒâ–…â–ƒâ–â–„
wandb:         train/mil_loss â–ˆâ–…â–…â–…â–†â–…â–†â–…â–…â–†â–‡â–…â–†â–…â–†â–…â–…â–„â–„â–†â–…â–„â–‚â–…â–„â–ƒâ–…â–ƒâ–…â–‚â–…â–ƒâ–ƒâ–…â–„â–â–„â–ƒâ–„â–„
wandb:      train/policy_loss â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–…â–ˆâ–ˆâ–â–â–â–ˆâ–â–…â–â–ˆâ–…â–â–ˆâ–…â–…â–â–â–…â–…â–…â–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–…â–…â–ˆâ–…â–…â–â–â–…â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85307
wandb: best/eval_avg_mil_loss 0.40675
wandb:  best/eval_ensemble_f1 0.85307
wandb:            eval/avg_f1 0.82836
wandb:      eval/avg_mil_loss 0.39805
wandb:       eval/ensemble_f1 0.82836
wandb:            test/avg_f1 0.80336
wandb:      test/avg_mil_loss 0.45047
wandb:       test/ensemble_f1 0.80336
wandb:           train/avg_f1 0.80228
wandb:      train/ensemble_f1 0.80228
wandb:         train/mil_loss 1.75821
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run serene-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v32zsuc9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102551-v32zsuc9/logs
wandb: Agent Starting Run: h5ngy92n with config:
wandb: 	actor_learning_rate: 3.822248796532522e-06
wandb: 	attention_dropout_p: 0.24670745124945348
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.264193522867457
wandb: 	temperature: 2.971641712956341
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102820-h5ngy92n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ngy92n
wandb: uploading history steps 48-56, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–„â–‡â–‡â–
wandb:  best/eval_ensemble_f1 â–â–â–„â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–ƒâ–…â–†â–…â–ƒâ–†â–†â–â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–„â–…â–†â–…â–†â–„â–ƒâ–†â–„â–…â–â–‚â–„â–ƒâ–…â–‡â–ƒâ–„â–„â–…â–‡â–…â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–…â–†â–‡â–…â–‚â–†â–†â–„â–„â–ˆâ–…â–ƒâ–…â–ˆâ–ˆâ–…â–…â–„â–…â–„â–ƒâ–†â–†â–„â–„â–…â–ˆâ–„â–‡â–†â–ƒâ–„â–…â–ˆâ–…â–…â–„â–…â–
wandb:       eval/ensemble_f1 â–…â–„â–ƒâ–‚â–…â–†â–„â–†â–†â–„â–‚â–‚â–‡â–…â–‚â–ƒâ–„â–„â–…â–„â–…â–†â–„â–‚â–†â–†â–„â–†â–â–„â–ƒâ–‚â–…â–‡â–„â–ƒâ–„â–…â–ˆâ–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–‡â–…â–‚â–„â–ƒâ–‡â–…â–ƒâ–†â–†â–„â–…â–†â–â–†â–„â–ƒâ–†â–…â–„â–ƒâ–„â–…â–„â–ƒâ–„â–…â–ƒâ–„â–‚â–ˆâ–ˆâ–†â–„â–„â–„â–„â–ƒ
wandb:      train/ensemble_f1 â–„â–„â–„â–‡â–…â–â–„â–ƒâ–‡â–…â–…â–†â–…â–…â–†â–„â–†â–„â–…â–„â–†â–„â–„â–ƒâ–ƒâ–…â–â–ˆâ–ƒâ–ƒâ–„â–ƒâ–â–ˆâ–ˆâ–„â–„â–ƒâ–„â–‚
wandb:         train/mil_loss â–ˆâ–…â–†â–†â–†â–…â–‡â–…â–…â–ƒâ–„â–ƒâ–†â–„â–„â–„â–ƒâ–„â–ƒâ–„â–„â–…â–„â–ƒâ–â–†â–„â–ƒâ–…â–„â–„â–„â–…â–ƒâ–…â–„â–‚â–ƒâ–ƒâ–…
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–ƒâ–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–ˆâ–…â–‡â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–‡â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86057
wandb: best/eval_avg_mil_loss 0.37841
wandb:  best/eval_ensemble_f1 0.86057
wandb:            eval/avg_f1 0.86057
wandb:      eval/avg_mil_loss 0.37841
wandb:       eval/ensemble_f1 0.86057
wandb:            test/avg_f1 0.77059
wandb:      test/avg_mil_loss 0.54935
wandb:       test/ensemble_f1 0.77059
wandb:           train/avg_f1 0.79427
wandb:      train/ensemble_f1 0.79427
wandb:         train/mil_loss 2.04495
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sleek-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h5ngy92n
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102820-h5ngy92n/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w82apwt0 with config:
wandb: 	actor_learning_rate: 7.817203545775061e-06
wandb: 	attention_dropout_p: 0.2207026181968209
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 199
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19500002341930325
wandb: 	temperature: 4.319185244705517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102943-w82apwt0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w82apwt0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–„â–…â–ƒâ–â–ƒâ–„â–„â–…â–„â–‚â–ƒâ–ƒâ–‚â–ˆâ–…â–ƒâ–„â–„â–ƒâ–…â–‚â–â–ƒâ–â–‚â–„â–ƒâ–‚â–†â–„â–„â–ƒâ–„â–ƒâ–†â–‚â–‡â–ƒâ–‚â–…
wandb:      eval/avg_mil_loss â–‚â–…â–â–‚â–„â–ˆâ–‚â–†â–ƒâ–„â–ƒâ–…â–‚â–…â–„â–„â–„â–‡â–…â–†â–…â–ƒâ–„â–„â–‚â–…â–†â–†â–‚â–â–…â–ƒâ–ƒâ–„â–„â–„â–„â–…â–ƒâ–„
wandb:       eval/ensemble_f1 â–†â–ƒâ–†â–…â–„â–†â–†â–‚â–„â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–„â–„â–‡â–†â–„â–ƒâ–‚â–†â–ƒâ–…â–…â–…â–†â–„â–†â–‡â–…â–†â–‡â–â–…â–ˆâ–„â–…
wandb:           train/avg_f1 â–„â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–†â–ƒâ–†â–ƒâ–…â–ˆâ–ƒâ–‚â–…â–‚â–â–ˆâ–…â–‚â–ƒâ–„â–â–…â–‡â–†â–…â–„â–„â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–â–ƒâ–
wandb:      train/ensemble_f1 â–„â–…â–‚â–ƒâ–â–„â–„â–…â–ˆâ–‡â–„â–‚â–‚â–‚â–ƒâ–†â–†â–…â–‚â–ƒâ–†â–ƒâ–‚â–ƒâ–„â–…â–†â–„â–„â–„â–…â–…â–ƒâ–‡â–â–ƒâ–„â–ƒâ–â–
wandb:         train/mil_loss â–ƒâ–…â–…â–†â–„â–‡â–„â–…â–…â–‡â–„â–„â–…â–†â–†â–„â–…â–ƒâ–†â–ƒâ–‚â–ƒâ–…â–…â–„â–„â–„â–„â–ˆâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–…â–„â–„â–â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86071
wandb: best/eval_avg_mil_loss 0.35013
wandb:  best/eval_ensemble_f1 0.86071
wandb:            eval/avg_f1 0.77701
wandb:      eval/avg_mil_loss 0.4804
wandb:       eval/ensemble_f1 0.77701
wandb:           train/avg_f1 0.78624
wandb:      train/ensemble_f1 0.78624
wandb:         train/mil_loss 1.00479
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w82apwt0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102943-w82apwt0/logs
wandb: ERROR Run w82apwt0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a5p5pcih with config:
wandb: 	actor_learning_rate: 0.0005123618864191318
wandb: 	attention_dropout_p: 0.26436086744619347
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 71
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.056963693636991386
wandb: 	temperature: 1.010696206111923
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103259-a5p5pcih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5p5pcih
wandb: uploading history steps 68-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–â–ƒâ–†â–ƒâ–‚â–ˆâ–„â–„â–…â–â–ƒâ–ˆâ–†â–…â–ƒâ–…â–†â–†â–‡â–†â–„â–„â–‚â–‡â–…â–‚â–„â–…â–„â–„â–„â–†â–ˆâ–„â–ƒâ–‚â–‡â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–„â–ˆâ–†â–„â–‡â–ƒâ–‡â–…â–†â–„â–…â–†â–ƒâ–‡â–â–…â–„â–‚â–…â–…â–ƒâ–„â–†â–…â–…â–ƒâ–„â–…â–†â–„â–ˆâ–†â–…â–†â–ƒâ–†â–„â–†â–„
wandb:       eval/ensemble_f1 â–ˆâ–‚â–â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–…â–ƒâ–ˆâ–†â–†â–„â–†â–‡â–ˆâ–ƒâ–…â–†â–„â–„â–ƒâ–ƒâ–…â–„â–†â–…â–…â–…â–‡â–ˆâ–…â–…â–ƒâ–†â–…â–…â–…
wandb:           train/avg_f1 â–â–†â–‡â–‡â–†â–‡â–‡â–‡â–„â–…â–‚â–ƒâ–„â–„â–…â–‚â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–…â–â–…â–ˆâ–‡â–â–†â–„â–„â–†â–„â–‡â–†â–†â–ƒ
wandb:      train/ensemble_f1 â–‚â–†â–ˆâ–‡â–†â–ˆâ–„â–†â–„â–‚â–…â–†â–†â–ƒâ–„â–ƒâ–†â–†â–„â–…â–‡â–„â–…â–‡â–„â–‚â–â–„â–ˆâ–…â–…â–‡â–‚â–†â–„â–‡â–…â–‡â–…â–‡
wandb:         train/mil_loss â–‡â–„â–‡â–ƒâ–…â–…â–„â–„â–„â–†â–…â–…â–‡â–â–„â–†â–ˆâ–…â–„â–…â–…â–â–…â–…â–…â–†â–â–†â–…â–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–ƒâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–â–„â–â–„â–„â–â–â–â–„â–â–â–ˆâ–â–„â–â–â–„â–„â–ˆâ–„â–ˆâ–„â–â–„â–„â–â–ˆâ–â–ˆâ–â–ˆâ–„â–ˆâ–â–„â–ˆâ–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83168
wandb: best/eval_avg_mil_loss 0.42442
wandb:  best/eval_ensemble_f1 0.83168
wandb:            eval/avg_f1 0.79175
wandb:      eval/avg_mil_loss 0.43812
wandb:       eval/ensemble_f1 0.79175
wandb:           train/avg_f1 0.79581
wandb:      train/ensemble_f1 0.79581
wandb:         train/mil_loss 2.0893
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5p5pcih
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103259-a5p5pcih/logs
wandb: ERROR Run a5p5pcih errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n8wrkqkf with config:
wandb: 	actor_learning_rate: 1.7265723933403287e-05
wandb: 	attention_dropout_p: 0.28352705860763194
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7073323371438555
wandb: 	temperature: 1.1467452797170474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103445-n8wrkqkf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8wrkqkf
wandb: uploading history steps 120-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–ƒâ–ƒâ–„â–‚â–„â–‡â–†â–…â–„â–†â–…â–„â–ƒâ–‚â–„â–…â–ƒâ–…â–‚â–„â–„â–‚â–„â–ƒâ–†â–†â–ƒâ–â–„â–‡â–ƒâ–†â–…â–„â–„â–„â–„â–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–ƒâ–…â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–…â–ƒâ–ƒâ–…â–‡â–â–†â–„â–„â–ƒâ–ƒâ–„â–ƒâ–…â–‚â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–†â–…â–„â–…â–…â–…â–ƒâ–…â–…â–ˆâ–…â–„â–„â–ƒâ–ƒâ–†â–…â–„â–„â–„â–…â–‚â–„â–‚â–‡â–…â–…â–ƒâ–†â–„â–â–„â–…â–ƒâ–†â–„â–…â–†
wandb:           train/avg_f1 â–ˆâ–‚â–†â–†â–ƒâ–‚â–…â–…â–‡â–„â–†â–†â–‡â–â–„â–ƒâ–„â–…â–…â–†â–ƒâ–â–ƒâ–†â–†â–„â–„â–…â–†â–‚â–…â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–†
wandb:      train/ensemble_f1 â–…â–„â–ƒâ–‡â–„â–„â–…â–†â–ˆâ–†â–†â–‚â–‡â–„â–†â–„â–…â–â–ˆâ–…â–„â–ƒâ–â–…â–†â–ƒâ–„â–†â–ƒâ–„â–…â–ƒâ–„â–„â–†â–â–ƒâ–„â–†â–…
wandb:         train/mil_loss â–ˆâ–†â–†â–‡â–‡â–…â–ˆâ–…â–„â–…â–‡â–‡â–‡â–†â–„â–„â–ƒâ–„â–ƒâ–…â–…â–†â–ƒâ–…â–…â–ƒâ–ƒâ–…â–†â–„â–ƒâ–‚â–â–‚â–„â–„â–ˆâ–…â–ƒâ–†
wandb:      train/policy_loss â–â–â–ˆâ–ˆâ–…â–â–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–ˆâ–…â–…â–…â–…â–ˆâ–â–…â–â–…â–â–ˆâ–â–…â–ˆâ–â–…â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–„â–â–ˆâ–ˆâ–â–„â–„â–â–ˆâ–„â–â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–â–â–„â–„â–ˆâ–„â–„â–â–â–â–â–„â–â–„â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84259
wandb: best/eval_avg_mil_loss 0.41074
wandb:  best/eval_ensemble_f1 0.84259
wandb:            eval/avg_f1 0.79895
wandb:      eval/avg_mil_loss 0.45519
wandb:       eval/ensemble_f1 0.79895
wandb:           train/avg_f1 0.79289
wandb:      train/ensemble_f1 0.79289
wandb:         train/mil_loss 0.84114
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n8wrkqkf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103445-n8wrkqkf/logs
wandb: ERROR Run n8wrkqkf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cdk5q55y with config:
wandb: 	actor_learning_rate: 0.00036814738797550376
wandb: 	attention_dropout_p: 0.3333833766979361
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.419451899150603
wandb: 	temperature: 7.699161136464024
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103741-cdk5q55y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdk5q55y
wandb: uploading history steps 41-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ˆâ–†â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–†â–ˆâ–‚â–ƒâ–„â–†â–…â–…â–‡â–ƒâ–†â–‡â–†â–…â–…â–„â–„â–…â–ˆâ–„â–‡â–‡â–„â–…â–ƒâ–…â–…â–†â–†â–„â–‡â–‡â–‡â–„â–â–‚â–ƒâ–‡â–†
wandb:      eval/avg_mil_loss â–†â–ƒâ–†â–„â–…â–„â–…â–‚â–ƒâ–ƒâ–…â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–…â–†â–‚â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–…â–„â–ƒâ–„â–„â–ˆâ–â–…â–†â–…â–†â–†â–„â–‚
wandb:       eval/ensemble_f1 â–„â–†â–ˆâ–‚â–ƒâ–„â–†â–„â–…â–‡â–ƒâ–‡â–†â–…â–ƒâ–„â–„â–ˆâ–†â–„â–‡â–‡â–„â–…â–â–…â–…â–†â–†â–‚â–‡â–‡â–‡â–„â–…â–â–‚â–ƒâ–‡â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–„â–„â–…â–…â–ƒâ–‚â–„â–†â–†â–…â–…â–„â–…â–…â–ƒâ–†â–ƒâ–„â–†â–…â–„â–…â–â–…â–…â–„â–ˆâ–„â–…â–„â–†â–„â–„â–‡â–…â–ƒâ–‡â–…
wandb:      train/ensemble_f1 â–…â–†â–„â–„â–…â–…â–ƒâ–‚â–„â–†â–†â–„â–…â–‡â–…â–†â–ƒâ–„â–†â–†â–„â–…â–â–„â–ƒâ–…â–„â–ˆâ–„â–ƒâ–„â–†â–„â–„â–†â–…â–…â–ƒâ–‡â–…
wandb:         train/mil_loss â–„â–†â–‡â–…â–â–…â–†â–ˆâ–†â–ˆâ–ƒâ–„â–‚â–ƒâ–„â–†â–†â–‚â–„â–„â–„â–…â–ƒâ–‡â–†â–…â–„â–†â–†â–„â–‡â–ƒâ–ƒâ–†â–„â–†â–ƒâ–â–ƒâ–‡
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.43381
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.8065
wandb:      eval/avg_mil_loss 0.37256
wandb:       eval/ensemble_f1 0.8065
wandb:            test/avg_f1 0.83237
wandb:      test/avg_mil_loss 0.41402
wandb:       test/ensemble_f1 0.83237
wandb:           train/avg_f1 0.80471
wandb:      train/ensemble_f1 0.80471
wandb:         train/mil_loss 2.08537
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdk5q55y
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103741-cdk5q55y/logs
wandb: Agent Starting Run: vlr5zqft with config:
wandb: 	actor_learning_rate: 0.000559304652127372
wandb: 	attention_dropout_p: 0.3253236694268936
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 62
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08761128637210669
wandb: 	temperature: 7.753714271127684
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103843-vlr5zqft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vlr5zqft
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 50-62, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–†â–„â–â–„
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–„â–†â–†â–…â–„â–…â–…â–„â–„â–„â–‡â–„â–…â–…â–ƒâ–ˆâ–â–‚â–‚â–ƒâ–…â–…â–†â–…â–ƒâ–…â–†â–†â–…â–‚â–‚â–…â–„â–‚â–„â–‡â–‚â–„â–†
wandb:      eval/avg_mil_loss â–…â–†â–‡â–‡â–ƒâ–…â–…â–†â–…â–„â–‚â–„â–ƒâ–â–„â–…â–†â–„â–…â–…â–ƒâ–„â–‚â–ƒâ–†â–‚â–‚â–‚â–…â–†â–…â–…â–ƒâ–‡â–†â–†â–„â–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–„â–„â–‚â–†â–…â–‚â–…â–…â–…â–„â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–…â–ƒâ–ˆâ–â–â–â–‚â–ƒâ–…â–…â–…â–‚â–…â–ƒâ–†â–„â–â–â–…â–ƒâ–ƒâ–„â–‡â–â–†
wandb:           train/avg_f1 â–‡â–…â–…â–…â–†â–†â–†â–†â–…â–…â–…â–ƒâ–…â–ƒâ–†â–…â–…â–ˆâ–†â–…â–†â–„â–…â–„â–†â–ƒâ–†â–â–†â–‡â–…â–…â–‚â–†â–†â–…â–ƒâ–†â–‡â–†
wandb:      train/ensemble_f1 â–‡â–…â–…â–…â–†â–†â–†â–†â–„â–…â–‚â–…â–…â–ƒâ–…â–†â–…â–ƒâ–…â–ˆâ–†â–„â–…â–†â–‡â–„â–ƒâ–†â–…â–â–‡â–†â–…â–„â–‚â–…â–…â–ƒâ–‡â–†
wandb:         train/mil_loss â–ƒâ–„â–…â–„â–„â–ƒâ–…â–ƒâ–…â–†â–…â–†â–ˆâ–†â–ƒâ–…â–‚â–…â–â–ƒâ–…â–‚â–…â–‚â–„â–â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–…â–†â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.41422
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.82076
wandb:      eval/avg_mil_loss 0.38825
wandb:       eval/ensemble_f1 0.82076
wandb:           train/avg_f1 0.79499
wandb:      train/ensemble_f1 0.79499
wandb:         train/mil_loss 0.83011
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vlr5zqft
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103843-vlr5zqft/logs
wandb: ERROR Run vlr5zqft errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wblau8zm with config:
wandb: 	actor_learning_rate: 3.239627722374084e-05
wandb: 	attention_dropout_p: 0.23240096340792205
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6959706464814311
wandb: 	temperature: 0.643466993076135
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104006-wblau8zm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wblau8zm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–„â–ˆâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–…â–‡â–„â–…â–ƒâ–„â–†â–‡â–…â–„â–…â–„â–‡â–„â–‡â–…â–ƒâ–…â–ƒâ–†â–…â–ƒâ–†â–ˆâ–„â–†â–…â–†â–„â–…â–„â–‚â–…â–ƒâ–ƒâ–…â–†â–
wandb:      eval/avg_mil_loss â–…â–†â–ƒâ–‡â–‚â–‚â–„â–â–…â–…â–ƒâ–ƒâ–‡â–ƒâ–„â–…â–ƒâ–†â–†â–†â–â–ƒâ–ƒâ–„â–†â–‡â–‡â–ƒâ–†â–„â–â–‚â–†â–†â–…â–ƒâ–†â–ˆâ–…â–†
wandb:       eval/ensemble_f1 â–…â–ƒâ–‡â–ƒâ–‡â–„â–†â–„â–„â–†â–ˆâ–„â–…â–…â–ˆâ–â–‡â–…â–…â–‚â–ƒâ–ƒâ–†â–„â–„â–„â–„â–…â–…â–ƒâ–…â–„â–‚â–„â–†â–ƒâ–…â–ƒâ–„â–ˆ
wandb:           train/avg_f1 â–…â–†â–â–…â–ˆâ–ƒâ–†â–„â–…â–ƒâ–ƒâ–…â–„â–…â–„â–„â–…â–„â–ˆâ–…â–…â–„â–…â–…â–ƒâ–†â–…â–â–‡â–‚â–ƒâ–„â–ˆâ–ƒâ–‚â–‡â–ƒâ–„â–„â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–‡â–†â–…â–ƒâ–ƒâ–†â–ƒâ–‚â–„â–†â–…â–„â–ƒâ–„â–ˆâ–‡â–„â–ƒâ–„â–…â–‚â–„â–„â–ƒâ–ƒâ–â–†â–„â–…â–†â–ƒâ–†â–…â–ƒâ–…â–…â–…â–‚â–‚
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–…â–†â–ƒâ–ˆâ–…â–†â–„â–…â–†â–„â–‡â–†â–ƒâ–†â–…â–‚â–„â–…â–…â–…â–ƒâ–â–„â–ƒâ–â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–„â–‚â–ƒâ–
wandb:      train/policy_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.39662
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.76252
wandb:      eval/avg_mil_loss 0.53469
wandb:       eval/ensemble_f1 0.76252
wandb:           train/avg_f1 0.79535
wandb:      train/ensemble_f1 0.79535
wandb:         train/mil_loss 1.83283
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devout-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wblau8zm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104006-wblau8zm/logs
wandb: ERROR Run wblau8zm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: r3pfom14 with config:
wandb: 	actor_learning_rate: 9.182080004155924e-05
wandb: 	attention_dropout_p: 0.06866548777808201
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14676004397759412
wandb: 	temperature: 1.445358523263025
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104231-r3pfom14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3pfom14
wandb: uploading history steps 83-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–†â–‚â–„â–…â–†â–‡â–ƒâ–†â–„â–ƒâ–†â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ˆâ–…â–‚â–‚â–‚â–‚â–â–â–…â–…â–ƒâ–‚â–‚â–ƒâ–„â–„â–…â–„â–…â–ƒ
wandb:      eval/avg_mil_loss â–†â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–‡â–ˆâ–†â–†â–†â–…â–„â–„â–„â–‡â–„â–â–„â–…â–†â–…â–ƒâ–ƒâ–ˆâ–†â–‚â–†â–‡â–‚â–„â–„â–ƒâ–„â–…â–„
wandb:       eval/ensemble_f1 â–„â–‚â–…â–†â–†â–‡â–…â–…â–†â–„â–ƒâ–†â–…â–‚â–â–ƒâ–„â–ƒâ–„â–„â–„â–ˆâ–†â–„â–ƒâ–„â–„â–…â–ƒâ–‚â–…â–…â–…â–ƒâ–…â–„â–„â–†â–…â–†
wandb:           train/avg_f1 â–ƒâ–ƒâ–ˆâ–‡â–‡â–„â–…â–ƒâ–‡â–ˆâ–„â–…â–ƒâ–‡â–†â–„â–ƒâ–„â–ƒâ–…â–†â–ƒâ–…â–…â–…â–…â–ƒâ–â–†â–ƒâ–ƒâ–…â–…â–†â–‚â–…â–ˆâ–‡â–…â–…
wandb:      train/ensemble_f1 â–ƒâ–‚â–ˆâ–„â–„â–†â–„â–„â–…â–ˆâ–„â–ƒâ–„â–ƒâ–†â–„â–ƒâ–„â–…â–ƒâ–…â–‡â–…â–…â–ˆâ–ƒâ–â–†â–…â–†â–†â–ƒâ–ƒâ–…â–„â–…â–…â–‡â–‡â–…
wandb:         train/mil_loss â–ˆâ–‡â–…â–…â–†â–†â–…â–†â–‡â–‡â–‡â–ˆâ–†â–…â–„â–‡â–…â–…â–„â–†â–â–ƒâ–‚â–†â–…â–…â–†â–„â–â–ƒâ–†â–…â–‡â–ƒâ–‚â–…â–ƒâ–„â–‚â–„
wandb:      train/policy_loss â–„â–ˆâ–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–ˆâ–„â–â–„â–„â–â–„â–„â–„â–ˆâ–â–ˆâ–„â–„â–„â–ˆâ–â–„â–„â–ˆâ–â–„â–„â–„â–â–„â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85398
wandb: best/eval_avg_mil_loss 0.37453
wandb:  best/eval_ensemble_f1 0.85398
wandb:            eval/avg_f1 0.81331
wandb:      eval/avg_mil_loss 0.40727
wandb:       eval/ensemble_f1 0.81331
wandb:           train/avg_f1 0.79542
wandb:      train/ensemble_f1 0.79542
wandb:         train/mil_loss 0.97666
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run absurd-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r3pfom14
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104231-r3pfom14/logs
wandb: ERROR Run r3pfom14 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 01bflznv with config:
wandb: 	actor_learning_rate: 0.0009841570730710764
wandb: 	attention_dropout_p: 0.48035199636856674
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38796538583557705
wandb: 	temperature: 8.112274480980991
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104410-01bflznv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/01bflznv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–ƒâ–‚â–â–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–„â–†â–…â–ˆâ–ƒâ–†â–ƒâ–ƒâ–…â–‡â–ƒâ–„â–„â–…â–â–‡â–†â–ƒâ–†â–‚â–ˆâ–†â–‡â–†â–†â–„â–„â–â–„â–„â–…â–„â–„â–†â–…â–ƒâ–…â–ƒâ–‚
wandb:      eval/avg_mil_loss â–…â–„â–…â–ˆâ–…â–…â–„â–‚â–…â–„â–„â–„â–„â–„â–„â–„â–…â–ƒâ–†â–„â–„â–ƒâ–„â–…â–â–…â–…â–†â–„â–†â–„â–†â–…â–…â–ƒâ–„â–…â–‡â–…â–‚
wandb:       eval/ensemble_f1 â–ƒâ–„â–‚â–ƒâ–†â–…â–ˆâ–„â–ƒâ–†â–ƒâ–„â–â–†â–ƒâ–‚â–ƒâ–‡â–…â–ƒâ–‚â–‚â–…â–†â–ƒâ–„â–„â–ƒâ–…â–„â–„â–…â–…â–„â–ƒâ–‚â–…â–„â–ƒâ–‚
wandb:           train/avg_f1 â–‡â–†â–‡â–‚â–…â–„â–…â–â–ˆâ–ƒâ–‡â–†â–ƒâ–„â–†â–†â–‡â–„â–…â–†â–‚â–„â–„â–…â–ˆâ–…â–†â–‡â–‚â–„â–†â–ƒâ–…â–„â–‡â–…â–„â–†â–†â–†
wandb:      train/ensemble_f1 â–…â–â–†â–„â–ƒâ–†â–‚â–…â–…â–‚â–‚â–…â–ƒâ–…â–ˆâ–…â–â–†â–‚â–ƒâ–„â–…â–…â–‚â–‚â–…â–â–…â–‚â–â–‚â–„â–„â–‚â–…â–„â–ƒâ–…â–…â–†
wandb:         train/mil_loss â–…â–‡â–†â–…â–…â–„â–ˆâ–„â–ˆâ–â–…â–„â–†â–†â–ˆâ–‡â–†â–„â–„â–‡â–†â–ˆâ–…â–…â–…â–‡â–†â–‡â–„â–…â–…â–†â–…â–ˆâ–†â–„â–†â–„â–†â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85003
wandb: best/eval_avg_mil_loss 0.47199
wandb:  best/eval_ensemble_f1 0.85003
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.49836
wandb:       eval/ensemble_f1 0.76597
wandb:           train/avg_f1 0.80837
wandb:      train/ensemble_f1 0.80837
wandb:         train/mil_loss 0.83305
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run breezy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/01bflznv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104410-01bflznv/logs
wandb: ERROR Run 01bflznv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ix4yif4m with config:
wandb: 	actor_learning_rate: 4.2450905928423065e-06
wandb: 	attention_dropout_p: 0.28898980505506544
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42097114887107634
wandb: 	temperature: 8.50465687704636
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104538-ix4yif4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ix4yif4m
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ˆâ–â–‡â–ƒ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–‡â–„â–‡â–ƒâ–†â–…â–„â–…â–…â–‚â–„â–ƒâ–…â–„â–„â–…â–‚â–ƒâ–‡â–‡â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–†â–â–†â–ˆâ–…â–…â–„â–â–„â–„â–†â–ƒ
wandb:      eval/avg_mil_loss â–„â–‚â–…â–â–†â–„â–„â–…â–…â–…â–‚â–‡â–ƒâ–ƒâ–„â–‡â–„â–†â–„â–‡â–…â–‡â–†â–„â–†â–„â–†â–ƒâ–ˆâ–„â–ƒâ–‚â–„â–ˆâ–‚â–â–‡â–ƒâ–‡â–„
wandb:       eval/ensemble_f1 â–‡â–ƒâ–…â–†â–…â–…â–…â–…â–ƒâ–„â–‚â–‚â–„â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–„â–…â–„â–†â–‡â–ˆâ–‚â–‡â–†â–…â–‡â–‚â–„â–ƒâ–…â–…â–…â–â–‡â–„â–„
wandb:           train/avg_f1 â–â–‚â–…â–‚â–…â–…â–…â–„â–†â–â–ˆâ–„â–„â–‚â–„â–ƒâ–„â–‚â–…â–…â–†â–ƒâ–„â–‚â–‚â–ƒâ–…â–„â–…â–„â–†â–†â–…â–„â–â–…â–†â–…â–„â–ƒ
wandb:      train/ensemble_f1 â–…â–ƒâ–†â–‡â–†â–„â–‚â–ƒâ–†â–…â–ƒâ–‡â–…â–ˆâ–…â–‚â–‡â–„â–ˆâ–ƒâ–…â–„â–„â–„â–‡â–‚â–†â–‡â–†â–†â–†â–†â–‡â–‡â–†â–…â–„â–‚â–…â–
wandb:         train/mil_loss â–†â–†â–†â–†â–…â–‡â–‡â–†â–…â–…â–ˆâ–…â–…â–„â–…â–…â–…â–…â–„â–…â–ƒâ–ƒâ–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–„â–…â–â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.42799
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.77713
wandb:      eval/avg_mil_loss 0.52735
wandb:       eval/ensemble_f1 0.77713
wandb:           train/avg_f1 0.79003
wandb:      train/ensemble_f1 0.79003
wandb:         train/mil_loss 0.85751
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run drawn-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ix4yif4m
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104538-ix4yif4m/logs
wandb: ERROR Run ix4yif4m errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wj2iueqb with config:
wandb: 	actor_learning_rate: 3.7745533252201433e-06
wandb: 	attention_dropout_p: 0.26848137548465667
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07077638900556305
wandb: 	temperature: 0.28453097794640225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104936-wj2iueqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj2iueqb
wandb: uploading wandb-summary.json
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–ƒâ–„â–…â–…â–ƒâ–„â–†â–ƒâ–†â–ˆâ–‡â–…â–„â–‚â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–…â–…â–†â–…â–ƒâ–ƒâ–â–†â–…â–ˆâ–ƒâ–‚â–‡â–„â–„â–…â–„
wandb:      eval/avg_mil_loss â–‚â–†â–ƒâ–„â–ˆâ–‡â–†â–„â–…â–†â–„â–…â–‡â–â–„â–‡â–ƒâ–†â–‚â–ˆâ–‡â–‡â–†â–‡â–ˆâ–†â–…â–†â–ˆâ–„â–„â–†â–‡â–…â–„â–†â–„â–…â–†â–…
wandb:       eval/ensemble_f1 â–‚â–‚â–…â–‚â–ƒâ–…â–…â–ƒâ–‚â–†â–„â–„â–†â–‚â–…â–â–‚â–„â–…â–ƒâ–â–…â–„â–†â–ƒâ–‚â–†â–‚â–â–„â–ˆâ–†â–‚â–‚â–„â–„â–„â–†â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–„â–‡â–†â–ˆâ–‡â–ƒâ–…â–„â–‡â–…â–…â–„â–‚â–‡â–†â–…â–‚â–†â–ˆâ–…â–„â–„â–…â–‡â–„â–†â–„â–„â–†â–ˆâ–„â–„â–†â–ˆâ–‡â–â–†â–‡
wandb:      train/ensemble_f1 â–…â–„â–‚â–…â–â–†â–‡â–†â–ƒâ–ˆâ–…â–‚â–‚â–„â–„â–‡â–„â–â–„â–…â–‚â–‚â–„â–ƒâ–†â–ƒâ–ˆâ–…â–‚â–…â–ƒâ–‚â–„â–‡â–†â–…â–ˆâ–ƒâ–‡â–„
wandb:         train/mil_loss â–…â–ˆâ–„â–…â–ƒâ–„â–…â–ƒâ–…â–…â–‡â–„â–‡â–…â–†â–„â–‡â–„â–‚â–‡â–ƒâ–†â–…â–†â–„â–„â–â–†â–ˆâ–„â–„â–†â–…â–„â–†â–…â–„â–…â–…â–ƒ
wandb:      train/policy_loss â–â–„â–„â–â–â–„â–ˆâ–ˆâ–â–ˆâ–â–„â–â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–â–„â–ˆâ–â–„â–„â–„â–„â–ˆâ–ˆâ–„â–ˆâ–ˆâ–„â–â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–…â–…â–ˆâ–â–â–ˆâ–…â–ˆâ–â–â–…â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–â–â–…â–â–…â–ˆâ–…â–â–…â–…â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84631
wandb: best/eval_avg_mil_loss 0.43929
wandb:  best/eval_ensemble_f1 0.84631
wandb:            eval/avg_f1 0.77651
wandb:      eval/avg_mil_loss 0.46301
wandb:       eval/ensemble_f1 0.77651
wandb:            test/avg_f1 0.74447
wandb:      test/avg_mil_loss 0.50655
wandb:       test/ensemble_f1 0.74447
wandb:           train/avg_f1 0.80783
wandb:      train/ensemble_f1 0.80783
wandb:         train/mil_loss 0.98909
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wj2iueqb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104936-wj2iueqb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k8ihwdsx with config:
wandb: 	actor_learning_rate: 0.0001257445934747285
wandb: 	attention_dropout_p: 0.4598370882172288
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9197816903678576
wandb: 	temperature: 1.370732573104262
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105150-k8ihwdsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8ihwdsx
wandb: uploading history steps 69-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‚â–…â–†â–„â–ƒâ–‚â–…â–â–†â–ƒâ–ƒâ–†â–ƒâ–ˆâ–„â–„â–†â–ƒâ–…â–„â–ƒâ–…â–†â–„â–†â–ƒâ–‚â–…â–†â–†â–„â–‡â–ƒâ–„â–‡â–ƒâ–ƒâ–„â–ƒ
wandb:      eval/avg_mil_loss â–…â–…â–…â–‡â–‡â–ˆâ–…â–…â–…â–…â–…â–†â–†â–â–ƒâ–‡â–…â–‡â–‡â–„â–‡â–„â–ƒâ–„â–…â–†â–„â–‚â–ƒâ–†â–â–ƒâ–†â–ƒâ–…â–†â–ƒâ–‡â–†â–…
wandb:       eval/ensemble_f1 â–‚â–…â–ˆâ–„â–ƒâ–„â–†â–„â–„â–â–…â–†â–ƒâ–ƒâ–ˆâ–â–â–ƒâ–…â–‚â–„â–…â–ƒâ–…â–ƒâ–‚â–„â–†â–…â–†â–‡â–‡â–‚â–…â–‚â–‡â–†â–ƒâ–„â–ƒ
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–â–…â–„â–ƒâ–ƒâ–„â–‚â–â–‚â–†â–ƒâ–…â–â–„â–‚â–†â–ƒâ–ƒâ–‡â–„â–‚â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–‚â–ˆ
wandb:      train/ensemble_f1 â–…â–…â–…â–…â–„â–ƒâ–…â–†â–†â–…â–ƒâ–…â–…â–‡â–†â–„â–„â–‡â–†â–‡â–…â–‡â–†â–‡â–…â–…â–ˆâ–â–„â–†â–†â–†â–…â–…â–„â–‡â–„â–ƒâ–†â–„
wandb:         train/mil_loss â–„â–‡â–…â–ƒâ–„â–†â–‡â–†â–…â–…â–„â–…â–„â–ƒâ–†â–…â–†â–ƒâ–†â–ˆâ–‡â–‚â–„â–„â–†â–…â–ƒâ–…â–†â–â–‚â–„â–†â–…â–…â–„â–†â–…â–…â–‚
wandb:      train/policy_loss â–â–â–…â–…â–â–…â–…â–â–…â–…â–…â–…â–…â–ˆâ–ˆâ–â–…â–â–…â–…â–â–…â–ˆâ–ˆâ–…â–ˆâ–…â–…â–â–ˆâ–â–…â–…â–â–…â–ˆâ–â–…â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–„â–â–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–ˆâ–â–„â–â–â–„â–â–â–„â–„â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–â–„â–„â–ˆâ–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83179
wandb: best/eval_avg_mil_loss 0.41358
wandb:  best/eval_ensemble_f1 0.83179
wandb:            eval/avg_f1 0.7773
wandb:      eval/avg_mil_loss 0.48001
wandb:       eval/ensemble_f1 0.7773
wandb:           train/avg_f1 0.81803
wandb:      train/ensemble_f1 0.81803
wandb:         train/mil_loss 0.98666
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run floral-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k8ihwdsx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105150-k8ihwdsx/logs
wandb: ERROR Run k8ihwdsx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2mp5ptuo with config:
wandb: 	actor_learning_rate: 1.2027227707656207e-06
wandb: 	attention_dropout_p: 0.1296477672601843
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22948703500530887
wandb: 	temperature: 0.3661073536873738
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105329-2mp5ptuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mp5ptuo
wandb: uploading config.yaml
wandb: uploading history steps 54-61, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–„â–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–‡â–‡â–â–ˆâ–‚â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–„â–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‚â–…â–…â–„â–…â–„â–†â–ƒâ–â–†â–‡â–†â–…â–ƒâ–ˆâ–†â–…â–†â–„â–‡â–†â–„â–…â–„â–„â–„â–†â–„â–„â–ˆâ–ƒâ–„â–†â–‡â–ƒâ–†â–†â–„â–‡
wandb:      eval/avg_mil_loss â–†â–„â–…â–ƒâ–…â–…â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–†â–„â–…â–â–†â–„â–‚â–ƒâ–…â–…â–ƒâ–„â–ƒâ–…â–‚
wandb:       eval/ensemble_f1 â–†â–‚â–…â–…â–ƒâ–„â–†â–ƒâ–â–†â–‡â–‡â–†â–…â–ƒâ–†â–…â–â–…â–„â–‡â–†â–„â–…â–„â–„â–„â–…â–†â–†â–…â–ˆâ–ƒâ–„â–†â–…â–ƒâ–†â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ƒâ–ƒâ–„â–…â–„â–„â–†â–…â–‚â–‚â–…â–„â–†â–‡â–‡â–â–‚â–„â–„â–‡â–†â–†â–ƒâ–…â–„â–„â–„â–„â–…â–†â–‚â–†â–„â–ˆâ–â–„â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–†â–‚â–ƒâ–„â–…â–„â–„â–†â–…â–‡â–…â–„â–†â–…â–‡â–‚â–„â–„â–„â–‡â–ƒâ–„â–†â–ƒâ–„â–„â–„â–…â–…â–„â–ƒâ–…â–†â–†â–‚â–„â–ˆâ–â–ƒâ–ƒ
wandb:         train/mil_loss â–…â–…â–…â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‡â–‚â–‚â–…â–„â–ƒâ–„â–‚â–ƒâ–…â–‚â–â–ƒâ–„â–…â–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–‚â–„â–„â–â–…â–‚â–â–†â–…â–‚
wandb:      train/policy_loss â–…â–â–ˆâ–…â–â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.42062
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.83168
wandb:      eval/avg_mil_loss 0.41318
wandb:       eval/ensemble_f1 0.83168
wandb:            test/avg_f1 0.75021
wandb:      test/avg_mil_loss 0.60575
wandb:       test/ensemble_f1 0.75021
wandb:           train/avg_f1 0.7958
wandb:      train/ensemble_f1 0.7958
wandb:         train/mil_loss 1.93651
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wobbly-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2mp5ptuo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105329-2mp5ptuo/logs
wandb: Agent Starting Run: atnpuhk5 with config:
wandb: 	actor_learning_rate: 7.1780122322134346e-06
wandb: 	attention_dropout_p: 0.07174477101698679
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 84
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8069538453174826
wandb: 	temperature: 9.525351670034585
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105441-atnpuhk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atnpuhk5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–…â–„â–„â–â–†â–ƒâ–„â–„â–…â–…â–ƒâ–†â–†â–‡â–†â–ƒâ–â–‡â–ˆâ–…â–†â–†â–†â–†â–„â–…â–ƒâ–…â–†â–†â–…â–…â–…â–†â–…â–ƒâ–…â–…
wandb:      eval/avg_mil_loss â–†â–†â–…â–…â–ƒâ–„â–†â–„â–†â–ƒâ–†â–ƒâ–ƒâ–„â–â–„â–‡â–ˆâ–„â–ƒâ–†â–„â–…â–ƒâ–„â–ˆâ–„â–â–†â–…â–„â–„â–ƒâ–‡â–ˆâ–‡â–‡â–â–„â–‡
wandb:       eval/ensemble_f1 â–„â–‡â–„â–„â–„â–…â–ƒâ–†â–â–„â–ƒâ–„â–„â–ƒâ–…â–†â–‡â–†â–†â–‡â–‚â–…â–‡â–‚â–†â–†â–„â–â–ƒâ–…â–…â–…â–…â–†â–…â–†â–„â–„â–ƒâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–‚â–â–„â–†â–ƒâ–…â–„â–†â–‡â–…â–‚â–ƒâ–ƒâ–ƒâ–†â–â–‚â–‚â–„â–‡â–†â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–…â–‡â–…â–‡â–â–â–‚â–„â–†
wandb:      train/ensemble_f1 â–ƒâ–†â–‚â–ƒâ–â–„â–…â–…â–„â–„â–„â–„â–ˆâ–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–„â–…â–‡â–ˆâ–„â–…â–„â–ƒâ–ƒâ–…â–‚â–„â–â–‡â–…â–‡â–â–†
wandb:         train/mil_loss â–„â–ˆâ–ƒâ–„â–†â–…â–…â–‡â–ˆâ–…â–‡â–„â–‡â–‡â–‚â–ƒâ–…â–‡â–…â–…â–…â–†â–†â–…â–…â–…â–„â–‚â–†â–…â–„â–ƒâ–‡â–‚â–„â–â–‡â–„â–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84605
wandb: best/eval_avg_mil_loss 0.44759
wandb:  best/eval_ensemble_f1 0.84605
wandb:            eval/avg_f1 0.80985
wandb:      eval/avg_mil_loss 0.53108
wandb:       eval/ensemble_f1 0.80985
wandb:            test/avg_f1 0.75308
wandb:      test/avg_mil_loss 0.52707
wandb:       test/ensemble_f1 0.75308
wandb:           train/avg_f1 0.81139
wandb:      train/ensemble_f1 0.81139
wandb:         train/mil_loss 1.94446
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run brisk-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/atnpuhk5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105441-atnpuhk5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r0i479qd with config:
wandb: 	actor_learning_rate: 7.641864928262804e-06
wandb: 	attention_dropout_p: 0.14461139588241617
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1353385411198863
wandb: 	temperature: 0.7613163257310196
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105629-r0i479qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0i479qd
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–…â–‚â–ƒâ–†â–…â–„â–†â–â–‡â–ƒâ–ƒâ–ƒâ–…â–†â–ˆâ–…â–‚â–„â–ƒâ–‡â–„â–‡â–‚â–…â–…â–†â–„â–„â–„â–…â–ƒâ–†â–ƒâ–‚â–‡â–„â–†â–
wandb:      eval/avg_mil_loss â–‡â–â–ƒâ–†â–†â–†â–â–‚â–„â–ƒâ–„â–…â–„â–†â–„â–‚â–„â–†â–†â–‚â–‡â–ˆâ–‡â–ƒâ–†â–†â–â–†â–ƒâ–„â–‡â–‚â–ƒâ–„â–…â–†â–‡â–‡â–â–†
wandb:       eval/ensemble_f1 â–‡â–‡â–…â–„â–†â–‡â–„â–â–ˆâ–ƒâ–†â–ƒâ–„â–‡â–ƒâ–†â–…â–‚â–„â–‡â–ˆâ–‡â–ƒâ–„â–‚â–…â–†â–„â–†â–‡â–ƒâ–â–‡â–†â–…â–‡â–†â–â–„â–
wandb:           train/avg_f1 â–†â–‚â–â–ƒâ–†â–…â–…â–†â–†â–†â–„â–‡â–ˆâ–†â–‡â–…â–…â–ƒâ–ƒâ–†â–†â–…â–…â–‡â–…â–„â–‡â–…â–„â–…â–ƒâ–†â–„â–…â–„â–…â–ˆâ–ƒâ–ƒâ–…
wandb:      train/ensemble_f1 â–…â–‚â–…â–â–‚â–‡â–…â–†â–ˆâ–„â–†â–…â–…â–‚â–ƒâ–„â–…â–„â–†â–†â–…â–ƒâ–„â–‡â–‡â–ƒâ–‡â–ƒâ–„â–ƒâ–â–„â–„â–ƒâ–†â–ƒâ–‚â–†â–‚â–…
wandb:         train/mil_loss â–ˆâ–†â–…â–†â–†â–…â–†â–†â–‚â–…â–†â–…â–…â–†â–†â–…â–†â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–…â–â–…â–‡â–„â–…â–‚â–…â–„â–„â–‡â–‡â–„â–‚â–ƒâ–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84589
wandb: best/eval_avg_mil_loss 0.42597
wandb:  best/eval_ensemble_f1 0.84589
wandb:            eval/avg_f1 0.76269
wandb:      eval/avg_mil_loss 0.48779
wandb:       eval/ensemble_f1 0.76269
wandb:           train/avg_f1 0.79977
wandb:      train/ensemble_f1 0.79977
wandb:         train/mil_loss 1.89307
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run happy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r0i479qd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105629-r0i479qd/logs
wandb: ERROR Run r0i479qd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: phgprhij with config:
wandb: 	actor_learning_rate: 3.6976148293554047e-06
wandb: 	attention_dropout_p: 0.3372463359203148
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1677673655981906
wandb: 	temperature: 5.136184295524167
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105854-phgprhij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phgprhij
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–ƒâ–…â–‚â–‚â–…â–‚â–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–…â–†â–„â–†â–…â–„â–â–ƒâ–†â–‚â–†â–…â–„â–…â–†â–„â–†â–†â–„â–†â–‡â–…â–ƒâ–‡â–…â–‡â–†â–†â–„â–„â–†â–…â–„â–†â–†â–‡â–…â–ˆ
wandb:      eval/avg_mil_loss â–‚â–„â–†â–‡â–„â–…â–‚â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–â–ˆâ–…â–„â–‚â–…â–…â–†â–„â–ˆâ–„â–‚â–…â–„â–„â–…â–…â–„â–„â–ƒâ–ƒâ–†â–„â–„â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–…â–…â–„â–‡â–†â–â–ƒâ–†â–†â–ƒâ–…â–…â–‡â–‡â–†â–…â–…â–…â–…â–ˆâ–…â–†â–„â–…â–†â–„â–„â–„â–…â–†â–„â–„â–†â–†â–‡â–†â–†â–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–ƒâ–†â–‡â–…â–‡â–…â–‡â–ˆâ–†â–†â–†â–ƒâ–„â–„â–„â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–‡â–†â–‚â–†â–‚â–†â–ƒâ–‡â–…â–â–†â–ˆâ–…â–ƒâ–†â–‡
wandb:      train/ensemble_f1 â–‚â–ƒâ–…â–ƒâ–†â–†â–†â–†â–…â–„â–„â–ƒâ–ˆâ–…â–†â–„â–†â–†â–ƒâ–…â–‚â–†â–…â–„â–†â–†â–‚â–…â–†â–â–„â–…â–…â–†â–ƒâ–ˆâ–„â–…â–ƒâ–ƒ
wandb:         train/mil_loss â–†â–‡â–ƒâ–„â–„â–†â–ˆâ–‚â–†â–…â–…â–†â–„â–†â–…â–„â–…â–ƒâ–„â–…â–„â–…â–‡â–â–„â–‚â–…â–„â–„â–ƒâ–†â–…â–„â–…â–…â–ƒâ–â–…â–ƒâ–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.40816
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80292
wandb:      eval/avg_mil_loss 0.38919
wandb:       eval/ensemble_f1 0.80292
wandb:            test/avg_f1 0.77274
wandb:      test/avg_mil_loss 0.59537
wandb:       test/ensemble_f1 0.77274
wandb:           train/avg_f1 0.79672
wandb:      train/ensemble_f1 0.79672
wandb:         train/mil_loss 0.69131
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run toasty-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/phgprhij
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105854-phgprhij/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: omk0hbun with config:
wandb: 	actor_learning_rate: 3.56142674863137e-06
wandb: 	attention_dropout_p: 0.4701773694135774
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6308530474575409
wandb: 	temperature: 5.703681703594614
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110229-omk0hbun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/omk0hbun
wandb: uploading history steps 151-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–ƒâ–†â–„â–ˆâ–‚â–ƒâ–„â–†â–†â–†â–„â–„â–…â–„â–ƒâ–„â–†â–…â–…â–†â–„â–ƒâ–‡â–‡â–‚â–‡â–…â–„â–â–‚â–‚â–‚â–‚â–†â–ƒâ–ƒâ–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–â–„â–â–…â–„â–„â–„â–‚â–„â–‚â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–„â–„â–„â–†â–„â–†â–…â–ƒâ–„â–„â–„â–ƒâ–…â–…â–‚â–†â–ƒâ–†â–„â–…â–ˆ
wandb:       eval/ensemble_f1 â–…â–…â–„â–„â–ƒâ–†â–ƒâ–„â–„â–…â–…â–„â–ˆâ–ƒâ–…â–†â–‚â–„â–ƒâ–…â–„â–„â–â–„â–„â–ƒâ–…â–â–„â–†â–‚â–ƒâ–„â–„â–ˆâ–†â–ƒâ–„â–ƒâ–‡
wandb:           train/avg_f1 â–‡â–…â–‡â–†â–ƒâ–ˆâ–ˆâ–‡â–†â–„â–…â–„â–„â–…â–…â–…â–„â–…â–‚â–„â–„â–‡â–…â–ƒâ–ƒâ–â–…â–…â–â–…â–‚â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–†
wandb:      train/ensemble_f1 â–†â–‡â–†â–ˆâ–†â–…â–ˆâ–…â–†â–‡â–‡â–ƒâ–ƒâ–†â–‡â–…â–‡â–ƒâ–†â–†â–„â–„â–†â–„â–…â–…â–†â–„â–…â–†â–ƒâ–…â–„â–…â–„â–â–…â–„â–ƒâ–…
wandb:         train/mil_loss â–†â–ˆâ–‡â–‡â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–‡â–…â–…â–‡â–„â–…â–…â–„â–‚â–„â–…â–…â–†â–„â–…â–„â–ƒâ–‚â–â–„â–„â–â–ƒâ–â–ƒâ–‚â–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84642
wandb: best/eval_avg_mil_loss 0.41182
wandb:  best/eval_ensemble_f1 0.84642
wandb:            eval/avg_f1 0.83208
wandb:      eval/avg_mil_loss 0.40071
wandb:       eval/ensemble_f1 0.83208
wandb:           train/avg_f1 0.80174
wandb:      train/ensemble_f1 0.80174
wandb:         train/mil_loss 1.67872
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wobbly-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/omk0hbun
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110229-omk0hbun/logs
wandb: ERROR Run omk0hbun errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cumu7kh7 with config:
wandb: 	actor_learning_rate: 0.0004796194978835046
wandb: 	attention_dropout_p: 0.4521900236181059
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22944046428201512
wandb: 	temperature: 3.387504536483774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110559-cumu7kh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cumu7kh7
wandb: uploading history steps 85-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–‡
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–ƒâ–‚â–…â–„â–„â–…â–ƒâ–„â–„â–†â–†â–ˆâ–‚â–…â–„â–„â–ƒâ–„â–…â–ƒâ–„â–„â–„â–…â–…â–…â–†â–…â–„â–„â–ƒâ–ƒâ–…â–ƒâ–â–„â–ƒâ–‚
wandb:      eval/avg_mil_loss â–‚â–…â–…â–„â–â–…â–‚â–†â–†â–‡â–…â–„â–ƒâ–„â–…â–‚â–‚â–…â–ˆâ–„â–ƒâ–„â–…â–â–ƒâ–ƒâ–ƒâ–„â–‡â–…â–ˆâ–ƒâ–‚â–‚â–„â–ƒâ–„â–‚â–ƒâ–†
wandb:       eval/ensemble_f1 â–„â–ˆâ–…â–„â–…â–ƒâ–†â–ƒâ–„â–†â–ƒâ–‡â–‡â–‚â–…â–†â–ˆâ–„â–†â–ƒâ–„â–â–ƒâ–†â–…â–†â–„â–ƒâ–„â–‚â–†â–†â–†â–ƒâ–ƒâ–ƒâ–ˆâ–†â–„â–
wandb:           train/avg_f1 â–‡â–„â–†â–‡â–„â–‡â–ƒâ–„â–„â–‡â–ƒâ–‚â–…â–…â–„â–„â–„â–‡â–†â–…â–„â–„â–„â–…â–ƒâ–…â–†â–ƒâ–†â–†â–†â–„â–â–ˆâ–†â–ƒâ–ƒâ–ƒâ–†â–…
wandb:      train/ensemble_f1 â–‡â–„â–†â–‡â–„â–ƒâ–‡â–…â–‡â–ƒâ–‚â–…â–„â–…â–„â–†â–‡â–†â–…â–„â–…â–ƒâ–†â–†â–†â–…â–‡â–ƒâ–ƒâ–„â–â–ˆâ–…â–‚â–…â–ƒâ–†â–‡â–ƒâ–…
wandb:         train/mil_loss â–‡â–‡â–…â–†â–†â–†â–ˆâ–…â–‡â–†â–†â–†â–…â–†â–…â–„â–„â–…â–„â–…â–…â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–‚â–ƒâ–„â–…â–
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–â–„â–„â–â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.45555
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.76275
wandb:      eval/avg_mil_loss 0.4823
wandb:       eval/ensemble_f1 0.76275
wandb:           train/avg_f1 0.80315
wandb:      train/ensemble_f1 0.80315
wandb:         train/mil_loss 1.48942
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dauntless-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cumu7kh7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110559-cumu7kh7/logs
wandb: ERROR Run cumu7kh7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hdflq1pq with config:
wandb: 	actor_learning_rate: 1.282056867862572e-06
wandb: 	attention_dropout_p: 0.007092340025441235
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8795213027332583
wandb: 	temperature: 4.021400159954203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110758-hdflq1pq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdflq1pq
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 93-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–â–†â–ˆâ–†â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–†â–…â–„â–‡â–‡â–„â–„â–…â–„â–†â–â–â–†â–ˆâ–‡â–ƒâ–†â–„â–†â–…â–„â–…â–ƒâ–…â–„â–ˆâ–„â–â–…â–„â–„â–†â–ƒâ–…â–ƒâ–…â–„
wandb:      eval/avg_mil_loss â–‡â–â–…â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–‡â–ƒâ–ƒâ–‚â–„â–„â–…â–ƒâ–†â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–…â–…â–†â–‚â–ˆâ–ˆâ–„â–‡â–…â–…â–†â–‚â–„â–…â–…
wandb:       eval/ensemble_f1 â–„â–ƒâ–†â–„â–…â–„â–„â–„â–ˆâ–„â–ƒâ–†â–„â–…â–â–„â–ƒâ–…â–†â–„â–…â–„â–…â–†â–„â–…â–„â–ƒâ–„â–‚â–…â–„â–ƒâ–…â–…â–†â–…â–„â–„â–…
wandb:           train/avg_f1 â–ˆâ–ƒâ–‡â–…â–†â–†â–„â–„â–…â–„â–†â–…â–…â–…â–…â–ƒâ–…â–…â–„â–„â–ˆâ–ƒâ–‚â–…â–‡â–‡â–„â–…â–…â–†â–†â–„â–…â–†â–â–„â–‚â–‚â–…â–„
wandb:      train/ensemble_f1 â–‡â–…â–ˆâ–„â–‚â–†â–‚â–„â–‡â–ƒâ–†â–…â–†â–„â–…â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–â–…â–‡â–…â–„â–†â–„â–…â–†â–‡â–‡â–…â–„â–â–‚â–†â–…â–ƒâ–
wandb:         train/mil_loss â–‚â–ˆâ–‡â–‡â–…â–‚â–…â–†â–…â–†â–‡â–‡â–ˆâ–†â–…â–ƒâ–ˆâ–†â–„â–„â–ƒâ–‡â–â–‚â–„â–ƒâ–†â–„â–„â–ˆâ–…â–‚â–ƒâ–â–ƒâ–ƒâ–„â–…â–…â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85734
wandb: best/eval_avg_mil_loss 0.39519
wandb:  best/eval_ensemble_f1 0.85734
wandb:            eval/avg_f1 0.79895
wandb:      eval/avg_mil_loss 0.47092
wandb:       eval/ensemble_f1 0.79895
wandb:           train/avg_f1 0.78687
wandb:      train/ensemble_f1 0.78687
wandb:         train/mil_loss 2.07335
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hdflq1pq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110758-hdflq1pq/logs
wandb: ERROR Run hdflq1pq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gdgrzp50 with config:
wandb: 	actor_learning_rate: 3.4776141595712335e-05
wandb: 	attention_dropout_p: 0.31660266025974587
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15754659828666295
wandb: 	temperature: 1.1234708956833928
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111004-gdgrzp50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdgrzp50
wandb: uploading history steps 130-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–ˆâ–‚â–ƒâ–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–„â–ƒâ–„â–†â–†â–…â–„â–„â–‡â–ƒâ–…â–„â–‡â–†â–…â–†â–‡â–†â–‡â–†â–†â–…â–‡â–…â–…â–‚â–„â–â–„â–†â–…â–…â–ˆâ–â–ƒâ–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–…â–â–â–‚â–†â–â–‚â–„â–„â–…â–…â–„â–‚â–‡â–‚â–„â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–â–ˆâ–„â–…â–ƒâ–ƒâ–„â–…â–„â–†â–„â–„â–‚â–„
wandb:       eval/ensemble_f1 â–‡â–†â–…â–‡â–‡â–…â–…â–†â–…â–‡â–†â–ˆâ–„â–†â–â–†â–†â–‡â–‡â–‡â–†â–…â–ˆâ–†â–…â–‡â–„â–„â–…â–‡â–…â–†â–„â–†â–„â–ƒâ–ƒâ–†â–†â–‡
wandb:           train/avg_f1 â–ƒâ–†â–‚â–†â–…â–…â–…â–…â–ˆâ–„â–…â–†â–…â–„â–†â–â–…â–…â–ˆâ–…â–…â–…â–…â–ƒâ–ƒâ–‡â–‚â–†â–…â–„â–…â–„â–…â–†â–†â–ƒâ–†â–„â–†â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–â–„â–ƒâ–ˆâ–„â–‡â–‡â–†â–†â–…â–‡â–„â–„â–‚â–‡â–„â–†â–‡â–ƒâ–„â–‡â–†â–„â–ƒâ–‚â–„â–…â–‚â–‡â–‚â–„â–„â–…â–„â–†â–ƒâ–‚â–‚
wandb:         train/mil_loss â–ˆâ–‡â–„â–‡â–„â–‡â–„â–„â–…â–…â–„â–„â–…â–…â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–â–ƒâ–ƒâ–„â–„â–‚â–„â–â–„â–ƒâ–„â–ƒâ–â–‚â–â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85743
wandb: best/eval_avg_mil_loss 0.3956
wandb:  best/eval_ensemble_f1 0.85743
wandb:            eval/avg_f1 0.80985
wandb:      eval/avg_mil_loss 0.42643
wandb:       eval/ensemble_f1 0.80985
wandb:           train/avg_f1 0.80415
wandb:      train/ensemble_f1 0.80415
wandb:         train/mil_loss 1.80612
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run upbeat-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdgrzp50
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111004-gdgrzp50/logs
wandb: ERROR Run gdgrzp50 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: j5axwzdc with config:
wandb: 	actor_learning_rate: 2.7731314587883893e-05
wandb: 	attention_dropout_p: 0.017215823515158435
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4331975330047764
wandb: 	temperature: 1.7860947967932683
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111311-j5axwzdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5axwzdc
wandb: uploading wandb-summary.json
wandb: uploading history steps 187-198, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–…â–ƒâ–†â–ƒâ–„â–â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–ƒâ–‡â–…â–‡â–†â–ƒâ–…â–‚â–‚â–„â–‚â–ƒâ–„â–„â–„â–„â–†â–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–…â–ˆâ–„â–„â–ƒâ–‡â–ƒâ–„â–ƒâ–ƒâ–†â–â–†â–
wandb:      eval/avg_mil_loss â–…â–ƒâ–ƒâ–†â–…â–‚â–…â–„â–†â–…â–…â–„â–ƒâ–…â–â–†â–„â–„â–†â–‡â–‡â–„â–„â–ƒâ–…â–†â–…â–ˆâ–ˆâ–„â–‡â–‚â–„â–‡â–…â–‚â–…â–„â–…â–†
wandb:       eval/ensemble_f1 â–â–„â–ˆâ–†â–†â–ƒâ–„â–ˆâ–„â–…â–‚â–‚â–…â–„â–†â–…â–…â–ƒâ–„â–ƒâ–ƒâ–„â–„â–†â–ƒâ–†â–„â–†â–…â–ˆâ–…â–„â–†â–„â–ƒâ–â–‡â–„â–‡â–‚
wandb:           train/avg_f1 â–‡â–‡â–‡â–„â–ˆâ–„â–†â–‡â–‡â–ƒâ–„â–‡â–†â–‡â–†â–‡â–ƒâ–ƒâ–†â–‡â–„â–…â–†â–„â–…â–‡â–‡â–†â–†â–…â–â–ƒâ–†â–‡â–ƒâ–…â–†â–‡â–„â–ƒ
wandb:      train/ensemble_f1 â–†â–„â–…â–ƒâ–…â–†â–ˆâ–ƒâ–†â–†â–…â–†â–…â–„â–‡â–…â–†â–‡â–…â–ƒâ–ˆâ–…â–†â–‚â–‚â–‡â–…â–ƒâ–‡â–…â–‚â–â–„â–â–‡â–…â–ƒâ–„â–‡â–„
wandb:         train/mil_loss â–ƒâ–„â–„â–ƒâ–„â–†â–„â–ƒâ–†â–ƒâ–ƒâ–ˆâ–…â–†â–„â–†â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–…â–†â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.44378
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.75866
wandb:      eval/avg_mil_loss 0.52247
wandb:       eval/ensemble_f1 0.75866
wandb:           train/avg_f1 0.787
wandb:      train/ensemble_f1 0.787
wandb:         train/mil_loss 1.65833
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5axwzdc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111311-j5axwzdc/logs
wandb: ERROR Run j5axwzdc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4642847l with config:
wandb: 	actor_learning_rate: 0.00013406808635676036
wandb: 	attention_dropout_p: 0.43775283725521497
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5695376421570829
wandb: 	temperature: 9.507744133718816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111703-4642847l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4642847l
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–â–†â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–„â–†â–…â–„â–†â–†â–„â–ƒâ–‚â–…â–„â–…â–†â–…â–†â–„â–„â–ƒâ–†â–‡â–†â–ƒâ–‚â–ƒâ–‚â–â–„â–…â–â–‡â–…â–„â–ˆâ–†â–ˆâ–‚â–ƒâ–…
wandb:      eval/avg_mil_loss â–…â–†â–‚â–„â–†â–„â–…â–ƒâ–â–†â–ƒâ–â–ˆâ–†â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–…â–†â–‡â–†â–ˆâ–ˆâ–‡â–‚â–„â–…â–…â–‡â–‚â–„â–‡â–‡â–…â–…â–„â–„
wandb:       eval/ensemble_f1 â–„â–‚â–‡â–â–ˆâ–†â–…â–†â–…â–ƒâ–‡â–†â–ƒâ–…â–‡â–‡â–„â–ƒâ–…â–ƒâ–ˆâ–ƒâ–…â–„â–…â–†â–†â–ƒâ–„â–„â–…â–…â–†â–ƒâ–„â–„â–‡â–…â–…â–„
wandb:           train/avg_f1 â–…â–„â–„â–†â–†â–‚â–…â–…â–‚â–…â–‡â–ƒâ–„â–„â–ƒâ–†â–„â–ƒâ–ƒâ–‡â–…â–„â–ˆâ–„â–â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–…â–ƒâ–„â–„â–‚â–ƒâ–
wandb:      train/ensemble_f1 â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–…â–…â–…â–…â–…â–‡â–…â–‡â–…â–…â–†â–…â–ˆâ–†â–‡â–‡â–‡â–†â–…â–‡â–…â–„â–†â–ƒâ–„â–â–…â–„â–…â–†â–†â–„â–‡
wandb:         train/mil_loss â–†â–‚â–†â–ƒâ–‡â–„â–„â–ˆâ–„â–†â–…â–‡â–„â–†â–†â–…â–…â–ƒâ–…â–…â–‚â–„â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–â–â–â–ˆâ–…â–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–â–…â–…â–…â–â–…â–…â–ˆâ–â–…â–ˆâ–…â–…â–…â–â–…â–â–…â–…â–…â–â–…â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8612
wandb: best/eval_avg_mil_loss 0.41062
wandb:  best/eval_ensemble_f1 0.8612
wandb:            eval/avg_f1 0.81018
wandb:      eval/avg_mil_loss 0.47015
wandb:       eval/ensemble_f1 0.81018
wandb:           train/avg_f1 0.78193
wandb:      train/ensemble_f1 0.78193
wandb:         train/mil_loss 0.86015
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4642847l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111703-4642847l/logs
wandb: ERROR Run 4642847l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g38qv44n with config:
wandb: 	actor_learning_rate: 6.470389095244708e-05
wandb: 	attention_dropout_p: 0.030584772148790296
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4248910948267475
wandb: 	temperature: 3.3234385623170315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112125-g38qv44n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g38qv44n
wandb: uploading history steps 53-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–…â–„â–‡â–†â–…â–ˆâ–†â–„â–ƒâ–„â–â–†â–…â–‡â–…â–ƒâ–‚â–‡â–ƒâ–‚â–†â–„â–ˆâ–‡â–†â–‡â–…â–†â–†â–„â–†â–„â–„â–„â–ƒâ–„â–†â–‡â–„
wandb:      eval/avg_mil_loss â–‡â–„â–…â–ƒâ–‚â–â–ƒâ–â–†â–„â–…â–…â–‚â–ƒâ–„â–†â–…â–…â–†â–„â–„â–…â–‡â–â–ƒâ–„â–…â–ˆâ–ƒâ–ƒâ–‚â–‡â–„â–…â–†â–…â–‡â–„â–„â–„
wandb:       eval/ensemble_f1 â–‚â–…â–„â–†â–‡â–…â–ˆâ–†â–„â–ƒâ–„â–â–†â–…â–‡â–…â–…â–ƒâ–‚â–‡â–„â–‚â–†â–„â–ˆâ–„â–†â–‡â–…â–†â–„â–†â–„â–„â–„â–ƒâ–„â–†â–ƒâ–†
wandb:           train/avg_f1 â–„â–…â–…â–…â–ƒâ–‚â–‚â–„â–ƒâ–„â–…â–…â–…â–„â–‚â–‡â–â–†â–„â–‚â–„â–…â–ˆâ–‚â–ƒâ–†â–ƒâ–…â–…â–†â–†â–†â–†â–„â–…â–‡â–ƒâ–ˆâ–ƒâ–…
wandb:      train/ensemble_f1 â–„â–…â–…â–ƒâ–†â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–…â–„â–‚â–‡â–â–†â–„â–„â–„â–…â–ˆâ–‚â–ƒâ–ƒâ–†â–†â–ƒâ–…â–…â–†â–†â–„â–…â–‡â–ƒâ–…â–ƒâ–…
wandb:         train/mil_loss â–„â–†â–ˆâ–ƒâ–…â–ˆâ–…â–…â–„â–‡â–†â–„â–‡â–ƒâ–„â–‡â–…â–†â–ˆâ–‡â–…â–„â–†â–â–…â–…â–„â–„â–ƒâ–„â–†â–†â–„â–…â–…â–†â–†â–†â–‚â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.38367
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.7876
wandb:      eval/avg_mil_loss 0.44102
wandb:       eval/ensemble_f1 0.7876
wandb:           train/avg_f1 0.80785
wandb:      train/ensemble_f1 0.80785
wandb:         train/mil_loss 2.31027
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run icy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g38qv44n
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112125-g38qv44n/logs
wandb: ERROR Run g38qv44n errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xxzspc0m with config:
wandb: 	actor_learning_rate: 2.9291422422123893e-05
wandb: 	attention_dropout_p: 0.14570051850046778
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48966088877892067
wandb: 	temperature: 8.01936330487695
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112232-xxzspc0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxzspc0m
wandb: uploading history steps 81-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–„â–â–ˆâ–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–†â–„â–…â–†â–‚â–‚â–„â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–†â–ƒâ–‡â–ˆâ–„â–‚â–†â–„â–‡â–ˆâ–…â–†â–†â–„â–„â–†â–…â–†â–…â–…â–„â–â–†â–‡â–ƒâ–…
wandb:      eval/avg_mil_loss â–ƒâ–†â–‡â–…â–…â–„â–‡â–„â–†â–…â–…â–„â–‡â–„â–…â–…â–‚â–…â–†â–ƒâ–„â–â–…â–†â–†â–‡â–â–ˆâ–…â–†â–…â–†â–„â–‡â–…â–†â–„â–ˆâ–ƒâ–†
wandb:       eval/ensemble_f1 â–…â–„â–…â–ƒâ–‚â–ƒâ–ˆâ–…â–„â–…â–â–ƒâ–ƒâ–ƒâ–†â–„â–‡â–ˆâ–…â–…â–ƒâ–…â–ƒâ–‡â–ƒâ–„â–…â–…â–…â–„â–„â–†â–„â–ƒâ–†â–‡â–„â–‚â–„â–‚
wandb:           train/avg_f1 â–ƒâ–†â–…â–ˆâ–‚â–…â–ˆâ–…â–†â–„â–â–…â–†â–„â–‡â–ƒâ–ˆâ–„â–ƒâ–â–„â–„â–„â–†â–†â–ƒâ–„â–‡â–…â–ˆâ–…â–‚â–…â–‚â–…â–‡â–…â–ƒâ–â–
wandb:      train/ensemble_f1 â–ƒâ–…â–…â–…â–…â–„â–†â–„â–ƒâ–…â–„â–…â–„â–â–„â–†â–ƒâ–â–…â–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–ˆâ–‡â–ƒâ–†â–‚â–„â–‚â–„â–…â–‚â–…â–„â–â–†â–
wandb:         train/mil_loss â–ˆâ–„â–†â–‡â–‚â–„â–†â–…â–„â–†â–‡â–…â–„â–â–‡â–†â–„â–„â–…â–†â–†â–†â–†â–†â–ƒâ–†â–†â–„â–…â–„â–…â–ƒâ–…â–‚â–„â–ƒâ–„â–…â–‚â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–â–â–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–â–â–â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83527
wandb: best/eval_avg_mil_loss 0.4477
wandb:  best/eval_ensemble_f1 0.83527
wandb:            eval/avg_f1 0.77723
wandb:      eval/avg_mil_loss 0.47474
wandb:       eval/ensemble_f1 0.77723
wandb:           train/avg_f1 0.79809
wandb:      train/ensemble_f1 0.79809
wandb:         train/mil_loss 1.67806
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fragrant-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xxzspc0m
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112232-xxzspc0m/logs
wandb: ERROR Run xxzspc0m errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9eayb0sr with config:
wandb: 	actor_learning_rate: 1.747656813554055e-06
wandb: 	attention_dropout_p: 0.05880625832594161
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.720793186157382
wandb: 	temperature: 6.491613356735899
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112415-9eayb0sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9eayb0sr
wandb: uploading history steps 148-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–†â–„â–â–†â–‚â–â–ˆâ–…â–†â–„â–†â–†â–†â–ˆâ–†â–„â–…â–ƒâ–‡â–†â–†â–…â–‡â–‡â–†â–„â–‚â–†â–…â–‡â–†â–‚â–…â–„â–†â–„â–ƒâ–ˆâ–„â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–‚â–‚â–‡â–…â–…â–„â–„â–„â–†â–†â–ƒâ–…â–†â–„â–…â–ƒâ–‚â–…â–…â–„â–â–‚â–â–ˆâ–ƒâ–‚â–ˆâ–‚â–ƒâ–…â–ƒâ–†â–‚â–„â–ƒâ–†â–‚â–‚â–†
wandb:       eval/ensemble_f1 â–…â–ƒâ–ƒâ–‚â–…â–â–ƒâ–â–…â–ƒâ–†â–‡â–…â–ˆâ–†â–ƒâ–‚â–‚â–„â–‚â–…â–†â–‚â–†â–…â–„â–…â–…â–ƒâ–…â–…â–ƒâ–„â–…â–†â–…â–†â–„â–ƒâ–ƒ
wandb:           train/avg_f1 â–â–‡â–ˆâ–‡â–‡â–„â–…â–†â–…â–†â–‡â–†â–†â–…â–†â–†â–‡â–‡â–†â–…â–‡â–†â–‡â–…â–…â–…â–†â–†â–…â–†â–ƒâ–…â–‡â–…â–†â–„â–…â–†â–‚â–…
wandb:      train/ensemble_f1 â–…â–‡â–ˆâ–ˆâ–ˆâ–…â–†â–ˆâ–…â–†â–†â–…â–†â–…â–†â–‡â–â–…â–‡â–‡â–†â–‡â–†â–…â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–…â–…â–†â–‡â–…â–ƒâ–…â–†
wandb:         train/mil_loss â–…â–†â–†â–†â–…â–…â–…â–†â–‡â–ƒâ–ƒâ–ˆâ–…â–…â–‡â–…â–ƒâ–ƒâ–„â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–‡â–„â–‚â–„â–„â–„â–„â–â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85323
wandb: best/eval_avg_mil_loss 0.43276
wandb:  best/eval_ensemble_f1 0.85323
wandb:            eval/avg_f1 0.79535
wandb:      eval/avg_mil_loss 0.49353
wandb:       eval/ensemble_f1 0.79535
wandb:           train/avg_f1 0.8031
wandb:      train/ensemble_f1 0.8031
wandb:         train/mil_loss 1.94972
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run resilient-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9eayb0sr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112415-9eayb0sr/logs
wandb: ERROR Run 9eayb0sr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lu8jtmb8 with config:
wandb: 	actor_learning_rate: 9.395452484173451e-05
wandb: 	attention_dropout_p: 0.1759659927938505
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.692485725045909
wandb: 	temperature: 9.99003522937436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112726-lu8jtmb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lu8jtmb8
wandb: uploading history steps 139-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–ˆâ–‡â–…â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–…â–†â–„â–„â–„â–…â–ƒâ–ˆâ–ƒâ–†â–†â–…â–…â–ƒâ–†â–†â–…â–†â–…â–‡â–…â–†â–‚â–‡â–ƒâ–â–…â–…â–„â–…â–†â–†â–‚â–†â–†â–‚â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–„â–„â–ƒâ–„â–‡â–ƒâ–…â–‡â–‚â–„â–‚â–…â–„â–„â–„â–‡â–‚â–‡â–…â–…â–„â–…â–ƒâ–…â–ƒâ–„â–…â–‡â–ƒâ–„â–ƒâ–„â–‚â–ˆâ–„â–†â–â–…
wandb:       eval/ensemble_f1 â–…â–„â–…â–„â–†â–ƒâ–ƒâ–…â–‡â–„â–†â–ˆâ–†â–â–…â–„â–„â–‡â–…â–„â–‡â–‚â–ƒâ–…â–ˆâ–„â–…â–†â–†â–…â–‚â–†â–„â–„â–„â–†â–â–ˆâ–†â–„
wandb:           train/avg_f1 â–…â–â–ˆâ–…â–…â–…â–„â–‚â–†â–‚â–„â–†â–†â–„â–…â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–„â–ƒâ–„â–â–‚â–‚â–†â–„â–â–‚â–…â–…â–ƒâ–ƒâ–
wandb:      train/ensemble_f1 â–ƒâ–‚â–†â–…â–†â–…â–ƒâ–‚â–‡â–†â–‡â–ƒâ–†â–…â–ˆâ–…â–‡â–â–„â–…â–„â–„â–‚â–‚â–‚â–…â–ƒâ–…â–…â–…â–„â–…â–…â–„â–†â–‚â–…â–„â–ƒâ–‚
wandb:         train/mil_loss â–†â–†â–ˆâ–‡â–†â–†â–†â–†â–…â–‡â–…â–†â–†â–„â–…â–†â–†â–„â–ƒâ–„â–„â–…â–†â–„â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–„â–ƒâ–â–†â–ƒâ–‚â–â–‚â–‚â–
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–ˆâ–†â–†â–â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–‡â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84619
wandb: best/eval_avg_mil_loss 0.41174
wandb:  best/eval_ensemble_f1 0.84619
wandb:            eval/avg_f1 0.78467
wandb:      eval/avg_mil_loss 0.47472
wandb:       eval/ensemble_f1 0.78467
wandb:           train/avg_f1 0.79231
wandb:      train/ensemble_f1 0.79231
wandb:         train/mil_loss 1.77049
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run crisp-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lu8jtmb8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112726-lu8jtmb8/logs
wandb: ERROR Run lu8jtmb8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: u47jcnd4 with config:
wandb: 	actor_learning_rate: 1.7260353012441365e-05
wandb: 	attention_dropout_p: 0.42647724389064245
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.999434566468568
wandb: 	temperature: 6.356491465303029
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113033-u47jcnd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u47jcnd4
wandb: uploading history steps 131-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–‚â–…â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–„â–„â–…â–…â–ƒâ–‡â–†â–ƒâ–„â–„â–„â–„â–ˆâ–†â–â–…â–„â–…â–„â–ˆâ–ˆâ–…â–â–…â–…â–ƒâ–…â–…â–„â–…â–ƒâ–„â–†â–†â–„â–…â–…â–„
wandb:      eval/avg_mil_loss â–ƒâ–†â–„â–â–…â–‚â–ƒâ–„â–„â–‡â–ƒâ–…â–ƒâ–„â–ƒâ–…â–„â–…â–‚â–‚â–ˆâ–ƒâ–‚â–ƒâ–â–…â–„â–‡â–„â–„â–‚â–‡â–„â–ƒâ–ƒâ–ƒâ–‚â–…â–„â–„
wandb:       eval/ensemble_f1 â–…â–„â–‡â–…â–…â–ƒâ–â–…â–„â–…â–ƒâ–‡â–„â–ƒâ–„â–…â–†â–„â–†â–ˆâ–â–„â–…â–…â–„â–…â–„â–ƒâ–„â–„â–…â–„â–…â–ƒâ–†â–„â–„â–„â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‚â–â–†â–ƒâ–†â–†â–†â–‡â–†â–…â–ƒâ–…â–‚â–‚â–‡â–†â–‡â–„â–ƒâ–†â–ƒâ–ˆâ–†â–†â–‡â–…â–‡â–„â–‡â–ˆâ–‡â–†â–†â–†â–…â–‡â–…â–…â–‡
wandb:      train/ensemble_f1 â–‡â–†â–‚â–â–…â–ƒâ–†â–…â–…â–‡â–…â–†â–‡â–†â–ˆâ–ˆâ–ƒâ–…â–†â–…â–†â–‡â–†â–‡â–‡â–†â–ˆâ–ƒâ–…â–…â–…â–‡â–…â–ƒâ–‡â–‡â–…â–†â–„â–‡
wandb:         train/mil_loss â–…â–†â–…â–…â–…â–„â–‚â–‚â–ƒâ–†â–ˆâ–…â–„â–‚â–†â–…â–†â–„â–„â–†â–ƒâ–â–„â–‚â–†â–‚â–†â–‡â–ˆâ–„â–‚â–…â–‚â–…â–†â–…â–‚â–„â–†â–„
wandb:      train/policy_loss â–ˆâ–…â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–â–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–…â–…â–…â–â–â–ˆâ–…â–…â–…â–â–…â–ˆâ–…â–â–â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–ˆâ–„â–â–â–„â–â–„â–â–„â–â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–ˆâ–â–â–„â–ˆâ–„â–„â–ˆâ–„â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.41366
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79074
wandb:      eval/avg_mil_loss 0.49385
wandb:       eval/ensemble_f1 0.79074
wandb:            test/avg_f1 0.77225
wandb:      test/avg_mil_loss 0.49931
wandb:       test/ensemble_f1 0.77225
wandb:           train/avg_f1 0.79856
wandb:      train/ensemble_f1 0.79856
wandb:         train/mil_loss 0.97237
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run royal-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u47jcnd4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113033-u47jcnd4/logs
wandb: Agent Starting Run: 7qz7etct with config:
wandb: 	actor_learning_rate: 6.396679067789122e-05
wandb: 	attention_dropout_p: 0.4328019748566976
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 50
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6674384927087627
wandb: 	temperature: 9.130044299255776
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113318-7qz7etct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qz7etct
wandb: uploading wandb-summary.json
wandb: uploading history steps 39-50, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–ˆâ–ƒâ–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–â–„â–ƒâ–„â–„â–ƒâ–†â–†â–ƒâ–…â–„â–ƒâ–…â–ƒâ–ƒâ–…â–„â–†â–†â–„â–ˆâ–‚â–†â–ƒâ–†â–…â–„â–â–…â–†â–„â–„â–‚â–„â–„â–…â–†â–‚â–ƒâ–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–‚â–†â–„â–ƒâ–ƒâ–†â–‡â–‡â–‚â–„â–‚â–†â–†â–…â–â–…â–â–ƒâ–‚â–‡â–†â–†â–…â–ˆâ–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–„â–â–…â–†â–…â–…â–‡
wandb:       eval/ensemble_f1 â–„â–‚â–„â–„â–ƒâ–†â–†â–‚â–…â–ƒâ–‚â–…â–‚â–†â–ƒâ–…â–„â–†â–†â–„â–ˆâ–â–†â–ƒâ–†â–…â–„â–…â–…â–„â–„â–â–ƒâ–„â–…â–†â–‚â–ƒâ–ƒâ–ƒ
wandb:           train/avg_f1 â–ƒâ–„â–‡â–„â–…â–„â–„â–†â–ƒâ–‡â–ˆâ–ˆâ–„â–„â–…â–…â–„â–…â–…â–„â–ƒâ–„â–„â–…â–‡â–„â–…â–ƒâ–†â–†â–†â–‚â–ƒâ–â–ƒâ–…â–ƒâ–â–‡â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–‡â–„â–…â–„â–„â–†â–ƒâ–‡â–ˆâ–ˆâ–„â–„â–…â–„â–…â–…â–„â–â–„â–„â–„â–…â–‡â–„â–…â–ƒâ–†â–†â–†â–‚â–ƒâ–â–„â–‚â–…â–â–‡â–…
wandb:         train/mil_loss â–†â–…â–„â–…â–ƒâ–…â–‡â–ƒâ–…â–„â–„â–†â–†â–„â–ˆâ–ƒâ–…â–‡â–„â–…â–…â–…â–…â–…â–„â–‡â–â–…â–…â–ˆâ–‡â–ƒâ–‡â–„â–„â–†â–ƒâ–„â–ƒâ–‡
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.43301
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.78453
wandb:      eval/avg_mil_loss 0.53259
wandb:       eval/ensemble_f1 0.78453
wandb:           train/avg_f1 0.79581
wandb:      train/ensemble_f1 0.79581
wandb:         train/mil_loss 0.64689
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qz7etct
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113318-7qz7etct/logs
wandb: ERROR Run 7qz7etct errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1zz2ms6h with config:
wandb: 	actor_learning_rate: 0.0003171430341435999
wandb: 	attention_dropout_p: 0.2511303760481841
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6377816583732581
wandb: 	temperature: 0.6971902685262932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113431-1zz2ms6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zz2ms6h
wandb: uploading history steps 64-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‚â–…â–„â–‚â–ƒâ–„â–…â–„â–‚â–ˆâ–„â–ƒâ–â–‡â–„â–…â–…â–…â–…â–ˆâ–„â–‡â–…â–ˆâ–…â–„â–‡â–ƒâ–ƒâ–†â–…â–‚â–…â–„â–‚â–„â–„â–†â–„
wandb:      eval/avg_mil_loss â–ˆâ–…â–ˆâ–„â–…â–„â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–…â–…â–‡â–ƒâ–…â–„â–‡â–â–„â–„â–â–„â–â–„â–…â–ƒâ–„â–„â–…â–„â–‚â–†â–†â–‡â–…â–ƒâ–…â–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–‚â–„â–„â–„â–„â–‚â–…â–…â–‡â–„â–ƒâ–‚â–†â–â–„â–ƒâ–…â–…â–…â–„â–†â–„â–…â–„â–„â–…â–„â–†â–ƒâ–ƒâ–„â–…â–ˆâ–„â–‚â–…â–‚â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–†â–‚â–…â–„â–‡â–…â–†â–„â–â–…â–ƒâ–†â–†â–…â–†â–„â–ƒâ–†â–†â–ƒâ–‚â–‚â–„â–†â–†â–‚â–†â–ˆâ–ƒâ–…â–†â–„â–†â–‚â–„â–…â–„â–‚
wandb:      train/ensemble_f1 â–‡â–ƒâ–â–‡â–†â–†â–…â–…â–ˆâ–…â–‚â–„â–…â–†â–†â–…â–‡â–„â–…â–‡â–„â–„â–‡â–ƒâ–ƒâ–‡â–†â–ƒâ–‡â–…â–†â–†â–†â–‡â–â–…â–…â–…â–…â–ƒ
wandb:         train/mil_loss â–†â–†â–†â–†â–ˆâ–„â–ˆâ–„â–…â–‡â–…â–‡â–‡â–„â–†â–…â–ƒâ–ƒâ–…â–‡â–‚â–†â–…â–†â–…â–„â–‚â–„â–ƒâ–â–â–ƒâ–â–‡â–†â–†â–„â–„â–‚â–
wandb:      train/policy_loss â–…â–ˆâ–ˆâ–…â–â–ˆâ–…â–…â–…â–…â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–â–ˆâ–ˆâ–â–…â–â–â–…â–…â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83887
wandb: best/eval_avg_mil_loss 0.40383
wandb:  best/eval_ensemble_f1 0.83887
wandb:            eval/avg_f1 0.78791
wandb:      eval/avg_mil_loss 0.48409
wandb:       eval/ensemble_f1 0.78791
wandb:            test/avg_f1 0.72143
wandb:      test/avg_mil_loss 0.51444
wandb:       test/ensemble_f1 0.72143
wandb:           train/avg_f1 0.78492
wandb:      train/ensemble_f1 0.78492
wandb:         train/mil_loss 0.83567
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zz2ms6h
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113431-1zz2ms6h/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.237.4:38758->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 2m7kh7n7 with config:
wandb: 	actor_learning_rate: 0.00021634689368203207
wandb: 	attention_dropout_p: 0.39801730541160985
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7530687964902101
wandb: 	temperature: 8.598249097384103
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113622-2m7kh7n7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2m7kh7n7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–„â–‚â–‡â–…â–…â–„â–ƒâ–„â–â–„â–ƒâ–…â–‡â–ˆâ–‚â–‚â–‚â–ƒâ–â–„â–ƒâ–‚â–„â–…â–„â–…â–‚â–„â–‚â–„â–â–†â–„â–‡â–‚â–‡â–„â–‚â–†â–‡
wandb:      eval/avg_mil_loss â–…â–â–…â–…â–‡â–„â–ƒâ–„â–„â–†â–â–…â–â–â–…â–ƒâ–„â–…â–ƒâ–…â–ˆâ–ˆâ–„â–…â–‚â–†â–‚â–‚â–ƒâ–†â–ƒâ–‚â–†â–†â–†â–ƒâ–…â–‡â–‚â–‡
wandb:       eval/ensemble_f1 â–ˆâ–…â–‚â–ˆâ–‡â–†â–…â–‡â–†â–ƒâ–†â–ˆâ–†â–…â–ˆâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–…â–…â–„â–ˆâ–†â–ˆâ–„â–â–„â–…â–…â–â–â–„â–ƒâ–ˆâ–‚â–…â–ƒ
wandb:           train/avg_f1 â–†â–„â–ˆâ–…â–†â–…â–ƒâ–…â–„â–…â–ƒâ–ƒâ–â–‚â–„â–‚â–„â–ƒâ–†â–‡â–ƒâ–…â–‡â–†â–ƒâ–„â–…â–„â–„â–†â–†â–…â–„â–„â–…â–ƒâ–ƒâ–ˆâ–‡â–…
wandb:      train/ensemble_f1 â–„â–ˆâ–‚â–„â–„â–…â–ƒâ–…â–„â–…â–ƒâ–‚â–ƒâ–‡â–ƒâ–†â–‚â–‡â–ƒâ–ˆâ–„â–‚â–‚â–„â–„â–†â–‚â–„â–…â–‡â–…â–ƒâ–…â–ƒâ–‚â–â–…â–ˆâ–‡â–…
wandb:         train/mil_loss â–†â–…â–…â–…â–ƒâ–ˆâ–†â–‡â–‡â–„â–†â–‡â–…â–„â–„â–…â–†â–…â–…â–…â–ƒâ–„â–†â–†â–ƒâ–…â–„â–‡â–…â–„â–â–ƒâ–„â–„â–ƒâ–…â–„â–‚â–…â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86444
wandb: best/eval_avg_mil_loss 0.46935
wandb:  best/eval_ensemble_f1 0.86444
wandb:            eval/avg_f1 0.83197
wandb:      eval/avg_mil_loss 0.43522
wandb:       eval/ensemble_f1 0.83197
wandb:           train/avg_f1 0.79994
wandb:      train/ensemble_f1 0.79994
wandb:         train/mil_loss 1.77124
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run legendary-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2m7kh7n7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113622-2m7kh7n7/logs
wandb: ERROR Run 2m7kh7n7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xg2ha0r7 with config:
wandb: 	actor_learning_rate: 4.9116010226028515e-05
wandb: 	attention_dropout_p: 0.006057471123719349
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4432980385683328
wandb: 	temperature: 9.772311247050869
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113843-xg2ha0r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xg2ha0r7
wandb: uploading history steps 104-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–†â–…â–†â–‡â–„â–â–ˆâ–…â–†â–ƒâ–„â–„â–‚â–„â–„â–ƒâ–…â–†â–†â–…â–…â–ˆâ–„â–…â–„â–ƒâ–‡â–†â–‚â–„â–„â–‚â–…â–ƒâ–ƒâ–â–‚â–†
wandb:      eval/avg_mil_loss â–…â–‡â–‡â–…â–…â–…â–…â–„â–‡â–„â–†â–ƒâ–„â–ƒâ–„â–„â–…â–„â–†â–…â–â–‚â–„â–‡â–†â–„â–†â–â–†â–„â–„â–…â–†â–†â–…â–ˆâ–ƒâ–…â–†â–…
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–…â–â–†â–ƒâ–…â–†â–…â–„â–ƒâ–ˆâ–…â–„â–…â–†â–†â–…â–„â–…â–„â–…â–†â–ƒâ–â–…â–†â–…â–„â–…â–‡â–„â–‚â–„â–…â–â–†â–ƒâ–†â–…
wandb:           train/avg_f1 â–ƒâ–†â–„â–„â–„â–†â–ˆâ–…â–…â–ˆâ–†â–‡â–„â–ƒâ–…â–†â–„â–‚â–‡â–‚â–…â–„â–„â–„â–†â–…â–„â–†â–†â–†â–†â–„â–„â–…â–‡â–…â–†â–ƒâ–…â–
wandb:      train/ensemble_f1 â–…â–„â–„â–†â–†â–…â–…â–ƒâ–„â–ƒâ–‡â–…â–„â–ˆâ–„â–„â–„â–†â–„â–ƒâ–…â–„â–„â–„â–â–ƒâ–…â–â–ƒâ–…â–„â–„â–ƒâ–…â–„â–‚â–ƒâ–„â–ƒâ–‚
wandb:         train/mil_loss â–…â–‡â–†â–‡â–ˆâ–„â–†â–…â–…â–„â–„â–ˆâ–‡â–‡â–†â–†â–‡â–…â–…â–‚â–‡â–‡â–…â–…â–…â–„â–ƒâ–ƒâ–„â–„â–„â–…â–„â–ƒâ–â–ƒâ–‚â–„â–…â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–ˆâ–„â–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–â–„â–â–â–ˆâ–â–„â–â–„â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85289
wandb: best/eval_avg_mil_loss 0.39899
wandb:  best/eval_ensemble_f1 0.85289
wandb:            eval/avg_f1 0.80225
wandb:      eval/avg_mil_loss 0.46691
wandb:       eval/ensemble_f1 0.80225
wandb:           train/avg_f1 0.78401
wandb:      train/ensemble_f1 0.78401
wandb:         train/mil_loss 1.0205
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run soft-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xg2ha0r7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113843-xg2ha0r7/logs
wandb: ERROR Run xg2ha0r7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bmld7qb9 with config:
wandb: 	actor_learning_rate: 0.0004915588657792863
wandb: 	attention_dropout_p: 0.49008641585536344
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9153492703077404
wandb: 	temperature: 5.9804651261094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114118-bmld7qb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmld7qb9
wandb: uploading history steps 127-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–„â–ˆâ–ˆâ–‚â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–†â–â–…â–ƒâ–…â–…â–†â–ƒâ–‚â–†â–ˆâ–†â–…â–‡â–ˆâ–…â–ƒâ–†â–ƒâ–†â–‚â–†â–†â–…â–…â–‚â–ˆâ–†â–ƒâ–‡â–†â–…â–…â–‚â–…â–„â–†â–„
wandb:      eval/avg_mil_loss â–â–†â–ƒâ–„â–ˆâ–„â–†â–…â–…â–ƒâ–†â–‚â–„â–ƒâ–†â–…â–‚â–ƒâ–…â–„â–ƒâ–ƒâ–„â–ƒâ–‡â–„â–â–…â–„â–‡â–„â–„â–ƒâ–„â–ƒâ–…â–„â–†â–…â–‚
wandb:       eval/ensemble_f1 â–†â–‚â–…â–â–ƒâ–†â–†â–…â–†â–†â–†â–‚â–„â–„â–ƒâ–„â–†â–ƒâ–ƒâ–‡â–…â–†â–ƒâ–…â–‚â–†â–…â–ƒâ–ƒâ–ƒâ–…â–…â–…â–†â–†â–„â–†â–‡â–„â–ˆ
wandb:           train/avg_f1 â–…â–†â–…â–†â–„â–‡â–â–…â–„â–†â–…â–†â–…â–†â–…â–…â–‡â–†â–‡â–…â–‡â–…â–†â–†â–ƒâ–†â–†â–ƒâ–‡â–†â–†â–†â–…â–†â–ƒâ–†â–ˆâ–„â–†â–‡
wandb:      train/ensemble_f1 â–…â–ˆâ–ˆâ–…â–†â–‡â–â–„â–…â–‡â–†â–…â–†â–†â–…â–†â–ˆâ–…â–†â–†â–‡â–†â–‡â–ˆâ–…â–…â–„â–‡â–†â–†â–…â–„â–†â–ˆâ–†â–„â–†â–‡â–‡â–†
wandb:         train/mil_loss â–†â–…â–„â–†â–ˆâ–„â–‡â–ˆâ–ˆâ–†â–†â–…â–‡â–„â–†â–„â–…â–‡â–…â–†â–…â–…â–…â–â–†â–ƒâ–‡â–„â–…â–…â–‚â–…â–‡â–†â–…â–…â–‚â–„â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–â–…â–â–ˆâ–â–…â–ˆâ–…â–â–…â–ˆâ–ˆâ–…â–â–…â–ˆâ–â–…â–…â–…â–ˆâ–â–…â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–â–ˆâ–…â–ˆâ–â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–â–ˆâ–…â–â–ˆâ–…â–ˆâ–…â–…â–ˆâ–â–â–ˆâ–â–…â–â–…â–…â–…â–ˆâ–â–…â–ˆâ–â–â–…â–â–ˆâ–ˆâ–…â–…â–…â–…â–…â–ˆâ–â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.839
wandb: best/eval_avg_mil_loss 0.39762
wandb:  best/eval_ensemble_f1 0.839
wandb:            eval/avg_f1 0.8355
wandb:      eval/avg_mil_loss 0.42277
wandb:       eval/ensemble_f1 0.8355
wandb:           train/avg_f1 0.80078
wandb:      train/ensemble_f1 0.80078
wandb:         train/mil_loss 0.52389
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cosmic-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmld7qb9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114118-bmld7qb9/logs
wandb: ERROR Run bmld7qb9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: to09pela with config:
wandb: 	actor_learning_rate: 0.0001408134134789785
wandb: 	attention_dropout_p: 0.30193196026705876
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29868743261865005
wandb: 	temperature: 5.295504636595391
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114424-to09pela
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to09pela
wandb: uploading wandb-summary.json
wandb: uploading history steps 143-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–‚â–ƒâ–…â–…â–†â–„â–…â–„â–„â–ˆâ–ƒâ–„â–‡â–…â–…â–â–ƒâ–…â–„â–„â–‚â–ƒâ–ƒâ–„â–„â–‡â–†â–…â–‚â–„â–â–„â–„â–„â–ƒâ–„â–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–ƒâ–‡â–ƒâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–ƒâ–„â–…â–‡â–†â–…â–…â–â–ƒâ–‚â–„â–…â–…â–ˆâ–„â–„â–ƒâ–„â–„â–„â–„â–ˆâ–†â–‚â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–…â–†â–†â–„â–â–ˆâ–â–„â–†â–ˆâ–ˆâ–…â–â–…â–†â–ˆâ–†â–â–…â–â–‡â–‚â–…â–†â–ƒâ–‡â–‚â–ˆâ–ƒâ–…â–ƒâ–‡â–…â–â–„â–‡â–†â–…â–†
wandb:           train/avg_f1 â–ƒâ–ƒâ–â–‡â–†â–„â–‚â–†â–†â–‡â–†â–‚â–†â–…â–ƒâ–†â–…â–‡â–†â–‡â–ƒâ–‡â–„â–ƒâ–†â–…â–â–‡â–†â–‡â–…â–‚â–ƒâ–ƒâ–‡â–†â–‡â–ƒâ–…â–ˆ
wandb:      train/ensemble_f1 â–ƒâ–„â–‚â–„â–ƒâ–…â–…â–„â–ˆâ–„â–†â–…â–‡â–…â–‡â–‚â–…â–ƒâ–…â–†â–…â–‡â–…â–ƒâ–…â–…â–„â–‚â–…â–ƒâ–ƒâ–ˆâ–…â–â–†â–‡â–…â–„â–„â–‚
wandb:         train/mil_loss â–…â–…â–…â–‚â–ƒâ–…â–†â–†â–ƒâ–‡â–†â–„â–†â–„â–‡â–ƒâ–‚â–ƒâ–„â–†â–…â–ƒâ–‚â–ƒâ–ˆâ–…â–ƒâ–…â–…â–†â–‚â–ƒâ–„â–†â–„â–…â–†â–ƒâ–…â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83911
wandb: best/eval_avg_mil_loss 0.38961
wandb:  best/eval_ensemble_f1 0.83911
wandb:            eval/avg_f1 0.77274
wandb:      eval/avg_mil_loss 0.40714
wandb:       eval/ensemble_f1 0.77274
wandb:           train/avg_f1 0.81184
wandb:      train/ensemble_f1 0.81184
wandb:         train/mil_loss 0.83239
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run proud-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/to09pela
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114424-to09pela/logs
wandb: ERROR Run to09pela errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 566xln5z with config:
wandb: 	actor_learning_rate: 3.9197873240016366e-05
wandb: 	attention_dropout_p: 0.04287035086175056
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19566146978017052
wandb: 	temperature: 3.474112456244449
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114726-566xln5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/566xln5z
wandb: uploading wandb-summary.json; uploading history steps 40-52, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–…â–â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–„â–„â–‡â–„â–‡â–†â–†â–‡â–‡â–†â–†â–ˆâ–ˆâ–…â–‡â–†â–†â–…â–…â–‡â–‡â–†â–‡â–†â–‡â–…â–†â–†â–…â–…â–†â–‡â–â–‡â–†â–‡â–†
wandb:      eval/avg_mil_loss â–†â–‚â–ˆâ–…â–…â–…â–ˆâ–ƒâ–…â–„â–„â–„â–…â–„â–‡â–†â–â–„â–ƒâ–‡â–ƒâ–†â–…â–„â–‡â–…â–ƒâ–…â–ƒâ–„â–†â–„â–„â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–‡â–†â–„â–„â–‡â–„â–‡â–†â–†â–ˆâ–…â–‡â–†â–ƒâ–ˆâ–†â–‡â–†â–‡â–…â–‡â–‡â–†â–„â–†â–‡â–…â–†â–…â–…â–…â–†â–†â–†â–†â–â–‡â–‡â–†
wandb:           train/avg_f1 â–†â–…â–…â–†â–ƒâ–„â–ˆâ–‚â–„â–„â–â–†â–‡â–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–„â–†â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–…â–…â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–†â–†â–‡â–‡â–…â–ƒâ–‚â–„â–…â–â–ˆâ–…â–ƒâ–…â–†â–ƒâ–ƒâ–†â–…â–„â–ƒâ–ƒâ–†â–ƒâ–„â–…â–ƒâ–„â–‡â–„â–„â–„â–„â–„â–ƒâ–…â–†â–„â–„â–…
wandb:         train/mil_loss â–…â–†â–‚â–…â–ˆâ–…â–„â–â–ƒâ–ƒâ–†â–â–„â–‡â–„â–†â–‡â–„â–„â–…â–â–‚â–„â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–…â–ƒâ–‚â–†â–‚â–†â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.44515
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.79523
wandb:      eval/avg_mil_loss 0.43669
wandb:       eval/ensemble_f1 0.79523
wandb:           train/avg_f1 0.80146
wandb:      train/ensemble_f1 0.80146
wandb:         train/mil_loss 0.66426
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run splendid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/566xln5z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114726-566xln5z/logs
wandb: ERROR Run 566xln5z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qn720xor with config:
wandb: 	actor_learning_rate: 0.00035524435304393903
wandb: 	attention_dropout_p: 0.359669959844059
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5205948274922481
wandb: 	temperature: 5.6344762239915624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114833-qn720xor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qn720xor
wandb: uploading wandb-summary.json
wandb: uploading history steps 51-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–„â–†
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–…â–…â–†â–…â–‡â–ƒâ–…â–ƒâ–‚â–„â–â–„â–…â–ƒâ–ƒâ–„â–…â–‚â–…â–‚â–…â–…â–ƒâ–ˆâ–„â–„â–…â–â–ƒâ–â–ƒâ–…â–„â–ƒâ–„â–…â–…â–‚
wandb:      eval/avg_mil_loss â–…â–…â–…â–„â–ƒâ–†â–„â–ƒâ–…â–‚â–…â–…â–„â–‡â–„â–ƒâ–ƒâ–ƒâ–â–‡â–‚â–…â–…â–â–„â–„â–ƒâ–…â–…â–‚â–ˆâ–‚â–„â–…â–ˆâ–â–ƒâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–…â–ˆâ–ƒâ–†â–‡â–ˆâ–„â–…â–†â–‚â–„â–â–„â–†â–„â–ƒâ–„â–…â–†â–†â–„â–‚â–†â–†â–‡â–…â–„â–…â–‡â–â–‡â–ƒâ–â–ƒâ–†â–ƒâ–„â–…â–„â–„
wandb:           train/avg_f1 â–…â–„â–„â–ƒâ–…â–†â–‡â–‡â–‚â–ƒâ–…â–‡â–‡â–„â–†â–â–ƒâ–‚â–†â–…â–‡â–†â–„â–ƒâ–†â–…â–„â–â–„â–„â–ˆâ–ƒâ–…â–†â–†â–„â–‡â–…â–…â–ƒ
wandb:      train/ensemble_f1 â–„â–ƒâ–‚â–ƒâ–‚â–„â–†â–†â–…â–‚â–ƒâ–„â–„â–†â–†â–„â–â–ƒâ–ˆâ–…â–…â–…â–ƒâ–…â–…â–‚â–„â–â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–„â–‚
wandb:         train/mil_loss â–‚â–ƒâ–†â–„â–‚â–„â–ƒâ–‚â–„â–‡â–†â–‚â–„â–ƒâ–â–‚â–ƒâ–„â–…â–„â–‚â–…â–‚â–…â–ƒâ–„â–„â–ˆâ–ƒâ–†â–â–ƒâ–„â–‚â–ƒâ–â–„â–‚â–‚â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85363
wandb: best/eval_avg_mil_loss 0.45877
wandb:  best/eval_ensemble_f1 0.85363
wandb:            eval/avg_f1 0.78027
wandb:      eval/avg_mil_loss 0.49533
wandb:       eval/ensemble_f1 0.78027
wandb:           train/avg_f1 0.79088
wandb:      train/ensemble_f1 0.79088
wandb:         train/mil_loss 1.73677
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qn720xor
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114833-qn720xor/logs
wandb: ERROR Run qn720xor errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dw2qsrmp with config:
wandb: 	actor_learning_rate: 8.064001901344729e-06
wandb: 	attention_dropout_p: 0.4576596313405458
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7203802076841308
wandb: 	temperature: 1.9549080846968911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114951-dw2qsrmp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2qsrmp
wandb: uploading history steps 103-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–„â–â–„
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–„â–…â–‡â–„â–„â–ƒâ–‚â–†â–„â–…â–…â–„â–…â–„â–†â–‡â–ˆâ–…â–‡â–…â–†â–†â–†â–‚â–ƒâ–â–ˆâ–…â–„â–ƒâ–†â–…â–†â–‚â–ƒâ–„â–…
wandb:      eval/avg_mil_loss â–‡â–†â–…â–‡â–…â–‡â–…â–ˆâ–„â–„â–„â–ˆâ–†â–…â–†â–…â–…â–ˆâ–†â–…â–…â–…â–‚â–â–„â–†â–ƒâ–ƒâ–…â–ƒâ–†â–‡â–„â–…â–…â–„â–†â–ˆâ–„â–…
wandb:       eval/ensemble_f1 â–…â–†â–ƒâ–„â–…â–‡â–…â–…â–ƒâ–„â–‚â–…â–…â–ƒâ–„â–…â–„â–…â–…â–‚â–…â–ˆâ–†â–‡â–†â–†â–…â–‡â–ƒâ–‡â–…â–ƒâ–â–ˆâ–…â–†â–‚â–„â–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–ƒâ–†â–ƒâ–…â–„â–…â–‚â–ƒâ–„â–„â–„â–†â–…â–â–…â–ƒâ–„â–„â–‡â–ˆâ–ƒâ–â–‚â–â–…â–†â–ƒâ–…â–„â–„â–ˆâ–‡â–…â–ƒâ–â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–†â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–„â–ƒâ–„â–†â–ˆâ–„â–…â–„â–†â–‡â–‚â–…â–â–…â–…â–…â–ƒâ–…â–ˆâ–†â–‚â–†â–†â–ƒâ–…â–ƒâ–â–ƒâ–…â–…â–…
wandb:         train/mil_loss â–ƒâ–…â–ˆâ–„â–…â–„â–…â–…â–†â–…â–†â–†â–„â–…â–„â–„â–ƒâ–„â–†â–ƒâ–†â–‚â–†â–…â–‡â–…â–‡â–„â–…â–…â–…â–ƒâ–„â–„â–…â–ˆâ–ƒâ–…â–â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ˆâ–â–…â–â–…â–ˆâ–ˆâ–â–â–â–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–â–ˆâ–ˆâ–â–…â–â–â–â–â–â–…â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83872
wandb: best/eval_avg_mil_loss 0.44154
wandb:  best/eval_ensemble_f1 0.83872
wandb:            eval/avg_f1 0.76597
wandb:      eval/avg_mil_loss 0.49631
wandb:       eval/ensemble_f1 0.76597
wandb:            test/avg_f1 0.78891
wandb:      test/avg_mil_loss 0.49459
wandb:       test/ensemble_f1 0.78891
wandb:           train/avg_f1 0.79995
wandb:      train/ensemble_f1 0.79995
wandb:         train/mil_loss 0.9934
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run graceful-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2qsrmp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114951-dw2qsrmp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rws58g0f with config:
wandb: 	actor_learning_rate: 9.708523383978746e-06
wandb: 	attention_dropout_p: 0.07706330303167197
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20525116165155344
wandb: 	temperature: 2.437511719416958
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115255-rws58g0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rws58g0f
wandb: uploading history steps 142-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‡â–‡â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–…â–ƒâ–†â–â–…â–ƒâ–„â–„â–…â–â–…â–ƒâ–„â–†â–ˆâ–„â–„â–ƒâ–…â–„â–…â–†â–‚â–†â–†â–…â–‡â–„â–…â–„â–„â–„â–‡â–„â–‚â–ˆâ–…
wandb:      eval/avg_mil_loss â–…â–„â–†â–„â–„â–ƒâ–ƒâ–‚â–‡â–…â–‚â–…â–ˆâ–‚â–â–‚â–‚â–‡â–„â–…â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–„â–ƒâ–„â–…â–ƒâ–„â–…â–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–†â–‡â–ƒâ–†â–ƒâ–…â–…â–‚â–„â–‡â–‡â–…â–†â–‡â–ƒâ–ƒâ–†â–â–‡â–…â–‡â–†â–…â–†â–ˆâ–…â–…â–†â–„â–†â–‡â–ˆâ–„â–†â–‚â–†â–‚â–ƒ
wandb:           train/avg_f1 â–†â–…â–‡â–ƒâ–…â–‡â–„â–‡â–…â–…â–…â–†â–ƒâ–„â–†â–‚â–…â–†â–†â–†â–ˆâ–‡â–…â–‡â–„â–…â–…â–†â–…â–‚â–…â–…â–…â–„â–â–…â–…â–ƒâ–…â–†
wandb:      train/ensemble_f1 â–…â–‚â–„â–…â–ˆâ–…â–…â–ˆâ–…â–„â–…â–„â–…â–…â–‡â–‡â–…â–â–ƒâ–„â–…â–†â–†â–‡â–„â–†â–‡â–…â–…â–…â–…â–‡â–„â–…â–‡â–†â–…â–ƒâ–…â–†
wandb:         train/mil_loss â–„â–‚â–†â–…â–ƒâ–†â–ˆâ–…â–…â–„â–…â–†â–ƒâ–ƒâ–†â–â–„â–†â–…â–‡â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–‚â–ƒâ–„â–ƒâ–…â–†â–„â–„â–ƒ
wandb:      train/policy_loss â–„â–â–„â–„â–â–â–â–â–â–â–ˆâ–„â–„â–â–ˆâ–â–â–â–ˆâ–„â–„â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–„â–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84195
wandb: best/eval_avg_mil_loss 0.4123
wandb:  best/eval_ensemble_f1 0.84195
wandb:            eval/avg_f1 0.82458
wandb:      eval/avg_mil_loss 0.44659
wandb:       eval/ensemble_f1 0.82458
wandb:           train/avg_f1 0.80217
wandb:      train/ensemble_f1 0.80217
wandb:         train/mil_loss 0.8263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rws58g0f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115255-rws58g0f/logs
wandb: ERROR Run rws58g0f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: yohthy2v with config:
wandb: 	actor_learning_rate: 1.0063986890021735e-06
wandb: 	attention_dropout_p: 0.07621648635192729
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6902872670760987
wandb: 	temperature: 2.6471426918837637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115556-yohthy2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yohthy2v
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 127-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–„â–…â–†â–ƒâ–„â–†â–„â–‚â–ˆâ–…â–†â–â–„â–…â–ƒâ–…â–†â–„â–„â–‡â–ƒâ–…â–„â–…â–ƒâ–„â–…â–â–†â–†â–†â–‡â–…â–…â–ƒâ–†â–„â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–‚â–„â–„â–„â–„â–„â–…â–ƒâ–‚â–‚â–…â–ƒâ–„â–‚â–…â–…â–„â–‚â–ƒâ–…â–…â–„â–ƒâ–ƒâ–„â–â–†â–†â–ˆâ–ƒâ–‚â–„â–„â–…â–ƒâ–†â–‚
wandb:       eval/ensemble_f1 â–„â–‚â–„â–ƒâ–ˆâ–†â–„â–†â–„â–„â–â–„â–„â–…â–…â–„â–„â–„â–…â–…â–„â–„â–ƒâ–†â–â–†â–„â–†â–„â–„â–„â–…â–…â–†â–‡â–…â–†â–†â–„â–…
wandb:           train/avg_f1 â–â–…â–…â–„â–ˆâ–„â–„â–†â–†â–‡â–†â–„â–…â–†â–ƒâ–„â–ˆâ–ƒâ–‡â–„â–„â–‡â–ƒâ–‚â–„â–„â–‚â–ƒâ–ƒâ–„â–†â–‡â–…â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„
wandb:      train/ensemble_f1 â–†â–„â–…â–„â–†â–ˆâ–‡â–…â–†â–‡â–‡â–„â–†â–†â–‡â–…â–‡â–ƒâ–ƒâ–…â–„â–‡â–„â–ˆâ–‚â–†â–ƒâ–…â–‚â–â–†â–…â–†â–ˆâ–†â–†â–„â–†â–…â–†
wandb:         train/mil_loss â–ˆâ–„â–…â–…â–†â–…â–…â–„â–‚â–„â–†â–…â–†â–ƒâ–…â–‡â–…â–„â–ƒâ–„â–†â–†â–ˆâ–‚â–†â–‚â–…â–‚â–„â–„â–†â–„â–‡â–…â–„â–ƒâ–â–ƒâ–„â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86084
wandb: best/eval_avg_mil_loss 0.39617
wandb:  best/eval_ensemble_f1 0.86084
wandb:            eval/avg_f1 0.81689
wandb:      eval/avg_mil_loss 0.38823
wandb:       eval/ensemble_f1 0.81689
wandb:           train/avg_f1 0.80566
wandb:      train/ensemble_f1 0.80566
wandb:         train/mil_loss 1.67008
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yohthy2v
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115556-yohthy2v/logs
wandb: ERROR Run yohthy2v errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tj748om8 with config:
wandb: 	actor_learning_rate: 0.0008957230648063887
wandb: 	attention_dropout_p: 0.20556831295466388
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24065646661940976
wandb: 	temperature: 9.07892470762046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115841-tj748om8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tj748om8
wandb: uploading history steps 125-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–â–ƒâ–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–‡â–†â–â–‡â–„â–…â–…â–…â–ƒâ–…â–ˆâ–‚â–†â–‚â–„â–‚â–ƒâ–…â–…â–…â–‡â–…â–„â–„â–†â–ƒâ–ˆâ–„â–‡â–„â–ˆâ–†â–…â–„â–„â–…â–„â–ƒ
wandb:      eval/avg_mil_loss â–‡â–ƒâ–‚â–†â–ƒâ–…â–…â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–…â–…â–â–†â–†â–‚â–ˆâ–ƒâ–„â–ƒâ–†â–„â–‚â–„â–…â–ƒâ–â–†â–„â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–†
wandb:       eval/ensemble_f1 â–„â–ƒâ–…â–‚â–‚â–ˆâ–…â–…â–†â–…â–…â–ƒâ–‚â–â–„â–„â–…â–ˆâ–…â–†â–†â–ƒâ–†â–†â–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–‡â–ˆâ–†â–ƒâ–…â–…â–„â–ˆâ–†â–„
wandb:           train/avg_f1 â–…â–…â–ˆâ–„â–…â–ƒâ–…â–ƒâ–‚â–ƒâ–â–ƒâ–…â–‚â–„â–†â–‚â–‚â–ƒâ–ƒâ–â–„â–‚â–‚â–„â–†â–…â–„â–„â–†â–‚â–ƒâ–ƒâ–†â–‚â–„â–‚â–â–â–„
wandb:      train/ensemble_f1 â–‡â–„â–†â–‡â–…â–ƒâ–‡â–…â–‚â–…â–‚â–ƒâ–…â–‚â–…â–‡â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‡â–†â–„â–ƒâ–„â–„â–ˆâ–‡â–†â–‡â–‡â–…â–…â–…â–ƒâ–…â–â–„
wandb:         train/mil_loss â–„â–„â–„â–„â–†â–ˆâ–…â–„â–ƒâ–…â–‡â–„â–„â–…â–…â–„â–†â–„â–†â–„â–â–â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83837
wandb: best/eval_avg_mil_loss 0.43632
wandb:  best/eval_ensemble_f1 0.83837
wandb:            eval/avg_f1 0.78092
wandb:      eval/avg_mil_loss 0.45203
wandb:       eval/ensemble_f1 0.78092
wandb:           train/avg_f1 0.79469
wandb:      train/ensemble_f1 0.79469
wandb:         train/mil_loss 0.50863
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dutiful-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tj748om8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115841-tj748om8/logs
wandb: ERROR Run tj748om8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: j60apo51 with config:
wandb: 	actor_learning_rate: 5.669584278242621e-05
wandb: 	attention_dropout_p: 0.032594949661134964
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9001055361581723
wandb: 	temperature: 6.519042164853652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120137-j60apo51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j60apo51
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–…â–â–…â–â–‚â–‡â–†â–„â–„â–‡â–ƒâ–…â–„â–‡â–„â–…â–„â–‡â–„â–‚â–†â–„â–†â–„â–†â–…â–ˆâ–„â–„â–‚â–†â–…â–ˆâ–…â–‡â–â–ƒâ–†â–„
wandb:      eval/avg_mil_loss â–‚â–‡â–…â–…â–…â–ˆâ–…â–„â–†â–ƒâ–†â–„â–â–ƒâ–‡â–ƒâ–ƒâ–„â–ƒâ–ˆâ–…â–ƒâ–…â–†â–„â–„â–‚â–â–„â–â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–…â–„â–…â–…
wandb:       eval/ensemble_f1 â–„â–‚â–ƒâ–†â–†â–ƒâ–ƒâ–ƒâ–â–†â–ƒâ–†â–„â–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–â–„â–„â–„â–…â–‡â–†â–ƒâ–†â–„â–…â–†â–â–†â–ƒâ–‚â–‚â–„â–‚â–ƒ
wandb:           train/avg_f1 â–‡â–‚â–†â–‚â–â–…â–†â–„â–‡â–…â–ƒâ–„â–ƒâ–â–ƒâ–…â–ƒâ–‚â–†â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–…â–„â–ˆâ–„â–‚â–…â–…â–„â–ƒâ–†â–…â–…â–…â–‚
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–†â–…â–†â–…â–„â–„â–‡â–†â–ƒâ–‡â–‚â–…â–ƒâ–…â–ƒâ–‡â–…â–„â–„â–…â–…â–„â–â–…â–…â–…â–…â–„â–ˆâ–…â–„â–†â–„â–…â–„â–‡â–ƒ
wandb:         train/mil_loss â–†â–…â–‚â–ƒâ–…â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–„â–…â–„â–„â–†â–‚â–†â–‡â–ƒâ–ˆâ–‚â–„â–„â–‡â–ƒâ–ƒâ–„â–ƒâ–…â–‡â–â–‡â–‡â–†â–„â–â–„â–†â–‡â–„
wandb:      train/policy_loss â–…â–…â–ˆâ–…â–ˆâ–â–…â–…â–…â–â–ˆâ–…â–â–â–ˆâ–ˆâ–…â–…â–…â–…â–â–…â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–…â–â–…â–ˆâ–…â–ˆâ–…â–…â–â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–â–ˆâ–ˆâ–„â–„â–„â–â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–â–â–â–„â–â–„â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85373
wandb: best/eval_avg_mil_loss 0.38759
wandb:  best/eval_ensemble_f1 0.85373
wandb:            eval/avg_f1 0.79914
wandb:      eval/avg_mil_loss 0.46677
wandb:       eval/ensemble_f1 0.79914
wandb:           train/avg_f1 0.79843
wandb:      train/ensemble_f1 0.79843
wandb:         train/mil_loss 0.84915
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run noble-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j60apo51
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120137-j60apo51/logs
wandb: ERROR Run j60apo51 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: np59qy50 with config:
wandb: 	actor_learning_rate: 2.3730400557761267e-06
wandb: 	attention_dropout_p: 0.20110840832569857
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9264135842672416
wandb: 	temperature: 1.2360547974859892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120433-np59qy50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np59qy50
wandb: uploading history steps 104-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–ˆ
wandb:            eval/avg_f1 â–…â–…â–„â–„â–„â–‚â–„â–…â–„â–‚â–‚â–ƒâ–†â–…â–„â–…â–„â–†â–â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–ƒâ–…â–„â–„â–ƒâ–‚â–‚â–…â–ƒâ–…â–ƒâ–…â–„â–â–„â–„
wandb:      eval/avg_mil_loss â–‚â–‚â–…â–„â–â–…â–…â–„â–ƒâ–â–ƒâ–…â–…â–ƒâ–‚â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–â–„â–…â–ƒâ–…â–…â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–ƒâ–†â–†â–…â–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–…â–‡â–„â–„â–…â–„â–‚â–„â–ƒâ–…â–†â–„â–…â–„â–‚â–…â–…â–„â–†â–â–„â–„â–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–†â–…â–†â–†â–…â–‚â–‚â–â–„â–‚
wandb:           train/avg_f1 â–†â–…â–…â–ˆâ–‡â–…â–ƒâ–…â–â–„â–†â–†â–„â–†â–…â–ˆâ–ƒâ–ˆâ–…â–†â–†â–…â–†â–‡â–†â–„â–ƒâ–†â–„â–…â–†â–…â–†â–†â–ƒâ–…â–…â–†â–…â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–†â–†â–ˆâ–…â–„â–†â–…â–…â–â–…â–†â–ˆâ–…â–„â–…â–ƒâ–‡â–‡â–„â–‡â–†â–„â–‡â–…â–ƒâ–‚â–†â–†â–†â–ƒâ–ƒâ–†â–†â–„â–‚â–…â–…â–„â–„
wandb:         train/mil_loss â–ˆâ–„â–…â–ƒâ–†â–…â–‡â–ƒâ–…â–‡â–‡â–ƒâ–…â–ƒâ–â–…â–„â–„â–„â–â–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–„â–ƒâ–â–‚â–‚â–„â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–‚
wandb:      train/policy_loss â–ˆâ–…â–…â–â–â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–…â–…â–…â–ˆâ–…â–â–…â–ˆâ–…â–â–ˆâ–…â–…â–â–â–â–…â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–ˆâ–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84979
wandb: best/eval_avg_mil_loss 0.37356
wandb:  best/eval_ensemble_f1 0.84979
wandb:            eval/avg_f1 0.79492
wandb:      eval/avg_mil_loss 0.4581
wandb:       eval/ensemble_f1 0.79492
wandb:           train/avg_f1 0.78648
wandb:      train/ensemble_f1 0.78648
wandb:         train/mil_loss 1.55026
wandb:      train/policy_loss 0.46391
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.46391
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/np59qy50
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120433-np59qy50/logs
wandb: ERROR Run np59qy50 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: rme4kynf with config:
wandb: 	actor_learning_rate: 1.7979723582273274e-06
wandb: 	attention_dropout_p: 0.4081120796257889
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06777522420390436
wandb: 	temperature: 7.631636938866009
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120653-rme4kynf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rme4kynf
wandb: uploading history steps 92-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–‡â–„â–ƒâ–…â–ƒâ–‡â–„â–„â–„â–†â–†â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–…â–†â–…â–…â–ƒâ–ƒâ–â–ƒâ–†â–„â–â–ˆâ–ƒâ–ˆâ–„â–†â–ƒâ–„â–ƒâ–‡â–‡
wandb:      eval/avg_mil_loss â–‚â–‚â–ˆâ–…â–„â–„â–ƒâ–†â–â–ƒâ–‚â–„â–„â–…â–…â–†â–ƒâ–†â–ˆâ–…â–ƒâ–…â–ƒâ–…â–ˆâ–…â–„â–†â–†â–…â–†â–ƒâ–‚â–‚â–…â–ˆâ–…â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–†â–…â–â–ƒâ–†â–ƒâ–‡â–…â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–ƒâ–†â–ƒâ–†â–…â–†â–…â–…â–†â–‚â–ƒâ–â–†â–…â–…â–ƒâ–ˆâ–…â–„â–…â–„â–‡â–„â–â–†
wandb:           train/avg_f1 â–â–†â–„â–†â–…â–†â–ƒâ–„â–…â–ƒâ–…â–ˆâ–†â–…â–…â–‚â–ƒâ–„â–„â–†â–…â–…â–‚â–ƒâ–†â–„â–„â–„â–ƒâ–‡â–ˆâ–ƒâ–‡â–„â–‡â–„â–ƒâ–†â–„â–…
wandb:      train/ensemble_f1 â–‡â–ƒâ–…â–†â–…â–‡â–†â–†â–†â–„â–…â–ˆâ–†â–‡â–ˆâ–ƒâ–†â–ƒâ–‚â–…â–„â–†â–†â–†â–ƒâ–†â–‡â–‡â–…â–…â–‡â–‡â–†â–‡â–‡â–…â–†â–ˆâ–‡â–
wandb:         train/mil_loss â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–…â–„â–…â–‚â–†â–†â–„â–„â–‚â–ƒâ–â–„â–…â–„â–†â–„â–†â–ƒâ–ƒâ–„â–„â–„â–‡â–†â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–†â–‡â–†
wandb:      train/policy_loss â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–â–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–„â–„â–â–â–„â–â–„â–„â–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–ˆâ–ˆâ–â–„â–ˆâ–„â–ˆâ–„â–â–„â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83566
wandb: best/eval_avg_mil_loss 0.41726
wandb:  best/eval_ensemble_f1 0.83566
wandb:            eval/avg_f1 0.81331
wandb:      eval/avg_mil_loss 0.4348
wandb:       eval/ensemble_f1 0.81331
wandb:           train/avg_f1 0.78735
wandb:      train/ensemble_f1 0.78735
wandb:         train/mil_loss 0.96757
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dazzling-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rme4kynf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120653-rme4kynf/logs
wandb: ERROR Run rme4kynf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 624, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_ilse.py", line 563, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_ilse:
wandb: ERROR 	Missing key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ucju3ny6 with config:
wandb: 	actor_learning_rate: 1.2323572872089547e-05
wandb: 	attention_dropout_p: 0.28900285778086604
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4397813910170526
wandb: 	temperature: 9.905731190790116
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120912-ucju3ny6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucju3ny6
wandb: uploading history steps 114-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–†
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–‡â–…â–‡â–ˆâ–…â–…â–„â–†â–…â–„â–†â–…â–…â–„â–…â–†â–„â–ƒâ–„â–â–†â–„â–†â–…â–†â–†â–‚â–‡â–†â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–…â–…
wandb:      eval/avg_mil_loss â–‚â–„â–â–…â–†â–„â–‚â–…â–‡â–…â–…â–‡â–…â–…â–…â–„â–…â–ƒâ–„â–…â–â–„â–ƒâ–†â–†â–‡â–†â–†â–„â–„â–„â–„â–…â–†â–ˆâ–„â–†â–‡â–„â–†
wandb:       eval/ensemble_f1 â–‡â–„â–„â–…â–„â–…â–…â–†â–…â–…â–ˆâ–…â–‡â–†â–…â–…â–‡â–…â–‡â–„â–„â–„â–…â–ˆâ–†â–…â–ˆâ–†â–†â–†â–„â–‡â–‡â–â–„â–†â–„â–‡â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–â–ƒâ–ˆâ–„â–‡â–…â–ƒâ–†â–‚â–ƒâ–„â–ƒâ–„â–…â–ƒâ–…â–†â–ƒâ–ˆâ–„â–ƒâ–„â–…â–ƒâ–†â–†â–‚â–†â–„â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–†â–„
wandb:      train/ensemble_f1 â–‚â–ˆâ–‡â–†â–†â–‡â–ƒâ–„â–ˆâ–„â–†â–†â–…â–‡â–„â–‡â–„â–„â–„â–ƒâ–†â–ƒâ–…â–‡â–…â–…â–„â–ˆâ–…â–ƒâ–„â–â–„â–…â–‚â–…â–…â–†â–‡â–†
wandb:         train/mil_loss â–„â–…â–‡â–ˆâ–‡â–‡â–‡â–…â–…â–…â–ˆâ–†â–…â–…â–…â–†â–†â–…â–‡â–…â–ƒâ–†â–…â–…â–„â–ƒâ–†â–ƒâ–„â–ƒâ–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83571
wandb: best/eval_avg_mil_loss 0.41435
wandb:  best/eval_ensemble_f1 0.83571
wandb:            eval/avg_f1 0.80291
wandb:      eval/avg_mil_loss 0.46798
wandb:       eval/ensemble_f1 0.80291
wandb:            test/avg_f1 0.76541
wandb:      test/avg_mil_loss 0.55479
wandb:       test/ensemble_f1 0.76541
wandb:           train/avg_f1 0.79593
wandb:      train/ensemble_f1 0.79593
wandb:         train/mil_loss 1.71852
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run decent-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucju3ny6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120912-ucju3ny6/logs
wandb: Agent Starting Run: fu4rjp6z with config:
wandb: 	actor_learning_rate: 7.513378626992665e-05
wandb: 	attention_dropout_p: 0.10602774871258148
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3098368165004557
wandb: 	temperature: 7.538445805616156
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121158-fu4rjp6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu4rjp6z
wandb: uploading history steps 172-179, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–†â–‡â–„â–‚â–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–‚â–‡â–ƒâ–â–‡â–â–…â–„â–…â–†â–…â–…â–†â–…â–‡â–„â–„â–†â–ƒâ–†â–‡â–…â–…â–„â–„â–†â–‚â–ƒâ–ƒâ–„â–ˆâ–†â–…â–ƒâ–…â–„â–‚â–ƒâ–…
wandb:      eval/avg_mil_loss â–…â–†â–†â–‡â–…â–ƒâ–ƒâ–…â–†â–…â–†â–„â–ƒâ–†â–…â–„â–†â–ƒâ–…â–ƒâ–…â–ˆâ–„â–‚â–„â–ƒâ–…â–ƒâ–‚â–â–ƒâ–‡â–…â–ƒâ–„â–…â–‚â–…â–â–„
wandb:       eval/ensemble_f1 â–…â–†â–ƒâ–…â–†â–†â–‚â–…â–„â–ˆâ–…â–„â–…â–‚â–†â–…â–†â–†â–†â–…â–…â–…â–†â–…â–â–…â–‡â–‡â–†â–„â–ƒâ–…â–„â–…â–„â–„â–‚â–…â–„â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–„â–ƒâ–ƒâ–ˆâ–„â–‚â–â–ƒâ–…â–ƒâ–â–…â–‚â–…â–†â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–…â–„â–„
wandb:      train/ensemble_f1 â–„â–ƒâ–ˆâ–‚â–„â–‚â–„â–ƒâ–â–„â–‚â–„â–‚â–„â–„â–…â–„â–„â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–‚â–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–…â–‚â–‚â–‚â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–†â–…â–‡â–…â–‡â–†â–…â–„â–„â–…â–„â–„â–ƒâ–ƒâ–†â–…â–†â–†â–„â–ƒâ–…â–…â–‚â–„â–†â–†â–„â–ƒâ–â–…â–†â–‚â–„â–„â–‚â–ƒâ–„â–ƒâ–‡
wandb:      train/policy_loss â–â–â–ˆâ–ˆâ–…â–…â–ˆâ–…â–â–ˆâ–ˆâ–…â–ˆâ–…â–…â–â–…â–ˆâ–…â–ˆâ–ˆâ–…â–â–ˆâ–â–…â–…â–…â–…â–…â–â–â–ˆâ–…â–ˆâ–â–…â–ˆâ–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–…â–â–…â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–â–…â–ˆâ–â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–â–ˆâ–ˆâ–â–â–â–…â–ˆâ–â–â–ˆâ–â–…â–ˆâ–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84281
wandb: best/eval_avg_mil_loss 0.41286
wandb:  best/eval_ensemble_f1 0.84281
wandb:            eval/avg_f1 0.77701
wandb:      eval/avg_mil_loss 0.51132
wandb:       eval/ensemble_f1 0.77701
wandb:            test/avg_f1 0.77485
wandb:      test/avg_mil_loss 0.52183
wandb:       test/ensemble_f1 0.77485
wandb:           train/avg_f1 0.80673
wandb:      train/ensemble_f1 0.80673
wandb:         train/mil_loss 0.59589
wandb:      train/policy_loss -0.12498
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.12498
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fu4rjp6z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121158-fu4rjp6z/logs
wandb: Agent Starting Run: 86wgu7uc with config:
wandb: 	actor_learning_rate: 0.0007334296893241583
wandb: 	attention_dropout_p: 0.327322112412064
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2999772007007121
wandb: 	temperature: 4.012646296956399
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121556-86wgu7uc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/1symfx94
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86wgu7uc
wandb: uploading history steps 127-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–â–‚â–…â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–†â–…â–„â–â–„â–„â–„â–†â–‡â–†â–„â–†â–…â–‚â–ƒâ–ƒâ–…â–…â–‡â–ƒâ–†â–‚â–†â–…â–„â–ˆâ–„â–…â–„â–†â–„â–‚â–ˆâ–…â–„â–…â–‡â–…
wandb:      eval/avg_mil_loss â–„â–‚â–„â–†â–‚â–ƒâ–…â–‚â–…â–†â–ƒâ–‚â–…â–ƒâ–ƒâ–…â–„â–†â–…â–†â–„â–‚â–…â–…â–ˆâ–…â–„â–„â–…â–ƒâ–ƒâ–„â–â–„â–…â–„â–„â–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–†â–„â–„â–„â–…â–…â–ƒâ–„â–…â–†â–„â–‡â–…â–†â–„â–…â–…â–â–â–…â–ƒâ–…â–‡â–ƒâ–„â–‡â–…â–…â–„â–„â–…â–„â–ˆâ–ˆâ–„â–„â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–†â–…â–…â–†â–†â–„â–†â–‡â–ˆâ–†â–‡â–‡â–„â–„â–†â–†â–„â–ƒâ–†â–ƒâ–…â–†â–†â–‡â–„â–„â–†â–†â–‚â–‚â–†â–ˆâ–„â–â–„â–„â–†â–†
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–…â–‚â–ƒâ–„â–„â–„â–…â–†â–ƒâ–‚â–‡â–ˆâ–…â–‡â–„â–…â–…â–…â–…â–„â–…â–‡â–‚â–ƒâ–„â–†â–…â–…â–…â–â–â–„â–ƒâ–‡â–ƒâ–…â–…
wandb:         train/mil_loss â–„â–†â–†â–„â–‡â–…â–ˆâ–†â–„â–…â–‡â–…â–„â–…â–‡â–‡â–…â–‡â–†â–†â–…â–†â–ƒâ–…â–â–…â–†â–…â–…â–…â–„â–…â–‡â–„â–ƒâ–‡â–…â–…â–„â–‡
wandb:      train/policy_loss â–„â–â–ˆâ–â–„â–â–â–ˆâ–„â–„â–„â–â–„â–„â–â–„â–ˆâ–ˆâ–ˆâ–„â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–â–â–â–„â–ˆâ–„â–â–„â–ˆâ–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–â–ˆâ–ˆâ–â–â–â–ˆâ–…â–ˆâ–…â–ˆâ–â–â–ˆâ–â–ˆâ–…â–â–ˆâ–ˆâ–ˆâ–…â–â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–â–â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83796
wandb: best/eval_avg_mil_loss 0.41254
wandb:  best/eval_ensemble_f1 0.83796
wandb:            eval/avg_f1 0.80495
wandb:      eval/avg_mil_loss 0.45059
wandb:       eval/ensemble_f1 0.80495
wandb:            test/avg_f1 0.77225
wandb:      test/avg_mil_loss 0.49896
wandb:       test/ensemble_f1 0.77225
wandb:           train/avg_f1 0.79863
wandb:      train/ensemble_f1 0.79863
wandb:         train/mil_loss 0.93991
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run true-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/86wgu7uc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121556-86wgu7uc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
