wandb: Agent Starting Run: tmghv61g with config:
wandb: 	actor_learning_rate: 8.183053463181886e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9061640147326836
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041753-tmghv61g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmghv61g
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 186-197, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–ˆâ–ˆâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–‚â–„â–ƒâ–ˆâ–ƒâ–‡â–„â–„â–ƒâ–ƒâ–„â–…â–„â–ƒâ–‚â–‡â–„â–…â–†â–‡â–â–ˆâ–‚â–„â–â–…â–…â–†â–ƒâ–„â–‡â–…â–‡â–ˆâ–…â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–…â–…â–ƒâ–ˆâ–ƒâ–„â–…â–‚â–‚â–„â–ƒâ–„â–ƒâ–„â–„â–…â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–†
wandb:       eval/ensemble_f1 â–ƒâ–…â–ˆâ–‡â–„â–â–„â–„â–„â–…â–„â–ˆâ–…â–„â–„â–‡â–â–„â–â–„â–…â–…â–„â–†â–„â–…â–„â–…â–„â–ˆâ–…â–‡â–„â–‡â–‡â–‡â–…â–…â–…â–‡
wandb:           train/avg_f1 â–‡â–‚â–„â–„â–ƒâ–„â–„â–â–„â–‚â–‡â–„â–‚â–…â–…â–â–„â–‚â–†â–…â–ƒâ–…â–â–ƒâ–…â–…â–†â–„â–ˆâ–ˆâ–„â–â–‡â–ƒâ–„â–„â–…â–…â–„â–‡
wandb:      train/ensemble_f1 â–„â–‚â–ƒâ–…â–‚â–‚â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‚â–‚â–„â–‡â–â–…â–‡â–†â–‡â–ˆâ–„â–…â–ƒâ–„â–…â–„â–…â–„â–‡â–„â–„â–„â–†â–…â–‡â–†â–
wandb:         train/mil_loss â–…â–†â–‚â–‡â–…â–†â–‚â–ƒâ–„â–â–„â–†â–†â–„â–„â–…â–ƒâ–‚â–…â–ƒâ–‡â–ƒâ–…â–‚â–†â–„â–ƒâ–ƒâ–†â–â–â–‚â–„â–ˆâ–ƒâ–ƒâ–ƒâ–…â–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83697
wandb: best/eval_avg_mil_loss 0.79615
wandb:  best/eval_ensemble_f1 0.83697
wandb:            eval/avg_f1 0.74571
wandb:      eval/avg_mil_loss 0.90628
wandb:       eval/ensemble_f1 0.74571
wandb:           train/avg_f1 0.73874
wandb:      train/ensemble_f1 0.73874
wandb:         train/mil_loss 0.65097
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmghv61g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041753-tmghv61g/logs
wandb: ERROR Run tmghv61g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8sc5dms7 with config:
wandb: 	actor_learning_rate: 3.128973254728881e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7228414776924362
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042119-8sc5dms7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sc5dms7
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–…â–†â–ˆâ–ˆâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‡â–„â–‡â–ƒâ–†â–„â–‡â–‡â–‡â–ƒâ–â–†â–…â–…â–ˆâ–‡â–†â–†â–„â–ˆâ–‡â–†â–…â–†â–ˆâ–„â–ƒâ–…â–‡â–„â–‡â–„â–„â–ƒâ–…â–â–ˆâ–‚
wandb:      eval/avg_mil_loss â–…â–„â–†â–ƒâ–‚â–†â–ƒâ–â–…â–…â–ƒâ–„â–‡â–…â–…â–‡â–‚â–â–†â–†â–â–ƒâ–„â–‚â–â–„â–„â–ƒâ–…â–…â–‡â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–â–„â–„â–‡â–…â–ƒâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–„â–‡â–†â–ˆâ–‡â–„â–ˆâ–„â–†â–†â–†â–‡â–†â–†â–†â–ˆâ–„â–‡â–ƒâ–‡â–ƒâ–†â–„â–„â–†â–…â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‚â–„â–ƒâ–â–‡â–…â–‡â–„â–…â–…â–†â–†â–„â–‚â–ƒâ–â–‡â–†â–ˆâ–†â–†â–†â–‡â–†â–…â–„â–„â–‚â–‚â–ˆâ–‡â–…â–‡â–†â–„â–„â–†â–„
wandb:      train/ensemble_f1 â–…â–…â–…â–…â–‡â–‚â–…â–…â–ƒâ–ƒâ–â–„â–†â–„â–ƒâ–…â–†â–†â–†â–†â–„â–…â–â–‡â–†â–ˆâ–‡â–ƒâ–†â–†â–ˆâ–‡â–†â–…â–…â–†â–„â–ˆâ–‚â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–†â–ƒâ–„â–‚â–„â–„â–ƒâ–†â–„â–‚â–ˆâ–„â–ƒâ–‚â–…â–…â–…â–â–â–â–ƒâ–„â–…â–…â–†â–ƒâ–…â–„â–…â–ƒâ–ƒâ–„â–‚â–„â–…â–…â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77262
wandb: best/eval_avg_mil_loss 0.76713
wandb:  best/eval_ensemble_f1 0.77262
wandb:            eval/avg_f1 0.43827
wandb:      eval/avg_mil_loss 0.95597
wandb:       eval/ensemble_f1 0.43827
wandb:            test/avg_f1 0.55253
wandb:      test/avg_mil_loss 0.84701
wandb:       test/ensemble_f1 0.55253
wandb:           train/avg_f1 0.61737
wandb:      train/ensemble_f1 0.61737
wandb:         train/mil_loss 0.96808
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sc5dms7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042119-8sc5dms7/logs
wandb: Agent Starting Run: y9yczkmc with config:
wandb: 	actor_learning_rate: 0.0004093592216090446
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14269761607415243
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042302-y9yczkmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9yczkmc
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–‡â–‚â–…â–ƒâ–â–‚â–‡â–ƒâ–‚â–…â–‡â–‚â–…â–…â–†â–„â–„â–„â–ƒâ–ˆâ–„â–…â–‚â–ƒâ–„â–†â–…â–…â–†â–ˆâ–…â–…â–‡
wandb:      eval/avg_mil_loss â–†â–…â–„â–†â–ˆâ–…â–„â–ƒâ–‡â–„â–†â–ƒâ–…â–â–…â–‚â–„â–‡â–„â–…â–„â–„â–ƒâ–„â–ƒâ–‡â–„â–…â–„â–„â–„â–„â–†â–„â–„â–…â–ƒâ–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–ƒâ–„â–„â–â–‚â–‚â–‡â–‚â–…â–„â–‡â–†â–ƒâ–‚â–„â–‚â–ƒâ–…â–†â–„â–†â–„â–„â–„â–ˆâ–…â–„â–â–‚â–†â–…â–…â–ˆâ–†â–„â–†â–â–„â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–â–‚â–…â–…â–…â–…â–„â–„â–…â–†â–…â–„â–„â–„â–…â–â–„â–…â–†â–„â–…â–„â–†â–‡â–ˆâ–†â–†â–…â–‡â–…â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–â–‚â–…â–„â–…â–„â–ƒâ–…â–„â–…â–…â–ƒâ–„â–…â–…â–„â–…â–„â–„â–…â–â–„â–„â–…â–„â–ˆâ–†â–†â–†â–†â–…â–‡â–ˆâ–ˆ
wandb:         train/mil_loss â–‡â–…â–…â–ˆâ–…â–…â–…â–‡â–„â–„â–†â–„â–…â–ƒâ–ƒâ–„â–†â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–…â–„â–‚â–„â–‚â–…â–„â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb:      train/policy_loss â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–„â–†â–…â–…â–„â–…â–…â–ƒâ–…â–…â–…â–…â–„â–ˆâ–…â–…â–…â–ƒâ–…â–…â–…â–â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77923
wandb: best/eval_avg_mil_loss 0.68143
wandb:  best/eval_ensemble_f1 0.77923
wandb:            eval/avg_f1 0.76999
wandb:      eval/avg_mil_loss 0.6585
wandb:       eval/ensemble_f1 0.76999
wandb:            test/avg_f1 0.79078
wandb:      test/avg_mil_loss 0.49598
wandb:       test/ensemble_f1 0.79078
wandb:           train/avg_f1 0.75844
wandb:      train/ensemble_f1 0.75844
wandb:         train/mil_loss 0.58513
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9yczkmc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042302-y9yczkmc/logs
wandb: Agent Starting Run: do0wxj9u with config:
wandb: 	actor_learning_rate: 0.0004436808120775917
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14399557390090223
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042425-do0wxj9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/do0wxj9u
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 91-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–ˆâ–ˆâ–†â–‡
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–ˆâ–…â–ˆâ–„â–†â–‡â–…â–†â–†â–…â–ˆâ–†â–ƒâ–†â–†â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–ƒâ–…â–„â–…â–„â–…â–…â–†â–…â–†â–†â–…â–†â–‡â–â–†â–…
wandb:      eval/avg_mil_loss â–„â–…â–…â–‡â–‚â–ƒâ–ƒâ–ƒâ–â–†â–†â–„â–ƒâ–‚â–â–ˆâ–ƒâ–ˆâ–„â–†â–‚â–‚â–‚â–‚â–…â–…â–„â–‚â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‡â–â–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–â–„â–…â–„â–ƒâ–…â–‡â–„â–ˆâ–…â–†â–†â–ƒâ–…â–‡â–ˆâ–â–ƒâ–â–„â–†â–ˆâ–…â–†â–‚â–ˆâ–…â–„â–…â–„â–†â–…â–†â–†â–†â–…â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–„â–…â–†â–ƒâ–„â–†â–…â–…â–…â–…â–…â–…â–ƒâ–„â–„â–„â–…â–‚â–„â–ˆâ–†â–†â–†â–ƒâ–‡â–†â–â–…â–‡â–…â–ƒâ–†â–…â–…â–…â–ƒâ–„â–…
wandb:      train/ensemble_f1 â–ˆâ–‡â–…â–„â–…â–†â–‡â–‚â–†â–†â–†â–…â–ˆâ–†â–†â–†â–†â–ƒâ–ƒâ–‚â–†â–„â–â–„â–„â–„â–‡â–ˆâ–…â–ƒâ–…â–ˆâ–†â–…â–ƒâ–†â–…â–‡â–„â–†
wandb:         train/mil_loss â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–†â–ƒâ–ƒâ–„â–ˆâ–„â–…â–â–„â–„â–â–‚â–„â–‚â–„â–‚â–…â–…â–„â–„â–‚â–‚â–ƒâ–…â–‚â–„â–â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82127
wandb: best/eval_avg_mil_loss 1.0712
wandb:  best/eval_ensemble_f1 0.82127
wandb:            eval/avg_f1 0.73644
wandb:      eval/avg_mil_loss 0.903
wandb:       eval/ensemble_f1 0.73644
wandb:            test/avg_f1 0.86435
wandb:      test/avg_mil_loss 0.67687
wandb:       test/ensemble_f1 0.86435
wandb:           train/avg_f1 0.7395
wandb:      train/ensemble_f1 0.7395
wandb:         train/mil_loss 0.86423
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/do0wxj9u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042425-do0wxj9u/logs
wandb: Agent Starting Run: ze1lcut0 with config:
wandb: 	actor_learning_rate: 2.8741824090481746e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13324131499936165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042603-ze1lcut0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ze1lcut0
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–‚â–„â–â–†â–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–‡â–„â–†â–†â–…â–‡â–„â–…â–ƒâ–†â–â–…â–‡â–†â–…â–…â–‡â–‡â–†â–‡â–…â–‚â–…â–…â–â–‚â–†â–†â–†â–†â–„â–†â–…â–‡â–„â–ƒâ–ˆâ–†
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ƒâ–â–ƒâ–ˆâ–†â–„â–„â–ƒâ–‚â–…â–„â–„â–†â–„â–†â–„â–ƒâ–‚â–…â–ƒâ–…â–„â–ƒâ–‚â–‡â–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–â–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–†â–…â–…â–†â–†â–‡â–ƒâ–†â–…â–„â–…â–‚â–ˆâ–‡â–…â–â–…â–†â–…â–„â–…â–‡â–‡â–…â–ƒâ–†â–ƒâ–ƒâ–†â–‡â–‡â–‡â–†â–†â–ˆâ–‡â–‚â–†â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–‚â–‡â–†â–…â–…â–†â–†â–„â–…â–‡â–â–ƒâ–„â–…â–†â–‡â–‡â–ƒâ–…â–†â–„â–‡â–†â–†â–‡â–…â–ˆâ–†â–ƒâ–…â–‡â–„â–…â–…â–‡â–…â–‡â–ˆâ–†
wandb:      train/ensemble_f1 â–â–„â–ƒâ–†â–…â–…â–…â–…â–…â–†â–‚â–‡â–ƒâ–ˆâ–…â–†â–†â–â–ƒâ–†â–†â–„â–„â–†â–†â–…â–…â–…â–â–„â–‚â–†â–…â–„â–„â–‚â–‡â–…â–‡â–†
wandb:         train/mil_loss â–…â–…â–„â–…â–†â–…â–…â–…â–‡â–„â–‡â–â–ˆâ–„â–ˆâ–„â–…â–„â–†â–‡â–…â–ƒâ–…â–„â–„â–…â–‡â–‚â–…â–…â–ƒâ–†â–†â–…â–ƒâ–ƒâ–„â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–ˆâ–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79697
wandb: best/eval_avg_mil_loss 0.77449
wandb:  best/eval_ensemble_f1 0.79697
wandb:            eval/avg_f1 0.67853
wandb:      eval/avg_mil_loss 0.68924
wandb:       eval/ensemble_f1 0.67853
wandb:            test/avg_f1 0.85203
wandb:      test/avg_mil_loss 0.5477
wandb:       test/ensemble_f1 0.85203
wandb:           train/avg_f1 0.73051
wandb:      train/ensemble_f1 0.73051
wandb:         train/mil_loss 0.80959
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wild-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ze1lcut0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042603-ze1lcut0/logs
wandb: Agent Starting Run: rfl9ql3w with config:
wandb: 	actor_learning_rate: 2.645944739094576e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 83
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1595728951515334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042837-rfl9ql3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfl9ql3w
wandb: uploading wandb-summary.json
wandb: uploading history steps 77-84, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–‡â–‡â–†â–…
wandb:  best/eval_ensemble_f1 â–â–â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–ˆâ–„â–…â–„â–…â–…â–†â–…â–‡â–‡â–…â–†â–‡â–‡â–„â–…â–†â–‡â–‡â–…â–‚â–â–‡â–„â–ˆâ–‡â–‡â–†â–…â–…â–†â–ˆâ–…â–„â–…â–‚â–„
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–†â–†â–…â–„â–‡â–‚â–…â–‚â–„â–…â–…â–†â–‡â–‡â–ˆâ–…â–…â–…â–…â–…â–…â–‚â–‡â–†â–„â–‚â–â–ƒâ–…â–…â–„â–…â–†â–„â–ƒâ–†â–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–‡â–„â–…â–…â–…â–†â–„â–…â–‡â–†â–†â–…â–…â–†â–…â–‚â–…â–‡â–…â–†â–‡â–‡â–†â–â–ˆâ–†â–ˆâ–‡â–†â–‡â–†â–…â–†â–…â–‡â–…â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–„â–‡â–‚â–‚â–‡â–…â–…â–‡â–â–ˆâ–„â–†â–ˆâ–†â–ˆâ–‡â–†â–ƒâ–‡â–‡â–…â–„â–…â–…â–„â–†â–…â–…â–‡â–…â–ˆâ–‡â–…â–ˆâ–„â–ƒâ–‡â–ˆ
wandb:      train/ensemble_f1 â–‡â–‚â–ƒâ–„â–‚â–†â–‚â–ƒâ–â–ˆâ–„â–ƒâ–…â–„â–†â–‡â–†â–„â–‡â–‡â–ƒâ–„â–‡â–‚â–„â–…â–ƒâ–„â–â–„â–†â–…â–†â–…â–†â–„â–†â–…â–ˆâ–…
wandb:         train/mil_loss â–ƒâ–â–ƒâ–†â–†â–†â–ƒâ–ˆâ–ƒâ–â–…â–†â–…â–‡â–‚â–â–‡â–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–…â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83188
wandb: best/eval_avg_mil_loss 0.88732
wandb:  best/eval_ensemble_f1 0.83188
wandb:            eval/avg_f1 0.50776
wandb:      eval/avg_mil_loss 0.85256
wandb:       eval/ensemble_f1 0.50776
wandb:            test/avg_f1 0.73895
wandb:      test/avg_mil_loss 0.37197
wandb:       test/ensemble_f1 0.73895
wandb:           train/avg_f1 0.64199
wandb:      train/ensemble_f1 0.64199
wandb:         train/mil_loss 0.85464
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dutiful-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfl9ql3w
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042837-rfl9ql3w/logs
wandb: Agent Starting Run: gwdv57c5 with config:
wandb: 	actor_learning_rate: 2.230754742063651e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.029708684407015573
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043005-gwdv57c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gwdv57c5
wandb: uploading history steps 156-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–†â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–…â–…â–…â–‡â–…â–„â–‡â–…â–ƒâ–‡â–…â–ƒâ–…â–„â–†â–…â–…â–…â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–â–‡â–…â–„â–…â–†â–…â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–„â–ƒâ–†â–†â–ƒâ–†â–†â–„â–ƒâ–„â–…â–‚â–ˆâ–„â–„â–„â–„â–‡â–â–ƒâ–ƒâ–ƒâ–‡â–„â–ƒâ–ƒâ–‡â–…â–ƒâ–…â–‚â–‡â–ƒâ–â–‚â–ƒâ–„â–…â–…â–†
wandb:       eval/ensemble_f1 â–‡â–†â–‡â–†â–‡â–ˆâ–…â–â–†â–ˆâ–ˆâ–†â–†â–‡â–†â–†â–†â–‡â–ˆâ–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–…â–‡â–†â–†â–†â–‡â–„â–ˆâ–…
wandb:           train/avg_f1 â–ƒâ–…â–„â–…â–„â–…â–…â–â–…â–†â–ƒâ–…â–†â–ƒâ–‡â–‡â–„â–†â–†â–‡â–„â–ˆâ–„â–…â–‡â–„â–…â–…â–…â–…â–…â–„â–…â–‡â–„â–†â–‡â–‡â–…â–‡
wandb:      train/ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–…â–„â–„â–ƒâ–†â–ƒâ–â–…â–„â–…â–„â–„â–ƒâ–…â–„â–„â–ƒâ–…â–ƒâ–„â–„â–†â–ƒâ–ƒâ–…â–„â–…â–ˆâ–…â–‡â–…
wandb:         train/mil_loss â–†â–‡â–†â–…â–†â–ˆâ–†â–†â–„â–…â–„â–‡â–†â–‡â–„â–†â–ˆâ–…â–ƒâ–ƒâ–â–…â–„â–‡â–†â–ƒâ–…â–…â–…â–†â–‚â–ƒâ–ƒâ–„â–…â–†â–ƒâ–ƒâ–ˆâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78206
wandb: best/eval_avg_mil_loss 0.78425
wandb:  best/eval_ensemble_f1 0.78206
wandb:            eval/avg_f1 0.60906
wandb:      eval/avg_mil_loss 0.91207
wandb:       eval/ensemble_f1 0.60906
wandb:           train/avg_f1 0.69558
wandb:      train/ensemble_f1 0.69558
wandb:         train/mil_loss 0.72526
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gwdv57c5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043005-gwdv57c5/logs
wandb: ERROR Run gwdv57c5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: yb4bp7qk with config:
wandb: 	actor_learning_rate: 1.954829334098714e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.059041003808593895
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043245-yb4bp7qk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yb4bp7qk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–‚â–‚â–„â–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–„â–…â–‚â–ƒâ–…â–…â–‚â–ƒâ–…â–ƒâ–ˆâ–ˆâ–†â–‚â–…â–…â–…â–…â–‡â–„â–„â–†â–ˆâ–„â–„â–†â–†â–‚â–†â–‚â–‡â–‡â–ˆâ–ƒâ–†â–…â–†â–‡â–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–â–‚â–‚â–…â–‚â–…â–„â–„â–‚â–ƒâ–‚â–‚â–…â–…â–„â–ƒâ–ƒâ–…â–ˆâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–†â–‚â–â–„â–â–â–„â–‚â–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–ƒâ–‡â–…â–†â–†â–â–‡â–‚â–†â–ˆâ–…â–†â–…â–ƒâ–‚â–…â–‡â–…â–…â–ˆâ–†â–…â–†â–‡â–…â–ˆâ–„â–„â–ƒâ–†â–‡â–ƒâ–…â–‡â–‡â–…â–†â–…â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–„â–„â–†â–…â–„â–„â–…â–ƒâ–†â–„â–„â–„â–„â–‡â–„â–ˆâ–…â–…â–…â–…â–…â–…â–ƒâ–„â–†â–‡â–ˆâ–‡â–†â–…â–…â–†
wandb:      train/ensemble_f1 â–â–‚â–„â–â–‚â–…â–ƒâ–ƒâ–…â–…â–„â–…â–†â–„â–‚â–‚â–„â–†â–ƒâ–„â–…â–ƒâ–†â–…â–„â–…â–†â–ˆâ–…â–†â–‡â–†â–…â–ƒâ–„â–†â–…â–…â–†â–†
wandb:         train/mil_loss â–†â–…â–†â–ƒâ–„â–ƒâ–…â–ƒâ–„â–…â–‡â–„â–‚â–ƒâ–†â–ƒâ–„â–…â–„â–ƒâ–ƒâ–†â–…â–„â–„â–†â–ˆâ–ƒâ–„â–„â–„â–‚â–„â–‚â–„â–‚â–â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–†â–â–…â–…â–…â–…â–‡â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77756
wandb: best/eval_avg_mil_loss 0.63518
wandb:  best/eval_ensemble_f1 0.77756
wandb:            eval/avg_f1 0.69708
wandb:      eval/avg_mil_loss 0.75434
wandb:       eval/ensemble_f1 0.69708
wandb:            test/avg_f1 0.77528
wandb:      test/avg_mil_loss 0.51441
wandb:       test/ensemble_f1 0.77528
wandb:           train/avg_f1 0.70631
wandb:      train/ensemble_f1 0.70631
wandb:         train/mil_loss 0.71362
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run flowing-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yb4bp7qk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043245-yb4bp7qk/logs
wandb: Agent Starting Run: hlb9k6kz with config:
wandb: 	actor_learning_rate: 0.0005146363855436523
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9034035264605214
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043509-hlb9k6kz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hlb9k6kz
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–„â–…â–ƒâ–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–…â–„â–‚â–ˆâ–…â–„â–ƒâ–â–…â–†â–…â–„â–‡â–‚â–„â–†â–‚â–…â–ƒâ–‡â–†â–†â–†â–„â–†â–‡
wandb:      eval/avg_mil_loss â–†â–ƒâ–â–‚â–ƒâ–ƒâ–„â–†â–‚â–†â–ƒâ–â–‚â–‚â–„â–„â–„â–‚â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–â–â–„â–„â–ƒâ–ƒâ–‚â–‚â–…â–â–„â–‚â–ƒâ–
wandb:       eval/ensemble_f1 â–…â–„â–„â–„â–…â–†â–„â–„â–‡â–†â–…â–†â–ƒâ–…â–„â–‚â–…â–‡â–†â–â–„â–†â–ƒâ–†â–‡â–†â–‡â–ˆâ–…â–‡â–†â–„â–‡â–†â–†â–…â–â–ˆâ–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–†â–ƒâ–„â–„â–„â–ƒâ–„â–„â–‚â–…â–„â–„â–†â–„â–‡â–…â–…â–„â–…â–‡â–…â–†â–†â–ƒâ–‡â–†â–ˆâ–†â–†â–…â–†
wandb:      train/ensemble_f1 â–‚â–â–‚â–‚â–ƒâ–â–ƒâ–â–…â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–†â–„â–ƒâ–†â–…â–…â–„â–…â–…â–…â–…â–„â–ˆâ–†â–…â–„â–„â–†
wandb:         train/mil_loss â–…â–…â–„â–ˆâ–…â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–…â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–â–â–†â–‚â–„â–„â–…â–…â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–ˆâ–ƒâ–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–‡â–†â–„â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74953
wandb: best/eval_avg_mil_loss 0.7376
wandb:  best/eval_ensemble_f1 0.74953
wandb:            eval/avg_f1 0.71385
wandb:      eval/avg_mil_loss 0.70272
wandb:       eval/ensemble_f1 0.71385
wandb:            test/avg_f1 0.72944
wandb:      test/avg_mil_loss 0.72512
wandb:       test/ensemble_f1 0.72944
wandb:           train/avg_f1 0.68222
wandb:      train/ensemble_f1 0.68222
wandb:         train/mil_loss 0.78216
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lilac-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hlb9k6kz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043509-hlb9k6kz/logs
wandb: Agent Starting Run: w00anstr with config:
wandb: 	actor_learning_rate: 5.468738679420877e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.160894008708641
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043733-w00anstr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w00anstr
wandb: uploading history steps 93-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–ƒâ–ƒâ–‡â–‡â–†â–„â–‡â–†â–‡â–†â–‡â–‚â–‡â–…â–…â–…â–†â–„â–†â–‡â–‡â–ˆâ–†â–†â–†â–…â–â–„â–†â–ˆâ–„â–…â–‡â–ˆâ–„â–„â–‡â–†
wandb:      eval/avg_mil_loss â–„â–…â–ƒâ–ƒâ–â–ƒâ–„â–ˆâ–ƒâ–â–„â–ƒâ–ƒâ–„â–„â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–â–†â–‚â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–‡â–„â–ƒâ–†â–„â–ƒâ–‡â–…â–„â–…â–„â–‡â–…â–„â–…â–…â–„â–…â–…â–„â–‡â–†â–†â–ƒâ–ˆâ–…â–ƒâ–…â–„â–â–…â–†â–ƒâ–…â–†â–„â–„â–ƒâ–„
wandb:           train/avg_f1 â–ƒâ–‡â–â–†â–†â–ƒâ–†â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–„â–…â–†â–ƒâ–„â–ˆâ–‚â–ƒâ–ˆâ–…â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–†â–„â–‚â–„â–…â–ˆâ–…â–†
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–ƒâ–‡â–…â–‚â–ƒâ–„â–…â–†â–„â–ƒâ–„â–ƒâ–ƒâ–â–„â–†â–†â–ƒâ–‚â–„â–„â–„â–ˆâ–ƒâ–ƒâ–…â–ƒâ–…â–„â–…â–†â–„â–„â–…â–ƒâ–…â–ˆ
wandb:         train/mil_loss â–ƒâ–†â–…â–…â–…â–…â–†â–…â–„â–…â–…â–…â–…â–…â–†â–„â–ˆâ–†â–‡â–‚â–„â–†â–‡â–†â–…â–„â–…â–†â–„â–†â–„â–„â–…â–…â–ƒâ–…â–â–ƒâ–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78671
wandb: best/eval_avg_mil_loss 0.82011
wandb:  best/eval_ensemble_f1 0.78671
wandb:            eval/avg_f1 0.67361
wandb:      eval/avg_mil_loss 0.75972
wandb:       eval/ensemble_f1 0.67361
wandb:           train/avg_f1 0.66701
wandb:      train/ensemble_f1 0.66701
wandb:         train/mil_loss 0.74731
wandb:      train/policy_loss -0.26283
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.26283
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run young-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w00anstr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043733-w00anstr/logs
wandb: ERROR Run w00anstr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: i6ywudqz with config:
wandb: 	actor_learning_rate: 9.82432126016169e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8939964449460334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043911-i6ywudqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6ywudqz
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‡â–…â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–…â–…â–„â–ƒâ–‡â–…â–„â–â–…â–…â–‚â–ƒâ–…â–…â–‡â–…â–„â–ƒâ–†â–…â–„â–ˆâ–…â–ˆâ–„â–ˆâ–„â–„â–†â–ˆâ–…â–„â–ˆâ–†â–„â–ƒâ–†â–†
wandb:      eval/avg_mil_loss â–…â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–†â–…â–‚â–„â–†â–„â–†â–†â–‡â–‚â–„â–„â–†â–„â–ƒâ–†â–â–„â–„â–ƒâ–ƒâ–†â–„â–„â–â–‚â–‚â–…â–…â–‡â–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–„â–†â–ˆâ–ƒâ–†â–„â–â–ƒâ–‚â–†â–‚â–‚â–„â–‚â–…â–„â–‡â–ˆâ–…â–‚â–…â–†â–ƒâ–‚â–…â–…â–…â–…â–…â–‡â–…â–‡â–â–‡â–…â–„â–†â–ƒâ–†
wandb:           train/avg_f1 â–‚â–‚â–‚â–„â–â–ƒâ–„â–„â–‚â–†â–„â–‚â–‡â–ƒâ–ƒâ–‡â–‚â–ƒâ–…â–„â–„â–„â–…â–…â–†â–„â–ˆâ–ˆâ–„â–ƒâ–†â–…â–…â–…â–†â–„â–†â–…â–…â–‡
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–‚â–…â–„â–…â–„â–…â–…â–„â–…â–…â–ƒâ–„â–†â–ƒâ–ƒâ–†â–…â–„â–…â–„â–†â–â–ˆâ–…â–…â–„â–…â–†â–†â–…â–†â–…â–†â–…â–‡â–‡â–‡
wandb:         train/mil_loss â–…â–…â–†â–‡â–†â–ˆâ–…â–…â–ƒâ–„â–‚â–†â–‚â–‚â–‚â–‚â–†â–…â–…â–ƒâ–‚â–‚â–„â–ˆâ–†â–‡â–ƒâ–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–ƒâ–â–„
wandb:      train/policy_loss â–†â–†â–â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80699
wandb: best/eval_avg_mil_loss 0.63563
wandb:  best/eval_ensemble_f1 0.80699
wandb:            eval/avg_f1 0.75083
wandb:      eval/avg_mil_loss 0.691
wandb:       eval/ensemble_f1 0.75083
wandb:           train/avg_f1 0.75919
wandb:      train/ensemble_f1 0.75919
wandb:         train/mil_loss 0.73065
wandb:      train/policy_loss -0.08861
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.08861
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run likely-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6ywudqz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043911-i6ywudqz/logs
wandb: ERROR Run i6ywudqz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1tklhkdj with config:
wandb: 	actor_learning_rate: 0.00013393157987123068
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09018640064227468
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044145-1tklhkdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1tklhkdj
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–â–‚â–†â–„â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–ƒâ–ƒâ–„â–…â–„â–„â–…â–†â–†â–ƒâ–„â–…â–„â–ƒâ–†â–ˆâ–„â–†â–ˆâ–†â–‡â–…â–…â–†â–…
wandb:      eval/avg_mil_loss â–†â–„â–…â–†â–…â–ƒâ–ˆâ–‚â–‡â–‡â–â–„â–†â–ƒâ–„â–ƒâ–‡â–„â–„â–†â–‡â–„â–„â–ƒâ–‚â–‡â–ƒâ–„â–ƒâ–…â–…â–ƒâ–‚â–„â–‚â–â–„â–…â–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–„â–„â–ƒâ–„â–„â–‚â–„â–â–„â–ƒâ–ƒâ–…â–‡â–…â–„â–†â–„â–…â–„â–ƒâ–„â–…â–†â–„â–…â–ˆâ–†â–ˆâ–ƒâ–…â–‡â–†â–â–…â–…â–ƒâ–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–‚â–â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–…â–„â–ƒâ–„â–„â–‚â–…â–ƒâ–†â–ƒâ–ƒâ–…â–‡â–‡â–ƒâ–…â–„â–„â–…â–†â–…â–…â–†â–ˆâ–„â–†â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–ƒâ–â–‚â–‚â–„â–ƒâ–„â–†â–ƒâ–‚â–ƒâ–†â–„â–…â–ƒâ–„â–„â–ƒâ–…â–†â–†â–ƒâ–„â–…â–…â–ˆâ–„â–ƒâ–†â–…â–„â–…â–„â–„â–†â–‡â–…â–†
wandb:         train/mil_loss â–†â–‡â–ˆâ–†â–ˆâ–„â–ˆâ–…â–‡â–‡â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–„â–ƒâ–„â–„â–†â–„â–…â–†â–ƒâ–…â–ƒâ–‚â–†â–„â–„â–„â–„â–„â–ƒâ–
wandb:      train/policy_loss â–…â–â–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–„â–„â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–‚â–…â–…â–…â–ˆâ–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81014
wandb: best/eval_avg_mil_loss 0.62704
wandb:  best/eval_ensemble_f1 0.81014
wandb:            eval/avg_f1 0.73952
wandb:      eval/avg_mil_loss 0.65791
wandb:       eval/ensemble_f1 0.73952
wandb:            test/avg_f1 0.77095
wandb:      test/avg_mil_loss 0.55612
wandb:       test/ensemble_f1 0.77095
wandb:           train/avg_f1 0.74782
wandb:      train/ensemble_f1 0.74782
wandb:         train/mil_loss 0.67299
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polished-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1tklhkdj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044145-1tklhkdj/logs
wandb: Agent Starting Run: jhmcbiaw with config:
wandb: 	actor_learning_rate: 1.8547287549979115e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33325189789388143
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044405-jhmcbiaw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhmcbiaw
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–…â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–„â–„â–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–…â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–â–ƒâ–„â–…â–„â–„â–ƒâ–ƒâ–…â–„â–„â–„â–…â–…â–†â–…â–„â–…â–…â–†â–†â–†â–†â–ƒâ–„â–‡â–†â–„â–‡â–‡â–†â–‡â–‡â–†â–ˆâ–†â–†
wandb:      eval/avg_mil_loss â–„â–…â–„â–†â–„â–„â–…â–ˆâ–†â–ƒâ–ƒâ–‡â–ƒâ–‚â–‚â–†â–ƒâ–‚â–‡â–‚â–‚â–‚â–ƒâ–‚â–‚â–†â–â–‚â–†â–‚â–…â–‚â–â–†â–‚â–ƒâ–ƒâ–„â–â–„
wandb:       eval/ensemble_f1 â–â–â–â–ƒâ–‡â–„â–ƒâ–ˆâ–â–…â–„â–„â–†â–…â–…â–…â–„â–‡â–…â–…â–ƒâ–…â–…â–…â–†â–…â–‡â–…â–†â–‡â–†â–‡â–„â–†â–ˆâ–†â–‡â–‡â–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–„â–„â–„â–…â–…â–†â–„â–…â–†â–…â–†â–†â–…â–†â–†â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–†â–†â–†â–‡â–†
wandb:      train/ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–…â–…â–…â–…â–†â–…â–„â–†â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:         train/mil_loss â–…â–ˆâ–„â–†â–…â–…â–†â–†â–„â–‡â–„â–‡â–ƒâ–„â–‚â–†â–…â–„â–†â–ƒâ–„â–‚â–‚â–‚â–†â–ƒâ–„â–‚â–„â–‚â–ƒâ–ƒâ–‡â–ƒâ–…â–â–‚â–â–â–ƒ
wandb:      train/policy_loss â–…â–ˆâ–…â–…â–ƒâ–ˆâ–…â–„â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ƒâ–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–‚â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–…â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77977
wandb: best/eval_avg_mil_loss 0.62758
wandb:  best/eval_ensemble_f1 0.77977
wandb:            eval/avg_f1 0.77467
wandb:      eval/avg_mil_loss 0.72823
wandb:       eval/ensemble_f1 0.77467
wandb:            test/avg_f1 0.77528
wandb:      test/avg_mil_loss 0.51071
wandb:       test/ensemble_f1 0.77528
wandb:           train/avg_f1 0.74675
wandb:      train/ensemble_f1 0.74675
wandb:         train/mil_loss 0.62475
wandb:      train/policy_loss -0.22548
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.22548
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run zesty-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhmcbiaw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044405-jhmcbiaw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8l81pkmo with config:
wandb: 	actor_learning_rate: 0.0002485897967293602
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.85812232598203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044701-8l81pkmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8l81pkmo
wandb: uploading history steps 142-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–ƒâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–‚â–‚â–â–„â–ƒâ–„â–ƒâ–‚â–…â–„â–„â–…â–…â–…â–ƒâ–†â–…â–‡â–†â–‚â–ƒâ–ƒâ–ˆâ–…â–‡â–‡â–…â–„â–‡â–„â–†â–†â–ƒâ–…â–‡â–†â–…â–ˆ
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–ˆâ–„â–…â–„â–‚â–†â–ƒâ–…â–„â–â–ƒâ–„â–ƒâ–„â–‚â–„â–‡â–‚â–ƒâ–…â–„â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–…â–…â–ƒâ–‚â–‚â–ƒâ–â–ƒ
wandb:       eval/ensemble_f1 â–„â–†â–„â–â–„â–ƒâ–„â–…â–ƒâ–†â–…â–†â–…â–…â–†â–†â–ˆâ–ˆâ–†â–†â–†â–†â–„â–…â–„â–„â–„â–†â–„â–ƒâ–…â–†â–…â–†â–…â–„â–…â–‚â–†â–„
wandb:           train/avg_f1 â–†â–â–†â–ƒâ–ƒâ–„â–…â–†â–„â–„â–„â–…â–…â–‡â–…â–‡â–†â–„â–†â–†â–„â–…â–‡â–„â–„â–‡â–†â–…â–…â–…â–†â–…â–‡â–†â–…â–„â–ˆâ–…â–†â–†
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–â–‚â–„â–…â–„â–…â–ƒâ–„â–†â–‚â–†â–†â–„â–†â–„â–â–‡â–‡â–„â–„â–†â–‡â–ƒâ–†â–‚â–„â–ˆâ–‡â–â–‡â–‡â–†â–‡â–…â–†â–ˆâ–‡
wandb:         train/mil_loss â–†â–ƒâ–ƒâ–…â–…â–†â–„â–†â–ƒâ–†â–â–…â–†â–ˆâ–…â–„â–„â–ˆâ–†â–ƒâ–‡â–…â–ƒâ–†â–‡â–ƒâ–‚â–…â–„â–„â–„â–„â–‚â–„â–†â–…â–ƒâ–‚â–…â–„
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–„â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–„â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8248
wandb: best/eval_avg_mil_loss 0.71473
wandb:  best/eval_ensemble_f1 0.8248
wandb:            eval/avg_f1 0.71723
wandb:      eval/avg_mil_loss 0.58041
wandb:       eval/ensemble_f1 0.71723
wandb:           train/avg_f1 0.71732
wandb:      train/ensemble_f1 0.71732
wandb:         train/mil_loss 0.69937
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glowing-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8l81pkmo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044701-8l81pkmo/logs
wandb: ERROR Run 8l81pkmo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hsl17ki3 with config:
wandb: 	actor_learning_rate: 0.0009091823336460736
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5941656474377738
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045005-hsl17ki3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hsl17ki3
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 90-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–ƒâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–…â–ƒâ–ƒâ–…â–„â–ƒâ–„â–…â–ˆâ–„â–„â–†â–ƒâ–ƒâ–â–†â–‡â–…â–†â–…â–ƒâ–„
wandb:      eval/avg_mil_loss â–…â–ƒâ–‚â–…â–…â–„â–…â–„â–ˆâ–ƒâ–‚â–…â–ƒâ–ƒâ–„â–‚â–†â–„â–ƒâ–„â–â–‚â–…â–„â–ƒâ–„â–…â–„â–‚â–†â–ƒâ–â–‡â–â–ƒâ–ƒâ–„â–„â–ƒâ–‡
wandb:       eval/ensemble_f1 â–ˆâ–ƒâ–â–…â–…â–…â–ƒâ–„â–…â–‚â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–‡â–…â–…â–ƒâ–…â–…â–ƒâ–†â–ƒâ–„â–„â–„â–â–†â–‚â–‚â–ƒâ–„â–„
wandb:           train/avg_f1 â–ƒâ–„â–„â–…â–†â–…â–…â–„â–ƒâ–„â–ƒâ–…â–†â–†â–†â–ƒâ–…â–ˆâ–…â–‚â–ˆâ–‡â–†â–„â–ƒâ–‚â–†â–ˆâ–…â–â–†â–…â–„â–‡â–ƒâ–†â–ƒâ–„â–…â–†
wandb:      train/ensemble_f1 â–‡â–†â–…â–‡â–„â–â–…â–ƒâ–†â–…â–„â–„â–ƒâ–ˆâ–†â–„â–‡â–„â–ƒâ–ƒâ–ˆâ–ƒâ–‡â–‚â–„â–‡â–…â–‡â–†â–„â–‚â–„â–†â–ˆâ–†â–ƒâ–…â–†â–ƒâ–‡
wandb:         train/mil_loss â–…â–‡â–…â–‡â–ƒâ–ƒâ–ƒâ–†â–ˆâ–†â–„â–‚â–ƒâ–„â–‡â–„â–…â–†â–„â–â–…â–ƒâ–…â–†â–…â–‡â–†â–…â–ƒâ–ƒâ–…â–†â–„â–‚â–‡â–†â–…â–†â–…â–ƒ
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–†â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77002
wandb: best/eval_avg_mil_loss 0.63507
wandb:  best/eval_ensemble_f1 0.77002
wandb:            eval/avg_f1 0.60584
wandb:      eval/avg_mil_loss 1.14229
wandb:       eval/ensemble_f1 0.60584
wandb:           train/avg_f1 0.66072
wandb:      train/ensemble_f1 0.66072
wandb:         train/mil_loss 0.81434
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run celestial-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hsl17ki3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045005-hsl17ki3/logs
wandb: ERROR Run hsl17ki3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: om36sjiq with config:
wandb: 	actor_learning_rate: 3.390921205307796e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4913184286297601
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045212-om36sjiq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/om36sjiq
wandb: uploading wandb-summary.json
wandb: uploading history steps 103-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–ƒâ–‡â–ƒâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–‚â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–†â–…â–…â–…â–ˆâ–ƒâ–„â–†â–†â–†â–„â–‚â–‡â–â–…â–„â–†â–ƒâ–…â–‚â–‡â–‚â–ƒâ–†â–„â–„â–‚
wandb:      eval/avg_mil_loss â–…â–„â–„â–„â–‡â–„â–…â–…â–‡â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–„â–‡â–„â–‚â–‚â–ƒâ–…â–…â–„â–…â–ˆâ–â–ƒâ–ˆâ–ƒâ–‚â–†â–„â–ƒâ–ƒâ–„â–…â–„â–†
wandb:       eval/ensemble_f1 â–â–ƒâ–…â–‡â–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–„â–†â–„â–„â–‚â–ƒâ–‚â–„â–„â–…â–…â–ˆâ–„â–ƒâ–„â–ƒâ–…â–ƒâ–…â–‚â–‡â–ƒâ–„â–„â–„â–ƒâ–
wandb:           train/avg_f1 â–„â–‚â–…â–„â–â–…â–„â–‚â–„â–„â–ƒâ–…â–„â–„â–…â–†â–…â–‡â–‡â–…â–…â–„â–†â–…â–ˆâ–„â–†â–†â–…â–‡â–†â–‡â–†â–†â–‡â–†â–†â–…â–…â–†
wandb:      train/ensemble_f1 â–…â–ƒâ–†â–„â–â–„â–‚â–…â–„â–ƒâ–…â–‚â–…â–ƒâ–„â–…â–‡â–…â–„â–…â–‚â–…â–‡â–…â–…â–†â–‡â–„â–…â–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ƒâ–†â–†â–†
wandb:         train/mil_loss â–†â–ˆâ–†â–‡â–…â–‡â–‡â–„â–…â–†â–„â–‡â–„â–„â–…â–†â–‡â–„â–„â–„â–…â–†â–†â–ƒâ–„â–…â–†â–†â–…â–„â–„â–‡â–†â–ˆâ–„â–…â–…â–ƒâ–…â–
wandb:      train/policy_loss â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–‡â–…â–ƒâ–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–†â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80956
wandb: best/eval_avg_mil_loss 0.70575
wandb:  best/eval_ensemble_f1 0.80956
wandb:            eval/avg_f1 0.64203
wandb:      eval/avg_mil_loss 0.85623
wandb:       eval/ensemble_f1 0.64203
wandb:           train/avg_f1 0.73469
wandb:      train/ensemble_f1 0.73469
wandb:         train/mil_loss 0.68736
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pretty-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/om36sjiq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045212-om36sjiq/logs
wandb: ERROR Run om36sjiq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 	size mismatch for task_model.mlp.0.weight: copying a param with shape torch.Size([512, 20]) from checkpoint, the shape in current model is torch.Size([128, 20]).
wandb: ERROR 	size mismatch for task_model.mlp.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).
wandb: ERROR 	size mismatch for task_model.mlp.3.weight: copying a param with shape torch.Size([2, 512]) from checkpoint, the shape in current model is torch.Size([2, 128]).
wandb: ERROR 
wandb: Agent Starting Run: ykejev61 with config:
wandb: 	actor_learning_rate: 5.568415889295736e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.032299506110540666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045429-ykejev61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ykejev61
wandb: uploading history steps 102-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–„â–†â–â–„â–ˆâ–‚â–ƒâ–ˆâ–†â–ƒâ–…â–„â–„â–‚â–‚â–…â–†â–†â–…â–‡â–„â–†â–‡â–„â–ƒâ–†â–‚â–ƒâ–„â–„â–…â–ˆâ–„â–„â–†â–…â–…â–‡â–ƒâ–„
wandb:      eval/avg_mil_loss â–…â–„â–‡â–†â–‡â–…â–‚â–ˆâ–„â–ˆâ–…â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‡â–‡â–ƒâ–‚â–‡â–‡â–ƒâ–ƒâ–„â–…â–‡â–…â–â–‡â–„â–ˆâ–„â–…â–â–…â–„â–†â–‚â–…
wandb:       eval/ensemble_f1 â–†â–â–†â–ƒâ–ˆâ–„â–‚â–ƒâ–„â–…â–ˆâ–ƒâ–…â–„â–†â–…â–ƒâ–†â–„â–‡â–‡â–‡â–ƒâ–„â–‚â–…â–†â–†â–…â–ƒâ–„â–ˆâ–„â–…â–…â–„â–…â–„â–†â–…
wandb:           train/avg_f1 â–…â–„â–‚â–ˆâ–†â–‚â–†â–„â–‡â–†â–„â–†â–…â–ƒâ–…â–„â–â–…â–†â–„â–„â–„â–…â–…â–…â–…â–„â–…â–…â–â–ˆâ–…â–†â–„â–‡â–„â–†â–‡â–‚â–ƒ
wandb:      train/ensemble_f1 â–ˆâ–…â–…â–†â–‚â–‡â–†â–†â–†â–‡â–…â–„â–…â–â–‚â–‡â–ˆâ–…â–‡â–…â–…â–„â–…â–ƒâ–…â–‡â–…â–ƒâ–â–†â–„â–‡â–„â–ˆâ–‡â–ˆâ–…â–†â–ƒâ–„
wandb:         train/mil_loss â–ƒâ–‡â–ˆâ–‚â–„â–†â–ˆâ–„â–…â–‡â–ƒâ–‡â–‚â–„â–ƒâ–ƒâ–„â–…â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–†â–‡â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–†â–‚â–ˆâ–â–„â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75928
wandb: best/eval_avg_mil_loss 0.85686
wandb:  best/eval_ensemble_f1 0.75928
wandb:            eval/avg_f1 0.73302
wandb:      eval/avg_mil_loss 0.80629
wandb:       eval/ensemble_f1 0.73302
wandb:           train/avg_f1 0.66014
wandb:      train/ensemble_f1 0.66014
wandb:         train/mil_loss 0.86623
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rose-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ykejev61
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045429-ykejev61/logs
wandb: ERROR Run ykejev61 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xt8xp9rl with config:
wandb: 	actor_learning_rate: 8.957260818029275e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.734625713413434
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045645-xt8xp9rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xt8xp9rl
wandb: uploading history steps 102-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–ƒâ–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–„â–ˆâ–…â–…â–…â–â–ˆâ–†â–„â–‚â–‚â–‚â–„â–…â–„â–…â–†â–…â–…â–‚â–ƒâ–…â–‚â–„â–„â–ƒâ–‡â–„â–…â–„â–…â–…â–…â–…â–ƒâ–†â–…â–…
wandb:      eval/avg_mil_loss â–…â–‚â–…â–„â–…â–†â–‚â–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–…â–†â–ƒâ–…â–ˆâ–„â–‚â–ƒâ–…â–â–â–„â–„â–‚â–„â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–ƒâ–…â–„â–„â–…â–ƒâ–„â–ƒâ–â–„â–ƒâ–„â–†â–‚â–…â–ƒâ–ƒâ–…â–‡â–ƒâ–ˆâ–„â–‡â–â–…â–â–ƒâ–„â–‚â–…â–„â–…â–„â–…â–…â–…â–„â–„â–„
wandb:           train/avg_f1 â–ƒâ–…â–†â–‡â–…â–„â–‚â–„â–…â–ƒâ–…â–ˆâ–…â–†â–„â–„â–„â–ƒâ–†â–„â–â–ƒâ–…â–ƒâ–†â–…â–„â–ƒâ–„â–…â–‚â–…â–…â–†â–…â–…â–‡â–…â–ˆâ–…
wandb:      train/ensemble_f1 â–…â–ˆâ–†â–ƒâ–‚â–ƒâ–…â–ƒâ–†â–ˆâ–â–ƒâ–…â–‚â–„â–†â–‡â–…â–„â–†â–„â–‡â–ƒâ–ˆâ–â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‡â–ˆâ–…â–…â–…â–‡â–†â–†â–ƒ
wandb:         train/mil_loss â–‚â–„â–†â–†â–†â–†â–…â–†â–‡â–…â–ˆâ–‡â–†â–…â–‚â–†â–†â–…â–…â–‡â–…â–„â–„â–ƒâ–ƒâ–ˆâ–„â–„â–„â–â–‚â–†â–†â–â–…â–„â–†â–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–â–ˆâ–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76458
wandb: best/eval_avg_mil_loss 0.7559
wandb:  best/eval_ensemble_f1 0.76458
wandb:            eval/avg_f1 0.6736
wandb:      eval/avg_mil_loss 0.91935
wandb:       eval/ensemble_f1 0.6736
wandb:           train/avg_f1 0.64423
wandb:      train/ensemble_f1 0.64423
wandb:         train/mil_loss 0.8653
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run classic-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xt8xp9rl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045645-xt8xp9rl/logs
wandb: ERROR Run xt8xp9rl errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bqrcclxg with config:
wandb: 	actor_learning_rate: 1.3571721763649243e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4377874631203982
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045909-bqrcclxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqrcclxg
wandb: uploading wandb-summary.json
wandb: uploading history steps 165-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–†â–„â–†â–ˆâ–…â–ƒâ–‚â–†â–„â–ˆâ–†â–†â–†â–‡â–ƒâ–„â–…â–„â–„â–†â–„â–†â–…â–†â–„â–†â–ˆâ–…â–„â–„â–„â–„â–â–â–†â–„â–†â–…â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–‚â–…â–„â–…â–ƒâ–…â–„â–…â–ƒâ–„â–„â–‚â–…â–ƒâ–‚â–ƒâ–‡â–…â–„â–‡â–„â–â–‡â–‡â–‚â–ƒâ–„â–„â–‡â–„â–â–„â–„â–â–…â–ƒâ–ˆâ–…
wandb:       eval/ensemble_f1 â–‚â–‡â–†â–‡â–ˆâ–…â–‚â–…â–„â–…â–‡â–†â–†â–…â–ˆâ–†â–…â–„â–‚â–„â–†â–ƒâ–†â–‚â–„â–„â–„â–†â–„â–…â–„â–„â–‡â–†â–â–‡â–ˆâ–„â–„â–„
wandb:           train/avg_f1 â–ƒâ–†â–‡â–†â–†â–„â–†â–…â–†â–…â–ˆâ–‡â–‡â–…â–‡â–…â–„â–†â–†â–‡â–„â–ˆâ–„â–„â–…â–‡â–…â–ƒâ–‡â–ƒâ–â–…â–ƒâ–…â–†â–‡â–‡â–‡â–…â–†
wandb:      train/ensemble_f1 â–‡â–ƒâ–†â–†â–‚â–„â–…â–â–…â–…â–â–…â–…â–†â–‡â–…â–…â–†â–…â–†â–ˆâ–ƒâ–„â–…â–ˆâ–…â–…â–…â–‡â–…â–„â–…â–‡â–†â–…â–„â–…â–„â–…â–
wandb:         train/mil_loss â–†â–‚â–â–„â–‚â–ˆâ–„â–‡â–„â–†â–†â–…â–â–…â–†â–…â–‡â–…â–ƒâ–â–ˆâ–ˆâ–‡â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–„â–â–‚â–‚â–‡â–‚â–ƒâ–„â–â–ƒâ–‡
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85169
wandb: best/eval_avg_mil_loss 0.66833
wandb:  best/eval_ensemble_f1 0.85169
wandb:            eval/avg_f1 0.71888
wandb:      eval/avg_mil_loss 0.77085
wandb:       eval/ensemble_f1 0.71888
wandb:           train/avg_f1 0.63839
wandb:      train/ensemble_f1 0.63839
wandb:         train/mil_loss 0.92355
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misunderstood-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqrcclxg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045909-bqrcclxg/logs
wandb: ERROR Run bqrcclxg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 8sv7w6q7 with config:
wandb: 	actor_learning_rate: 0.00021169327581865093
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.059005898538945334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050214-8sv7w6q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sv7w6q7
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 178-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–†â–„â–„â–„â–ƒâ–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–â–‡â–†â–†â–‡â–…â–†â–‡â–‡â–†â–ˆâ–„â–†â–ˆâ–†â–…â–„â–‡â–ˆâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–†â–†â–…â–†â–‡â–â–…â–‡â–…â–ˆâ–ˆâ–„â–…â–„
wandb:      eval/avg_mil_loss â–‚â–‡â–ƒâ–„â–…â–„â–ˆâ–ƒâ–…â–„â–ƒâ–…â–‡â–†â–„â–‚â–„â–ˆâ–„â–ƒâ–„â–„â–…â–ƒâ–„â–†â–„â–…â–ƒâ–â–…â–…â–„â–†â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–‡â–†â–…â–‡â–†â–‡â–ˆâ–‡â–†â–‡â–…â–†â–…â–„â–†â–„â–…â–‡â–‡â–„â–ˆâ–…â–†â–†â–†â–‡â–â–„â–ˆâ–‡â–„â–ˆâ–‡â–‡â–„â–„â–†â–†â–ˆ
wandb:           train/avg_f1 â–†â–…â–ƒâ–„â–„â–†â–†â–†â–ƒâ–ƒâ–†â–ƒâ–‚â–„â–…â–„â–„â–‡â–†â–…â–„â–â–†â–†â–†â–ƒâ–…â–†â–‚â–…â–„â–ƒâ–ƒâ–ˆâ–†â–…â–†â–„â–†â–…
wandb:      train/ensemble_f1 â–ƒâ–†â–„â–ƒâ–…â–ƒâ–ƒâ–„â–‚â–†â–â–‡â–ƒâ–…â–ƒâ–ƒâ–†â–ƒâ–†â–…â–†â–†â–‡â–ƒâ–‡â–„â–†â–ƒâ–‚â–…â–„â–†â–†â–ˆâ–…â–†â–†â–†â–†â–…
wandb:         train/mil_loss â–‚â–„â–„â–…â–†â–†â–‡â–ƒâ–…â–‚â–ƒâ–„â–„â–…â–„â–„â–ƒâ–ƒâ–…â–…â–ƒâ–†â–ƒâ–â–â–„â–…â–…â–ˆâ–ƒâ–…â–‚â–„â–ƒâ–†â–ƒâ–„â–„â–…â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84717
wandb: best/eval_avg_mil_loss 0.78361
wandb:  best/eval_ensemble_f1 0.84717
wandb:            eval/avg_f1 0.67579
wandb:      eval/avg_mil_loss 0.84211
wandb:       eval/ensemble_f1 0.67579
wandb:           train/avg_f1 0.72101
wandb:      train/ensemble_f1 0.72101
wandb:         train/mil_loss 0.76816
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run quiet-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sv7w6q7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050214-8sv7w6q7/logs
wandb: ERROR Run 8sv7w6q7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9cd6j8pg with config:
wandb: 	actor_learning_rate: 1.933001487146608e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 72
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8884126267856782
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050541-9cd6j8pg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cd6j8pg
wandb: uploading wandb-summary.json
wandb: uploading history steps 59-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–…â–‚â–â–â–„â–ƒ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–†â–…â–†â–‚â–‡â–â–‡â–ƒâ–„â–„â–‚â–„â–‡â–†â–„â–‚â–‡â–â–‚â–…â–â–„â–ƒâ–â–†â–ƒâ–‡â–‡â–„â–‚â–â–‡â–ˆâ–‡â–‡â–‡â–ƒâ–‡â–‚
wandb:      eval/avg_mil_loss â–†â–‡â–„â–â–â–‡â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–‡â–„â–ƒâ–„â–ƒâ–…â–„â–‡â–…â–„â–…â–„â–…â–‡â–ˆâ–‚â–‚â–†â–â–â–â–†â–„â–ƒâ–…â–…
wandb:       eval/ensemble_f1 â–‚â–†â–‚â–…â–‚â–‚â–â–…â–‡â–ƒâ–â–‡â–„â–‚â–‡â–‡â–‡â–„â–‚â–‡â–‡â–â–‚â–ƒâ–„â–‡â–„â–‚â–â–â–ˆâ–‡â–‚â–‡â–â–†â–‡â–‡â–„â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–‡â–‡â–„â–ƒâ–†â–†â–„â–ƒâ–â–„â–‡â–„â–…â–…â–ƒâ–‚â–…â–†â–„â–„â–ƒâ–…â–…â–…â–ƒâ–‚â–ƒâ–‡â–…â–…â–ˆâ–…â–†â–ƒâ–…â–â–„â–‡â–„
wandb:      train/ensemble_f1 â–ˆâ–ƒâ–‡â–„â–…â–†â–„â–„â–ƒâ–ƒâ–‡â–„â–†â–‡â–…â–ƒâ–…â–†â–„â–ƒâ–…â–…â–…â–‚â–†â–„â–ƒâ–‡â–…â–„â–†â–…â–ˆâ–…â–†â–…â–ƒâ–‚â–â–…
wandb:         train/mil_loss â–…â–„â–„â–†â–„â–ƒâ–â–ˆâ–ƒâ–„â–ƒâ–…â–„â–…â–ƒâ–†â–„â–†â–†â–„â–ƒâ–„â–†â–„â–†â–ƒâ–†â–ƒâ–…â–…â–„â–ƒâ–…â–„â–‚â–„â–„â–‡â–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86804
wandb: best/eval_avg_mil_loss 0.71843
wandb:  best/eval_ensemble_f1 0.86804
wandb:            eval/avg_f1 0.40771
wandb:      eval/avg_mil_loss 1.01495
wandb:       eval/ensemble_f1 0.40771
wandb:            test/avg_f1 0.33691
wandb:      test/avg_mil_loss 1.12488
wandb:       test/ensemble_f1 0.33691
wandb:           train/avg_f1 0.63176
wandb:      train/ensemble_f1 0.63176
wandb:         train/mil_loss 0.88947
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dulcet-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cd6j8pg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050541-9cd6j8pg/logs
wandb: Agent Starting Run: i5s3mbl7 with config:
wandb: 	actor_learning_rate: 5.3141706496978616e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.375873028689643
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050702-i5s3mbl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i5s3mbl7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 104-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–…â–„â–†
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–ˆ
wandb:            eval/avg_f1 â–â–†â–â–†â–†â–†â–‡â–ˆâ–â–…â–â–†â–„â–…â–‡â–‡â–â–‡â–†â–â–†â–‡â–‡â–‡â–†â–ƒâ–‡â–…â–„â–†â–‡â–…â–†â–‡â–…â–‡â–‡â–‚â–‚â–†
wandb:      eval/avg_mil_loss â–ˆâ–†â–„â–ƒâ–†â–‚â–†â–†â–†â–ˆâ–…â–„â–‡â–‡â–„â–â–…â–„â–„â–†â–…â–ˆâ–ˆâ–‡â–‡â–‚â–‡â–ƒâ–†â–‚â–„â–ƒâ–…â–ƒâ–„â–‡â–…â–…â–‡â–†
wandb:       eval/ensemble_f1 â–â–†â–†â–‡â–‚â–â–â–„â–„â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–ƒâ–‡â–‡â–‡â–…â–…â–‡â–‡â–„â–ˆâ–†â–‡â–‡â–…â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–…â–‡
wandb:           train/avg_f1 â–ƒâ–ˆâ–„â–â–‡â–‡â–‡â–†â–„â–ˆâ–„â–‡â–‡â–†â–„â–„â–…â–†â–‡â–‚â–†â–‡â–…â–‡â–…â–ˆâ–‡â–ˆâ–†â–‡â–„â–‡â–†â–‡â–†â–†â–…â–ˆâ–‡â–‡
wandb:      train/ensemble_f1 â–„â–‚â–‡â–†â–‚â–…â–†â–ƒâ–…â–„â–‡â–„â–†â–„â–„â–„â–…â–‡â–‡â–…â–‡â–…â–â–‚â–‡â–†â–†â–…â–‡â–ƒâ–†â–…â–†â–†â–‡â–ˆâ–„â–†â–…â–†
wandb:         train/mil_loss â–‚â–‚â–„â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–†â–†â–„â–†â–„â–„â–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–ˆâ–…â–…â–…â–„â–ƒâ–„â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84046
wandb: best/eval_avg_mil_loss 0.90662
wandb:  best/eval_ensemble_f1 0.84046
wandb:            eval/avg_f1 0.72011
wandb:      eval/avg_mil_loss 0.90961
wandb:       eval/ensemble_f1 0.72011
wandb:           train/avg_f1 0.71917
wandb:      train/ensemble_f1 0.71917
wandb:         train/mil_loss 0.79821
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run happy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i5s3mbl7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050702-i5s3mbl7/logs
wandb: ERROR Run i5s3mbl7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cko2s2bx with config:
wandb: 	actor_learning_rate: 2.454837458158047e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1707678497764703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050907-cko2s2bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cko2s2bx
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–ˆâ–…â–†â–â–„â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–‡â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–…â–†â–…â–â–†â–ˆâ–†â–‡â–ˆâ–‡â–ˆâ–…â–ˆâ–†â–‡â–â–†â–ˆâ–‡â–ˆâ–†â–†â–†â–ˆâ–ˆâ–ˆâ–†â–‡â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–…â–…â–„â–„â–„â–„â–†â–ƒâ–‡â–„â–„â–‡â–„â–‡â–‡â–„â–‡â–‚â–…â–‚â–…â–„â–ˆâ–ƒâ–„â–†â–„â–â–â–‚â–‚â–‡â–„â–„â–„â–„â–„â–„â–…
wandb:       eval/ensemble_f1 â–†â–ˆâ–†â–†â–†â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–‡â–ˆâ–‚â–ˆâ–†â–‡â–â–‡â–‡â–ƒâ–†â–†â–ƒâ–‡â–†â–†â–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–â–…â–…â–‡â–„â–„â–…â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ˆâ–‚â–†â–‡â–…â–…â–…â–ƒâ–…â–„â–…â–†â–…â–„â–‡â–†â–â–…â–‡â–‚â–ƒâ–…â–‚â–†â–ƒ
wandb:      train/ensemble_f1 â–„â–…â–â–…â–„â–…â–ƒâ–…â–‚â–„â–ƒâ–„â–â–‚â–…â–„â–…â–ˆâ–‚â–„â–„â–â–‡â–†â–‚â–…â–ƒâ–„â–†â–‡â–…â–†â–…â–‡â–ƒâ–ƒâ–ƒâ–†â–‡â–„
wandb:         train/mil_loss â–†â–†â–…â–†â–‡â–†â–†â–…â–…â–„â–‚â–„â–†â–†â–ƒâ–„â–„â–ƒâ–‡â–†â–ˆâ–„â–‡â–†â–‡â–„â–…â–…â–…â–â–ƒâ–„â–‡â–„â–ƒâ–„â–…â–…â–„â–„
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83952
wandb: best/eval_avg_mil_loss 0.65345
wandb:  best/eval_ensemble_f1 0.83952
wandb:            eval/avg_f1 0.66767
wandb:      eval/avg_mil_loss 1.08751
wandb:       eval/ensemble_f1 0.66767
wandb:            test/avg_f1 0.84536
wandb:      test/avg_mil_loss 0.35273
wandb:       test/ensemble_f1 0.84536
wandb:           train/avg_f1 0.74515
wandb:      train/ensemble_f1 0.74515
wandb:         train/mil_loss 0.58857
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run misty-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cko2s2bx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050907-cko2s2bx/logs
wandb: Agent Starting Run: mnc1177z with config:
wandb: 	actor_learning_rate: 2.365342338914513e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.202536471864727
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051227-mnc1177z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnc1177z
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 147-151, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–…â–…
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–‡â–‡â–†â–‡â–ˆâ–„â–‡â–†â–‡â–‡â–ˆâ–‡â–…â–‡â–†â–‡â–…â–‡â–ˆâ–†â–†â–ˆâ–†â–†â–†â–†â–‡â–‡â–‡â–…â–†â–‡â–ˆâ–‡â–â–‡â–†â–ˆ
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–‚â–†â–…â–‚â–…â–ƒâ–ƒâ–â–„â–„â–„â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–â–„â–â–â–…â–â–â–„â–„â–â–„â–ˆâ–ƒâ–ƒâ–†â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–…â–†â–‡â–…â–‡â–‡â–†â–ˆâ–‡â–†â–‡â–ˆâ–†â–‡â–‡â–…â–â–‡â–ˆâ–ˆâ–…â–â–…â–…â–‡â–…â–ˆâ–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–†â–„â–„â–†â–ˆâ–†â–„â–„â–†â–„â–ƒâ–ƒâ–ƒâ–„â–â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–‡â–ƒâ–…â–…â–ƒâ–†â–†â–ˆâ–ƒâ–ƒâ–…â–…â–…â–†â–ƒâ–†â–ˆ
wandb:      train/ensemble_f1 â–â–†â–„â–‡â–†â–ˆâ–…â–†â–‡â–„â–†â–„â–‚â–‚â–…â–„â–†â–…â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–ƒâ–â–„â–‡â–‡â–†â–…â–ƒâ–…â–…â–…â–†â–‚â–…â–†â–ˆ
wandb:         train/mil_loss â–‚â–ƒâ–†â–ƒâ–†â–…â–‚â–„â–„â–…â–„â–…â–ƒâ–„â–‚â–ƒâ–„â–…â–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–‡â–†â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–ƒâ–ˆâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82533
wandb: best/eval_avg_mil_loss 0.762
wandb:  best/eval_ensemble_f1 0.82533
wandb:            eval/avg_f1 0.69284
wandb:      eval/avg_mil_loss 0.85596
wandb:       eval/ensemble_f1 0.69284
wandb:            test/avg_f1 0.85426
wandb:      test/avg_mil_loss 0.3818
wandb:       test/ensemble_f1 0.85426
wandb:           train/avg_f1 0.76911
wandb:      train/ensemble_f1 0.76911
wandb:         train/mil_loss 0.68483
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run classic-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mnc1177z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051227-mnc1177z/logs
wandb: Agent Starting Run: mex2wdmk with config:
wandb: 	actor_learning_rate: 2.2048437328332342e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6470653121121944
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051507-mex2wdmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mex2wdmk
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 104-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–†â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–†â–†â–‡â–…â–ˆâ–‡â–ˆâ–â–‡â–†â–†â–‚â–†â–†â–„â–ƒâ–‡â–…â–‡â–ƒâ–‡â–‡â–‡â–‡â–ƒâ–†â–„â–…â–†â–„â–â–†â–ˆâ–†â–„â–‡â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–ƒâ–ƒâ–†â–…â–‡â–ˆâ–‚â–†â–ƒâ–…â–ƒâ–‚â–„â–…â–„â–ƒâ–‡â–‚â–…â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‡â–â–„â–‚â–ˆâ–„â–‚â–†â–â–ˆ
wandb:       eval/ensemble_f1 â–†â–‡â–…â–‡â–‡â–‡â–…â–‡â–„â–…â–‡â–†â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–ƒâ–‡â–ƒâ–†â–‡â–†â–…â–ˆâ–†â–ˆâ–ˆâ–â–ˆâ–†â–…â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–„â–„â–†â–†â–ƒâ–ƒâ–…â–‡â–‡â–†â–ƒâ–ƒâ–‡â–…â–†â–ƒâ–ˆâ–â–ˆâ–…â–ƒâ–‡â–†â–…â–†â–ƒâ–„â–†â–‚â–ˆâ–ƒâ–ƒâ–…â–ƒâ–…â–‡â–„â–ƒâ–„
wandb:      train/ensemble_f1 â–„â–ƒâ–†â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–…â–‡â–†â–â–†â–„â–†â–‚â–‡â–„â–‡â–…â–ˆâ–ƒâ–ƒâ–…â–„â–†â–†â–†â–…â–ƒâ–…â–‡â–‡â–ƒâ–‡â–ˆâ–‡â–„â–†â–†
wandb:         train/mil_loss â–†â–„â–…â–…â–„â–…â–†â–„â–„â–„â–ƒâ–‚â–„â–„â–ƒâ–â–‡â–ƒâ–…â–ˆâ–„â–„â–†â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–„â–„â–†â–†â–â–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83188
wandb: best/eval_avg_mil_loss 0.53317
wandb:  best/eval_ensemble_f1 0.83188
wandb:            eval/avg_f1 0.77611
wandb:      eval/avg_mil_loss 0.80659
wandb:       eval/ensemble_f1 0.77611
wandb:            test/avg_f1 0.80389
wandb:      test/avg_mil_loss 0.45162
wandb:       test/ensemble_f1 0.80389
wandb:           train/avg_f1 0.74036
wandb:      train/ensemble_f1 0.74036
wandb:         train/mil_loss 0.78229
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polar-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mex2wdmk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051507-mex2wdmk/logs
wandb: Agent Starting Run: 2u7tj572 with config:
wandb: 	actor_learning_rate: 2.0905395925457973e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4215402590536058
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051706-2u7tj572
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2u7tj572
wandb: uploading history steps 88-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–„â–†â–†â–…â–â–…â–…â–…â–„â–†â–„â–‡â–…â–…â–…â–…â–‡â–„â–ˆâ–…â–†â–„â–„â–â–‡â–‡â–ˆâ–…â–†â–‡â–„â–…â–‡â–…â–†â–„â–†â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–„â–ˆâ–…â–„â–„â–â–ƒâ–„â–„â–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–â–…â–…â–ƒâ–…â–ƒâ–‚â–„â–â–‡â–„â–â–…â–â–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–…â–„â–â–…â–†â–ƒâ–„â–‡â–‡â–„â–ˆâ–…â–‡â–†â–‡â–„â–„â–ˆâ–†â–†â–„â–‡â–„â–‚â–‡â–†â–…â–ˆâ–†â–…â–…â–„â–…â–…â–†â–†â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–‚â–…â–‚â–…â–„â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–†â–„â–â–ƒâ–ƒâ–…â–„â–ƒâ–…â–‚â–†â–†â–…â–‚â–…â–ˆâ–„â–…â–…â–„â–ƒâ–…â–ƒâ–„â–‚â–ƒ
wandb:      train/ensemble_f1 â–‚â–„â–ƒâ–ƒâ–‡â–†â–…â–ƒâ–„â–â–„â–†â–ƒâ–ƒâ–…â–‚â–„â–ˆâ–â–†â–„â–†â–…â–…â–„â–‡â–†â–‡â–‚â–†â–‚â–…â–†â–…â–…â–‚â–…â–†â–„â–…
wandb:         train/mil_loss â–†â–ˆâ–†â–†â–†â–…â–„â–…â–‚â–„â–†â–‡â–ƒâ–ƒâ–…â–…â–…â–…â–…â–‚â–‡â–„â–…â–„â–…â–†â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–†â–â–â–‚â–„â–†
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80961
wandb: best/eval_avg_mil_loss 0.68622
wandb:  best/eval_ensemble_f1 0.80961
wandb:            eval/avg_f1 0.65834
wandb:      eval/avg_mil_loss 0.79052
wandb:       eval/ensemble_f1 0.65834
wandb:            test/avg_f1 0.65674
wandb:      test/avg_mil_loss 0.84185
wandb:       test/ensemble_f1 0.65674
wandb:           train/avg_f1 0.65294
wandb:      train/ensemble_f1 0.65294
wandb:         train/mil_loss 0.92745
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2u7tj572
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051706-2u7tj572/logs
wandb: Agent Starting Run: iamx3gek with config:
wandb: 	actor_learning_rate: 7.350027642319752e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 51
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19925413554880733
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051905-iamx3gek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iamx3gek
wandb: uploading history steps 50-51, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–„â–ˆâ–â–…â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–…â–„â–…â–â–„â–„â–ƒâ–…â–…â–‡â–…â–…â–ƒâ–‡â–„â–„â–†â–…â–…â–„â–…â–…â–†â–…â–„â–ˆâ–†â–„â–†â–†â–…â–‡â–…â–„â–…â–„â–ˆâ–„
wandb:      eval/avg_mil_loss â–ƒâ–‚â–„â–ƒâ–„â–‡â–„â–„â–ƒâ–‚â–â–ƒâ–ƒâ–„â–‚â–„â–ˆâ–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–‚â–„â–†â–‚â–ƒâ–‚â–„â–…â–‡â–„â–„â–â–†â–ƒâ–ƒâ–…â–…â–†â–„â–ƒâ–ƒâ–„â–†â–„â–ƒâ–ˆâ–†â–ƒâ–‡â–…â–…â–„â–†â–†â–‚â–„â–ƒâ–ƒ
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–†â–„â–…â–ƒâ–ƒâ–„â–‚â–…â–…â–â–†â–ƒâ–‡â–„â–„â–‡â–ˆâ–…â–â–‚â–‡â–…â–†â–„â–…â–„â–…â–…â–„â–ƒâ–…â–‚â–ƒâ–„â–…â–…â–„
wandb:      train/ensemble_f1 â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–ƒâ–ƒâ–„â–‚â–…â–â–†â–ƒâ–‡â–‡â–„â–„â–‡â–ˆâ–…â–â–‚â–‡â–…â–†â–„â–…â–„â–…â–„â–ƒâ–„â–…â–‚â–ƒâ–„â–…â–…â–„
wandb:         train/mil_loss â–†â–…â–ˆâ–ˆâ–‡â–‡â–…â–„â–†â–†â–…â–†â–…â–†â–â–†â–…â–‡â–ƒâ–ƒâ–…â–‡â–†â–†â–„â–†â–„â–…â–„â–ˆâ–„â–‚â–ƒâ–…â–„â–ƒâ–…â–ƒâ–†â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75837
wandb: best/eval_avg_mil_loss 0.76187
wandb:  best/eval_ensemble_f1 0.75837
wandb:            eval/avg_f1 0.71435
wandb:      eval/avg_mil_loss 0.82283
wandb:       eval/ensemble_f1 0.71435
wandb:           train/avg_f1 0.74438
wandb:      train/ensemble_f1 0.74438
wandb:         train/mil_loss 0.63691
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run clean-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iamx3gek
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051905-iamx3gek/logs
wandb: ERROR Run iamx3gek errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: sm9jgudl with config:
wandb: 	actor_learning_rate: 2.859631691486875e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16174277753886557
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052012-sm9jgudl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sm9jgudl
wandb: uploading history steps 163-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–‚â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–‚â–„â–…â–‚â–„â–†â–‚â–„â–â–…â–„â–†â–ƒâ–‚â–ƒâ–…â–‚â–ƒâ–„â–…â–‚â–ƒâ–†â–„â–ˆâ–…â–„â–†â–…â–â–„â–ƒâ–„â–…â–†â–„â–‡â–…â–‡
wandb:      eval/avg_mil_loss â–…â–ƒâ–…â–…â–…â–…â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–†â–ƒâ–ƒâ–…â–â–„â–†â–‚â–ƒâ–ƒâ–‚â–„â–â–†â–„â–‚â–‚â–â–„â–…â–…â–ƒâ–…â–ˆâ–‚â–„â–ƒâ–‚â–ƒ
wandb:       eval/ensemble_f1 â–â–…â–â–„â–„â–„â–„â–â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–‚â–ƒâ–…â–…â–…â–‡â–…â–ƒâ–„â–„â–ƒâ–ƒâ–â–…â–…â–‚â–ˆâ–„â–…â–…â–„â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–„â–„â–â–„â–‚â–„â–†â–†â–‡â–„â–…â–†â–„â–†â–ƒâ–…â–…â–„â–…â–„â–‡â–ƒâ–ˆâ–„â–‚â–†â–…â–…â–„â–…â–†â–…â–„â–…â–…â–„â–…â–…
wandb:      train/ensemble_f1 â–…â–‚â–†â–â–†â–„â–†â–†â–‡â–†â–ƒâ–‚â–†â–„â–„â–†â–†â–…â–‡â–„â–…â–„â–…â–ˆâ–…â–ƒâ–‡â–…â–†â–†â–†â–…â–…â–…â–‡â–†â–†â–â–ˆâ–‡
wandb:         train/mil_loss â–†â–‡â–ˆâ–…â–…â–†â–…â–†â–„â–„â–„â–ƒâ–…â–ˆâ–ƒâ–†â–‚â–ƒâ–‡â–†â–ƒâ–ƒâ–„â–ƒâ–‡â–…â–„â–†â–…â–‚â–â–…â–„â–„â–ƒâ–‡â–ƒâ–ƒâ–‚â–†
wandb:      train/policy_loss â–†â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83388
wandb: best/eval_avg_mil_loss 0.70051
wandb:  best/eval_ensemble_f1 0.83388
wandb:            eval/avg_f1 0.73933
wandb:      eval/avg_mil_loss 0.69798
wandb:       eval/ensemble_f1 0.73933
wandb:            test/avg_f1 0.61015
wandb:      test/avg_mil_loss 0.775
wandb:       test/ensemble_f1 0.61015
wandb:           train/avg_f1 0.69157
wandb:      train/ensemble_f1 0.69157
wandb:         train/mil_loss 0.85738
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sunny-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sm9jgudl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052012-sm9jgudl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g8wtzlas with config:
wandb: 	actor_learning_rate: 0.0007838290581396433
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 159
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2984103558697444
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052343-g8wtzlas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g8wtzlas
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml; uploading history steps 146-159, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–†â–†â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‡â–„â–ˆâ–‡â–‡â–‡â–â–†â–ƒâ–‡â–‡â–…â–ˆâ–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–‡â–ˆâ–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:      eval/avg_mil_loss â–†â–„â–‡â–‡â–†â–…â–‡â–…â–†â–â–ƒâ–‚â–…â–†â–†â–†â–†â–‡â–ˆâ–„â–…â–†â–ƒâ–‡â–†â–…â–ˆâ–†â–„â–â–‚â–‡â–â–‚â–†â–„â–†â–†â–‡â–…
wandb:       eval/ensemble_f1 â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–‡â–†â–‡â–†â–ˆâ–†â–…â–‡â–‡â–†â–ˆâ–†â–‡â–‡â–†â–‡â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–ˆâ–…â–†â–â–†â–…â–†â–‡â–‡
wandb:           train/avg_f1 â–‚â–‚â–…â–ƒâ–‚â–‚â–†â–„â–„â–â–„â–„â–ˆâ–„â–…â–…â–†â–…â–„â–†â–…â–‚â–…â–‡â–‡â–‡â–†â–†â–†â–…â–†â–…â–‡â–ƒâ–…â–‡â–…â–…â–ˆâ–†
wandb:      train/ensemble_f1 â–†â–†â–†â–…â–…â–‚â–„â–â–…â–‚â–„â–„â–„â–†â–‚â–ˆâ–ƒâ–„â–…â–†â–…â–…â–„â–†â–„â–…â–‚â–„â–‡â–ˆâ–†â–…â–…â–†â–…â–„â–†â–‡â–„â–†
wandb:         train/mil_loss â–†â–„â–‚â–‡â–„â–…â–„â–‚â–†â–†â–„â–†â–‡â–…â–‚â–ˆâ–‡â–‡â–â–…â–ƒâ–…â–ƒâ–…â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–„â–ƒâ–‡â–…â–‚â–„â–…â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8348
wandb: best/eval_avg_mil_loss 0.75616
wandb:  best/eval_ensemble_f1 0.8348
wandb:            eval/avg_f1 0.80277
wandb:      eval/avg_mil_loss 0.50106
wandb:       eval/ensemble_f1 0.80277
wandb:           train/avg_f1 0.74942
wandb:      train/ensemble_f1 0.74942
wandb:         train/mil_loss 0.71444
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run tough-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g8wtzlas
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052343-g8wtzlas/logs
wandb: ERROR Run g8wtzlas errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cerjg4zi with config:
wandb: 	actor_learning_rate: 1.7923206852559134e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4698250376187164
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052633-cerjg4zi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cerjg4zi
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–†â–†â–†â–…â–„â–†â–ƒâ–„â–†â–„â–„â–ƒâ–†â–„â–†â–‡â–†â–‡â–„â–„â–†â–†â–‡â–„â–†â–„â–„â–†â–†â–ˆâ–‡â–„â–‡â–â–…â–‚â–
wandb:      eval/avg_mil_loss â–…â–†â–…â–†â–…â–„â–…â–…â–‡â–â–†â–ˆâ–…â–ƒâ–ˆâ–…â–†â–…â–ƒâ–ƒâ–†â–„â–†â–…â–‡â–†â–„â–†â–†â–„â–â–‚â–ƒâ–†â–†â–…â–†â–„â–…â–„
wandb:       eval/ensemble_f1 â–„â–„â–‚â–‡â–…â–†â–†â–†â–†â–…â–ƒâ–†â–„â–„â–â–†â–†â–†â–…â–†â–†â–ƒâ–„â–†â–‡â–ƒâ–ƒâ–†â–†â–ˆâ–„â–„â–„â–‡â–…â–†â–†â–…â–â–„
wandb:           train/avg_f1 â–ƒâ–…â–‡â–…â–„â–„â–ƒâ–„â–†â–†â–‡â–‡â–†â–†â–‡â–…â–…â–…â–ˆâ–‡â–†â–‡â–â–…â–ƒâ–‚â–…â–ƒâ–‡â–ƒâ–ˆâ–…â–‡â–‡â–…â–†â–â–…â–†â–‡
wandb:      train/ensemble_f1 â–„â–ƒâ–†â–„â–ˆâ–â–„â–‡â–„â–„â–†â–‚â–†â–„â–‡â–„â–‡â–„â–…â–†â–†â–â–†â–‡â–ƒâ–„â–ƒâ–„â–‡â–…â–‚â–…â–†â–†â–„â–…â–‡â–ƒâ–ˆâ–‡
wandb:         train/mil_loss â–†â–…â–ƒâ–…â–†â–†â–…â–ˆâ–†â–…â–‡â–…â–‚â–ƒâ–…â–…â–‚â–‚â–ˆâ–†â–…â–„â–â–„â–†â–…â–‚â–…â–ƒâ–‚â–â–…â–ƒâ–â–ƒâ–…â–†â–‚â–…â–
wandb:      train/policy_loss â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80257
wandb: best/eval_avg_mil_loss 0.59303
wandb:  best/eval_ensemble_f1 0.80257
wandb:            eval/avg_f1 0.59777
wandb:      eval/avg_mil_loss 0.94372
wandb:       eval/ensemble_f1 0.59777
wandb:           train/avg_f1 0.70294
wandb:      train/ensemble_f1 0.70294
wandb:         train/mil_loss 0.7483
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run jumping-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cerjg4zi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052633-cerjg4zi/logs
wandb: ERROR Run cerjg4zi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1kpo4t7c with config:
wandb: 	actor_learning_rate: 0.0004958388609648109
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3987538008602366
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052822-1kpo4t7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kpo4t7c
wandb: uploading history steps 117-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–…â–â–…â–â–„â–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–‡â–„â–†â–‡â–†â–ƒâ–…â–‡â–‡â–†â–ˆâ–‡â–†â–‡â–†â–‡â–†â–ƒâ–†â–‡â–†â–…â–†â–†â–…â–†â–†â–†â–†â–†â–‡â–â–†â–‡â–†â–…â–†
wandb:      eval/avg_mil_loss â–„â–†â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–†â–ƒâ–ƒâ–‚â–„â–ƒâ–‡â–ƒâ–ƒâ–„â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–„â–‚â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‚â–ƒâ–†â–…â–‡â–†â–ˆâ–‡â–†â–ˆâ–‡â–ˆâ–†â–â–†â–â–…â–†â–‡â–†â–ˆâ–†â–ˆâ–…â–†â–‡â–…â–ˆâ–„â–‡â–‡â–†â–…â–†â–ƒâ–…â–…â–†â–†â–†
wandb:           train/avg_f1 â–‚â–‚â–†â–‚â–‚â–„â–„â–ƒâ–„â–…â–ƒâ–…â–…â–„â–…â–†â–ƒâ–ˆâ–‚â–‡â–‚â–†â–ƒâ–…â–†â–†â–„â–‚â–„â–„â–…â–„â–„â–…â–†â–â–„â–„â–„â–ƒ
wandb:      train/ensemble_f1 â–â–†â–„â–‚â–†â–†â–†â–ƒâ–ƒâ–†â–ƒâ–‚â–…â–„â–†â–ƒâ–†â–â–ƒâ–‚â–â–†â–†â–…â–†â–†â–„â–ˆâ–…â–…â–„â–…â–†â–„â–„â–…â–„â–‚â–‚â–‡
wandb:         train/mil_loss â–†â–…â–…â–‡â–ƒâ–‡â–„â–„â–†â–ˆâ–†â–…â–ƒâ–…â–…â–„â–ƒâ–…â–â–‚â–ƒâ–…â–‚â–ƒâ–„â–†â–ƒâ–…â–„â–‚â–ƒâ–„â–ƒâ–…â–…â–â–ƒâ–‚â–„â–„
wandb:      train/policy_loss â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79404
wandb: best/eval_avg_mil_loss 0.70132
wandb:  best/eval_ensemble_f1 0.79404
wandb:            eval/avg_f1 0.69797
wandb:      eval/avg_mil_loss 0.87629
wandb:       eval/ensemble_f1 0.69797
wandb:           train/avg_f1 0.68894
wandb:      train/ensemble_f1 0.68894
wandb:         train/mil_loss 0.7186
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sandy-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1kpo4t7c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052822-1kpo4t7c/logs
wandb: ERROR Run 1kpo4t7c errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pn9zx4bg with config:
wandb: 	actor_learning_rate: 1.1057726374027227e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13376297241031676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053041-pn9zx4bg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pn9zx4bg
wandb: uploading wandb-summary.json
wandb: uploading history steps 174-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–„â–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–‡â–…â–†â–†â–‡â–†â–…â–†â–‚â–†â–â–„â–ƒâ–…â–‡â–†â–…â–â–…â–†â–…â–‡â–‡â–â–‡â–‡â–†â–‡â–†â–…â–…â–‡â–‡â–†â–ˆâ–ˆâ–…
wandb:      eval/avg_mil_loss â–…â–†â–ƒâ–‚â–ƒâ–â–â–…â–„â–„â–„â–…â–…â–â–ƒâ–ƒâ–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–…â–â–ƒâ–„â–…â–…â–„â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–†â–†â–‡â–†â–ƒâ–‡â–†â–†â–‚â–…â–â–‡â–†â–ˆâ–…â–…â–‡â–‡â–‡â–‡â–†â–â–…â–†â–ˆâ–‡â–†â–‡â–†â–ˆâ–‚â–…â–…â–†â–…â–‡â–…â–‡â–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–†â–…â–„â–…â–„â–…â–†â–„â–â–„â–‚â–ƒâ–„â–†â–„â–…â–…â–„â–…â–‡â–„â–…â–‡â–…â–ˆâ–…â–…â–ƒâ–…â–‡â–„â–…â–„â–†â–†â–ˆâ–„â–†
wandb:      train/ensemble_f1 â–„â–„â–…â–…â–ƒâ–‡â–…â–â–…â–„â–‡â–ƒâ–†â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–…â–„â–„â–‚â–…â–…â–…â–„â–ˆâ–â–ˆâ–…â–‚â–…â–…â–‡â–ƒâ–‚â–†â–†â–ƒ
wandb:         train/mil_loss â–†â–„â–…â–„â–ƒâ–…â–‚â–†â–†â–„â–…â–…â–†â–â–…â–„â–‚â–…â–‡â–…â–‚â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‡â–†â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–„â–…â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86409
wandb: best/eval_avg_mil_loss 0.50825
wandb:  best/eval_ensemble_f1 0.86409
wandb:            eval/avg_f1 0.70059
wandb:      eval/avg_mil_loss 0.85464
wandb:       eval/ensemble_f1 0.70059
wandb:            test/avg_f1 0.76232
wandb:      test/avg_mil_loss 0.49622
wandb:       test/ensemble_f1 0.76232
wandb:           train/avg_f1 0.71929
wandb:      train/ensemble_f1 0.71929
wandb:         train/mil_loss 0.66128
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fragrant-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pn9zx4bg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053041-pn9zx4bg/logs
wandb: Agent Starting Run: 5iprh2by with config:
wandb: 	actor_learning_rate: 5.668882692177237e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8404017855091248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053402-5iprh2by
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5iprh2by
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–†â–‚â–‡â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–ˆâ–„â–„â–ˆâ–…â–…â–…â–‡â–†â–‡â–ˆâ–†â–…â–…â–‡â–‡â–â–…â–‡â–ˆâ–†â–„â–…â–„â–‚â–…â–â–†â–†â–‡â–†â–…â–‡â–…â–…â–†â–…â–…
wandb:      eval/avg_mil_loss â–‡â–‡â–„â–…â–‚â–…â–„â–‚â–ˆâ–…â–…â–ƒâ–…â–„â–â–‚â–„â–‚â–„â–ƒâ–‡â–ƒâ–â–…â–„â–‚â–…â–‚â–â–‚â–‡â–„â–ƒâ–‚â–„â–„â–‚â–„â–„â–
wandb:       eval/ensemble_f1 â–ˆâ–†â–†â–…â–…â–â–†â–‡â–ƒâ–†â–ˆâ–†â–‡â–†â–‡â–†â–‡â–†â–‡â–…â–†â–†â–†â–…â–†â–ˆâ–„â–‡â–†â–†â–†â–†â–‡â–†â–‡â–…â–†â–ˆâ–†â–ˆ
wandb:           train/avg_f1 â–‡â–…â–…â–†â–‡â–†â–„â–…â–„â–†â–…â–†â–†â–…â–…â–…â–…â–‡â–†â–†â–†â–ƒâ–‡â–„â–‡â–‡â–…â–†â–…â–â–…â–‡â–…â–…â–…â–ˆâ–†â–†â–†â–…
wandb:      train/ensemble_f1 â–„â–„â–„â–†â–„â–…â–ƒâ–„â–ƒâ–†â–‡â–â–…â–„â–ƒâ–„â–ˆâ–‡â–„â–„â–‚â–…â–…â–…â–‡â–†â–„â–ƒâ–‚â–ƒâ–‡â–‡â–‡â–…â–…â–„â–…â–†â–„â–†
wandb:         train/mil_loss â–…â–‡â–ˆâ–ƒâ–„â–ˆâ–…â–†â–„â–†â–‚â–…â–„â–†â–ƒâ–†â–‡â–…â–…â–…â–…â–ƒâ–…â–„â–„â–ƒâ–…â–‡â–ƒâ–â–‚â–‚â–†â–‚â–‡â–ƒâ–…â–‡â–†â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83342
wandb: best/eval_avg_mil_loss 0.58749
wandb:  best/eval_ensemble_f1 0.83342
wandb:            eval/avg_f1 0.80833
wandb:      eval/avg_mil_loss 0.62477
wandb:       eval/ensemble_f1 0.80833
wandb:           train/avg_f1 0.70291
wandb:      train/ensemble_f1 0.70291
wandb:         train/mil_loss 0.68731
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pretty-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5iprh2by
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053402-5iprh2by/logs
wandb: ERROR Run 5iprh2by errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: eoljvasj with config:
wandb: 	actor_learning_rate: 1.7570527127581364e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 143
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10137626068073124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053714-eoljvasj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eoljvasj
wandb: uploading wandb-summary.json
wandb: uploading history steps 102-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–„â–…â–„â–„â–†â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–…â–ˆâ–…â–â–‡â–‡â–‡â–†â–ˆâ–†â–‡â–…â–‡â–…â–†â–†â–‡â–†
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–â–ƒâ–…â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–…â–„â–…â–„â–„â–„â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–ˆâ–„â–„â–„â–‚â–„â–‚â–â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–â–†â–ˆâ–â–â–…â–â–…â–…â–â–ˆâ–†â–†â–…â–„â–…â–…â–…â–†â–…â–…â–â–…â–‡â–ƒâ–‡â–‡â–…â–†â–‚â–‡â–…â–†â–‡â–…â–…â–…â–†â–‡â–†
wandb:           train/avg_f1 â–†â–ˆâ–„â–ƒâ–„â–†â–†â–…â–‡â–…â–†â–„â–ƒâ–…â–…â–…â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–ƒâ–„â–…â–…â–…â–â–†â–ƒâ–‡â–…â–ƒâ–‚â–†â–‚â–„â–„â–„â–‚
wandb:      train/ensemble_f1 â–„â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–…â–…â–ƒâ–„â–„â–ƒâ–„â–„â–‡â–†â–„â–‡â–„â–„â–…â–‚â–‚â–…â–‡â–ƒâ–…â–…â–…â–ƒâ–‚â–â–…â–ƒâ–ˆâ–
wandb:         train/mil_loss â–ˆâ–…â–†â–…â–…â–„â–…â–†â–ƒâ–ƒâ–…â–…â–ƒâ–‚â–ƒâ–„â–â–ƒâ–ƒâ–…â–ƒâ–†â–‡â–…â–‚â–…â–†â–‡â–„â–„â–…â–ƒâ–‚â–ˆâ–â–…â–ƒâ–…â–…â–„
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81204
wandb: best/eval_avg_mil_loss 0.85397
wandb:  best/eval_ensemble_f1 0.81204
wandb:            eval/avg_f1 0.73788
wandb:      eval/avg_mil_loss 0.96261
wandb:       eval/ensemble_f1 0.73788
wandb:           train/avg_f1 0.66444
wandb:      train/ensemble_f1 0.66444
wandb:         train/mil_loss 0.73137
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lucky-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eoljvasj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053714-eoljvasj/logs
wandb: ERROR Run eoljvasj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: whignmrq with config:
wandb: 	actor_learning_rate: 0.0001229725791576035
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3637741605266264
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053907-whignmrq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/whignmrq
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–…â–…â–„â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–†â–…â–†â–…â–…â–†â–ƒâ–‡â–‡â–…â–…â–†â–…â–‡â–‡â–‡â–†â–ƒâ–‡â–†â–ˆâ–‡â–„â–†â–†â–„â–…â–â–†â–‡â–†â–‚â–†â–…â–…â–ƒâ–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–…â–†â–„â–ƒâ–†â–ˆâ–…â–ƒâ–ˆâ–â–â–„â–ƒâ–„â–‚â–„â–ƒâ–‚â–…â–ƒâ–‚â–â–†â–„â–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–…â–‡â–„â–‚â–„â–„
wandb:       eval/ensemble_f1 â–†â–†â–„â–â–ƒâ–„â–…â–„â–„â–‚â–„â–…â–„â–„â–„â–ƒâ–‡â–…â–„â–„â–†â–‚â–…â–ƒâ–†â–…â–ƒâ–…â–ˆâ–…â–‡â–…â–†â–…â–†â–…â–‚â–â–…â–…
wandb:           train/avg_f1 â–â–„â–†â–†â–„â–â–…â–„â–…â–„â–ƒâ–ˆâ–…â–ƒâ–„â–†â–‡â–†â–…â–ˆâ–…â–†â–…â–…â–‡â–‡â–…â–‚â–„â–‡â–„â–…â–‚â–„â–…â–…â–‡â–ƒâ–‡â–…
wandb:      train/ensemble_f1 â–…â–„â–†â–‚â–„â–†â–„â–„â–ƒâ–‡â–‡â–‚â–…â–‡â–…â–‡â–†â–‡â–†â–†â–„â–ƒâ–ƒâ–†â–ˆâ–ƒâ–…â–‚â–„â–…â–â–†â–„â–„â–‡â–ƒâ–‡â–…â–†â–‡
wandb:         train/mil_loss â–‚â–‡â–ˆâ–…â–‡â–„â–…â–â–‚â–ˆâ–†â–…â–…â–‚â–„â–ƒâ–â–‡â–ƒâ–‚â–„â–„â–†â–ƒâ–†â–„â–…â–‚â–ƒâ–†â–…â–„â–„â–„â–„â–ƒâ–†â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82414
wandb: best/eval_avg_mil_loss 0.54109
wandb:  best/eval_ensemble_f1 0.82414
wandb:            eval/avg_f1 0.50243
wandb:      eval/avg_mil_loss 1.18969
wandb:       eval/ensemble_f1 0.50243
wandb:           train/avg_f1 0.71257
wandb:      train/ensemble_f1 0.71257
wandb:         train/mil_loss 0.7533
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run magic-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/whignmrq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053907-whignmrq/logs
wandb: ERROR Run whignmrq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: gyft0fk1 with config:
wandb: 	actor_learning_rate: 1.5173766160684695e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.708623118656289
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054232-gyft0fk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gyft0fk1
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–ƒâ–…â–„â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–…â–„â–…â–„â–‡â–ˆâ–†â–†â–‡â–„â–‡â–ˆâ–„â–…â–â–…â–ƒâ–â–‡â–†â–„â–†â–ƒâ–…â–‡â–†â–…â–ˆâ–‡â–…â–„â–‚â–†â–ˆâ–„â–„â–ƒâ–„
wandb:      eval/avg_mil_loss â–†â–ƒâ–…â–„â–„â–ƒâ–‡â–„â–†â–…â–ƒâ–ˆâ–…â–…â–„â–„â–ˆâ–…â–…â–„â–…â–„â–…â–â–‡â–‚â–…â–…â–ƒâ–â–â–„â–…â–ƒâ–…â–‚â–„â–…â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–…â–…â–†â–‡â–…â–ˆâ–…â–‚â–…â–„â–„â–â–„â–„â–‡â–„â–‚â–…â–…â–„â–…â–ƒâ–â–ƒâ–ƒâ–…â–ˆâ–†â–…â–ˆâ–†â–…â–…â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–…â–„â–…â–†â–‚â–†â–…â–ƒâ–…â–ƒâ–†â–…â–ƒâ–‡â–…â–†â–†â–…â–†â–„â–„â–†â–…â–†â–†â–„â–ƒâ–ƒâ–†â–ˆâ–‡â–…â–†â–ƒâ–…â–†â–„â–†â–†
wandb:      train/ensemble_f1 â–†â–â–„â–…â–†â–…â–…â–„â–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–„â–†â–…â–„â–†â–…â–†â–…â–‡â–„â–ƒâ–†â–†â–„â–†â–…â–…â–…â–ˆâ–†â–ƒâ–†â–…â–‡â–…
wandb:         train/mil_loss â–„â–ˆâ–„â–…â–…â–„â–…â–„â–ƒâ–â–†â–†â–ˆâ–‡â–…â–†â–ƒâ–…â–ƒâ–…â–„â–„â–†â–‚â–ƒâ–…â–„â–†â–…â–‡â–ˆâ–‡â–ƒâ–„â–…â–„â–ƒâ–‚â–…â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79818
wandb: best/eval_avg_mil_loss 0.63801
wandb:  best/eval_ensemble_f1 0.79818
wandb:            eval/avg_f1 0.62596
wandb:      eval/avg_mil_loss 0.86166
wandb:       eval/ensemble_f1 0.62596
wandb:            test/avg_f1 0.70963
wandb:      test/avg_mil_loss 0.64201
wandb:       test/ensemble_f1 0.70963
wandb:           train/avg_f1 0.67777
wandb:      train/ensemble_f1 0.67777
wandb:         train/mil_loss 0.79925
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gyft0fk1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054232-gyft0fk1/logs
wandb: Agent Starting Run: zj2ekkbk with config:
wandb: 	actor_learning_rate: 5.2230421464239945e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9705725431029408
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054605-zj2ekkbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zj2ekkbk
wandb: uploading history steps 163-167, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–†â–„â–‚â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–…â–…â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–…â–‡â–†â–…â–ƒâ–ƒâ–„â–„â–†â–‚â–ˆâ–„â–„â–„â–…â–ƒâ–†â–‡â–‚â–‡â–„â–â–†â–„â–ˆâ–†â–„â–„
wandb:      eval/avg_mil_loss â–„â–‡â–ƒâ–…â–„â–ˆâ–„â–â–†â–†â–ƒâ–‡â–‡â–…â–ƒâ–ƒâ–…â–„â–‚â–…â–ˆâ–„â–ƒâ–…â–…â–…â–ƒâ–„â–…â–„â–„â–‡â–…â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–
wandb:       eval/ensemble_f1 â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–…â–‚â–†â–â–„â–ƒâ–ƒâ–†â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–ƒâ–‚â–„â–‚â–…â–„â–„â–„â–ˆâ–„â–ƒâ–â–†â–…â–ƒâ–†â–‡â–â–ƒ
wandb:           train/avg_f1 â–„â–†â–„â–‚â–â–ƒâ–„â–â–„â–„â–„â–…â–…â–ˆâ–ƒâ–„â–‚â–„â–ƒâ–…â–†â–‚â–„â–‡â–…â–‡â–ƒâ–‡â–…â–â–ˆâ–‚â–…â–…â–…â–…â–ƒâ–…â–ƒâ–…
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–†â–ƒâ–…â–ƒâ–â–…â–ƒâ–ˆâ–†â–…â–…â–‡â–…â–‚â–‚â–…â–…â–ƒ
wandb:         train/mil_loss â–‡â–‡â–‡â–‡â–…â–†â–…â–…â–„â–‡â–…â–†â–ˆâ–…â–„â–‡â–„â–…â–†â–†â–‚â–…â–‡â–…â–ƒâ–‚â–ƒâ–ƒâ–â–„â–„â–ƒâ–„â–‚â–ƒâ–„â–…â–‚â–ƒâ–„
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85123
wandb: best/eval_avg_mil_loss 0.50381
wandb:  best/eval_ensemble_f1 0.85123
wandb:            eval/avg_f1 0.80053
wandb:      eval/avg_mil_loss 0.58351
wandb:       eval/ensemble_f1 0.80053
wandb:           train/avg_f1 0.73741
wandb:      train/ensemble_f1 0.73741
wandb:         train/mil_loss 0.67321
wandb:      train/policy_loss -0.14957
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.14957
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run colorful-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zj2ekkbk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054605-zj2ekkbk/logs
wandb: ERROR Run zj2ekkbk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nyv7nzma with config:
wandb: 	actor_learning_rate: 2.771907346480686e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18276892180104776
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054936-nyv7nzma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyv7nzma
wandb: uploading history steps 159-173, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–ˆâ–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–†â–†â–…â–„â–â–†â–†â–…â–ƒâ–ƒâ–‡â–ƒâ–†â–‡â–‡â–ƒâ–†â–ƒâ–†â–‡â–‡â–‡â–‡â–†â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–„
wandb:      eval/avg_mil_loss â–‚â–„â–„â–†â–…â–ˆâ–…â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–„â–‚â–ƒâ–‚â–‚â–…â–‚â–ƒâ–„â–…â–‚â–†â–„â–‚â–â–†â–ƒâ–‚â–„â–…â–†â–„â–â–ƒâ–
wandb:       eval/ensemble_f1 â–„â–…â–†â–†â–„â–†â–â–‡â–†â–„â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–†â–„â–‡â–‡â–„â–‡â–ˆâ–â–‡â–…â–†â–ˆâ–†â–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–…â–„â–„â–†â–„â–„â–‚â–‡â–â–†â–…â–…â–…â–‚â–†â–ƒâ–†â–†â–„â–„â–…â–…â–†â–ƒâ–†â–‡â–…â–‡â–‡â–†â–…â–…â–†â–†â–ƒâ–‡â–ˆâ–ƒâ–‚
wandb:      train/ensemble_f1 â–ƒâ–…â–†â–ƒâ–„â–„â–‡â–…â–…â–†â–…â–‚â–‡â–‡â–„â–ƒâ–…â–…â–ˆâ–„â–‚â–‡â–…â–†â–†â–†â–ƒâ–„â–‡â–…â–„â–„â–…â–†â–ƒâ–ƒâ–…â–â–ˆâ–
wandb:         train/mil_loss â–†â–ˆâ–‡â–†â–‡â–†â–†â–†â–„â–ˆâ–‡â–†â–ˆâ–…â–†â–„â–†â–…â–†â–„â–†â–„â–…â–„â–„â–ˆâ–„â–‚â–‡â–„â–ˆâ–ƒâ–„â–…â–‚â–„â–â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–†â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87231
wandb: best/eval_avg_mil_loss 0.437
wandb:  best/eval_ensemble_f1 0.87231
wandb:            eval/avg_f1 0.72463
wandb:      eval/avg_mil_loss 0.68755
wandb:       eval/ensemble_f1 0.72463
wandb:            test/avg_f1 0.66752
wandb:      test/avg_mil_loss 0.59745
wandb:       test/ensemble_f1 0.66752
wandb:           train/avg_f1 0.73265
wandb:      train/ensemble_f1 0.73265
wandb:         train/mil_loss 0.58916
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nyv7nzma
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054936-nyv7nzma/logs
wandb: Agent Starting Run: nq2bpbq1 with config:
wandb: 	actor_learning_rate: 3.355028320910748e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8776498605205327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055241-nq2bpbq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nq2bpbq1
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–ˆ
wandb:            eval/avg_f1 â–†â–ˆâ–ˆâ–‡â–ˆâ–ƒâ–…â–ƒâ–‡â–‡â–ƒâ–†â–‡â–ƒâ–ƒâ–†â–‡â–†â–â–‡â–„â–‡â–ˆâ–†â–†â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–†â–ˆâ–†â–†â–ˆâ–†â–„â–„
wandb:      eval/avg_mil_loss â–ƒâ–„â–‚â–„â–„â–†â–â–†â–‚â–ƒâ–…â–†â–…â–„â–…â–„â–‚â–ƒâ–‚â–‚â–ˆâ–…â–„â–‚â–†â–„â–„â–‚â–ƒâ–ƒâ–„â–ƒâ–†â–„â–„â–„â–„â–†â–‚â–†
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–†â–†â–ƒâ–„â–‡â–‡â–‡â–†â–…â–ˆâ–†â–ƒâ–‡â–†â–ƒâ–ƒâ–…â–†â–†â–ˆâ–†â–‡â–…â–„â–†â–ˆâ–‡â–…â–â–ˆâ–†â–ƒâ–†â–ˆâ–ƒâ–†â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–…â–…â–†â–†â–ˆâ–ƒâ–ˆâ–„â–…â–‚â–„â–„â–†â–†â–†â–…â–‡â–ƒâ–â–†â–†â–‚â–‡â–ƒâ–ƒâ–…â–…â–…â–†â–ƒâ–…â–…â–…â–„â–ƒâ–ƒâ–‡â–†â–‡
wandb:      train/ensemble_f1 â–‚â–„â–†â–†â–†â–â–‡â–†â–ƒâ–„â–†â–ƒâ–ˆâ–„â–…â–„â–…â–‡â–„â–â–†â–…â–†â–‡â–‡â–†â–…â–„â–ˆâ–ƒâ–†â–…â–†â–„â–…â–‚â–ƒâ–†â–…â–‡
wandb:         train/mil_loss â–…â–ƒâ–†â–‚â–‡â–â–†â–ƒâ–†â–†â–„â–ƒâ–ˆâ–â–‚â–‚â–‡â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–â–ƒâ–â–„â–„â–„â–ˆâ–†â–ˆâ–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8648
wandb: best/eval_avg_mil_loss 0.54424
wandb:  best/eval_ensemble_f1 0.8648
wandb:            eval/avg_f1 0.56934
wandb:      eval/avg_mil_loss 0.79651
wandb:       eval/ensemble_f1 0.56934
wandb:            test/avg_f1 0.77859
wandb:      test/avg_mil_loss 0.34471
wandb:       test/ensemble_f1 0.77859
wandb:           train/avg_f1 0.74688
wandb:      train/ensemble_f1 0.74688
wandb:         train/mil_loss 0.87728
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run good-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nq2bpbq1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055241-nq2bpbq1/logs
wandb: Agent Starting Run: 54d593r8 with config:
wandb: 	actor_learning_rate: 0.0006437901564506275
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.64513733898379
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055456-54d593r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/54d593r8
wandb: uploading history steps 159-168, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ƒâ–ˆâ–ƒâ–‚â–„â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–‡â–‡â–…â–…â–…â–…â–ˆâ–†â–„â–…â–†â–…â–„â–†â–„â–…â–‡â–„â–…â–…â–…â–„â–…â–…â–„â–…â–…â–†â–„â–‡â–†â–ƒâ–‡â–…â–„â–…â–ˆâ–†â–…
wandb:      eval/avg_mil_loss â–‡â–…â–ƒâ–„â–ƒâ–„â–„â–‡â–…â–ƒâ–„â–…â–‡â–ƒâ–‡â–…â–‡â–‚â–…â–…â–‚â–…â–‡â–†â–â–„â–‚â–…â–‚â–‚â–„â–‚â–„â–ƒâ–ˆâ–ˆâ–ˆâ–‡â–…â–ƒ
wandb:       eval/ensemble_f1 â–„â–†â–…â–‚â–…â–†â–…â–‡â–…â–†â–…â–„â–†â–…â–ƒâ–ƒâ–†â–†â–ƒâ–†â–ƒâ–ƒâ–ˆâ–†â–…â–…â–„â–…â–‡â–„â–…â–†â–ƒâ–…â–†â–…â–â–„â–ƒâ–†
wandb:           train/avg_f1 â–†â–†â–…â–ƒâ–„â–‡â–„â–„â–…â–†â–…â–„â–ƒâ–‚â–†â–ƒâ–…â–„â–ƒâ–ƒâ–†â–ƒâ–„â–ˆâ–â–†â–ƒâ–‡â–„â–„â–ƒâ–…â–‡â–‡â–‚â–†â–„â–†â–…â–„
wandb:      train/ensemble_f1 â–‡â–‡â–„â–…â–‡â–‡â–…â–…â–…â–†â–ƒâ–…â–†â–…â–…â–„â–ˆâ–„â–‡â–â–‡â–…â–†â–…â–ˆâ–…â–ˆâ–…â–†â–‡â–†â–†â–ƒâ–…â–†â–…â–…â–„â–†â–…
wandb:         train/mil_loss â–„â–†â–‡â–ƒâ–†â–ˆâ–‡â–…â–ƒâ–‚â–…â–‡â–ˆâ–…â–…â–„â–†â–‡â–â–†â–‡â–…â–…â–‚â–ƒâ–„â–…â–„â–…â–…â–‡â–…â–…â–†â–„â–ƒâ–†â–‚â–ƒâ–†
wandb:      train/policy_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–ˆâ–ˆâ–ˆâ–â–â–„â–ˆâ–â–„â–ˆâ–ˆâ–†â–â–„â–â–„â–„â–„â–ˆâ–ƒâ–„â–â–â–ˆâ–„â–„â–†â–ˆâ–â–„â–ˆâ–â–â–„â–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77493
wandb: best/eval_avg_mil_loss 0.6979
wandb:  best/eval_ensemble_f1 0.77493
wandb:            eval/avg_f1 0.58759
wandb:      eval/avg_mil_loss 0.89921
wandb:       eval/ensemble_f1 0.58759
wandb:           train/avg_f1 0.61951
wandb:      train/ensemble_f1 0.61951
wandb:         train/mil_loss 0.84259
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run serene-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/54d593r8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055456-54d593r8/logs
wandb: ERROR Run 54d593r8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pgkp1gnf with config:
wandb: 	actor_learning_rate: 3.2474349011586263e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04078006427032632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055828-pgkp1gnf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgkp1gnf
wandb: uploading wandb-summary.json; uploading config.yaml; uploading history steps 116-129, summary
wandb: uploading history steps 116-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ƒâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–‡â–…â–‚â–ƒâ–ƒâ–‡â–†â–†â–„â–‡â–ƒâ–†â–„â–ˆâ–„â–‚â–†â–‡â–‡â–„â–‡â–ˆâ–ˆâ–‡â–‡â–…â–ˆâ–ˆâ–…â–â–ˆâ–‡â–‡â–†â–…â–…â–†â–‡
wandb:      eval/avg_mil_loss â–ƒâ–ˆâ–ˆâ–ƒâ–„â–…â–„â–‡â–„â–â–…â–„â–‡â–†â–…â–…â–…â–‡â–…â–„â–…â–ƒâ–ƒâ–…â–…â–‚â–†â–ƒâ–„â–‡â–…â–‡â–„â–ˆâ–‡â–„â–…â–…â–‡â–…
wandb:       eval/ensemble_f1 â–ˆâ–†â–‡â–‡â–‡â–†â–ˆâ–„â–†â–‡â–†â–…â–†â–†â–ƒâ–†â–‡â–„â–„â–„â–†â–‡â–†â–ƒâ–ˆâ–„â–„â–‡â–†â–…â–ˆâ–…â–â–†â–†â–…â–ˆâ–†â–ƒâ–…
wandb:           train/avg_f1 â–‚â–‚â–‚â–„â–„â–‡â–â–â–„â–†â–†â–„â–„â–…â–…â–‡â–ƒâ–…â–‡â–…â–‚â–ˆâ–„â–…â–ƒâ–„â–„â–…â–‚â–†â–†â–‚â–„â–‚â–…â–†â–‚â–…â–ˆâ–‚
wandb:      train/ensemble_f1 â–â–â–‚â–…â–†â–‚â–ˆâ–‚â–†â–†â–‡â–„â–†â–„â–…â–‚â–‚â–…â–†â–‡â–‚â–„â–†â–…â–†â–†â–…â–„â–†â–„â–†â–ƒâ–ƒâ–„â–‡â–‚â–„â–‚â–…â–‚
wandb:         train/mil_loss â–ˆâ–†â–„â–†â–†â–†â–…â–†â–…â–…â–…â–„â–†â–„â–†â–…â–†â–‡â–†â–ˆâ–ƒâ–„â–…â–‡â–…â–„â–‡â–…â–‡â–‡â–â–‡â–†â–ƒâ–„â–ƒâ–‚â–ˆâ–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8228
wandb: best/eval_avg_mil_loss 0.92696
wandb:  best/eval_ensemble_f1 0.8228
wandb:            eval/avg_f1 0.65535
wandb:      eval/avg_mil_loss 0.92794
wandb:       eval/ensemble_f1 0.65535
wandb:           train/avg_f1 0.70501
wandb:      train/ensemble_f1 0.70501
wandb:         train/mil_loss 0.60172
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgkp1gnf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055828-pgkp1gnf/logs
wandb: ERROR Run pgkp1gnf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v2zvhyve with config:
wandb: 	actor_learning_rate: 0.00025109168519178016
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5709450969100892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060057-v2zvhyve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v2zvhyve
wandb: uploading history steps 186-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–…â–†â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–†â–…â–…â–„â–„â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–…â–†â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–ƒâ–‡â–…â–†â–†â–†â–…â–…â–ˆâ–â–â–„â–…â–…â–‡â–…â–ƒâ–†â–„â–‡â–†â–‡â–†â–‡â–„â–…â–‡â–„â–…â–‡â–†â–…â–â–‡â–‚â–…â–‡â–ˆ
wandb:      eval/avg_mil_loss â–ˆâ–‡â–†â–‡â–…â–‡â–ˆâ–†â–„â–…â–†â–†â–„â–…â–…â–†â–†â–†â–ˆâ–†â–‡â–…â–†â–…â–†â–„â–ˆâ–†â–‡â–â–†â–ƒâ–…â–‡â–…â–„â–…â–…â–‚â–†
wandb:       eval/ensemble_f1 â–ƒâ–†â–ƒâ–‡â–…â–†â–…â–‡â–†â–†â–…â–…â–…â–ˆâ–…â–‡â–„â–„â–„â–„â–†â–â–†â–†â–â–†â–„â–ƒâ–…â–‡â–†â–‚â–‚â–…â–„â–ˆâ–…â–„â–…â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–ƒâ–ƒâ–ˆâ–„â–„â–†â–‡â–„â–„â–‡â–†â–„â–…â–‚â–ƒâ–…â–‡â–†â–ƒâ–„â–…â–ˆâ–ˆâ–…â–‡â–„â–†â–â–…â–…â–†â–…â–ˆâ–ƒâ–†â–ˆâ–†â–†
wandb:      train/ensemble_f1 â–†â–„â–‚â–‚â–…â–ƒâ–‡â–‚â–†â–ƒâ–…â–„â–…â–„â–ƒâ–„â–‡â–„â–†â–†â–‚â–…â–â–…â–…â–†â–…â–ˆâ–†â–†â–…â–ˆâ–†â–…â–…â–ˆâ–ƒâ–ˆâ–…â–…
wandb:         train/mil_loss â–‚â–…â–ƒâ–†â–ƒâ–…â–â–ˆâ–‚â–…â–†â–…â–ƒâ–†â–†â–…â–†â–ƒâ–‡â–„â–…â–„â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–…â–…â–„â–†â–…â–„â–ƒâ–…â–†â–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–…â–â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–ˆâ–…â–…â–…â–â–ˆâ–ˆâ–…â–â–…â–…â–…â–â–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8436
wandb: best/eval_avg_mil_loss 0.53068
wandb:  best/eval_ensemble_f1 0.8436
wandb:            eval/avg_f1 0.78927
wandb:      eval/avg_mil_loss 0.6665
wandb:       eval/ensemble_f1 0.78927
wandb:            test/avg_f1 0.78736
wandb:      test/avg_mil_loss 0.66511
wandb:       test/ensemble_f1 0.78736
wandb:           train/avg_f1 0.73962
wandb:      train/ensemble_f1 0.73962
wandb:         train/mil_loss 0.65236
wandb:      train/policy_loss 0.525
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.525
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polar-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v2zvhyve
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060057-v2zvhyve/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qxgwqbts with config:
wandb: 	actor_learning_rate: 0.0006301622196264024
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1588695049739861
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060428-qxgwqbts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxgwqbts
wandb: uploading wandb-summary.json
wandb: uploading history steps 116-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–â–†â–†â–ƒâ–‚â–ˆâ–„â–‚â–„â–‡â–‡â–ƒâ–‚â–†â–ƒâ–‡â–ƒâ–‡â–‡â–‡â–†â–‡â–„â–„â–‡â–‡â–ƒâ–†â–…â–â–„â–ƒâ–…â–„â–†â–‚â–‡â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–†â–ƒâ–…â–…â–ƒâ–…â–„â–„â–ƒâ–„â–„â–ƒâ–„â–â–…â–‚â–„â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–†â–ƒâ–‚â–„â–ˆâ–†â–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–‚â–…
wandb:       eval/ensemble_f1 â–†â–ˆâ–â–‡â–ƒâ–†â–‡â–ˆâ–ˆâ–„â–‡â–ƒâ–†â–†â–ƒâ–‡â–‡â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–‚â–â–…â–ˆâ–„â–ƒâ–â–‡â–ƒâ–‡â–‡â–‡â–†â–‚â–‡â–‚â–…
wandb:           train/avg_f1 â–†â–…â–ƒâ–â–ƒâ–†â–†â–„â–…â–„â–„â–ƒâ–†â–„â–…â–â–†â–„â–ƒâ–…â–†â–ƒâ–„â–â–ˆâ–‚â–†â–†â–„â–‚â–„â–…â–ƒâ–…â–„â–„â–…â–…â–…â–„
wandb:      train/ensemble_f1 â–„â–‡â–…â–ƒâ–…â–‚â–‡â–‡â–†â–„â–‚â–ƒâ–†â–„â–†â–ˆâ–…â–†â–†â–…â–‡â–„â–…â–ˆâ–‡â–…â–ˆâ–‡â–‡â–…â–‡â–†â–â–„â–†â–†â–…â–†â–†â–ƒ
wandb:         train/mil_loss â–„â–„â–â–…â–ƒâ–†â–…â–†â–‡â–„â–‚â–â–†â–‚â–ƒâ–…â–ƒâ–ƒâ–…â–…â–„â–…â–ƒâ–†â–ƒâ–ˆâ–„â–„â–‡â–ƒâ–…â–„â–â–…â–„â–„â–„â–„â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81526
wandb: best/eval_avg_mil_loss 0.79337
wandb:  best/eval_ensemble_f1 0.81526
wandb:            eval/avg_f1 0.5827
wandb:      eval/avg_mil_loss 1.03543
wandb:       eval/ensemble_f1 0.5827
wandb:           train/avg_f1 0.65032
wandb:      train/ensemble_f1 0.65032
wandb:         train/mil_loss 0.94432
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run usual-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qxgwqbts
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060428-qxgwqbts/logs
wandb: ERROR Run qxgwqbts errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5w2fvwxy with config:
wandb: 	actor_learning_rate: 2.168567723674717e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4228941782035466
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060638-5w2fvwxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5w2fvwxy
wandb: uploading wandb-summary.json
wandb: uploading history steps 129-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–â–â–ˆâ–ˆâ–†â–†â–†â–†â–ˆâ–â–†â–…â–†â–ˆâ–†â–†â–†â–…â–‚â–‡â–…â–†â–†â–†â–†â–‡â–†â–â–‡â–…â–‡â–ˆâ–†â–‚â–ˆâ–ƒâ–†â–„â–ƒ
wandb:      eval/avg_mil_loss â–ˆâ–‡â–„â–„â–„â–„â–‚â–…â–†â–†â–ƒâ–â–…â–ƒâ–ˆâ–‚â–„â–ƒâ–‚â–†â–„â–ƒâ–„â–„â–ƒâ–…â–…â–…â–…â–…â–ƒâ–†â–ƒâ–†â–ƒâ–†â–…â–…â–ƒâ–‚
wandb:       eval/ensemble_f1 â–â–†â–†â–‡â–‡â–ˆâ–â–â–ˆâ–‡â–‚â–ˆâ–„â–‡â–ˆâ–†â–ˆâ–ƒâ–‚â–‡â–‚â–‡â–„â–‡â–†â–‚â–ˆâ–…â–ƒâ–†â–†â–ƒâ–ƒâ–‡â–ƒâ–‚â–†â–â–ˆâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–ˆâ–‡â–‡â–†â–ˆâ–‡â–…â–†â–„â–â–…â–‡â–†â–…â–†â–†â–…â–‚â–ˆâ–…â–‡â–ƒâ–ƒâ–…â–…â–ƒâ–†â–‡â–ƒâ–…â–†â–‡â–†â–‡â–‡â–†â–„â–‚
wandb:      train/ensemble_f1 â–ˆâ–‚â–…â–„â–ˆâ–â–„â–…â–‡â–‡â–†â–„â–†â–‡â–â–†â–†â–†â–ˆâ–…â–†â–…â–†â–‡â–‡â–…â–…â–…â–‡â–„â–…â–‡â–‚â–ƒâ–…â–‡â–‡â–…â–‚â–†
wandb:         train/mil_loss â–ˆâ–…â–‚â–…â–ƒâ–„â–â–„â–„â–„â–…â–„â–…â–ƒâ–†â–â–†â–â–‡â–„â–ƒâ–…â–„â–‚â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–‚â–„â–‡â–‚â–„â–‚â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85627
wandb: best/eval_avg_mil_loss 1.18599
wandb:  best/eval_ensemble_f1 0.85627
wandb:            eval/avg_f1 0.655
wandb:      eval/avg_mil_loss 0.75015
wandb:       eval/ensemble_f1 0.655
wandb:            test/avg_f1 0.85465
wandb:      test/avg_mil_loss 0.66335
wandb:       test/ensemble_f1 0.85465
wandb:           train/avg_f1 0.68434
wandb:      train/ensemble_f1 0.68434
wandb:         train/mil_loss 0.70451
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run prime-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5w2fvwxy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060638-5w2fvwxy/logs
wandb: Agent Starting Run: tgar004y with config:
wandb: 	actor_learning_rate: 0.00036420837374157326
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2936177956175936
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060913-tgar004y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tgar004y
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–ˆ
wandb:            eval/avg_f1 â–â–…â–‡â–‡â–‡â–†â–ƒâ–…â–ˆâ–ˆâ–…â–ƒâ–„â–‡â–„â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–„â–‡â–†â–‡â–…â–‡â–†â–‡â–„â–‡â–†â–ˆâ–‚â–ˆâ–†â–ˆâ–‚â–†
wandb:      eval/avg_mil_loss â–„â–†â–…â–ƒâ–…â–‡â–†â–ƒâ–…â–ƒâ–‡â–ƒâ–â–ƒâ–„â–ƒâ–…â–â–…â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–‚â–„â–†â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–ˆâ–…â–…
wandb:       eval/ensemble_f1 â–ˆâ–â–‡â–‡â–†â–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–…â–„â–„â–„â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–„â–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–â–‚â–†â–ˆâ–†â–‚â–ˆâ–ˆâ–†â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–„â–†â–‡â–ƒâ–†â–…â–†â–‚â–ƒâ–…â–‚â–ƒâ–ˆâ–…â–„â–„â–„â–…â–ƒâ–…â–†â–„â–…â–‚â–„â–†â–†â–…â–„â–…â–ˆâ–…â–â–…â–„â–†â–…â–„
wandb:      train/ensemble_f1 â–…â–„â–‡â–‡â–ƒâ–…â–†â–†â–‡â–†â–ˆâ–†â–ƒâ–†â–„â–ƒâ–…â–‡â–„â–…â–…â–…â–…â–†â–†â–„â–„â–†â–…â–‡â–†â–…â–„â–†â–â–„â–†â–„â–…â–†
wandb:         train/mil_loss â–„â–ƒâ–…â–„â–…â–…â–‚â–ƒâ–„â–„â–ƒâ–‡â–…â–‚â–…â–„â–†â–ƒâ–„â–ƒâ–ƒâ–„â–…â–‚â–†â–…â–…â–…â–ƒâ–ƒâ–…â–…â–ˆâ–…â–â–…â–â–ƒâ–†â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8266
wandb: best/eval_avg_mil_loss 0.56621
wandb:  best/eval_ensemble_f1 0.8266
wandb:            eval/avg_f1 0.68227
wandb:      eval/avg_mil_loss 1.02639
wandb:       eval/ensemble_f1 0.68227
wandb:            test/avg_f1 0.84982
wandb:      test/avg_mil_loss 0.29431
wandb:       test/ensemble_f1 0.84982
wandb:           train/avg_f1 0.74545
wandb:      train/ensemble_f1 0.74545
wandb:         train/mil_loss 0.7416
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run worldly-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tgar004y
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060913-tgar004y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 64o3p8sn with config:
wandb: 	actor_learning_rate: 6.797231477134681e-06
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9017662075411088
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061135-64o3p8sn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/64o3p8sn
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–„â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–†â–„â–„â–†â–„â–„â–†â–…â–…â–„â–„â–…â–„â–†â–„â–ƒâ–‚â–…â–„â–…â–…â–ƒâ–â–…â–…â–„â–…â–†â–‚â–…â–†â–…â–„â–†â–„â–†â–†â–ˆâ–…
wandb:      eval/avg_mil_loss â–‡â–„â–ƒâ–ƒâ–†â–„â–„â–„â–…â–‚â–„â–ƒâ–„â–ƒâ–…â–‡â–„â–„â–…â–ˆâ–†â–‚â–„â–ƒâ–„â–†â–‚â–ƒâ–…â–‡â–…â–„â–…â–ƒâ–„â–‚â–â–‚â–„â–‚
wandb:       eval/ensemble_f1 â–†â–…â–…â–…â–†â–†â–…â–…â–†â–…â–…â–ˆâ–‡â–‚â–‡â–ƒâ–„â–†â–„â–„â–ƒâ–â–…â–…â–„â–„â–‚â–…â–‚â–‡â–†â–…â–„â–‡â–…â–†â–…â–…â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‚â–†â–ƒâ–‚â–‚â–…â–…â–†â–†â–‡â–‡â–„â–ˆâ–â–„â–†â–…â–â–â–†â–…â–ƒâ–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–†â–…â–…â–…â–„â–ˆâ–…â–„â–„
wandb:      train/ensemble_f1 â–‡â–‡â–ƒâ–ˆâ–…â–ƒâ–…â–…â–‡â–†â–…â–…â–…â–„â–‡â–ƒâ–ƒâ–†â–‡â–ƒâ–…â–…â–ˆâ–‡â–ƒâ–…â–ˆâ–†â–„â–†â–„â–‡â–‡â–ˆâ–…â–„â–â–…â–„â–†
wandb:         train/mil_loss â–„â–†â–…â–‡â–„â–†â–„â–…â–…â–ˆâ–…â–ƒâ–„â–…â–„â–…â–ƒâ–„â–…â–„â–…â–…â–„â–ƒâ–…â–„â–…â–„â–ƒâ–„â–„â–â–†â–„â–†â–„â–ƒâ–…â–„â–„
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–‡â–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84015
wandb: best/eval_avg_mil_loss 0.76518
wandb:  best/eval_ensemble_f1 0.84015
wandb:            eval/avg_f1 0.72957
wandb:      eval/avg_mil_loss 0.70635
wandb:       eval/ensemble_f1 0.72957
wandb:            test/avg_f1 0.78736
wandb:      test/avg_mil_loss 0.60064
wandb:       test/ensemble_f1 0.78736
wandb:           train/avg_f1 0.70722
wandb:      train/ensemble_f1 0.70722
wandb:         train/mil_loss 0.62847
wandb:      train/policy_loss -0.46516
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.46516
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run graceful-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/64o3p8sn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061135-64o3p8sn/logs
wandb: Agent Starting Run: 2glpvtou with config:
wandb: 	actor_learning_rate: 1.8603741224438782e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6489150423635117
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061400-2glpvtou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2glpvtou
wandb: uploading history steps 74-86, summary; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–ƒâ–â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–…â–†â–†â–†â–„â–ƒâ–…â–…â–†â–…â–†â–…â–â–…â–‡â–†â–†â–…â–…â–â–†â–ˆâ–…â–„â–†â–…â–†â–…â–ˆâ–‡â–ƒâ–ˆâ–‡â–†â–…â–†â–†â–‡
wandb:      eval/avg_mil_loss â–‡â–„â–…â–„â–†â–‡â–…â–ˆâ–†â–…â–ƒâ–…â–…â–„â–…â–…â–‡â–„â–„â–„â–ƒâ–‡â–â–ƒâ–…â–…â–„â–„â–†â–†â–„â–…â–ƒâ–…â–…â–„â–…â–‡â–†â–‡
wandb:       eval/ensemble_f1 â–â–†â–‡â–„â–†â–…â–ƒâ–…â–…â–†â–†â–‚â–…â–…â–†â–„â–†â–†â–…â–ˆâ–‚â–†â–ˆâ–†â–…â–†â–†â–‡â–†â–„â–ƒâ–…â–…â–‡â–†â–…â–ƒâ–…â–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–…â–ƒâ–†â–†â–â–„â–‚â–„â–…â–†â–…â–‚â–…â–‚â–„â–†â–„â–‡â–„â–‚â–ƒâ–‡â–‚â–†â–‡â–…â–ƒâ–ˆâ–ƒâ–‚â–…â–„â–‡â–ˆâ–„â–…â–ˆâ–†
wandb:      train/ensemble_f1 â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–â–„â–ƒâ–…â–‚â–„â–„â–„â–…â–„â–†â–…â–ƒâ–„â–‚â–…â–„â–…â–‚â–†â–â–„â–„â–ƒâ–„â–†â–…â–„â–ˆâ–…â–„â–†â–ƒ
wandb:         train/mil_loss â–‚â–†â–†â–‚â–†â–…â–†â–ƒâ–…â–…â–…â–ˆâ–†â–…â–„â–‚â–ƒâ–…â–‡â–‚â–†â–ƒâ–„â–†â–†â–‚â–ƒâ–ƒâ–ƒâ–†â–â–‚â–…â–ƒâ–„â–„â–‚â–„â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85571
wandb: best/eval_avg_mil_loss 0.459
wandb:  best/eval_ensemble_f1 0.85571
wandb:            eval/avg_f1 0.61674
wandb:      eval/avg_mil_loss 1.0268
wandb:       eval/ensemble_f1 0.61674
wandb:            test/avg_f1 0.63655
wandb:      test/avg_mil_loss 0.9413
wandb:       test/ensemble_f1 0.63655
wandb:           train/avg_f1 0.72008
wandb:      train/ensemble_f1 0.72008
wandb:         train/mil_loss 0.69751
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run treasured-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2glpvtou
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061400-2glpvtou/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9bhdrdak with config:
wandb: 	actor_learning_rate: 1.7340925134925288e-06
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7540514603693792
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061558-9bhdrdak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bhdrdak
wandb: uploading history steps 183-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–„â–…â–…â–…â–…â–†â–„â–„â–‡â–…â–‡â–…â–„â–ƒâ–‡â–â–†â–‡â–…â–…â–†â–†â–…â–„â–„â–„â–…â–„â–ƒâ–†â–„â–†â–†â–ˆâ–â–…â–‡â–…
wandb:      eval/avg_mil_loss â–ˆâ–†â–…â–ƒâ–…â–‡â–ƒâ–ƒâ–ƒâ–„â–†â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–„â–…â–…â–†â–â–â–„â–ƒâ–‚â–†â–ƒâ–‚â–‚â–ƒâ–…â–â–„â–ƒâ–‚â–‚â–â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–„â–ƒâ–ƒâ–…â–†â–‡â–†â–†â–…â–…â–ƒâ–‡â–‡â–ˆâ–â–‡â–‡â–„â–ƒâ–‡â–…â–†â–…â–†â–‡â–„â–…â–†â–‡â–‡â–†â–ƒâ–ƒâ–ˆâ–…â–ˆâ–‡â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–†â–â–„â–ƒâ–„â–‚â–†â–ƒâ–…â–…â–…â–„â–‚â–†â–…â–†â–‡â–ƒâ–ˆâ–„â–…â–â–…â–„â–…â–†â–…â–ƒâ–‡â–…â–†â–‡â–†â–ˆâ–†â–„â–…â–‡
wandb:      train/ensemble_f1 â–„â–ƒâ–ƒâ–…â–…â–„â–…â–â–ƒâ–…â–„â–ƒâ–ƒâ–â–ƒâ–‡â–„â–ƒâ–ƒâ–‚â–‚â–†â–ƒâ–â–…â–„â–„â–„â–„â–…â–†â–ˆâ–…â–†â–…â–…â–„â–…â–„â–ˆ
wandb:         train/mil_loss â–‡â–‡â–‡â–…â–…â–ˆâ–†â–‡â–†â–…â–ƒâ–…â–…â–‡â–„â–…â–„â–„â–…â–‚â–„â–„â–„â–ƒâ–‚â–‚â–ƒâ–â–„â–„â–‚â–ƒâ–‚â–ƒâ–„â–â–‚â–ƒâ–ƒâ–ƒ
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83388
wandb: best/eval_avg_mil_loss 0.58828
wandb:  best/eval_ensemble_f1 0.83388
wandb:            eval/avg_f1 0.74747
wandb:      eval/avg_mil_loss 0.65606
wandb:       eval/ensemble_f1 0.74747
wandb:            test/avg_f1 0.82039
wandb:      test/avg_mil_loss 0.53141
wandb:       test/ensemble_f1 0.82039
wandb:           train/avg_f1 0.79881
wandb:      train/ensemble_f1 0.79881
wandb:         train/mil_loss 0.59651
wandb:      train/policy_loss 0.15822
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.15822
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sandy-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bhdrdak
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061558-9bhdrdak/logs
wandb: Agent Starting Run: ms8e2lix with config:
wandb: 	actor_learning_rate: 1.2118555336415223e-05
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8197175603176269
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061950-ms8e2lix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ms8e2lix
wandb: uploading history steps 110-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–â–‚â–ƒâ–„â–ƒâ–…â–†â–‚â–…â–…â–„â–„â–‚â–â–„â–…â–ƒâ–„â–†â–ƒâ–‚â–†â–ƒâ–„â–â–…â–ƒâ–„â–ƒâ–†â–†â–ƒâ–ˆâ–ƒâ–†â–…â–‡â–…â–„
wandb:      eval/avg_mil_loss â–ˆâ–„â–„â–…â–†â–„â–‚â–…â–ƒâ–‡â–„â–„â–‡â–…â–†â–„â–…â–ƒâ–ƒâ–‚â–‡â–„â–‚â–…â–†â–‚â–â–„â–…â–…â–…â–‚â–„â–„â–ƒâ–„â–…â–„â–„â–‚
wandb:       eval/ensemble_f1 â–‚â–ƒâ–â–‚â–ƒâ–„â–‡â–ƒâ–…â–„â–…â–‚â–ƒâ–…â–‡â–†â–‡â–‚â–„â–…â–‡â–„â–…â–†â–ˆâ–…â–…â–‡â–ƒâ–„â–„â–„â–†â–ˆâ–„â–…â–…â–ˆâ–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–…â–â–â–„â–†â–„â–…â–„â–„â–ƒâ–„â–ƒâ–„â–†â–„â–…â–†â–ƒâ–‚â–†â–‡â–†â–‡â–„â–„â–…â–‡â–†â–‡â–…â–‡â–…â–†â–‡â–…â–†â–ˆâ–…â–†
wandb:      train/ensemble_f1 â–„â–…â–â–„â–„â–ˆâ–…â–†â–‡â–ƒâ–„â–‡â–…â–‡â–…â–„â–†â–†â–„â–†â–†â–…â–…â–†â–‡â–…â–…â–†â–ƒâ–…â–†â–‡â–ˆâ–†â–‡â–ˆâ–‡â–‡â–ˆâ–†
wandb:         train/mil_loss â–…â–‡â–ˆâ–…â–†â–…â–…â–ƒâ–‡â–…â–†â–†â–…â–„â–„â–…â–…â–ƒâ–†â–‚â–ƒâ–…â–„â–…â–…â–„â–‚â–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84499
wandb: best/eval_avg_mil_loss 0.4676
wandb:  best/eval_ensemble_f1 0.84499
wandb:            eval/avg_f1 0.78022
wandb:      eval/avg_mil_loss 0.56589
wandb:       eval/ensemble_f1 0.78022
wandb:            test/avg_f1 0.78301
wandb:      test/avg_mil_loss 0.48267
wandb:       test/ensemble_f1 0.78301
wandb:           train/avg_f1 0.78071
wandb:      train/ensemble_f1 0.78071
wandb:         train/mil_loss 0.58092
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run divine-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ms8e2lix
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061950-ms8e2lix/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7x0tglla with config:
wandb: 	actor_learning_rate: 8.292866705110153e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 56
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2550818839156864
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062230-7x0tglla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7x0tglla
wandb: uploading wandb-summary.json; uploading config.yaml; uploading history steps 43-57, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–…â–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–‡â–‡â–…â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ƒâ–‡â–â–‡â–‡â–†â–‡â–…â–ˆâ–†â–‡â–…â–‡â–‡â–‡â–†â–ˆâ–…â–†â–†â–†â–‡â–„â–„â–ˆ
wandb:      eval/avg_mil_loss â–‚â–‚â–…â–‚â–‚â–„â–ƒâ–ƒâ–â–†â–‚â–‚â–‚â–ƒâ–ƒâ–†â–‚â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–„â–â–â–‚â–‚â–‚â–„â–‚â–ƒâ–‚â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–‡â–ƒâ–‡â–…â–â–‡â–‡â–‡â–ˆâ–„â–‡â–‡â–ˆâ–‡â–‡â–ƒâ–‡â–â–ˆâ–‡â–†â–‡â–…â–ˆâ–†â–†â–‡â–‡â–„â–…â–‡â–‡â–ˆâ–†â–…â–†â–†â–‡â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–ƒâ–…â–†â–„â–…â–ˆâ–…â–‚â–„â–„â–†â–ƒâ–„â–…â–…â–„â–‡â–‡â–†â–„â–…â–â–†â–‡â–…â–„â–†â–…â–â–…â–…â–…â–†â–…â–‡â–†â–‡â–†
wandb:      train/ensemble_f1 â–…â–…â–…â–†â–„â–ˆâ–‚â–‡â–„â–†â–„â–†â–„â–†â–…â–„â–‡â–‡â–„â–†â–…â–â–†â–„â–‡â–„â–†â–†â–…â–…â–…â–…â–†â–‡â–…â–‡â–…â–ˆâ–‡â–†
wandb:         train/mil_loss â–‚â–â–„â–ƒâ–ƒâ–‚â–†â–ƒâ–ƒâ–‡â–‡â–ƒâ–‚â–‡â–„â–â–ƒâ–„â–…â–‡â–ˆâ–…â–…â–„â–…â–…â–…â–„â–…â–†â–†â–â–„â–„â–ƒâ–…â–‚â–ƒâ–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81889
wandb: best/eval_avg_mil_loss 0.66779
wandb:  best/eval_ensemble_f1 0.81889
wandb:            eval/avg_f1 0.81889
wandb:      eval/avg_mil_loss 0.66779
wandb:       eval/ensemble_f1 0.81889
wandb:            test/avg_f1 0.69704
wandb:      test/avg_mil_loss 0.55596
wandb:       test/ensemble_f1 0.69704
wandb:           train/avg_f1 0.74748
wandb:      train/ensemble_f1 0.74748
wandb:         train/mil_loss 0.65656
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run frosty-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7x0tglla
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062230-7x0tglla/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 7qgnjsf1 with config:
wandb: 	actor_learning_rate: 7.734920312042465e-05
wandb: 	attention_dropout_p: 0.4757306587706696
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9059335219025488
wandb: 	temperature: 8.449042611113123
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062434-7qgnjsf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qgnjsf1
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 119-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ƒâ–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–‚â–…â–ˆâ–ˆâ–…â–…â–‚â–â–…â–ˆâ–â–‚â–‡â–ˆâ–ˆâ–‚â–ˆâ–‡â–ˆâ–‚â–‚â–ˆâ–‚â–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–†â–…â–‡â–â–„â–ˆâ–ˆâ–…â–„
wandb:      eval/avg_mil_loss â–‡â–„â–‚â–…â–„â–‡â–…â–ƒâ–â–…â–‚â–‚â–…â–„â–â–„â–ƒâ–‚â–…â–…â–„â–„â–„â–‚â–â–‚â–ƒâ–…â–‚â–â–…â–†â–„â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–ˆ
wandb:       eval/ensemble_f1 â–…â–ˆâ–…â–†â–„â–…â–‚â–â–…â–ˆâ–‚â–‡â–ˆâ–‡â–…â–…â–ˆâ–ˆâ–…â–‚â–…â–‚â–†â–†â–ˆâ–ˆâ–…â–…â–…â–†â–…â–†â–‡â–‡â–„â–…â–ˆâ–…â–ˆâ–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–†â–…â–‡â–„â–…â–†â–†â–‡â–†â–†â–†â–†â–ˆâ–…â–†â–‡â–„â–‡â–…â–†â–†â–„â–â–…â–…â–†â–†â–†â–†â–…â–„â–‡â–†â–‡â–„â–ˆâ–‡â–ƒ
wandb:      train/ensemble_f1 â–…â–„â–†â–‡â–ƒâ–„â–…â–‡â–†â–…â–‡â–†â–ˆâ–ˆâ–ƒâ–‡â–…â–…â–„â–ƒâ–‡â–„â–â–ƒâ–ƒâ–…â–„â–„â–„â–†â–‚â–…â–‡â–†â–†â–ƒâ–…â–‡â–‡â–‚
wandb:         train/mil_loss â–†â–‡â–‡â–ˆâ–†â–‡â–ˆâ–…â–„â–‡â–„â–…â–„â–†â–‡â–â–‚â–†â–ˆâ–…â–„â–†â–ƒâ–‡â–ˆâ–‡â–„â–ˆâ–‡â–‡â–…â–„â–‡â–ƒâ–ƒâ–†â–„â–ƒâ–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77957
wandb: best/eval_avg_mil_loss 0.57326
wandb:  best/eval_ensemble_f1 0.77957
wandb:            eval/avg_f1 0.72747
wandb:      eval/avg_mil_loss 0.68229
wandb:       eval/ensemble_f1 0.72747
wandb:            test/avg_f1 0.34754
wandb:      test/avg_mil_loss 0.84945
wandb:       test/ensemble_f1 0.34754
wandb:           train/avg_f1 0.57917
wandb:      train/ensemble_f1 0.57917
wandb:         train/mil_loss 0.69802
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7qgnjsf1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062434-7qgnjsf1/logs
wandb: Agent Starting Run: 29rg9709 with config:
wandb: 	actor_learning_rate: 0.0004925631227808748
wandb: 	attention_dropout_p: 0.1445032993586461
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8298206110144439
wandb: 	temperature: 4.947292121122989
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062647-29rg9709
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/29rg9709
wandb: uploading history steps 107-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–†â–†â–ƒâ–„â–â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–…â–‡â–‡â–‡â–ƒâ–†â–â–…â–ˆâ–†â–‡â–…â–…â–…â–…â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–…â–‡â–…â–‡â–…â–…â–‡â–ˆâ–…â–ƒâ–‡â–†â–‡â–…â–…
wandb:      eval/avg_mil_loss â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–ˆâ–…â–‚â–…â–„â–ƒâ–…â–…â–ƒâ–„â–…â–‡â–…â–„â–„â–†â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–…
wandb:       eval/ensemble_f1 â–…â–‡â–ˆâ–‡â–…â–†â–ˆâ–â–…â–…â–†â–ˆâ–‡â–…â–…â–‡â–…â–‡â–…â–…â–ƒâ–…â–ˆâ–ˆâ–‡â–‡â–…â–…â–‡â–…â–†â–‚â–ˆâ–‡â–‡â–ˆâ–…â–†â–ˆâ–†
wandb:           train/avg_f1 â–„â–…â–ˆâ–ƒâ–ƒâ–„â–…â–†â–„â–…â–ˆâ–…â–„â–ƒâ–â–†â–ƒâ–ƒâ–‡â–‡â–‡â–†â–„â–ƒâ–…â–†â–…â–„â–„â–â–‡â–„â–„â–…â–†â–…â–…â–„â–‡â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–†â–„â–„â–„â–„â–‚â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–…â–…â–ˆâ–„â–…â–‡â–…â–†â–†â–…â–„â–…â–â–‚â–„â–„â–†â–ƒâ–ƒâ–‚â–„â–‡â–ƒâ–†â–…
wandb:         train/mil_loss â–‚â–ƒâ–„â–‚â–„â–ƒâ–†â–‚â–‚â–‡â–ƒâ–â–†â–‚â–ƒâ–†â–…â–†â–„â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–†â–ƒâ–„â–„â–„â–ˆâ–…â–…â–„â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.54715
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.62527
wandb:      eval/avg_mil_loss 0.61652
wandb:       eval/ensemble_f1 0.62527
wandb:           train/avg_f1 0.63754
wandb:      train/ensemble_f1 0.63754
wandb:         train/mil_loss 0.70904
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run ruby-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/29rg9709
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062647-29rg9709/logs
wandb: ERROR Run 29rg9709 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 4u70klne with config:
wandb: 	actor_learning_rate: 0.00036023269091007355
wandb: 	attention_dropout_p: 0.4879364792230948
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4031303028107487
wandb: 	temperature: 6.9516811879332865
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062852-4u70klne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4u70klne
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–‡â–„â–„â–„â–†â–‡â–ˆâ–‡â–ˆâ–…â–‡â–ƒâ–‚â–…â–…â–‡â–…â–„â–‡â–…â–‡â–„â–‚â–…â–„â–…â–â–ƒâ–…â–…â–â–‚â–‚â–‡â–‡â–†â–‡â–…
wandb:      eval/avg_mil_loss â–„â–„â–‚â–ƒâ–â–„â–„â–„â–†â–†â–„â–„â–„â–ƒâ–†â–ˆâ–„â–…â–‚â–ƒâ–„â–†â–‚â–†â–†â–ˆâ–†â–‡â–‚â–„â–‡â–‡â–„â–†â–â–…â–ƒâ–‡â–â–…
wandb:       eval/ensemble_f1 â–‡â–‡â–†â–„â–†â–„â–â–â–‡â–ˆâ–…â–ˆâ–ˆâ–…â–‡â–„â–‚â–†â–‡â–ˆâ–…â–…â–…â–…â–ˆâ–†â–â–ƒâ–…â–…â–‡â–‡â–„â–ˆâ–â–‚â–‡â–ƒâ–‡â–ˆ
wandb:           train/avg_f1 â–†â–†â–ƒâ–ƒâ–…â–…â–„â–…â–ƒâ–ˆâ–†â–…â–„â–…â–†â–…â–…â–„â–â–†â–…â–‚â–‡â–„â–…â–ƒâ–…â–…â–…â–…â–…â–„â–…â–„â–…â–†â–„â–…â–‡â–‡
wandb:      train/ensemble_f1 â–„â–†â–ƒâ–ƒâ–…â–…â–„â–„â–†â–ˆâ–ƒâ–…â–„â–…â–ƒâ–„â–„â–„â–ƒâ–†â–…â–‡â–‡â–†â–‚â–„â–…â–â–ƒâ–„â–„â–†â–ƒâ–…â–â–…â–…â–â–ƒâ–…
wandb:         train/mil_loss â–‚â–„â–ƒâ–†â–…â–â–â–ˆâ–…â–„â–…â–†â–â–â–…â–„â–„â–…â–†â–ƒâ–‚â–„â–…â–ˆâ–…â–„â–…â–‡â–ˆâ–ˆâ–ƒâ–†â–ƒâ–â–‡â–ƒâ–†â–ƒâ–…â–…
wandb:      train/policy_loss â–„â–„â–†â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–â–ˆâ–„â–„â–†â–ˆâ–„â–ˆâ–ˆâ–„â–ƒâ–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–â–„â–„â–„â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ƒâ–…â–ˆâ–…â–â–ƒâ–…â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–â–…â–ƒâ–…â–â–ˆâ–…â–…â–…â–ˆâ–…â–â–ˆâ–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83476
wandb: best/eval_avg_mil_loss 0.46716
wandb:  best/eval_ensemble_f1 0.83476
wandb:            eval/avg_f1 0.61983
wandb:      eval/avg_mil_loss 0.79493
wandb:       eval/ensemble_f1 0.61983
wandb:           train/avg_f1 0.66943
wandb:      train/ensemble_f1 0.66943
wandb:         train/mil_loss 0.73672
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run celestial-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4u70klne
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062852-4u70klne/logs
wandb: ERROR Run 4u70klne errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9pz8j84k with config:
wandb: 	actor_learning_rate: 1.0157782153568212e-06
wandb: 	attention_dropout_p: 0.4483930450327599
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7755767673333852
wandb: 	temperature: 7.037798175552007
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063116-9pz8j84k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9pz8j84k
wandb: uploading wandb-summary.json
wandb: uploading history steps 93-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–†â–â–†
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–‡â–„â–ƒâ–‡â–‚â–„â–…â–‡â–„â–„â–†â–ˆâ–…â–ƒâ–‡â–â–ˆâ–‚â–…â–„â–‡â–…â–‚â–ƒâ–„â–…â–‡â–â–‡â–‡â–ƒâ–ƒâ–ƒâ–„â–„â–†â–ƒâ–„
wandb:      eval/avg_mil_loss â–‚â–‡â–†â–…â–…â–‚â–â–…â–ƒâ–†â–‡â–†â–‚â–…â–ˆâ–‚â–…â–†â–ˆâ–…â–…â–…â–†â–‡â–…â–†â–‚â–†â–„â–…â–†â–â–‡â–„â–…â–…â–…â–‚â–†â–‚
wandb:       eval/ensemble_f1 â–‡â–„â–‡â–…â–„â–‡â–†â–„â–†â–…â–‡â–‡â–†â–ƒâ–…â–†â–„â–ƒâ–†â–ƒâ–†â–â–‡â–†â–ˆâ–„â–‡â–‡â–‡â–…â–„â–…â–„â–„â–‡â–†â–‡â–…â–‡â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–„â–…â–„â–‚â–„â–†â–„â–…â–…â–…â–„â–…â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–‡â–„â–„â–â–†â–„â–„â–…â–†â–ƒâ–…â–‚â–‚â–ƒ
wandb:      train/ensemble_f1 â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–‡â–ƒâ–…â–…â–…â–ˆâ–ƒâ–‚â–†â–†â–…â–…â–ƒâ–„â–‚â–„â–ƒâ–„â–†â–…â–‡â–„â–â–†â–„â–‡â–…â–†â–†â–„â–†â–‚â–‚
wandb:         train/mil_loss â–ƒâ–„â–‡â–†â–†â–„â–…â–‡â–…â–…â–†â–…â–…â–†â–ƒâ–ˆâ–„â–„â–†â–†â–…â–‡â–ƒâ–†â–„â–…â–â–…â–…â–ˆâ–…â–‚â–…â–ƒâ–†â–„â–„â–„â–‡â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8272
wandb: best/eval_avg_mil_loss 0.64749
wandb:  best/eval_ensemble_f1 0.8272
wandb:            eval/avg_f1 0.76379
wandb:      eval/avg_mil_loss 0.63818
wandb:       eval/ensemble_f1 0.76379
wandb:            test/avg_f1 0.77871
wandb:      test/avg_mil_loss 0.44304
wandb:       test/ensemble_f1 0.77871
wandb:           train/avg_f1 0.76137
wandb:      train/ensemble_f1 0.76137
wandb:         train/mil_loss 0.56138
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polished-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9pz8j84k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063116-9pz8j84k/logs
wandb: Agent Starting Run: mmtju8py with config:
wandb: 	actor_learning_rate: 9.376460044976456e-06
wandb: 	attention_dropout_p: 0.4195649386610502
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22556544349083263
wandb: 	temperature: 1.101464212334884
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063301-mmtju8py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mmtju8py
wandb: uploading history steps 152-154, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–…â–ˆâ–…â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–â–â–…â–‚â–â–‡â–‚â–‚â–‡â–‡â–ˆâ–â–‡â–â–‚â–ˆâ–‚â–‡â–â–‚â–‚â–‚â–‡â–â–‡â–‡â–†â–‡â–…â–†â–‡â–‚â–„â–…â–†â–‚â–‡â–ƒâ–…
wandb:      eval/avg_mil_loss â–‡â–†â–…â–„â–…â–ƒâ–…â–†â–‚â–ƒâ–…â–ƒâ–‡â–†â–‚â–„â–…â–…â–†â–â–ƒâ–ƒâ–‡â–†â–†â–ƒâ–ƒâ–„â–†â–ˆâ–…â–â–…â–†â–ƒâ–‚â–…â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–‡â–â–‡â–ƒâ–‡â–â–â–‡â–‚â–‡â–ˆâ–‚â–‡â–â–‡â–‚â–â–‡â–‡â–‚â–‡â–‡â–‡â–‡â–‡â–‚â–‚â–‡â–ˆâ–‡â–ˆâ–ƒâ–‡â–‡â–â–†â–‡â–‡â–„â–‡
wandb:           train/avg_f1 â–…â–„â–…â–‡â–…â–ˆâ–‡â–ƒâ–‡â–†â–…â–‡â–„â–‡â–â–…â–‚â–†â–†â–†â–†â–‡â–…â–ƒâ–ƒâ–‡â–â–‡â–„â–‡â–„â–†â–†â–†â–â–ˆâ–†â–„â–†â–†
wandb:      train/ensemble_f1 â–ˆâ–‡â–…â–†â–†â–…â–†â–„â–‡â–†â–†â–†â–†â–‡â–ƒâ–‡â–…â–…â–â–‡â–…â–‡â–†â–†â–‡â–…â–ƒâ–„â–…â–†â–‡â–„â–†â–…â–‡â–…â–†â–‡â–†â–†
wandb:         train/mil_loss â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–â–‚â–†â–ˆâ–„â–ƒâ–„â–†â–…â–†â–‡â–†â–†â–„â–†â–ƒâ–ƒâ–„â–„â–…â–‚â–…â–ƒâ–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83388
wandb: best/eval_avg_mil_loss 0.52107
wandb:  best/eval_ensemble_f1 0.83388
wandb:            eval/avg_f1 0.74526
wandb:      eval/avg_mil_loss 0.45607
wandb:       eval/ensemble_f1 0.74526
wandb:           train/avg_f1 0.66423
wandb:      train/ensemble_f1 0.66423
wandb:         train/mil_loss 0.66714
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mmtju8py
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063301-mmtju8py/logs
wandb: ERROR Run mmtju8py errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: y5dl3ioa with config:
wandb: 	actor_learning_rate: 5.51288179165023e-06
wandb: 	attention_dropout_p: 0.13617941457721394
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.329884823237916
wandb: 	temperature: 7.687060359870042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063540-y5dl3ioa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5dl3ioa
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–‚â–„â–†â–†â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–„â–‚â–„â–‚â–„â–„â–„â–„â–ƒâ–ƒâ–†â–†â–â–„â–‚â–‚â–ƒâ–†â–‚â–…â–ƒâ–‡â–†â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–â–ˆâ–…â–â–‚â–‡â–…â–‚
wandb:      eval/avg_mil_loss â–…â–„â–‡â–…â–â–‡â–†â–†â–„â–…â–…â–‡â–„â–…â–…â–‡â–‡â–„â–‡â–ƒâ–„â–‡â–‡â–â–ƒâ–‡â–†â–…â–…â–â–ƒâ–ˆâ–†â–‚â–„â–ƒâ–ƒâ–†â–‚â–ƒ
wandb:       eval/ensemble_f1 â–…â–‚â–„â–‡â–„â–„â–ƒâ–†â–…â–„â–…â–…â–‚â–„â–„â–ˆâ–…â–ƒâ–ƒâ–â–„â–†â–„â–…â–â–‡â–‚â–†â–„â–ˆâ–‡â–†â–â–ƒâ–…â–„â–‚â–ƒâ–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–‡â–„â–…â–†â–†â–…â–„â–‡â–†â–…â–…â–„â–â–‡â–‡â–†â–„â–…â–†â–ƒâ–ˆâ–…â–‡â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–„â–ˆâ–†â–†â–…
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–â–‚â–ƒâ–†â–‚â–…â–…â–‚â–„â–â–ƒâ–…â–†â–‡â–†â–‚â–„â–…â–„â–†â–…â–†â–…â–„â–‚â–ƒâ–…â–†â–‚â–†â–ˆâ–‡
wandb:         train/mil_loss â–†â–ˆâ–…â–ƒâ–†â–…â–ƒâ–ƒâ–†â–„â–‡â–„â–†â–ƒâ–ˆâ–‡â–…â–…â–…â–„â–„â–…â–…â–‚â–†â–†â–‚â–â–‚â–ƒâ–‚â–„â–ƒâ–…â–„â–†â–ƒâ–‚â–†â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84939
wandb: best/eval_avg_mil_loss 0.42439
wandb:  best/eval_ensemble_f1 0.84939
wandb:            eval/avg_f1 0.74696
wandb:      eval/avg_mil_loss 0.51874
wandb:       eval/ensemble_f1 0.74696
wandb:            test/avg_f1 0.79697
wandb:      test/avg_mil_loss 0.44948
wandb:       test/ensemble_f1 0.79697
wandb:           train/avg_f1 0.80208
wandb:      train/ensemble_f1 0.80208
wandb:         train/mil_loss 0.52685
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run charmed-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5dl3ioa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063540-y5dl3ioa/logs
wandb: Agent Starting Run: 5i80cr8l with config:
wandb: 	actor_learning_rate: 4.94471393663813e-06
wandb: 	attention_dropout_p: 0.0828724264091803
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 108
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18400777438137517
wandb: 	temperature: 6.55759740922524
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063809-5i80cr8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5i80cr8l
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–†â–ƒâ–„â–†â–‚â–†â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‚â–†â–ƒâ–†â–ƒâ–„â–‡â–‡â–†â–ˆâ–„â–„â–‡â–†â–„â–†â–‡â–â–†â–†â–‡â–‡â–†â–†â–†â–„â–…â–‡â–ˆâ–‡â–†â–ˆâ–†â–…â–ˆâ–‡â–„â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–„â–ƒâ–‚â–‚â–…â–ˆâ–‚â–…â–ƒâ–†â–‚â–ƒâ–†â–â–ƒâ–‚â–…â–ˆâ–ƒâ–†â–ƒâ–ƒâ–„â–„â–…â–‚â–â–†â–‚â–…â–‚â–‚â–„â–ƒâ–„â–„â–ƒâ–„â–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–†â–†â–„â–…â–ƒâ–‡â–ƒâ–ƒâ–…â–„â–„â–„â–†â–‡â–…â–…â–„â–â–„â–†â–ƒâ–†â–†â–†â–‡â–„â–…â–†â–†â–…â–‡â–‡â–‡â–ˆâ–ƒâ–‡â–„â–ˆâ–†
wandb:           train/avg_f1 â–ƒâ–‚â–â–„â–â–„â–…â–ƒâ–â–‚â–…â–‚â–ƒâ–„â–…â–ƒâ–„â–…â–ƒâ–„â–„â–„â–„â–„â–…â–„â–†â–‡â–ˆâ–†â–…â–ƒâ–„â–†â–…â–†â–„â–‚â–‚â–†
wandb:      train/ensemble_f1 â–â–„â–„â–‚â–„â–„â–…â–…â–‚â–„â–…â–…â–„â–ƒâ–‚â–†â–…â–„â–ƒâ–ƒâ–„â–…â–‡â–…â–ˆâ–ƒâ–†â–…â–†â–„â–†â–‡â–ƒâ–‡â–‚â–‡â–…â–‚â–…â–„
wandb:         train/mil_loss â–‚â–„â–ƒâ–„â–„â–„â–‚â–†â–â–„â–„â–ƒâ–ƒâ–‚â–â–ˆâ–‚â–…â–…â–‚â–ƒâ–†â–‚â–…â–‚â–â–‚â–â–ƒâ–ƒâ–â–ƒâ–„â–„â–‚â–ƒâ–â–â–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8098
wandb: best/eval_avg_mil_loss 0.47452
wandb:  best/eval_ensemble_f1 0.8098
wandb:            eval/avg_f1 0.78951
wandb:      eval/avg_mil_loss 0.50517
wandb:       eval/ensemble_f1 0.78951
wandb:           train/avg_f1 0.7632
wandb:      train/ensemble_f1 0.7632
wandb:         train/mil_loss 0.58308
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pious-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5i80cr8l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063809-5i80cr8l/logs
wandb: ERROR Run 5i80cr8l errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: p1emm307 with config:
wandb: 	actor_learning_rate: 0.00010582770243307648
wandb: 	attention_dropout_p: 0.2312670422389535
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6609256262399915
wandb: 	temperature: 7.637611133179508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064024-p1emm307
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p1emm307
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–ˆâ–…â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–†â–‚â–‡â–‡â–â–ƒâ–ˆâ–‡â–ˆâ–‚â–…â–‡â–†â–‡â–†â–‡â–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–‡â–‚â–‚â–‡â–‡â–ˆâ–â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–ƒâ–„â–ˆâ–‚â–†â–ƒâ–‚â–ƒâ–‚â–‡â–‚â–„â–„â–‚â–ƒâ–…â–â–„â–„â–‡â–†â–„â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–‚â–…
wandb:       eval/ensemble_f1 â–‡â–â–ˆâ–‡â–‡â–…â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–†â–ˆâ–‡â–‡â–â–†â–‡â–‡â–‚â–‡â–‡â–‡â–‡â–ˆâ–‡â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–ˆâ–…â–„â–â–†â–„â–ƒâ–†â–†â–„â–ƒâ–‚â–‡â–…â–ƒâ–ƒâ–‡â–†â–†â–†â–„â–…â–ˆâ–„â–…â–†â–‡â–‡â–†â–ˆâ–†â–†â–‡â–‡â–„â–ˆâ–‡â–‡â–†
wandb:      train/ensemble_f1 â–‡â–„â–…â–…â–‡â–ˆâ–…â–‚â–„â–„â–„â–â–ƒâ–„â–…â–…â–…â–‚â–‡â–†â–„â–„â–…â–‡â–…â–„â–†â–…â–…â–…â–…â–ƒâ–‡â–…â–‡â–‚â–†â–„â–†â–…
wandb:         train/mil_loss â–â–„â–†â–ƒâ–‡â–„â–‚â–‚â–„â–‚â–…â–„â–„â–†â–†â–„â–ƒâ–†â–ƒâ–…â–„â–ˆâ–†â–†â–ƒâ–ƒâ–„â–‚â–‚â–†â–„â–…â–†â–ƒâ–†â–†â–‡â–ƒâ–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79264
wandb: best/eval_avg_mil_loss 0.7005
wandb:  best/eval_ensemble_f1 0.79264
wandb:            eval/avg_f1 0.73606
wandb:      eval/avg_mil_loss 0.6898
wandb:       eval/ensemble_f1 0.73606
wandb:            test/avg_f1 0.80277
wandb:      test/avg_mil_loss 0.41963
wandb:       test/ensemble_f1 0.80277
wandb:           train/avg_f1 0.69728
wandb:      train/ensemble_f1 0.69728
wandb:         train/mil_loss 0.60644
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run exalted-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p1emm307
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064024-p1emm307/logs
wandb: Agent Starting Run: 41ersb1b with config:
wandb: 	actor_learning_rate: 1.780075639033794e-05
wandb: 	attention_dropout_p: 0.3435034154185942
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9216990729173048
wandb: 	temperature: 2.098379268132912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064239-41ersb1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41ersb1b
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–â–â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‚â–â–‡â–†â–†â–ˆâ–ƒâ–†â–†â–‡â–‡â–‡â–ˆâ–ƒâ–â–†â–…â–†â–‡â–‡â–„â–†â–†â–†â–‡â–ˆâ–‡â–†â–…â–‚â–†â–‡â–‡â–‡â–‡â–…â–ˆâ–ƒâ–†
wandb:      eval/avg_mil_loss â–…â–â–„â–ˆâ–„â–ƒâ–â–†â–‚â–…â–ƒâ–â–ƒâ–ƒâ–„â–â–„â–„â–„â–â–„â–ƒâ–„â–‚â–ƒâ–â–â–â–â–â–„â–â–„â–„â–ƒâ–â–‚â–ƒâ–â–‚
wandb:       eval/ensemble_f1 â–‡â–†â–‚â–†â–†â–‡â–‚â–†â–â–†â–†â–‡â–ˆâ–†â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–…â–‡â–„â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–†â–†â–ˆâ–„â–„â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–ˆâ–‡â–…â–ƒâ–‡â–†â–‡â–ˆâ–„â–‡â–†â–‡â–…â–â–‡â–„â–…â–„â–ƒâ–„â–…â–„â–ˆâ–‚â–‚â–†â–…â–…â–ƒâ–†â–†â–†â–‡â–†â–‡â–†â–…â–„â–…
wandb:      train/ensemble_f1 â–…â–‡â–…â–†â–ƒâ–†â–†â–†â–ƒâ–‡â–…â–ƒâ–‡â–‡â–„â–ƒâ–…â–„â–…â–…â–…â–…â–‡â–‚â–†â–†â–†â–‡â–†â–‡â–†â–â–‡â–†â–†â–„â–†â–ˆâ–ƒâ–†
wandb:         train/mil_loss â–ƒâ–…â–„â–ƒâ–„â–ƒâ–†â–ƒâ–…â–‚â–ˆâ–„â–…â–„â–‚â–‚â–ƒâ–‚â–…â–â–…â–ƒâ–ƒâ–‚â–…â–„â–‚â–†â–„â–†â–‚â–„â–†â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–‚
wandb:      train/policy_loss â–…â–â–â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–â–ˆâ–…â–ˆâ–…â–â–â–ˆâ–…â–…â–ˆâ–…â–…â–â–ˆâ–ˆâ–â–…â–…â–ˆâ–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–ˆâ–â–ˆâ–…â–…â–…â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84455
wandb: best/eval_avg_mil_loss 0.47852
wandb:  best/eval_ensemble_f1 0.84455
wandb:            eval/avg_f1 0.79049
wandb:      eval/avg_mil_loss 0.58829
wandb:       eval/ensemble_f1 0.79049
wandb:            test/avg_f1 0.77467
wandb:      test/avg_mil_loss 0.46347
wandb:       test/ensemble_f1 0.77467
wandb:           train/avg_f1 0.76108
wandb:      train/ensemble_f1 0.76108
wandb:         train/mil_loss 0.55808
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run exalted-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41ersb1b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064239-41ersb1b/logs
wandb: Agent Starting Run: 54rmck8j with config:
wandb: 	actor_learning_rate: 0.0006560220984037228
wandb: 	attention_dropout_p: 0.4830601364446454
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22500385418476865
wandb: 	temperature: 1.8272184040156505
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064432-54rmck8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/54rmck8j
wandb: uploading history steps 51-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–ˆâ–‡â–ˆâ–‡â–…â–…â–…â–‡â–†â–‡â–‡â–‡â–†â–†â–ˆâ–†â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–…â–…â–‡â–†â–ˆâ–‡â–…â–…â–‡â–†â–†â–†â–â–†
wandb:      eval/avg_mil_loss â–‡â–„â–‚â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–†â–†â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–…â–ƒâ–ƒâ–…â–†â–„â–â–†â–…â–„â–ƒâ–ƒâ–‚â–„â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–„â–‡â–ˆâ–ˆâ–‡â–‚â–‡â–†â–…â–ˆâ–‡â–‡â–†â–†â–‡â–†â–ˆâ–†â–†â–ˆâ–‡â–‡â–‡â–†â–„â–‡â–†â–†â–…â–‡â–‡â–‚â–„â–‡â–‡â–‡â–‡â–†â–â–†
wandb:           train/avg_f1 â–…â–„â–„â–„â–„â–„â–‡â–…â–…â–…â–ˆâ–ˆâ–‡â–ˆâ–â–†â–ƒâ–‡â–ˆâ–…â–„â–ˆâ–ˆâ–†â–„â–…â–‡â–†â–†â–†â–…â–…â–ˆâ–†â–ƒâ–‡â–†â–„â–‚â–„
wandb:      train/ensemble_f1 â–„â–ƒâ–„â–„â–‡â–…â–ˆâ–…â–„â–‡â–‡â–ˆâ–â–„â–†â–‡â–‡â–„â–„â–ˆâ–‡â–‡â–†â–„â–…â–†â–†â–…â–…â–…â–‡â–†â–ƒâ–ˆâ–ˆâ–„â–…â–„â–‚â–„
wandb:         train/mil_loss â–†â–‡â–…â–†â–†â–„â–…â–„â–â–†â–…â–…â–‡â–„â–„â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–…â–…â–‚â–‚â–†â–ˆâ–…â–†â–…â–‡â–„â–‡â–„â–…â–‚
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8065
wandb: best/eval_avg_mil_loss 0.51881
wandb:  best/eval_ensemble_f1 0.8065
wandb:            eval/avg_f1 0.64598
wandb:      eval/avg_mil_loss 0.70783
wandb:       eval/ensemble_f1 0.64598
wandb:           train/avg_f1 0.66448
wandb:      train/ensemble_f1 0.66448
wandb:         train/mil_loss 0.58808
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run logical-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/54rmck8j
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064432-54rmck8j/logs
wandb: ERROR Run 54rmck8j errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: upqnz9yb with config:
wandb: 	actor_learning_rate: 1.5674787090107516e-05
wandb: 	attention_dropout_p: 0.0014564722218897153
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 173
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8799129956389368
wandb: 	temperature: 9.699835473816208
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064549-upqnz9yb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upqnz9yb
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 118-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–â–ˆâ–†
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–…â–‡â–‡â–†â–‚â–ˆâ–†â–ˆâ–ˆâ–ƒâ–‡â–…â–ˆâ–„â–†â–‡â–‡â–…â–‡â–‡â–„â–‡â–†â–â–ˆâ–‡â–…â–‡â–ˆâ–‚â–…â–ˆâ–‡â–‡â–‡â–†â–ˆâ–…
wandb:      eval/avg_mil_loss â–â–„â–†â–†â–ƒâ–ƒâ–‚â–ˆâ–‚â–‡â–†â–‚â–‡â–‚â–…â–„â–„â–ƒâ–†â–ƒâ–†â–‡â–‚â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–†â–„â–‚â–„â–ƒâ–†â–‚â–‡â–„â–„â–…
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–…â–‡â–ˆâ–†â–‡â–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–‡â–†â–†â–ˆâ–ˆâ–†â–…â–ƒâ–‡â–ˆâ–ˆâ–ƒâ–†â–‡â–ˆâ–‡â–†â–†â–†â–†â–‡â–â–…â–‡â–‡â–†
wandb:           train/avg_f1 â–†â–…â–ˆâ–â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–„â–…â–‚â–†â–‡â–ƒâ–‡â–‚â–‡â–ƒâ–â–‡â–„â–‡â–ƒâ–…â–ƒâ–„â–‡â–ˆâ–…â–…â–ƒâ–‚â–‚â–†â–‡â–‡â–†â–†
wandb:      train/ensemble_f1 â–‚â–„â–…â–„â–‚â–ˆâ–„â–†â–ƒâ–…â–…â–†â–ƒâ–‚â–‚â–†â–ƒâ–†â–†â–â–†â–ƒâ–„â–ƒâ–†â–„â–ƒâ–…â–…â–†â–†â–‡â–…â–…â–…â–…â–ƒâ–…â–†â–ƒ
wandb:         train/mil_loss â–‡â–„â–ƒâ–‡â–…â–„â–„â–‡â–†â–…â–‚â–‚â–†â–‚â–„â–†â–†â–â–„â–‡â–†â–†â–â–„â–†â–„â–…â–‚â–ˆâ–‚â–…â–ˆâ–†â–…â–‡â–ƒâ–‚â–„â–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79084
wandb: best/eval_avg_mil_loss 0.5609
wandb:  best/eval_ensemble_f1 0.79084
wandb:            eval/avg_f1 0.64519
wandb:      eval/avg_mil_loss 0.76689
wandb:       eval/ensemble_f1 0.64519
wandb:           train/avg_f1 0.6649
wandb:      train/ensemble_f1 0.6649
wandb:         train/mil_loss 0.71462
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run feasible-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upqnz9yb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064549-upqnz9yb/logs
wandb: ERROR Run upqnz9yb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zkk1z8sm with config:
wandb: 	actor_learning_rate: 0.00040680999429698074
wandb: 	attention_dropout_p: 0.19531463545185537
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2382617840377379
wandb: 	temperature: 8.444916521151868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064809-zkk1z8sm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkk1z8sm
wandb: uploading history steps 105-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–‚â–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–…â–ˆâ–„â–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–â–â–‚â–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–‡â–ƒâ–†â–…â–ˆâ–‡â–‡â–‡â–‡â–‚â–†â–ˆâ–‡â–‚â–„â–‡â–‡â–‡â–‡â–â–†â–‡â–‚â–‡â–‡â–†â–‡â–‡â–†â–ƒâ–‚â–†â–‡â–†â–ˆâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ˆâ–â–ƒâ–ƒâ–â–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–‡â–ˆâ–‡â–…â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–…â–‡â–…â–ƒâ–†â–‡â–‡â–‡â–†â–†â–…â–‡â–…â–‡â–‡â–„â–â–‡â–†â–‡â–ˆâ–†â–…
wandb:           train/avg_f1 â–…â–…â–‚â–…â–†â–„â–†â–†â–…â–†â–…â–†â–„â–†â–…â–„â–†â–‡â–†â–…â–†â–…â–â–†â–„â–…â–„â–…â–„â–…â–†â–…â–ƒâ–†â–†â–…â–†â–ˆâ–„â–ƒ
wandb:      train/ensemble_f1 â–‡â–„â–„â–…â–†â–†â–†â–â–†â–„â–†â–„â–†â–‚â–…â–†â–†â–…â–„â–†â–†â–‡â–„â–…â–…â–ƒâ–„â–†â–„â–‡â–…â–†â–†â–‡â–„â–†â–ˆâ–„â–…â–†
wandb:         train/mil_loss â–†â–ˆâ–…â–ƒâ–„â–†â–ƒâ–…â–…â–‚â–‡â–†â–„â–…â–†â–…â–ƒâ–„â–†â–„â–‚â–…â–ƒâ–„â–„â–„â–ƒâ–ˆâ–„â–†â–†â–„â–ˆâ–â–†â–…â–ƒâ–†â–ƒâ–†
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7977
wandb: best/eval_avg_mil_loss 0.57783
wandb:  best/eval_ensemble_f1 0.7977
wandb:            eval/avg_f1 0.74182
wandb:      eval/avg_mil_loss 0.67288
wandb:       eval/ensemble_f1 0.74182
wandb:           train/avg_f1 0.70228
wandb:      train/ensemble_f1 0.70228
wandb:         train/mil_loss 0.59188
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run breezy-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zkk1z8sm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064809-zkk1z8sm/logs
wandb: ERROR Run zkk1z8sm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3ru90nik with config:
wandb: 	actor_learning_rate: 0.00034219678150341885
wandb: 	attention_dropout_p: 0.4828326607977986
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 83
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17081744159311096
wandb: 	temperature: 8.611305377909815
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065008-3ru90nik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ru90nik
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 75-83, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–â–„â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–‡â–†â–†â–â–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–†â–‡â–…â–ˆâ–‡â–‡â–†â–‡â–…â–ˆâ–ˆâ–†â–†â–†â–†â–‡â–ˆâ–†â–‡â–ˆâ–†â–†â–†â–†â–ˆâ–ˆâ–†â–ˆ
wandb:      eval/avg_mil_loss â–‡â–…â–…â–â–…â–ˆâ–‚â–‡â–â–…â–†â–ƒâ–…â–…â–…â–…â–…â–„â–‚â–†â–…â–â–†â–â–‚â–‚â–ƒâ–„â–„â–â–‚â–„â–‚â–…â–…â–ƒâ–„â–†â–‚â–…
wandb:       eval/ensemble_f1 â–â–ˆâ–‡â–‡â–‡â–ˆâ–„â–‡â–†â–ˆâ–†â–†â–†â–ˆâ–‡â–†â–†â–‡â–‡â–…â–…â–ˆâ–‡â–ˆâ–†â–†â–‡â–â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–‡
wandb:           train/avg_f1 â–„â–…â–†â–…â–‡â–…â–†â–…â–†â–‡â–…â–…â–‚â–‡â–„â–‡â–…â–†â–…â–†â–ƒâ–„â–†â–…â–ˆâ–†â–ƒâ–ˆâ–„â–â–…â–…â–†â–„â–‡â–ƒâ–†â–…â–„â–†
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–„â–…â–†â–…â–„â–ƒâ–…â–‚â–…â–†â–…â–„â–ƒâ–…â–„â–ƒâ–†â–ƒâ–…â–ƒâ–â–…â–„â–ƒâ–‚â–‡â–…â–ˆâ–„â–ƒâ–‚â–‡â–„
wandb:         train/mil_loss â–‡â–…â–‡â–ƒâ–ƒâ–†â–†â–ƒâ–‡â–…â–‡â–„â–…â–‡â–â–…â–„â–†â–‡â–†â–„â–†â–…â–‡â–…â–†â–ˆâ–…â–†â–‡â–„â–†â–…â–ƒâ–†â–…â–…â–„â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–†â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84408
wandb: best/eval_avg_mil_loss 0.43898
wandb:  best/eval_ensemble_f1 0.84408
wandb:            eval/avg_f1 0.78649
wandb:      eval/avg_mil_loss 0.39469
wandb:       eval/ensemble_f1 0.78649
wandb:           train/avg_f1 0.78232
wandb:      train/ensemble_f1 0.78232
wandb:         train/mil_loss 0.54992
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run gallant-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3ru90nik
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065008-3ru90nik/logs
wandb: ERROR Run 3ru90nik errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: x3xny669 with config:
wandb: 	actor_learning_rate: 1.938765369794086e-06
wandb: 	attention_dropout_p: 0.3484092521426673
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6437303010057296
wandb: 	temperature: 2.9576102410821346
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065141-x3xny669
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x3xny669
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 147-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–ƒâ–â–â–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ƒâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–â–‡â–ˆâ–ˆâ–‡â–ˆâ–â–
wandb:      eval/avg_mil_loss â–…â–‡â–†â–‚â–â–…â–ƒâ–ƒâ–‡â–â–ƒâ–…â–‚â–†â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–ƒâ–„â–ˆâ–‡â–…â–ƒâ–…â–‚â–‚â–…â–†â–ƒâ–‚â–â–‡â–‚â–‚
wandb:       eval/ensemble_f1 â–‡â–‡â–‡â–‡â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‚â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–„â–‡â–„â–†â–…â–…â–…â–†â–„â–†â–‚â–‚â–…â–‡â–‡â–…â–‚â–…â–…â–„â–â–‡â–„â–†â–„â–‡â–…â–†â–†â–†â–ƒâ–‡â–†â–‚â–„â–ˆâ–†â–…â–…
wandb:      train/ensemble_f1 â–ƒâ–â–ƒâ–…â–ƒâ–â–ƒâ–†â–…â–‡â–…â–„â–†â–†â–‡â–†â–ˆâ–„â–…â–ƒâ–†â–ƒâ–†â–…â–†â–†â–†â–ƒâ–„â–â–‚â–†â–‚â–ƒâ–ˆâ–‡â–„â–…â–‡â–ƒ
wandb:         train/mil_loss â–ƒâ–‚â–â–‚â–„â–…â–‚â–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–â–ˆâ–ƒâ–ƒâ–â–‚â–â–…â–…â–ƒâ–„â–…â–…â–‚â–ƒâ–ƒâ–ˆâ–…â–„â–‚â–ƒâ–‚â–‚â–…â–‚â–„â–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79697
wandb: best/eval_avg_mil_loss 0.57769
wandb:  best/eval_ensemble_f1 0.79697
wandb:            eval/avg_f1 0.74297
wandb:      eval/avg_mil_loss 0.60809
wandb:       eval/ensemble_f1 0.74297
wandb:            test/avg_f1 0.79957
wandb:      test/avg_mil_loss 0.65234
wandb:       test/ensemble_f1 0.79957
wandb:           train/avg_f1 0.73161
wandb:      train/ensemble_f1 0.73161
wandb:         train/mil_loss 0.56943
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run morning-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x3xny669
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065141-x3xny669/logs
wandb: Agent Starting Run: mz0ksglt with config:
wandb: 	actor_learning_rate: 0.0005787563282084093
wandb: 	attention_dropout_p: 0.38503915748385453
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4234758934827466
wandb: 	temperature: 0.15003527596298305
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065426-mz0ksglt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mz0ksglt
wandb: uploading history steps 119-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–â–ƒâ–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–…â–‚â–„â–ƒâ–…â–…â–ƒâ–ƒâ–â–†â–†â–„â–„â–‡â–†â–…â–„â–„â–†â–„â–ƒâ–ˆâ–„â–…â–†â–…â–ƒâ–„â–…â–†â–‚â–…â–†â–†â–†â–†â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–†â–ƒâ–†â–†â–†â–‚â–ƒâ–…â–…â–‡â–…â–ƒâ–†â–ˆâ–‚â–„â–â–‚â–â–…â–‡â–†â–†â–‡â–…â–ƒâ–‚â–…â–â–‡â–…â–‡â–â–†â–ƒâ–…â–ƒâ–…
wandb:       eval/ensemble_f1 â–‚â–‚â–„â–…â–†â–…â–…â–„â–ƒâ–†â–â–…â–ƒâ–ƒâ–„â–…â–†â–„â–„â–ƒâ–†â–†â–†â–ƒâ–ˆâ–‡â–„â–†â–†â–‡â–†â–†â–†â–‚â–„â–†â–„â–†â–†â–‚
wandb:           train/avg_f1 â–„â–â–‚â–…â–ƒâ–â–„â–…â–ƒâ–‚â–„â–„â–ˆâ–†â–‚â–‚â–†â–…â–„â–…â–ƒâ–…â–‡â–…â–†â–‚â–†â–†â–‡â–†â–…â–ƒâ–ƒâ–†â–„â–ˆâ–…â–‚â–ƒâ–…
wandb:      train/ensemble_f1 â–„â–„â–†â–…â–ˆâ–‡â–„â–…â–‚â–ƒâ–ˆâ–„â–‚â–‚â–†â–„â–ˆâ–…â–…â–‚â–‚â–…â–†â–ƒâ–„â–‡â–…â–ƒâ–ƒâ–„â–„â–ƒâ–†â–‚â–†â–„â–â–…â–‚â–„
wandb:         train/mil_loss â–†â–ƒâ–„â–…â–„â–…â–‡â–‡â–„â–‡â–ƒâ–‚â–„â–ˆâ–â–„â–…â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–†â–…â–„â–‚â–‚â–ƒâ–†â–‚â–ƒâ–ƒâ–…â–‚â–„â–‡â–„â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–ˆâ–…â–…â–â–ˆâ–ˆâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–ˆâ–â–…â–â–…â–…â–…â–…â–â–â–…â–…â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–ˆâ–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83597
wandb: best/eval_avg_mil_loss 0.48783
wandb:  best/eval_ensemble_f1 0.83597
wandb:            eval/avg_f1 0.74297
wandb:      eval/avg_mil_loss 0.48298
wandb:       eval/ensemble_f1 0.74297
wandb:           train/avg_f1 0.79333
wandb:      train/ensemble_f1 0.79333
wandb:         train/mil_loss 0.54485
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mz0ksglt
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065426-mz0ksglt/logs
wandb: ERROR Run mz0ksglt errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: r33solf6 with config:
wandb: 	actor_learning_rate: 0.0001681351589395993
wandb: 	attention_dropout_p: 0.21205200985557188
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.387808270674543
wandb: 	temperature: 8.693535756597907
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065640-r33solf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r33solf6
wandb: uploading history steps 88-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–„â–…â–…â–„â–…â–„â–…â–…â–„â–†â–‡â–„â–â–…â–†â–†â–‡â–…â–…â–„â–„â–†â–…â–ƒâ–„â–…â–…â–‡â–ƒâ–„â–ˆâ–ƒâ–†â–â–…â–†â–‡â–ƒ
wandb:      eval/avg_mil_loss â–ˆâ–„â–„â–…â–†â–„â–…â–„â–†â–ˆâ–†â–…â–‚â–†â–…â–†â–…â–†â–ƒâ–â–‚â–„â–ƒâ–„â–‡â–†â–‚â–ƒâ–‡â–‡â–‡â–‡â–‡â–…â–…â–‡â–…â–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–‚â–„â–…â–…â–…â–†â–„â–„â–‡â–ˆâ–…â–…â–…â–„â–…â–„â–ƒâ–…â–…â–â–‡â–†â–‡â–„â–…â–„â–…â–‚â–ƒâ–…â–‡â–…â–…â–…â–ˆâ–ƒâ–ƒâ–„â–‡â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–ƒâ–„â–ƒâ–„â–…â–„â–ƒâ–‚â–…â–…â–„â–„â–â–†â–…â–…â–„â–ƒâ–‡â–…â–†â–†â–†â–…â–‡â–…â–„â–…â–‡â–‡â–…â–†â–†â–„â–…â–„â–‡â–‡
wandb:      train/ensemble_f1 â–ƒâ–„â–‡â–…â–ƒâ–„â–„â–„â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–†â–…â–„â–…â–…â–â–…â–†â–„â–…â–â–„â–‚â–†â–…â–†â–…â–…â–ˆâ–†â–„â–„â–†â–†â–†
wandb:         train/mil_loss â–‚â–„â–„â–ƒâ–ƒâ–†â–†â–„â–„â–‚â–…â–„â–ˆâ–‡â–„â–ƒâ–ƒâ–‚â–…â–â–„â–…â–†â–‡â–„â–„â–â–â–ƒâ–ƒâ–…â–„â–…â–â–‡â–ƒâ–ƒâ–…â–ƒâ–‡
wandb:      train/policy_loss â–ƒâ–…â–…â–â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79512
wandb: best/eval_avg_mil_loss 0.55656
wandb:  best/eval_ensemble_f1 0.79512
wandb:            eval/avg_f1 0.78451
wandb:      eval/avg_mil_loss 0.53868
wandb:       eval/ensemble_f1 0.78451
wandb:            test/avg_f1 0.77265
wandb:      test/avg_mil_loss 0.49848
wandb:       test/ensemble_f1 0.77265
wandb:           train/avg_f1 0.74595
wandb:      train/ensemble_f1 0.74595
wandb:         train/mil_loss 0.59425
wandb:      train/policy_loss 0.29876
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.29876
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run celestial-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r33solf6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065640-r33solf6/logs
wandb: Agent Starting Run: goghz60o with config:
wandb: 	actor_learning_rate: 1.9990466073557043e-06
wandb: 	attention_dropout_p: 0.00042338105105210744
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29843886482993154
wandb: 	temperature: 5.274036817816543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065834-goghz60o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/goghz60o
wandb: uploading history steps 100-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–„â–ƒâ–†â–ˆâ–‡â–‚â–‡â–„â–†â–‡â–…â–‚â–â–…â–‡â–ˆâ–‡â–†â–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–‚â–†â–„â–†â–ƒâ–ƒâ–‚â–„â–†â–‡â–‚â–†â–„â–…
wandb:      eval/avg_mil_loss â–ƒâ–…â–†â–‚â–â–…â–„â–ƒâ–…â–…â–‚â–ƒâ–†â–â–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–‡â–…â–†â–…â–…â–ƒâ–„â–„â–„â–ˆâ–ƒâ–„â–†â–ƒâ–„â–„â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–ˆâ–„â–„â–ƒâ–†â–„â–†â–‡â–â–†â–…â–„â–ƒâ–‡â–†â–„â–‚â–„â–†â–ƒâ–†â–„â–‡â–…â–†â–†â–ƒâ–„â–„â–‡â–„â–ˆâ–†â–„â–„â–‡â–…â–†â–…
wandb:           train/avg_f1 â–ƒâ–†â–„â–†â–†â–ƒâ–…â–…â–„â–…â–ƒâ–…â–…â–†â–‡â–ƒâ–…â–†â–„â–„â–†â–…â–…â–„â–â–‚â–„â–„â–…â–…â–…â–„â–…â–ƒâ–ˆâ–ƒâ–„â–†â–„â–…
wandb:      train/ensemble_f1 â–‚â–…â–„â–„â–â–…â–„â–…â–â–„â–†â–†â–…â–ƒâ–…â–ƒâ–…â–„â–…â–…â–„â–…â–†â–ˆâ–„â–…â–„â–…â–„â–…â–„â–„â–„â–ƒâ–ƒâ–ˆâ–„â–‚â–†â–ƒ
wandb:         train/mil_loss â–ˆâ–†â–…â–„â–…â–ƒâ–…â–†â–†â–„â–…â–†â–…â–…â–…â–â–„â–…â–‚â–…â–…â–†â–…â–„â–ƒâ–„â–„â–„â–„â–…â–†â–…â–…â–„â–„â–…â–ƒâ–‚â–†â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81002
wandb: best/eval_avg_mil_loss 0.53832
wandb:  best/eval_ensemble_f1 0.81002
wandb:            eval/avg_f1 0.6352
wandb:      eval/avg_mil_loss 0.70954
wandb:       eval/ensemble_f1 0.6352
wandb:           train/avg_f1 0.67065
wandb:      train/ensemble_f1 0.67065
wandb:         train/mil_loss 0.75487
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/goghz60o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065834-goghz60o/logs
wandb: ERROR Run goghz60o errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nf1kd8fu with config:
wandb: 	actor_learning_rate: 0.0007100302548671122
wandb: 	attention_dropout_p: 0.460760156834563
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8317695851339422
wandb: 	temperature: 2.7491033231645137
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070048-nf1kd8fu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nf1kd8fu
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 102-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–†â–ˆâ–â–†â–â–…â–‡â–‚â–‡â–ˆâ–†â–‚â–†â–ƒâ–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‚â–„â–‡â–†â–‡â–†â–†â–‡â–‡â–â–†â–ƒâ–…â–‡â–ˆ
wandb:      eval/avg_mil_loss â–â–„â–ƒâ–‚â–„â–†â–†â–ƒâ–„â–„â–‡â–ƒâ–…â–†â–â–†â–†â–ˆâ–ƒâ–â–ƒâ–„â–…â–…â–„â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–…â–„â–†â–†â–â–‚â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–ˆâ–‡â–‡â–„â–„â–‡â–‡â–†â–„â–†â–ƒâ–‡â–‡â–ˆâ–„â–‡â–‡â–‡â–â–†â–„â–‡â–†â–ˆâ–…â–‡â–â–†â–‡â–‡â–ˆâ–‡â–ˆâ–…â–„â–‡â–†â–…â–…â–ˆ
wandb:           train/avg_f1 â–…â–†â–†â–…â–…â–‡â–‡â–†â–„â–‡â–„â–ƒâ–„â–†â–†â–†â–ƒâ–…â–…â–†â–‡â–ˆâ–†â–â–†â–‡â–ƒâ–‡â–ƒâ–„â–…â–†â–…â–ƒâ–†â–ƒâ–‡â–…â–…â–…
wandb:      train/ensemble_f1 â–…â–…â–‡â–‡â–‡â–â–†â–†â–‡â–ˆâ–„â–ƒâ–…â–‡â–„â–ˆâ–…â–…â–‚â–ƒâ–†â–…â–ˆâ–‚â–ƒâ–„â–†â–‚â–„â–‚â–ƒâ–ƒâ–â–„â–„â–ˆâ–„â–…â–„â–†
wandb:         train/mil_loss â–ƒâ–„â–‡â–ˆâ–†â–ƒâ–ƒâ–„â–…â–â–‚â–„â–…â–‡â–ƒâ–„â–„â–ˆâ–‡â–ˆâ–‚â–‚â–…â–‡â–„â–…â–ˆâ–…â–‚â–‚â–ƒâ–„â–„â–ƒâ–…â–„â–†â–‚â–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84186
wandb: best/eval_avg_mil_loss 0.4449
wandb:  best/eval_ensemble_f1 0.84186
wandb:            eval/avg_f1 0.82882
wandb:      eval/avg_mil_loss 0.39278
wandb:       eval/ensemble_f1 0.82882
wandb:           train/avg_f1 0.75822
wandb:      train/ensemble_f1 0.75822
wandb:         train/mil_loss 0.569
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run balmy-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nf1kd8fu
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070048-nf1kd8fu/logs
wandb: ERROR Run nf1kd8fu errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: qm3r2z1l with config:
wandb: 	actor_learning_rate: 0.0004096284901416452
wandb: 	attention_dropout_p: 0.4008160068316042
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39202872326902993
wandb: 	temperature: 6.277033192135039
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070246-qm3r2z1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qm3r2z1l
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–…â–‡â–ˆâ–…â–„â–†â–†â–…â–ˆâ–…â–†â–ˆâ–„â–†â–‡â–†â–†â–…â–â–…â–†â–†â–„â–ƒâ–…â–ˆâ–†â–†â–†â–†â–„â–„â–†â–†â–ˆâ–„â–ˆâ–ƒâ–
wandb:      eval/avg_mil_loss â–„â–†â–…â–‚â–†â–„â–„â–†â–ƒâ–…â–†â–„â–…â–ƒâ–ƒâ–†â–…â–ˆâ–…â–„â–†â–‡â–…â–ƒâ–…â–„â–„â–…â–ƒâ–‡â–‡â–…â–ƒâ–†â–‚â–â–„â–…â–…â–„
wandb:       eval/ensemble_f1 â–†â–‡â–…â–ˆâ–…â–†â–†â–ˆâ–†â–…â–ˆâ–…â–†â–„â–‡â–‡â–†â–…â–…â–â–†â–„â–‡â–…â–ˆâ–†â–…â–…â–†â–‡â–„â–„â–†â–†â–…â–ˆâ–ˆâ–…â–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‡â–…â–ƒâ–…â–ˆâ–‡â–†â–ƒâ–…â–†â–„â–†â–‚â–…â–„â–„â–…â–‡â–„â–ƒâ–…â–„â–…â–†â–…â–„â–‡â–†â–ƒâ–â–†â–…â–ƒâ–„â–…â–ˆâ–ƒâ–‚
wandb:      train/ensemble_f1 â–…â–ƒâ–†â–…â–‡â–…â–ˆâ–ƒâ–‡â–ƒâ–†â–…â–†â–„â–ƒâ–„â–…â–†â–‚â–„â–„â–„â–…â–‡â–„â–†â–†â–…â–„â–†â–â–†â–†â–…â–ƒâ–„â–…â–‚â–ˆâ–…
wandb:         train/mil_loss â–â–†â–„â–†â–†â–„â–†â–…â–„â–„â–ƒâ–ƒâ–†â–ƒâ–‡â–‚â–‚â–†â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–†â–†â–‚â–„â–„â–…â–…â–†â–…â–…â–ƒâ–ƒâ–‡â–ƒâ–†â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–…â–ˆâ–…â–ˆâ–â–…â–…â–…â–â–…â–â–â–…â–…â–†â–…â–…â–†â–â–ƒâ–â–…â–…â–…â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7769
wandb: best/eval_avg_mil_loss 0.47092
wandb:  best/eval_ensemble_f1 0.7769
wandb:            eval/avg_f1 0.65021
wandb:      eval/avg_mil_loss 0.72257
wandb:       eval/ensemble_f1 0.65021
wandb:            test/avg_f1 0.59067
wandb:      test/avg_mil_loss 0.67695
wandb:       test/ensemble_f1 0.59067
wandb:           train/avg_f1 0.63106
wandb:      train/ensemble_f1 0.63106
wandb:         train/mil_loss 0.66581
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run brisk-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qm3r2z1l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070246-qm3r2z1l/logs
wandb: Agent Starting Run: g8rvy27d with config:
wandb: 	actor_learning_rate: 0.00016514314532696162
wandb: 	attention_dropout_p: 0.13852740806248626
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6137103798584225
wandb: 	temperature: 9.218290499506107
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070415-g8rvy27d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g8rvy27d
wandb: uploading wandb-summary.json
wandb: uploading history steps 44-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–†â–†â–â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–‡â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–…â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‚â–‡â–‚â–ˆâ–ˆâ–…â–â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡
wandb:      eval/avg_mil_loss â–„â–„â–â–…â–†â–…â–…â–â–…â–„â–…â–â–…â–†â–â–…â–„â–ˆâ–„â–„â–‡â–ˆâ–…â–…â–…â–†â–…â–…â–ƒâ–…â–…â–…â–„â–„â–…â–…â–„â–„â–…â–‚
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–…â–‡â–‡â–ˆâ–‚â–ˆâ–…â–â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:           train/avg_f1 â–„â–…â–„â–…â–„â–„â–…â–ƒâ–‡â–…â–…â–„â–†â–†â–†â–†â–„â–…â–…â–†â–†â–„â–†â–ƒâ–…â–…â–‚â–„â–„â–†â–†â–â–ƒâ–„â–…â–…â–ˆâ–„â–…â–‡
wandb:      train/ensemble_f1 â–„â–†â–…â–…â–„â–„â–…â–ƒâ–‡â–…â–„â–†â–†â–…â–†â–…â–…â–†â–†â–…â–†â–ƒâ–„â–†â–ƒâ–‚â–…â–‚â–„â–„â–†â–†â–â–ƒâ–…â–…â–ˆâ–„â–…â–‡
wandb:         train/mil_loss â–ˆâ–‚â–„â–‚â–ƒâ–†â–ƒâ–†â–â–„â–ƒâ–…â–„â–„â–…â–†â–‚â–…â–â–„â–„â–‚â–â–‡â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–„â–„â–â–„â–„â–„â–„â–„â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79228
wandb: best/eval_avg_mil_loss 0.71857
wandb:  best/eval_ensemble_f1 0.79228
wandb:            eval/avg_f1 0.75042
wandb:      eval/avg_mil_loss 0.50956
wandb:       eval/ensemble_f1 0.75042
wandb:           train/avg_f1 0.78074
wandb:      train/ensemble_f1 0.78074
wandb:         train/mil_loss 0.56105
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sage-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g8rvy27d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070415-g8rvy27d/logs
wandb: ERROR Run g8rvy27d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nqrxklt2 with config:
wandb: 	actor_learning_rate: 0.00011500086568542453
wandb: 	attention_dropout_p: 0.2806761236503586
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16490581635811363
wandb: 	temperature: 0.7736841335454736
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070517-nqrxklt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqrxklt2
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–…â–ˆâ–†â–
wandb:  best/eval_ensemble_f1 â–â–â–â–„â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–†â–ˆâ–…â–…â–…â–†â–â–ˆâ–ˆâ–ˆâ–…â–…â–…â–ˆâ–…â–ˆâ–…â–â–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–ˆâ–â–…â–…â–â–…â–ˆâ–‡â–ˆâ–ˆâ–…â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–…â–†â–‚â–†â–„â–„â–‚â–„â–‚â–‚â–…â–„â–„â–‚â–…â–‚â–„â–‚â–ƒâ–â–…â–ƒâ–„â–†â–‡â–ƒâ–‚â–…â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–…â–ƒâ–‚â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–†â–†â–†â–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–…â–†â–‚â–ˆâ–ˆâ–ˆâ–†â–ˆâ–‚â–†â–â–†â–†â–‚â–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–‚â–†â–†â–…â–ˆâ–ˆâ–ˆâ–†â–‚â–ˆ
wandb:           train/avg_f1 â–â–‡â–†â–…â–†â–‡â–„â–‡â–‡â–‡â–„â–ƒâ–†â–…â–‡â–„â–‡â–‡â–…â–…â–â–‚â–‚â–„â–†â–ˆâ–‡â–„â–†â–†â–‡â–ƒâ–†â–†â–…â–…â–…â–…â–†â–‡
wandb:      train/ensemble_f1 â–â–†â–…â–†â–‡â–ƒâ–‚â–ˆâ–…â–†â–ˆâ–â–†â–„â–„â–…â–‡â–…â–‡â–ˆâ–„â–ˆâ–†â–ƒâ–‡â–ƒâ–‡â–‡â–„â–†â–‚â–ˆâ–ˆâ–ˆâ–†â–…â–…â–ˆâ–†â–…
wandb:         train/mil_loss â–ƒâ–„â–„â–‚â–„â–‚â–†â–„â–„â–…â–‡â–ƒâ–â–‚â–…â–‚â–†â–…â–ˆâ–„â–…â–‚â–‚â–‚â–†â–ƒâ–„â–‚â–†â–‚â–â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8228
wandb: best/eval_avg_mil_loss 0.57328
wandb:  best/eval_ensemble_f1 0.8228
wandb:            eval/avg_f1 0.72708
wandb:      eval/avg_mil_loss 0.68161
wandb:       eval/ensemble_f1 0.72708
wandb:           train/avg_f1 0.68603
wandb:      train/ensemble_f1 0.68603
wandb:         train/mil_loss 0.67943
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cerulean-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqrxklt2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070517-nqrxklt2/logs
wandb: ERROR Run nqrxklt2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 05dszkmj with config:
wandb: 	actor_learning_rate: 1.9442586613124617e-05
wandb: 	attention_dropout_p: 0.17838405621003883
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 95
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.932650180398216
wandb: 	temperature: 1.247182380671913
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070731-05dszkmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/05dszkmj
wandb: uploading history steps 88-95, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‚â–‚â–‚â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‡â–†â–†â–ˆâ–…â–‡â–ˆâ–…â–ˆâ–ˆâ–‡â–…â–…â–…â–ˆâ–‡â–…â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–†â–ˆâ–†â–‡â–‡â–‡â–…â–…â–‡â–ˆâ–
wandb:      eval/avg_mil_loss â–…â–â–…â–‡â–„â–‚â–…â–„â–„â–‚â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–â–â–ˆâ–‚â–â–…â–â–…â–‚â–„â–â–ˆâ–ˆâ–„â–â–„â–„â–â–â–…â–„â–‚â–â–…
wandb:       eval/ensemble_f1 â–†â–‡â–‡â–…â–‡â–ˆâ–†â–ˆâ–‡â–…â–ˆâ–…â–ˆâ–‡â–…â–‡â–…â–…â–‡â–…â–‡â–ˆâ–…â–ˆâ–†â–‡â–…â–ˆâ–ˆâ–…â–ˆâ–†â–†â–ˆâ–ˆâ–†â–†â–‡â–ˆâ–
wandb:           train/avg_f1 â–‡â–‚â–„â–†â–†â–ƒâ–ƒâ–‡â–†â–…â–†â–â–‚â–‡â–ˆâ–„â–…â–†â–…â–‡â–…â–†â–‡â–…â–†â–†â–ˆâ–‡â–…â–…â–„â–…â–„â–‚â–ƒâ–…â–†â–ƒâ–‡â–†
wandb:      train/ensemble_f1 â–‚â–†â–…â–…â–ƒâ–ƒâ–…â–‡â–…â–‚â–â–â–‚â–†â–‡â–„â–…â–†â–…â–‡â–…â–…â–†â–„â–…â–‡â–…â–…â–ˆâ–…â–…â–„â–„â–…â–…â–‡â–‚â–†â–‚â–†
wandb:         train/mil_loss â–â–„â–„â–‚â–„â–‚â–‚â–…â–…â–…â–ƒâ–ˆâ–â–„â–„â–‡â–‚â–„â–„â–†â–„â–ƒâ–…â–ƒâ–‡â–‚â–‚â–…â–„â–…â–â–…â–‚â–„â–‡â–‡â–„â–…â–ƒâ–„
wandb:      train/policy_loss â–â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–â–‡â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7873
wandb: best/eval_avg_mil_loss 0.56026
wandb:  best/eval_ensemble_f1 0.7873
wandb:            eval/avg_f1 0.74642
wandb:      eval/avg_mil_loss 0.58173
wandb:       eval/ensemble_f1 0.74642
wandb:           train/avg_f1 0.71495
wandb:      train/ensemble_f1 0.71495
wandb:         train/mil_loss 0.60963
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run splendid-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/05dszkmj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070731-05dszkmj/logs
wandb: ERROR Run 05dszkmj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pj4ja90u with config:
wandb: 	actor_learning_rate: 3.838632101143836e-05
wandb: 	attention_dropout_p: 0.379005373238484
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 125
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3561125224866354
wandb: 	temperature: 6.122591021646896
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070914-pj4ja90u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pj4ja90u
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–…â–†â–†â–ƒâ–…â–„â–…â–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–‡â–‡â–ˆâ–…â–‡â–ˆâ–â–†â–…â–…â–†â–ˆâ–†â–…â–†â–â–‚â–‡â–‚â–ˆâ–„â–†â–ˆâ–…â–ˆ
wandb:      eval/avg_mil_loss â–„â–ƒâ–‡â–ƒâ–„â–ˆâ–„â–…â–„â–„â–†â–ƒâ–‚â–„â–…â–…â–‚â–‡â–ƒâ–…â–ƒâ–‡â–†â–…â–†â–…â–†â–…â–‡â–ˆâ–…â–‡â–…â–â–…â–ƒâ–ƒâ–…â–„â–†
wandb:       eval/ensemble_f1 â–â–â–‡â–„â–†â–‚â–ˆâ–â–‡â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–‡â–ˆâ–…â–…â–ˆâ–…â–…â–…â–†â–…â–ƒâ–â–‡â–ˆâ–„â–…â–…â–…â–ˆâ–‚â–…â–‚
wandb:           train/avg_f1 â–„â–†â–„â–„â–†â–ƒâ–ƒâ–…â–ˆâ–…â–„â–‚â–…â–‚â–„â–„â–†â–ƒâ–„â–ƒâ–ƒâ–‚â–â–ˆâ–…â–â–†â–…â–†â–…â–…â–„â–†â–…â–ƒâ–†â–ƒâ–†â–„â–‚
wandb:      train/ensemble_f1 â–ƒâ–†â–‡â–…â–„â–…â–‡â–ƒâ–ƒâ–„â–†â–„â–…â–‚â–…â–†â–„â–ƒâ–â–‡â–„â–…â–â–†â–â–†â–‡â–„â–†â–†â–‡â–‚â–‡â–ˆâ–†â–…â–„â–ˆâ–„â–†
wandb:         train/mil_loss â–‡â–…â–‚â–†â–ƒâ–‚â–‡â–â–â–…â–‡â–…â–†â–…â–ƒâ–‡â–‡â–ƒâ–…â–„â–…â–„â–„â–‚â–â–…â–ˆâ–ƒâ–…â–„â–…â–…â–†â–„â–ƒâ–…â–…â–ˆâ–…â–†
wandb:      train/policy_loss â–…â–…â–ˆâ–â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–ƒâ–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–„â–â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82767
wandb: best/eval_avg_mil_loss 0.45293
wandb:  best/eval_ensemble_f1 0.82767
wandb:            eval/avg_f1 0.78798
wandb:      eval/avg_mil_loss 0.69836
wandb:       eval/ensemble_f1 0.78798
wandb:           train/avg_f1 0.59394
wandb:      train/ensemble_f1 0.59394
wandb:         train/mil_loss 0.77331
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run laced-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pj4ja90u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070914-pj4ja90u/logs
wandb: ERROR Run pj4ja90u errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: swhw8gil with config:
wandb: 	actor_learning_rate: 1.2311530511101655e-06
wandb: 	attention_dropout_p: 0.26078423291400943
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2239997172526853
wandb: 	temperature: 9.438084172704082
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071108-swhw8gil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swhw8gil
wandb: uploading history steps 130-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–„â–â–†
wandb:  best/eval_ensemble_f1 â–â–„â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–…â–†â–…â–â–…â–ƒâ–‡â–‡â–…â–†â–ˆâ–†â–‡â–‡â–…â–†â–â–â–„â–…â–…â–ˆâ–…â–ƒâ–ˆâ–ˆâ–†â–‡â–‡â–…â–ˆâ–ˆâ–…â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–†â–‚â–…â–„â–ƒâ–†â–ˆâ–ƒâ–…â–…â–†â–‡â–…â–„â–ƒâ–†â–ˆâ–ƒâ–ƒâ–ƒâ–„â–‡â–‡â–…â–…â–†â–…â–†â–…â–†â–†â–ƒâ–â–‚â–†â–‚â–†â–…
wandb:       eval/ensemble_f1 â–…â–ˆâ–ˆâ–‡â–…â–‡â–…â–‡â–‡â–â–…â–ƒâ–„â–â–…â–‡â–‡â–‡â–â–ˆâ–„â–‡â–‡â–†â–…â–‡â–„â–ƒâ–…â–ˆâ–ˆâ–ƒâ–ˆâ–…â–ˆâ–ˆâ–…â–â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‡â–ƒâ–„â–…â–ˆâ–…â–„â–ˆâ–„â–†â–‡â–†â–†â–‡â–‡â–ƒâ–‡â–†â–„â–‡â–‡â–„â–…â–„â–‡â–…â–ˆâ–†â–â–…â–†â–„â–†â–ƒâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:      train/ensemble_f1 â–†â–„â–†â–„â–‡â–ˆâ–…â–†â–…â–†â–„â–‚â–„â–…â–…â–„â–ˆâ–‡â–ˆâ–ƒâ–„â–‡â–†â–†â–†â–„â–…â–†â–â–‡â–…â–„â–‡â–„â–…â–†â–‡â–‡â–‡â–„
wandb:         train/mil_loss â–„â–ƒâ–‡â–…â–ƒâ–ƒâ–ˆâ–…â–‚â–†â–†â–„â–†â–…â–…â–„â–†â–‡â–ƒâ–ƒâ–â–†â–ƒâ–ƒâ–„â–ƒâ–„â–„â–…â–ƒâ–…â–ƒâ–†â–„â–ƒâ–†â–„â–‡â–„â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–â–†â–„â–„â–†â–†â–„â–ˆâ–„â–„â–„â–„â–„â–†â–„â–„â–ˆâ–„â–â–„â–ˆâ–ˆâ–â–„â–„â–„â–â–ˆâ–„â–â–ˆâ–„â–„â–„â–ƒâ–„â–„â–†â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80471
wandb: best/eval_avg_mil_loss 0.74611
wandb:  best/eval_ensemble_f1 0.80471
wandb:            eval/avg_f1 0.62532
wandb:      eval/avg_mil_loss 0.7703
wandb:       eval/ensemble_f1 0.62532
wandb:            test/avg_f1 0.78256
wandb:      test/avg_mil_loss 0.43754
wandb:       test/ensemble_f1 0.78256
wandb:           train/avg_f1 0.69081
wandb:      train/ensemble_f1 0.69081
wandb:         train/mil_loss 0.62586
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stellar-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swhw8gil
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071108-swhw8gil/logs
wandb: Agent Starting Run: nxvs7fyq with config:
wandb: 	actor_learning_rate: 1.093090180834644e-06
wandb: 	attention_dropout_p: 0.4762463162516009
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8409338288163539
wandb: 	temperature: 2.459719361033712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071327-nxvs7fyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nxvs7fyq
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 102-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–†â–‡â–‡â–…â–†â–‡â–‡â–†â–‡â–‡â–‡â–†â–â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–ˆ
wandb:      eval/avg_mil_loss â–ˆâ–‡â–…â–„â–‚â–â–„â–…â–„â–…â–†â–â–ƒâ–…â–ˆâ–„â–„â–ƒâ–†â–„â–„â–„â–…â–„â–‚â–ƒâ–„â–‡â–‚â–…â–ˆâ–ƒâ–„â–„â–„â–„â–…â–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–ƒâ–†â–‡â–†â–ˆâ–‡â–…â–‡â–†â–‡â–†â–…â–†â–‡â–†â–…â–ƒâ–‡â–â–‡â–†â–…â–‡â–‡â–‡â–†â–†â–†â–„â–‡â–‡â–†â–†â–„â–†â–†â–†â–†â–†â–†
wandb:           train/avg_f1 â–ƒâ–â–†â–…â–†â–…â–‡â–‚â–‡â–†â–ƒâ–„â–ƒâ–…â–†â–‡â–„â–â–…â–‚â–…â–‡â–…â–ˆâ–…â–‡â–„â–‚â–…â–…â–ˆâ–†â–…â–‡â–‡â–…â–„â–…â–†â–ˆ
wandb:      train/ensemble_f1 â–ƒâ–„â–…â–†â–ˆâ–„â–†â–ƒâ–…â–„â–„â–ƒâ–…â–†â–…â–„â–â–…â–‡â–‡â–ƒâ–ƒâ–„â–…â–…â–‡â–…â–„â–…â–…â–…â–ˆâ–â–‡â–…â–„â–…â–‡â–…â–ˆ
wandb:         train/mil_loss â–ˆâ–ƒâ–„â–„â–‚â–…â–â–„â–ƒâ–ƒâ–„â–…â–‚â–„â–â–ƒâ–„â–†â–„â–ƒâ–‚â–â–ƒâ–…â–‡â–„â–ƒâ–ƒâ–…â–‚â–‚â–†â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–„â–„
wandb:      train/policy_loss â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–„â–â–„â–„â–â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–ˆâ–„â–â–ˆâ–„â–ˆâ–ˆâ–â–„â–â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–â–„â–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78482
wandb: best/eval_avg_mil_loss 0.5947
wandb:  best/eval_ensemble_f1 0.78482
wandb:            eval/avg_f1 0.77957
wandb:      eval/avg_mil_loss 0.53964
wandb:       eval/ensemble_f1 0.77957
wandb:           train/avg_f1 0.76435
wandb:      train/ensemble_f1 0.76435
wandb:         train/mil_loss 0.54908
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run graceful-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nxvs7fyq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071327-nxvs7fyq/logs
wandb: ERROR Run nxvs7fyq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ui2tfjsa with config:
wandb: 	actor_learning_rate: 0.00011245490332365838
wandb: 	attention_dropout_p: 0.2574137071041007
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8105350801726853
wandb: 	temperature: 0.3486164056894514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071527-ui2tfjsa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ui2tfjsa
wandb: uploading history steps 159-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–…â–‚â–…â–‡â–‚â–‚â–‡â–„â–…â–„â–†â–†â–‡â–…â–‡â–†â–…â–…â–„â–„â–…â–ˆâ–†â–„â–„â–†â–ƒâ–†â–†â–‡â–„â–†â–…â–â–†â–‡â–‡â–â–‡
wandb:      eval/avg_mil_loss â–†â–‚â–ƒâ–â–†â–‚â–…â–†â–‚â–…â–„â–‡â–…â–„â–‚â–…â–…â–„â–ƒâ–„â–‚â–„â–…â–‚â–…â–ƒâ–…â–ˆâ–â–„â–ƒâ–‚â–†â–ˆâ–‚â–…â–…â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–ƒâ–†â–‚â–†â–ˆâ–„â–†â–†â–â–ƒâ–„â–†â–ˆâ–…â–‡â–…â–„â–„â–…â–„â–†â–ˆâ–‡â–†â–‡â–…â–…â–†â–…â–†â–†â–„â–‚â–ƒâ–â–â–†â–„â–†â–„
wandb:           train/avg_f1 â–â–…â–…â–†â–‡â–…â–…â–„â–‡â–„â–…â–„â–†â–†â–„â–…â–‡â–…â–„â–ƒâ–…â–…â–„â–†â–ƒâ–ƒâ–ˆâ–ƒâ–†â–…â–ƒâ–†â–ƒâ–â–†â–‡â–…â–…â–†â–‚
wandb:      train/ensemble_f1 â–„â–…â–†â–…â–„â–‡â–ƒâ–ˆâ–‡â–„â–„â–…â–…â–‚â–â–â–†â–ƒâ–…â–ˆâ–…â–ƒâ–†â–„â–‚â–‚â–ƒâ–„â–ƒâ–‡â–‡â–ƒâ–†â–‡â–…â–ƒâ–‡â–…â–ˆâ–ƒ
wandb:         train/mil_loss â–†â–ƒâ–†â–ˆâ–„â–…â–†â–…â–â–…â–„â–†â–†â–„â–ƒâ–†â–…â–‚â–…â–†â–†â–†â–„â–„â–„â–‡â–‚â–…â–…â–…â–„â–„â–‚â–ƒâ–†â–…â–„â–„â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–†â–„â–â–â–ƒâ–â–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–„â–†â–„â–„â–ˆâ–ˆâ–†â–„â–ˆâ–ˆâ–„â–ˆâ–„â–„â–ˆâ–†â–„â–„â–ˆâ–ˆâ–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82127
wandb: best/eval_avg_mil_loss 0.49887
wandb:  best/eval_ensemble_f1 0.82127
wandb:            eval/avg_f1 0.55831
wandb:      eval/avg_mil_loss 0.80726
wandb:       eval/ensemble_f1 0.55831
wandb:           train/avg_f1 0.64118
wandb:      train/ensemble_f1 0.64118
wandb:         train/mil_loss 0.70321
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run curious-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ui2tfjsa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071527-ui2tfjsa/logs
wandb: ERROR Run ui2tfjsa errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: hj0mnpjy with config:
wandb: 	actor_learning_rate: 5.34455000470148e-06
wandb: 	attention_dropout_p: 0.23294220977461896
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.016219082460368073
wandb: 	temperature: 1.1502681213456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071852-hj0mnpjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hj0mnpjy
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 100-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‡â–†â–„â–‡â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–‡â–†â–†â–†â–†â–â–†â–†â–†â–…â–†â–‡â–‡â–ˆâ–†â–ˆâ–†â–ˆâ–‡â–‡â–†â–ƒâ–‡â–†â–ˆâ–†â–‡â–ˆâ–ˆâ–…â–…â–†â–ˆâ–‡â–‡â–ˆâ–â–†â–‡
wandb:      eval/avg_mil_loss â–…â–…â–…â–…â–‡â–‚â–…â–ˆâ–…â–…â–ƒâ–…â–‚â–„â–„â–„â–†â–…â–„â–…â–…â–…â–„â–…â–„â–„â–‡â–…â–…â–…â–â–…â–…â–…â–‡â–‡â–†â–…â–‚â–„
wandb:       eval/ensemble_f1 â–†â–‡â–†â–‡â–†â–â–‡â–‡â–‚â–‡â–‡â–‡â–ˆâ–‡â–ƒâ–â–ˆâ–ˆâ–†â–‡â–†â–ˆâ–†â–‡â–‡â–‚â–ˆâ–‡â–ˆâ–‡â–†â–ˆâ–‡â–ˆâ–†â–‚â–‡â–‡â–ˆâ–‡
wandb:           train/avg_f1 â–†â–‚â–…â–…â–‡â–†â–„â–†â–‡â–„â–†â–…â–…â–…â–â–…â–‡â–‚â–…â–„â–†â–…â–†â–…â–†â–‡â–ƒâ–„â–†â–„â–…â–†â–†â–…â–†â–ˆâ–…â–‡â–â–„
wandb:      train/ensemble_f1 â–†â–„â–…â–‚â–‡â–‚â–‡â–†â–†â–‡â–…â–â–…â–‡â–…â–†â–…â–†â–†â–…â–…â–„â–…â–‚â–†â–†â–‡â–…â–†â–‚â–…â–„â–ƒâ–ˆâ–ƒâ–†â–„â–â–†â–‡
wandb:         train/mil_loss â–…â–†â–ˆâ–‚â–„â–„â–ˆâ–â–„â–…â–…â–†â–†â–„â–…â–‚â–…â–ƒâ–â–ƒâ–†â–„â–‚â–ƒâ–„â–â–ƒâ–…â–‚â–„â–„â–â–â–…â–„â–ƒâ–ƒâ–„â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84542
wandb: best/eval_avg_mil_loss 0.39685
wandb:  best/eval_ensemble_f1 0.84542
wandb:            eval/avg_f1 0.76573
wandb:      eval/avg_mil_loss 0.61273
wandb:       eval/ensemble_f1 0.76573
wandb:           train/avg_f1 0.78987
wandb:      train/ensemble_f1 0.78987
wandb:         train/mil_loss 0.59311
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run radiant-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hj0mnpjy
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071852-hj0mnpjy/logs
wandb: ERROR Run hj0mnpjy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: myiz0nl9 with config:
wandb: 	actor_learning_rate: 3.820541008580758e-06
wandb: 	attention_dropout_p: 0.134615384634593
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.010968355657717256
wandb: 	temperature: 7.175204806542583
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072056-myiz0nl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myiz0nl9
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–‡â–‡
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–‡â–ˆâ–‚â–‡â–‚â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–†â–‡â–‚â–ˆâ–‡â–‚â–â–â–ˆâ–â–ƒâ–‡â–â–‡â–‚â–‡â–‡â–‡â–‡â–„
wandb:      eval/avg_mil_loss â–ƒâ–„â–…â–‡â–‡â–„â–…â–„â–‚â–†â–†â–ƒâ–ƒâ–‡â–„â–„â–‚â–ˆâ–†â–ƒâ–†â–‚â–‚â–â–ˆâ–„â–ƒâ–…â–‚â–†â–…â–„â–…â–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–‡â–‚â–†â–ˆâ–‚â–‡â–‡â–ˆâ–‡â–‚â–†â–‡â–ˆâ–ˆâ–„â–‚â–†â–‡â–‡â–ˆâ–‡â–‡â–‚â–ˆâ–â–…â–ˆâ–â–‡â–‡â–‚â–â–‡â–‡â–‡â–â–‡â–‡â–ˆ
wandb:           train/avg_f1 â–ƒâ–†â–†â–†â–‚â–ƒâ–†â–â–†â–…â–„â–†â–„â–ƒâ–…â–…â–…â–…â–…â–ƒâ–‡â–‡â–†â–ƒâ–†â–†â–‚â–…â–„â–ƒâ–ˆâ–‚â–‡â–‚â–†â–„â–…â–†â–„â–„
wandb:      train/ensemble_f1 â–â–‡â–‡â–„â–†â–„â–„â–…â–†â–…â–„â–„â–†â–ƒâ–†â–ƒâ–‡â–…â–‡â–‡â–„â–‡â–„â–…â–ˆâ–‡â–„â–…â–„â–‡â–…â–ˆâ–„â–…â–ƒâ–„â–‡â–…â–…â–…
wandb:         train/mil_loss â–…â–ƒâ–…â–‚â–†â–‡â–„â–†â–„â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–…â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–†â–„â–…â–„â–â–ƒâ–â–†â–‚â–…â–†â–…â–ˆâ–…â–â–‚â–…â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82987
wandb: best/eval_avg_mil_loss 0.61249
wandb:  best/eval_ensemble_f1 0.82987
wandb:            eval/avg_f1 0.80719
wandb:      eval/avg_mil_loss 0.58276
wandb:       eval/ensemble_f1 0.80719
wandb:           train/avg_f1 0.65762
wandb:      train/ensemble_f1 0.65762
wandb:         train/mil_loss 0.80013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fancy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myiz0nl9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072056-myiz0nl9/logs
wandb: ERROR Run myiz0nl9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: be6zfd8d with config:
wandb: 	actor_learning_rate: 2.563673110691598e-05
wandb: 	attention_dropout_p: 0.1509929192704721
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4141038925737759
wandb: 	temperature: 6.477575574044211
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072337-be6zfd8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/be6zfd8d
wandb: uploading wandb-summary.json
wandb: uploading history steps 184-192, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‚â–ƒâ–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–‡â–ƒâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–‚â–ƒâ–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–†â–ˆâ–„â–‡â–‚â–†â–ˆâ–â–ˆâ–ˆâ–‡â–‡â–ˆâ–‚â–…â–â–ˆâ–â–ƒâ–‡â–ˆâ–â–ˆâ–‚â–‚â–â–‚â–â–ˆâ–ˆâ–‡â–â–‡â–‚â–ˆâ–‚â–ƒâ–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–„â–ˆâ–ƒâ–„â–‚â–†â–…â–‡â–‡â–‡â–…â–‡â–‡â–„â–‚â–â–‡â–‚â–…â–‡â–ƒâ–„â–„â–†â–ƒâ–„â–†â–„â–…â–ƒâ–‚â–„â–…â–ƒâ–ƒâ–„â–…â–…â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–„â–ˆâ–‚â–‚â–‚â–‚â–ˆâ–ˆâ–ˆâ–‚â–‚â–ˆâ–‚â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–‡â–â–â–‡â–â–‚â–‡â–‚â–‚â–ƒâ–ˆâ–‚â–‚
wandb:           train/avg_f1 â–‡â–„â–„â–‡â–‡â–†â–‡â–…â–„â–†â–‡â–†â–…â–…â–ƒâ–ƒâ–†â–†â–†â–†â–â–‡â–†â–†â–…â–‚â–ˆâ–„â–‡â–…â–†â–„â–„â–†â–„â–†â–„â–‡â–…â–†
wandb:      train/ensemble_f1 â–ˆâ–‡â–ˆâ–„â–ˆâ–ƒâ–‡â–†â–„â–ˆâ–…â–†â–‡â–‡â–â–‡â–†â–†â–…â–†â–†â–…â–…â–ƒâ–†â–ˆâ–‡â–†â–„â–†â–…â–ƒâ–„â–ˆâ–ˆâ–†â–†â–‚â–‡â–‡
wandb:         train/mil_loss â–â–ƒâ–â–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–‚â–‚â–„â–‚â–…â–‚â–‚â–„â–â–„â–ƒâ–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚â–â–…â–…â–ƒâ–„â–„â–„â–‚â–„â–„â–â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81184
wandb: best/eval_avg_mil_loss 0.54977
wandb:  best/eval_ensemble_f1 0.81184
wandb:            eval/avg_f1 0.777
wandb:      eval/avg_mil_loss 0.59351
wandb:       eval/ensemble_f1 0.777
wandb:           train/avg_f1 0.6819
wandb:      train/ensemble_f1 0.6819
wandb:         train/mil_loss 0.63831
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sleek-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/be6zfd8d
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072337-be6zfd8d/logs
wandb: ERROR Run be6zfd8d errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: bzcgw4lo with config:
wandb: 	actor_learning_rate: 4.873476873416405e-05
wandb: 	attention_dropout_p: 0.4558845199749065
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.601132278696145
wandb: 	temperature: 1.1640103662092272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072709-bzcgw4lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bzcgw4lo
wandb: uploading output.log; uploading config.yaml; uploading history steps 100-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–ˆâ–„â–‡â–†â–‡â–â–‡â–…â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–ƒâ–‡â–…â–†â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–†â–‡â–‡
wandb:      eval/avg_mil_loss â–†â–†â–„â–…â–…â–„â–„â–…â–…â–…â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–„â–„â–‡â–†â–†â–‚â–†â–†â–‡â–‡â–„â–…â–ƒâ–„â–…â–ƒâ–„â–ˆâ–…â–„â–†
wandb:       eval/ensemble_f1 â–…â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–…â–‡â–‡â–„â–ˆâ–â–‡â–‡â–‡â–ˆâ–‡â–…â–†â–„â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–‡
wandb:           train/avg_f1 â–ƒâ–ƒâ–†â–†â–„â–†â–†â–‚â–ˆâ–„â–„â–…â–…â–…â–ƒâ–…â–„â–‚â–‡â–…â–†â–…â–„â–…â–ƒâ–‚â–â–†â–†â–„â–…â–„â–†â–„â–„â–„â–ƒâ–‚â–†â–
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–†â–…â–†â–ˆâ–ƒâ–„â–†â–…â–‚â–…â–…â–ƒâ–‚â–â–…â–„â–…â–…â–„â–…â–†â–‚â–ƒâ–„â–…â–…â–„â–†â–†â–„â–ƒâ–„â–ƒâ–â–‚â–…â–‚â–
wandb:         train/mil_loss â–„â–â–„â–‡â–„â–â–…â–†â–†â–ƒâ–…â–…â–…â–ƒâ–„â–…â–†â–‡â–„â–…â–ƒâ–„â–ˆâ–„â–…â–„â–‡â–‚â–„â–ƒâ–‚â–…â–‡â–†â–‡â–â–ˆâ–‡â–†â–‚
wandb:      train/policy_loss â–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–â–â–„â–„â–„â–„â–„â–„â–â–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81471
wandb: best/eval_avg_mil_loss 0.49612
wandb:  best/eval_ensemble_f1 0.81471
wandb:            eval/avg_f1 0.75967
wandb:      eval/avg_mil_loss 0.62487
wandb:       eval/ensemble_f1 0.75967
wandb:           train/avg_f1 0.69207
wandb:      train/ensemble_f1 0.69207
wandb:         train/mil_loss 0.60767
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bzcgw4lo
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072709-bzcgw4lo/logs
wandb: ERROR Run bzcgw4lo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: llreoqp3 with config:
wandb: 	actor_learning_rate: 0.00014690452808316902
wandb: 	attention_dropout_p: 0.2122923659009431
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.010501310132672192
wandb: 	temperature: 0.9535464241022706
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072912-llreoqp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/llreoqp3
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–„â–„â–„â–†â–ˆâ–‡â–ˆâ–…â–ˆâ–‚â–‡â–†â–„â–…â–…â–†â–†â–‚â–ƒâ–…â–â–…â–ƒâ–†â–„â–‡â–…â–†â–‡â–‚â–‚â–…â–†â–‚â–ƒâ–ƒâ–‡â–„â–†
wandb:      eval/avg_mil_loss â–â–„â–†â–‡â–„â–†â–„â–ƒâ–‡â–â–„â–„â–‚â–…â–‚â–â–…â–ƒâ–„â–ˆâ–ƒâ–ƒâ–‡â–â–‚â–†â–†â–ƒâ–‚â–ƒâ–†â–…â–…â–†â–‚â–‚â–†â–…â–„â–„
wandb:       eval/ensemble_f1 â–†â–„â–„â–†â–„â–„â–‚â–…â–ˆâ–‡â–†â–‡â–â–‚â–‡â–„â–â–…â–„â–…â–„â–„â–…â–„â–†â–„â–†â–†â–‡â–†â–‚â–‚â–â–„â–ƒâ–‡â–‡â–„â–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–„â–†â–†â–„â–„â–ƒâ–…â–†â–„â–ƒâ–‡â–…â–„â–†â–‚â–…â–…â–„â–‚â–„â–„â–†â–„â–„â–…â–…â–„â–†â–†â–ˆâ–„â–„â–…â–„â–„â–â–…â–„â–‡
wandb:      train/ensemble_f1 â–â–ƒâ–‚â–ƒâ–‡â–„â–†â–„â–‚â–„â–†â–…â–â–‡â–†â–†â–‡â–„â–‡â–„â–‚â–ƒâ–…â–‚â–ƒâ–…â–ƒâ–â–‡â–†â–ˆâ–‡â–…â–ƒâ–„â–…â–„â–„â–ƒâ–„
wandb:         train/mil_loss â–…â–…â–„â–ƒâ–‡â–ƒâ–‡â–…â–†â–„â–…â–…â–‡â–†â–„â–†â–†â–„â–‚â–‚â–â–†â–…â–„â–ˆâ–ˆâ–„â–…â–ˆâ–…â–ƒâ–…â–…â–‡â–„â–â–†â–„â–…â–„
wandb:      train/policy_loss â–†â–…â–â–â–ƒâ–â–†â–â–…â–…â–…â–â–…â–ˆâ–…â–…â–â–â–…â–†â–…â–ˆâ–…â–…â–…â–†â–…â–ˆâ–â–…â–ˆâ–†â–†â–ˆâ–â–â–â–ƒâ–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–â–â–â–ƒâ–…â–…â–ƒâ–†â–…â–â–…â–â–â–â–…â–…â–†â–…â–…â–…â–â–ˆâ–…â–…â–…â–…â–ˆâ–…â–ˆâ–†â–â–…â–†â–ƒâ–…â–â–…â–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72991
wandb: best/eval_avg_mil_loss 0.74857
wandb:  best/eval_ensemble_f1 0.72991
wandb:            eval/avg_f1 0.57997
wandb:      eval/avg_mil_loss 0.85496
wandb:       eval/ensemble_f1 0.57997
wandb:            test/avg_f1 0.57188
wandb:      test/avg_mil_loss 0.75003
wandb:       test/ensemble_f1 0.57188
wandb:           train/avg_f1 0.56026
wandb:      train/ensemble_f1 0.56026
wandb:         train/mil_loss 0.78924
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run balmy-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/llreoqp3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072912-llreoqp3/logs
wandb: Agent Starting Run: d6vczghi with config:
wandb: 	actor_learning_rate: 1.4467800852177037e-05
wandb: 	attention_dropout_p: 0.1772539619190441
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8744207138876056
wandb: 	temperature: 9.11388431841903
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073127-d6vczghi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6vczghi
wandb: uploading wandb-summary.json; uploading history steps 156-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–â–‡â–‡â–‡â–‡â–†â–†â–‡â–â–‡â–‡â–‡â–ˆâ–ˆâ–†â–†â–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–…â–ˆâ–‡â–†â–‡â–â–†â–‡â–ˆâ–‡â–â–ˆâ–ˆâ–‡â–†â–ƒ
wandb:      eval/avg_mil_loss â–‚â–…â–‡â–â–‚â–‡â–‚â–„â–„â–‡â–†â–…â–‚â–†â–ƒâ–ƒâ–†â–ˆâ–‡â–‚â–†â–„â–ƒâ–â–ƒâ–â–„â–„â–„â–„â–‚â–â–„â–ƒâ–„â–…â–‚â–„â–ƒâ–…
wandb:       eval/ensemble_f1 â–ˆâ–â–‡â–‡â–‡â–‡â–ƒâ–‡â–†â–†â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–…â–ˆâ–‡â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–â–ˆâ–‡â–†â–…â–‡â–…â–‡â–ƒâ–‡
wandb:           train/avg_f1 â–…â–‡â–†â–…â–…â–…â–…â–…â–‡â–†â–…â–‡â–‡â–‚â–…â–…â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–…â–‡â–†â–…â–‡â–„â–…â–‡â–‡â–‡â–†â–â–ƒ
wandb:      train/ensemble_f1 â–„â–„â–…â–…â–ƒâ–…â–â–„â–ƒâ–‚â–…â–†â–‡â–‡â–‡â–†â–…â–‚â–„â–†â–…â–†â–…â–ƒâ–ƒâ–ˆâ–ˆâ–„â–‡â–†â–‡â–ƒâ–…â–…â–ƒâ–†â–‚â–†â–†â–ƒ
wandb:         train/mil_loss â–„â–ƒâ–‡â–†â–…â–‡â–„â–…â–‡â–†â–ƒâ–„â–ƒâ–â–‚â–ƒâ–‚â–‡â–‡â–…â–‚â–ƒâ–…â–ˆâ–ƒâ–…â–ƒâ–â–‚â–…â–†â–ƒâ–„â–…â–‡â–‡â–â–…â–…â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83952
wandb: best/eval_avg_mil_loss 0.44726
wandb:  best/eval_ensemble_f1 0.83952
wandb:            eval/avg_f1 0.7776
wandb:      eval/avg_mil_loss 0.63806
wandb:       eval/ensemble_f1 0.7776
wandb:           train/avg_f1 0.70916
wandb:      train/ensemble_f1 0.70916
wandb:         train/mil_loss 0.5771
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run volcanic-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6vczghi
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073127-d6vczghi/logs
wandb: ERROR Run d6vczghi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5pr7e2no with config:
wandb: 	actor_learning_rate: 0.0005225572435810106
wandb: 	attention_dropout_p: 0.4223470767123675
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8026752628639867
wandb: 	temperature: 1.2638371758680975
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073434-5pr7e2no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5pr7e2no
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–„â–‚â–„â–†â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–‡â–â–†â–‡â–„â–„â–†â–„â–…â–…â–‡â–ˆâ–†â–‚â–‡â–†â–…â–ˆâ–„â–ˆâ–‡â–…â–…â–â–†â–ˆâ–â–‡â–‚â–‡â–â–‡â–‚â–‡â–†â–†â–…â–ˆâ–„
wandb:      eval/avg_mil_loss â–‚â–†â–†â–ƒâ–‚â–â–‚â–†â–…â–„â–‚â–…â–…â–‚â–â–…â–„â–‚â–†â–„â–„â–„â–„â–„â–ƒâ–†â–ƒâ–ƒâ–…â–‡â–„â–„â–ƒâ–ˆâ–‡â–†â–…â–‚â–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–‚â–ˆâ–‡â–ˆâ–‡â–„â–‡â–„â–ˆâ–ˆâ–ˆâ–ƒâ–„â–„â–‡â–ˆâ–â–…â–‡â–ˆâ–…â–†â–…â–‡â–†â–ˆâ–†â–‚â–†â–â–‡â–…â–‡â–‡â–†â–‡â–„â–†â–‡â–…
wandb:           train/avg_f1 â–†â–…â–…â–†â–‡â–…â–ƒâ–ƒâ–ˆâ–‡â–„â–†â–ƒâ–‚â–…â–„â–ƒâ–„â–…â–„â–†â–…â–‚â–ƒâ–ˆâ–ˆâ–†â–„â–†â–…â–‚â–†â–…â–â–„â–„â–…â–ˆâ–†â–†
wandb:      train/ensemble_f1 â–‚â–…â–„â–‡â–‡â–ƒâ–†â–‡â–‡â–ƒâ–â–ˆâ–‚â–†â–ƒâ–…â–„â–‡â–ƒâ–…â–…â–‚â–ƒâ–„â–„â–ˆâ–†â–â–‚â–ƒâ–„â–†â–„â–…â–…â–ƒâ–…â–†â–†â–†
wandb:         train/mil_loss â–†â–†â–…â–…â–‚â–„â–ƒâ–„â–‚â–…â–…â–†â–ƒâ–‡â–„â–„â–…â–…â–…â–†â–†â–ƒâ–†â–ˆâ–„â–„â–„â–†â–†â–†â–„â–„â–†â–†â–„â–â–‚â–„â–‚â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–„â–„â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ˆâ–â–†â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–â–ˆâ–„â–„â–â–ˆâ–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84338
wandb: best/eval_avg_mil_loss 0.39711
wandb:  best/eval_ensemble_f1 0.84338
wandb:            eval/avg_f1 0.52849
wandb:      eval/avg_mil_loss 0.83327
wandb:       eval/ensemble_f1 0.52849
wandb:           train/avg_f1 0.68544
wandb:      train/ensemble_f1 0.68544
wandb:         train/mil_loss 0.77137
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5pr7e2no
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073434-5pr7e2no/logs
wandb: ERROR Run 5pr7e2no errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 5zu3902u with config:
wandb: 	actor_learning_rate: 1.1468841254602786e-06
wandb: 	attention_dropout_p: 0.05277174157754488
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2830979735095871
wandb: 	temperature: 6.078186213554161
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073713-5zu3902u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5zu3902u
wandb: uploading history steps 97-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–…â–ˆâ–ƒâ–…â–„â–ƒâ–†â–„â–‚â–…â–‡â–…â–‡â–ˆâ–‡â–„â–†â–ˆâ–†â–‚â–‚â–…â–†â–†â–†â–ˆâ–†â–„â–†â–†â–†â–„â–…â–ƒâ–â–†â–‚â–…â–‡
wandb:      eval/avg_mil_loss â–‚â–ƒâ–ƒâ–‚â–†â–†â–â–„â–…â–â–ƒâ–…â–‚â–…â–†â–ƒâ–ˆâ–‚â–‡â–‡â–…â–„â–â–…â–â–ˆâ–…â–†â–ƒâ–‡â–‡â–ƒâ–‚â–…â–…â–†â–†â–„â–ƒâ–†
wandb:       eval/ensemble_f1 â–…â–ˆâ–‡â–‚â–‚â–†â–…â–…â–„â–‡â–ˆâ–‚â–†â–„â–„â–…â–ƒâ–ƒâ–ˆâ–â–‚â–…â–‡â–ˆâ–†â–†â–†â–‡â–‡â–†â–…â–†â–‡â–†â–„â–ƒâ–‡â–…â–…â–„
wandb:           train/avg_f1 â–ˆâ–…â–â–„â–â–‚â–â–ƒâ–…â–…â–†â–…â–†â–‡â–…â–ƒâ–†â–„â–†â–ƒâ–†â–ƒâ–…â–ƒâ–†â–„â–„â–…â–‚â–…â–…â–â–„â–‡â–…â–†â–‚â–‚â–†â–‡
wandb:      train/ensemble_f1 â–ˆâ–„â–„â–†â–†â–‚â–ƒâ–…â–ƒâ–†â–…â–ƒâ–â–†â–†â–‡â–†â–‡â–…â–…â–†â–…â–„â–†â–…â–†â–†â–…â–…â–†â–…â–…â–ƒâ–ˆâ–†â–ƒâ–‡â–‡â–ƒâ–…
wandb:         train/mil_loss â–ƒâ–‡â–„â–ƒâ–…â–â–…â–…â–…â–ƒâ–‚â–‚â–…â–†â–†â–„â–ƒâ–ƒâ–„â–ƒâ–…â–ˆâ–„â–„â–…â–…â–‚â–‡â–„â–…â–â–„â–‚â–ƒâ–ƒâ–„â–„â–…â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82767
wandb: best/eval_avg_mil_loss 0.46843
wandb:  best/eval_ensemble_f1 0.82767
wandb:            eval/avg_f1 0.74532
wandb:      eval/avg_mil_loss 0.64829
wandb:       eval/ensemble_f1 0.74532
wandb:           train/avg_f1 0.78422
wandb:      train/ensemble_f1 0.78422
wandb:         train/mil_loss 0.57737
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5zu3902u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073713-5zu3902u/logs
wandb: ERROR Run 5zu3902u errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5jltwxb5 with config:
wandb: 	actor_learning_rate: 6.371743771833903e-05
wandb: 	attention_dropout_p: 0.09830512591210684
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10490284541322448
wandb: 	temperature: 1.6045342453007427
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073938-5jltwxb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5jltwxb5
wandb: uploading history steps 168-172, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–†â–„â–‡â–„â–â–‚â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–‡â–†â–‡â–‡â–‚â–…â–…â–‡â–ƒâ–‡â–‡â–ƒâ–†â–‡â–â–ƒâ–ˆâ–†â–‡â–ˆâ–†â–„â–‚â–ˆâ–ƒâ–ˆâ–‡â–‡â–ˆâ–‚â–â–†â–‡â–‡â–„â–‡â–‡
wandb:      eval/avg_mil_loss â–ƒâ–…â–ƒâ–„â–…â–„â–ƒâ–…â–ˆâ–„â–„â–†â–ƒâ–†â–‡â–ƒâ–„â–„â–„â–†â–ƒâ–ƒâ–…â–‡â–…â–„â–†â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–†â–â–„â–…â–…â–ƒâ–„
wandb:       eval/ensemble_f1 â–ˆâ–…â–‡â–ˆâ–‡â–â–‡â–ˆâ–…â–…â–ˆâ–‡â–…â–…â–…â–‡â–‡â–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–‡â–‡â–…â–ˆâ–â–…â–‡â–‡â–ˆâ–†â–…â–‡â–†
wandb:           train/avg_f1 â–„â–…â–‡â–†â–…â–ƒâ–†â–â–…â–‚â–†â–†â–„â–ƒâ–„â–„â–â–‡â–ˆâ–†â–…â–†â–ˆâ–†â–†â–„â–‡â–„â–ˆâ–‡â–„â–…â–†â–ƒâ–‡â–‡â–‡â–…â–‚â–‡
wandb:      train/ensemble_f1 â–…â–†â–…â–ƒâ–‚â–†â–†â–…â–†â–â–…â–…â–ˆâ–…â–‡â–„â–‚â–ˆâ–…â–†â–„â–…â–…â–„â–„â–‡â–„â–†â–…â–‡â–„â–†â–…â–†â–†â–†â–…â–ˆâ–‚â–‡
wandb:         train/mil_loss â–†â–…â–„â–„â–†â–„â–ˆâ–ƒâ–ƒâ–…â–„â–„â–‡â–„â–†â–‚â–„â–„â–„â–‚â–†â–†â–†â–„â–ˆâ–…â–†â–„â–â–‚â–â–„â–…â–…â–ƒâ–â–…â–…â–„â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–â–â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80018
wandb: best/eval_avg_mil_loss 0.52122
wandb:  best/eval_ensemble_f1 0.80018
wandb:            eval/avg_f1 0.73721
wandb:      eval/avg_mil_loss 0.62197
wandb:       eval/ensemble_f1 0.73721
wandb:           train/avg_f1 0.75169
wandb:      train/ensemble_f1 0.75169
wandb:         train/mil_loss 0.63672
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run stellar-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5jltwxb5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073938-5jltwxb5/logs
wandb: ERROR Run 5jltwxb5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tpbghbe3 with config:
wandb: 	actor_learning_rate: 0.0003649760905713604
wandb: 	attention_dropout_p: 0.1356976755621493
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42678469820441745
wandb: 	temperature: 1.4696201415353594
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074249-tpbghbe3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpbghbe3
wandb: uploading history steps 97-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ˆâ–…â–…â–†â–„â–â–„â–†â–†â–ˆâ–‡â–†â–…â–…â–…â–‡â–†â–…â–†â–„â–†â–„â–„â–†â–…â–‡â–†â–ƒâ–ƒâ–‡â–‡â–†â–†â–‚â–„â–„â–…â–‡â–†â–„
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–…â–â–„â–â–ƒâ–„â–…â–‚â–‚â–…â–…â–„â–…â–ƒâ–†â–…â–‚â–‡â–‚â–…â–ƒâ–…â–‡â–â–„â–ƒâ–‚â–†â–†â–†â–„â–‡â–…â–„â–†â–ˆâ–„
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–…â–…â–†â–‚â–…â–„â–†â–†â–…â–†â–†â–„â–‚â–…â–†â–†â–†â–‡â–†â–…â–†â–†â–†â–‡â–„â–†â–ˆâ–„â–ƒâ–„â–„â–‡â–‡â–‡â–‡â–â–‡â–…
wandb:           train/avg_f1 â–ƒâ–…â–„â–‡â–†â–‚â–‡â–…â–†â–ƒâ–…â–„â–†â–„â–…â–‚â–„â–„â–†â–â–„â–‡â–‡â–â–…â–†â–†â–…â–‡â–†â–†â–ƒâ–…â–„â–…â–ˆâ–ˆâ–ƒâ–‡â–‚
wandb:      train/ensemble_f1 â–ƒâ–…â–‡â–†â–…â–‚â–‚â–‡â–…â–†â–ƒâ–‡â–„â–…â–ƒâ–„â–…â–‚â–…â–„â–ƒâ–„â–„â–ƒâ–„â–‡â–‡â–â–†â–ƒâ–ˆâ–…â–†â–ƒâ–ƒâ–†â–ˆâ–ˆâ–„â–†
wandb:         train/mil_loss â–„â–ƒâ–‡â–…â–‚â–ƒâ–‡â–…â–„â–„â–ƒâ–ƒâ–„â–…â–â–„â–„â–„â–†â–„â–ƒâ–†â–…â–â–ƒâ–‚â–†â–ˆâ–ƒâ–†â–…â–ƒâ–…â–…â–‚â–…â–†â–„â–ƒâ–…
wandb:      train/policy_loss â–â–…â–ˆâ–…â–…â–â–…â–…â–ˆâ–ˆâ–…â–â–ˆâ–…â–ˆâ–â–…â–…â–â–â–ˆâ–ˆâ–…â–â–…â–…â–…â–ˆâ–ˆâ–…â–…â–â–â–â–…â–ˆâ–…â–…â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81366
wandb: best/eval_avg_mil_loss 0.52081
wandb:  best/eval_ensemble_f1 0.81366
wandb:            eval/avg_f1 0.78188
wandb:      eval/avg_mil_loss 0.54283
wandb:       eval/ensemble_f1 0.78188
wandb:           train/avg_f1 0.7461
wandb:      train/ensemble_f1 0.7461
wandb:         train/mil_loss 0.58714
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run generous-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpbghbe3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074249-tpbghbe3/logs
wandb: ERROR Run tpbghbe3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: st7fif95 with config:
wandb: 	actor_learning_rate: 0.00018222203071640788
wandb: 	attention_dropout_p: 0.19381093596877536
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6613768689902628
wandb: 	temperature: 1.164452617592272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074503-st7fif95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/st7fif95
wandb: uploading history steps 111-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ˆâ–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–†â–†â–‡â–â–‡â–ˆâ–‡â–‚â–‡â–‡â–ˆâ–â–†â–‡â–†â–ˆâ–†â–†â–‡â–â–‡â–ˆâ–‡â–„â–‡â–…â–†â–†
wandb:      eval/avg_mil_loss â–„â–‚â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–†â–„â–„â–‚â–ˆâ–…â–„â–â–ƒâ–‚â–†â–ƒâ–…â–‚â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–†â–…â–ƒâ–„â–â–„â–„â–‚â–„
wandb:       eval/ensemble_f1 â–†â–†â–‡â–†â–†â–‡â–†â–†â–‡â–†â–‡â–†â–†â–‚â–ˆâ–‡â–‡â–…â–‡â–†â–…â–ˆâ–†â–â–†â–‡â–…â–‡â–†â–ˆâ–â–†â–†â–†â–‡â–ƒâ–‡â–†â–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–â–â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–„â–†â–„â–†â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–„â–„â–‡â–…â–„â–„â–ƒâ–„â–‚â–„â–‚â–ƒâ–…â–ˆ
wandb:      train/ensemble_f1 â–†â–„â–†â–…â–‡â–„â–…â–‡â–„â–ƒâ–†â–ˆâ–†â–‚â–‡â–‡â–†â–„â–„â–‚â–…â–„â–‡â–„â–†â–‡â–„â–„â–ƒâ–†â–†â–„â–…â–†â–â–†â–‡â–„â–†â–
wandb:         train/mil_loss â–ƒâ–‚â–ƒâ–†â–‚â–†â–ƒâ–…â–„â–ƒâ–„â–†â–…â–…â–†â–…â–â–…â–†â–ƒâ–…â–ƒâ–„â–ˆâ–‚â–„â–‡â–†â–…â–…â–„â–…â–…â–…â–ƒâ–‚â–„â–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78482
wandb: best/eval_avg_mil_loss 0.51943
wandb:  best/eval_ensemble_f1 0.78482
wandb:            eval/avg_f1 0.72619
wandb:      eval/avg_mil_loss 0.62744
wandb:       eval/ensemble_f1 0.72619
wandb:            test/avg_f1 0.78951
wandb:      test/avg_mil_loss 0.50701
wandb:       test/ensemble_f1 0.78951
wandb:           train/avg_f1 0.76588
wandb:      train/ensemble_f1 0.76588
wandb:         train/mil_loss 0.55217
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run eager-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/st7fif95
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074503-st7fif95/logs
wandb: Agent Starting Run: q9aqveg0 with config:
wandb: 	actor_learning_rate: 0.0001221306881483886
wandb: 	attention_dropout_p: 0.18192782193148663
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 193
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6632107030950932
wandb: 	temperature: 0.5694239695905412
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_074718-q9aqveg0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q9aqveg0
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–…â–ˆâ–â–â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–‡â–‚â–‡â–‚â–…â–â–â–‡â–ˆâ–‡â–‚â–‚â–â–â–„â–‡â–‚â–â–‚â–â–ˆâ–‚â–‡â–‚â–‡â–…â–‚â–‚â–ˆâ–ˆâ–…â–‚â–…â–‚â–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:      eval/avg_mil_loss â–ƒâ–‡â–ƒâ–ƒâ–â–…â–†â–‡â–…â–…â–ƒâ–‡â–â–…â–…â–‡â–†â–â–‚â–…â–ˆâ–ˆâ–…â–…â–ƒâ–‚â–ƒâ–†â–„â–†â–ƒâ–…â–…â–‡â–ˆâ–…â–…â–‚â–…â–†
wandb:       eval/ensemble_f1 â–‡â–‚â–‡â–â–â–‚â–‚â–‡â–‚â–…â–…â–‚â–‡â–ˆâ–‚â–„â–‡â–â–…â–‚â–…â–‚â–ˆâ–ˆâ–‡â–‡â–â–‚â–‚â–‡â–‡â–ˆâ–‚â–†â–‡â–‡â–†â–‡â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ƒâ–…â–…â–…â–ƒâ–„â–†â–†â–‡â–„â–ƒâ–‚â–„â–„â–†â–ƒâ–„â–ƒâ–„â–‡â–ƒâ–…â–…â–…â–„â–…â–„â–‚â–ƒâ–â–ƒâ–ˆâ–…â–‚â–…â–„â–‚â–â–„
wandb:      train/ensemble_f1 â–„â–„â–„â–‡â–…â–„â–†â–„â–…â–…â–…â–ƒâ–†â–…â–ƒâ–‚â–…â–ƒâ–†â–†â–†â–†â–†â–…â–â–†â–„â–…â–†â–…â–ˆâ–†â–â–„â–†â–‚â–†â–…â–„â–…
wandb:         train/mil_loss â–ƒâ–…â–â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–…â–…â–ƒâ–„â–†â–„â–‡â–…â–†â–†â–ƒâ–„â–„â–…â–„â–„â–ƒâ–„â–†â–ƒâ–‡â–ˆâ–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84103
wandb: best/eval_avg_mil_loss 0.51103
wandb:  best/eval_ensemble_f1 0.84103
wandb:            eval/avg_f1 0.46262
wandb:      eval/avg_mil_loss 0.94413
wandb:       eval/ensemble_f1 0.46262
wandb:            test/avg_f1 0.45212
wandb:      test/avg_mil_loss 0.6995
wandb:       test/ensemble_f1 0.45212
wandb:           train/avg_f1 0.6446
wandb:      train/ensemble_f1 0.6446
wandb:         train/mil_loss 0.83028
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wild-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q9aqveg0
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_074718-q9aqveg0/logs
wandb: Agent Starting Run: i18gnz44 with config:
wandb: 	actor_learning_rate: 1.4130755557441716e-06
wandb: 	attention_dropout_p: 0.002716148263062379
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3205933860532669
wandb: 	temperature: 2.791888560752509
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075029-i18gnz44
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i18gnz44
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ˆâ–‡â–…â–â–ƒâ–„â–„â–‡â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–†â–†â–†â–†â–„â–‡â–†â–†â–…â–„â–„â–…â–‡â–…â–‡â–†â–…â–â–†â–…â–‚â–„â–†â–„â–†â–†â–‡â–‡â–„â–ˆâ–‡â–†â–‡â–‡â–†â–ˆâ–†â–…
wandb:      eval/avg_mil_loss â–…â–ƒâ–…â–„â–ƒâ–â–‚â–†â–â–‚â–‚â–„â–‡â–„â–‚â–‚â–ƒâ–…â–‚â–â–â–â–ƒâ–‡â–ˆâ–…â–„â–…â–ƒâ–ƒâ–â–â–‚â–ƒâ–â–‡â–ƒâ–â–„â–‡
wandb:       eval/ensemble_f1 â–…â–…â–†â–ƒâ–†â–…â–…â–„â–†â–â–„â–‡â–†â–‚â–„â–„â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–„â–‡â–‡â–†â–…â–†â–†â–‡â–ƒâ–ˆâ–„â–ˆâ–‡â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–ƒâ–…â–…â–„â–†â–…â–„â–†â–†â–‚â–ˆâ–„â–…â–„â–†â–‚â–‡â–…â–â–„â–…â–‡â–‡â–†â–…â–ˆâ–…â–‡â–†â–…â–†â–…â–†â–‡â–…â–…â–‡â–†
wandb:      train/ensemble_f1 â–„â–â–‡â–‡â–„â–‚â–‚â–…â–ƒâ–…â–…â–‡â–„â–†â–„â–„â–ƒâ–†â–‡â–ƒâ–†â–†â–†â–†â–†â–ˆâ–†â–†â–…â–…â–„â–…â–„â–…â–…â–„â–ˆâ–…â–‡â–ˆ
wandb:         train/mil_loss â–„â–†â–…â–„â–„â–ƒâ–‚â–†â–„â–„â–ˆâ–‚â–ˆâ–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–‡â–…â–„â–…â–…â–„â–„â–„â–…â–ƒâ–â–…â–ƒâ–„â–â–…â–…â–„â–ƒâ–…â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83121
wandb: best/eval_avg_mil_loss 0.50006
wandb:  best/eval_ensemble_f1 0.83121
wandb:            eval/avg_f1 0.72011
wandb:      eval/avg_mil_loss 0.70441
wandb:       eval/ensemble_f1 0.72011
wandb:            test/avg_f1 0.81952
wandb:      test/avg_mil_loss 0.54286
wandb:       test/ensemble_f1 0.81952
wandb:           train/avg_f1 0.7862
wandb:      train/ensemble_f1 0.7862
wandb:         train/mil_loss 0.54571
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run upbeat-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i18gnz44
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075029-i18gnz44/logs
wandb: Agent Starting Run: eegg99rr with config:
wandb: 	actor_learning_rate: 9.007574832286728e-05
wandb: 	attention_dropout_p: 0.018989275002083472
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9499104736290996
wandb: 	temperature: 7.456935009180309
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075253-eegg99rr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eegg99rr
wandb: uploading history steps 56-64, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–‡â–ˆâ–â–ˆâ–‡â–‡â–†â–‡â–â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–‡â–‚â–‡â–‡â–†â–‡â–â–†â–‡â–‡â–‚â–‡â–‚â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‡â–„â–†â–†â–‡â–…â–„â–…â–…â–„â–…â–…â–ƒâ–‡â–ƒâ–†â–ƒâ–„â–â–â–‡â–â–ˆâ–ƒâ–„â–„â–‡â–„â–‡â–…â–…â–…â–…â–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–‡â–…â–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–‡â–â–ˆâ–…â–‡â–‡â–‡â–ˆâ–‚â–ˆâ–†â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–‡â–â–‡â–†â–‡â–â–‡â–‡â–‡â–‡â–‡
wandb:           train/avg_f1 â–„â–†â–‡â–„â–‡â–‚â–…â–ƒâ–„â–…â–„â–…â–ˆâ–…â–†â–ˆâ–‚â–†â–†â–‚â–‡â–†â–‡â–…â–„â–†â–†â–„â–‡â–†â–â–†â–ˆâ–†â–†â–‡â–ƒâ–…â–„â–‚
wandb:      train/ensemble_f1 â–…â–†â–„â–†â–ˆâ–„â–…â–ƒâ–â–„â–…â–‡â–„â–…â–‡â–…â–†â–…â–„â–‚â–‡â–…â–†â–…â–…â–…â–„â–…â–„â–†â–„â–â–…â–…â–‡â–…â–†â–„â–…â–‚
wandb:         train/mil_loss â–ƒâ–†â–ƒâ–‡â–„â–†â–„â–…â–…â–„â–„â–„â–‡â–…â–ƒâ–‡â–‡â–ˆâ–ƒâ–‚â–‚â–„â–‚â–†â–ƒâ–ƒâ–…â–„â–…â–†â–‡â–†â–ƒâ–â–†â–„â–†â–ˆâ–ƒâ–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80896
wandb: best/eval_avg_mil_loss 0.58621
wandb:  best/eval_ensemble_f1 0.80896
wandb:            eval/avg_f1 0.80203
wandb:      eval/avg_mil_loss 0.65698
wandb:       eval/ensemble_f1 0.80203
wandb:           train/avg_f1 0.66939
wandb:      train/ensemble_f1 0.66939
wandb:         train/mil_loss 0.67715
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lyric-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eegg99rr
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075253-eegg99rr/logs
wandb: ERROR Run eegg99rr errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: mxb4ay8o with config:
wandb: 	actor_learning_rate: 1.0529291897233456e-05
wandb: 	attention_dropout_p: 0.3105960714357317
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.024237435341690428
wandb: 	temperature: 3.792045385041136
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075412-mxb4ay8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mxb4ay8o
wandb: uploading history steps 180-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–‚â–ˆâ–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–‡â–†â–ˆâ–†â–‡â–†â–‡â–ˆâ–â–„â–…â–…â–†â–…â–ˆâ–…â–…â–…â–ˆâ–â–‡â–†â–ƒâ–…â–‚â–‡â–„â–„â–ˆâ–‡â–‡â–‡â–†â–†â–…â–†â–…â–†
wandb:      eval/avg_mil_loss â–ƒâ–‚â–…â–„â–ƒâ–‚â–„â–â–†â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–…â–ˆâ–„â–…â–…â–„â–ƒâ–ƒâ–â–…â–‚â–„â–ƒâ–‚â–ƒâ–„â–„â–‡â–ƒâ–„â–â–†â–„
wandb:       eval/ensemble_f1 â–‡â–„â–…â–†â–‡â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–ƒâ–â–‡â–…â–…â–‡â–‡â–ˆâ–‡â–†â–„â–…â–ˆâ–†â–†â–‡â–ˆâ–†â–†â–†â–‡â–‡â–‡
wandb:           train/avg_f1 â–†â–‡â–†â–…â–…â–†â–ƒâ–…â–†â–‡â–‡â–‡â–†â–…â–‡â–ƒâ–†â–‡â–†â–†â–…â–‡â–†â–‚â–ˆâ–…â–†â–„â–ˆâ–‡â–†â–…â–ˆâ–…â–†â–†â–‡â–â–†â–†
wandb:      train/ensemble_f1 â–„â–…â–„â–…â–‡â–‚â–…â–†â–†â–†â–…â–„â–‡â–…â–ˆâ–†â–…â–†â–„â–…â–…â–…â–…â–†â–†â–„â–ƒâ–â–…â–…â–ˆâ–…â–ƒâ–…â–†â–†â–‡â–ˆâ–†â–†
wandb:         train/mil_loss â–‡â–ƒâ–…â–ƒâ–‡â–ˆâ–†â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–…â–…â–„â–…â–ƒâ–…â–‡â–…â–â–†â–…â–‚â–‡â–„â–…â–‚â–…â–„â–ƒâ–…â–â–ƒâ–ƒâ–ˆâ–„â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–ˆâ–„â–„â–â–„â–â–„â–„â–„â–„â–â–â–â–ˆâ–â–„â–„â–ˆâ–â–â–„â–„â–„â–„â–ˆâ–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83488
wandb: best/eval_avg_mil_loss 0.451
wandb:  best/eval_ensemble_f1 0.83488
wandb:            eval/avg_f1 0.75492
wandb:      eval/avg_mil_loss 0.69876
wandb:       eval/ensemble_f1 0.75492
wandb:           train/avg_f1 0.72302
wandb:      train/ensemble_f1 0.72302
wandb:         train/mil_loss 0.72507
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run drawn-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mxb4ay8o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075412-mxb4ay8o/logs
wandb: ERROR Run mxb4ay8o errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kyzc4ajb with config:
wandb: 	actor_learning_rate: 0.0005881591396435628
wandb: 	attention_dropout_p: 0.4910794318775117
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 77
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45580123821496
wandb: 	temperature: 0.5729732335318971
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075739-kyzc4ajb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kyzc4ajb
wandb: uploading wandb-summary.json
wandb: uploading history steps 69-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‚â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†â–‡â–†â–‡â–ˆâ–†â–ˆâ–…â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–ˆâ–†â–‡â–â–†â–†â–†â–ˆâ–ˆâ–…
wandb:      eval/avg_mil_loss â–…â–…â–„â–‚â–„â–„â–â–‚â–â–ƒâ–â–„â–…â–‚â–…â–†â–„â–…â–â–â–…â–„â–…â–â–‚â–†â–‡â–ƒâ–…â–â–â–‚â–†â–…â–ˆâ–…â–…â–â–…â–…
wandb:       eval/ensemble_f1 â–†â–†â–†â–†â–ˆâ–†â–†â–†â–â–†â–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–‡â–‡â–‡â–ˆâ–…â–ˆâ–†â–†â–‡â–†â–†â–‡â–†â–†â–‡â–ˆâ–ˆâ–†
wandb:           train/avg_f1 â–…â–‡â–†â–‡â–…â–…â–„â–…â–…â–„â–‚â–„â–‡â–â–„â–†â–…â–â–†â–„â–‡â–‚â–„â–„â–†â–„â–‡â–„â–‡â–†â–„â–…â–…â–…â–†â–„â–‡â–„â–„â–ˆ
wandb:      train/ensemble_f1 â–…â–‡â–†â–…â–ˆâ–…â–…â–…â–ƒâ–…â–…â–…â–„â–†â–â–…â–‡â–„â–„â–…â–„â–„â–„â–‡â–„â–„â–†â–…â–†â–…â–„â–…â–…â–…â–†â–…â–„â–†â–„â–ˆ
wandb:         train/mil_loss â–‚â–†â–†â–…â–‡â–‚â–…â–ƒâ–†â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–…â–„â–„â–‚â–„â–†â–…â–ƒâ–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–†â–‡â–‚â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84765
wandb: best/eval_avg_mil_loss 0.4367
wandb:  best/eval_ensemble_f1 0.84765
wandb:            eval/avg_f1 0.73896
wandb:      eval/avg_mil_loss 0.6658
wandb:       eval/ensemble_f1 0.73896
wandb:           train/avg_f1 0.8095
wandb:      train/ensemble_f1 0.8095
wandb:         train/mil_loss 0.62752
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fragrant-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kyzc4ajb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075739-kyzc4ajb/logs
wandb: ERROR Run kyzc4ajb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 1yfr9gsm with config:
wandb: 	actor_learning_rate: 2.270757708754449e-06
wandb: 	attention_dropout_p: 0.39994428224574224
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 182
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8834612396050322
wandb: 	temperature: 1.613840000954131
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075912-1yfr9gsm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1yfr9gsm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–…â–…â–†â–ƒâ–†â–…â–„â–‡â–…â–…â–†â–ƒâ–â–‡â–‡â–ƒâ–ƒâ–…â–ˆâ–†â–„â–†â–†â–ˆâ–…â–‡â–†â–†â–„â–„â–‡â–ƒâ–…â–‡â–‡â–‡â–…â–†
wandb:      eval/avg_mil_loss â–†â–‡â–†â–‡â–…â–‡â–…â–‡â–…â–‡â–ˆâ–„â–†â–†â–†â–‡â–‡â–†â–…â–…â–â–„â–„â–‡â–ˆâ–…â–†â–‡â–„â–…â–…â–‡â–…â–ˆâ–‡â–…â–…â–†â–†â–…
wandb:       eval/ensemble_f1 â–†â–†â–†â–†â–‡â–†â–ˆâ–†â–ˆâ–â–„â–ˆâ–„â–„â–â–„â–‡â–…â–„â–†â–†â–…â–†â–†â–„â–‡â–†â–â–„â–‡â–‚â–‡â–„â–‚â–‡â–„â–†â–†â–†â–„
wandb:           train/avg_f1 â–„â–ˆâ–‚â–„â–„â–„â–‡â–…â–…â–‡â–„â–„â–‡â–„â–…â–ƒâ–…â–†â–‚â–‚â–…â–…â–„â–„â–ƒâ–†â–„â–„â–„â–ƒâ–ƒâ–„â–†â–…â–„â–ƒâ–„â–ˆâ–â–„
wandb:      train/ensemble_f1 â–†â–…â–‡â–†â–…â–‡â–†â–„â–…â–„â–ˆâ–„â–…â–‡â–†â–†â–ƒâ–†â–‡â–‡â–…â–…â–…â–†â–ƒâ–†â–‚â–ˆâ–‡â–„â–†â–ƒâ–„â–‡â–â–‡â–†â–„â–…â–„
wandb:         train/mil_loss â–…â–…â–†â–…â–…â–†â–ƒâ–‚â–„â–†â–†â–ˆâ–†â–„â–…â–â–‡â–…â–„â–‡â–ƒâ–…â–…â–‚â–ƒâ–„â–„â–‡â–†â–…â–ƒâ–‚â–‚â–ƒâ–‡â–…â–„â–‚â–ƒâ–„
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–‚â–‡â–„â–…â–„â–„â–‡â–â–„â–„â–„â–‡â–â–‡â–„â–ˆâ–„â–„â–â–â–„â–â–â–„â–â–â–„â–‡â–„â–â–…â–â–â–„â–â–â–‡â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79965
wandb: best/eval_avg_mil_loss 0.47361
wandb:  best/eval_ensemble_f1 0.79965
wandb:            eval/avg_f1 0.63061
wandb:      eval/avg_mil_loss 0.77761
wandb:       eval/ensemble_f1 0.63061
wandb:           train/avg_f1 0.5796
wandb:      train/ensemble_f1 0.5796
wandb:         train/mil_loss 0.8269
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1yfr9gsm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075912-1yfr9gsm/logs
wandb: ERROR Run 1yfr9gsm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t91amaoe with config:
wandb: 	actor_learning_rate: 1.4930936989444544e-05
wandb: 	attention_dropout_p: 0.0973077814358948
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 162
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16700733849246818
wandb: 	temperature: 7.178915469985723
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080315-t91amaoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t91amaoe
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‡â–‡â–ƒâ–…â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–â–ˆâ–‡â–‡â–…â–†â–†â–†â–†â–ƒâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–â–‡â–‡â–†â–‡â–‡
wandb:      eval/avg_mil_loss â–„â–†â–…â–‡â–ˆâ–â–â–„â–„â–†â–‡â–‡â–†â–†â–†â–‚â–†â–‚â–ˆâ–ƒâ–„â–‡â–†â–…â–‚â–…â–„â–†â–†â–ƒâ–ƒâ–…â–â–†â–…â–…â–„â–…â–ˆâ–ˆ
wandb:       eval/ensemble_f1 â–‡â–ˆâ–ˆâ–‡â–†â–‡â–‡â–†â–ƒâ–â–‡â–†â–„â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–†â–…â–‡â–…â–…â–„â–…â–ˆâ–†â–‡â–ˆâ–…â–†â–ƒâ–†â–…â–‡â–…â–„â–â–‡â–ˆâ–…â–…â–…â–‡â–…â–„â–†â–„â–ˆâ–ˆâ–†â–…â–†â–†â–…â–„â–…
wandb:      train/ensemble_f1 â–ˆâ–…â–…â–…â–…â–†â–…â–‡â–â–†â–‡â–ˆâ–…â–ˆâ–…â–†â–ˆâ–‡â–â–‡â–†â–…â–ƒâ–†â–†â–ƒâ–‚â–…â–ˆâ–†â–ƒâ–„â–ˆâ–‡â–‡â–†â–…â–‡â–†â–…
wandb:         train/mil_loss â–ƒâ–ƒâ–„â–†â–ˆâ–†â–ƒâ–†â–‚â–‡â–‡â–‚â–„â–„â–‚â–„â–ƒâ–†â–„â–ƒâ–ƒâ–â–ƒâ–„â–„â–‡â–…â–‚â–…â–„â–„â–…â–…â–…â–…â–†â–‚â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86005
wandb: best/eval_avg_mil_loss 0.36325
wandb:  best/eval_ensemble_f1 0.86005
wandb:            eval/avg_f1 0.79179
wandb:      eval/avg_mil_loss 0.399
wandb:       eval/ensemble_f1 0.79179
wandb:            test/avg_f1 0.8819
wandb:      test/avg_mil_loss 0.39007
wandb:       test/ensemble_f1 0.8819
wandb:           train/avg_f1 0.73957
wandb:      train/ensemble_f1 0.73957
wandb:         train/mil_loss 0.60054
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smart-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t91amaoe
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080315-t91amaoe/logs
wandb: Agent Starting Run: my6gpn5a with config:
wandb: 	actor_learning_rate: 2.5148053886172943e-05
wandb: 	attention_dropout_p: 0.3159659241036897
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9849405118515484
wandb: 	temperature: 3.028208781973821
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080615-my6gpn5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/my6gpn5a
wandb: uploading wandb-summary.json
wandb: uploading history steps 110-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–ˆâ–â–†â–„â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–‚â–†â–„â–†â–†â–†â–â–ˆâ–ˆâ–†â–‡â–‡â–†â–‚â–ˆâ–‚â–‡â–…â–†â–‡â–‡â–„â–†â–†â–ˆâ–‡â–†â–†â–ˆâ–…â–†â–†â–†â–†â–†â–‡â–‡â–„â–‡
wandb:      eval/avg_mil_loss â–„â–…â–ˆâ–‡â–‚â–„â–†â–â–†â–…â–ƒâ–ˆâ–‚â–‚â–‡â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–…â–…â–„â–…â–…â–‡â–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–‚â–ƒâ–‚â–‚â–…â–
wandb:       eval/ensemble_f1 â–†â–†â–…â–…â–‡â–ˆâ–‡â–…â–†â–†â–†â–ˆâ–„â–â–„â–…â–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–ˆâ–‡â–‡â–ƒâ–†â–†â–†â–…â–ƒâ–‡â–†â–ˆâ–‡â–‡â–ƒâ–ˆâ–‡
wandb:           train/avg_f1 â–„â–â–…â–„â–ƒâ–‚â–ƒâ–†â–â–†â–ƒâ–ƒâ–…â–ˆâ–‚â–„â–„â–‚â–…â–†â–„â–ƒâ–„â–‡â–ƒâ–†â–ƒâ–ƒâ–‚â–„â–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–‡
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‡â–…â–…â–†â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–…â–„â–…â–„â–‚â–†â–„â–„â–„â–‡â–‚â–‡â–ƒâ–†â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–â–„â–†â–‚â–â–…â–â–„
wandb:         train/mil_loss â–…â–…â–„â–‚â–„â–„â–‡â–…â–…â–ƒâ–…â–‚â–…â–‚â–ƒâ–„â–‚â–„â–…â–‡â–â–„â–ƒâ–„â–ƒâ–†â–ƒâ–„â–„â–‡â–ƒâ–ˆâ–‚â–…â–‚â–‚â–„â–„â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–„â–„â–„â–â–„â–â–ˆâ–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„â–ˆâ–ˆâ–â–ˆâ–â–„â–„â–„â–ˆâ–„â–â–ˆâ–„â–â–„â–â–„â–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83433
wandb: best/eval_avg_mil_loss 0.45671
wandb:  best/eval_ensemble_f1 0.83433
wandb:            eval/avg_f1 0.77295
wandb:      eval/avg_mil_loss 0.62956
wandb:       eval/ensemble_f1 0.77295
wandb:           train/avg_f1 0.75695
wandb:      train/ensemble_f1 0.75695
wandb:         train/mil_loss 0.61207
wandb:      train/policy_loss -0.19849
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.19849
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/my6gpn5a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080615-my6gpn5a/logs
wandb: ERROR Run my6gpn5a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: y4s58js3 with config:
wandb: 	actor_learning_rate: 3.862068653587336e-06
wandb: 	attention_dropout_p: 0.4425566982378252
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7663119882083661
wandb: 	temperature: 7.405698201715564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080835-y4s58js3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4s58js3
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 42-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–‡â–‡â–„â–‡â–‡â–‡â–…â–…â–†â–…â–†â–…â–‡â–…â–…â–…â–…â–‡â–‡â–…â–†â–†â–â–…â–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–…â–†â–‡â–‡â–…â–…â–†
wandb:      eval/avg_mil_loss â–â–â–…â–„â–‡â–‚â–‚â–‚â–ˆâ–ƒâ–â–‡â–‚â–†â–ƒâ–†â–†â–‚â–â–‚â–‚â–â–ƒâ–â–†â–â–…â–†â–â–â–â–‚â–†â–‡â–‚â–…â–‚â–â–‡â–†
wandb:       eval/ensemble_f1 â–‡â–†â–‡â–‡â–‡â–‡â–†â–…â–‡â–†â–†â–…â–†â–…â–…â–‡â–‡â–‡â–…â–†â–†â–â–‡â–…â–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–…â–†â–‡â–‡â–…â–ˆâ–…â–†â–…
wandb:           train/avg_f1 â–…â–â–„â–„â–‚â–‚â–„â–…â–†â–‚â–…â–‡â–ƒâ–…â–ƒâ–…â–ƒâ–‡â–…â–†â–ˆâ–†â–†â–†â–†â–…â–…â–‚â–…â–â–…â–†â–…â–‚â–‚â–‡â–‚â–„â–‚â–†
wandb:      train/ensemble_f1 â–‡â–‡â–ƒâ–†â–†â–â–„â–†â–‡â–‡â–†â–ˆâ–…â–†â–†â–†â–ˆâ–…â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–„â–‡â–ƒâ–†â–‡â–‡â–†â–„â–ˆâ–„â–†â–„â–‡
wandb:         train/mil_loss â–„â–„â–†â–†â–†â–„â–‡â–‡â–‡â–„â–„â–†â–„â–‡â–†â–‡â–†â–ƒâ–â–†â–…â–‡â–…â–…â–…â–‚â–ƒâ–…â–‡â–†â–„â–‚â–†â–…â–…â–ˆâ–„â–‡â–†â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83242
wandb: best/eval_avg_mil_loss 0.4532
wandb:  best/eval_ensemble_f1 0.83242
wandb:            eval/avg_f1 0.7435
wandb:      eval/avg_mil_loss 0.71626
wandb:       eval/ensemble_f1 0.7435
wandb:           train/avg_f1 0.79426
wandb:      train/ensemble_f1 0.79426
wandb:         train/mil_loss 0.58059
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run firm-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4s58js3
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080835-y4s58js3/logs
wandb: ERROR Run y4s58js3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: g0kw4x5s with config:
wandb: 	actor_learning_rate: 9.379449082020227e-06
wandb: 	attention_dropout_p: 0.461426717103547
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.294444136262378
wandb: 	temperature: 4.312380486630504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080943-g0kw4x5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0kw4x5s
wandb: uploading history steps 110-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–â–‡â–ˆâ–…â–…â–‡â–‡â–ˆâ–„â–„â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–„â–†â–ƒâ–„â–†â–‡â–‡â–‡â–†â–…â–ˆâ–ˆâ–ˆâ–ƒâ–…â–ˆâ–„â–ˆâ–…â–‡â–‡
wandb:      eval/avg_mil_loss â–ƒâ–‡â–†â–ƒâ–ˆâ–…â–„â–†â–ƒâ–ˆâ–ƒâ–…â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–…â–†â–†â–„â–ƒâ–†â–â–ƒâ–„â–ƒâ–‡â–ƒâ–„â–‚â–„â–‚â–†â–…â–„â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–…â–…â–‚â–‡â–…â–ˆâ–…â–‡â–„â–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–…â–†â–ˆâ–ˆâ–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–…â–…â–ˆâ–‡â–‡â–ˆâ–…â–ˆ
wandb:           train/avg_f1 â–„â–„â–„â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–†â–â–…â–‚â–„â–„â–„â–…â–â–â–ƒâ–„â–†â–â–†â–„â–ƒâ–„â–ƒâ–â–…â–„â–…â–„â–‚â–„â–ƒâ–‚â–ˆâ–‚
wandb:      train/ensemble_f1 â–†â–„â–ƒâ–…â–ƒâ–†â–„â–‚â–ƒâ–‚â–â–‚â–…â–…â–…â–†â–„â–…â–„â–‡â–â–‚â–‚â–…â–ƒâ–ˆâ–…â–„â–‡â–‡â–„â–…â–…â–„â–†â–‡â–‚â–„â–‚â–…
wandb:         train/mil_loss â–â–„â–ƒâ–ƒâ–„â–…â–â–ˆâ–‡â–…â–‡â–…â–ˆâ–â–…â–‚â–…â–†â–ƒâ–…â–‡â–†â–‡â–…â–ƒâ–†â–‡â–‡â–ƒâ–„â–ƒâ–‚â–â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–…
wandb:      train/policy_loss â–„â–â–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80545
wandb: best/eval_avg_mil_loss 0.50035
wandb:  best/eval_ensemble_f1 0.80545
wandb:            eval/avg_f1 0.77217
wandb:      eval/avg_mil_loss 0.60821
wandb:       eval/ensemble_f1 0.77217
wandb:           train/avg_f1 0.68086
wandb:      train/ensemble_f1 0.68086
wandb:         train/mil_loss 0.5953
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run mild-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0kw4x5s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080943-g0kw4x5s/logs
wandb: ERROR Run g0kw4x5s errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wltsglpt with config:
wandb: 	actor_learning_rate: 0.0001853060268348073
wandb: 	attention_dropout_p: 0.4967422519566934
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8055805468093156
wandb: 	temperature: 8.559038123096933
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081154-wltsglpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wltsglpt
wandb: uploading history steps 83-93, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–‡â–‡â–„â–†â–…â–†â–…â–…â–‡â–ƒâ–†â–‚â–†â–„â–„â–†â–„â–ƒâ–‡â–ˆâ–ƒâ–†â–†â–…â–†â–‡â–â–†â–ˆâ–„â–ˆâ–…â–„â–„â–„â–‡â–„â–‡
wandb:      eval/avg_mil_loss â–‡â–…â–â–‡â–‡â–†â–…â–ˆâ–„â–…â–…â–…â–â–ƒâ–ƒâ–„â–‚â–‚â–„â–…â–…â–ƒâ–„â–ƒâ–‡â–„â–ƒâ–‚â–…â–…â–„â–ƒâ–…â–†â–‡â–ƒâ–†â–ƒâ–â–„
wandb:       eval/ensemble_f1 â–ˆâ–†â–â–†â–†â–…â–†â–„â–‡â–„â–†â–â–†â–ƒâ–†â–†â–‡â–„â–ƒâ–†â–„â–†â–‚â–‡â–†â–†â–‡â–ˆâ–ˆâ–†â–‚â–„â–ƒâ–…â–‚â–†â–†â–ƒâ–ˆâ–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–„â–ƒâ–†â–‡â–ƒâ–„â–…â–‡â–„â–„â–…â–†â–„â–…â–…â–…â–„â–…â–ƒâ–†â–†â–…â–â–†â–…â–…â–…â–„â–„â–…â–†â–…â–…â–„â–…â–„â–„â–ƒâ–ˆ
wandb:      train/ensemble_f1 â–ˆâ–‡â–„â–…â–ˆâ–…â–…â–‡â–…â–†â–ƒâ–…â–†â–†â–„â–ƒâ–†â–…â–†â–„â–â–‡â–‡â–†â–„â–†â–†â–†â–†â–‡â–†â–†â–…â–‚â–„â–…â–…â–ƒâ–…â–…
wandb:         train/mil_loss â–…â–†â–„â–…â–ˆâ–„â–†â–„â–…â–†â–…â–ˆâ–ˆâ–„â–ƒâ–„â–…â–„â–‡â–ƒâ–†â–ƒâ–„â–†â–†â–„â–†â–†â–ˆâ–„â–„â–…â–‡â–…â–â–…â–†â–…â–†â–‡
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81526
wandb: best/eval_avg_mil_loss 0.49959
wandb:  best/eval_ensemble_f1 0.81526
wandb:            eval/avg_f1 0.7257
wandb:      eval/avg_mil_loss 0.63757
wandb:       eval/ensemble_f1 0.7257
wandb:            test/avg_f1 0.77766
wandb:      test/avg_mil_loss 0.5063
wandb:       test/ensemble_f1 0.77766
wandb:           train/avg_f1 0.73605
wandb:      train/ensemble_f1 0.73605
wandb:         train/mil_loss 0.63464
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run soft-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wltsglpt
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081154-wltsglpt/logs
wandb: Agent Starting Run: 0gs7kay8 with config:
wandb: 	actor_learning_rate: 6.881657154660066e-05
wandb: 	attention_dropout_p: 0.3407973886148896
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46840305256766535
wandb: 	temperature: 3.7099651707345127
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081357-0gs7kay8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0gs7kay8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–‡â–…â–…â–‡â–„â–‡â–‡â–…â–†â–â–†â–…â–‡â–…â–†â–†â–‡â–‚â–†â–…â–‡â–‡â–ˆâ–†â–ˆâ–†â–‡â–‡â–ˆâ–†â–…
wandb:      eval/avg_mil_loss â–„â–†â–†â–ƒâ–‡â–„â–„â–„â–„â–„â–…â–…â–‚â–†â–ƒâ–…â–†â–†â–ˆâ–ƒâ–†â–…â–ƒâ–ƒâ–„â–„â–ˆâ–‡â–†â–„â–„â–â–…â–„â–„â–„â–‚â–„â–ˆâ–ƒ
wandb:       eval/ensemble_f1 â–‡â–†â–…â–ƒâ–†â–†â–‡â–†â–‡â–†â–…â–„â–„â–‡â–„â–„â–†â–â–†â–†â–„â–†â–…â–…â–‡â–…â–‡â–†â–‚â–†â–ˆâ–†â–‡â–‡â–†â–†â–†â–‡â–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–†â–†â–ˆâ–„â–‡â–ƒâ–…â–…â–†â–†â–‡â–â–…â–‡â–ƒâ–†â–ƒâ–†â–‡â–†â–ƒâ–ˆâ–ƒâ–…â–‡â–…â–ƒâ–…â–†â–…â–„â–…â–†â–…â–†â–†â–…â–†â–†
wandb:      train/ensemble_f1 â–…â–†â–†â–†â–ˆâ–†â–‡â–ƒâ–…â–…â–†â–‡â–†â–‡â–â–‡â–„â–†â–†â–‡â–†â–ƒâ–ˆâ–ƒâ–…â–‡â–…â–ƒâ–…â–†â–…â–„â–†â–…â–†â–†â–†â–…â–†â–†
wandb:         train/mil_loss â–…â–ƒâ–†â–â–…â–ˆâ–…â–ƒâ–„â–…â–„â–†â–„â–†â–…â–…â–…â–„â–…â–‡â–…â–…â–ƒâ–ƒâ–„â–â–â–„â–ƒâ–‡â–†â–„â–„â–‡â–†â–†â–†â–‚â–‚â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84856
wandb: best/eval_avg_mil_loss 0.4752
wandb:  best/eval_ensemble_f1 0.84856
wandb:            eval/avg_f1 0.66335
wandb:      eval/avg_mil_loss 0.56653
wandb:       eval/ensemble_f1 0.66335
wandb:            test/avg_f1 0.70975
wandb:      test/avg_mil_loss 0.61232
wandb:       test/ensemble_f1 0.70975
wandb:           train/avg_f1 0.74405
wandb:      train/ensemble_f1 0.74405
wandb:         train/mil_loss 0.56808
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lyric-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0gs7kay8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081357-0gs7kay8/logs
wandb: Agent Starting Run: df8cptln with config:
wandb: 	actor_learning_rate: 6.224983334565223e-05
wandb: 	attention_dropout_p: 0.3817428557440229
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22819900470698007
wandb: 	temperature: 6.307201986511886
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081459-df8cptln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cjbrxv00
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/df8cptln
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–†â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–…â–†â–‚â–‡â–â–‡â–‡â–ˆâ–„â–‡â–†â–†â–ˆâ–ˆâ–‡â–‡â–†â–‡â–‡â–â–‡â–‡â–‡â–‡â–„â–‡â–ˆâ–ˆâ–ƒâ–‡â–‡
wandb:      eval/avg_mil_loss â–â–„â–â–„â–‚â–„â–„â–„â–†â–ƒâ–‚â–„â–â–â–…â–â–„â–â–â–…â–ƒâ–„â–„â–„â–…â–…â–ˆâ–ƒâ–†â–â–„â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–
wandb:       eval/ensemble_f1 â–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‚â–ˆâ–ˆâ–‚â–ƒâ–‡â–‡â–â–„â–‡â–ˆâ–‡â–„â–‡â–†â–‡â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–„â–†â–ƒâ–‡â–…â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–…â–„â–‚â–‡â–…â–‡â–„â–†â–…â–â–†â–„â–„â–‚â–ˆâ–â–„â–ƒâ–ƒâ–…â–†â–†â–†â–†â–‡â–ƒâ–â–†â–…â–„â–…â–‚â–…â–…â–‡â–†â–†â–†
wandb:      train/ensemble_f1 â–†â–‚â–â–†â–„â–ˆâ–†â–„â–…â–ˆâ–…â–†â–†â–…â–â–„â–„â–„â–†â–‡â–…â–â–ƒâ–ƒâ–…â–†â–ˆâ–„â–ƒâ–„â–†â–†â–„â–†â–„â–…â–„â–†â–„â–†
wandb:         train/mil_loss â–…â–ƒâ–†â–„â–†â–†â–„â–…â–‚â–…â–„â–…â–…â–…â–‚â–„â–‡â–†â–ƒâ–†â–ƒâ–ˆâ–„â–„â–…â–‡â–†â–ƒâ–„â–„â–…â–‡â–†â–…â–…â–…â–ˆâ–…â–…â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83952
wandb: best/eval_avg_mil_loss 0.44551
wandb:  best/eval_ensemble_f1 0.83952
wandb:            eval/avg_f1 0.81952
wandb:      eval/avg_mil_loss 0.46211
wandb:       eval/ensemble_f1 0.81952
wandb:            test/avg_f1 0.48822
wandb:      test/avg_mil_loss 0.62559
wandb:       test/ensemble_f1 0.48822
wandb:           train/avg_f1 0.76939
wandb:      train/ensemble_f1 0.76939
wandb:         train/mil_loss 0.47864
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lyric-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/df8cptln
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081459-df8cptln/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 9ujqn91z with config:
wandb: 	actor_learning_rate: 2.018138350104916e-05
wandb: 	attention_dropout_p: 0.11603230113860352
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 151
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5786748463428447
wandb: 	temperature: 4.8584246181783355
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081706-9ujqn91z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ujqn91z
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ˆâ–†â–„â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–ˆâ–ˆâ–„â–ˆâ–„â–‡â–„â–‡â–„â–‡â–†â–‡â–„â–â–„â–â–â–„â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–…â–„â–„â–‡â–ˆâ–‡â–‡â–ˆâ–„â–‡â–†â–†â–…
wandb:      eval/avg_mil_loss â–ƒâ–…â–â–…â–‡â–„â–†â–„â–„â–ˆâ–„â–ƒâ–â–‚â–‚â–…â–‡â–â–ƒâ–ƒâ–â–‚â–â–ƒâ–„â–…â–†â–…â–…â–â–„â–ƒâ–‡â–‚â–‚â–…â–…â–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–…â–„â–ˆâ–†â–„â–ˆâ–„â–ˆâ–„â–…â–„â–‡â–ˆâ–†â–ˆâ–…â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–„â–…â–…â–†â–„â–…â–„â–‡â–ˆâ–‡â–†â–…â–…â–ˆâ–ˆâ–„â–…
wandb:           train/avg_f1 â–„â–„â–ƒâ–†â–„â–â–…â–„â–…â–„â–…â–„â–ƒâ–†â–ƒâ–†â–„â–†â–ˆâ–„â–„â–„â–†â–‚â–…â–†â–„â–…â–ƒâ–„â–…â–…â–†â–…â–„â–†â–‡â–…â–„â–†
wandb:      train/ensemble_f1 â–‚â–…â–„â–„â–…â–†â–„â–„â–†â–„â–ƒâ–ƒâ–â–ˆâ–ƒâ–„â–ƒâ–‡â–ƒâ–…â–‚â–‚â–ƒâ–†â–ƒâ–†â–ƒâ–„â–„â–…â–„â–„â–„â–ƒâ–„â–†â–ƒâ–…â–„â–…
wandb:         train/mil_loss â–ˆâ–„â–…â–†â–†â–„â–‡â–„â–…â–„â–‡â–…â–‚â–…â–†â–…â–†â–ƒâ–„â–ƒâ–…â–ƒâ–…â–„â–‚â–„â–†â–„â–…â–ƒâ–„â–„â–ƒâ–†â–…â–…â–„â–â–„â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78741
wandb: best/eval_avg_mil_loss 0.80601
wandb:  best/eval_ensemble_f1 0.78741
wandb:            eval/avg_f1 0.62464
wandb:      eval/avg_mil_loss 0.68672
wandb:       eval/ensemble_f1 0.62464
wandb:           train/avg_f1 0.66358
wandb:      train/ensemble_f1 0.66358
wandb:         train/mil_loss 0.72847
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run whole-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ujqn91z
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081706-9ujqn91z/logs
wandb: ERROR Run 9ujqn91z errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: reg2k3a5 with config:
wandb: 	actor_learning_rate: 3.3857475849458705e-06
wandb: 	attention_dropout_p: 0.21653102379262995
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9769447636332076
wandb: 	temperature: 1.5900301267078998
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081952-reg2k3a5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/reg2k3a5
wandb: uploading wandb-summary.json
wandb: uploading history steps 168-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–‡â–â–†â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–…â–ƒâ–ˆâ–„â–„â–„â–…â–ƒâ–…â–„â–„â–„â–ƒâ–ˆâ–…â–„â–…â–‚â–…â–‚â–„â–„â–ˆâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–…â–„â–…â–„â–â–…â–†â–„â–…
wandb:      eval/avg_mil_loss â–ƒâ–‚â–ˆâ–…â–†â–…â–†â–ˆâ–„â–‚â–†â–…â–ƒâ–‡â–„â–†â–‚â–†â–†â–†â–†â–ƒâ–‚â–‚â–‡â–‡â–‚â–‚â–„â–ƒâ–…â–†â–ƒâ–…â–‚â–â–„â–„â–†â–‚
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–â–„â–„â–…â–„â–…â–†â–„â–ˆâ–…â–‚â–…â–‚â–…â–„â–…â–…â–„â–…â–‚â–„â–†â–†â–…â–„â–…â–„â–ƒâ–‡â–„â–…â–†â–‡â–†â–„â–„â–ƒ
wandb:           train/avg_f1 â–…â–†â–‚â–â–‡â–†â–ˆâ–‚â–â–„â–‚â–…â–ƒâ–…â–‚â–†â–†â–†â–‚â–„â–ƒâ–†â–ƒâ–…â–‚â–„â–â–ˆâ–†â–†â–„â–ˆâ–„â–ˆâ–†â–†â–†â–„â–†â–‡
wandb:      train/ensemble_f1 â–â–„â–„â–ƒâ–‡â–ƒâ–…â–ƒâ–†â–†â–…â–â–„â–…â–…â–‚â–â–â–‡â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‡â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–„â–„â–†â–…â–†â–ƒâ–ƒâ–„â–†
wandb:         train/mil_loss â–†â–ƒâ–ˆâ–‚â–‡â–„â–ƒâ–…â–„â–…â–‡â–„â–ƒâ–„â–„â–†â–…â–…â–„â–†â–†â–ƒâ–†â–â–…â–‡â–‡â–ƒâ–…â–ˆâ–…â–ƒâ–†â–„â–†â–„â–„â–ƒâ–ˆâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76859
wandb: best/eval_avg_mil_loss 1.11135
wandb:  best/eval_ensemble_f1 0.76859
wandb:            eval/avg_f1 0.60021
wandb:      eval/avg_mil_loss 0.77975
wandb:       eval/ensemble_f1 0.60021
wandb:           train/avg_f1 0.61685
wandb:      train/ensemble_f1 0.61685
wandb:         train/mil_loss 1.2606
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wild-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/reg2k3a5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081952-reg2k3a5/logs
wandb: ERROR Run reg2k3a5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3g2j62qz with config:
wandb: 	actor_learning_rate: 4.9191573477206685e-05
wandb: 	attention_dropout_p: 0.13191204556474012
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3303342310234296
wandb: 	temperature: 5.142908450317762
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082247-3g2j62qz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3g2j62qz
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–„â–‚â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–„â–ƒâ–…â–‡â–‚â–ˆâ–„â–„â–‡â–‡â–„â–„â–ƒâ–…â–†â–†â–†â–‡â–„â–‡â–â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆâ–…â–„â–‡
wandb:      eval/avg_mil_loss â–„â–‚â–„â–†â–ˆâ–â–…â–†â–ƒâ–‚â–‚â–…â–…â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–„â–„â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–„â–â–…
wandb:       eval/ensemble_f1 â–…â–…â–ƒâ–…â–â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–„â–„â–ƒâ–ˆâ–„â–ƒâ–…â–ƒâ–â–†â–†â–„â–†â–†â–†â–„â–„â–†â–‚â–„â–„â–ƒâ–†â–†â–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‚â–„â–ƒâ–‚â–â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–„â–„â–…â–ƒâ–…â–ƒâ–…â–„â–„â–ƒâ–ƒâ–„â–…â–…â–…â–†â–„â–…â–…â–†â–‡â–ˆâ–…â–…â–‡
wandb:      train/ensemble_f1 â–„â–â–„â–†â–„â–…â–…â–‡â–…â–†â–„â–…â–…â–…â–…â–†â–„â–„â–…â–…â–†â–…â–…â–…â–†â–ˆâ–„â–†â–†â–†â–†â–‡â–†â–†â–ˆâ–ˆâ–†â–†â–†â–…
wandb:         train/mil_loss â–†â–„â–„â–…â–‡â–‡â–†â–…â–‡â–„â–ˆâ–…â–ƒâ–†â–ˆâ–†â–„â–„â–†â–ˆâ–„â–„â–â–‚â–‡â–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–„â–‚â–â–ƒâ–„â–ƒâ–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77608
wandb: best/eval_avg_mil_loss 0.59667
wandb:  best/eval_ensemble_f1 0.77608
wandb:            eval/avg_f1 0.58314
wandb:      eval/avg_mil_loss 1.18678
wandb:       eval/ensemble_f1 0.58314
wandb:            test/avg_f1 0.67612
wandb:      test/avg_mil_loss 0.88327
wandb:       test/ensemble_f1 0.67612
wandb:           train/avg_f1 0.65052
wandb:      train/ensemble_f1 0.65052
wandb:         train/mil_loss 0.94247
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3g2j62qz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082247-3g2j62qz/logs
wandb: Agent Starting Run: avq9xvwv with config:
wandb: 	actor_learning_rate: 2.7562457338733458e-05
wandb: 	attention_dropout_p: 0.3039106938556306
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6681279175197148
wandb: 	temperature: 8.872633380520675
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082602-avq9xvwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avq9xvwv
wandb: uploading history steps 89-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–ƒâ–ƒâ–‚â–ˆâ–„â–â–„â–‚â–„â–ƒâ–…â–†â–ƒâ–…â–„â–…â–…â–ƒâ–‡â–‡â–„â–…â–‚â–„â–†â–…â–ƒâ–…â–„â–…â–…â–ˆâ–„â–‡â–…â–„â–†â–†â–†â–„
wandb:      eval/avg_mil_loss â–…â–„â–ƒâ–…â–‡â–†â–†â–…â–†â–ƒâ–…â–‡â–‡â–†â–…â–†â–‡â–ˆâ–…â–…â–„â–„â–„â–‡â–„â–…â–„â–„â–‡â–â–…â–„â–â–‡â–ƒâ–…â–„â–†â–„â–†
wandb:       eval/ensemble_f1 â–‚â–ˆâ–…â–„â–â–‚â–ƒâ–ƒâ–…â–†â–‡â–†â–„â–†â–…â–„â–…â–ƒâ–‡â–„â–ƒâ–†â–„â–„â–†â–†â–„â–†â–…â–„â–ƒâ–…â–…â–ˆâ–„â–…â–†â–…â–†â–‡
wandb:           train/avg_f1 â–‚â–ƒâ–â–‚â–â–â–ƒâ–„â–ƒâ–‚â–…â–„â–…â–„â–„â–ƒâ–‚â–â–…â–ƒâ–…â–ƒâ–…â–†â–…â–‡â–„â–†â–„â–„â–†â–†â–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–†
wandb:      train/ensemble_f1 â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–â–‚â–…â–â–…â–…â–ƒâ–†â–…â–†â–†â–„â–…â–„â–…â–‡â–‡â–†â–…â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–†
wandb:         train/mil_loss â–…â–†â–ˆâ–…â–„â–…â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77874
wandb: best/eval_avg_mil_loss 0.71146
wandb:  best/eval_ensemble_f1 0.77874
wandb:            eval/avg_f1 0.75011
wandb:      eval/avg_mil_loss 0.73898
wandb:       eval/ensemble_f1 0.75011
wandb:           train/avg_f1 0.70039
wandb:      train/ensemble_f1 0.70039
wandb:         train/mil_loss 0.86461
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run brisk-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/avq9xvwv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082602-avq9xvwv/logs
wandb: ERROR Run avq9xvwv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9bqys6xp with config:
wandb: 	actor_learning_rate: 5.115795878236665e-05
wandb: 	attention_dropout_p: 0.4140007015211401
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 155
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.435275378610492
wandb: 	temperature: 6.8150254174644935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082807-9bqys6xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bqys6xp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–„â–„â–‚â–â–ƒâ–…â–‡â–‚â–„â–…â–ƒâ–‚â–„â–‚â–ƒâ–…â–ˆâ–ƒâ–„â–…â–„â–†â–„â–„â–‚â–†â–ƒâ–„â–ƒâ–…â–†â–†â–â–‚â–…â–‚â–…â–ƒâ–‚â–ƒ
wandb:      eval/avg_mil_loss â–†â–‡â–…â–†â–„â–„â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‡â–â–„â–„â–â–…â–„â–ƒâ–„â–†â–„â–†â–ƒâ–…â–…â–…â–„â–ƒâ–â–„â–„â–„â–„â–„â–ƒâ–†â–‚â–ƒ
wandb:       eval/ensemble_f1 â–‡â–‚â–‡â–…â–…â–â–‚â–„â–ƒâ–…â–‡â–…â–†â–…â–…â–„â–„â–†â–ƒâ–†â–†â–†â–…â–‚â–„â–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–ƒâ–†â–…â–„â–ˆâ–â–…â–‡â–‚
wandb:           train/avg_f1 â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–…â–ˆâ–‚â–…â–ƒâ–„â–„â–‡â–ƒâ–ƒâ–‡â–…â–ƒâ–…â–‚â–ƒâ–ƒâ–†â–ƒâ–‚â–…â–ƒâ–…â–„â–…â–ˆâ–ƒâ–…â–…â–…â–†â–ƒâ–†
wandb:      train/ensemble_f1 â–‚â–‚â–ƒâ–„â–‚â–„â–ƒâ–ˆâ–â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–…â–„â–„â–ƒâ–‚â–„â–ƒâ–‡â–…â–ƒâ–‚â–„â–„â–ˆâ–…â–†â–…â–ƒâ–ƒâ–‡â–‡â–ƒâ–„â–„
wandb:         train/mil_loss â–‡â–…â–†â–…â–„â–†â–ƒâ–…â–ƒâ–‚â–†â–…â–‚â–ƒâ–†â–‚â–ˆâ–„â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–„â–ƒâ–„â–…â–ƒâ–â–ƒâ–…â–„â–ƒâ–ƒâ–„â–…â–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73433
wandb: best/eval_avg_mil_loss 1.01464
wandb:  best/eval_ensemble_f1 0.73433
wandb:            eval/avg_f1 0.55626
wandb:      eval/avg_mil_loss 0.96111
wandb:       eval/ensemble_f1 0.55626
wandb:           train/avg_f1 0.62557
wandb:      train/ensemble_f1 0.62557
wandb:         train/mil_loss 1.08266
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9bqys6xp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082807-9bqys6xp/logs
wandb: ERROR Run 9bqys6xp errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ivvnkbod with config:
wandb: 	actor_learning_rate: 1.6584819216084023e-05
wandb: 	attention_dropout_p: 0.35999739781142337
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6413353729064096
wandb: 	temperature: 4.469342859375179
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083057-ivvnkbod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivvnkbod
wandb: uploading history steps 125-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–†â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–…â–…â–†â–…â–…â–…â–…â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–„â–„â–ƒâ–…â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–…â–…â–…â–…â–…â–…â–„â–…â–†â–„â–…â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–
wandb:       eval/ensemble_f1 â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–„â–…â–…â–…â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:      train/ensemble_f1 â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–†â–…â–…â–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/mil_loss â–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–‡â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚
wandb:      train/policy_loss â–…â–…â–„â–ƒâ–…â–…â–‚â–…â–…â–ƒâ–â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–„â–…â–…â–…â–…â–…â–„â–…â–…â–ƒâ–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–„â–…â–‚â–…â–…â–ƒâ–…â–…â–…â–ˆâ–ƒâ–„â–…â–‡â–â–ƒâ–…â–„â–…â–„â–…â–…â–…â–…â–…â–„â–…â–ƒâ–…â–…â–„â–„â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77311
wandb: best/eval_avg_mil_loss 0.52332
wandb:  best/eval_ensemble_f1 0.77311
wandb:            eval/avg_f1 0.74526
wandb:      eval/avg_mil_loss 0.60674
wandb:       eval/ensemble_f1 0.74526
wandb:            test/avg_f1 0.78603
wandb:      test/avg_mil_loss 0.51093
wandb:       test/ensemble_f1 0.78603
wandb:           train/avg_f1 0.75994
wandb:      train/ensemble_f1 0.75994
wandb:         train/mil_loss 0.57885
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run different-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivvnkbod
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083057-ivvnkbod/logs
wandb: Agent Starting Run: voginadh with config:
wandb: 	actor_learning_rate: 2.608841689826192e-05
wandb: 	attention_dropout_p: 0.3707146818237003
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 143
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44407592363845183
wandb: 	temperature: 5.240057033038456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083337-voginadh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/voginadh
wandb: uploading history steps 135-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–â–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–ƒâ–…â–ˆâ–†â–†â–‡â–…â–‡â–†â–‡â–†â–‡â–…â–‡â–†â–†â–…â–†â–…â–…â–†â–…â–â–…â–‚â–†â–†â–‡â–†â–…â–„â–…â–‡â–‚â–„â–„â–†â–†
wandb:      eval/avg_mil_loss â–…â–ƒâ–‚â–„â–ƒâ–‚â–„â–â–„â–…â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‡â–‚â–ƒâ–…â–„â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–„â–…â–†â–„â–…â–‚â–‡â–‚
wandb:       eval/ensemble_f1 â–…â–‡â–ƒâ–…â–ˆâ–†â–…â–„â–„â–†â–„â–†â–…â–‡â–ˆâ–…â–†â–…â–„â–†â–„â–…â–…â–‡â–†â–„â–‡â–ƒâ–„â–â–…â–‚â–ƒâ–†â–…â–ƒâ–†â–â–â–…
wandb:           train/avg_f1 â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–‡â–„â–ˆâ–…â–„â–…â–„â–…â–„â–…â–„â–ƒâ–â–†â–ƒâ–„â–„â–‚â–„â–†â–†â–†â–ƒ
wandb:      train/ensemble_f1 â–…â–…â–‚â–†â–â–ƒâ–…â–‡â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–„â–ˆâ–‚â–„â–…â–„â–…â–…â–ƒâ–„â–„â–„â–…â–„â–…â–â–ƒâ–„â–‡â–„â–„â–‚â–ƒâ–†
wandb:         train/mil_loss â–‚â–„â–†â–ƒâ–ˆâ–„â–…â–ƒâ–†â–ƒâ–‡â–‡â–‡â–„â–„â–‡â–„â–‚â–‚â–…â–‚â–„â–ƒâ–â–†â–ƒâ–„â–„â–ˆâ–„â–†â–ƒâ–„â–„â–„â–„â–†â–â–ˆâ–ƒ
wandb:      train/policy_loss â–„â–â–„â–„â–„â–ˆâ–„â–„â–â–„â–ˆâ–â–ˆâ–„â–„â–„â–„â–„â–†â–†â–ˆâ–„â–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–ˆâ–â–ˆâ–ˆâ–„â–ˆâ–„â–„â–„â–„â–â–â–ˆâ–„â–„â–„â–„â–„â–â–„â–„â–„â–â–†â–ƒâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75145
wandb: best/eval_avg_mil_loss 0.90199
wandb:  best/eval_ensemble_f1 0.75145
wandb:            eval/avg_f1 0.62208
wandb:      eval/avg_mil_loss 0.95743
wandb:       eval/ensemble_f1 0.62208
wandb:           train/avg_f1 0.57821
wandb:      train/ensemble_f1 0.57821
wandb:         train/mil_loss 0.96339
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run jolly-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/voginadh
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083337-voginadh/logs
wandb: ERROR Run voginadh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h3bs9eqz with config:
wandb: 	actor_learning_rate: 0.00025359355038866225
wandb: 	attention_dropout_p: 0.1903798273908935
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6266042360899733
wandb: 	temperature: 1.438174648197944
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083616-h3bs9eqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h3bs9eqz
wandb: uploading history steps 90-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–ˆâ–…â–…â–†â–‚â–ƒâ–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–†â–„â–…â–â–„â–…â–„â–…â–…â–ƒâ–„â–„â–†â–„â–…â–†â–†â–…â–…â–â–…â–…â–†â–…â–‡â–†â–„â–†â–ˆâ–…â–†â–…â–‡â–‡â–‡â–„â–‡â–‡
wandb:      eval/avg_mil_loss â–ƒâ–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–†â–â–â–‡â–„â–â–â–‚
wandb:       eval/ensemble_f1 â–â–ƒâ–„â–„â–…â–„â–„â–„â–„â–…â–ƒâ–„â–…â–‚â–…â–„â–„â–…â–†â–†â–†â–†â–…â–â–…â–‡â–†â–†â–†â–„â–…â–†â–ˆâ–…â–†â–…â–‡â–‚â–„â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–‚â–ƒâ–…â–„â–„â–…â–„â–ƒâ–…â–„â–…â–†â–†â–†â–†â–†â–†â–‡â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:      train/ensemble_f1 â–â–â–‚â–â–‚â–‚â–‚â–â–„â–‚â–„â–„â–…â–„â–…â–…â–„â–„â–„â–…â–…â–†â–…â–†â–†â–‡â–…â–‡â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:         train/mil_loss â–‡â–†â–…â–†â–…â–„â–„â–†â–‡â–†â–†â–†â–†â–„â–‡â–…â–†â–…â–„â–†â–†â–„â–„â–ƒâ–ƒâ–†â–…â–â–ƒâ–ƒâ–…â–ƒâ–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–ƒâ–ˆâ–…â–ˆâ–â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ˆâ–†â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–†â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65822
wandb: best/eval_avg_mil_loss 0.72002
wandb:  best/eval_ensemble_f1 0.65822
wandb:            eval/avg_f1 0.62557
wandb:      eval/avg_mil_loss 0.76136
wandb:       eval/ensemble_f1 0.62557
wandb:            test/avg_f1 0.62047
wandb:      test/avg_mil_loss 0.60015
wandb:       test/ensemble_f1 0.62047
wandb:           train/avg_f1 0.62442
wandb:      train/ensemble_f1 0.62442
wandb:         train/mil_loss 0.76209
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run flowing-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h3bs9eqz
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083616-h3bs9eqz/logs
wandb: Agent Starting Run: 5xym1b8b with config:
wandb: 	actor_learning_rate: 1.687945720944979e-05
wandb: 	attention_dropout_p: 0.1535917488789194
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7086927834985323
wandb: 	temperature: 2.2269951977645155
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083756-5xym1b8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5xym1b8b
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–‚â–„â–ˆ
wandb:  best/eval_ensemble_f1 â–â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–ˆâ–‚â–‡â–„â–ƒâ–â–„â–„â–ˆâ–ˆâ–‡â–„â–ƒâ–â–…â–‡â–„â–‡â–ˆâ–‚â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‡â–„â–ƒâ–…â–ƒâ–„â–ˆâ–…â–ˆâ–„â–„â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–„â–„â–†â–‚â–ƒâ–†â–„â–„â–â–ƒâ–ˆâ–†â–â–ƒâ–…â–„â–ƒâ–…â–ˆâ–…â–â–ƒâ–â–ƒâ–â–â–†â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–„â–ƒâ–‡â–…â–†â–â–„
wandb:       eval/ensemble_f1 â–ˆâ–…â–„â–ˆâ–…â–‡â–…â–…â–…â–ˆâ–…â–ˆâ–ˆâ–ˆâ–…â–…â–„â–†â–…â–‡â–ˆâ–„â–…â–…â–ˆâ–…â–â–ˆâ–‡â–ˆâ–…â–…â–ˆâ–…â–…â–…â–†â–ˆâ–‡â–…
wandb:           train/avg_f1 â–…â–ƒâ–ƒâ–‚â–ˆâ–„â–â–…â–ƒâ–†â–†â–…â–ƒâ–ˆâ–…â–ƒâ–…â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–†â–„â–‡â–†â–†â–†â–…â–ƒâ–‡â–…â–„â–…â–†â–†â–‡â–ˆ
wandb:      train/ensemble_f1 â–‚â–…â–…â–„â–„â–‚â–â–‡â–ƒâ–…â–ƒâ–„â–…â–†â–„â–„â–‚â–ƒâ–†â–‡â–†â–†â–„â–…â–†â–ˆâ–…â–†â–†â–†â–†â–„â–„â–†â–…â–…â–„â–‡â–„â–‡
wandb:         train/mil_loss â–†â–ƒâ–„â–„â–†â–„â–‡â–‚â–„â–ƒâ–ƒâ–„â–…â–…â–†â–…â–‚â–…â–ƒâ–‚â–‚â–‚â–…â–‡â–…â–„â–„â–â–ƒâ–„â–ƒâ–†â–‚â–ƒâ–„â–‚â–ˆâ–„â–„â–…
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77608
wandb: best/eval_avg_mil_loss 0.87864
wandb:  best/eval_ensemble_f1 0.77608
wandb:            eval/avg_f1 0.75605
wandb:      eval/avg_mil_loss 0.84482
wandb:       eval/ensemble_f1 0.75605
wandb:           train/avg_f1 0.69936
wandb:      train/ensemble_f1 0.69936
wandb:         train/mil_loss 0.89268
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run smooth-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5xym1b8b
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083756-5xym1b8b/logs
wandb: ERROR Run 5xym1b8b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: btomoawn with config:
wandb: 	actor_learning_rate: 5.950067682296237e-06
wandb: 	attention_dropout_p: 0.3429526705718988
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3537178368163504
wandb: 	temperature: 4.254425354725129
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084000-btomoawn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btomoawn
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–ˆâ–†â–†â–â–ƒâ–„
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–ƒâ–†â–…â–‡â–‡â–…â–†â–„â–…â–„â–‡â–†â–â–‡â–†â–ˆâ–†â–‚â–ˆâ–†â–…â–‚â–„â–…â–ˆâ–‚â–‡â–…â–ƒâ–„â–â–ƒâ–†â–„â–…â–„â–‡â–‚
wandb:      eval/avg_mil_loss â–‚â–…â–‚â–â–†â–„â–„â–ƒâ–…â–†â–†â–‚â–ƒâ–†â–„â–…â–‚â–…â–‡â–†â–ƒâ–ˆâ–…â–ƒâ–†â–…â–„â–„â–†â–„â–ƒâ–ƒâ–†â–„â–ƒâ–‡â–„â–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–†â–†â–ƒâ–‚â–†â–‡â–†â–ƒâ–‡â–‡â–„â–„â–…â–‡â–„â–‚â–„â–ˆâ–„â–„â–„â–†â–‚â–‡â–ƒâ–‡â–†â–‡â–ˆâ–„â–†â–‡â–â–‚â–ˆâ–„â–…â–…â–†â–„
wandb:           train/avg_f1 â–…â–ƒâ–…â–…â–†â–…â–…â–„â–„â–†â–„â–ƒâ–…â–…â–„â–…â–‡â–†â–„â–…â–‚â–…â–…â–„â–„â–„â–…â–â–‡â–‡â–„â–‡â–ƒâ–ˆâ–…â–…â–…â–…â–‡â–…
wandb:      train/ensemble_f1 â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–â–„â–„â–ƒâ–„â–‚â–ˆâ–ƒâ–„â–„â–ƒâ–„â–„â–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–†â–„â–ƒâ–ƒâ–„â–…â–‚â–„
wandb:         train/mil_loss â–…â–…â–†â–…â–†â–ˆâ–„â–…â–ˆâ–ƒâ–‡â–„â–†â–…â–ƒâ–ƒâ–„â–†â–…â–…â–…â–†â–„â–ƒâ–†â–„â–…â–†â–†â–†â–„â–â–‚â–„â–â–ƒâ–†â–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–„â–â–„â–„â–â–„â–„â–ˆâ–†â–„â–â–„â–ˆâ–†â–ˆâ–„â–ˆâ–„â–ˆâ–â–ˆâ–„â–„â–ˆâ–„â–â–„â–â–ˆâ–â–â–„â–„â–â–„â–â–â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67067
wandb: best/eval_avg_mil_loss 0.96335
wandb:  best/eval_ensemble_f1 0.67067
wandb:            eval/avg_f1 0.4897
wandb:      eval/avg_mil_loss 1.10977
wandb:       eval/ensemble_f1 0.4897
wandb:           train/avg_f1 0.60129
wandb:      train/ensemble_f1 0.60129
wandb:         train/mil_loss 1.08171
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run cool-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btomoawn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084000-btomoawn/logs
wandb: ERROR Run btomoawn errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 40q1nin8 with config:
wandb: 	actor_learning_rate: 3.2311273413047864e-06
wandb: 	attention_dropout_p: 0.2664206604671621
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5165295454231946
wandb: 	temperature: 9.366840696462068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084327-40q1nin8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40q1nin8
wandb: uploading history steps 87-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–„â–„â–ˆâ–…â–†â–ˆâ–…â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–ƒâ–ƒâ–„â–â–†â–…â–…â–†â–…â–†â–…â–†â–‚â–†â–†â–„â–‡â–…â–„â–ƒâ–‡â–…â–†â–„â–†â–†â–…â–‡â–ƒâ–…â–…â–†â–ˆâ–…â–…â–ˆâ–‡
wandb:      eval/avg_mil_loss â–„â–…â–„â–„â–…â–ƒâ–‚â–†â–„â–ˆâ–ƒâ–…â–ƒâ–‡â–„â–ƒâ–…â–†â–„â–„â–ˆâ–…â–†â–‚â–â–‚â–„â–ƒâ–…â–…â–…â–‚â–â–„â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–…â–„â–†â–…â–‡â–‡â–†â–ƒâ–„â–„â–†â–„â–„â–…â–†â–†â–„â–„â–ƒâ–‡â–â–†â–†â–„â–‡â–ƒâ–…â–„â–†â–…â–‡â–„â–…â–ˆâ–„â–†â–‡
wandb:           train/avg_f1 â–…â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–…â–„â–†â–ƒâ–„â–ˆâ–†â–ˆâ–…â–…â–†â–‡â–†â–‡â–†â–…â–‡â–†â–…â–‡â–‡â–‡â–…â–…â–†â–„â–ˆ
wandb:      train/ensemble_f1 â–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–‚â–„â–ƒâ–…â–ƒâ–„â–†â–‡â–ˆâ–…â–‡â–ƒâ–‡â–…â–‡â–…â–†â–‡â–…â–†â–‡â–ˆâ–‡â–‡â–…â–…â–‡â–‡â–ˆ
wandb:         train/mil_loss â–…â–…â–‡â–†â–‚â–ˆâ–„â–„â–…â–†â–â–‚â–…â–â–‚â–ˆâ–ƒâ–…â–„â–‡â–„â–„â–ƒâ–‚â–†â–‚â–†â–ƒâ–ƒâ–„â–‚â–†â–„â–‚â–ƒâ–…â–‚â–‚â–„â–…
wandb:      train/policy_loss â–„â–…â–…â–…â–‡â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–â–„â–…â–…â–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73678
wandb: best/eval_avg_mil_loss 0.64969
wandb:  best/eval_ensemble_f1 0.73678
wandb:            eval/avg_f1 0.6627
wandb:      eval/avg_mil_loss 0.7464
wandb:       eval/ensemble_f1 0.6627
wandb:           train/avg_f1 0.64771
wandb:      train/ensemble_f1 0.64771
wandb:         train/mil_loss 0.93032
wandb:      train/policy_loss 0.32537
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.32537
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dazzling-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40q1nin8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084327-40q1nin8/logs
wandb: ERROR Run 40q1nin8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iudzn8sg with config:
wandb: 	actor_learning_rate: 4.07608509571466e-06
wandb: 	attention_dropout_p: 0.165503877325335
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 84
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6557377003527957
wandb: 	temperature: 3.236467066391804
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084532-iudzn8sg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iudzn8sg
wandb: uploading history steps 73-84, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–…â–‡â–â–‡â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‚â–‚â–â–„â–‚â–„â–…â–â–ƒâ–„â–‚â–ƒâ–â–„â–â–„â–„â–„â–…â–ˆâ–„â–„â–†â–ƒâ–…â–„â–…â–‡â–†â–†â–„â–„â–…â–‡â–‡â–…â–…â–„â–†â–‚
wandb:      eval/avg_mil_loss â–ˆâ–†â–‡â–‡â–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–„â–…â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ˆâ–„â–…â–„â–â–„â–†â–„â–„â–â–…â–…â–ˆâ–â–ƒâ–â–„â–„â–…
wandb:       eval/ensemble_f1 â–â–â–„â–ƒâ–„â–„â–„â–ƒâ–ƒâ–â–â–ƒâ–„â–…â–ƒâ–…â–„â–„â–†â–„â–ˆâ–…â–‡â–…â–…â–†â–…â–„â–ƒâ–ƒâ–†â–‡â–…â–…â–…â–†â–…â–…â–‡â–…
wandb:           train/avg_f1 â–„â–â–â–„â–…â–ƒâ–‚â–„â–ƒâ–…â–„â–†â–â–…â–„â–†â–†â–„â–†â–…â–…â–…â–…â–†â–„â–†â–‚â–ƒâ–†â–†â–‡â–‡â–†â–‡â–†â–‡â–†â–…â–‡â–ˆ
wandb:      train/ensemble_f1 â–„â–â–‚â–‚â–„â–„â–‚â–ƒâ–„â–„â–„â–…â–‚â–…â–„â–…â–…â–„â–†â–†â–„â–†â–…â–†â–„â–…â–†â–„â–‚â–„â–…â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆ
wandb:         train/mil_loss â–ƒâ–„â–…â–…â–…â–ƒâ–„â–„â–ƒâ–‚â–„â–†â–ˆâ–†â–…â–ƒâ–„â–ƒâ–‚â–„â–„â–„â–ƒâ–â–„â–„â–‚â–ƒâ–‚â–…â–‚â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66312
wandb: best/eval_avg_mil_loss 0.94268
wandb:  best/eval_ensemble_f1 0.66312
wandb:            eval/avg_f1 0.59394
wandb:      eval/avg_mil_loss 0.79768
wandb:       eval/ensemble_f1 0.59394
wandb:           train/avg_f1 0.62108
wandb:      train/ensemble_f1 0.62108
wandb:         train/mil_loss 1.02165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pretty-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iudzn8sg
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084532-iudzn8sg/logs
wandb: ERROR Run iudzn8sg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: j696u8pn with config:
wandb: 	actor_learning_rate: 1.3498796547995312e-05
wandb: 	attention_dropout_p: 0.2501377135291625
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2213403557494229
wandb: 	temperature: 0.8378854319354634
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084705-j696u8pn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j696u8pn
wandb: uploading history steps 176-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–…â–†â–†â–†â–†â–†â–†â–ˆâ–…â–…â–„â–‚â–„â–„â–‚â–â–‚â–
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–„â–„â–†â–„â–ƒâ–…â–„â–…â–ƒâ–…â–…â–ƒâ–†â–‡â–ƒâ–ƒâ–†â–†â–…â–â–„â–†â–‡â–…â–‡â–‡â–†â–„â–‡â–ˆâ–ˆâ–‡â–†â–‡â–‡â–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–…â–ƒâ–†â–…â–ƒâ–†â–„â–…â–ˆâ–ƒâ–‚â–…â–‡â–„â–†â–†â–ƒâ–„â–ƒâ–…â–‚â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–„â–ƒâ–„â–â–ƒâ–ƒâ–â–„â–‚â–…â–‚â–‚
wandb:       eval/ensemble_f1 â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–…â–„â–‚â–…â–„â–„â–„â–‚â–‚â–‡â–ƒâ–†â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–„â–‡â–‡â–…â–ƒâ–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–„â–„â–„â–…â–„â–ƒâ–„â–„â–„â–…â–…â–†â–†â–…â–‡â–‡â–†â–†â–‡â–†â–…â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:      train/ensemble_f1 â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–„â–†â–…â–…â–…â–„â–…â–„â–„â–†â–†â–†â–‡â–†â–…â–‡â–‡â–†â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡
wandb:         train/mil_loss â–†â–‡â–…â–‡â–†â–…â–„â–…â–ˆâ–„â–„â–…â–†â–…â–ˆâ–…â–…â–†â–„â–…â–„â–„â–†â–…â–„â–â–ƒâ–ƒâ–„â–‚â–„â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–ƒâ–ƒ
wandb:      train/policy_loss â–…â–…â–†â–ƒâ–†â–†â–†â–†â–†â–â–…â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–…â–†â–†â–ƒâ–ˆâ–†â–†â–†â–†â–†â–†â–„â–…â–†â–†â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–„â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72558
wandb: best/eval_avg_mil_loss 0.65413
wandb:  best/eval_ensemble_f1 0.72558
wandb:            eval/avg_f1 0.54209
wandb:      eval/avg_mil_loss 0.87637
wandb:       eval/ensemble_f1 0.54209
wandb:            test/avg_f1 0.70652
wandb:      test/avg_mil_loss 0.47283
wandb:       test/ensemble_f1 0.70652
wandb:           train/avg_f1 0.66689
wandb:      train/ensemble_f1 0.66689
wandb:         train/mil_loss 0.66777
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j696u8pn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084705-j696u8pn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6rfysf7f with config:
wandb: 	actor_learning_rate: 9.031360147312014e-05
wandb: 	attention_dropout_p: 0.372825622572535
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9433697907810052
wandb: 	temperature: 9.064383942850029
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085032-6rfysf7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6rfysf7f
wandb: uploading wandb-summary.json
wandb: uploading history steps 185-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–„â–‡â–â–ˆâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–†â–†â–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–ƒâ–…â–„â–ˆâ–ƒâ–ƒâ–„â–â–ˆâ–…â–ˆâ–†â–…â–„â–…â–ˆâ–„â–„â–…â–„â–„â–„â–…â–…â–…â–…â–â–†â–ˆâ–…â–…â–„â–†â–ˆâ–…â–…â–„â–„â–…
wandb:      eval/avg_mil_loss â–‚â–ƒâ–‚â–‡â–†â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–…â–ƒâ–‚â–„â–…â–„â–‚â–‚â–‚â–…â–„â–„â–…â–‡â–†â–„â–ƒâ–ˆâ–ƒâ–â–‚â–…â–‚â–„â–†â–„
wandb:       eval/ensemble_f1 â–†â–…â–„â–„â–‚â–…â–…â–…â–„â–„â–ˆâ–…â–…â–â–ƒâ–…â–†â–ˆâ–„â–‚â–…â–„â–…â–†â–…â–…â–„â–ˆâ–…â–…â–†â–„â–ƒâ–…â–„â–…â–„â–ˆâ–„â–„
wandb:           train/avg_f1 â–â–â–‚â–‡â–â–ƒâ–…â–…â–„â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–„â–„â–„â–…â–„â–ƒâ–„â–„â–ƒâ–†â–„â–…â–…â–ƒâ–ˆâ–ƒâ–†â–„â–…â–…â–‡â–…â–…â–ƒ
wandb:      train/ensemble_f1 â–…â–ƒâ–â–‡â–â–„â–‡â–„â–…â–†â–‚â–ƒâ–‡â–…â–…â–ƒâ–†â–†â–„â–…â–†â–…â–…â–†â–â–†â–ƒâ–…â–ƒâ–…â–…â–†â–…â–†â–…â–‡â–ˆâ–‡â–†â–ˆ
wandb:         train/mil_loss â–…â–‡â–…â–ƒâ–†â–…â–‚â–‚â–…â–†â–ƒâ–†â–…â–ƒâ–„â–…â–‚â–ˆâ–„â–…â–ˆâ–„â–…â–ƒâ–‡â–†â–ƒâ–‡â–„â–„â–‚â–ƒâ–‚â–‚â–‚â–â–â–‡â–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82725
wandb: best/eval_avg_mil_loss 0.86676
wandb:  best/eval_ensemble_f1 0.82725
wandb:            eval/avg_f1 0.53836
wandb:      eval/avg_mil_loss 1.0071
wandb:       eval/ensemble_f1 0.53836
wandb:           train/avg_f1 0.68361
wandb:      train/ensemble_f1 0.68361
wandb:         train/mil_loss 0.98745
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run solar-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6rfysf7f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085032-6rfysf7f/logs
wandb: ERROR Run 6rfysf7f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: nl84rp0w with config:
wandb: 	actor_learning_rate: 3.1104351295398443e-06
wandb: 	attention_dropout_p: 0.032939212659177985
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 115
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.49149599751849526
wandb: 	temperature: 8.234518073273788
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085408-nl84rp0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nl84rp0w
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–…â–…â–…â–…â–ˆâ–…â–„â–„â–†â–„â–…â–…â–…â–†â–…â–…â–†â–…â–…â–…â–â–…â–…â–…â–â–†â–‡â–†â–…â–†â–ˆâ–…â–„â–‡â–…â–…â–†
wandb:      eval/avg_mil_loss â–„â–…â–…â–†â–ˆâ–…â–„â–ƒâ–ƒâ–‡â–†â–‚â–ƒâ–ƒâ–ƒâ–‚â–‡â–‚â–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–†â–ƒâ–„â–‚â–„â–ƒâ–â–‚â–â–„â–ƒâ–‚â–…â–„
wandb:       eval/ensemble_f1 â–„â–„â–…â–„â–‚â–…â–„â–…â–…â–…â–…â–…â–…â–ƒâ–â–„â–…â–…â–†â–…â–…â–…â–„â–…â–„â–„â–…â–„â–‚â–…â–‡â–…â–…â–…â–„â–ˆâ–†â–„â–…â–…
wandb:           train/avg_f1 â–„â–‚â–„â–‡â–ƒâ–…â–â–†â–‚â–…â–„â–…â–„â–„â–†â–ƒâ–†â–ƒâ–â–…â–‡â–…â–ˆâ–‡â–‡â–†â–†â–…â–‡â–†â–ƒâ–†â–…â–„â–†â–ˆâ–‡â–„â–…â–†
wandb:      train/ensemble_f1 â–„â–…â–‚â–ƒâ–â–…â–‚â–„â–‚â–†â–„â–„â–ƒâ–‡â–†â–‚â–…â–…â–‚â–„â–ˆâ–„â–„â–†â–â–„â–†â–‡â–‚â–†â–‡â–ƒâ–‡â–…â–…â–‡â–†â–„â–ƒâ–…
wandb:         train/mil_loss â–ƒâ–…â–„â–ƒâ–„â–ƒâ–…â–†â–ˆâ–ˆâ–…â–…â–ƒâ–ƒâ–„â–„â–†â–„â–ƒâ–‚â–„â–…â–…â–‚â–„â–„â–„â–…â–‚â–†â–†â–„â–ƒâ–…â–â–â–„â–ƒâ–…â–„
wandb:      train/policy_loss â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–„â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79614
wandb: best/eval_avg_mil_loss 1.00426
wandb:  best/eval_ensemble_f1 0.79614
wandb:            eval/avg_f1 0.59688
wandb:      eval/avg_mil_loss 1.12662
wandb:       eval/ensemble_f1 0.59688
wandb:           train/avg_f1 0.61451
wandb:      train/ensemble_f1 0.61451
wandb:         train/mil_loss 1.00328
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run iconic-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nl84rp0w
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085408-nl84rp0w/logs
wandb: ERROR Run nl84rp0w errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 7rjn2rao with config:
wandb: 	actor_learning_rate: 1.4479263503872402e-06
wandb: 	attention_dropout_p: 0.22688396282913015
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9086383774597472
wandb: 	temperature: 8.45921366803799
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085618-7rjn2rao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rjn2rao
wandb: uploading wandb-summary.json
wandb: uploading history steps 102-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–ƒâ–„â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–ƒâ–‚â–‡â–‡â–‡â–ƒâ–„â–„â–„â–â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–â–…â–†â–„â–†â–„â–ƒâ–ƒâ–„â–ˆâ–ƒâ–„â–„â–†â–„â–â–ƒâ–…â–‡â–…â–…â–„
wandb:      eval/avg_mil_loss â–ˆâ–ƒâ–…â–…â–„â–â–„â–…â–‡â–ƒâ–…â–†â–„â–…â–‡â–ˆâ–†â–…â–‡â–†â–…â–„â–ƒâ–…â–†â–ƒâ–‡â–‡â–ƒâ–ƒâ–…â–ˆâ–ƒâ–‡â–†â–„â–„â–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–…â–„â–ƒâ–„â–ƒâ–„â–„â–ˆâ–„â–…â–ˆâ–„â–…â–â–ƒâ–†â–†â–â–â–„â–ƒâ–†â–„â–„â–„â–„â–‚â–ˆâ–ƒâ–„â–…â–‡â–…â–ƒâ–…â–‡â–…â–ˆâ–ˆâ–…
wandb:           train/avg_f1 â–â–‚â–„â–‚â–ƒâ–‚â–ƒâ–†â–„â–†â–ˆâ–ƒâ–â–ƒâ–…â–ƒâ–‡â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–†â–†â–…â–ƒâ–…â–†â–…
wandb:      train/ensemble_f1 â–‚â–…â–‚â–…â–ˆâ–…â–„â–„â–†â–†â–„â–ƒâ–„â–‡â–â–‡â–†â–‚â–‚â–†â–†â–†â–ƒâ–‡â–„â–‚â–…â–…â–…â–…â–ˆâ–ƒâ–†â–…â–ƒâ–…â–‡â–†â–…â–†
wandb:         train/mil_loss â–†â–‡â–…â–†â–…â–‡â–ƒâ–…â–…â–„â–†â–„â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–†â–„â–…â–‡â–†â–ƒâ–†â–†â–„â–‡â–…â–…â–„â–„â–…â–â–…â–ƒâ–…â–…â–„â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80554
wandb: best/eval_avg_mil_loss 0.94375
wandb:  best/eval_ensemble_f1 0.80554
wandb:            eval/avg_f1 0.56188
wandb:      eval/avg_mil_loss 0.91036
wandb:       eval/ensemble_f1 0.56188
wandb:           train/avg_f1 0.58906
wandb:      train/ensemble_f1 0.58906
wandb:         train/mil_loss 1.12393
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rjn2rao
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085618-7rjn2rao/logs
wandb: ERROR Run 7rjn2rao errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: wo9nzot2 with config:
wandb: 	actor_learning_rate: 2.0414310739394768e-05
wandb: 	attention_dropout_p: 0.02157157893353079
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5227326969444275
wandb: 	temperature: 9.786288770051469
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085822-wo9nzot2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo9nzot2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ˆâ–„â–„â–‚â–‚â–…â–…â–„â–â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–…â–ƒâ–…â–…â–„â–„â–‡â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–…â–†â–…
wandb:      eval/avg_mil_loss â–…â–‡â–ƒâ–ƒâ–†â–†â–‚â–„â–†â–†â–†â–…â–…â–„â–ˆâ–„â–ƒâ–„â–ƒâ–‡â–‚â–„â–‡â–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…â–â–†â–ƒâ–‚â–†â–„â–„â–‡â–„
wandb:       eval/ensemble_f1 â–„â–„â–‚â–ˆâ–„â–„â–„â–ƒâ–…â–„â–„â–â–â–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–„â–„â–…â–„â–„â–…â–„â–…â–„â–…â–…â–„â–…â–ˆâ–„â–‚
wandb:           train/avg_f1 â–„â–â–‚â–ƒâ–„â–‚â–â–„â–ƒâ–…â–†â–‚â–ƒâ–‚â–†â–‚â–ƒâ–„â–‚â–ƒâ–…â–‡â–„â–†â–„â–„â–†â–†â–ƒâ–†â–†â–†â–…â–„â–†â–ˆâ–„â–†â–…â–…
wandb:      train/ensemble_f1 â–â–„â–ƒâ–ƒâ–…â–ˆâ–ƒâ–…â–‚â–…â–†â–ƒâ–‚â–…â–‚â–„â–†â–„â–„â–„â–‡â–„â–…â–†â–‡â–‡â–„â–…â–†â–‡â–†â–…â–†â–†â–†â–„â–†â–†â–ˆâ–„
wandb:         train/mil_loss â–…â–„â–…â–†â–ƒâ–†â–„â–ˆâ–ƒâ–ƒâ–‚â–…â–†â–…â–‡â–‚â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–…â–„â–…â–â–„â–ƒâ–ƒâ–â–„â–‚â–ƒâ–‚â–‚â–
wandb:      train/policy_loss â–…â–…â–â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–ˆâ–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75605
wandb: best/eval_avg_mil_loss 0.99997
wandb:  best/eval_ensemble_f1 0.75605
wandb:            eval/avg_f1 0.6284
wandb:      eval/avg_mil_loss 0.91903
wandb:       eval/ensemble_f1 0.6284
wandb:           train/avg_f1 0.57099
wandb:      train/ensemble_f1 0.57099
wandb:         train/mil_loss 0.92503
wandb:      train/policy_loss -0.41591
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.41591
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bright-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo9nzot2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085822-wo9nzot2/logs
wandb: ERROR Run wo9nzot2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ifk43s6g with config:
wandb: 	actor_learning_rate: 1.7170542624251165e-06
wandb: 	attention_dropout_p: 0.23364925299614725
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8015852998950692
wandb: 	temperature: 7.955316967838675
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090031-ifk43s6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ifk43s6g
wandb: uploading history steps 134-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–‡â–…â–…â–†â–ˆâ–ˆâ–‡â–…â–†â–…â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–â–„â–„â–ƒâ–„â–‚â–ƒâ–†â–„â–‚â–…â–‚â–…â–…â–„â–†â–…â–„â–‚â–†â–…â–†â–‡â–…â–‚â–…â–†â–‡â–†â–…â–ˆâ–„â–‡â–‡
wandb:      eval/avg_mil_loss â–„â–†â–„â–…â–…â–„â–…â–„â–…â–„â–†â–„â–…â–„â–…â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–„â–…â–â–ˆâ–…â–â–…â–…â–â–‚â–‚â–‚â–„
wandb:       eval/ensemble_f1 â–‚â–â–ƒâ–â–‚â–ƒâ–‚â–‚â–â–„â–…â–‡â–„â–„â–…â–„â–„â–„â–…â–…â–‚â–ƒâ–…â–ƒâ–„â–‡â–†â–†â–„â–„â–‡â–ƒâ–„â–„â–‡â–„â–…â–ˆâ–‡â–…
wandb:           train/avg_f1 â–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–„â–…â–„â–…â–…â–…â–†â–…â–„â–‡â–†â–‡â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆ
wandb:      train/ensemble_f1 â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–‡â–†â–‡â–†â–…â–ˆâ–†â–†â–‡â–ˆâ–†â–‡â–†â–†
wandb:         train/mil_loss â–ˆâ–†â–…â–‡â–…â–„â–†â–†â–„â–†â–…â–…â–†â–†â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–†â–„â–ƒâ–…â–…â–ƒâ–…â–‚â–ƒâ–‚â–ƒâ–„â–â–â–‚
wandb:      train/policy_loss â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–…â–‡â–‚â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–†â–‡â–ƒâ–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76405
wandb: best/eval_avg_mil_loss 0.53032
wandb:  best/eval_ensemble_f1 0.76405
wandb:            eval/avg_f1 0.72463
wandb:      eval/avg_mil_loss 0.77653
wandb:       eval/ensemble_f1 0.72463
wandb:           train/avg_f1 0.69478
wandb:      train/ensemble_f1 0.69478
wandb:         train/mil_loss 0.6928
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run winter-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ifk43s6g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090031-ifk43s6g/logs
wandb: ERROR Run ifk43s6g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: dz9zblr4 with config:
wandb: 	actor_learning_rate: 1.705641738954369e-05
wandb: 	attention_dropout_p: 0.3554232788875363
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1893940382156396
wandb: 	temperature: 0.8884301980831999
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090332-dz9zblr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dz9zblr4
wandb: uploading history steps 101-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–†â–†â–…â–ƒâ–ˆâ–â–„â–â–ƒâ–‚â–…â–„â–…â–„â–‚â–„â–…â–…â–ˆâ–„â–â–…â–…â–…â–„â–‚â–ƒâ–…â–ƒâ–„â–†â–„â–„â–ˆâ–â–…â–…â–‚â–†
wandb:      eval/avg_mil_loss â–‚â–ˆâ–†â–„â–…â–„â–…â–ƒâ–ƒâ–…â–‚â–†â–ƒâ–‚â–„â–‡â–‡â–†â–…â–„â–†â–„â–†â–ƒâ–ƒâ–„â–„â–ƒâ–…â–…â–„â–†â–ˆâ–…â–â–‚â–…â–†â–‡â–…
wandb:       eval/ensemble_f1 â–„â–‡â–†â–„â–…â–ƒâ–‡â–â–ƒâ–‚â–‚â–ƒâ–„â–†â–„â–†â–‚â–„â–ƒâ–…â–‚â–…â–‚â–…â–ƒâ–„â–ƒâ–‚â–‡â–…â–ˆâ–…â–„â–†â–‡â–…â–…â–‚â–„â–„
wandb:           train/avg_f1 â–ƒâ–ƒâ–â–â–†â–‚â–…â–ƒâ–…â–…â–‚â–…â–‚â–„â–„â–†â–„â–‚â–…â–†â–†â–…â–†â–…â–…â–„â–‡â–†â–…â–…â–„â–„â–„â–„â–„â–†â–…â–†â–ˆâ–†
wandb:      train/ensemble_f1 â–â–â–ƒâ–„â–â–„â–†â–„â–ƒâ–…â–…â–†â–„â–…â–ƒâ–…â–…â–ƒâ–ƒâ–…â–…â–…â–†â–†â–…â–…â–‡â–†â–…â–†â–†â–„â–„â–…â–‡â–†â–…â–†â–†â–ˆ
wandb:         train/mil_loss â–…â–…â–…â–„â–„â–ˆâ–ƒâ–„â–†â–…â–…â–…â–ƒâ–…â–…â–„â–„â–„â–„â–„â–…â–‡â–„â–…â–†â–†â–…â–„â–‚â–†â–„â–„â–…â–ƒâ–„â–â–„â–„â–…â–„
wandb:      train/policy_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–ˆâ–„â–„â–„â–„â–„â–‡â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75694
wandb: best/eval_avg_mil_loss 0.75726
wandb:  best/eval_ensemble_f1 0.75694
wandb:            eval/avg_f1 0.66839
wandb:      eval/avg_mil_loss 1.03662
wandb:       eval/ensemble_f1 0.66839
wandb:           train/avg_f1 0.61744
wandb:      train/ensemble_f1 0.61744
wandb:         train/mil_loss 1.09157
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run jumping-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dz9zblr4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090332-dz9zblr4/logs
wandb: ERROR Run dz9zblr4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l3cf4qmj with config:
wandb: 	actor_learning_rate: 4.160424117553572e-05
wandb: 	attention_dropout_p: 0.184600104595599
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4965432423211979
wandb: 	temperature: 5.890881253075287
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090526-l3cf4qmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l3cf4qmj
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 114-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‡â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–…â–ˆâ–â–…â–…â–ˆâ–…â–…â–‚â–…â–…â–†â–…â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–‡
wandb:      eval/avg_mil_loss â–…â–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–„â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–â–ƒâ–ˆâ–…â–‡â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:       eval/ensemble_f1 â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–‡â–‚â–…â–„â–…â–‚â–…â–…â–…â–…â–„â–„â–…â–ˆâ–†â–…â–…â–â–…â–†â–…â–…â–…â–…â–â–…â–‡â–…â–…â–â–…
wandb:           train/avg_f1 â–ƒâ–„â–‚â–„â–ƒâ–â–„â–ƒâ–„â–†â–…â–„â–ƒâ–„â–…â–„â–ƒâ–„â–†â–…â–…â–„â–ˆâ–†â–‡â–…â–…â–…â–„â–…â–‡â–†â–…â–†â–…â–‡â–ˆâ–‡â–‡â–‡
wandb:      train/ensemble_f1 â–‚â–ƒâ–‚â–„â–â–ƒâ–…â–â–ƒâ–…â–…â–‚â–…â–„â–†â–‚â–…â–„â–ƒâ–ƒâ–„â–…â–‡â–†â–…â–„â–„â–…â–…â–…â–…â–‡â–…â–†â–‡â–ˆâ–‡â–‡â–†â–‡
wandb:         train/mil_loss â–…â–ƒâ–„â–ƒâ–„â–„â–…â–„â–†â–„â–ƒâ–…â–„â–ƒâ–†â–„â–ˆâ–‚â–‚â–…â–†â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–â–‡â–‚â–†â–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77068
wandb: best/eval_avg_mil_loss 0.67331
wandb:  best/eval_ensemble_f1 0.77068
wandb:            eval/avg_f1 0.58921
wandb:      eval/avg_mil_loss 1.03931
wandb:       eval/ensemble_f1 0.58921
wandb:           train/avg_f1 0.62443
wandb:      train/ensemble_f1 0.62443
wandb:         train/mil_loss 0.70235
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glad-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l3cf4qmj
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090526-l3cf4qmj/logs
wandb: ERROR Run l3cf4qmj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: lwhrhy54 with config:
wandb: 	actor_learning_rate: 2.541895063211129e-06
wandb: 	attention_dropout_p: 0.12973794545440714
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34766716266856434
wandb: 	temperature: 6.22383609100563
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090745-lwhrhy54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lwhrhy54
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–„â–ƒâ–â–†â–‚
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–…â–‡â–â–‚â–…â–â–ˆâ–„â–â–ˆâ–‚â–†â–‚â–‚â–‡â–â–‚â–…â–ˆâ–â–„â–ˆâ–‚â–†â–‚â–â–‚â–â–‚â–â–â–â–‚â–ˆâ–„â–„â–â–ƒâ–‚
wandb:      eval/avg_mil_loss â–‡â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–…â–†â–…â–†â–ˆâ–‡â–‡â–…â–„â–„â–†â–ƒâ–…â–ƒâ–†â–…â–ˆâ–…â–…â–„â–â–…â–…â–†â–…â–ƒâ–ƒâ–…â–„â–ƒâ–„â–…â–…
wandb:       eval/ensemble_f1 â–ƒâ–…â–‚â–„â–â–â–‡â–‚â–ˆâ–„â–â–…â–â–‚â–ˆâ–â–ˆâ–‡â–‚â–ˆâ–ƒâ–ƒâ–†â–‚â–‚â–‚â–â–â–„â–ˆâ–‚â–â–„â–‚â–â–â–â–‚â–ƒâ–‚
wandb:           train/avg_f1 â–‡â–†â–ƒâ–„â–„â–„â–ˆâ–‚â–…â–‡â–‚â–…â–â–ƒâ–‡â–ƒâ–„â–‡â–‚â–„â–…â–„â–…â–„â–‚â–†â–ˆâ–†â–†â–†â–…â–†â–ƒâ–†â–†â–ƒâ–‚â–„â–ƒâ–…
wandb:      train/ensemble_f1 â–…â–ƒâ–…â–…â–ˆâ–†â–‚â–†â–„â–‡â–†â–…â–ƒâ–ƒâ–ƒâ–â–‡â–…â–ƒâ–†â–„â–†â–…â–†â–ƒâ–ƒâ–†â–„â–„â–„â–„â–…â–†â–…â–„â–ƒâ–„â–ƒâ–†â–…
wandb:         train/mil_loss â–…â–†â–ƒâ–ƒâ–†â–„â–ƒâ–„â–ƒâ–„â–…â–„â–†â–…â–„â–ƒâ–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–†â–„â–†â–‚â–‚â–ˆâ–â–…â–â–ƒâ–„â–â–ƒâ–‚â–„â–‚â–ƒâ–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80719
wandb: best/eval_avg_mil_loss 0.69766
wandb:  best/eval_ensemble_f1 0.80719
wandb:            eval/avg_f1 0.61913
wandb:      eval/avg_mil_loss 1.01995
wandb:       eval/ensemble_f1 0.61913
wandb:           train/avg_f1 0.58896
wandb:      train/ensemble_f1 0.58896
wandb:         train/mil_loss 1.06468
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run kind-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lwhrhy54
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090745-lwhrhy54/logs
wandb: ERROR Run lwhrhy54 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7abdu3ou with config:
wandb: 	actor_learning_rate: 9.77230538810012e-06
wandb: 	attention_dropout_p: 0.031168693209303155
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.040595618177793336
wandb: 	temperature: 6.998742318498177
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091047-7abdu3ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7abdu3ou
wandb: uploading wandb-summary.json
wandb: uploading history steps 85-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–ˆâ–…â–„â–†â–„â–…â–…â–…â–‡â–…â–…â–…â–ˆâ–…â–…â–†â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–„â–‡â–…â–…â–â–…â–…â–…â–…â–…â–…â–†â–ˆâ–…
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–„â–ƒâ–…â–…â–†â–‚â–ˆâ–ƒâ–‚â–„â–†â–„â–ƒâ–‚â–…â–‚â–ƒâ–‚â–ƒâ–„â–â–‚â–‚â–ƒâ–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–ƒâ–…â–„â–…â–…â–„â–„â–„â–…â–‡â–…â–…â–‡â–…â–„â–…â–…â–…â–„â–…â–†â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–…â–â–…â–‡â–„â–†â–…â–…
wandb:           train/avg_f1 â–ƒâ–…â–„â–†â–„â–ˆâ–„â–„â–„â–„â–„â–ƒâ–†â–†â–ƒâ–ˆâ–…â–†â–†â–ƒâ–†â–†â–†â–ƒâ–…â–„â–‡â–…â–†â–‚â–†â–…â–‡â–â–…â–†â–‡â–…â–„â–…
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–„â–ƒâ–„â–â–‡â–…â–„â–â–…â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–‡â–„â–„â–†â–†â–‡â–„â–„â–…â–ƒâ–…â–ˆâ–„â–„â–†â–†â–†â–…â–†â–…â–‡â–ƒâ–†
wandb:         train/mil_loss â–…â–…â–†â–…â–†â–†â–ˆâ–…â–†â–‡â–…â–‡â–„â–…â–…â–…â–…â–„â–‚â–‡â–‡â–„â–‡â–‚â–„â–†â–‚â–„â–ƒâ–…â–‡â–†â–‚â–ƒâ–†â–ƒâ–…â–†â–…â–
wandb:      train/policy_loss â–„â–„â–„â–„â–â–„â–„â–„â–„â–ˆâ–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‚â–„â–„â–„â–â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7712
wandb: best/eval_avg_mil_loss 0.99623
wandb:  best/eval_ensemble_f1 0.7712
wandb:            eval/avg_f1 0.55745
wandb:      eval/avg_mil_loss 0.891
wandb:       eval/ensemble_f1 0.55745
wandb:           train/avg_f1 0.59491
wandb:      train/ensemble_f1 0.59491
wandb:         train/mil_loss 0.71292
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vague-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7abdu3ou
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091047-7abdu3ou/logs
wandb: ERROR Run 7abdu3ou errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: gbut464q with config:
wandb: 	actor_learning_rate: 4.523196057174809e-06
wandb: 	attention_dropout_p: 0.4447634124719856
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7808055828251474
wandb: 	temperature: 7.496158829616808
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091225-gbut464q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbut464q
wandb: uploading history steps 100-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–„â–ƒâ–†â–‡â–„â–„â–„â–‚â–†â–ƒâ–‡â–ˆâ–†â–â–†â–„â–ƒâ–ƒâ–…â–…â–„â–†â–ƒâ–ƒâ–†â–‚â–…â–…â–‚â–ƒâ–†â–„â–„â–†â–ƒâ–†â–ƒâ–‚
wandb:      eval/avg_mil_loss â–ƒâ–…â–…â–„â–â–‚â–…â–ˆâ–ˆâ–„â–ˆâ–„â–†â–„â–‚â–„â–ƒâ–‡â–ƒâ–ƒâ–„â–„â–â–‡â–…â–ƒâ–ƒâ–‚â–ƒâ–†â–…â–â–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–
wandb:       eval/ensemble_f1 â–„â–„â–ƒâ–„â–…â–†â–‚â–…â–‡â–…â–†â–â–ˆâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–â–‡â–†â–„â–†â–ˆâ–ƒâ–…â–„â–‡â–„â–…â–„â–ƒâ–„â–ƒâ–ƒâ–ˆâ–†â–„â–…
wandb:           train/avg_f1 â–„â–‚â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ˆâ–…â–ƒâ–†â–…â–…â–„â–…â–â–ƒâ–„â–…â–„â–‚â–‡â–â–…â–„â–†â–†â–â–‚â–…â–„â–†â–…â–„â–‡â–…â–†
wandb:      train/ensemble_f1 â–„â–â–ƒâ–…â–ƒâ–ƒâ–ˆâ–„â–„â–†â–‚â–„â–„â–‚â–ƒâ–‚â–…â–â–„â–„â–…â–ƒâ–…â–ƒâ–…â–â–…â–„â–ƒâ–†â–„â–…â–†â–ƒâ–†â–†â–„â–…â–…â–„
wandb:         train/mil_loss â–„â–…â–†â–„â–†â–„â–ƒâ–„â–„â–†â–ƒâ–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–…â–…â–‚â–†â–ƒâ–ƒâ–„â–ˆâ–…â–„â–†â–„â–„â–â–†â–„â–„â–„â–‡â–…â–ƒ
wandb:      train/policy_loss â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ˆâ–ˆâ–„â–„â–„â–‡â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–‚
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7637
wandb: best/eval_avg_mil_loss 0.85752
wandb:  best/eval_ensemble_f1 0.7637
wandb:            eval/avg_f1 0.53133
wandb:      eval/avg_mil_loss 0.84769
wandb:       eval/ensemble_f1 0.53133
wandb:           train/avg_f1 0.60011
wandb:      train/ensemble_f1 0.60011
wandb:         train/mil_loss 0.95123
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run drawn-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbut464q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091225-gbut464q/logs
wandb: ERROR Run gbut464q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: udhii7if with config:
wandb: 	actor_learning_rate: 5.640209138728446e-06
wandb: 	attention_dropout_p: 0.013521188686490436
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03729968270343376
wandb: 	temperature: 8.725353228522476
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091419-udhii7if
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/udhii7if
wandb: uploading history steps 128-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–†â–ˆâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–‡â–â–‡â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–†â–†â–†â–ƒâ–ƒâ–‡â–ˆâ–…â–…â–‡â–…â–„â–‚â–†â–†â–†â–…â–ˆâ–†â–‡â–†â–ˆâ–†â–ˆâ–‡
wandb:      eval/avg_mil_loss â–„â–ƒâ–…â–ˆâ–†â–…â–…â–†â–…â–‡â–…â–†â–‡â–†â–…â–„â–†â–„â–ƒâ–„â–„â–„â–â–„â–…â–ƒâ–†â–ƒâ–…â–†â–‚â–ƒâ–…â–ƒâ–†â–„â–ˆâ–…â–ƒâ–†
wandb:       eval/ensemble_f1 â–ƒâ–…â–ˆâ–…â–â–†â–†â–‚â–â–ˆâ–‡â–…â–†â–ˆâ–…â–ƒâ–‡â–‡â–ˆâ–…â–ˆâ–„â–‡â–„â–„â–†â–†â–†â–‡â–†â–†â–…â–ˆâ–„â–…â–†â–†â–†â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–„â–…â–…â–‚â–†â–â–ƒâ–â–„â–ƒâ–†â–„â–‚â–…â–„â–…â–†â–…â–ƒâ–…â–‡â–†â–ƒâ–„â–…â–„â–ƒâ–…â–†â–†â–‡â–‡â–…â–…â–‡â–ˆâ–‡â–ˆâ–†
wandb:      train/ensemble_f1 â–†â–â–„â–…â–‚â–â–…â–†â–„â–â–…â–†â–…â–ƒâ–„â–†â–„â–„â–ƒâ–†â–…â–†â–„â–ƒâ–…â–†â–†â–ƒâ–…â–…â–†â–‡â–†â–†â–‡â–ˆâ–‡â–ˆâ–†â–…
wandb:         train/mil_loss â–…â–…â–ˆâ–…â–†â–†â–ˆâ–…â–†â–ƒâ–„â–†â–„â–â–†â–ƒâ–…â–†â–ƒâ–ƒâ–†â–ƒâ–…â–„â–‚â–†â–„â–‡â–†â–†â–…â–ƒâ–„â–‚â–…â–â–ƒâ–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–â–ˆâ–â–ˆâ–â–…â–ˆâ–…â–ˆâ–â–…â–â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–â–…â–â–…â–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77859
wandb: best/eval_avg_mil_loss 0.83344
wandb:  best/eval_ensemble_f1 0.77859
wandb:            eval/avg_f1 0.73751
wandb:      eval/avg_mil_loss 1.02147
wandb:       eval/ensemble_f1 0.73751
wandb:            test/avg_f1 0.71205
wandb:      test/avg_mil_loss 0.54379
wandb:       test/ensemble_f1 0.71205
wandb:           train/avg_f1 0.70162
wandb:      train/ensemble_f1 0.70162
wandb:         train/mil_loss 0.98013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/udhii7if
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091419-udhii7if/logs
wandb: Agent Starting Run: z7sjuue6 with config:
wandb: 	actor_learning_rate: 3.903093400542032e-06
wandb: 	attention_dropout_p: 0.3052354570563609
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 94
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47772072931121745
wandb: 	temperature: 5.8052266660922305
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091650-z7sjuue6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z7sjuue6
wandb: uploading history steps 85-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–…â–…â–…â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ƒâ–…â–„â–…â–ˆâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–…â–…â–…â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–†â–…â–…â–„â–‡â–…â–…â–‡â–„â–…â–‡â–†â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–†â–†â–…â–…â–†â–†â–†â–…â–‡â–†â–ˆâ–†â–…â–‡â–†â–ˆâ–†â–ˆ
wandb:      eval/avg_mil_loss â–‚â–…â–‡â–ƒâ–…â–„â–„â–†â–…â–‡â–†â–…â–…â–ƒâ–ƒâ–„â–ˆâ–…â–„â–†â–„â–…â–ƒâ–‚â–„â–‡â–â–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–„â–‚â–‚â–‚â–„â–
wandb:       eval/ensemble_f1 â–…â–â–…â–…â–…â–…â–…â–…â–‡â–…â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–…â–†â–†â–…â–‡â–…â–‡â–†â–†â–†â–„â–†â–†â–‡â–ˆâ–‡â–‡â–†â–†â–†â–ˆ
wandb:           train/avg_f1 â–„â–ƒâ–â–„â–‚â–…â–ƒâ–„â–…â–…â–„â–…â–…â–„â–…â–…â–ƒâ–†â–†â–†â–†â–†â–„â–ƒâ–…â–„â–„â–‡â–…â–…â–…â–…â–‡â–‡â–ˆâ–†â–ˆâ–†â–‡â–ˆ
wandb:      train/ensemble_f1 â–‚â–‚â–â–â–â–„â–â–‚â–„â–ƒâ–ƒâ–…â–„â–„â–„â–…â–…â–…â–…â–…â–…â–ƒâ–†â–†â–‡â–„â–…â–„â–†â–†â–†â–‡â–‡â–†â–†â–†â–ˆâ–„â–†â–ˆ
wandb:         train/mil_loss â–…â–ˆâ–‡â–‡â–†â–‡â–„â–ˆâ–†â–…â–ƒâ–‡â–‡â–ˆâ–†â–‡â–‚â–„â–‡â–ƒâ–…â–†â–…â–„â–‚â–‡â–ˆâ–…â–â–…â–…â–‚â–„â–†â–…â–â–„â–…â–…â–„
wandb:      train/policy_loss â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74006
wandb: best/eval_avg_mil_loss 0.5823
wandb:  best/eval_ensemble_f1 0.74006
wandb:            eval/avg_f1 0.7328
wandb:      eval/avg_mil_loss 0.62311
wandb:       eval/ensemble_f1 0.7328
wandb:           train/avg_f1 0.66481
wandb:      train/ensemble_f1 0.66481
wandb:         train/mil_loss 0.88894
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z7sjuue6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091650-z7sjuue6/logs
wandb: ERROR Run z7sjuue6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 9x73cbd8 with config:
wandb: 	actor_learning_rate: 0.0001485885557102545
wandb: 	attention_dropout_p: 0.401031398005572
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1844424657718403
wandb: 	temperature: 1.4143312789348728
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091854-9x73cbd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9x73cbd8
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–†â–†â–…â–â–„
wandb:  best/eval_ensemble_f1 â–â–…â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–†â–‡â–ƒâ–„â–‚â–‚â–â–‚â–‚â–„â–ƒâ–„â–‚â–ˆâ–‚â–†â–â–ƒâ–‚â–†â–ˆâ–ƒâ–‡â–‡â–‚â–ƒâ–â–†â–â–„â–„â–‚â–â–‡â–â–†â–„â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–ˆâ–…â–ˆâ–‚â–‚â–†â–ƒâ–„â–‡â–‡â–ƒâ–‡â–†â–ƒâ–†â–â–â–…â–‡â–ƒâ–‚â–‚â–„â–ƒâ–„â–„â–†â–„â–â–†â–‚â–„â–†â–†â–…â–‚â–„â–‚â–ƒâ–
wandb:       eval/ensemble_f1 â–â–†â–†â–†â–…â–…â–„â–…â–…â–…â–…â–†â–„â–ˆâ–„â–…â–…â–…â–ˆâ–†â–‡â–„â–…â–ˆâ–ˆâ–…â–ˆâ–…â–…â–†â–†â–†â–…â–†â–…â–†â–…â–‡â–†â–†
wandb:           train/avg_f1 â–‚â–…â–†â–„â–„â–…â–‚â–…â–…â–‚â–…â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–„â–…â–‚â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–â–‚â–ƒâ–„â–ƒâ–†â–…â–…â–…â–ƒâ–†â–…â–„
wandb:      train/ensemble_f1 â–…â–â–ƒâ–ƒâ–…â–…â–ƒâ–„â–‚â–ƒâ–…â–†â–†â–‡â–…â–„â–„â–…â–…â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‡â–„â–‚â–„â–„â–ƒâ–…â–…â–„â–†â–…â–„â–†â–†â–„
wandb:         train/mil_loss â–ˆâ–„â–†â–…â–…â–ƒâ–ˆâ–„â–†â–ƒâ–‡â–„â–…â–†â–ˆâ–ƒâ–‚â–„â–â–‚â–…â–„â–„â–ƒâ–ƒâ–„â–…â–…â–ˆâ–…â–…â–â–†â–„â–‚â–…â–ƒâ–†â–…â–‡
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–…â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77413
wandb: best/eval_avg_mil_loss 0.90505
wandb:  best/eval_ensemble_f1 0.77413
wandb:            eval/avg_f1 0.60842
wandb:      eval/avg_mil_loss 1.12195
wandb:       eval/ensemble_f1 0.60842
wandb:           train/avg_f1 0.6245
wandb:      train/ensemble_f1 0.6245
wandb:         train/mil_loss 1.02889
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hopeful-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9x73cbd8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091854-9x73cbd8/logs
wandb: ERROR Run 9x73cbd8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: zf0uffj4 with config:
wandb: 	actor_learning_rate: 4.27082434257544e-05
wandb: 	attention_dropout_p: 0.24828987041547723
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9856528205907664
wandb: 	temperature: 9.901334665227616
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092048-zf0uffj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zf0uffj4
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–‡â–‚â–†
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–…â–„â–‚â–…â–‡â–…â–…â–ˆâ–†â–…â–â–‚â–â–â–‡â–„â–‡â–†â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–†â–‡â–†â–†â–„â–†â–‡â–†â–ˆâ–†â–ˆâ–ˆâ–†
wandb:      eval/avg_mil_loss â–ƒâ–†â–ˆâ–„â–„â–…â–†â–ƒâ–ˆâ–†â–„â–…â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–†â–„â–„â–‚â–ƒâ–ˆâ–‡â–†â–ƒâ–„â–„â–‡â–â–†â–„â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–†
wandb:       eval/ensemble_f1 â–„â–…â–ƒâ–â–†â–…â–†â–ƒâ–…â–…â–â–‡â–‡â–ƒâ–ƒâ–†â–†â–…â–ƒâ–„â–†â–…â–†â–ˆâ–†â–†â–†â–…â–…â–†â–ˆâ–ƒâ–…â–‡â–†â–…â–ˆâ–ˆâ–…â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–‚â–‚â–‚â–…â–‚â–ƒâ–â–ƒâ–„â–„â–â–„â–â–„â–ƒâ–„â–„â–…â–…â–…â–ƒâ–ƒâ–†â–…â–†â–ˆâ–…â–‡â–‡â–‡â–…â–‚â–…â–…â–…â–‡â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–‚â–ƒâ–‚â–‚â–…â–„â–„â–â–„â–â–ƒâ–„â–…â–…â–â–„â–ƒâ–„â–ƒâ–…â–‚â–†â–†â–ƒâ–„â–‡â–„â–‡â–†â–„â–…â–ˆâ–‚â–…â–…â–‡â–†â–‡â–…
wandb:         train/mil_loss â–…â–†â–…â–…â–ƒâ–…â–…â–…â–„â–ƒâ–ˆâ–…â–„â–„â–„â–…â–„â–„â–„â–ƒâ–„â–…â–„â–„â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–…â–‚â–ƒâ–â–‚â–„
wandb:      train/policy_loss â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–…â–…â–â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–‚â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70329
wandb: best/eval_avg_mil_loss 0.97688
wandb:  best/eval_ensemble_f1 0.70329
wandb:            eval/avg_f1 0.6225
wandb:      eval/avg_mil_loss 0.86793
wandb:       eval/ensemble_f1 0.6225
wandb:            test/avg_f1 0.67225
wandb:      test/avg_mil_loss 0.69654
wandb:       test/ensemble_f1 0.67225
wandb:           train/avg_f1 0.60012
wandb:      train/ensemble_f1 0.60012
wandb:         train/mil_loss 0.93276
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wandering-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zf0uffj4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092048-zf0uffj4/logs
wandb: Agent Starting Run: 03czczto with config:
wandb: 	actor_learning_rate: 1.1123659574207702e-06
wandb: 	attention_dropout_p: 0.4814243801614711
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6844440692783557
wandb: 	temperature: 2.7987127969393977
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092258-03czczto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03czczto
wandb: uploading wandb-summary.json
wandb: uploading history steps 168-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–„â–‚â–…â–…â–ƒâ–‚â–„â–…â–…â–„â–„â–„â–„â–†â–„â–„â–„â–…â–…â–„â–…â–…â–…â–…â–…â–…â–†â–‚â–â–†â–†â–†
wandb:      eval/avg_mil_loss â–„â–„â–…â–„â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–â–„â–„â–ƒâ–ƒâ–…â–†â–„â–ˆâ–ƒâ–ƒâ–â–ˆâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–„â–‡â–â–…â–„â–…â–„â–…â–…â–…â–…â–…â–„â–ˆâ–…â–…â–„â–…â–†â–…â–ˆâ–…â–…â–…â–…â–…â–…â–†â–ƒâ–†â–†â–†â–…â–†â–…â–†â–†â–†â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–„â–„â–„â–†â–…â–…â–…â–†â–…â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–„â–†â–ˆ
wandb:      train/ensemble_f1 â–â–‚â–…â–†â–…â–‚â–ƒâ–„â–‚â–„â–ƒâ–…â–…â–…â–…â–‡â–…â–„â–…â–ˆâ–†â–‡â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:         train/mil_loss â–…â–…â–…â–…â–‡â–„â–…â–†â–ƒâ–…â–ˆâ–ƒâ–†â–…â–„â–„â–‚â–„â–ƒâ–‚â–…â–„â–ƒâ–…â–…â–ƒâ–…â–ƒâ–…â–ƒâ–…â–†â–â–ƒâ–‚â–„â–‚â–â–‚â–‚
wandb:      train/policy_loss â–â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74559
wandb: best/eval_avg_mil_loss 0.83027
wandb:  best/eval_ensemble_f1 0.74559
wandb:            eval/avg_f1 0.63947
wandb:      eval/avg_mil_loss 0.90803
wandb:       eval/ensemble_f1 0.63947
wandb:            test/avg_f1 0.66456
wandb:      test/avg_mil_loss 0.54976
wandb:       test/ensemble_f1 0.66456
wandb:           train/avg_f1 0.61396
wandb:      train/ensemble_f1 0.61396
wandb:         train/mil_loss 0.69873
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03czczto
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092258-03czczto/logs
wandb: Agent Starting Run: 77hf3fip with config:
wandb: 	actor_learning_rate: 3.595612597021158e-06
wandb: 	attention_dropout_p: 0.4532057882143906
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12235617059477576
wandb: 	temperature: 6.055624417311764
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092614-77hf3fip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/77hf3fip
wandb: uploading wandb-summary.json
wandb: uploading history steps 126-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–ƒâ–„â–ˆ
wandb: best/eval_avg_mil_loss â–„â–„â–ƒâ–„â–â–ˆâ–†
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–ƒâ–„â–ˆ
wandb:            eval/avg_f1 â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ˆâ–‚â–‚â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„â–ˆâ–ƒâ–„â–„â–…â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„
wandb:      eval/avg_mil_loss â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ˆâ–ƒâ–ƒâ–â–‡â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–…â–‚â–‚â–‚â–‡â–ƒâ–‚â–‚â–‚â–„
wandb:       eval/ensemble_f1 â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–ˆâ–…â–…â–…â–ƒâ–„
wandb:           train/avg_f1 â–„â–„â–‚â–„â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–ƒâ–…â–†â–„â–…â–ƒâ–…â–„â–ƒâ–„â–†â–…â–…â–„â–„â–…â–†â–…â–†â–…â–…â–†â–‡â–†â–†â–‡â–†â–ˆâ–‡
wandb:      train/ensemble_f1 â–…â–„â–…â–â–„â–‚â–ƒâ–„â–‚â–„â–‚â–„â–†â–„â–ƒâ–…â–…â–…â–…â–…â–„â–†â–†â–…â–…â–‡â–ˆâ–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–ˆâ–†â–ˆ
wandb:         train/mil_loss â–…â–‡â–ˆâ–„â–„â–ˆâ–ƒâ–„â–ˆâ–‡â–…â–…â–„â–…â–„â–„â–ƒâ–…â–ˆâ–â–‡â–„â–…â–„â–†â–‚â–…â–ƒâ–ˆâ–‚â–â–‚â–‚â–ƒâ–„â–†â–‚â–‚â–‚â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70868
wandb: best/eval_avg_mil_loss 1.04034
wandb:  best/eval_ensemble_f1 0.70868
wandb:            eval/avg_f1 0.59515
wandb:      eval/avg_mil_loss 0.80714
wandb:       eval/ensemble_f1 0.59515
wandb:           train/avg_f1 0.58891
wandb:      train/ensemble_f1 0.58891
wandb:         train/mil_loss 0.76623
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run gallant-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/77hf3fip
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092614-77hf3fip/logs
wandb: ERROR Run 77hf3fip errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vzrjj05j with config:
wandb: 	actor_learning_rate: 4.8370040960537324e-06
wandb: 	attention_dropout_p: 0.4452112617181314
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.171010445828646
wandb: 	temperature: 8.568907195627618
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092854-vzrjj05j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vzrjj05j
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–…â–„
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–†â–ˆâ–„â–†â–‚â–…â–‡â–…â–†â–†â–†â–â–ƒâ–ˆâ–„â–…â–‡â–…â–†â–„â–„â–…â–†â–ˆâ–ƒâ–†â–„â–‡â–…â–„â–„â–…â–…â–…â–†â–…â–‡â–…â–…
wandb:      eval/avg_mil_loss â–ƒâ–†â–ƒâ–‚â–„â–…â–ƒâ–„â–â–ƒâ–†â–…â–‚â–„â–…â–ƒâ–ƒâ–‚â–ˆâ–†â–…â–…â–‡â–†â–ƒâ–â–‚â–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–…â–‚â–â–„â–…
wandb:       eval/ensemble_f1 â–ˆâ–‡â–…â–â–‡â–†â–‡â–‡â–†â–„â–…â–„â–†â–â–„â–…â–‡â–‡â–†â–„â–ˆâ–†â–‡â–‡â–…â–„â–†â–‡â–…â–†â–…â–‡â–†â–‡â–‡â–…â–‡â–…â–…â–…
wandb:           train/avg_f1 â–„â–…â–ƒâ–„â–…â–â–ƒâ–†â–ƒâ–„â–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–„â–†â–‡â–†â–†â–ƒâ–…â–â–†â–ƒâ–‡â–ƒâ–„â–ˆâ–†â–„â–…â–…â–ƒâ–‡â–„â–†
wandb:      train/ensemble_f1 â–ƒâ–â–„â–ƒâ–ƒâ–‚â–…â–„â–†â–„â–ƒâ–„â–ƒâ–‚â–‚â–„â–‚â–ƒâ–…â–ƒâ–â–„â–†â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–…â–â–„â–„â–†â–ˆâ–‚â–ˆâ–„â–„
wandb:         train/mil_loss â–…â–…â–†â–ˆâ–„â–†â–„â–ƒâ–†â–„â–ƒâ–…â–…â–ƒâ–„â–…â–â–â–„â–†â–„â–‚â–ƒâ–†â–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚â–…â–ƒâ–‚â–„â–„â–
wandb:      train/policy_loss â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80482
wandb: best/eval_avg_mil_loss 0.79636
wandb:  best/eval_ensemble_f1 0.80482
wandb:            eval/avg_f1 0.58947
wandb:      eval/avg_mil_loss 0.86199
wandb:       eval/ensemble_f1 0.58947
wandb:           train/avg_f1 0.6792
wandb:      train/ensemble_f1 0.6792
wandb:         train/mil_loss 0.73635
wandb:      train/policy_loss -0.4979
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.4979
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run twilight-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vzrjj05j
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092854-vzrjj05j/logs
wandb: ERROR Run vzrjj05j errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: pi3n9im8 with config:
wandb: 	actor_learning_rate: 0.00019781176566738352
wandb: 	attention_dropout_p: 0.1947507634810293
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.971538230397636
wandb: 	temperature: 3.612425319374534
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093150-pi3n9im8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pi3n9im8
wandb: uploading wandb-summary.json; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–†â–…â–‚â–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–†â–‚â–â–‚â–‚â–‚â–…â–„â–…â–„â–â–„â–„â–ƒâ–„â–„â–ˆâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–…â–„â–„â–…â–ƒâ–ƒâ–‚â–„â–†â–…â–„â–‚â–‡â–†â–…â–„
wandb:      eval/avg_mil_loss â–ˆâ–†â–„â–‡â–„â–‡â–ƒâ–…â–„â–ˆâ–…â–†â–†â–†â–‡â–…â–ƒâ–ƒâ–†â–‚â–…â–…â–…â–ƒâ–„â–„â–…â–â–„â–ƒâ–†â–†â–„â–†â–†â–ƒâ–ƒâ–…â–ƒâ–‡
wandb:       eval/ensemble_f1 â–â–ƒâ–‚â–â–„â–‚â–‚â–‚â–„â–…â–„â–„â–„â–‚â–ˆâ–„â–ƒâ–„â–ƒâ–„â–…â–„â–…â–ƒâ–…â–†â–ƒâ–…â–„â–„â–„â–†â–‚â–…â–„â–„â–‚â–…â–„â–ƒ
wandb:           train/avg_f1 â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–…â–â–„â–â–„â–„â–„â–ˆâ–„â–„â–…â–…â–‡â–„â–„â–‡â–†â–ƒâ–ƒâ–„â–ˆâ–…â–…â–…â–†â–‡â–†â–…â–†â–…â–†
wandb:      train/ensemble_f1 â–„â–„â–…â–‚â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–‡â–â–…â–„â–„â–„â–…â–†â–…â–…â–ˆâ–ƒâ–‡â–‡â–„â–‡â–‡â–…â–…â–…â–…â–†â–…â–ˆâ–†â–ˆâ–„â–…â–…
wandb:         train/mil_loss â–ƒâ–…â–…â–†â–„â–…â–ƒâ–…â–‚â–…â–…â–ˆâ–ƒâ–„â–„â–ƒâ–„â–„â–…â–ƒâ–ƒâ–ƒâ–…â–‚â–â–ƒâ–‚â–„â–„â–â–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7328
wandb: best/eval_avg_mil_loss 0.98614
wandb:  best/eval_ensemble_f1 0.7328
wandb:            eval/avg_f1 0.58791
wandb:      eval/avg_mil_loss 1.20088
wandb:       eval/ensemble_f1 0.58791
wandb:           train/avg_f1 0.64231
wandb:      train/ensemble_f1 0.64231
wandb:         train/mil_loss 1.10943
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run polar-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pi3n9im8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093150-pi3n9im8/logs
wandb: ERROR Run pi3n9im8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: xu5wgfw1 with config:
wandb: 	actor_learning_rate: 0.00024346470273844357
wandb: 	attention_dropout_p: 0.2935332031041669
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09914793612345608
wandb: 	temperature: 5.789381068841894
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093349-xu5wgfw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xu5wgfw1
wandb: uploading history steps 123-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–„â–„â–„â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–ˆâ–„â–‚â–…â–ƒâ–‡â–„â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–„â–„â–„â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–…â–…â–…â–†â–…â–…â–…â–„â–…â–†â–…â–…â–…â–†â–â–†â–…â–„â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–„â–‡â–ˆâ–‡â–†â–ˆâ–‡â–†â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–ˆâ–…â–ƒâ–…â–‡â–„â–„â–†â–…â–‡â–‡â–ˆâ–…â–…â–„â–†â–„â–„â–ˆâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–â–ƒâ–‚â–ƒâ–„â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–†â–â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–„â–…â–„â–„â–†â–†â–‚â–…â–†â–…â–„â–†â–ˆâ–…â–ƒâ–ƒâ–†â–ˆâ–†â–†â–ˆâ–‡â–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–„â–„â–†â–…â–…â–…â–ƒâ–„â–…â–†â–†â–…â–‡â–†â–‡â–‡â–…â–‡â–ˆ
wandb:      train/ensemble_f1 â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–„â–…â–…â–‡â–†â–…â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–„â–…â–‡â–‡â–‡
wandb:         train/mil_loss â–ˆâ–‡â–†â–…â–‡â–†â–†â–…â–ˆâ–…â–†â–ˆâ–†â–…â–†â–…â–‡â–…â–…â–…â–ƒâ–ƒâ–†â–‚â–…â–†â–…â–ƒâ–„â–‡â–ƒâ–‚â–…â–‚â–„â–â–‚â–…â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–…â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69562
wandb: best/eval_avg_mil_loss 0.74134
wandb:  best/eval_ensemble_f1 0.69562
wandb:            eval/avg_f1 0.63787
wandb:      eval/avg_mil_loss 0.79404
wandb:       eval/ensemble_f1 0.63787
wandb:            test/avg_f1 0.60942
wandb:      test/avg_mil_loss 0.65735
wandb:       test/ensemble_f1 0.60942
wandb:           train/avg_f1 0.68949
wandb:      train/ensemble_f1 0.68949
wandb:         train/mil_loss 0.75321
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comic-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xu5wgfw1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093349-xu5wgfw1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pl4w75ey with config:
wandb: 	actor_learning_rate: 4.9501572682046364e-06
wandb: 	attention_dropout_p: 0.23240860552872533
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 127
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31157789816577164
wandb: 	temperature: 2.2901151841595446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093624-pl4w75ey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pl4w75ey
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–…â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–…â–‡â–â–„â–†â–„â–†â–‡â–‡â–„â–…â–†â–…â–‡â–ˆâ–…â–ˆâ–†â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆâ–†â–‡â–‡â–†â–…â–‡â–ˆâ–‡â–†â–†â–ˆâ–†â–ˆ
wandb:      eval/avg_mil_loss â–…â–…â–„â–…â–‡â–ƒâ–„â–…â–„â–…â–‡â–‡â–ƒâ–„â–†â–ƒâ–‚â–„â–†â–„â–„â–†â–‚â–ƒâ–â–„â–ˆâ–…â–„â–…â–‚â–…â–†â–„â–ƒâ–„â–†â–„â–‚â–…
wandb:       eval/ensemble_f1 â–†â–†â–‡â–â–†â–†â–…â–…â–…â–…â–„â–…â–†â–…â–†â–‡â–…â–‡â–†â–…â–†â–…â–†â–†â–‡â–‡â–„â–„â–†â–†â–ˆâ–‡â–ˆâ–‡â–†â–†â–ˆâ–…â–ˆâ–ˆ
wandb:           train/avg_f1 â–…â–„â–ƒâ–â–„â–‚â–…â–ƒâ–†â–„â–…â–…â–†â–…â–†â–„â–…â–†â–…â–†â–…â–†â–…â–†â–†â–†â–‡â–ˆâ–†â–†â–…â–‡â–†â–†â–…â–†â–†â–†â–‡â–†
wandb:      train/ensemble_f1 â–„â–„â–ƒâ–ƒâ–…â–â–‚â–„â–…â–„â–…â–…â–†â–„â–‡â–‡â–†â–…â–…â–†â–†â–†â–‡â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–‡â–‡
wandb:         train/mil_loss â–…â–…â–†â–†â–ˆâ–„â–‡â–„â–†â–†â–†â–†â–…â–…â–„â–…â–ƒâ–‚â–†â–ˆâ–„â–…â–„â–‚â–„â–‚â–‚â–…â–†â–‚â–ƒâ–â–„â–…â–â–…â–‚â–â–‚â–‚
wandb:      train/policy_loss â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68706
wandb: best/eval_avg_mil_loss 0.87226
wandb:  best/eval_ensemble_f1 0.68706
wandb:            eval/avg_f1 0.59982
wandb:      eval/avg_mil_loss 0.9066
wandb:       eval/ensemble_f1 0.59982
wandb:           train/avg_f1 0.59622
wandb:      train/ensemble_f1 0.59622
wandb:         train/mil_loss 0.99924
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bright-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pl4w75ey
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093624-pl4w75ey/logs
wandb: ERROR Run pl4w75ey errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gjx85i06 with config:
wandb: 	actor_learning_rate: 0.0003720412875816403
wandb: 	attention_dropout_p: 0.2434818692305859
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9339898382865768
wandb: 	temperature: 0.7021993518829994
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093914-gjx85i06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gjx85i06
wandb: uploading history steps 84-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–„â–‡â–ˆâ–‡
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–‡â–†â–…â–†â–„â–‡â–„â–…â–…â–‡â–‡â–„â–„â–…â–„â–‡â–†â–‡â–…â–…â–…â–†â–‡â–„â–„â–ˆâ–…â–…â–â–‡â–…â–ˆâ–†â–‡â–…â–…â–…â–‡
wandb:      eval/avg_mil_loss â–â–ƒâ–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–„â–ˆâ–ƒâ–„â–…â–†â–ƒâ–„â–†â–‚â–„â–ƒâ–…â–ƒâ–†â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–
wandb:       eval/ensemble_f1 â–ƒâ–‚â–…â–„â–ƒâ–†â–„â–„â–ƒâ–…â–…â–…â–â–‚â–‚â–ƒâ–†â–ƒâ–ƒâ–ˆâ–ƒâ–…â–…â–ƒâ–„â–ƒâ–…â–‡â–†â–…â–ƒâ–†â–„â–‡â–„â–‡â–†â–ƒâ–†â–…
wandb:           train/avg_f1 â–ƒâ–‚â–„â–ƒâ–â–…â–…â–…â–„â–†â–ƒâ–…â–ƒâ–…â–ƒâ–„â–ˆâ–ˆâ–†â–†â–…â–†â–‚â–†â–ƒâ–…â–„â–†â–†â–ˆâ–…â–†â–„â–†â–…â–†â–‡â–‡â–‡â–…
wandb:      train/ensemble_f1 â–‚â–â–…â–ƒâ–â–„â–„â–…â–„â–‚â–‚â–„â–…â–„â–‚â–„â–„â–„â–ˆâ–…â–…â–‡â–„â–„â–„â–‚â–ƒâ–„â–†â–†â–ƒâ–„â–†â–†â–†â–†â–‡â–‡â–†â–…
wandb:         train/mil_loss â–†â–„â–‡â–…â–…â–†â–‚â–‡â–„â–„â–ˆâ–…â–…â–…â–„â–†â–ˆâ–†â–ƒâ–‚â–…â–…â–…â–„â–„â–‡â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–†â–ƒâ–…
wandb:      train/policy_loss â–ˆâ–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–…â–†â–…â–†â–†â–ƒâ–†â–†â–ˆâ–†â–‡â–†â–ˆâ–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76965
wandb: best/eval_avg_mil_loss 0.96034
wandb:  best/eval_ensemble_f1 0.76965
wandb:            eval/avg_f1 0.67111
wandb:      eval/avg_mil_loss 0.85424
wandb:       eval/ensemble_f1 0.67111
wandb:           train/avg_f1 0.64268
wandb:      train/ensemble_f1 0.64268
wandb:         train/mil_loss 0.97003
wandb:      train/policy_loss -0.59912
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.59912
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run efficient-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gjx85i06
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093914-gjx85i06/logs
wandb: ERROR Run gjx85i06 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 3jo7uk0c with config:
wandb: 	actor_learning_rate: 5.880076663428172e-06
wandb: 	attention_dropout_p: 0.06166355563474085
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6922507097019394
wandb: 	temperature: 5.712049954342765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094057-3jo7uk0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jo7uk0c
wandb: uploading history steps 42-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–„â–‡â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–„â–†â–ˆ
wandb:            eval/avg_f1 â–†â–…â–â–†â–‡â–†â–†â–‡â–†â–‡â–„â–†â–†â–‡â–ƒâ–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–†â–â–…â–„â–†â–ˆâ–‡â–‚â–‚â–‡â–‡â–‡â–‡â–‡â–†â–‡
wandb:      eval/avg_mil_loss â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–†â–â–‚â–†â–ƒâ–â–ˆâ–â–â–ƒâ–ƒâ–â–â–ƒâ–†â–‚â–â–â–‡â–„â–„â–â–‚â–‚â–‡â–„â–„â–â–â–â–â–ƒâ–‚
wandb:       eval/ensemble_f1 â–†â–…â–â–†â–‡â–†â–†â–†â–‡â–†â–‡â–ˆâ–„â–†â–†â–ƒâ–‡â–†â–†â–†â–‡â–‡â–‡â–†â–†â–†â–‡â–â–…â–„â–ˆâ–‡â–‚â–‚â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–‚â–â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…â–„â–„â–„â–‚â–ƒâ–†â–ƒâ–„â–„â–…â–ˆâ–„â–…â–„â–…â–ƒâ–…â–…â–„
wandb:      train/ensemble_f1 â–ƒâ–†â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„â–‚â–â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–…â–„â–„â–„â–…â–ƒâ–„â–†â–ƒâ–„â–…â–…â–ˆâ–…â–„â–…â–ƒâ–…â–„
wandb:         train/mil_loss â–ƒâ–„â–ƒâ–â–†â–ƒâ–…â–…â–‚â–ˆâ–‚â–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‡â–ƒâ–ƒâ–‡â–„â–â–‚â–ƒâ–„â–„â–…â–‚â–‚â–„â–‡â–ƒâ–…â–‚â–‡â–…
wandb:      train/policy_loss â–„â–†â–ˆâ–†â–„â–†â–†â–â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–ˆâ–†â–„â–†â–†â–†â–â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61944
wandb: best/eval_avg_mil_loss 0.83438
wandb:  best/eval_ensemble_f1 0.61944
wandb:            eval/avg_f1 0.5684
wandb:      eval/avg_mil_loss 0.85617
wandb:       eval/ensemble_f1 0.5684
wandb:            test/avg_f1 0.60144
wandb:      test/avg_mil_loss 0.57504
wandb:       test/ensemble_f1 0.60144
wandb:           train/avg_f1 0.57213
wandb:      train/ensemble_f1 0.57213
wandb:         train/mil_loss 0.93232
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run volcanic-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3jo7uk0c
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094057-3jo7uk0c/logs
wandb: Agent Starting Run: ykmj1rxx with config:
wandb: 	actor_learning_rate: 3.0430598407409713e-05
wandb: 	attention_dropout_p: 0.4276283352407362
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2506343316389621
wandb: 	temperature: 2.7981042580645754
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094159-ykmj1rxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ykmj1rxx
wandb: uploading history steps 126-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–â–…â–ˆâ–„â–†â–†â–‡â–‡â–†â–†â–…â–„â–†â–…â–†â–ƒâ–‚â–†â–…â–†â–…â–…â–‡â–…â–†â–ˆâ–†â–‚â–ˆâ–…â–†â–†
wandb:      eval/avg_mil_loss â–ƒâ–ƒâ–†â–„â–ƒâ–„â–„â–†â–„â–‡â–‚â–„â–ƒâ–…â–ƒâ–ˆâ–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–‡â–‡â–ƒâ–„â–‚â–„â–„â–ƒâ–â–ˆâ–„â–†
wandb:       eval/ensemble_f1 â–„â–…â–‡â–„â–…â–ƒâ–†â–„â–‚â–â–ƒâ–…â–ƒâ–†â–‡â–â–ƒâ–†â–…â–ƒâ–…â–ƒâ–‡â–„â–ƒâ–„â–…â–…â–…â–ˆâ–ƒâ–‡â–…â–‡â–†â–‡â–„â–‡â–†â–…
wandb:           train/avg_f1 â–â–‚â–…â–â–â–ƒâ–â–„â–ƒâ–…â–‚â–ƒâ–„â–†â–„â–†â–‚â–…â–…â–„â–‚â–†â–„â–†â–…â–â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–…â–„â–„â–…â–ˆâ–†â–†
wandb:      train/ensemble_f1 â–„â–„â–ƒâ–‚â–†â–ƒâ–…â–â–…â–„â–„â–‚â–ˆâ–ƒâ–…â–„â–‚â–‡â–†â–„â–†â–…â–‡â–ƒâ–‡â–…â–‡â–†â–…â–„â–„â–…â–…â–†â–„â–„â–…â–…â–†â–†
wandb:         train/mil_loss â–‚â–‡â–…â–…â–‡â–…â–…â–ƒâ–„â–„â–…â–‡â–‚â–†â–…â–ƒâ–â–†â–†â–„â–†â–â–†â–ƒâ–…â–â–ƒâ–ƒâ–ˆâ–â–…â–â–‡â–†â–ˆâ–ƒâ–„â–‡â–…â–†
wandb:      train/policy_loss â–ˆâ–â–ˆâ–†â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78858
wandb: best/eval_avg_mil_loss 0.74504
wandb:  best/eval_ensemble_f1 0.78858
wandb:            eval/avg_f1 0.69545
wandb:      eval/avg_mil_loss 0.71492
wandb:       eval/ensemble_f1 0.69545
wandb:           train/avg_f1 0.67815
wandb:      train/ensemble_f1 0.67815
wandb:         train/mil_loss 0.82881
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rich-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ykmj1rxx
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094159-ykmj1rxx/logs
wandb: ERROR Run ykmj1rxx errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: czgiddr8 with config:
wandb: 	actor_learning_rate: 1.2738128449268476e-06
wandb: 	attention_dropout_p: 0.08338596829894196
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5123198154108991
wandb: 	temperature: 7.3228822490734515
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094439-czgiddr8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czgiddr8
wandb: uploading history steps 42-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–„â–†â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–ƒâ–†â–‚â–ƒâ–„â–â–â–ƒâ–‡â–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‡â–‚â–„â–ƒâ–‚â–‚â–…â–„â–â–…â–…â–ƒâ–†â–‚â–…â–ˆâ–ƒâ–
wandb:      eval/avg_mil_loss â–‡â–†â–„â–ƒâ–…â–ƒâ–…â–…â–‡â–‡â–…â–…â–…â–†â–‡â–‚â–…â–ƒâ–…â–‚â–†â–…â–†â–‚â–ƒâ–†â–†â–…â–†â–…â–„â–ˆâ–ƒâ–†â–„â–„â–…â–â–„â–
wandb:       eval/ensemble_f1 â–‚â–ƒâ–†â–ƒâ–ƒâ–â–…â–â–‡â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‡â–‚â–„â–‚â–‚â–‚â–„â–â–…â–‚â–…â–…â–ƒâ–†â–‚â–…â–ˆâ–ƒâ–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–†â–‚â–ƒâ–‚â–‚â–„â–‚â–…â–„â–ˆâ–â–„â–…â–„â–‡â–…â–„â–†â–†â–ƒâ–„â–„â–„â–„â–„â–„â–â–ƒâ–†â–„â–‡â–‚â–„â–ƒâ–…â–…â–â–ƒ
wandb:      train/ensemble_f1 â–ƒâ–„â–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–„â–ˆâ–‚â–„â–…â–…â–‡â–…â–„â–†â–†â–„â–„â–…â–â–„â–„â–…â–ƒâ–‡â–ƒâ–…â–ƒâ–‚â–†â–…â–â–‚â–ƒ
wandb:         train/mil_loss â–„â–ƒâ–‚â–„â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ˆâ–„â–…â–„â–„â–‚â–„â–ƒâ–†â–„â–‚â–„â–â–ƒâ–…â–…â–…â–‚â–ƒâ–†â–„â–‚â–„â–…â–ƒâ–…â–„â–†â–â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74839
wandb: best/eval_avg_mil_loss 0.69317
wandb:  best/eval_ensemble_f1 0.74839
wandb:            eval/avg_f1 0.52677
wandb:      eval/avg_mil_loss 0.72487
wandb:       eval/ensemble_f1 0.52677
wandb:            test/avg_f1 0.58697
wandb:      test/avg_mil_loss 0.84564
wandb:       test/ensemble_f1 0.58697
wandb:           train/avg_f1 0.58355
wandb:      train/ensemble_f1 0.58355
wandb:         train/mil_loss 0.98014
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run good-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/czgiddr8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094439-czgiddr8/logs
wandb: Agent Starting Run: fi4hsov6 with config:
wandb: 	actor_learning_rate: 0.00013966997883742144
wandb: 	attention_dropout_p: 0.055328945349481795
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35377132621311336
wandb: 	temperature: 6.1402403191119586
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094542-fi4hsov6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fi4hsov6
wandb: uploading history steps 140-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–ƒâ–ˆâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–…â–„â–‡â–ˆâ–…â–†â–…â–‚â–…â–…â–ƒâ–‡â–†â–ƒâ–†â–ƒâ–†â–‡â–„â–…â–ˆâ–…â–…â–ƒâ–â–†â–†â–‚â–‡â–‡â–ƒâ–ƒâ–‡â–„â–…â–…â–‡â–„â–†
wandb:      eval/avg_mil_loss â–‚â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–†â–…â–…â–ƒâ–‚â–ƒâ–…â–ˆâ–‚â–‚â–†â–‚â–â–‚â–…â–‚â–ƒâ–‚â–ƒâ–†â–‚â–‚â–„â–â–
wandb:       eval/ensemble_f1 â–…â–„â–…â–ƒâ–‚â–†â–‚â–…â–…â–ƒâ–…â–…â–†â–„â–ƒâ–â–„â–ƒâ–‡â–†â–â–…â–ƒâ–…â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–‡â–„â–…â–‚â–‡â–‡â–ˆâ–†â–‡â–ˆ
wandb:           train/avg_f1 â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–â–…â–‚â–…â–†â–„â–„â–â–†â–ƒâ–„â–…â–„â–…â–„â–ƒâ–†â–„â–„â–„â–†â–„â–‡â–ƒâ–ˆâ–ƒâ–…â–„â–†â–‡
wandb:      train/ensemble_f1 â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–‚â–‚â–…â–„â–„â–…â–â–ƒâ–…â–‡â–…â–†â–„â–…â–…â–…â–„â–„â–ˆâ–†â–‡â–‡â–…â–ƒâ–„â–‡â–ˆâ–†â–‡â–†â–ˆ
wandb:         train/mil_loss â–…â–„â–ˆâ–†â–‡â–…â–‡â–‡â–‚â–‡â–ˆâ–†â–…â–†â–…â–ƒâ–‚â–ƒâ–†â–„â–‚â–†â–ƒâ–‡â–…â–ƒâ–‚â–„â–„â–†â–…â–ˆâ–â–„â–ˆâ–‡â–‚â–†â–ƒâ–…
wandb:      train/policy_loss â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–†â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63739
wandb: best/eval_avg_mil_loss 0.72894
wandb:  best/eval_ensemble_f1 0.63739
wandb:            eval/avg_f1 0.62043
wandb:      eval/avg_mil_loss 0.80581
wandb:       eval/ensemble_f1 0.62043
wandb:           train/avg_f1 0.59999
wandb:      train/ensemble_f1 0.59999
wandb:         train/mil_loss 0.79349
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run dauntless-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fi4hsov6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094542-fi4hsov6/logs
wandb: ERROR Run fi4hsov6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 6obbwcbq with config:
wandb: 	actor_learning_rate: 1.1099356983779151e-05
wandb: 	attention_dropout_p: 0.25134345460941576
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4575060300495362
wandb: 	temperature: 1.1043680294992977
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094822-6obbwcbq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6obbwcbq
wandb: uploading history steps 97-110; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–â–…â–†
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ƒâ–ˆ
wandb:            eval/avg_f1 â–…â–â–…â–ˆâ–…â–…â–ƒâ–…â–†â–…â–†â–…â–†â–†â–ˆâ–†â–…â–…â–†â–ˆâ–†â–†â–†â–†â–†â–‡â–…â–‡â–†â–‡â–‡â–‡â–†â–ˆâ–‡â–†â–†â–‡â–†â–†
wandb:      eval/avg_mil_loss â–‡â–…â–‡â–„â–„â–„â–ˆâ–„â–„â–„â–…â–ƒâ–†â–„â–†â–„â–ƒâ–â–„â–‚â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–„â–„â–…â–…
wandb:       eval/ensemble_f1 â–ƒâ–â–„â–„â–„â–„â–„â–ƒâ–„â–ˆâ–„â–…â–†â–…â–„â–…â–„â–…â–…â–â–…â–…â–…â–ƒâ–†â–…â–…â–ƒâ–…â–…â–…â–ˆâ–…â–‡â–ƒâ–†â–…â–†â–…â–…
wandb:           train/avg_f1 â–‚â–‚â–â–ƒâ–…â–‡â–„â–…â–…â–â–ƒâ–‚â–ƒâ–‚â–â–…â–…â–ƒâ–…â–ƒâ–…â–ƒâ–†â–„â–„â–†â–†â–…â–…â–„â–‡â–…â–†â–ˆâ–ˆâ–†â–ƒâ–†â–†â–…
wandb:      train/ensemble_f1 â–â–ƒâ–‚â–‚â–ƒâ–„â–…â–„â–…â–‚â–‚â–ƒâ–…â–ƒâ–…â–…â–ƒâ–†â–†â–†â–…â–†â–†â–„â–‡â–…â–…â–ˆâ–…â–†â–…â–„â–ƒâ–…â–‡â–†â–…â–…â–…â–…
wandb:         train/mil_loss â–ˆâ–‚â–„â–†â–„â–…â–…â–…â–ƒâ–„â–†â–…â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–…â–…â–ƒâ–â–…â–…â–â–ƒâ–‚â–„â–‚â–‚â–„â–ƒâ–‚â–…â–
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68611
wandb: best/eval_avg_mil_loss 0.8636
wandb:  best/eval_ensemble_f1 0.68611
wandb:            eval/avg_f1 0.56339
wandb:      eval/avg_mil_loss 0.93384
wandb:       eval/ensemble_f1 0.56339
wandb:           train/avg_f1 0.63219
wandb:      train/ensemble_f1 0.63219
wandb:         train/mil_loss 0.75943
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fine-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6obbwcbq
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094822-6obbwcbq/logs
wandb: ERROR Run 6obbwcbq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uj9g431k with config:
wandb: 	actor_learning_rate: 0.00014064557220792788
wandb: 	attention_dropout_p: 0.28502424060252374
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22243346812384523
wandb: 	temperature: 7.258905457221233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095037-uj9g431k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uj9g431k
wandb: uploading history steps 180-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–â–‡
wandb:  best/eval_ensemble_f1 â–â–â–…â–ˆ
wandb:            eval/avg_f1 â–„â–„â–†â–ƒâ–„â–â–†â–‡â–…â–‡â–…â–ˆâ–…â–†â–„â–†â–…â–„â–†â–„â–†â–ƒâ–ˆâ–ƒâ–„â–‚â–„â–†â–‡â–†â–†â–ƒâ–„â–ƒâ–„â–‡â–…â–…â–ˆâ–‡
wandb:      eval/avg_mil_loss â–…â–†â–…â–‡â–‡â–…â–ƒâ–…â–…â–‚â–ƒâ–ˆâ–ƒâ–„â–„â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–†â–â–„â–„â–â–ƒâ–‚â–†â–†â–‚â–â–â–„â–„â–ˆâ–†â–â–‚â–†
wandb:       eval/ensemble_f1 â–ˆâ–â–‡â–‡â–ƒâ–…â–„â–„â–‡â–‡â–‡â–â–…â–…â–‡â–„â–ˆâ–†â–†â–â–†â–…â–„â–‡â–‚â–„â–…â–†â–‡â–†â–†â–†â–†â–…â–†â–ˆâ–†â–„â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–„â–‚â–‚â–…â–â–…â–ƒâ–‚â–ƒâ–„â–‚â–…â–„â–„â–„â–…â–ƒâ–ƒâ–…â–†â–ˆâ–…â–…â–…â–†â–†â–…â–†â–…â–†â–‡
wandb:      train/ensemble_f1 â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–ƒâ–…â–„â–‚â–„â–„â–„â–ƒâ–„â–…â–…â–„â–„â–†â–„â–‡â–…â–„â–…â–ˆâ–†â–†â–…â–…â–…â–†â–‡â–…â–…
wandb:         train/mil_loss â–„â–ˆâ–…â–‚â–‡â–†â–„â–‡â–ˆâ–…â–„â–†â–…â–…â–…â–…â–„â–†â–†â–„â–†â–…â–â–…â–†â–„â–‚â–…â–‡â–‚â–â–‡â–‡â–†â–‚â–„â–ƒâ–ƒâ–†â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78916
wandb: best/eval_avg_mil_loss 0.91036
wandb:  best/eval_ensemble_f1 0.78916
wandb:            eval/avg_f1 0.78301
wandb:      eval/avg_mil_loss 0.78479
wandb:       eval/ensemble_f1 0.78301
wandb:            test/avg_f1 0.77969
wandb:      test/avg_mil_loss 0.47248
wandb:       test/ensemble_f1 0.77969
wandb:           train/avg_f1 0.74325
wandb:      train/ensemble_f1 0.74325
wandb:         train/mil_loss 0.8074
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run floral-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uj9g431k
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095037-uj9g431k/logs
wandb: Agent Starting Run: 3dxyoqa7 with config:
wandb: 	actor_learning_rate: 0.0005990505678833434
wandb: 	attention_dropout_p: 0.32452557975317575
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.055882446917507655
wandb: 	temperature: 2.937513744671504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095404-3dxyoqa7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dxyoqa7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–‡â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–…â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–„â–ƒâ–†â–‚â–…â–…â–„â–„â–â–‚â–‡â–â–„â–…â–â–‡â–‡â–„â–…â–„â–‡â–â–…â–â–„â–‚â–„â–‚â–…â–‚â–…â–‚â–„â–â–ˆâ–…â–‡â–„â–‡
wandb:      eval/avg_mil_loss â–‚â–…â–†â–„â–„â–…â–‡â–‚â–ƒâ–ˆâ–†â–„â–„â–‚â–…â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–…â–„â–…â–ƒâ–„â–‡â–â–„â–…â–…â–„â–…â–ƒâ–…â–„â–„â–„
wandb:       eval/ensemble_f1 â–„â–…â–‡â–…â–‚â–†â–…â–…â–â–‚â–â–…â–…â–…â–„â–…â–…â–…â–†â–ˆâ–‚â–…â–…â–‚â–…â–„â–†â–…â–…â–…â–…â–…â–…â–â–„â–†â–‡â–…â–„â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–„â–‚â–ƒâ–„â–…â–…â–„â–…â–†â–…â–ƒâ–…â–‚â–…â–†â–…â–ƒâ–‚â–ˆâ–†â–…â–ƒâ–…â–‡â–„â–…â–ƒâ–‚â–†â–„â–„â–„â–ˆâ–ƒâ–‚â–…â–ƒâ–
wandb:      train/ensemble_f1 â–ƒâ–„â–ƒâ–ƒâ–â–…â–…â–„â–„â–„â–ˆâ–†â–†â–ˆâ–ƒâ–‚â–„â–…â–„â–…â–ˆâ–‡â–…â–ƒâ–„â–‚â–„â–…â–†â–„â–†â–„â–„â–†â–„â–ƒâ–ƒâ–†â–â–‡
wandb:         train/mil_loss â–ˆâ–…â–ƒâ–…â–‡â–„â–‡â–†â–„â–ˆâ–ƒâ–…â–†â–†â–ƒâ–†â–‡â–„â–‡â–†â–…â–ƒâ–„â–„â–ƒâ–â–ƒâ–…â–…â–†â–…â–„â–ƒâ–„â–…â–…â–„â–†â–„â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79863
wandb: best/eval_avg_mil_loss 0.87296
wandb:  best/eval_ensemble_f1 0.79863
wandb:            eval/avg_f1 0.52005
wandb:      eval/avg_mil_loss 0.88463
wandb:       eval/ensemble_f1 0.52005
wandb:            test/avg_f1 0.55568
wandb:      test/avg_mil_loss 0.94183
wandb:       test/ensemble_f1 0.55568
wandb:           train/avg_f1 0.63371
wandb:      train/ensemble_f1 0.63371
wandb:         train/mil_loss 0.95965
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3dxyoqa7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095404-3dxyoqa7/logs
wandb: Agent Starting Run: 0fvdm8aw with config:
wandb: 	actor_learning_rate: 5.658359525346602e-06
wandb: 	attention_dropout_p: 0.22146013298757328
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22810854013789628
wandb: 	temperature: 4.216469686761645
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095559-0fvdm8aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fvdm8aw
wandb: uploading history steps 176-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–‚â–‚â–„â–„â–„â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–…â–…â–ˆâ–†â–†â–ƒâ–‚â–ƒâ–‚â–â–â–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–â–â–‚â–‚â–„â–„â–„â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–‚â–‚â–ƒâ–„â–„â–…â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–…â–†â–…â–†â–†â–„â–…â–†â–†â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆ
wandb:      eval/avg_mil_loss â–ˆâ–‡â–†â–†â–„â–…â–„â–…â–…â–†â–‡â–…â–†â–…â–ƒâ–…â–„â–„â–„â–†â–…â–ƒâ–†â–†â–„â–‚â–‚â–…â–ƒâ–‚â–‚â–…â–ƒâ–…â–ƒâ–…â–‚â–„â–â–
wandb:       eval/ensemble_f1 â–â–ƒâ–ƒâ–â–â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–„â–ƒâ–…â–…â–†â–‡â–…â–†â–‡â–†â–†â–†â–†â–ˆâ–†â–‡â–‡â–‡â–…â–ˆâ–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–…â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡
wandb:      train/ensemble_f1 â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆ
wandb:         train/mil_loss â–‡â–ˆâ–†â–†â–…â–…â–…â–…â–…â–†â–…â–ƒâ–…â–…â–…â–„â–„â–‚â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–
wandb:      train/policy_loss â–ƒâ–â–†â–ˆâ–„â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–†â–„â–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.5553
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.78603
wandb:      eval/avg_mil_loss 0.52064
wandb:       eval/ensemble_f1 0.78603
wandb:            test/avg_f1 0.81536
wandb:      test/avg_mil_loss 0.40115
wandb:       test/ensemble_f1 0.81536
wandb:           train/avg_f1 0.74639
wandb:      train/ensemble_f1 0.74639
wandb:         train/mil_loss 0.63686
wandb:      train/policy_loss 0.32503
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.32503
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devoted-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0fvdm8aw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095559-0fvdm8aw/logs
wandb: Agent Starting Run: 7vzf5jji with config:
wandb: 	actor_learning_rate: 5.696969380257409e-06
wandb: 	attention_dropout_p: 0.3204446174267133
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6430429323438486
wandb: 	temperature: 9.93832160248928
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100001-7vzf5jji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vzf5jji
wandb: uploading history steps 109-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ƒâ–‡â–…â–„â–â–…â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–…â–†â–‚â–â–‚â–…â–…â–‡â–‡â–ƒâ–„â–„â–„â–ˆâ–„â–„â–ˆâ–‡â–‡â–ƒâ–„â–„â–…â–†â–„â–ƒâ–…â–‚â–…â–†â–ˆâ–…â–…â–„â–ƒâ–…â–„â–†
wandb:      eval/avg_mil_loss â–„â–†â–„â–‚â–†â–„â–ƒâ–‡â–‡â–‚â–†â–†â–„â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–…â–…â–â–„â–„â–„â–„â–†â–ƒâ–„â–ƒâ–…â–…â–„â–‚â–â–…â–‚â–ƒâ–„â–„
wandb:       eval/ensemble_f1 â–„â–‡â–…â–…â–ƒâ–â–…â–…â–‡â–„â–„â–ƒâ–„â–‚â–…â–„â–„â–‡â–†â–…â–ƒâ–…â–…â–ƒâ–‚â–†â–…â–ƒâ–…â–†â–ˆâ–‡â–„â–…â–…â–„â–†â–ˆâ–ƒâ–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–ƒâ–„â–â–â–‚â–„â–„â–…â–ƒâ–†â–…â–…â–…â–ƒâ–„â–ƒâ–…â–ƒâ–…â–†â–‡â–…â–†â–†â–„â–†â–†â–†â–ˆâ–‡â–„â–…â–‡â–…â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:      train/ensemble_f1 â–„â–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–â–‡â–‚â–…â–…â–„â–„â–†â–„â–…â–…â–†â–†â–ˆâ–†â–„â–…â–†â–†â–‡â–…â–†â–‡â–„â–ˆâ–‡â–…â–‡â–†â–ˆâ–†â–ˆ
wandb:         train/mil_loss â–„â–„â–†â–‚â–‚â–„â–ƒâ–…â–…â–‚â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–ƒâ–…â–…â–ƒâ–‚â–‚â–‚â–â–â–â–„â–‚â–ƒâ–ƒâ–…â–‡â–ƒâ–â–â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:      train/policy_loss â–„â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–„â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72083
wandb: best/eval_avg_mil_loss 0.83319
wandb:  best/eval_ensemble_f1 0.72083
wandb:            eval/avg_f1 0.62772
wandb:      eval/avg_mil_loss 0.98959
wandb:       eval/ensemble_f1 0.62772
wandb:            test/avg_f1 0.59967
wandb:      test/avg_mil_loss 0.67243
wandb:       test/ensemble_f1 0.59967
wandb:           train/avg_f1 0.63258
wandb:      train/ensemble_f1 0.63258
wandb:         train/mil_loss 1.02771
wandb:      train/policy_loss -0.5997
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.5997
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run bumbling-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7vzf5jji
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100001-7vzf5jji/logs
wandb: Agent Starting Run: aor4g451 with config:
wandb: 	actor_learning_rate: 6.070045399443527e-05
wandb: 	attention_dropout_p: 0.4694050463049989
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06658742639366544
wandb: 	temperature: 0.23199572003929855
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100211-aor4g451
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aor4g451
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–†â–„â–…â–„â–…â–„â–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–â–‚â–â–ƒâ–„â–ƒâ–‚â–„â–…â–„â–…â–…â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–‡â–‡â–‡â–‡â–†â–…â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–ˆâ–ˆ
wandb:      eval/avg_mil_loss â–‡â–†â–ˆâ–‡â–‡â–†â–†â–…â–…â–†â–…â–…â–…â–…â–„â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–„â–„â–†â–â–ƒâ–
wandb:       eval/ensemble_f1 â–‚â–â–â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–„â–…â–…â–…â–†â–†â–‡â–†â–ˆâ–†â–‡â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–ˆâ–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–‚â–„â–„â–„â–…â–†â–…â–†â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆ
wandb:      train/ensemble_f1 â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–…â–…â–…â–†â–…â–†â–…â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         train/mil_loss â–ˆâ–†â–‡â–ˆâ–†â–ˆâ–†â–†â–†â–†â–†â–„â–„â–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚
wandb:      train/policy_loss â–ƒâ–…â–„â–„â–„â–ƒâ–„â–‚â–„â–„â–„â–„â–â–ƒâ–ƒâ–„â–„â–„â–„â–‚â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–†â–‚â–‚â–‡â–‡â–†â–†â–‚â–†â–†â–ƒâ–†â–†â–†â–†â–„â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–„â–†â–†â–†â–„â–ˆâ–†â–…â–†
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7641
wandb: best/eval_avg_mil_loss 0.60413
wandb:  best/eval_ensemble_f1 0.7641
wandb:            eval/avg_f1 0.72747
wandb:      eval/avg_mil_loss 0.58479
wandb:       eval/ensemble_f1 0.72747
wandb:            test/avg_f1 0.75145
wandb:      test/avg_mil_loss 0.5271
wandb:       test/ensemble_f1 0.75145
wandb:           train/avg_f1 0.76009
wandb:      train/ensemble_f1 0.76009
wandb:         train/mil_loss 0.56875
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run tough-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aor4g451
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100211-aor4g451/logs
wandb: Agent Starting Run: 22lw5ons with config:
wandb: 	actor_learning_rate: 4.459821450181388e-06
wandb: 	attention_dropout_p: 0.17653166134939907
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28334569156907563
wandb: 	temperature: 1.0465501065161251
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100624-22lw5ons
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/22lw5ons
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–â–„â–†â–ˆ
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–‡â–„â–„â–…â–†â–‚â–„â–‡â–†â–†â–â–†â–…â–†â–„â–…â–…â–†â–â–â–…â–†â–…â–„â–â–â–‡â–…â–…â–…â–‚â–†â–…â–„â–…â–…â–ˆâ–…
wandb:      eval/avg_mil_loss â–„â–‡â–‡â–…â–„â–…â–„â–„â–â–ƒâ–ƒâ–‚â–‚â–„â–…â–ƒâ–‚â–†â–†â–‡â–ƒâ–†â–ˆâ–„â–„â–‚â–†â–‡â–†â–…â–‚â–â–†â–ƒâ–â–‚â–‡â–‚â–…â–‚
wandb:       eval/ensemble_f1 â–†â–ƒâ–ˆâ–…â–„â–…â–‡â–‡â–‡â–…â–†â–‡â–„â–‡â–‡â–â–†â–†â–‡â–‡â–†â–‡â–†â–„â–â–†â–‡â–„â–†â–ƒâ–…â–‡â–‚â–‡â–†â–â–…â–†â–†â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–„â–†â–†â–„â–†â–†â–ˆâ–†â–„â–†â–„â–…â–ˆâ–‡â–„â–…â–…â–…â–…â–â–…â–ƒâ–â–…â–‡â–†â–‚â–‚â–…â–„â–†â–„â–…â–†â–†â–†â–…â–„
wandb:      train/ensemble_f1 â–‡â–‡â–‡â–‚â–†â–ƒâ–†â–…â–‡â–‡â–†â–…â–…â–…â–†â–‚â–„â–„â–ˆâ–…â–†â–…â–†â–…â–â–‡â–†â–…â–‡â–ˆâ–„â–†â–…â–â–‡â–…â–†â–†â–„â–„
wandb:         train/mil_loss â–…â–„â–…â–ƒâ–‚â–…â–ƒâ–ƒâ–†â–‚â–„â–„â–ˆâ–‚â–…â–‚â–„â–„â–‚â–…â–ƒâ–ƒâ–â–„â–‚â–…â–„â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–…â–ƒâ–ƒâ–‚â–…
wandb:      train/policy_loss â–ˆâ–ƒâ–…â–…â–…â–ƒâ–â–…â–…â–…â–†â–â–â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–†â–ˆâ–…â–†â–â–…â–ƒâ–ƒâ–…â–ƒâ–ˆâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–…â–…â–â–ƒâ–…â–…â–…â–…â–†â–ƒâ–…â–…â–…â–ƒâ–…â–ˆâ–…â–…â–â–â–…â–ˆâ–…â–…â–…â–†â–â–…â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–…â–ˆâ–ƒâ–ˆâ–…â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77443
wandb: best/eval_avg_mil_loss 0.98538
wandb:  best/eval_ensemble_f1 0.77443
wandb:            eval/avg_f1 0.56167
wandb:      eval/avg_mil_loss 1.00949
wandb:       eval/ensemble_f1 0.56167
wandb:            test/avg_f1 0.54379
wandb:      test/avg_mil_loss 1.03357
wandb:       test/ensemble_f1 0.54379
wandb:           train/avg_f1 0.56794
wandb:      train/ensemble_f1 0.56794
wandb:         train/mil_loss 1.0703
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run easy-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/22lw5ons
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100624-22lw5ons/logs
wandb: Agent Starting Run: wo3fdx0q with config:
wandb: 	actor_learning_rate: 5.17797322880416e-05
wandb: 	attention_dropout_p: 0.05240537638145765
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 69
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8950853210188011
wandb: 	temperature: 3.156762757153694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100757-wo3fdx0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo3fdx0q
wandb: uploading history steps 55-68, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–â–ˆâ–…â–„â–‚â–‚â–…â–ƒâ–ƒâ–†â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–…â–ˆâ–„â–ƒâ–‚â–ƒâ–‡â–ˆâ–„â–‚â–ƒ
wandb:      eval/avg_mil_loss â–‡â–†â–ƒâ–„â–‡â–„â–…â–„â–‚â–…â–‡â–†â–ƒâ–„â–†â–„â–„â–„â–…â–„â–…â–ƒâ–‡â–„â–ƒâ–‚â–‚â–„â–â–„â–ˆâ–‚â–…â–…â–‡â–‚â–ˆâ–†â–…â–ƒ
wandb:       eval/ensemble_f1 â–â–ˆâ–â–†â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–„â–‚â–‚â–‚â–ƒâ–â–…â–‚â–ƒâ–â–ˆâ–ƒâ–„â–‚â–ƒâ–…â–ƒâ–„â–ˆâ–ƒ
wandb:           train/avg_f1 â–…â–ƒâ–â–†â–„â–…â–‡â–„â–…â–ˆâ–„â–„â–†â–…â–‡â–…â–†â–…â–†â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‡â–†â–‡â–†â–…â–…â–†â–‡â–ˆâ–‡â–„â–…â–„â–‡
wandb:      train/ensemble_f1 â–ƒâ–†â–…â–â–…â–†â–…â–ˆâ–„â–„â–…â–…â–‡â–„â–…â–†â–…â–…â–„â–„â–„â–†â–ˆâ–…â–‡â–‡â–†â–…â–…â–†â–…â–…â–ˆâ–„â–‡â–‡â–…â–„â–‡â–ˆ
wandb:         train/mil_loss â–†â–‡â–†â–†â–„â–„â–ƒâ–‚â–…â–‡â–…â–ƒâ–„â–…â–ƒâ–„â–†â–„â–ƒâ–ˆâ–†â–„â–ƒâ–ƒâ–â–ƒâ–…â–„â–…â–‚â–â–…â–ƒâ–‚â–„â–„â–…â–‚â–„â–‚
wandb:      train/policy_loss â–…â–…â–…â–ƒâ–…â–…â–ƒâ–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–‚â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78649
wandb: best/eval_avg_mil_loss 1.00507
wandb:  best/eval_ensemble_f1 0.78649
wandb:            eval/avg_f1 0.59394
wandb:      eval/avg_mil_loss 0.86418
wandb:       eval/ensemble_f1 0.59394
wandb:           train/avg_f1 0.63156
wandb:      train/ensemble_f1 0.63156
wandb:         train/mil_loss 0.8331
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run whole-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wo3fdx0q
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100757-wo3fdx0q/logs
wandb: ERROR Run wo3fdx0q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 76l4i06o with config:
wandb: 	actor_learning_rate: 0.0008817483315671197
wandb: 	attention_dropout_p: 0.31914139552335596
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 83
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4312980041339616
wandb: 	temperature: 0.17991670590482456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_100921-76l4i06o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/76l4i06o
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–…â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–„â–ƒâ–„â–â–ˆâ–‚
wandb:  best/eval_ensemble_f1 â–â–â–„â–…â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–â–„â–„â–„â–„â–„â–„â–†â–„â–…â–„â–‡â–†â–„â–…â–‡â–„â–†â–…â–†â–„â–…â–†â–…â–ƒâ–ƒâ–„â–…â–‡â–…â–…â–‡â–…â–„â–…â–ˆâ–ˆâ–ˆâ–†
wandb:      eval/avg_mil_loss â–‡â–‡â–„â–…â–„â–ƒâ–ƒâ–…â–…â–ƒâ–‡â–„â–â–ƒâ–‡â–ƒâ–‡â–†â–ˆâ–…â–†â–ƒâ–‡â–†â–‚â–‡â–…â–ˆâ–„â–…â–‡â–ƒâ–ƒâ–‚â–…â–„â–„â–‚â–â–„
wandb:       eval/ensemble_f1 â–„â–â–„â–„â–„â–„â–„â–…â–„â–‡â–„â–„â–†â–…â–„â–†â–…â–„â–…â–…â–†â–…â–…â–†â–ƒâ–ƒâ–„â–†â–…â–…â–„â–…â–…â–†â–†â–ˆâ–ˆâ–ˆâ–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–†â–„â–â–ƒâ–ƒâ–ƒâ–‚â–„â–â–…â–„â–‡â–„â–„â–…â–…â–…â–…â–‚â–„â–„â–…â–…â–…â–‡â–†â–‡â–…â–…â–‡â–†â–†â–†â–„â–‡â–‡â–‡â–†â–ˆ
wandb:      train/ensemble_f1 â–„â–†â–â–ƒâ–‚â–â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–„â–„â–†â–…â–ƒâ–‚â–†â–…â–†â–†â–…â–…â–…â–‡â–„â–…â–…â–†â–†â–†â–†â–„â–‡â–‡â–‡â–…â–ˆ
wandb:         train/mil_loss â–†â–„â–‡â–…â–‡â–†â–ƒâ–‡â–„â–†â–…â–‡â–…â–†â–†â–†â–†â–…â–…â–†â–„â–…â–…â–†â–ƒâ–ˆâ–‚â–…â–…â–„â–‚â–„â–‚â–„â–â–‡â–„â–â–ƒâ–„
wandb:      train/policy_loss â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–‡â–…â–â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–‡â–…â–…â–…â–†â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71847
wandb: best/eval_avg_mil_loss 0.81858
wandb:  best/eval_ensemble_f1 0.71847
wandb:            eval/avg_f1 0.61665
wandb:      eval/avg_mil_loss 0.85955
wandb:       eval/ensemble_f1 0.61665
wandb:            test/avg_f1 0.65051
wandb:      test/avg_mil_loss 0.62246
wandb:       test/ensemble_f1 0.65051
wandb:           train/avg_f1 0.67088
wandb:      train/ensemble_f1 0.67088
wandb:         train/mil_loss 0.69717
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fluent-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/76l4i06o
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_100921-76l4i06o/logs
wandb: Agent Starting Run: th2ec5h8 with config:
wandb: 	actor_learning_rate: 0.00015831497676235058
wandb: 	attention_dropout_p: 0.39184270339945304
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 101
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34051967122088267
wandb: 	temperature: 1.9071523752938944
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101059-th2ec5h8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/th2ec5h8
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–ƒâ–„â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–â–ƒâ–â–ˆâ–‚â–„â–ƒ
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–ƒâ–„â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–…â–„â–…â–…â–†â–â–ˆâ–„â–„â–…â–„â–…â–…â–…â–…â–…â–…â–‚â–‚â–„â–„â–ˆâ–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–ƒâ–†â–†â–†â–…
wandb:      eval/avg_mil_loss â–…â–„â–„â–…â–ˆâ–„â–„â–…â–…â–†â–â–‡â–„â–„â–ƒâ–†â–‡â–„â–„â–…â–…â–„â–ƒâ–…â–„â–ƒâ–†â–…â–‡â–…â–„â–„â–‚â–…â–„â–„â–„â–â–‡â–…
wandb:       eval/ensemble_f1 â–„â–„â–â–„â–…â–…â–…â–„â–†â–„â–â–†â–…â–…â–„â–„â–â–„â–„â–ˆâ–†â–…â–ƒâ–…â–„â–…â–…â–„â–†â–…â–†â–†â–…â–„â–†â–†â–‚â–†â–â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–‚â–…â–ƒâ–†â–ƒâ–‡â–…â–…â–‡â–ƒâ–„â–ƒâ–…â–‡â–†â–„â–ƒâ–†â–†â–â–„â–…â–‡â–‡â–…â–‡â–…â–…â–ˆâ–ˆâ–†â–…â–‡â–‡â–‡â–ˆâ–‡â–†â–‡
wandb:      train/ensemble_f1 â–‚â–ƒâ–„â–…â–‚â–…â–‡â–†â–„â–ƒâ–†â–…â–â–…â–„â–„â–…â–…â–†â–‡â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–†â–…â–…â–†â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–‡
wandb:         train/mil_loss â–…â–…â–„â–„â–ˆâ–ˆâ–…â–†â–ƒâ–„â–‡â–‚â–ˆâ–†â–†â–†â–…â–„â–…â–„â–†â–†â–ƒâ–…â–„â–ƒâ–‚â–…â–…â–„â–…â–…â–ˆâ–‚â–‚â–…â–ƒâ–…â–â–
wandb:      train/policy_loss â–â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74684
wandb: best/eval_avg_mil_loss 0.98602
wandb:  best/eval_ensemble_f1 0.74684
wandb:            eval/avg_f1 0.58809
wandb:      eval/avg_mil_loss 0.98279
wandb:       eval/ensemble_f1 0.58809
wandb:            test/avg_f1 0.54745
wandb:      test/avg_mil_loss 0.58708
wandb:       test/ensemble_f1 0.54745
wandb:           train/avg_f1 0.62406
wandb:      train/ensemble_f1 0.62406
wandb:         train/mil_loss 0.78659
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fresh-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/th2ec5h8
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101059-th2ec5h8/logs
wandb: Agent Starting Run: lm92krkm with config:
wandb: 	actor_learning_rate: 5.811517423595428e-05
wandb: 	attention_dropout_p: 0.39593681655695057
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5972251448453461
wandb: 	temperature: 7.935357273651864
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101258-lm92krkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lm92krkm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–…â–ˆâ–„â–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–…â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–â–ƒâ–„â–†â–ƒâ–„â–…â–…â–„â–…â–„â–ƒâ–†â–…â–„â–†â–‡â–„â–„â–†â–‡â–…â–ˆ
wandb:      eval/avg_mil_loss â–„â–„â–„â–„â–„â–„â–†â–„â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–…â–ƒâ–‚â–‚â–ƒâ–ˆâ–â–„â–
wandb:       eval/ensemble_f1 â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–†â–ƒâ–„â–†â–„â–…â–…â–‡â–„â–„â–†â–…â–‡â–…â–…â–…â–‡â–†â–‡â–†â–‡â–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–…â–…â–…â–…â–†â–‡â–…â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:      train/ensemble_f1 â–â–â–‚â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–„â–„â–…â–„â–‡â–†â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–ˆ
wandb:         train/mil_loss â–…â–…â–…â–…â–…â–†â–ˆâ–†â–†â–†â–…â–…â–…â–…â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–„â–„â–‡â–‚â–„â–‚â–„â–ƒâ–‡â–‚â–‚â–
wandb:      train/policy_loss â–â–ƒâ–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74559
wandb: best/eval_avg_mil_loss 0.62636
wandb:  best/eval_ensemble_f1 0.74559
wandb:            eval/avg_f1 0.6858
wandb:      eval/avg_mil_loss 0.85493
wandb:       eval/ensemble_f1 0.6858
wandb:            test/avg_f1 0.74243
wandb:      test/avg_mil_loss 0.52692
wandb:       test/ensemble_f1 0.74243
wandb:           train/avg_f1 0.71173
wandb:      train/ensemble_f1 0.71173
wandb:         train/mil_loss 0.62155
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run blooming-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lm92krkm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101258-lm92krkm/logs
wandb: Agent Starting Run: frjgpc1p with config:
wandb: 	actor_learning_rate: 0.00013654830006410289
wandb: 	attention_dropout_p: 0.1644646655841045
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5372934480379667
wandb: 	temperature: 6.359807617048218
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101635-frjgpc1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/b47tidcn
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frjgpc1p
wandb: uploading history steps 165-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‚â–ƒâ–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–„â–†â–…â–ˆâ–†â–†â–†â–†â–…â–†â–„â–‡â–‡â–â–…â–†â–†â–‡â–ˆâ–‡â–†â–†â–ˆâ–‡â–‚â–†â–…â–‚â–‡â–†â–ƒâ–†â–ˆâ–†â–…â–‡â–†â–†â–‡
wandb:      eval/avg_mil_loss â–…â–…â–…â–„â–ƒâ–â–…â–„â–ƒâ–†â–…â–ƒâ–â–‚â–„â–‚â–„â–ƒâ–ƒâ–…â–…â–…â–„â–„â–ƒâ–ˆâ–„â–†â–…â–„â–„â–ƒâ–ƒâ–„â–‚â–‚â–„â–„â–‚â–
wandb:       eval/ensemble_f1 â–â–‡â–…â–…â–†â–…â–…â–…â–‡â–…â–†â–†â–†â–†â–ˆâ–†â–…â–‚â–ˆâ–†â–‡â–‡â–„â–…â–…â–†â–‡â–‚â–…â–ˆâ–‡â–†â–…â–†â–…â–†â–†â–‡â–‡â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ƒâ–†â–†â–„â–‡â–…â–†â–†â–ˆâ–„â–…â–†â–ƒâ–…â–…â–…â–ƒâ–†â–†â–…â–…â–‡â–†â–ˆâ–†â–„â–…â–‡â–…â–…â–†â–„â–„â–„â–…â–…â–â–…â–…
wandb:      train/ensemble_f1 â–‡â–‡â–…â–ƒâ–†â–‡â–‡â–„â–‡â–„â–…â–„â–†â–‡â–„â–„â–…â–…â–ˆâ–‡â–…â–„â–†â–‡â–„â–…â–†â–†â–…â–…â–‡â–†â–„â–ˆâ–†â–…â–†â–…â–â–…
wandb:         train/mil_loss â–ƒâ–ˆâ–†â–†â–‡â–…â–‡â–…â–‡â–†â–…â–…â–„â–ƒâ–‡â–ˆâ–†â–†â–ƒâ–†â–†â–‡â–„â–…â–„â–…â–†â–„â–‚â–‚â–‚â–„â–ƒâ–†â–ˆâ–â–ƒâ–…â–ƒâ–…
wandb:      train/policy_loss â–â–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80047
wandb: best/eval_avg_mil_loss 0.82341
wandb:  best/eval_ensemble_f1 0.80047
wandb:            eval/avg_f1 0.57961
wandb:      eval/avg_mil_loss 0.78084
wandb:       eval/ensemble_f1 0.57961
wandb:            test/avg_f1 0.69104
wandb:      test/avg_mil_loss 0.59887
wandb:       test/ensemble_f1 0.69104
wandb:           train/avg_f1 0.63647
wandb:      train/ensemble_f1 0.63647
wandb:         train/mil_loss 1.0499
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/frjgpc1p
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101635-frjgpc1p/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 8xy37jb7 with config:
wandb: 	actor_learning_rate: 0.00020311083779030905
wandb: 	attention_dropout_p: 0.33910018273922893
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9072957464043128
wandb: 	temperature: 1.2277324820491742
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102018-8xy37jb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8xy37jb7
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–„â–‡â–ˆâ–‡â–‚â–„â–ˆâ–‡â–†â–ˆâ–ˆâ–ƒâ–ˆâ–‚â–ˆâ–‡â–‚â–ƒâ–â–„â–„â–ˆâ–‡â–ˆâ–„â–†â–‚â–ˆâ–ˆâ–„â–†â–â–‚â–‡â–â–‚â–‚â–â–ˆ
wandb:      eval/avg_mil_loss â–ƒâ–…â–†â–„â–ƒâ–„â–ƒâ–ˆâ–ƒâ–†â–‡â–â–ˆâ–ƒâ–†â–†â–ƒâ–ƒâ–„â–„â–„â–†â–…â–…â–ƒâ–„â–…â–…â–ˆâ–ƒâ–†â–†â–†â–â–…â–„â–†â–„â–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–„â–‡â–‡â–†â–„â–‡â–†â–‚â–‡â–‚â–â–‡â–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–â–‚â–„â–â–‡â–ˆâ–‡â–„â–‡â–‡â–†â–‚â–‚â–ˆâ–‡â–â–â–‚â–‚â–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–‡â–‚â–…â–ƒâ–ˆâ–ˆâ–†â–â–…â–…â–†â–†â–‚â–…â–„â–ƒâ–†â–ƒâ–ˆâ–…â–ƒâ–†â–†â–†â–ƒâ–…â–‚â–‡â–„â–ˆâ–„â–‡â–…â–†â–ƒâ–‡â–†â–…
wandb:      train/ensemble_f1 â–…â–„â–…â–ƒâ–ˆâ–‡â–†â–‡â–†â–…â–†â–…â–‡â–†â–†â–…â–ˆâ–…â–…â–…â–†â–‡â–ˆâ–†â–„â–†â–†â–…â–…â–„â–„â–ˆâ–…â–…â–†â–†â–â–ƒâ–ˆâ–…
wandb:         train/mil_loss â–„â–ƒâ–ƒâ–â–…â–ƒâ–„â–ƒâ–„â–†â–†â–†â–…â–†â–„â–ƒâ–ƒâ–…â–„â–‡â–ƒâ–…â–‡â–…â–‚â–†â–„â–â–ˆâ–…â–ƒâ–ƒâ–‡â–„â–„â–…â–‚â–‚â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77957
wandb: best/eval_avg_mil_loss 0.67757
wandb:  best/eval_ensemble_f1 0.77957
wandb:            eval/avg_f1 0.75488
wandb:      eval/avg_mil_loss 0.8145
wandb:       eval/ensemble_f1 0.75488
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.18298
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.56129
wandb:      train/ensemble_f1 0.56129
wandb:         train/mil_loss 0.82421
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run serene-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8xy37jb7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102018-8xy37jb7/logs
wandb: Agent Starting Run: cw993lup with config:
wandb: 	actor_learning_rate: 1.893631630209292e-06
wandb: 	attention_dropout_p: 0.21591566646620064
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8771605705265287
wandb: 	temperature: 2.6726849020722887
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102212-cw993lup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cw993lup
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ˆâ–â–„
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–…â–ˆâ–†â–…â–…â–†â–‡â–‡â–ˆâ–…â–†â–‡â–„â–…â–†â–†â–…â–†â–‡â–…â–„â–…â–†â–‡â–‡â–„â–„â–â–†â–†â–…â–â–‡â–…â–‡â–ˆâ–‡â–‡â–†
wandb:      eval/avg_mil_loss â–„â–…â–„â–…â–…â–ƒâ–…â–„â–ƒâ–‡â–…â–„â–‡â–ˆâ–…â–†â–‡â–†â–†â–ˆâ–‚â–„â–†â–†â–„â–ƒâ–â–„â–„â–â–ˆâ–‚â–…â–„â–„â–ƒâ–‚â–„â–‚â–…
wandb:       eval/ensemble_f1 â–…â–…â–ˆâ–†â–‡â–†â–…â–†â–‡â–ˆâ–†â–‡â–†â–†â–‡â–„â–‡â–†â–…â–‡â–â–…â–‡â–‡â–„â–„â–„â–„â–‡â–†â–†â–…â–â–†â–‡â–‡â–…â–ˆâ–…â–‡
wandb:           train/avg_f1 â–ƒâ–…â–†â–…â–‚â–…â–…â–„â–…â–ƒâ–…â–†â–†â–‡â–ƒâ–…â–†â–…â–†â–…â–…â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–…â–„â–„â–â–„â–„â–†â–†â–ƒâ–‡â–ˆâ–…â–…
wandb:      train/ensemble_f1 â–‚â–†â–â–‡â–‚â–†â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–†â–†â–†â–‚â–…â–†â–ƒâ–ƒâ–†â–„â–â–…â–ƒâ–„â–‚â–…â–„â–ˆâ–†â–ˆâ–†â–†â–ƒâ–„
wandb:         train/mil_loss â–„â–„â–…â–„â–…â–†â–‡â–‡â–…â–…â–‚â–ˆâ–„â–‚â–‡â–…â–…â–„â–…â–…â–„â–ƒâ–ƒâ–†â–…â–…â–‡â–â–ƒâ–…â–…â–„â–„â–„â–…â–…â–„â–†â–„â–ˆ
wandb:      train/policy_loss â–â–â–ˆâ–…â–…â–…â–â–ˆâ–…â–…â–â–…â–â–…â–…â–…â–…â–…â–â–…â–â–…â–…â–…â–ˆâ–…â–…â–…â–â–â–…â–…â–â–â–…â–ˆâ–…â–ˆâ–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–ˆâ–ˆâ–â–„â–„â–„â–â–â–„â–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–ˆâ–„â–†â–„â–„â–â–„â–„â–„â–„â–„â–â–ˆâ–„â–„â–„â–„â–ˆâ–„â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7504
wandb: best/eval_avg_mil_loss 0.68252
wandb:  best/eval_ensemble_f1 0.7504
wandb:            eval/avg_f1 0.73027
wandb:      eval/avg_mil_loss 0.75062
wandb:       eval/ensemble_f1 0.73027
wandb:           train/avg_f1 0.6454
wandb:      train/ensemble_f1 0.6454
wandb:         train/mil_loss 0.74013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run woven-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cw993lup
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102212-cw993lup/logs
wandb: ERROR Run cw993lup errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jcnkjsxe with config:
wandb: 	actor_learning_rate: 0.0005680480528232748
wandb: 	attention_dropout_p: 0.4349626880982901
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.831123323424398
wandb: 	temperature: 6.742113577677533
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102421-jcnkjsxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jcnkjsxe
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–…â–…â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–‡â–ˆâ–…â–‚â–â–â–‡â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–…â–…â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–†â–ˆâ–â–‡â–‡â–ˆâ–†â–‡â–†â–‡â–ˆâ–†â–ˆâ–‡â–†â–ˆâ–‡â–‡â–‡â–…â–…â–„â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–‡â–„â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–†â–…â–†â–†â–†â–ˆâ–…â–†â–†â–†â–…â–†â–†â–„â–…â–†â–„â–†â–†â–†â–…â–ƒâ–…â–…â–…â–ƒâ–…â–…â–â–…â–…â–†â–†â–â–…â–‚â–…â–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–‡â–ˆâ–â–‡â–‡â–‡â–‡â–‡â–‡â–„â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–…â–„â–‡â–‡â–ˆâ–‡â–‡â–‚â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ƒ
wandb:           train/avg_f1 â–‡â–„â–†â–„â–…â–†â–†â–†â–…â–…â–ˆâ–ˆâ–„â–„â–‡â–„â–…â–ƒâ–†â–‡â–ƒâ–ƒâ–…â–†â–…â–„â–„â–„â–‡â–„â–†â–†â–ˆâ–ƒâ–‡â–…â–ˆâ–â–‡â–‚
wandb:      train/ensemble_f1 â–…â–†â–†â–ƒâ–„â–†â–ƒâ–„â–„â–†â–†â–‡â–…â–…â–„â–…â–‚â–†â–ƒâ–„â–„â–†â–„â–‡â–ƒâ–…â–†â–…â–…â–‡â–†â–ˆâ–„â–‡â–ƒâ–â–†â–ƒâ–„â–†
wandb:         train/mil_loss â–†â–„â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‡â–ƒâ–‚â–†â–ƒâ–‚â–ˆâ–‡â–„â–„â–‚â–†â–„â–„â–†â–„â–„â–‚â–‚â–â–…â–ƒâ–‚â–‚â–‚â–…â–„â–…
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81824
wandb: best/eval_avg_mil_loss 0.4775
wandb:  best/eval_ensemble_f1 0.81824
wandb:            eval/avg_f1 0.50888
wandb:      eval/avg_mil_loss 0.9676
wandb:       eval/ensemble_f1 0.50888
wandb:           train/avg_f1 0.74377
wandb:      train/ensemble_f1 0.74377
wandb:         train/mil_loss 0.68308
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rural-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jcnkjsxe
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102421-jcnkjsxe/logs
wandb: ERROR Run jcnkjsxe errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mid3z3f1 with config:
wandb: 	actor_learning_rate: 0.0004224427707664127
wandb: 	attention_dropout_p: 0.3654207629456081
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7965465166014982
wandb: 	temperature: 0.24889894312098315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102748-mid3z3f1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mid3z3f1
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 61-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–„â–„â–…â–‡â–†â–ˆâ–‡â–‡â–ˆâ–„â–‡â–‡â–‡â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–„â–‡â–„â–‡â–‡â–ˆâ–‡â–â–‡â–†
wandb:      eval/avg_mil_loss â–…â–ˆâ–…â–†â–‡â–‚â–‚â–‚â–…â–‚â–ƒâ–…â–…â–‡â–‚â–…â–‚â–ƒâ–„â–‚â–â–…â–‚â–†â–‚â–„â–ƒâ–‚â–„â–‚â–‡â–„â–…â–„â–†â–…â–â–ƒâ–ˆâ–„
wandb:       eval/ensemble_f1 â–‡â–ˆâ–„â–„â–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–„â–‡â–„â–‡â–â–â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡â–„â–‡â–‡â–ˆâ–‡â–‡â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–…â–…â–‡â–…â–†â–„â–…â–„â–…â–…â–„â–â–„â–…â–†â–…â–†â–ˆâ–‚â–†â–‡â–‚â–‡â–…â–…â–ˆâ–…â–…â–…â–‡â–‡â–„â–†â–†â–†â–†â–„â–…
wandb:      train/ensemble_f1 â–…â–„â–…â–…â–…â–†â–…â–„â–ƒâ–…â–„â–ˆâ–„â–†â–â–†â–‚â–†â–„â–„â–‡â–†â–„â–…â–‡â–ƒâ–‡â–†â–…â–…â–„â–…â–‡â–„â–†â–†â–†â–†â–„â–„
wandb:         train/mil_loss â–‡â–ˆâ–ˆâ–†â–†â–…â–†â–‡â–…â–‚â–‡â–‡â–…â–‡â–‚â–…â–…â–…â–†â–„â–†â–‚â–‚â–†â–‡â–†â–‚â–…â–…â–…â–ƒâ–â–‡â–†â–‚â–„â–„â–…â–‡â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80628
wandb: best/eval_avg_mil_loss 0.60595
wandb:  best/eval_ensemble_f1 0.80628
wandb:            eval/avg_f1 0.71164
wandb:      eval/avg_mil_loss 0.89758
wandb:       eval/ensemble_f1 0.71164
wandb:            test/avg_f1 0.67486
wandb:      test/avg_mil_loss 0.57557
wandb:       test/ensemble_f1 0.67486
wandb:           train/avg_f1 0.72507
wandb:      train/ensemble_f1 0.72507
wandb:         train/mil_loss 0.76817
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mid3z3f1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102748-mid3z3f1/logs
wandb: Agent Starting Run: slrg5qyl with config:
wandb: 	actor_learning_rate: 6.338237322641096e-05
wandb: 	attention_dropout_p: 0.2877706760176988
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9361427344323094
wandb: 	temperature: 3.216494228313681
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102900-slrg5qyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/slrg5qyl
wandb: uploading wandb-summary.json
wandb: uploading history steps 76-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–†â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–„â–â–‡â–„â–ƒâ–„â–…â–„â–„â–…â–ˆâ–„â–„â–„â–„â–‡â–„â–„â–…â–‚â–…â–„â–‚â–„â–ˆâ–„â–†â–…â–‡â–„â–…â–…â–‡â–‚â–†â–‡â–…â–„â–‚â–…
wandb:      eval/avg_mil_loss â–…â–†â–…â–…â–ƒâ–ƒâ–‚â–†â–†â–„â–ƒâ–â–„â–‚â–„â–ƒâ–‚â–„â–…â–†â–‚â–„â–ƒâ–‚â–†â–…â–‚â–ˆâ–ƒâ–„â–„â–‚â–‚â–†â–â–„â–‚â–ƒâ–‚â–„
wandb:       eval/ensemble_f1 â–‡â–…â–†â–„â–â–‡â–„â–„â–ƒâ–†â–ˆâ–…â–ˆâ–ˆâ–ƒâ–ˆâ–„â–ˆâ–‚â–„â–‡â–„â–‚â–…â–‡â–…â–†â–„â–‡â–…â–…â–‡â–…â–…â–ƒâ–‡â–†â–â–‡â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‚â–„â–‚â–„â–…â–ƒâ–‚â–†â–†â–…â–ƒâ–†â–„â–‚â–ˆâ–ƒâ–†â–„â–ƒâ–ƒâ–‚â–‚â–‡â–…â–†â–â–ƒâ–…â–…â–‚â–‚â–…â–„â–„â–„â–‡â–†â–ƒ
wandb:      train/ensemble_f1 â–…â–†â–†â–†â–‚â–ˆâ–‚â–„â–…â–ƒâ–‡â–ƒâ–„â–ˆâ–…â–‡â–„â–…â–†â–‚â–ƒâ–„â–†â–â–„â–„â–†â–ˆâ–†â–‚â–ƒâ–…â–„â–…â–…â–„â–…â–ˆâ–„â–„
wandb:         train/mil_loss â–…â–‚â–ƒâ–„â–…â–…â–…â–‚â–‚â–ƒâ–‚â–…â–„â–…â–â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–„â–„â–â–…â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–†â–„â–†â–„â–‡â–„â–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78695
wandb: best/eval_avg_mil_loss 0.62593
wandb:  best/eval_ensemble_f1 0.78695
wandb:            eval/avg_f1 0.55534
wandb:      eval/avg_mil_loss 0.92564
wandb:       eval/ensemble_f1 0.55534
wandb:            test/avg_f1 0.82526
wandb:      test/avg_mil_loss 0.65193
wandb:       test/ensemble_f1 0.82526
wandb:           train/avg_f1 0.60614
wandb:      train/ensemble_f1 0.60614
wandb:         train/mil_loss 0.75848
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run likely-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/slrg5qyl
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102900-slrg5qyl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a36mq69l with config:
wandb: 	actor_learning_rate: 1.1389240205608054e-06
wandb: 	attention_dropout_p: 0.3963841618632497
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7512265660344656
wandb: 	temperature: 9.27225327120913
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103044-a36mq69l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-6
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a36mq69l
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–„â–ƒâ–â–ƒâ–„â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–†â–†â–‡â–„â–„â–‡â–‡â–‡â–‡â–‡â–‡â–†â–„â–†â–‡â–‡â–‡â–„â–‡â–‡â–‡â–ˆâ–‡â–„â–‡â–‡â–†â–…â–ƒâ–â–ˆâ–†â–„â–„â–†â–‡
wandb:      eval/avg_mil_loss â–…â–…â–ƒâ–…â–ˆâ–ƒâ–‡â–ƒâ–‚â–ƒâ–†â–†â–ƒâ–‚â–‡â–„â–‡â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ˆâ–„â–‚â–â–„â–ƒâ–†â–†â–‡â–ƒâ–‡â–‚â–†â–†â–ƒ
wandb:       eval/ensemble_f1 â–„â–…â–‡â–…â–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–„â–‡â–…â–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–…â–…â–‡â–‡â–ˆâ–…â–â–‡â–â–ˆâ–„â–‡â–‡â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–ˆâ–…â–ƒâ–†â–„â–„â–ƒâ–†â–ƒâ–†â–„â–‚â–ƒâ–„â–…â–‡â–…â–â–…â–…â–…â–‡â–‡â–…â–‡â–„â–„â–„â–‡â–†â–…â–…â–†â–†â–†â–…â–„â–‡â–…
wandb:      train/ensemble_f1 â–‡â–…â–…â–…â–ƒâ–„â–…â–…â–„â–ƒâ–„â–ˆâ–‚â–…â–„â–…â–„â–…â–†â–†â–…â–„â–…â–ƒâ–ƒâ–†â–„â–â–†â–ƒâ–„â–…â–…â–…â–‡â–„â–…â–…â–„â–„
wandb:         train/mil_loss â–„â–‡â–‚â–…â–…â–„â–†â–„â–â–„â–ƒâ–†â–…â–‡â–„â–…â–…â–†â–„â–…â–„â–ˆâ–†â–†â–†â–„â–…â–…â–…â–ƒâ–„â–…â–…â–ƒâ–„â–ƒâ–…â–„â–‡â–†
wandb:      train/policy_loss â–„â–„â–„â–â–„â–â–„â–„â–„â–„â–†â–â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–„â–â–ˆâ–„â–„â–„â–â–ˆâ–„â–„â–â–„â–ˆâ–ˆâ–„â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–â–„â–â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–„â–„â–â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78162
wandb: best/eval_avg_mil_loss 0.79629
wandb:  best/eval_ensemble_f1 0.78162
wandb:            eval/avg_f1 0.6383
wandb:      eval/avg_mil_loss 0.87586
wandb:       eval/ensemble_f1 0.6383
wandb:            test/avg_f1 0.79791
wandb:      test/avg_mil_loss 0.42809
wandb:       test/ensemble_f1 0.79791
wandb:           train/avg_f1 0.69368
wandb:      train/ensemble_f1 0.69368
wandb:         train/mil_loss 0.72742
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a36mq69l
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103044-a36mq69l/logs
wandb: Agent Starting Run: a4gw1lba with config:
wandb: 	actor_learning_rate: 2.682785858931994e-06
wandb: 	attention_dropout_p: 0.25917499839834296
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15603559906809228
wandb: 	temperature: 1.6176800453267104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103222-a4gw1lba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-7
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a4gw1lba
wandb: uploading history steps 167-180, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–…â–…â–…â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–„â–„â–„â–…â–„â–†â–…â–„â–…â–„â–„â–†â–„â–„â–„â–„â–ˆâ–ƒâ–†â–„â–‡â–ƒâ–†â–†â–„â–…â–‡â–ƒâ–†â–ƒâ–†â–„â–…â–†â–„â–†â–†â–â–ƒâ–„
wandb:      eval/avg_mil_loss â–†â–†â–‚â–„â–„â–†â–…â–†â–…â–…â–‡â–†â–‚â–‡â–†â–‡â–†â–†â–‡â–ƒâ–†â–†â–‡â–‚â–‡â–„â–‡â–‡â–‚â–„â–‡â–ƒâ–„â–„â–…â–â–…â–…â–ˆâ–‚
wandb:       eval/ensemble_f1 â–…â–…â–…â–…â–…â–…â–„â–†â–‡â–‡â–…â–â–ˆâ–…â–‡â–…â–…â–‡â–…â–…â–„â–…â–…â–…â–†â–„â–‡â–…â–â–…â–†â–ˆâ–‡â–„â–â–†â–…â–ˆâ–‡â–…
wandb:           train/avg_f1 â–‚â–‚â–â–…â–„â–ƒâ–„â–„â–†â–…â–ƒâ–‚â–â–‚â–†â–…â–†â–ƒâ–…â–ƒâ–…â–â–…â–†â–ƒâ–ˆâ–…â–„â–ƒâ–„â–ƒâ–„â–†â–…â–…â–…â–ƒâ–†â–â–ƒ
wandb:      train/ensemble_f1 â–…â–ƒâ–„â–ƒâ–‡â–„â–…â–ƒâ–„â–„â–„â–‚â–„â–‡â–‚â–ƒâ–„â–†â–†â–â–„â–‡â–†â–…â–†â–…â–†â–„â–ˆâ–„â–„â–„â–ƒâ–ƒâ–„â–…â–„â–„â–‡â–†
wandb:         train/mil_loss â–…â–…â–…â–„â–…â–„â–ƒâ–„â–ƒâ–ƒâ–„â–…â–…â–„â–…â–‚â–„â–‚â–ƒâ–…â–ƒâ–â–‚â–†â–„â–…â–…â–ƒâ–‚â–ƒâ–â–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–„â–…
wandb:      train/policy_loss â–„â–ˆâ–ˆâ–ˆâ–â–„â–ˆâ–„â–ˆâ–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–ˆâ–„â–ƒâ–ˆâ–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–â–†â–„â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–â–…â–…â–…â–ˆâ–â–…â–â–…â–â–…â–…â–ˆâ–…â–â–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79577
wandb: best/eval_avg_mil_loss 0.64621
wandb:  best/eval_ensemble_f1 0.79577
wandb:            eval/avg_f1 0.56785
wandb:      eval/avg_mil_loss 0.98194
wandb:       eval/ensemble_f1 0.56785
wandb:           train/avg_f1 0.63406
wandb:      train/ensemble_f1 0.63406
wandb:         train/mil_loss 0.84669
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run wobbly-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a4gw1lba
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103222-a4gw1lba/logs
wandb: ERROR Run a4gw1lba errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sqbcexpv with config:
wandb: 	actor_learning_rate: 0.0004367040989125103
wandb: 	attention_dropout_p: 0.3841427345701155
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8039484354491085
wandb: 	temperature: 3.4319020168379257
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103605-sqbcexpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-8
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sqbcexpv
wandb: uploading wandb-summary.json
wandb: uploading history steps 74-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–‡â–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–‡â–‡â–…â–‡â–„â–†â–‡â–‡â–„â–†â–‡â–‚â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–‡â–â–ˆâ–…â–‡â–‡â–‡â–â–ˆâ–‡â–†â–‡â–‡â–‡â–‚â–â–†â–‚â–‡â–†
wandb:      eval/avg_mil_loss â–†â–†â–ƒâ–…â–…â–‡â–…â–…â–‚â–…â–‡â–ƒâ–„â–„â–†â–ˆâ–…â–…â–†â–‚â–„â–„â–„â–„â–ˆâ–…â–„â–…â–â–…â–‡â–„â–†â–„â–‚â–‚â–ˆâ–…â–‡â–‚
wandb:       eval/ensemble_f1 â–†â–ˆâ–‡â–ƒâ–„â–‡â–„â–â–‡â–ˆâ–‡â–‡â–â–…â–‡â–„â–â–‡â–ˆâ–ƒâ–‡â–„â–‡â–†â–‡â–‡â–â–ˆâ–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–â–‡â–‡â–â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–…â–…â–…â–ƒâ–„â–…â–‡â–‚â–…â–…â–‡â–†â–„â–ˆâ–â–…â–†â–†â–„â–„â–…â–†â–†â–…â–‚â–‡â–â–ƒâ–†â–„â–„â–„â–„â–„â–„â–ƒâ–„â–…â–„
wandb:      train/ensemble_f1 â–â–‚â–ƒâ–†â–…â–„â–ƒâ–†â–„â–†â–‡â–‚â–†â–‡â–†â–†â–†â–â–‡â–„â–†â–…â–ƒâ–…â–†â–…â–â–‚â–†â–…â–…â–„â–‡â–ƒâ–„â–ˆâ–…â–„â–ƒâ–
wandb:         train/mil_loss â–…â–„â–ƒâ–†â–ƒâ–ƒâ–…â–„â–…â–ƒâ–â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–†â–„â–ˆâ–†â–„â–ƒâ–…â–„â–‚â–„â–†â–„â–‚â–â–„â–…â–ƒâ–…â–ƒâ–ƒâ–„â–„â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80127
wandb: best/eval_avg_mil_loss 0.61182
wandb:  best/eval_ensemble_f1 0.80127
wandb:            eval/avg_f1 0.6516
wandb:      eval/avg_mil_loss 1.00329
wandb:       eval/ensemble_f1 0.6516
wandb:            test/avg_f1 0.76277
wandb:      test/avg_mil_loss 0.53452
wandb:       test/ensemble_f1 0.76277
wandb:           train/avg_f1 0.6753
wandb:      train/ensemble_f1 0.6753
wandb:         train/mil_loss 0.70634
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glorious-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sqbcexpv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103605-sqbcexpv/logs
wandb: Agent Starting Run: kahyebl5 with config:
wandb: 	actor_learning_rate: 0.0006125561113135179
wandb: 	attention_dropout_p: 0.06533753799707309
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.894747562107777
wandb: 	temperature: 2.8042131623730726
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103742-kahyebl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-9
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kahyebl5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–‡â–„â–…â–„â–„â–‡â–ƒâ–…â–‡â–ˆâ–‡â–…â–†â–…â–„â–†â–†â–†â–â–ˆâ–ˆâ–„â–„â–ƒâ–â–‡â–…â–‡â–ˆâ–†â–‡â–…â–†â–…â–†â–†â–…â–‡
wandb:      eval/avg_mil_loss â–„â–†â–ƒâ–†â–…â–†â–ƒâ–‚â–‚â–…â–…â–„â–‚â–†â–†â–ƒâ–ƒâ–‚â–â–‚â–‚â–„â–†â–ˆâ–„â–†â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–…â–…â–„â–ƒâ–„â–
wandb:       eval/ensemble_f1 â–†â–†â–„â–…â–„â–†â–„â–‡â–‡â–‡â–ˆâ–‡â–†â–†â–…â–†â–„â–„â–†â–‡â–‡â–†â–ˆâ–„â–‡â–…â–„â–…â–â–â–‡â–…â–…â–†â–‡â–„â–†â–…â–…â–‡
wandb:           train/avg_f1 â–‚â–‚â–„â–â–ƒâ–„â–„â–‚â–†â–„â–ƒâ–…â–…â–„â–†â–„â–â–…â–…â–†â–ƒâ–ˆâ–…â–„â–‡â–…â–…â–ˆâ–‡â–„â–ˆâ–†â–†â–†â–†â–…â–…â–†â–…â–‚
wandb:      train/ensemble_f1 â–â–â–„â–ƒâ–„â–†â–†â–…â–ƒâ–„â–…â–„â–ƒâ–„â–ƒâ–„â–‚â–†â–ˆâ–ˆâ–„â–‚â–†â–„â–„â–‡â–‡â–„â–…â–‡â–†â–†â–…â–‚â–„â–„â–ƒâ–â–…â–ˆ
wandb:         train/mil_loss â–„â–…â–ƒâ–„â–„â–‚â–‚â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ˆâ–‚â–‚â–ƒâ–ƒâ–„â–â–â–…â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–â–‚â–ƒâ–
wandb:      train/policy_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7712
wandb: best/eval_avg_mil_loss 0.67532
wandb:  best/eval_ensemble_f1 0.7712
wandb:            eval/avg_f1 0.74429
wandb:      eval/avg_mil_loss 0.65602
wandb:       eval/ensemble_f1 0.74429
wandb:           train/avg_f1 0.74995
wandb:      train/ensemble_f1 0.74995
wandb:         train/mil_loss 0.66913
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kahyebl5
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103742-kahyebl5/logs
wandb: ERROR Run kahyebl5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 08ya5gsp with config:
wandb: 	actor_learning_rate: 3.168213634149289e-05
wandb: 	attention_dropout_p: 0.4303203524861222
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5582455201494523
wandb: 	temperature: 5.424779417423371
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103919-08ya5gsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-10
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/08ya5gsp
wandb: uploading wandb-summary.json
wandb: uploading history steps 149-159, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–ƒâ–ˆâ–…â–‚â–â–â–
wandb:  best/eval_ensemble_f1 â–â–‚â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–‚â–…â–„â–ƒâ–„â–‚â–ƒâ–‚â–…â–…â–…â–ƒâ–„â–„â–‚â–‡â–ƒâ–ƒâ–…â–ƒâ–„â–…â–ƒâ–‚â–‡â–ƒâ–…â–…â–ƒâ–†â–…â–†â–„â–„â–ƒâ–â–„â–ˆâ–ƒ
wandb:      eval/avg_mil_loss â–†â–†â–ˆâ–‡â–ƒâ–ƒâ–‚â–‡â–†â–‡â–†â–‡â–‡â–†â–ƒâ–…â–†â–â–†â–†â–†â–‡â–†â–â–…â–‡â–†â–ƒâ–†â–†â–‡â–†â–†â–‡â–…â–…â–„â–‡â–‡â–‡
wandb:       eval/ensemble_f1 â–‡â–†â–ˆâ–†â–‡â–†â–‡â–†â–…â–‡â–‡â–…â–â–†â–‡â–‡â–‡â–…â–†â–…â–†â–ˆâ–‡â–‚â–†â–…â–†â–…â–‡â–†â–†â–‡â–†â–†â–‡â–‡â–ˆâ–†â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–ƒâ–…â–‚â–‡â–â–„â–„â–„â–…â–‚â–„â–ˆâ–†â–…â–„â–…â–…â–†â–†â–„â–„â–ƒâ–„â–†â–…â–„â–„â–ƒâ–ˆâ–„â–†â–‡â–„â–„â–ƒâ–…â–†â–ˆâ–ƒ
wandb:      train/ensemble_f1 â–†â–‡â–ƒâ–†â–‚â–ƒâ–†â–ƒâ–„â–ˆâ–†â–…â–„â–†â–…â–†â–ƒâ–„â–…â–‚â–ƒâ–…â–‚â–„â–â–„â–â–ˆâ–„â–…â–†â–„â–‚â–„â–„â–†â–ˆâ–†â–†â–ƒ
wandb:         train/mil_loss â–„â–…â–ƒâ–ƒâ–‚â–…â–„â–â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–…â–ƒâ–…â–â–ƒâ–„â–†â–â–ƒâ–„â–…â–‚â–„â–ƒâ–„â–‚â–‡â–‚â–‚â–ƒâ–â–‚â–ˆâ–‚â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78916
wandb: best/eval_avg_mil_loss 0.85344
wandb:  best/eval_ensemble_f1 0.78916
wandb:            eval/avg_f1 0.75792
wandb:      eval/avg_mil_loss 0.89262
wandb:       eval/ensemble_f1 0.75792
wandb:            test/avg_f1 0.82996
wandb:      test/avg_mil_loss 0.29193
wandb:       test/ensemble_f1 0.82996
wandb:           train/avg_f1 0.72831
wandb:      train/ensemble_f1 0.72831
wandb:         train/mil_loss 0.69059
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pretty-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/08ya5gsp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103919-08ya5gsp/logs
wandb: Agent Starting Run: elzooic9 with config:
wandb: 	actor_learning_rate: 0.0009477663284922084
wandb: 	attention_dropout_p: 0.3087695026447319
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7503315518219895
wandb: 	temperature: 8.090694317856492
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104204-elzooic9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-11
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/elzooic9
wandb: uploading wandb-summary.json
wandb: uploading history steps 75-85, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–‡â–‡â–‡â–â–†â–â–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–‡â–â–‡â–†â–‡â–‡â–„â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:      eval/avg_mil_loss â–‚â–„â–…â–…â–„â–…â–„â–„â–†â–‚â–†â–…â–‚â–ˆâ–…â–…â–„â–…â–„â–…â–ƒâ–â–„â–…â–…â–…â–†â–„â–…â–…â–‡â–…â–‡â–…â–…â–…â–…â–„â–„â–…
wandb:       eval/ensemble_f1 â–ˆâ–ˆâ–‡â–ˆâ–…â–â–‡â–‡â–‡â–‚â–‚â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:           train/avg_f1 â–„â–…â–‡â–„â–†â–†â–†â–„â–‚â–‡â–†â–†â–‚â–ƒâ–‚â–…â–„â–†â–…â–ƒâ–†â–†â–ƒâ–…â–‡â–…â–†â–„â–…â–„â–…â–â–„â–‚â–„â–…â–…â–…â–…â–ˆ
wandb:      train/ensemble_f1 â–…â–†â–‡â–‚â–…â–†â–‡â–†â–…â–‡â–â–‡â–†â–‡â–‡â–ƒâ–…â–†â–†â–„â–…â–†â–‡â–…â–‡â–ˆâ–…â–„â–†â–†â–†â–ƒâ–…â–…â–ƒâ–ƒâ–†â–†â–…â–ˆ
wandb:         train/mil_loss â–…â–…â–†â–…â–…â–†â–…â–…â–‡â–ƒâ–„â–…â–†â–…â–…â–…â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–…â–„â–†â–„â–†â–ƒâ–ƒâ–…â–‚â–‡â–…â–â–„â–„â–„â–ˆâ–ƒâ–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77954
wandb: best/eval_avg_mil_loss 0.7365
wandb:  best/eval_ensemble_f1 0.77954
wandb:            eval/avg_f1 0.72477
wandb:      eval/avg_mil_loss 0.87478
wandb:       eval/ensemble_f1 0.72477
wandb:           train/avg_f1 0.70682
wandb:      train/ensemble_f1 0.70682
wandb:         train/mil_loss 0.67262
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run clean-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/elzooic9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104204-elzooic9/logs
wandb: ERROR Run elzooic9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 37zl5i7t with config:
wandb: 	actor_learning_rate: 0.0002193306352939097
wandb: 	attention_dropout_p: 0.47669989731942886
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 55
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2633206155444541
wandb: 	temperature: 0.35399717848255796
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104338-37zl5i7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-12
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37zl5i7t
wandb: uploading wandb-summary.json
wandb: uploading history steps 45-55, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–â–†â–†â–†â–†â–†â–†â–†â–‚â–…â–†â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…
wandb:      eval/avg_mil_loss â–ˆâ–â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–…â–„â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‡â–ƒâ–ƒâ–‚â–‚â–â–‚â–ˆ
wandb:       eval/ensemble_f1 â–â–†â–†â–†â–†â–†â–†â–‚â–…â–†â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–‡â–†â–…
wandb:           train/avg_f1 â–…â–â–…â–†â–„â–‚â–‡â–„â–ƒâ–†â–‚â–‡â–†â–…â–‡â–„â–„â–…â–„â–…â–‚â–‚â–‚â–†â–…â–‚â–ˆâ–‡â–†â–…â–†â–…â–†â–‚â–‚â–…â–‡â–ƒâ–‡â–„
wandb:      train/ensemble_f1 â–…â–â–…â–ƒâ–†â–„â–‚â–‡â–†â–ƒâ–…â–†â–†â–…â–‡â–†â–„â–„â–…â–„â–…â–‚â–‚â–†â–…â–„â–‚â–ˆâ–‡â–†â–…â–†â–…â–‚â–‚â–…â–‡â–ƒâ–‡â–„
wandb:         train/mil_loss â–‚â–ƒâ–„â–ƒâ–…â–…â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–„â–ˆâ–â–‚â–â–ƒâ–„â–…â–ƒâ–â–†â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–‚â–‚â–‡
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79228
wandb: best/eval_avg_mil_loss 0.95659
wandb:  best/eval_ensemble_f1 0.79228
wandb:            eval/avg_f1 0.68706
wandb:      eval/avg_mil_loss 1.11978
wandb:       eval/ensemble_f1 0.68706
wandb:           train/avg_f1 0.69616
wandb:      train/ensemble_f1 0.69616
wandb:         train/mil_loss 0.75512
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run leafy-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37zl5i7t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104338-37zl5i7t/logs
wandb: ERROR Run 37zl5i7t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yvxdc87v with config:
wandb: 	actor_learning_rate: 6.647197319805467e-06
wandb: 	attention_dropout_p: 0.357592953288732
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6526721734793772
wandb: 	temperature: 8.246322742944146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104452-yvxdc87v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-13
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yvxdc87v
wandb: uploading history steps 102-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–…â–„â–„
wandb:  best/eval_ensemble_f1 â–â–„â–…â–…â–†â–ˆ
wandb:            eval/avg_f1 â–…â–†â–…â–‡â–‡â–„â–ƒâ–ƒâ–‡â–‡â–‡â–‡â–ƒâ–‚â–†â–ˆâ–…â–†â–†â–ƒâ–†â–‡â–‚â–ƒâ–ˆâ–†â–†â–‡â–â–ˆâ–‡â–†â–‡â–‡â–‚â–†â–‡â–‡â–‡â–†
wandb:      eval/avg_mil_loss â–‚â–ƒâ–„â–‚â–†â–â–„â–…â–â–…â–‡â–„â–†â–…â–‚â–ƒâ–ƒâ–‚â–„â–ˆâ–‚â–‡â–â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       eval/ensemble_f1 â–†â–„â–…â–†â–„â–…â–‡â–‡â–†â–†â–…â–„â–†â–†â–‚â–†â–‚â–…â–‚â–…â–†â–…â–â–ƒâ–…â–‡â–‡â–†â–†â–…â–ƒâ–†â–‡â–â–†â–ƒâ–‚â–ˆâ–†â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‚â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–…â–„â–…â–„â–„â–…â–…â–â–†â–†â–‡â–‚â–„â–†â–‡â–‚â–…â–ˆâ–…â–ƒâ–„â–ˆâ–…â–‡â–„â–†
wandb:      train/ensemble_f1 â–‚â–‚â–†â–ƒâ–…â–‚â–…â–‚â–†â–†â–„â–â–…â–„â–„â–„â–…â–ƒâ–…â–ƒâ–‚â–…â–…â–‡â–ƒâ–‡â–â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ˆâ–„â–…â–ˆâ–ƒâ–ƒâ–‡
wandb:         train/mil_loss â–„â–ˆâ–‚â–†â–…â–†â–„â–…â–‚â–ƒâ–ƒâ–„â–…â–ƒâ–…â–„â–ƒâ–„â–†â–„â–„â–ƒâ–…â–…â–…â–…â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–…â–‚â–…â–‚â–ƒâ–â–…â–ƒ
wandb:      train/policy_loss â–â–…â–…â–â–â–…â–…â–…â–…â–…â–â–…â–ˆâ–…â–â–…â–…â–â–…â–ˆâ–â–…â–…â–…â–ˆâ–â–…â–ˆâ–…â–…â–ˆâ–ˆâ–…â–…â–…â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7776
wandb: best/eval_avg_mil_loss 0.72623
wandb:  best/eval_ensemble_f1 0.7776
wandb:            eval/avg_f1 0.7144
wandb:      eval/avg_mil_loss 0.76886
wandb:       eval/ensemble_f1 0.7144
wandb:            test/avg_f1 0.64936
wandb:      test/avg_mil_loss 0.67986
wandb:       test/ensemble_f1 0.64936
wandb:           train/avg_f1 0.72557
wandb:      train/ensemble_f1 0.72557
wandb:         train/mil_loss 0.71718
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run soft-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yvxdc87v
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104452-yvxdc87v/logs
wandb: Agent Starting Run: 3203csj2 with config:
wandb: 	actor_learning_rate: 6.582833837666234e-06
wandb: 	attention_dropout_p: 0.45108032396366365
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5269390404489835
wandb: 	temperature: 9.969550142987758
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104645-3203csj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-14
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3203csj2
wandb: uploading history steps 90-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–†â–â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆ
wandb:            eval/avg_f1 â–†â–ƒâ–…â–‡â–‡â–‡â–‡â–†â–„â–‡â–†â–†â–‡â–†â–‡â–†â–‡â–„â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–…â–†â–†â–â–‡â–‡â–‡â–‡â–„â–‡â–‡â–‡â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–†â–„â–„â–„â–…â–ƒâ–ƒâ–…â–„â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–‚â–…â–…â–‚â–â–„â–ˆâ–„â–„â–‚â–‚â–…â–„â–‡â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–…â–‚
wandb:       eval/ensemble_f1 â–„â–‡â–‡â–‡â–‡â–‡â–…â–‡â–„â–„â–‡â–‡â–‡â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–â–‡â–ˆâ–„â–‡â–‡â–‡â–‡â–„â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–â–„â–„â–„â–…â–…â–„â–…â–‚â–„â–…â–…â–…â–ƒâ–†â–„â–„â–‡â–…â–…â–…â–…â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–„â–„â–…â–ƒâ–ˆâ–„
wandb:      train/ensemble_f1 â–„â–„â–ƒâ–‚â–„â–‚â–ƒâ–„â–„â–„â–â–ƒâ–„â–ƒâ–…â–…â–ƒâ–„â–†â–†â–…â–…â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–‚â–ˆâ–…
wandb:         train/mil_loss â–„â–ˆâ–ƒâ–„â–„â–„â–„â–„â–„â–‡â–ƒâ–ƒâ–…â–†â–‚â–ƒâ–…â–ƒâ–„â–‡â–„â–ƒâ–„â–„â–…â–„â–‚â–„â–â–‡â–„â–ƒâ–‚â–„â–„â–ƒâ–„â–…â–ƒâ–„
wandb:      train/policy_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–„â–„â–ˆâ–ˆâ–ˆâ–„â–â–„â–â–„â–„â–â–„â–ˆâ–â–„â–„â–„â–ˆâ–â–ˆâ–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75828
wandb: best/eval_avg_mil_loss 0.76745
wandb:  best/eval_ensemble_f1 0.75828
wandb:            eval/avg_f1 0.64198
wandb:      eval/avg_mil_loss 0.84227
wandb:       eval/ensemble_f1 0.64198
wandb:            test/avg_f1 0.76702
wandb:      test/avg_mil_loss 0.54998
wandb:       test/ensemble_f1 0.76702
wandb:           train/avg_f1 0.66927
wandb:      train/ensemble_f1 0.66927
wandb:         train/mil_loss 0.73957
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run hardy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3203csj2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104645-3203csj2/logs
wandb: Agent Starting Run: 3yktrwa7 with config:
wandb: 	actor_learning_rate: 1.7733408616203395e-05
wandb: 	attention_dropout_p: 0.4039972306121519
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5039796831676452
wandb: 	temperature: 6.014999978392242
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104824-3yktrwa7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-15
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3yktrwa7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–„â–â–â–…â–ˆâ–ƒâ–ˆâ–â–ˆâ–‡â–…â–„â–â–‚â–…â–ˆâ–â–…â–‚â–ˆâ–ˆâ–â–„â–„â–„â–â–„â–â–‚â–‚â–ˆâ–‡â–‡â–‚â–‚â–‡â–ˆâ–‡â–
wandb:      eval/avg_mil_loss â–„â–…â–‡â–…â–„â–‡â–„â–‡â–„â–‡â–…â–†â–†â–‡â–‡â–„â–…â–„â–†â–…â–„â–„â–‡â–ƒâ–ˆâ–†â–†â–†â–…â–„â–„â–†â–‡â–…â–„â–„â–„â–â–‡â–„
wandb:       eval/ensemble_f1 â–„â–…â–„â–‡â–â–‚â–‚â–‡â–â–…â–â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–â–ˆâ–ˆâ–â–‡â–„â–â–ˆâ–‡â–ˆâ–‡â–‡â–â–‚â–ˆâ–‡â–‡â–â–‡
wandb:           train/avg_f1 â–ƒâ–†â–†â–†â–„â–…â–„â–ƒâ–‡â–ƒâ–ƒâ–…â–‡â–†â–‡â–†â–„â–†â–ƒâ–…â–†â–†â–…â–…â–ƒâ–ˆâ–‡â–„â–…â–‡â–„â–‚â–â–†â–†â–„â–…â–†â–‚â–„
wandb:      train/ensemble_f1 â–†â–…â–‡â–„â–ˆâ–…â–ƒâ–‡â–„â–†â–…â–†â–„â–â–ˆâ–‡â–†â–…â–†â–†â–ƒâ–ˆâ–ˆâ–ƒâ–†â–…â–„â–„â–‚â–„â–†â–†â–†â–‚â–†â–‚â–†â–…â–„â–…
wandb:         train/mil_loss â–…â–ƒâ–…â–†â–…â–ˆâ–„â–ƒâ–†â–ƒâ–†â–„â–…â–‚â–ˆâ–ƒâ–ˆâ–„â–ƒâ–†â–„â–ƒâ–„â–â–…â–‡â–„â–„â–…â–…â–„â–†â–„â–†â–‡â–‚â–†â–…â–…â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77766
wandb: best/eval_avg_mil_loss 0.81862
wandb:  best/eval_ensemble_f1 0.77766
wandb:            eval/avg_f1 0.69957
wandb:      eval/avg_mil_loss 0.85721
wandb:       eval/ensemble_f1 0.69957
wandb:           train/avg_f1 0.5759
wandb:      train/ensemble_f1 0.5759
wandb:         train/mil_loss 0.78496
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run avid-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3yktrwa7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104824-3yktrwa7/logs
wandb: ERROR Run 3yktrwa7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: fa3xi77n with config:
wandb: 	actor_learning_rate: 2.8331744367150142e-06
wandb: 	attention_dropout_p: 0.4320334194958862
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7213400578215255
wandb: 	temperature: 9.345691965274527
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104951-fa3xi77n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-16
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fa3xi77n
wandb: uploading history steps 75-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–â–„â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–ˆ
wandb:            eval/avg_f1 â–…â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–â–…â–…â–…â–…â–†â–„â–„â–ƒâ–‚â–ƒâ–…â–…â–ˆâ–„â–â–†â–ƒâ–
wandb:      eval/avg_mil_loss â–‡â–‡â–ƒâ–†â–„â–„â–ˆâ–„â–„â–†â–ƒâ–…â–„â–‚â–…â–â–…â–…â–ƒâ–†â–ƒâ–„â–…â–ƒâ–„â–„â–†â–„â–…â–„â–‡â–‚â–…â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–…
wandb:       eval/ensemble_f1 â–†â–„â–‚â–‡â–‡â–„â–…â–‚â–…â–…â–‡â–‡â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–…â–†â–†â–‚â–†â–ˆâ–„â–ƒâ–â–ƒâ–†â–†â–‚â–ƒâ–ƒâ–†â–„â–â–‡â–…
wandb:           train/avg_f1 â–ƒâ–„â–„â–…â–…â–„â–ƒâ–‡â–„â–ƒâ–„â–‚â–„â–…â–…â–„â–…â–‚â–…â–…â–…â–â–†â–…â–„â–ƒâ–†â–ƒâ–…â–„â–‡â–‚â–…â–…â–ƒâ–ˆâ–…â–ƒâ–‡â–†
wandb:      train/ensemble_f1 â–ƒâ–„â–„â–‚â–„â–„â–„â–‚â–„â–„â–…â–„â–…â–…â–„â–‚â–…â–â–†â–†â–†â–„â–„â–…â–†â–‡â–…â–„â–…â–‡â–…â–…â–…â–ƒâ–„â–ˆâ–…â–ƒâ–†â–†
wandb:         train/mil_loss â–†â–†â–„â–„â–ˆâ–ƒâ–…â–…â–ˆâ–‡â–ƒâ–„â–…â–„â–„â–‡â–„â–…â–…â–ƒâ–ƒâ–„â–…â–ƒâ–‚â–„â–„â–ƒâ–„â–„â–„â–ƒâ–…â–„â–‚â–â–â–„â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77789
wandb: best/eval_avg_mil_loss 0.76451
wandb:  best/eval_ensemble_f1 0.77789
wandb:            eval/avg_f1 0.69712
wandb:      eval/avg_mil_loss 0.79502
wandb:       eval/ensemble_f1 0.69712
wandb:           train/avg_f1 0.73748
wandb:      train/ensemble_f1 0.73748
wandb:         train/mil_loss 0.63746
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run devout-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fa3xi77n
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104951-fa3xi77n/logs
wandb: ERROR Run fa3xi77n errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 29b67lri with config:
wandb: 	actor_learning_rate: 0.0002723474076462765
wandb: 	attention_dropout_p: 0.15545012925158902
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2144981128108097
wandb: 	temperature: 5.801022212779532
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105141-29b67lri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-17
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/29b67lri
wandb: uploading wandb-summary.json
wandb: uploading history steps 104-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–„â–â–ƒâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–â–â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–‚â–ˆâ–…â–„â–ˆâ–…â–ˆâ–‡â–„â–‡â–…â–†â–„â–…â–â–„â–‡â–„â–ˆâ–„â–„â–„â–…â–…â–„â–‡â–„â–…â–…â–â–…â–‡â–ˆâ–†â–â–„â–„â–„
wandb:      eval/avg_mil_loss â–†â–„â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–‡â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–ˆâ–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–â–„â–†â–„â–…â–„â–…â–„â–…â–„â–†â–„â–„â–‡â–ˆâ–„â–â–„â–„â–ˆâ–â–…â–â–„â–„â–ˆâ–„â–„â–â–…â–…â–ˆâ–ˆâ–„â–…â–‚â–„â–„â–„â–„
wandb:           train/avg_f1 â–‚â–‚â–ˆâ–„â–„â–†â–…â–†â–ƒâ–„â–ƒâ–…â–ˆâ–ƒâ–†â–„â–†â–ƒâ–†â–…â–‚â–„â–…â–ƒâ–„â–„â–†â–„â–â–„â–ƒâ–…â–†â–‚â–†â–ƒâ–„â–„â–‡â–…
wandb:      train/ensemble_f1 â–„â–…â–ƒâ–„â–†â–ˆâ–†â–ƒâ–„â–‚â–‚â–‚â–…â–ƒâ–…â–…â–„â–‚â–†â–„â–„â–ƒâ–„â–â–†â–†â–„â–„â–„â–ƒâ–…â–‚â–â–„â–…â–ƒâ–‚â–‚â–†â–„
wandb:         train/mil_loss â–…â–ƒâ–ƒâ–†â–…â–ƒâ–†â–ƒâ–‡â–…â–ƒâ–„â–ˆâ–„â–„â–â–ƒâ–‚â–ƒâ–„â–‚â–‚â–‚â–„â–…â–†â–‡â–…â–…â–„â–‡â–ƒâ–†â–‡â–…â–†â–„â–ƒâ–„â–ˆ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79179
wandb: best/eval_avg_mil_loss 0.80175
wandb:  best/eval_ensemble_f1 0.79179
wandb:            eval/avg_f1 0.50172
wandb:      eval/avg_mil_loss 0.97772
wandb:       eval/ensemble_f1 0.50172
wandb:           train/avg_f1 0.60906
wandb:      train/ensemble_f1 0.60906
wandb:         train/mil_loss 0.81593
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run daily-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/29b67lri
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105141-29b67lri/logs
wandb: ERROR Run 29b67lri errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 16nl1pre with config:
wandb: 	actor_learning_rate: 0.0001847199042644929
wandb: 	attention_dropout_p: 0.017846898657085997
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6228159471511661
wandb: 	temperature: 7.0396713822486525
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105343-16nl1pre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-18
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16nl1pre
wandb: uploading history steps 190-195, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–„â–ˆâ–†â–…â–…â–„â–…â–…â–â–
wandb:  best/eval_ensemble_f1 â–â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‚â–†â–…â–†â–â–†â–†â–†â–…â–…â–‚â–†â–ˆâ–ƒâ–ƒâ–†â–ˆâ–…â–†â–†â–‚â–â–…â–†â–†â–ƒâ–‡â–‡â–‡â–„â–„â–‡â–…â–…â–†â–…â–…â–†â–ˆâ–†
wandb:      eval/avg_mil_loss â–„â–†â–†â–†â–‡â–…â–„â–ƒâ–†â–‚â–†â–„â–‡â–…â–„â–„â–…â–…â–ƒâ–‡â–…â–…â–„â–…â–â–…â–†â–…â–„â–„â–ˆâ–„â–…â–„â–…â–â–„â–„â–…â–„
wandb:       eval/ensemble_f1 â–†â–†â–†â–…â–…â–â–ƒâ–†â–†â–„â–‡â–‡â–‡â–‚â–ƒâ–‚â–ˆâ–…â–â–†â–ƒâ–…â–†â–‡â–ˆâ–†â–…â–†â–†â–†â–‡â–†â–‚â–‡â–†â–…â–†â–†â–†â–
wandb:           train/avg_f1 â–…â–„â–„â–â–„â–‚â–â–†â–…â–â–ƒâ–ƒâ–…â–„â–„â–„â–…â–„â–â–…â–…â–†â–†â–…â–…â–†â–‚â–†â–ƒâ–ƒâ–…â–†â–†â–…â–†â–ˆâ–„â–†â–„â–†
wandb:      train/ensemble_f1 â–„â–†â–…â–ˆâ–…â–ƒâ–ƒâ–â–…â–†â–…â–†â–…â–„â–†â–„â–†â–…â–†â–†â–ˆâ–ˆâ–…â–†â–†â–ƒâ–†â–…â–‡â–‡â–‡â–‡â–„â–†â–…â–‡â–…â–‡â–ƒâ–ˆ
wandb:         train/mil_loss â–ˆâ–„â–ˆâ–„â–†â–…â–…â–…â–ƒâ–„â–„â–ƒâ–†â–‚â–†â–‚â–ˆâ–†â–ƒâ–†â–ƒâ–„â–„â–‡â–‚â–…â–ƒâ–‡â–„â–…â–ƒâ–…â–„â–„â–„â–â–„â–‚â–„â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8098
wandb: best/eval_avg_mil_loss 0.60202
wandb:  best/eval_ensemble_f1 0.8098
wandb:            eval/avg_f1 0.61377
wandb:      eval/avg_mil_loss 0.8538
wandb:       eval/ensemble_f1 0.61377
wandb:           train/avg_f1 0.73762
wandb:      train/ensemble_f1 0.73762
wandb:         train/mil_loss 0.6349
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run honest-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/16nl1pre
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105343-16nl1pre/logs
wandb: ERROR Run 16nl1pre errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 99t22fu2 with config:
wandb: 	actor_learning_rate: 0.00015161804055415298
wandb: 	attention_dropout_p: 0.10029349807739818
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 57
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8791125131063192
wandb: 	temperature: 9.398760283427768
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105709-99t22fu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-19
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/99t22fu2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–
wandb:  best/eval_ensemble_f1 â–â–†â–ˆ
wandb:            eval/avg_f1 â–„â–‡â–„â–ˆâ–â–‡â–‡â–„â–„â–â–‡â–â–„â–ˆâ–‡â–†â–„â–ƒâ–‡â–‡â–‡â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–ˆâ–‡â–â–ˆâ–‡â–„â–ƒâ–â–
wandb:      eval/avg_mil_loss â–…â–â–…â–…â–†â–„â–ˆâ–ˆâ–…â–…â–…â–‡â–„â–…â–‡â–…â–…â–‡â–†â–ƒâ–„â–‚â–„â–ƒâ–†â–…â–‚â–„â–…â–„â–…â–ˆâ–†â–ˆâ–ƒâ–‡â–„â–‡â–ˆâ–‡
wandb:       eval/ensemble_f1 â–ˆâ–„â–‡â–„â–â–‡â–‡â–„â–„â–â–‡â–â–‡â–ˆâ–‡â–‡â–„â–ƒâ–‡â–‡â–‡â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–â–ˆâ–‡â–â–„â–„â–„â–â–
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–…â–†â–ˆâ–†â–„â–…â–…â–…â–†â–ƒâ–ƒâ–…â–‡â–ˆâ–…â–†â–†â–…â–ƒâ–…â–„â–â–†â–‡â–„â–ƒâ–‡â–ƒâ–ƒâ–‡â–‡â–ƒâ–…â–†â–‚â–†â–„â–„â–‡
wandb:      train/ensemble_f1 â–„â–‡â–…â–†â–ˆâ–†â–„â–„â–…â–…â–ƒâ–ƒâ–…â–ƒâ–†â–ˆâ–„â–…â–†â–…â–ƒâ–†â–‚â–„â–â–„â–‡â–…â–„â–‡â–…â–‡â–‚â–…â–†â–†â–„â–„â–„â–‡
wandb:         train/mil_loss â–†â–ƒâ–†â–†â–„â–…â–„â–…â–ˆâ–â–ˆâ–„â–ƒâ–…â–ƒâ–†â–†â–‡â–ˆâ–…â–…â–ƒâ–…â–ƒâ–‡â–‚â–‡â–‡â–ˆâ–„â–…â–…â–…â–†â–‡â–„â–„â–†â–ƒâ–
wandb:      train/policy_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78007
wandb: best/eval_avg_mil_loss 0.76348
wandb:  best/eval_ensemble_f1 0.78007
wandb:            eval/avg_f1 0.35969
wandb:      eval/avg_mil_loss 1.02826
wandb:       eval/ensemble_f1 0.35969
wandb:            test/avg_f1 0.76822
wandb:      test/avg_mil_loss 0.53072
wandb:       test/ensemble_f1 0.76822
wandb:           train/avg_f1 0.71262
wandb:      train/ensemble_f1 0.71262
wandb:         train/mil_loss 0.62624
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run snowy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/99t22fu2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105709-99t22fu2/logs
wandb: Agent Starting Run: qr48gkjp with config:
wandb: 	actor_learning_rate: 1.8679134987148124e-06
wandb: 	attention_dropout_p: 0.002820885993351563
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5083562040663996
wandb: 	temperature: 1.1409474016829135
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105816-qr48gkjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-20
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qr48gkjp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ƒâ–ƒâ–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ˆâ–ƒâ–‚â–â–‚
wandb:  best/eval_ensemble_f1 â–â–â–ƒâ–ƒâ–†â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–…â–ƒâ–…â–ƒâ–…â–†â–…â–‡â–†â–ƒâ–…â–ˆâ–…â–„â–‡â–…â–‚â–…â–…â–†â–†â–‚â–…â–ˆâ–â–„â–…â–…â–â–ˆâ–…â–…â–‡â–„â–ˆâ–„â–…â–†
wandb:      eval/avg_mil_loss â–…â–ˆâ–…â–‚â–ˆâ–…â–ˆâ–ˆâ–…â–‡â–†â–â–…â–…â–ˆâ–ƒâ–ƒâ–‡â–„â–„â–ƒâ–ƒâ–…â–„â–…â–ˆâ–„â–…â–‚â–‡â–†â–â–†â–„â–‡â–„â–‡â–…â–ˆâ–…
wandb:       eval/ensemble_f1 â–…â–„â–„â–†â–ƒâ–†â–ƒâ–…â–†â–†â–‚â–…â–ƒâ–…â–„â–ƒâ–…â–ƒâ–†â–…â–…â–„â–†â–…â–†â–†â–„â–ƒâ–„â–ƒâ–†â–…â–†â–…â–†â–„â–ˆâ–ƒâ–â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–â–…â–…â–†â–†â–„â–…â–…â–„â–†â–„â–…â–†â–…â–…â–ƒâ–…â–…â–ˆâ–…â–…â–„â–„â–„â–…â–†â–„â–ƒâ–ƒâ–‡â–†â–‡â–†â–‡â–„â–†â–‡â–„â–†â–…
wandb:      train/ensemble_f1 â–‚â–…â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–†â–„â–„â–â–„â–„â–ˆâ–ƒâ–‚â–‡â–„â–„â–ƒâ–ƒâ–†â–…â–‚â–†â–ƒâ–…â–…â–‡â–‚â–†â–ƒâ–‡â–„â–…â–ƒâ–ƒâ–ƒ
wandb:         train/mil_loss â–†â–ˆâ–„â–‡â–ƒâ–†â–…â–…â–…â–„â–ˆâ–…â–…â–…â–†â–…â–‡â–†â–…â–„â–ƒâ–†â–„â–‡â–â–„â–†â–‚â–…â–ƒâ–†â–ƒâ–‚â–‚â–„â–ƒâ–‚â–„â–ƒâ–‚
wandb:      train/policy_loss â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–â–†â–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80277
wandb: best/eval_avg_mil_loss 0.68339
wandb:  best/eval_ensemble_f1 0.80277
wandb:            eval/avg_f1 0.71405
wandb:      eval/avg_mil_loss 0.75619
wandb:       eval/ensemble_f1 0.71405
wandb:            test/avg_f1 0.7779
wandb:      test/avg_mil_loss 0.53531
wandb:       test/ensemble_f1 0.7779
wandb:           train/avg_f1 0.67463
wandb:      train/ensemble_f1 0.67463
wandb:         train/mil_loss 0.72234
wandb:      train/policy_loss -0.03993
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.03993
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qr48gkjp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105816-qr48gkjp/logs
wandb: Agent Starting Run: 7bxxwcu6 with config:
wandb: 	actor_learning_rate: 4.77650094846435e-05
wandb: 	attention_dropout_p: 0.14110969556243663
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6434362303385125
wandb: 	temperature: 7.986073943723348
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110133-7bxxwcu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-21
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7bxxwcu6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–†â–†â–ˆ
wandb:            eval/avg_f1 â–…â–„â–„â–†â–…â–†â–„â–‡â–„â–‡â–†â–†â–„â–†â–…â–„â–‡â–â–„â–†â–†â–‡â–„â–…â–†â–ƒâ–ƒâ–ˆâ–…â–‡â–†â–ˆâ–†â–…â–…â–ˆâ–ƒâ–„â–…â–ˆ
wandb:      eval/avg_mil_loss â–…â–„â–„â–ƒâ–…â–‡â–„â–ƒâ–ˆâ–„â–‚â–ƒâ–…â–ƒâ–ƒâ–†â–‡â–‡â–†â–…â–„â–„â–†â–„â–â–…â–‚â–…â–‚â–‚â–…â–‚â–ƒâ–‚â–„â–‚â–…â–‚â–„â–‚
wandb:       eval/ensemble_f1 â–„â–„â–†â–†â–†â–‡â–†â–ƒâ–„â–‡â–‡â–ƒâ–„â–†â–‚â–‚â–‡â–â–…â–‚â–ƒâ–†â–†â–‡â–ˆâ–ƒâ–…â–ˆâ–…â–…â–†â–ˆâ–„â–†â–„â–‚â–ƒâ–„â–…â–†
wandb:           train/avg_f1 â–„â–„â–…â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–â–„â–„â–„â–‚â–â–…â–ˆâ–…â–ƒâ–‡â–†â–ƒâ–…â–ƒâ–…â–…â–…â–‡â–„â–…â–†â–†â–„â–„â–‚â–„â–‡â–‚
wandb:      train/ensemble_f1 â–†â–„â–â–†â–‚â–†â–„â–ƒâ–ƒâ–…â–„â–„â–†â–â–…â–â–†â–†â–†â–‡â–†â–ˆâ–†â–ƒâ–…â–†â–ƒâ–‡â–‚â–„â–ˆâ–‡â–„â–…â–„â–‚â–†â–…â–†â–ƒ
wandb:         train/mil_loss â–ˆâ–…â–…â–…â–…â–†â–„â–‡â–„â–‡â–†â–ˆâ–†â–‡â–†â–ƒâ–„â–…â–†â–‡â–†â–…â–…â–…â–‚â–†â–…â–„â–…â–ƒâ–„â–‚â–â–ƒâ–‚â–‚â–‚â–„â–ƒâ–
wandb:      train/policy_loss â–‚â–†â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–†â–†â–†
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82306
wandb: best/eval_avg_mil_loss 0.5621
wandb:  best/eval_ensemble_f1 0.82306
wandb:            eval/avg_f1 0.79946
wandb:      eval/avg_mil_loss 0.55801
wandb:       eval/ensemble_f1 0.79946
wandb:           train/avg_f1 0.79226
wandb:      train/ensemble_f1 0.79226
wandb:         train/mil_loss 0.61737
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7bxxwcu6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110133-7bxxwcu6/logs
wandb: ERROR Run 7bxxwcu6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: cs3jbakd with config:
wandb: 	actor_learning_rate: 8.234288622922646e-05
wandb: 	attention_dropout_p: 0.422386011144781
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 128
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8123784290659486
wandb: 	temperature: 8.930691431827082
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110444-cs3jbakd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-22
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cs3jbakd
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 115-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‚â–ˆâ–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–ƒâ–†â–â–„â–„â–„â–‡â–„â–‡â–ˆâ–‡â–‡â–…â–‡â–‡â–ˆâ–†â–„â–‡â–â–‡â–‡â–â–„â–‡â–‡â–„â–â–‡â–„â–â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–‡
wandb:      eval/avg_mil_loss â–„â–†â–‚â–ˆâ–‡â–„â–…â–ƒâ–†â–„â–„â–…â–‡â–…â–„â–…â–‚â–‚â–ƒâ–ƒâ–„â–â–„â–…â–†â–„â–…â–ƒâ–…â–„â–†â–‚â–†â–â–„â–‚â–ƒâ–…â–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–„â–‡â–ƒâ–ƒâ–„â–„â–‡â–„â–‡â–ˆâ–„â–‡â–„â–…â–„â–„â–ƒâ–‡â–…â–‡â–â–ˆâ–‡â–‡â–„â–‡â–„â–ƒâ–‡â–‡â–…â–‡â–‡â–‡â–â–…â–â–…â–
wandb:           train/avg_f1 â–†â–…â–„â–…â–ƒâ–‡â–ƒâ–„â–†â–†â–â–†â–†â–‡â–‡â–…â–ˆâ–…â–‡â–„â–…â–ƒâ–†â–‡â–…â–…â–‡â–…â–‡â–†â–„â–†â–…â–ƒâ–…â–‡â–…â–„â–ƒâ–…
wandb:      train/ensemble_f1 â–„â–ˆâ–‚â–†â–…â–…â–ƒâ–…â–…â–„â–†â–†â–†â–‡â–…â–„â–‡â–‡â–„â–…â–…â–„â–‚â–…â–…â–…â–â–†â–…â–„â–ˆâ–…â–„â–…â–…â–„â–…â–…â–„â–„
wandb:         train/mil_loss â–…â–â–ƒâ–…â–…â–„â–…â–†â–…â–„â–‚â–„â–ƒâ–…â–â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–„â–…â–†â–ƒâ–„â–ˆâ–…â–†â–„â–…â–„â–„â–ƒâ–…â–‡â–‡â–‚â–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78135
wandb: best/eval_avg_mil_loss 0.67702
wandb:  best/eval_ensemble_f1 0.78135
wandb:            eval/avg_f1 0.69289
wandb:      eval/avg_mil_loss 0.75342
wandb:       eval/ensemble_f1 0.69289
wandb:           train/avg_f1 0.62978
wandb:      train/ensemble_f1 0.62978
wandb:         train/mil_loss 0.79199
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run comic-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cs3jbakd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110444-cs3jbakd/logs
wandb: ERROR Run cs3jbakd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: p0mlbumn with config:
wandb: 	actor_learning_rate: 0.000320513317001505
wandb: 	attention_dropout_p: 0.3946167510670654
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 92
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42608753290153223
wandb: 	temperature: 9.88560765970126
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110704-p0mlbumn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-23
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0mlbumn
wandb: uploading history steps 85-93, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–„â–ƒâ–‚â–‚â–â–
wandb:  best/eval_ensemble_f1 â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–„â–ƒâ–„â–ƒâ–…â–‡â–‡â–…â–„â–†â–„â–…â–‚â–„â–ƒâ–ƒâ–ˆâ–…â–â–„â–…â–‚â–ƒâ–„â–…â–‚â–‚â–„â–‚â–„â–…â–ˆâ–†â–…â–ƒâ–…â–ƒâ–„â–…â–„
wandb:      eval/avg_mil_loss â–„â–„â–†â–„â–ƒâ–„â–„â–ƒâ–ƒâ–‡â–‚â–„â–…â–‚â–„â–†â–…â–…â–‚â–‚â–†â–ˆâ–„â–†â–…â–†â–„â–…â–…â–ƒâ–‡â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–„â–†â–
wandb:       eval/ensemble_f1 â–…â–„â–‡â–ƒâ–…â–‡â–…â–ƒâ–…â–…â–„â–…â–…â–ƒâ–ˆâ–…â–†â–†â–„â–ˆâ–ƒâ–„â–†â–…â–…â–ƒâ–ƒâ–ƒâ–„â–‡â–‡â–…â–†â–†â–…â–â–‡â–„â–…â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–‚â–‚â–‡â–ƒâ–„â–…â–„â–‚â–†â–„â–†â–…â–ƒâ–ƒâ–†â–ƒâ–„â–…â–„â–‡â–â–‚â–â–„â–‡â–ˆâ–„â–„â–„â–„â–…â–â–ƒâ–†â–„â–‚â–ˆâ–‚â–ƒ
wandb:      train/ensemble_f1 â–…â–„â–ƒâ–ˆâ–‡â–‡â–…â–„â–…â–„â–…â–‡â–„â–„â–„â–…â–‚â–„â–â–…â–…â–†â–‡â–†â–ˆâ–…â–…â–…â–…â–†â–†â–„â–†â–‡â–‡â–†â–…â–‡â–ˆâ–„
wandb:         train/mil_loss â–…â–†â–„â–„â–ƒâ–…â–ƒâ–†â–ˆâ–…â–…â–„â–„â–…â–…â–„â–‡â–‚â–„â–‚â–…â–‚â–†â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–†â–„â–†â–ƒâ–†â–ƒâ–â–â–ƒâ–„â–…
wandb:      train/policy_loss â–ˆâ–â–„â–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–„â–â–â–â–„â–„â–„â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–„â–„â–„â–„â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–„â–„â–ˆâ–â–â–ˆâ–â–ˆâ–„â–â–ˆâ–â–„â–ˆâ–ˆâ–„â–â–â–â–„â–â–„â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77348
wandb: best/eval_avg_mil_loss 0.68426
wandb:  best/eval_ensemble_f1 0.77348
wandb:            eval/avg_f1 0.72741
wandb:      eval/avg_mil_loss 0.64318
wandb:       eval/ensemble_f1 0.72741
wandb:            test/avg_f1 0.80937
wandb:      test/avg_mil_loss 0.43623
wandb:       test/ensemble_f1 0.80937
wandb:           train/avg_f1 0.66329
wandb:      train/ensemble_f1 0.66329
wandb:         train/mil_loss 0.75904
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rare-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p0mlbumn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110704-p0mlbumn/logs
wandb: Agent Starting Run: yvbs1rzk with config:
wandb: 	actor_learning_rate: 4.131872460124541e-05
wandb: 	attention_dropout_p: 0.4964179025130905
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30951588291326737
wandb: 	temperature: 9.76081140810511
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110903-yvbs1rzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-24
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yvbs1rzk
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–„â–„â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–ƒâ–â–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–„â–„â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–â–ˆâ–†â–†â–†â–„â–‚â–…â–„â–…â–…â–‡â–ƒâ–…â–…â–…â–ƒâ–ˆâ–ƒâ–…â–…â–ƒâ–„â–†â–„â–ƒâ–„â–„â–…â–ƒâ–‚â–†â–ƒâ–ƒâ–â–‚â–…â–…â–…â–…
wandb:      eval/avg_mil_loss â–…â–‚â–„â–‡â–„â–„â–„â–…â–…â–„â–ƒâ–„â–„â–†â–ƒâ–„â–‚â–ƒâ–â–‚â–†â–â–‚â–„â–†â–„â–…â–ˆâ–ƒâ–â–…â–…â–â–„â–…â–„â–„â–‚â–‚â–‚
wandb:       eval/ensemble_f1 â–†â–ƒâ–ƒâ–ˆâ–†â–‡â–‡â–‡â–ƒâ–†â–‡â–†â–†â–„â–†â–ƒâ–â–…â–†â–ƒâ–„â–†â–…â–…â–‡â–‡â–‡â–†â–…â–„â–…â–…â–†â–ˆâ–…â–†â–†â–†â–†â–…
wandb:           train/avg_f1 â–…â–â–ƒâ–„â–‚â–‚â–ƒâ–…â–‚â–†â–„â–ƒâ–ƒâ–â–ƒâ–„â–‚â–…â–†â–„â–…â–…â–„â–ƒâ–â–…â–â–„â–‚â–‡â–†â–ˆâ–‚â–…â–â–ƒâ–†â–…â–‡â–„
wandb:      train/ensemble_f1 â–…â–…â–ƒâ–†â–‡â–‚â–„â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–…â–†â–…â–…â–ƒâ–‡â–‡â–†â–‚â–„â–†â–„â–â–…â–…â–ƒâ–ƒâ–…â–„â–ˆâ–„â–ƒâ–†â–ƒâ–…â–„â–…
wandb:         train/mil_loss â–†â–ƒâ–‚â–†â–„â–…â–…â–„â–„â–ƒâ–„â–„â–ƒâ–â–ƒâ–„â–â–ƒâ–ˆâ–ƒâ–ƒâ–„â–…â–†â–…â–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–â–‚â–…â–„â–‡â–‚â–â–ƒ
wandb:      train/policy_loss â–…â–â–…â–…â–…â–…â–â–…â–…â–ˆâ–ˆâ–â–â–ˆâ–â–…â–ˆâ–†â–…â–…â–ˆâ–â–ˆâ–…â–…â–â–â–â–…â–ˆâ–â–â–ˆâ–…â–â–ˆâ–…â–â–â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77909
wandb: best/eval_avg_mil_loss 0.70162
wandb:  best/eval_ensemble_f1 0.77909
wandb:            eval/avg_f1 0.68238
wandb:      eval/avg_mil_loss 0.80205
wandb:       eval/ensemble_f1 0.68238
wandb:           train/avg_f1 0.66157
wandb:      train/ensemble_f1 0.66157
wandb:         train/mil_loss 0.78447
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run flowing-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yvbs1rzk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110903-yvbs1rzk/logs
wandb: ERROR Run yvbs1rzk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 12ck52xn with config:
wandb: 	actor_learning_rate: 3.806720463906307e-05
wandb: 	attention_dropout_p: 0.4151227662250063
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 60
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7111861102455009
wandb: 	temperature: 8.997523031360073
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111209-12ck52xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-25
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12ck52xn
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–…â–ˆâ–…â–†â–†â–„â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–…â–…â–ƒâ–†â–‡â–†â–…â–…â–‡â–ƒâ–…â–â–…â–…â–…â–ƒâ–ƒâ–„â–„â–ˆâ–‚â–†â–†â–ƒâ–„â–ƒâ–ƒâ–„â–‡â–†â–…â–ƒâ–…â–„â–…â–†â–†â–…
wandb:      eval/avg_mil_loss â–„â–†â–„â–…â–…â–„â–…â–†â–†â–…â–‚â–…â–†â–†â–†â–„â–†â–…â–†â–†â–…â–ˆâ–ˆâ–â–ˆâ–…â–„â–†â–…â–†â–†â–„â–‚â–…â–†â–„â–…â–ƒâ–…â–†
wandb:       eval/ensemble_f1 â–…â–‚â–…â–ƒâ–…â–…â–…â–ˆâ–‡â–ƒâ–…â–â–…â–ƒâ–…â–…â–…â–ƒâ–ƒâ–„â–„â–ˆâ–ƒâ–„â–ˆâ–†â–…â–†â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‡â–…â–…â–„â–„â–…â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–‡â–„â–†â–„â–ƒâ–†â–â–†â–ƒâ–ƒâ–„â–†â–ƒâ–„â–†â–„â–…â–…â–‚â–‡â–†â–„â–ƒâ–„â–ƒâ–†â–ˆâ–„â–„â–„â–…â–‚â–…â–ƒâ–„â–„â–‡â–„â–‡â–…
wandb:      train/ensemble_f1 â–‡â–ƒâ–‡â–†â–‚â–„â–†â–„â–†â–ƒâ–‚â–‡â–†â–‚â–†â–â–ƒâ–‡â–…â–„â–‚â–…â–†â–„â–‚â–‚â–„â–…â–ˆâ–ƒâ–ˆâ–ƒâ–„â–„â–‚â–ƒâ–‡â–‡â–ƒâ–„
wandb:         train/mil_loss â–…â–‚â–…â–†â–ƒâ–‡â–…â–ˆâ–…â–â–„â–ƒâ–‡â–ƒâ–ƒâ–‡â–â–„â–ƒâ–†â–…â–„â–‡â–‚â–†â–†â–‚â–„â–‚â–„â–…â–‡â–„â–†â–…â–â–‚â–„â–â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75808
wandb: best/eval_avg_mil_loss 0.54025
wandb:  best/eval_ensemble_f1 0.75808
wandb:            eval/avg_f1 0.59394
wandb:      eval/avg_mil_loss 0.95178
wandb:       eval/ensemble_f1 0.59394
wandb:            test/avg_f1 0.59671
wandb:      test/avg_mil_loss 0.80926
wandb:       test/ensemble_f1 0.59671
wandb:           train/avg_f1 0.65922
wandb:      train/ensemble_f1 0.65922
wandb:         train/mil_loss 0.86337
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run summer-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/12ck52xn
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111209-12ck52xn/logs
wandb: Agent Starting Run: j6mugzp9 with config:
wandb: 	actor_learning_rate: 0.0002628578174973789
wandb: 	attention_dropout_p: 0.07875883308117582
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4288190590676928
wandb: 	temperature: 4.776523637867456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111317-j6mugzp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-26
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6mugzp9
wandb: uploading history steps 44-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–„â–ˆ
wandb: best/eval_avg_mil_loss â–…â–‡â–ˆâ–â–…
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–„â–ˆ
wandb:            eval/avg_f1 â–†â–†â–†â–†â–‡â–†â–‡â–„â–†â–†â–†â–‡â–…â–‡â–‡â–†â–‚â–†â–â–…â–…â–„â–†â–‚â–†â–ˆâ–†â–…â–…â–…â–ƒâ–…â–ƒâ–†â–ƒâ–„â–‡â–…â–…â–†
wandb:      eval/avg_mil_loss â–ƒâ–…â–ˆâ–„â–„â–„â–„â–„â–„â–…â–ƒâ–„â–â–„â–„â–â–„â–„â–†â–„â–„â–…â–…â–†â–‡â–ƒâ–„â–…â–„â–„â–†â–„â–‡â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–‡â–‡â–‚â–‡â–†â–‡â–ˆâ–†â–‡â–„â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–‚â–â–†â–†â–„â–‡â–‡â–‡â–‡â–†â–†â–ƒâ–†â–ƒâ–‡â–ƒâ–‡â–†â–†â–†â–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ˆâ–â–ƒâ–†â–„â–‚â–ƒâ–‚â–‚â–ƒâ–…â–â–„â–…â–ƒâ–†â–†â–†â–‚â–†â–„â–†â–ƒâ–†â–†â–ˆâ–ƒâ–…â–‡â–‡â–‡â–…â–„â–‚â–ƒâ–ƒâ–†â–…â–†â–…
wandb:      train/ensemble_f1 â–ˆâ–ƒâ–…â–†â–…â–„â–„â–„â–…â–„â–…â–†â–„â–ƒâ–…â–„â–â–†â–‡â–‡â–†â–…â–†â–„â–†â–‡â–ˆâ–„â–†â–‡â–‡â–†â–…â–…â–„â–ˆâ–…â–†â–†â–…
wandb:         train/mil_loss â–ˆâ–†â–†â–â–‡â–„â–„â–…â–†â–„â–…â–…â–â–„â–ƒâ–„â–‡â–‚â–†â–ƒâ–„â–…â–…â–…â–†â–„â–…â–†â–…â–ƒâ–„â–ƒâ–…â–„â–†â–…â–ƒâ–„â–„â–‚
wandb:      train/policy_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78135
wandb: best/eval_avg_mil_loss 0.72979
wandb:  best/eval_ensemble_f1 0.78135
wandb:            eval/avg_f1 0.71329
wandb:      eval/avg_mil_loss 0.78075
wandb:       eval/ensemble_f1 0.71329
wandb:            test/avg_f1 0.7122
wandb:      test/avg_mil_loss 0.77374
wandb:       test/ensemble_f1 0.7122
wandb:           train/avg_f1 0.71889
wandb:      train/ensemble_f1 0.71889
wandb:         train/mil_loss 0.60559
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rich-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6mugzp9
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111317-j6mugzp9/logs
wandb: Agent Starting Run: 792dnpke with config:
wandb: 	actor_learning_rate: 0.00014671719315256904
wandb: 	attention_dropout_p: 0.22256959775834695
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05771697791716912
wandb: 	temperature: 7.509491939618618
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111419-792dnpke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-27
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/792dnpke
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–†â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–‡â–ˆ
wandb:            eval/avg_f1 â–â–ƒâ–…â–â–â–ƒâ–…â–„â–…â–‚â–…â–„â–â–„â–…â–„â–‚â–‡â–ƒâ–‚â–ˆâ–…â–„â–…â–„â–ƒâ–‡â–†â–‚â–…â–…â–ƒâ–‚â–ƒâ–‚â–…â–‡â–†â–†â–†
wandb:      eval/avg_mil_loss â–…â–‚â–†â–…â–„â–‡â–…â–…â–„â–ˆâ–†â–…â–†â–„â–†â–‡â–…â–†â–ƒâ–…â–â–„â–…â–ƒâ–…â–‡â–†â–‡â–‡â–…â–…â–†â–…â–ƒâ–„â–…â–ƒâ–„â–…â–ƒ
wandb:       eval/ensemble_f1 â–‚â–„â–†â–‚â–ˆâ–…â–…â–…â–ƒâ–ƒâ–„â–†â–‚â–…â–…â–†â–†â–…â–„â–ˆâ–‡â–„â–‡â–†â–†â–…â–„â–ˆâ–ƒâ–…â–‡â–„â–‚â–„â–…â–â–„â–…â–ƒâ–…
wandb:           train/avg_f1 â–ˆâ–…â–…â–†â–‡â–ˆâ–ƒâ–ƒâ–‚â–â–‡â–ƒâ–…â–‡â–ƒâ–ƒâ–‡â–ˆâ–‡â–‚â–â–…â–…â–†â–…â–„â–ƒâ–…â–…â–…â–…â–…â–…â–„â–ƒâ–…â–ˆâ–†â–„â–…
wandb:      train/ensemble_f1 â–†â–„â–ƒâ–„â–…â–‡â–ƒâ–ƒâ–‚â–â–‡â–†â–‡â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–‚â–‚â–„â–â–„â–„â–„â–„â–ƒâ–…â–„â–ƒâ–ˆâ–„â–†â–…â–ƒâ–„
wandb:         train/mil_loss â–ƒâ–„â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–ˆâ–…â–‡â–ˆâ–„â–†â–ƒâ–‡â–â–„â–„â–‚â–…â–†â–…â–‡â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–‚â–…â–‚â–†â–
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75934
wandb: best/eval_avg_mil_loss 0.6445
wandb:  best/eval_ensemble_f1 0.75934
wandb:            eval/avg_f1 0.68248
wandb:      eval/avg_mil_loss 0.77413
wandb:       eval/ensemble_f1 0.68248
wandb:           train/avg_f1 0.64089
wandb:      train/ensemble_f1 0.64089
wandb:         train/mil_loss 0.80716
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fast-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/792dnpke
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111419-792dnpke/logs
wandb: ERROR Run 792dnpke errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: jqodd6xw with config:
wandb: 	actor_learning_rate: 9.596592975233752e-05
wandb: 	attention_dropout_p: 0.08160140281063033
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2307350951078101
wandb: 	temperature: 1.107353038882929
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111557-jqodd6xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-28
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqodd6xw
wandb: uploading wandb-summary.json
wandb: uploading history steps 86-96, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–…â–…â–†â–†â–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–†â–ƒâ–…â–†â–†â–†â–ˆâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–â–…â–…â–†â–†â–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–ˆâ–†â–„â–‡â–‚â–‚â–‚â–„â–â–†â–†â–‡â–ˆâ–‚â–‡â–‡â–†â–‡â–‡â–â–†â–ƒâ–†â–ˆâ–…â–†â–‡â–ˆâ–â–†â–†â–ƒâ–‚â–â–†â–‡â–‡â–†
wandb:      eval/avg_mil_loss â–‚â–â–„â–…â–‚â–ƒâ–…â–„â–…â–…â–ƒâ–ˆâ–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–‚â–„â–„â–…â–‚â–ƒâ–…â–‚â–‚â–‚â–ƒâ–„â–„â–â–ƒâ–ƒâ–‚
wandb:       eval/ensemble_f1 â–†â–†â–‡â–â–‡â–„â–‡â–‚â–‚â–…â–†â–â–‚â–‚â–†â–ƒâ–†â–‚â–†â–â–†â–†â–†â–ƒâ–‚â–†â–ˆâ–‡â–‡â–‡â–â–†â–„â–†â–‚â–â–â–†â–‚â–ˆ
wandb:           train/avg_f1 â–†â–„â–„â–„â–â–‡â–ƒâ–„â–…â–…â–ƒâ–â–ƒâ–ƒâ–ˆâ–ˆâ–‡â–„â–†â–„â–„â–…â–ƒâ–†â–‚â–„â–†â–ƒâ–…â–„â–†â–„â–‚â–‡â–‚â–†â–‚â–ƒâ–…â–„
wandb:      train/ensemble_f1 â–†â–…â–„â–ƒâ–ˆâ–†â–„â–ˆâ–†â–…â–ƒâ–â–„â–ƒâ–†â–…â–‡â–…â–…â–†â–…â–…â–†â–„â–„â–†â–†â–…â–‡â–…â–‡â–ˆâ–‚â–â–†â–†â–‚â–ƒâ–†â–„
wandb:         train/mil_loss â–ƒâ–‡â–„â–„â–†â–‚â–‚â–…â–ƒâ–…â–ƒâ–ƒâ–ˆâ–ˆâ–…â–„â–‚â–ƒâ–†â–…â–„â–‚â–ƒâ–„â–„â–‡â–ƒâ–…â–ƒâ–…â–„â–„â–…â–„â–†â–…â–†â–„â–†â–
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81014
wandb: best/eval_avg_mil_loss 0.70157
wandb:  best/eval_ensemble_f1 0.81014
wandb:            eval/avg_f1 0.79529
wandb:      eval/avg_mil_loss 0.74952
wandb:       eval/ensemble_f1 0.79529
wandb:           train/avg_f1 0.66005
wandb:      train/ensemble_f1 0.66005
wandb:         train/mil_loss 0.84552
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glamorous-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqodd6xw
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111557-jqodd6xw/logs
wandb: ERROR Run jqodd6xw errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: l9un3429 with config:
wandb: 	actor_learning_rate: 3.907957483581186e-06
wandb: 	attention_dropout_p: 0.10443178895915356
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2547723879873809
wandb: 	temperature: 3.1688069949166744
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111747-l9un3429
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-29
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l9un3429
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‡â–‚â–…â–ˆâ–ƒâ–ƒâ–‡â–„â–ƒâ–‚â–†â–†â–‚â–ƒâ–…â–…â–†â–…â–…â–†â–„â–‡â–ƒâ–â–†â–ˆâ–…â–…â–…â–‚â–‚â–ƒâ–‚â–‡â–†â–…â–‚â–ƒâ–ƒ
wandb:      eval/avg_mil_loss â–ƒâ–â–†â–ƒâ–„â–‚â–…â–…â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–…â–ƒâ–…â–„â–„â–„â–ƒâ–…â–â–‚â–„â–„â–†â–ƒâ–ˆâ–ˆâ–†â–‚â–ƒâ–‚â–…â–â–ˆâ–‚
wandb:       eval/ensemble_f1 â–ƒâ–ˆâ–„â–ƒâ–â–â–‡â–„â–‡â–†â–ƒâ–…â–…â–ˆâ–…â–„â–…â–†â–…â–„â–„â–â–ˆâ–†â–†â–…â–‡â–â–‚â–‚â–ƒâ–‚â–‡â–†â–†â–‡â–„â–‚â–‡â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–…â–‡â–…â–…â–ƒâ–…â–…â–„â–ƒâ–„â–‚â–ˆâ–ƒâ–â–‚â–„â–ƒâ–†â–…â–„â–‡â–†â–†â–„â–†â–„â–ƒâ–…â–…â–…â–…â–…â–ƒâ–†â–ˆâ–ƒâ–‚â–…â–†
wandb:      train/ensemble_f1 â–…â–…â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–†â–ƒâ–‡â–â–‚â–ƒâ–‚â–ƒâ–†â–…â–…â–„â–†â–…â–„â–…â–…â–…â–‚â–…â–ˆâ–ƒâ–†â–†â–‚â–…â–…â–†
wandb:         train/mil_loss â–…â–ƒâ–†â–ƒâ–ˆâ–‚â–…â–…â–…â–ƒâ–†â–‚â–ƒâ–…â–‚â–…â–…â–‡â–…â–â–„â–„â–…â–…â–ƒâ–‚â–…â–„â–„â–â–„â–„â–ƒâ–…â–…â–…â–„â–„â–ƒâ–‚
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7631
wandb: best/eval_avg_mil_loss 0.70669
wandb:  best/eval_ensemble_f1 0.7631
wandb:            eval/avg_f1 0.63739
wandb:      eval/avg_mil_loss 0.90481
wandb:       eval/ensemble_f1 0.63739
wandb:            test/avg_f1 0.62772
wandb:      test/avg_mil_loss 0.87045
wandb:       test/ensemble_f1 0.62772
wandb:           train/avg_f1 0.71227
wandb:      train/ensemble_f1 0.71227
wandb:         train/mil_loss 0.67907
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lyric-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l9un3429
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111747-l9un3429/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3vb10y4s with config:
wandb: 	actor_learning_rate: 0.00012126726088296412
wandb: 	attention_dropout_p: 0.2023104833388895
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02134500401233841
wandb: 	temperature: 2.021313762645738
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111935-3vb10y4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-30
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3vb10y4s
wandb: uploading wandb-summary.json
wandb: uploading history steps 101-111, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–†â–‡â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ƒâ–„â–â–„â–„
wandb:  best/eval_ensemble_f1 â–â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–â–†â–ˆâ–„â–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–„â–â–‚â–ƒâ–„â–„â–…â–„â–†â–ƒâ–‡â–„â–„â–„â–…â–†â–ƒâ–†â–‚â–…â–…â–„â–…â–ˆâ–„â–„â–ˆâ–‡
wandb:      eval/avg_mil_loss â–†â–ˆâ–‚â–†â–…â–‚â–ƒâ–†â–ƒâ–„â–â–ƒâ–…â–„â–ƒâ–†â–†â–â–†â–‚â–…â–…â–„â–…â–†â–‚â–†â–†â–…â–„â–„â–†â–„â–ƒâ–‚â–„â–…â–ƒâ–ƒâ–…
wandb:       eval/ensemble_f1 â–„â–â–„â–„â–‡â–‡â–ƒâ–‡â–†â–‡â–„â–†â–‡â–ƒâ–„â–‚â–‡â–ƒâ–ƒâ–„â–„â–…â–ƒâ–‡â–„â–ƒâ–ˆâ–ƒâ–‡â–…â–…â–‡â–†â–…â–‡â–‡â–„â–‡â–„â–
wandb:           train/avg_f1 â–‡â–ƒâ–…â–„â–‡â–†â–†â–‡â–ƒâ–„â–…â–…â–†â–‡â–†â–„â–†â–‡â–†â–†â–…â–†â–„â–†â–â–„â–†â–…â–…â–ƒâ–…â–ˆâ–…â–ˆâ–„â–†â–†â–…â–…â–„
wandb:      train/ensemble_f1 â–…â–†â–…â–ƒâ–‚â–†â–„â–†â–†â–…â–ƒâ–‡â–ˆâ–…â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–„â–…â–â–ˆâ–ƒâ–‡â–†â–‡â–ƒâ–„â–„â–†â–ˆâ–…â–…â–‡â–…â–„â–„
wandb:         train/mil_loss â–‚â–…â–†â–‚â–ˆâ–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–„â–„â–„â–‚â–„â–ˆâ–„â–„â–†â–‚â–†â–…â–„â–„â–â–‚â–‡â–‚â–‡â–„â–â–…â–…â–‡â–‡â–„â–
wandb:      train/policy_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–†â–â–…â–†â–ƒâ–…â–…â–â–â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–…â–ˆâ–ˆâ–â–…â–…â–ˆâ–…â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–…â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–…â–ƒâ–â–…â–…â–…â–…â–â–…â–†â–…â–…â–…â–ˆâ–â–…â–…â–…â–…â–ˆâ–â–…â–…â–…â–…â–â–ˆâ–…â–â–ˆâ–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7515
wandb: best/eval_avg_mil_loss 0.72418
wandb:  best/eval_ensemble_f1 0.7515
wandb:            eval/avg_f1 0.50984
wandb:      eval/avg_mil_loss 0.92304
wandb:       eval/ensemble_f1 0.50984
wandb:           train/avg_f1 0.62508
wandb:      train/ensemble_f1 0.62508
wandb:         train/mil_loss 0.7345
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run faithful-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3vb10y4s
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111935-3vb10y4s/logs
wandb: ERROR Run 3vb10y4s errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5eepd20f with config:
wandb: 	actor_learning_rate: 0.00011653076638057892
wandb: 	attention_dropout_p: 0.021836274727049132
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8562537897845437
wandb: 	temperature: 0.5288552494288379
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112147-5eepd20f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-31
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5eepd20f
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–„â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–ˆâ–ˆâ–
wandb:  best/eval_ensemble_f1 â–â–â–„â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–ˆâ–…â–†â–„â–…â–„â–‡â–…â–‡â–ˆâ–…â–‡â–ƒâ–ˆâ–ˆâ–‡â–ƒâ–…â–‡â–‡â–‡â–ˆâ–„â–‡â–â–†â–†â–‡â–„â–„â–„â–‚â–…â–…â–ˆâ–‚â–â–ˆâ–†
wandb:      eval/avg_mil_loss â–…â–…â–…â–…â–†â–†â–…â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–…â–ˆâ–…â–ƒâ–†â–‡â–ˆâ–ˆâ–…â–„â–…â–†â–…â–†â–„â–„â–‡â–‚â–â–‡â–‡â–„â–„â–ƒâ–„â–‡
wandb:       eval/ensemble_f1 â–‡â–†â–ˆâ–ˆâ–…â–†â–‡â–…â–‡â–†â–‡â–…â–†â–…â–‡â–‡â–…â–…â–ˆâ–ˆâ–†â–â–â–†â–‡â–†â–ˆâ–†â–…â–…â–†â–‡â–…â–…â–„â–†â–…â–‡â–ˆâ–†
wandb:           train/avg_f1 â–ƒâ–„â–…â–…â–„â–†â–‡â–†â–ƒâ–…â–†â–ˆâ–„â–‡â–‡â–†â–†â–…â–‡â–ƒâ–…â–†â–†â–„â–ƒâ–†â–†â–„â–†â–…â–‡â–…â–‡â–„â–‡â–ƒâ–„â–‡â–â–‡
wandb:      train/ensemble_f1 â–…â–…â–„â–†â–„â–„â–ˆâ–…â–‡â–…â–‡â–ƒâ–„â–ƒâ–…â–…â–‡â–†â–„â–†â–†â–ƒâ–„â–†â–ƒâ–†â–…â–‡â–ƒâ–„â–…â–‡â–…â–„â–‡â–…â–ƒâ–…â–â–…
wandb:         train/mil_loss â–‡â–…â–…â–‚â–ƒâ–ƒâ–„â–‚â–‡â–„â–„â–â–ƒâ–†â–‡â–†â–ƒâ–â–†â–„â–ƒâ–ˆâ–…â–„â–…â–†â–â–ƒâ–‚â–ˆâ–ƒâ–â–…â–„â–„â–†â–ƒâ–ƒâ–„â–…
wandb:      train/policy_loss â–â–„â–„â–ˆâ–„â–â–ˆâ–„â–â–„â–â–„â–„â–â–„â–â–„â–â–â–„â–â–„â–ˆâ–„â–„â–ˆâ–ˆâ–„â–â–ˆâ–„â–â–„â–ˆâ–ˆâ–„â–â–„â–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–„â–„â–„â–ˆâ–â–â–„â–„â–â–ˆâ–â–„â–â–„â–â–ˆâ–„â–„â–„â–ˆâ–ˆâ–ˆâ–â–„â–ˆâ–„â–„â–„â–„â–â–„â–ƒâ–†â–„â–â–„â–„â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79648
wandb: best/eval_avg_mil_loss 0.60093
wandb:  best/eval_ensemble_f1 0.79648
wandb:            eval/avg_f1 0.64688
wandb:      eval/avg_mil_loss 0.99007
wandb:       eval/ensemble_f1 0.64688
wandb:           train/avg_f1 0.66756
wandb:      train/ensemble_f1 0.66756
wandb:         train/mil_loss 0.81009
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run glorious-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5eepd20f
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112147-5eepd20f/logs
wandb: ERROR Run 5eepd20f errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: tmp9gst1 with config:
wandb: 	actor_learning_rate: 1.3390030345210491e-06
wandb: 	attention_dropout_p: 0.1685925872095299
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1254837708370723
wandb: 	temperature: 5.250417727014517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112402-tmp9gst1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-32
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmp9gst1
wandb: uploading history steps 120-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‚â–„â–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–ˆ
wandb:            eval/avg_f1 â–†â–†â–„â–„â–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–†â–‚â–‚â–ˆâ–ƒâ–„â–ˆâ–„â–…â–ˆâ–‡â–†â–„â–„â–‚â–„â–„â–ƒâ–â–ƒâ–†â–…â–ƒâ–…â–ƒâ–ƒâ–†â–„â–…
wandb:      eval/avg_mil_loss â–‚â–ƒâ–†â–„â–‡â–‚â–„â–…â–†â–…â–ƒâ–†â–‡â–ˆâ–„â–„â–ƒâ–…â–†â–„â–…â–â–ƒâ–ƒâ–†â–†â–…â–†â–…â–ƒâ–…â–„â–†â–ƒâ–‚â–ƒâ–„â–„â–…â–‚
wandb:       eval/ensemble_f1 â–†â–†â–…â–â–ƒâ–ƒâ–„â–‚â–ˆâ–…â–‚â–ƒâ–â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–â–„â–„â–‡â–ƒâ–„â–‚â–„â–â–ƒâ–â–…â–…â–„â–‚â–‚â–„â–…â–„â–„â–„
wandb:           train/avg_f1 â–†â–†â–„â–…â–ƒâ–…â–â–†â–‡â–ƒâ–ƒâ–ƒâ–†â–…â–…â–…â–…â–…â–…â–„â–†â–…â–„â–„â–„â–„â–†â–„â–„â–…â–ƒâ–„â–ˆâ–†â–„â–„â–„â–…â–‚â–„
wandb:      train/ensemble_f1 â–†â–‡â–…â–„â–‡â–†â–‚â–„â–ƒâ–ƒâ–ˆâ–†â–‡â–…â–ˆâ–…â–†â–‡â–„â–…â–†â–ƒâ–ˆâ–„â–…â–‡â–„â–‡â–…â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–‡â–â–ƒ
wandb:         train/mil_loss â–‡â–ˆâ–…â–ƒâ–…â–ƒâ–ƒâ–…â–„â–…â–…â–†â–ƒâ–†â–†â–â–‚â–…â–†â–…â–‚â–‚â–ƒâ–ˆâ–…â–„â–ƒâ–„â–„â–„â–…â–…â–„â–ƒâ–‡â–…â–…â–…â–†â–„
wandb:      train/policy_loss â–…â–â–ˆâ–â–â–ˆâ–â–…â–…â–â–â–…â–â–â–…â–â–â–…â–ˆâ–ˆâ–…â–…â–…â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–â–…â–…â–…â–…â–â–ˆâ–…â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–â–…â–â–…â–ˆâ–…â–â–ˆâ–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–â–ˆâ–…â–ˆâ–…â–…â–ˆâ–…â–ˆâ–ˆâ–â–ˆâ–…â–…â–…â–â–ˆâ–â–ˆâ–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72062
wandb: best/eval_avg_mil_loss 0.6853
wandb:  best/eval_ensemble_f1 0.72062
wandb:            eval/avg_f1 0.59111
wandb:      eval/avg_mil_loss 0.75097
wandb:       eval/ensemble_f1 0.59111
wandb:           train/avg_f1 0.59405
wandb:      train/ensemble_f1 0.59405
wandb:         train/mil_loss 0.75126
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run pleasant-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmp9gst1
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112402-tmp9gst1/logs
wandb: ERROR Run tmp9gst1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d5ribwe6 with config:
wandb: 	actor_learning_rate: 1.334224585349956e-06
wandb: 	attention_dropout_p: 0.4676989756463748
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 134
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.724170975443014
wandb: 	temperature: 8.561375129972436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112652-d5ribwe6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-33
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d5ribwe6
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–â–…â–…â–„â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–„â–…â–†â–…â–…â–…â–„â–…â–…â–‡â–â–ƒâ–‡â–„â–‡â–ˆâ–…â–ƒâ–ƒâ–â–‡â–‡â–…â–…â–„â–ƒâ–‡â–ˆâ–‡â–„â–‡â–ƒâ–„â–†â–†â–„â–â–…
wandb:      eval/avg_mil_loss â–„â–„â–ƒâ–„â–„â–„â–…â–…â–ƒâ–‡â–…â–ƒâ–ƒâ–â–‚â–„â–†â–ƒâ–†â–…â–â–„â–ƒâ–‡â–†â–ƒâ–…â–„â–…â–…â–†â–‚â–„â–â–‡â–ˆâ–…â–ƒâ–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–…â–„â–‚â–‡â–â–„â–„â–…â–‚â–‡â–‡â–†â–â–ƒâ–‡â–‡â–…â–„â–†â–„â–„â–†â–„â–„â–„â–†â–‡â–…â–ƒâ–„â–„â–ˆâ–„â–â–„â–‡â–„â–„â–…
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–â–…â–ƒâ–„â–ƒâ–†â–„â–ƒâ–â–‚â–„â–â–…â–ƒâ–ƒâ–„â–…â–„â–…â–‚â–‚â–â–…â–‚â–‚â–ƒâ–ƒâ–â–ˆâ–†â–„â–†â–ƒ
wandb:      train/ensemble_f1 â–„â–†â–„â–…â–„â–„â–„â–…â–â–ƒâ–ƒâ–…â–â–†â–…â–‡â–†â–†â–‚â–„â–†â–…â–„â–†â–†â–‡â–…â–ˆâ–‚â–ˆâ–„â–‚â–…â–…â–â–‡â–„â–‡â–…â–‡
wandb:         train/mil_loss â–…â–†â–…â–‡â–„â–â–„â–‡â–…â–„â–ˆâ–…â–„â–‡â–†â–†â–…â–„â–…â–…â–…â–‡â–ˆâ–„â–…â–ƒâ–ƒâ–â–‡â–…â–‚â–†â–ƒâ–ƒâ–„â–„â–„â–â–‚â–…
wandb:      train/policy_loss â–„â–ˆâ–â–â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–â–ˆâ–„â–„â–â–â–â–ˆâ–„â–„â–â–„â–â–„â–„â–„â–â–„â–„â–„â–ˆâ–„â–„â–â–„â–ˆâ–„â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–„â–â–â–†â–„â–ˆâ–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–„â–„â–â–ˆâ–„â–„â–„â–ˆâ–â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79529
wandb: best/eval_avg_mil_loss 0.68379
wandb:  best/eval_ensemble_f1 0.79529
wandb:            eval/avg_f1 0.64917
wandb:      eval/avg_mil_loss 0.77906
wandb:       eval/ensemble_f1 0.64917
wandb:           train/avg_f1 0.6994
wandb:      train/ensemble_f1 0.6994
wandb:         train/mil_loss 0.75374
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run resilient-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d5ribwe6
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112652-d5ribwe6/logs
wandb: ERROR Run d5ribwe6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: aclc2x1t with config:
wandb: 	actor_learning_rate: 0.00011089479661490406
wandb: 	attention_dropout_p: 0.29640859009938203
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08246133339716244
wandb: 	temperature: 7.843136826478361
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112922-aclc2x1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aclc2x1t
wandb: uploading history steps 72-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–
wandb: best/eval_avg_mil_loss â–
wandb:  best/eval_ensemble_f1 â–
wandb:            eval/avg_f1 â–ˆâ–„â–…â–ƒâ–ƒâ–†â–†â–…â–‡â–„â–‚â–†â–ƒâ–†â–„â–‡â–…â–ƒâ–†â–…â–â–†â–†â–‡â–â–‡â–†â–„â–ƒâ–„â–†â–†â–†â–…â–„â–†â–…â–†â–‡â–…
wandb:      eval/avg_mil_loss â–…â–…â–…â–ˆâ–…â–ƒâ–‡â–ˆâ–…â–‡â–„â–†â–†â–…â–„â–„â–…â–„â–…â–‚â–‡â–…â–…â–„â–†â–ˆâ–†â–â–‡â–ˆâ–…â–…â–†â–ˆâ–„â–…â–ƒâ–†â–‚â–„
wandb:       eval/ensemble_f1 â–…â–ƒâ–…â–ƒâ–ƒâ–„â–†â–†â–ˆâ–‚â–†â–…â–„â–‚â–„â–†â–‡â–ˆâ–…â–†â–†â–„â–…â–â–…â–‡â–â–†â–ˆâ–†â–„â–…â–‡â–…â–„â–…â–‡â–…â–‡â–†
wandb:           train/avg_f1 â–†â–‚â–‚â–„â–‚â–†â–†â–‡â–„â–‚â–„â–ƒâ–‡â–†â–„â–ƒâ–‚â–„â–ƒâ–…â–‚â–„â–…â–„â–‚â–‡â–„â–‚â–†â–„â–„â–†â–ˆâ–ƒâ–â–ƒâ–†â–†â–„â–„
wandb:      train/ensemble_f1 â–‡â–†â–ƒâ–†â–…â–„â–„â–†â–…â–‡â–â–ˆâ–…â–„â–…â–…â–„â–…â–…â–…â–…â–†â–„â–…â–†â–ˆâ–†â–‡â–‡â–†â–ƒâ–†â–‡â–„â–‡â–„â–‡â–†â–‡â–†
wandb:         train/mil_loss â–„â–†â–…â–…â–„â–„â–†â–ˆâ–‡â–†â–…â–ƒâ–ƒâ–†â–ˆâ–„â–…â–†â–„â–…â–ˆâ–ƒâ–‚â–„â–„â–ƒâ–…â–ƒâ–„â–‚â–‚â–…â–â–‚â–„â–„â–„â–…â–…â–‚
wandb:      train/policy_loss â–ˆâ–…â–…â–â–…â–â–â–…â–…â–â–…â–ˆâ–â–ˆâ–…â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–…â–…â–…â–ˆâ–â–ˆâ–ˆâ–â–â–…â–…â–â–…â–â–…â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–â–„â–„â–â–â–â–„â–ˆâ–„â–â–â–â–ˆâ–„â–ˆâ–â–ˆâ–„â–„â–ˆâ–â–„â–„â–ˆâ–â–„â–„â–ˆâ–â–â–â–„â–â–„â–„â–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77766
wandb: best/eval_avg_mil_loss 0.70978
wandb:  best/eval_ensemble_f1 0.77766
wandb:            eval/avg_f1 0.7023
wandb:      eval/avg_mil_loss 0.74924
wandb:       eval/ensemble_f1 0.7023
wandb:           train/avg_f1 0.69261
wandb:      train/ensemble_f1 0.69261
wandb:         train/mil_loss 0.67975
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run toasty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aclc2x1t
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112922-aclc2x1t/logs
wandb: ERROR Run aclc2x1t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: waz3j73h with config:
wandb: 	actor_learning_rate: 9.914492885477284e-05
wandb: 	attention_dropout_p: 0.05717764593604313
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25417834238774883
wandb: 	temperature: 7.172871357359332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113101-waz3j73h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-35
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/waz3j73h
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–†â–ˆ
wandb: best/eval_avg_mil_loss â–†â–…â–…â–ˆâ–„â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–†â–ˆ
wandb:            eval/avg_f1 â–‡â–…â–‚â–â–‚â–„â–‚â–ƒâ–„â–…â–â–†â–„â–‡â–‚â–â–ˆâ–„â–ƒâ–ƒâ–„â–…â–â–„â–â–„â–ƒâ–‚â–‚â–‡â–‚â–…â–‚â–…â–ƒâ–…â–â–ˆâ–„â–ˆ
wandb:      eval/avg_mil_loss â–‡â–ƒâ–…â–„â–…â–‡â–„â–‡â–„â–…â–‡â–‡â–‡â–…â–†â–‡â–…â–†â–ƒâ–‡â–†â–â–…â–‡â–„â–ƒâ–…â–„â–„â–…â–…â–…â–„â–ˆâ–…â–„â–†â–†â–‡â–„
wandb:       eval/ensemble_f1 â–ƒâ–…â–†â–ƒâ–ƒâ–…â–„â–†â–…â–ƒâ–ƒâ–†â–ˆâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–…â–†â–ƒâ–‡â–„â–ƒâ–…â–‚â–„â–…â–„â–…â–‚â–â–†â–…â–…â–…â–…â–„â–…
wandb:           train/avg_f1 â–…â–‚â–…â–‚â–‚â–„â–…â–„â–†â–„â–‚â–„â–ƒâ–„â–…â–ƒâ–…â–„â–„â–…â–„â–ƒâ–†â–…â–„â–„â–â–„â–‚â–ƒâ–ˆâ–…â–ˆâ–ƒâ–†â–„â–ƒâ–‚â–ƒâ–‚
wandb:      train/ensemble_f1 â–„â–ƒâ–†â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–…â–…â–…â–„â–…â–ƒâ–ƒâ–‚â–„â–†â–…â–‚â–ƒâ–…â–ƒâ–…â–â–…â–‚â–†â–†â–ˆâ–ƒâ–ˆâ–…â–…â–ƒâ–„â–ƒâ–„
wandb:         train/mil_loss â–…â–„â–…â–„â–…â–†â–†â–ƒâ–†â–„â–ˆâ–„â–…â–†â–ƒâ–‚â–„â–…â–„â–„â–„â–â–ƒâ–„â–†â–„â–ƒâ–ƒâ–‚â–„â–…â–„â–…â–…â–ƒâ–‚â–…â–ƒâ–…â–ƒ
wandb:      train/policy_loss â–…â–…â–…â–…â–…â–â–â–â–ˆâ–…â–…â–…â–ˆâ–…â–ˆâ–â–â–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–„â–„â–„â–ˆâ–„â–ˆâ–„â–„â–â–„â–â–ˆâ–ˆâ–„â–„â–ˆâ–ˆâ–ˆâ–„â–â–â–â–ˆâ–â–„â–„â–â–â–â–„â–„â–â–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80699
wandb: best/eval_avg_mil_loss 0.54072
wandb:  best/eval_ensemble_f1 0.80699
wandb:            eval/avg_f1 0.68038
wandb:      eval/avg_mil_loss 0.84545
wandb:       eval/ensemble_f1 0.68038
wandb:           train/avg_f1 0.65564
wandb:      train/ensemble_f1 0.65564
wandb:         train/mil_loss 0.71857
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run revived-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/waz3j73h
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113101-waz3j73h/logs
wandb: ERROR Run waz3j73h errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9dr2pmmv with config:
wandb: 	actor_learning_rate: 0.00010775080520053044
wandb: 	attention_dropout_p: 0.4414154089630698
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28622836175001676
wandb: 	temperature: 3.482258201356472
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113357-9dr2pmmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-36
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dr2pmmv
wandb: uploading history steps 144-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–„â–…â–…â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–‡â–†â–„â–…â–
wandb:  best/eval_ensemble_f1 â–â–„â–„â–…â–…â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–…â–‚â–„â–…â–„â–ƒâ–„â–ƒâ–ƒâ–…â–†â–â–„â–†â–‡â–…â–„â–†â–„â–…â–ˆâ–†â–‡â–†â–„â–„â–ƒâ–‡â–„â–â–ƒâ–„â–„â–„â–ƒâ–‚â–„â–ƒâ–…
wandb:      eval/avg_mil_loss â–â–ƒâ–…â–‡â–ƒâ–‡â–„â–†â–‚â–ƒâ–ˆâ–‡â–‚â–‚â–†â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–‡â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–â–â–‚â–â–…â–â–ƒâ–â–‚â–â–‚â–„
wandb:       eval/ensemble_f1 â–„â–„â–„â–…â–„â–‡â–‚â–„â–…â–„â–‚â–‚â–„â–„â–…â–†â–„â–ƒâ–†â–†â–‚â–„â–‚â–…â–‡â–ƒâ–‡â–ˆâ–†â–…â–â–„â–ƒâ–…â–…â–ƒâ–ƒâ–‚â–ƒâ–„
wandb:           train/avg_f1 â–†â–„â–„â–„â–„â–â–„â–„â–„â–„â–ƒâ–„â–…â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–…â–‡â–…â–†â–‚â–ƒâ–…â–„â–ˆâ–†â–†â–†â–„
wandb:      train/ensemble_f1 â–â–ƒâ–…â–…â–„â–ƒâ–ƒâ–„â–…â–„â–†â–…â–„â–‡â–„â–ƒâ–ƒâ–„â–†â–„â–†â–†â–‚â–„â–ƒâ–…â–†â–†â–†â–ˆâ–…â–…â–…â–‡â–ƒâ–‡â–†â–‡â–ƒâ–„
wandb:         train/mil_loss â–‡â–„â–„â–„â–‚â–„â–ˆâ–‚â–„â–‚â–ƒâ–ƒâ–‡â–„â–‚â–ƒâ–„â–„â–…â–„â–‚â–…â–‚â–‚â–‚â–â–„â–â–ƒâ–„â–â–â–ƒâ–ƒâ–‚â–„â–‚â–â–ƒâ–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–â–„â–„â–ˆâ–ˆâ–„â–ˆâ–â–„â–ˆâ–â–„â–â–ˆâ–ˆâ–„â–â–â–â–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–â–„â–ˆâ–„â–ˆâ–â–â–â–â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74953
wandb: best/eval_avg_mil_loss 0.61409
wandb:  best/eval_ensemble_f1 0.74953
wandb:            eval/avg_f1 0.65267
wandb:      eval/avg_mil_loss 0.67723
wandb:       eval/ensemble_f1 0.65267
wandb:           train/avg_f1 0.63647
wandb:      train/ensemble_f1 0.63647
wandb:         train/mil_loss 0.85469
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run distinctive-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dr2pmmv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113357-9dr2pmmv/logs
wandb: ERROR Run 9dr2pmmv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: ysci1wt4 with config:
wandb: 	actor_learning_rate: 1.5578598513624328e-06
wandb: 	attention_dropout_p: 0.4479274620082512
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27385334347573564
wandb: 	temperature: 8.800491600362486
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113708-ysci1wt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-37
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ysci1wt4
wandb: uploading history steps 196-197, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–‚â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–…â–„â–„â–…â–„â–â–„â–‚â–‚â–‚â–
wandb:  best/eval_ensemble_f1 â–â–‚â–‚â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–†â–…â–†â–ƒâ–†â–„â–‡â–„â–…â–„â–†â–„â–‡â–‡â–…â–…â–‡â–ƒâ–‡â–‡â–†â–†â–ƒâ–â–†â–ƒâ–„â–†â–ˆâ–ˆâ–‡â–‡â–‡â–†â–„â–†â–†â–ƒâ–†â–
wandb:      eval/avg_mil_loss â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–„â–†â–„â–…â–‡â–„â–„â–ƒâ–ƒâ–„â–â–ƒâ–ˆâ–ƒâ–ƒâ–…â–ƒâ–„â–â–ƒâ–‚â–ƒâ–‚â–‚â–„
wandb:       eval/ensemble_f1 â–„â–†â–†â–†â–‡â–‡â–„â–‡â–…â–‡â–†â–„â–†â–†â–„â–…â–‡â–‚â–‡â–‡â–„â–‡â–†â–‚â–‡â–†â–†â–‡â–‡â–†â–‡â–„â–â–ƒâ–ˆâ–‡â–ˆâ–‡â–‡â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–„â–ƒâ–„â–…â–†â–ƒâ–„â–ƒâ–†â–…â–„â–„â–„â–„â–‡â–„â–ƒâ–â–ˆâ–…â–ƒâ–…â–‡â–…â–â–„â–†â–„â–„â–…â–…â–„â–„â–„â–‡â–…â–„â–ƒâ–‡
wandb:      train/ensemble_f1 â–…â–ƒâ–„â–â–…â–‚â–ƒâ–‚â–„â–„â–†â–‚â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–…â–„â–‚â–ƒâ–‡â–†â–ƒâ–‡â–‡â–†â–…â–ˆâ–…â–…â–…â–„â–…â–‡
wandb:         train/mil_loss â–…â–†â–ˆâ–‡â–†â–„â–‡â–…â–†â–ƒâ–„â–„â–„â–„â–…â–„â–…â–„â–ƒâ–…â–„â–†â–ƒâ–„â–‡â–„â–‚â–…â–ƒâ–„â–‚â–‚â–â–„â–â–ƒâ–„â–‚â–ƒâ–‚
wandb:      train/policy_loss â–â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–â–„â–â–„â–ˆâ–„â–„â–â–ˆâ–â–ˆâ–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–â–ˆâ–„â–„â–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79965
wandb: best/eval_avg_mil_loss 0.66203
wandb:  best/eval_ensemble_f1 0.79965
wandb:            eval/avg_f1 0.66316
wandb:      eval/avg_mil_loss 0.75836
wandb:       eval/ensemble_f1 0.66316
wandb:            test/avg_f1 0.76564
wandb:      test/avg_mil_loss 0.51453
wandb:       test/ensemble_f1 0.76564
wandb:           train/avg_f1 0.70443
wandb:      train/ensemble_f1 0.70443
wandb:         train/mil_loss 0.64392
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run apricot-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ysci1wt4
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113708-ysci1wt4/logs
wandb: Agent Starting Run: psqe6nnp with config:
wandb: 	actor_learning_rate: 4.520585387775661e-06
wandb: 	attention_dropout_p: 0.3625792410658736
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6225386509294787
wandb: 	temperature: 7.828541467794768
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114045-psqe6nnp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-38
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/psqe6nnp
wandb: uploading history steps 97-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–â–‡â–ˆ
wandb:            eval/avg_f1 â–…â–‡â–ˆâ–†â–„â–†â–†â–‡â–…â–‚â–†â–‡â–‡â–‡â–‡â–‡â–†â–…â–‡â–„â–â–‚â–†â–ƒâ–„â–…â–â–„â–…â–„â–†â–„â–†â–‡â–ƒâ–‡â–ƒâ–…â–†â–‡
wandb:      eval/avg_mil_loss â–…â–„â–â–‚â–„â–„â–…â–…â–†â–â–ƒâ–…â–ƒâ–ƒâ–„â–„â–‚â–„â–‡â–‡â–†â–„â–‡â–ƒâ–â–ˆâ–…â–…â–…â–†â–…â–„â–„â–„â–…â–ˆâ–„â–‚â–„â–ƒ
wandb:       eval/ensemble_f1 â–‡â–‚â–ˆâ–ƒâ–„â–†â–†â–ˆâ–‚â–‡â–„â–ƒâ–‡â–†â–†â–…â–ˆâ–…â–‚â–…â–…â–…â–…â–„â–„â–ƒâ–â–‚â–†â–ƒâ–‡â–„â–„â–†â–„â–ƒâ–…â–‡â–„â–…
wandb:           train/avg_f1 â–„â–‚â–„â–†â–‚â–„â–…â–…â–ˆâ–…â–„â–‡â–†â–â–…â–‡â–…â–„â–„â–ˆâ–ˆâ–†â–†â–†â–„â–„â–„â–†â–„â–†â–„â–ˆâ–…â–„â–„â–†â–ƒâ–…â–†â–ƒ
wandb:      train/ensemble_f1 â–…â–‡â–†â–â–…â–…â–‡â–‡â–‡â–…â–‡â–ƒâ–‡â–†â–†â–ˆâ–†â–‡â–ƒâ–…â–†â–…â–‡â–…â–‡â–…â–…â–‡â–‡â–…â–…â–…â–†â–„â–†â–†â–ˆâ–ˆâ–†â–†
wandb:         train/mil_loss â–â–ƒâ–…â–…â–ƒâ–‡â–…â–†â–…â–‡â–…â–„â–ƒâ–…â–…â–„â–…â–‡â–†â–ƒâ–ƒâ–‡â–‡â–â–„â–…â–‡â–ƒâ–„â–„â–„â–†â–†â–„â–ˆâ–„â–‡â–„â–„â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80203
wandb: best/eval_avg_mil_loss 0.6848
wandb:  best/eval_ensemble_f1 0.80203
wandb:            eval/avg_f1 0.73207
wandb:      eval/avg_mil_loss 0.76889
wandb:       eval/ensemble_f1 0.73207
wandb:           train/avg_f1 0.66025
wandb:      train/ensemble_f1 0.66025
wandb:         train/mil_loss 0.83585
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run rose-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/psqe6nnp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114045-psqe6nnp/logs
wandb: ERROR Run psqe6nnp errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kgi3tggd with config:
wandb: 	actor_learning_rate: 4.858605086081431e-06
wandb: 	attention_dropout_p: 0.2513867940715429
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 76
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3060654333915255
wandb: 	temperature: 1.323962492259504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114246-kgi3tggd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-39
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgi3tggd
wandb: uploading wandb-summary.json
wandb: uploading history steps 70-77, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–â–
wandb:  best/eval_ensemble_f1 â–â–â–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–‚â–‡â–…â–„â–‡â–‡â–‡â–„â–‡â–„â–â–‡â–„â–„â–„â–‡â–‚â–„â–‡â–‡â–„â–„â–‡â–‡â–‡â–‚â–…â–…â–…â–„â–‡â–„â–„â–…â–‡â–‡â–„â–‡â–ˆ
wandb:      eval/avg_mil_loss â–„â–ˆâ–„â–ƒâ–„â–…â–â–ƒâ–‚â–â–…â–‡â–„â–†â–ˆâ–ƒâ–‡â–„â–ƒâ–â–ƒâ–‚â–†â–ƒâ–„â–‡â–„â–†â–ƒâ–ƒâ–ƒâ–„â–„â–‡â–…â–„â–ƒâ–…â–ƒâ–
wandb:       eval/ensemble_f1 â–…â–ˆâ–‡â–„â–‡â–‡â–‡â–‡â–‡â–…â–†â–„â–…â–‡â–‡â–„â–‡â–ˆâ–‡â–ƒâ–ƒâ–‡â–„â–‡â–‡â–…â–…â–ƒâ–„â–„â–‡â–‡â–„â–„â–‡â–‡â–â–„â–ˆâ–‡
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–‚â–…â–…â–„â–‡â–ƒâ–‚â–‡â–…â–…â–‡â–„â–„â–â–‡â–„â–†â–…â–„â–‚â–…â–„â–‡â–ƒâ–„â–†â–ˆâ–‡â–„â–ƒâ–†â–†â–„â–„â–„â–…â–„â–„â–ˆ
wandb:      train/ensemble_f1 â–„â–â–ƒâ–„â–…â–…â–ƒâ–†â–‡â–ˆâ–â–…â–†â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–„â–â–ˆâ–ƒâ–â–†â–‡â–…â–„â–â–†â–†â–ƒâ–ƒâ–„â–ˆâ–ƒ
wandb:         train/mil_loss â–„â–„â–„â–â–ƒâ–…â–„â–ƒâ–„â–…â–‚â–â–…â–ƒâ–‚â–‚â–†â–‡â–ˆâ–„â–ƒâ–„â–‚â–ƒâ–†â–‚â–„â–‚â–†â–ƒâ–‡â–ƒâ–ƒâ–…â–â–ƒâ–ƒâ–†â–…â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78671
wandb: best/eval_avg_mil_loss 0.71045
wandb:  best/eval_ensemble_f1 0.78671
wandb:            eval/avg_f1 0.78671
wandb:      eval/avg_mil_loss 0.71045
wandb:       eval/ensemble_f1 0.78671
wandb:            test/avg_f1 0.34754
wandb:      test/avg_mil_loss 0.82797
wandb:       test/ensemble_f1 0.34754
wandb:           train/avg_f1 0.71567
wandb:      train/ensemble_f1 0.71567
wandb:         train/mil_loss 0.72106
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vibrant-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgi3tggd
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114246-kgi3tggd/logs
wandb: Agent Starting Run: 4gl5n1uv with config:
wandb: 	actor_learning_rate: 7.712219556461768e-05
wandb: 	attention_dropout_p: 0.2656840457522922
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 186
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5238269769249163
wandb: 	temperature: 0.4917059964884174
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114413-4gl5n1uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-40
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4gl5n1uv
wandb: uploading history steps 178-186, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–‡â–‚â–‡â–ˆâ–…â–†â–…â–
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–„â–…â–…â–†â–†â–ˆ
wandb:            eval/avg_f1 â–†â–„â–…â–†â–â–‚â–†â–†â–†â–„â–ƒâ–„â–†â–‡â–â–†â–ƒâ–ƒâ–…â–…â–ˆâ–…â–†â–†â–„â–ƒâ–ˆâ–‚â–„â–‡â–†â–†â–†â–…â–…â–„â–†â–‚â–…â–„
wandb:      eval/avg_mil_loss â–†â–†â–…â–†â–‡â–ˆâ–…â–†â–„â–…â–„â–…â–‡â–ˆâ–†â–‚â–„â–…â–ƒâ–†â–…â–†â–ƒâ–†â–ƒâ–…â–†â–ƒâ–ƒâ–…â–†â–†â–ƒâ–„â–ƒâ–â–ƒâ–†â–…â–ƒ
wandb:       eval/ensemble_f1 â–†â–…â–…â–…â–â–‡â–†â–‚â–…â–†â–ƒâ–†â–…â–…â–…â–„â–„â–†â–ˆâ–…â–…â–…â–†â–ˆâ–‡â–…â–‡â–…â–…â–ˆâ–‡â–†â–…â–†â–†â–„â–…â–‡â–†â–‡
wandb:           train/avg_f1 â–„â–„â–„â–„â–‚â–â–†â–‚â–ƒâ–…â–†â–â–†â–ƒâ–‡â–…â–ƒâ–â–…â–ƒâ–ƒâ–„â–„â–…â–ƒâ–…â–„â–‡â–ˆâ–‡â–„â–„â–ƒâ–ƒâ–…â–†â–„â–„â–„â–„
wandb:      train/ensemble_f1 â–†â–†â–„â–…â–â–ƒâ–ƒâ–…â–‚â–ƒâ–‡â–ƒâ–ˆâ–„â–ˆâ–…â–†â–†â–ƒâ–†â–†â–†â–„â–…â–‡â–‡â–†â–‚â–„â–„â–…â–ƒâ–ƒâ–„â–†â–„â–†â–„â–„â–
wandb:         train/mil_loss â–„â–†â–†â–…â–…â–ƒâ–„â–‚â–…â–ˆâ–…â–ƒâ–‡â–†â–„â–†â–‡â–ƒâ–â–„â–†â–ƒâ–‚â–…â–ƒâ–ƒâ–‡â–…â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–†â–ƒ
wandb:      train/policy_loss â–ˆâ–…â–â–â–…â–…â–â–…â–ˆâ–…â–…â–…â–â–ˆâ–â–…â–ˆâ–â–â–ˆâ–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–…â–…â–ˆâ–…â–…â–…â–…â–ˆâ–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8166
wandb: best/eval_avg_mil_loss 0.53036
wandb:  best/eval_ensemble_f1 0.8166
wandb:            eval/avg_f1 0.72174
wandb:      eval/avg_mil_loss 0.76285
wandb:       eval/ensemble_f1 0.72174
wandb:           train/avg_f1 0.74198
wandb:      train/ensemble_f1 0.74198
wandb:         train/mil_loss 0.61833
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run quiet-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4gl5n1uv
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114413-4gl5n1uv/logs
wandb: ERROR Run 4gl5n1uv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 41lshgo2 with config:
wandb: 	actor_learning_rate: 7.455311604894341e-06
wandb: 	attention_dropout_p: 0.14116425922646209
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05064497656574918
wandb: 	temperature: 4.55246967054535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114817-41lshgo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-41
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41lshgo2
wandb: uploading wandb-summary.json; uploading history steps 41-53, summary
wandb: uploading history steps 41-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒ
wandb:  best/eval_ensemble_f1 â–â–„â–ˆ
wandb:            eval/avg_f1 â–‡â–â–…â–â–‡â–‡â–‡â–…â–†â–â–‡â–‡â–†â–†â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–†â–‡â–â–‡â–‡â–…â–‡â–†â–‡â–ˆâ–†â–†â–‡
wandb:      eval/avg_mil_loss â–…â–ƒâ–…â–â–ƒâ–‚â–‚â–…â–ˆâ–…â–„â–…â–„â–„â–†â–â–ƒâ–„â–„â–…â–ƒâ–†â–†â–…â–…â–…â–‡â–†â–„â–ˆâ–†â–†â–‚â–â–‚â–†â–…â–‚â–…â–
wandb:       eval/ensemble_f1 â–â–…â–‡â–†â–‡â–…â–†â–‡â–â–â–‡â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–â–„â–‡â–…â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡
wandb:           train/avg_f1 â–ƒâ–„â–„â–…â–‚â–ƒâ–ˆâ–…â–…â–†â–…â–‡â–„â–ƒâ–â–…â–‚â–ƒâ–†â–…â–„â–‡â–„â–ƒâ–†â–ƒâ–…â–†â–†â–…â–‚â–ˆâ–„â–‚â–‡â–ƒâ–ƒâ–ƒâ–†â–†
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–ƒâ–„â–â–…â–„â–‚â–ˆâ–„â–…â–‡â–…â–‡â–„â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–†â–…â–…â–†â–†â–…â–ƒâ–‡â–„â–â–†â–…â–‚â–…â–ƒâ–†â–ƒ
wandb:         train/mil_loss â–ƒâ–…â–…â–„â–â–„â–…â–„â–ƒâ–…â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‡â–ƒâ–†â–„â–„â–ƒâ–ƒâ–„â–…â–ˆâ–†â–ƒâ–„â–â–ƒâ–â–…â–…â–„â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80398
wandb: best/eval_avg_mil_loss 0.78155
wandb:  best/eval_ensemble_f1 0.80398
wandb:            eval/avg_f1 0.75948
wandb:      eval/avg_mil_loss 0.85162
wandb:       eval/ensemble_f1 0.75948
wandb:           train/avg_f1 0.73979
wandb:      train/ensemble_f1 0.73979
wandb:         train/mil_loss 0.69172
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run vocal-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/41lshgo2
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114817-41lshgo2/logs
wandb: ERROR Run 41lshgo2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: kkzmdhpa with config:
wandb: 	actor_learning_rate: 2.6899423631830757e-05
wandb: 	attention_dropout_p: 0.2896253672690912
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4678967070048192
wandb: 	temperature: 6.895588455127292
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114924-kkzmdhpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-42
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kkzmdhpa
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–„â–„â–ƒâ–…â–â–„â–‚â–„
wandb:  best/eval_ensemble_f1 â–â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–‡â–‡â–…â–…â–‚â–„â–„â–‡â–†â–…â–†â–‡â–…â–‡â–…â–…â–â–…â–ˆâ–…â–„â–„â–‡â–‡â–„â–ˆâ–…â–†â–†â–†â–â–‡â–ƒâ–…â–ˆâ–†â–„â–…
wandb:      eval/avg_mil_loss â–„â–…â–†â–„â–â–…â–…â–ƒâ–†â–…â–‚â–†â–†â–ˆâ–…â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–‡â–…â–„â–ˆâ–â–†â–„â–„â–…â–‚â–‡â–„â–„â–„â–…â–ƒâ–…â–„â–†
wandb:       eval/ensemble_f1 â–ƒâ–„â–„â–†â–ƒâ–‡â–†â–‡â–„â–â–â–†â–‡â–„â–„â–…â–†â–â–…â–…â–†â–…â–ƒâ–†â–‡â–ƒâ–…â–ƒâ–â–…â–†â–ƒâ–‡â–„â–†â–ˆâ–‚â–ƒâ–„â–ƒ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–ƒâ–„â–ƒâ–ƒâ–…â–â–„â–…â–„â–…â–„â–‚â–„â–„â–ˆâ–‡â–†â–…â–„â–‚â–ƒâ–‡â–„â–‡â–‡â–ƒâ–ƒâ–ˆâ–‡â–„â–…â–‡â–ˆâ–ƒâ–‚â–…â–„â–„â–†
wandb:      train/ensemble_f1 â–„â–‚â–„â–…â–ƒâ–â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–â–„â–ƒâ–†â–…â–ƒâ–†â–„â–ƒâ–„â–…â–†â–†â–„â–‡â–ˆâ–‚â–ˆâ–„â–†â–„â–ƒâ–†â–†
wandb:         train/mil_loss â–„â–„â–ˆâ–ƒâ–ƒâ–…â–„â–…â–„â–„â–ƒâ–…â–…â–ƒâ–…â–„â–„â–ƒâ–„â–„â–„â–ƒâ–ƒâ–„â–…â–ƒâ–…â–â–„â–ƒâ–â–„â–‚â–„â–„â–ƒâ–…â–ƒâ–…â–„
wandb:      train/policy_loss â–ˆâ–â–„â–„â–ˆâ–â–„â–„â–ˆâ–„â–„â–ˆâ–„â–ˆâ–„â–â–â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–â–ˆâ–ˆâ–„â–„â–â–ˆâ–â–„â–ˆâ–„â–„â–ˆâ–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–„â–„â–„â–„â–„â–â–ˆâ–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–â–ˆâ–„â–ˆâ–ˆâ–„â–ˆâ–„â–ˆâ–â–â–ˆâ–â–ˆâ–„â–„â–ˆâ–ˆâ–„â–„â–ˆâ–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76405
wandb: best/eval_avg_mil_loss 0.79663
wandb:  best/eval_ensemble_f1 0.76405
wandb:            eval/avg_f1 0.6284
wandb:      eval/avg_mil_loss 0.97136
wandb:       eval/ensemble_f1 0.6284
wandb:            test/avg_f1 0.61135
wandb:      test/avg_mil_loss 0.64849
wandb:       test/ensemble_f1 0.61135
wandb:           train/avg_f1 0.68453
wandb:      train/ensemble_f1 0.68453
wandb:         train/mil_loss 0.75842
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run volcanic-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kkzmdhpa
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114924-kkzmdhpa/logs
wandb: Agent Starting Run: 4te7ecxp with config:
wandb: 	actor_learning_rate: 1.429150410352577e-06
wandb: 	attention_dropout_p: 0.09033814272625684
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03797600198993212
wandb: 	temperature: 3.9286967266533046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115139-4te7ecxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-43
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4te7ecxp
wandb: uploading history steps 140-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–†â–†â–†â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–„â–ƒâ–‚â–ƒâ–
wandb:  best/eval_ensemble_f1 â–â–…â–†â–†â–†â–ˆ
wandb:            eval/avg_f1 â–ˆâ–ˆâ–„â–â–…â–‡â–ƒâ–…â–â–…â–ƒâ–†â–‡â–…â–…â–†â–ƒâ–„â–„â–ƒâ–ˆâ–…â–‡â–ƒâ–†â–„â–†â–…â–†â–„â–†â–ƒâ–‚â–†â–…â–â–„â–†â–„â–…
wandb:      eval/avg_mil_loss â–…â–‚â–ƒâ–…â–ˆâ–ˆâ–ƒâ–†â–ˆâ–†â–…â–…â–‡â–…â–‡â–â–…â–‡â–‡â–…â–†â–‡â–†â–†â–…â–â–‡â–…â–ƒâ–…â–†â–…â–…â–ƒâ–…â–‡â–†â–ˆâ–„â–ƒ
wandb:       eval/ensemble_f1 â–ˆâ–‡â–ƒâ–â–„â–‡â–ƒâ–ƒâ–†â–‡â–â–„â–…â–…â–†â–„â–…â–ƒâ–„â–„â–‡â–„â–†â–ƒâ–‚â–ƒâ–…â–…â–„â–†â–…â–†â–†â–…â–†â–ƒâ–…â–ƒâ–…â–…
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–†â–†â–…â–…â–…â–„â–„â–ˆâ–†â–…â–‡â–†â–†â–ƒâ–ˆâ–‡â–…â–…â–†â–‡â–â–…â–…â–„â–†â–†â–â–„â–…â–„â–â–‡â–†â–…â–ˆâ–†â–…â–‡â–†
wandb:      train/ensemble_f1 â–â–ƒâ–†â–†â–„â–‡â–†â–‡â–…â–ƒâ–…â–‡â–„â–ƒâ–†â–„â–ˆâ–…â–„â–…â–‡â–„â–‡â–„â–…â–„â–ƒâ–…â–ƒâ–…â–…â–‡â–…â–†â–‚â–†â–…â–…â–‡â–†
wandb:         train/mil_loss â–„â–„â–…â–‚â–ƒâ–„â–„â–‚â–‚â–„â–ƒâ–ˆâ–ƒâ–†â–„â–…â–„â–â–„â–â–„â–…â–â–…â–„â–„â–†â–‚â–ƒâ–‚â–â–‚â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–†
wandb:      train/policy_loss â–„â–„â–„â–â–„â–ˆâ–ˆâ–ˆâ–„â–â–â–„â–„â–„â–†â–„â–ˆâ–â–„â–ˆâ–ˆâ–â–†â–„â–ˆâ–â–â–â–ˆâ–„â–â–ˆâ–ƒâ–â–„â–†â–„â–â–â–„
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–â–ˆâ–ˆâ–„â–â–ˆâ–ˆâ–ˆâ–„â–â–ƒâ–„â–ˆâ–„â–„â–„â–ˆâ–„â–ˆâ–†â–„â–â–ƒâ–„â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ƒâ–ˆâ–ˆâ–â–„â–ˆâ–â–ˆâ–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7597
wandb: best/eval_avg_mil_loss 0.64532
wandb:  best/eval_ensemble_f1 0.7597
wandb:            eval/avg_f1 0.55109
wandb:      eval/avg_mil_loss 0.94224
wandb:       eval/ensemble_f1 0.55109
wandb:            test/avg_f1 0.55825
wandb:      test/avg_mil_loss 0.87999
wandb:       test/ensemble_f1 0.55825
wandb:           train/avg_f1 0.58502
wandb:      train/ensemble_f1 0.58502
wandb:         train/mil_loss 0.88817
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run deep-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4te7ecxp
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115139-4te7ecxp/logs
wandb: Agent Starting Run: arkm7fkf with config:
wandb: 	actor_learning_rate: 0.0006801536505879161
wandb: 	attention_dropout_p: 0.003920080228726586
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9455906450033404
wandb: 	temperature: 2.9320271045688475
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115446-arkm7fkf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-44
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/arkm7fkf
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–„â–…â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–‡â–
wandb:  best/eval_ensemble_f1 â–â–„â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–‡â–‡â–‚â–…â–‡â–‡â–‡â–‡â–†â–†â–â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–â–‡â–†â–†â–†â–†â–‡â–ˆâ–‚â–‡â–†â–‡
wandb:      eval/avg_mil_loss â–„â–†â–‚â–„â–„â–†â–…â–†â–…â–‚â–†â–„â–…â–†â–„â–â–„â–†â–„â–ˆâ–†â–†â–†â–…â–„â–…â–â–…â–„â–†â–â–„â–…â–„â–…â–‚â–ˆâ–†â–„â–…
wandb:       eval/ensemble_f1 â–‡â–ƒâ–…â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–ƒâ–‡â–‡â–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–ƒâ–‡â–‡â–â–‡â–‡â–‡â–„â–ˆâ–‡â–‡
wandb:           train/avg_f1 â–…â–„â–„â–„â–ƒâ–„â–„â–ƒâ–…â–…â–‡â–†â–„â–†â–ƒâ–ˆâ–†â–„â–„â–„â–ƒâ–…â–ƒâ–†â–„â–ƒâ–…â–†â–…â–„â–â–…â–…â–„â–…â–„â–ˆâ–…â–„â–…
wandb:      train/ensemble_f1 â–„â–…â–…â–„â–ƒâ–ƒâ–‚â–„â–„â–ƒâ–„â–…â–„â–†â–‡â–…â–ˆâ–ƒâ–„â–ƒâ–…â–„â–…â–â–…â–‚â–„â–„â–„â–†â–„â–„â–ƒâ–…â–…â–„â–„â–ƒâ–„â–„
wandb:         train/mil_loss â–ƒâ–ƒâ–ˆâ–„â–‡â–„â–„â–ƒâ–‚â–‚â–‡â–ƒâ–‚â–„â–†â–‚â–…â–ƒâ–†â–ƒâ–ƒâ–â–‚â–…â–‡â–‡â–…â–ƒâ–â–„â–‚â–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–†â–‚
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80277
wandb: best/eval_avg_mil_loss 0.68566
wandb:  best/eval_ensemble_f1 0.80277
wandb:            eval/avg_f1 0.77225
wandb:      eval/avg_mil_loss 0.88484
wandb:       eval/ensemble_f1 0.77225
wandb:           train/avg_f1 0.73611
wandb:      train/ensemble_f1 0.73611
wandb:         train/mil_loss 0.62574
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run silver-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/arkm7fkf
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115446-arkm7fkf/logs
wandb: ERROR Run arkm7fkf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p6zfv8xk with config:
wandb: 	actor_learning_rate: 2.832113253113707e-06
wandb: 	attention_dropout_p: 0.010831874504487748
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4268106255998936
wandb: 	temperature: 5.16665890693374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115620-p6zfv8xk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-45
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p6zfv8xk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–ˆâ–ˆâ–„â–â–„â–„
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–…â–‡â–‡â–ƒâ–…â–ˆâ–„â–‡â–†â–…â–†â–†â–…â–‡â–†â–…â–‡â–â–…â–…â–„â–‡â–‡â–‚â–†â–‡â–‡â–†â–‚â–‡â–‡â–„â–‡â–ˆâ–ƒâ–†â–…â–…â–ˆ
wandb:      eval/avg_mil_loss â–‚â–†â–†â–‡â–‡â–„â–ˆâ–ƒâ–…â–…â–†â–†â–‚â–†â–ˆâ–…â–„â–ˆâ–…â–†â–…â–…â–‚â–ƒâ–†â–†â–‚â–„â–„â–„â–…â–ƒâ–„â–„â–ˆâ–„â–†â–„â–ƒâ–
wandb:       eval/ensemble_f1 â–…â–†â–‚â–„â–†â–ˆâ–„â–‡â–ƒâ–„â–‡â–†â–†â–…â–„â–ƒâ–…â–ƒâ–ƒâ–„â–…â–‚â–„â–‚â–ƒâ–†â–†â–‡â–‡â–„â–â–„â–‡â–ˆâ–‡â–…â–†â–†â–†â–†
wandb:           train/avg_f1 â–†â–ƒâ–†â–‚â–„â–„â–â–â–‚â–…â–ˆâ–â–†â–…â–‚â–ƒâ–†â–†â–†â–„â–…â–†â–…â–…â–†â–‡â–‚â–„â–ƒâ–„â–ƒâ–‡â–ˆâ–‚â–‡â–ƒâ–ˆâ–„â–†â–‡
wandb:      train/ensemble_f1 â–…â–…â–…â–‚â–†â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‡â–ˆâ–†â–…â–†â–‚â–…â–…â–„â–†â–…â–…â–…â–…â–‚â–†â–„â–‡â–ƒâ–‡â–…â–†â–ƒâ–‚â–†â–‚â–„â–…â–ƒ
wandb:         train/mil_loss â–ˆâ–…â–†â–‡â–ƒâ–„â–…â–„â–†â–†â–„â–„â–…â–ƒâ–‡â–‚â–„â–†â–‚â–…â–†â–…â–„â–ƒâ–â–ƒâ–…â–â–„â–…â–ƒâ–â–â–‚â–„â–ƒâ–…â–ƒâ–‚â–„
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79614
wandb: best/eval_avg_mil_loss 0.67729
wandb:  best/eval_ensemble_f1 0.79614
wandb:            eval/avg_f1 0.75965
wandb:      eval/avg_mil_loss 0.54563
wandb:       eval/ensemble_f1 0.75965
wandb:           train/avg_f1 0.71602
wandb:      train/ensemble_f1 0.71602
wandb:         train/mil_loss 0.7137
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run solar-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p6zfv8xk
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115620-p6zfv8xk/logs
wandb: ERROR Run p6zfv8xk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: 19qrgpsb with config:
wandb: 	actor_learning_rate: 0.00011104639353038775
wandb: 	attention_dropout_p: 0.45976195409416154
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 83
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1868877457176208
wandb: 	temperature: 2.5055020313251997
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115930-19qrgpsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-46
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/19qrgpsb
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–â–ƒâ–‡
wandb:  best/eval_ensemble_f1 â–â–â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–‡â–‡â–‡â–ˆâ–…â–†â–‡â–…â–‡â–ˆâ–ˆâ–†â–†â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–…â–‡â–ˆâ–†â–†â–ˆâ–ˆâ–â–‡â–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–†â–‡â–…
wandb:      eval/avg_mil_loss â–‚â–‚â–ƒâ–â–„â–ˆâ–†â–ƒâ–…â–„â–…â–‚â–…â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–‡â–„â–‚â–„â–…â–„â–ƒâ–…â–â–â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„
wandb:       eval/ensemble_f1 â–ˆâ–†â–†â–ˆâ–‚â–ƒâ–‡â–†â–‚â–†â–…â–‡â–†â–…â–‡â–…â–†â–†â–‡â–ˆâ–†â–†â–ˆâ–‡â–‚â–…â–‡â–â–„â–ˆâ–ƒâ–‡â–†â–‡â–‡â–†â–ƒâ–†â–†â–‚
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–„â–„â–†â–…â–‚â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–â–â–ˆâ–ƒâ–â–â–„â–„â–…â–‚â–ƒâ–†â–…â–‚â–†â–ƒâ–…â–‡â–‚â–†â–…â–…â–ƒâ–„â–…â–ƒâ–„â–…
wandb:      train/ensemble_f1 â–…â–†â–â–„â–…â–‡â–…â–†â–ƒâ–…â–„â–…â–…â–„â–ˆâ–†â–‡â–…â–„â–…â–†â–…â–…â–„â–…â–‡â–„â–‡â–†â–„â–ƒâ–‡â–‡â–ƒâ–…â–…â–…â–…â–ˆâ–„
wandb:         train/mil_loss â–„â–„â–†â–‡â–†â–ˆâ–â–„â–…â–‚â–‡â–„â–‡â–†â–ƒâ–„â–ƒâ–ƒâ–†â–ˆâ–„â–â–†â–ˆâ–…â–â–†â–…â–…â–…â–…â–‡â–…â–‚â–‡â–„â–†â–ƒâ–†â–„
wandb:      train/policy_loss â–„â–„â–â–â–â–â–„â–ˆâ–„â–„â–â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–ƒâ–„â–„â–ˆâ–â–„â–„â–„â–â–„â–„â–ˆâ–„â–â–„â–„â–„â–„â–ˆâ–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79367
wandb: best/eval_avg_mil_loss 0.80949
wandb:  best/eval_ensemble_f1 0.79367
wandb:            eval/avg_f1 0.62877
wandb:      eval/avg_mil_loss 0.78042
wandb:       eval/ensemble_f1 0.62877
wandb:            test/avg_f1 0.8083
wandb:      test/avg_mil_loss 0.4276
wandb:       test/ensemble_f1 0.8083
wandb:           train/avg_f1 0.71893
wandb:      train/ensemble_f1 0.71893
wandb:         train/mil_loss 0.69064
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run autumn-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/19qrgpsb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115930-19qrgpsb/logs
wandb: Agent Starting Run: 4jrma0fm with config:
wandb: 	actor_learning_rate: 9.71370659587846e-05
wandb: 	attention_dropout_p: 0.03359855264001388
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.815206627968991
wandb: 	temperature: 1.703116853270792
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120103-4jrma0fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-47
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4jrma0fm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–†â–„â–„â–„â–â–‚â–‚
wandb:  best/eval_ensemble_f1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–‡â–†â–…â–‡â–†â–‡â–ƒâ–‡â–‡â–â–„â–…â–†â–…â–‡â–…â–‡â–„â–‡â–„â–ƒâ–„â–„â–†â–ˆâ–…â–ˆâ–„â–ƒâ–‡â–‡â–‚â–ˆâ–ˆâ–‡â–†â–‡â–‡â–†â–ƒ
wandb:      eval/avg_mil_loss â–„â–â–ƒâ–ƒâ–‚â–‚â–‡â–ƒâ–†â–„â–ƒâ–ˆâ–„â–‚â–‚â–„â–†â–…â–„â–‚â–†â–„â–ƒâ–â–†â–„â–†â–†â–ƒâ–…â–ƒâ–‚â–…â–„â–â–ƒâ–ˆâ–†â–†â–…
wandb:       eval/ensemble_f1 â–ƒâ–†â–…â–‡â–ƒâ–â–ƒâ–„â–†â–‡â–„â–‡â–„â–„â–…â–‡â–‡â–†â–‡â–„â–„â–ˆâ–‡â–†â–…â–ˆâ–†â–ƒâ–‡â–†â–†â–†â–„â–â–‡â–ˆâ–ƒâ–‡â–‡â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–…â–„â–„â–â–ƒâ–„â–„â–…â–‚â–ƒâ–‚â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–â–ˆâ–„â–‚â–†â–…â–ƒâ–„â–ˆâ–…â–„â–„â–…â–†â–…â–„â–‚â–†â–†â–ˆâ–‚â–…â–„
wandb:      train/ensemble_f1 â–„â–…â–ƒâ–â–‚â–†â–ƒâ–„â–‚â–…â–„â–ƒâ–†â–ƒâ–…â–ƒâ–‚â–„â–ˆâ–„â–ƒâ–ƒâ–…â–†â–â–ƒâ–…â–†â–ƒâ–ƒâ–…â–†â–…â–‚â–†â–†â–ƒâ–ƒâ–…â–
wandb:         train/mil_loss â–…â–‡â–ƒâ–…â–‡â–†â–ƒâ–„â–†â–…â–ƒâ–„â–‚â–‡â–ƒâ–„â–…â–„â–„â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‡â–…â–ƒâ–„â–„â–…â–‚â–‚â–ƒâ–„â–ƒâ–…â–„â–„â–â–ƒ
wandb:      train/policy_loss â–„â–„â–ˆâ–ˆâ–ˆâ–„â–â–ˆâ–„â–„â–„â–„â–„â–ˆâ–„â–„â–ˆâ–â–„â–â–â–„â–„â–„â–ˆâ–„â–„â–â–â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–â–„â–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7692
wandb: best/eval_avg_mil_loss 0.68744
wandb:  best/eval_ensemble_f1 0.7692
wandb:            eval/avg_f1 0.64164
wandb:      eval/avg_mil_loss 0.81515
wandb:       eval/ensemble_f1 0.64164
wandb:            test/avg_f1 0.76965
wandb:      test/avg_mil_loss 0.56143
wandb:       test/ensemble_f1 0.76965
wandb:           train/avg_f1 0.6742
wandb:      train/ensemble_f1 0.6742
wandb:         train/mil_loss 0.6495
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lively-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4jrma0fm
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120103-4jrma0fm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: eo86ziws with config:
wandb: 	actor_learning_rate: 1.7341228511187306e-06
wandb: 	attention_dropout_p: 0.3221895885093186
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11041880983322072
wandb: 	temperature: 0.22093170338566392
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120433-eo86ziws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-48
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eo86ziws
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–â–†â–…â–ˆâ–â–‚
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–†â–‡â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–‡â–‡â–‡â–„â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–„â–…â–‡â–ˆâ–‡â–‡â–‡â–ƒâ–ˆâ–„â–„â–‡â–‡â–‡â–‡â–„â–…â–‡â–ˆâ–„â–â–„â–‡â–„â–„â–‡â–‡
wandb:      eval/avg_mil_loss â–‚â–„â–„â–…â–„â–…â–…â–‚â–†â–…â–‚â–‚â–…â–‚â–„â–†â–‚â–‚â–…â–â–ƒâ–…â–…â–‚â–ˆâ–…â–„â–„â–„â–ƒâ–„â–…â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–„
wandb:       eval/ensemble_f1 â–â–†â–†â–†â–â–†â–†â–ˆâ–†â–†â–‡â–â–â–â–†â–†â–†â–†â–â–†â–‚â–‚â–â–‡â–†â–â–‡â–‡â–ƒâ–ˆâ–‡â–ƒâ–ˆâ–‡â–†â–â–‚â–‡â–â–…
wandb:           train/avg_f1 â–ˆâ–„â–ƒâ–‚â–‡â–„â–„â–ƒâ–†â–„â–„â–„â–†â–„â–‚â–‡â–…â–‡â–ƒâ–†â–ƒâ–†â–†â–†â–â–†â–‡â–†â–‡â–†â–ƒâ–‡â–„â–…â–„â–†â–…â–‡â–†â–‡
wandb:      train/ensemble_f1 â–„â–†â–‡â–†â–…â–…â–‡â–ƒâ–„â–„â–…â–…â–„â–ƒâ–„â–‚â–…â–†â–‡â–‚â–…â–‚â–‡â–â–‡â–ˆâ–…â–„â–„â–ˆâ–â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‡â–„
wandb:         train/mil_loss â–…â–„â–â–‡â–„â–…â–†â–„â–†â–„â–ˆâ–‡â–„â–…â–‡â–…â–…â–…â–ƒâ–…â–†â–†â–…â–ˆâ–†â–ƒâ–…â–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–†â–‚â–†â–‡â–…
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7883
wandb: best/eval_avg_mil_loss 0.774
wandb:  best/eval_ensemble_f1 0.7883
wandb:            eval/avg_f1 0.50776
wandb:      eval/avg_mil_loss 0.82686
wandb:       eval/ensemble_f1 0.50776
wandb:           train/avg_f1 0.672
wandb:      train/ensemble_f1 0.672
wandb:         train/mil_loss 0.72306
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fanciful-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eo86ziws
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120433-eo86ziws/logs
wandb: ERROR Run eo86ziws errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: k1l97o0a with config:
wandb: 	actor_learning_rate: 1.808157727459299e-05
wandb: 	attention_dropout_p: 0.20849141964059945
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9482437309895512
wandb: 	temperature: 3.312836214308544
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120743-k1l97o0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-49
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1l97o0a
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–…â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆâ–‚
wandb:  best/eval_ensemble_f1 â–â–…â–ˆ
wandb:            eval/avg_f1 â–‡â–„â–‚â–†â–†â–ƒâ–„â–†â–†â–ƒâ–ˆâ–…â–†â–‡â–…â–„â–…â–†â–ˆâ–‡â–…â–ƒâ–‚â–†â–…â–†â–†â–…â–†â–…â–„â–â–‡â–‡â–ˆâ–…â–„â–…â–„â–‡
wandb:      eval/avg_mil_loss â–…â–ˆâ–†â–†â–‡â–ˆâ–†â–†â–‡â–†â–…â–ƒâ–†â–…â–‚â–ƒâ–‡â–†â–ƒâ–„â–…â–…â–ƒâ–†â–ƒâ–…â–‚â–…â–†â–‚â–†â–„â–†â–ƒâ–ƒâ–„â–‚â–â–„â–
wandb:       eval/ensemble_f1 â–ƒâ–â–‚â–†â–‚â–…â–‚â–†â–ƒâ–…â–ƒâ–„â–‚â–â–…â–…â–„â–…â–‡â–†â–ƒâ–‚â–†â–â–ˆâ–„â–…â–†â–…â–‡â–…â–…â–…â–‡â–†â–„â–ƒâ–†â–ƒâ–†
wandb:           train/avg_f1 â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–…â–†â–‚â–„â–ˆâ–ƒâ–‡â–‚â–ƒâ–‚â–…â–ƒâ–†â–‚â–‚â–†â–ƒâ–„â–‚â–â–„â–†â–‡â–„â–ƒâ–‚â–†â–„â–„â–…â–…â–„â–ƒâ–ƒ
wandb:      train/ensemble_f1 â–„â–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆâ–‡â–„â–…â–ƒâ–…â–„â–„â–„â–…â–„â–‚â–ƒâ–ƒâ–…â–‚â–…â–…â–‡â–‡â–ƒâ–†â–„â–…â–…â–ƒâ–†â–†
wandb:         train/mil_loss â–…â–„â–ƒâ–…â–…â–ƒâ–…â–ƒâ–„â–ˆâ–„â–„â–„â–‚â–†â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–â–‚â–ƒ
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–…â–…â–…â–…â–…â–…â–…â–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7776
wandb: best/eval_avg_mil_loss 0.72167
wandb:  best/eval_ensemble_f1 0.7776
wandb:            eval/avg_f1 0.76233
wandb:      eval/avg_mil_loss 0.6855
wandb:       eval/ensemble_f1 0.76233
wandb:           train/avg_f1 0.75249
wandb:      train/ensemble_f1 0.75249
wandb:         train/mil_loss 0.64005
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run chocolate-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1l97o0a
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120743-k1l97o0a/logs
wandb: ERROR Run k1l97o0a errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Agent Starting Run: eovjxikb with config:
wandb: 	actor_learning_rate: 9.36559052271791e-06
wandb: 	attention_dropout_p: 0.3783155194897519
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7567684413781505
wandb: 	temperature: 8.945249125990367
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_120947-eovjxikb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-50
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/9pmgzkhh
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eovjxikb
wandb: uploading wandb-summary.json
wandb: uploading history steps 83-89, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ˆ
wandb: best/eval_avg_mil_loss â–â–ˆ
wandb:  best/eval_ensemble_f1 â–â–ˆ
wandb:            eval/avg_f1 â–‡â–ˆâ–‡â–…â–â–…â–‡â–ˆâ–…â–â–…â–‡â–„â–…â–‡â–ˆâ–…â–„â–‡â–‡â–…â–‡â–…â–…â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–„â–…â–„â–‡â–‡â–ˆâ–‡â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–â–…â–„â–…â–„â–ˆâ–„â–…â–ˆâ–…â–ƒâ–…â–â–†â–ˆâ–‚â–†â–„â–…â–ƒâ–…â–…â–…â–ƒâ–„â–…â–…â–„â–‡â–‚â–†â–…â–…â–…â–…â–„â–„â–…â–„â–†
wandb:       eval/ensemble_f1 â–ˆâ–‡â–…â–â–‡â–‡â–ˆâ–‡â–„â–…â–‡â–‡â–‡â–…â–„â–„â–„â–„â–‡â–„â–‡â–…â–‡â–‡â–‡â–„â–‡â–â–„â–‡â–‡â–‡â–…â–‡â–‡â–‡â–„â–‡â–‡â–„
wandb:           train/avg_f1 â–†â–„â–‡â–„â–ˆâ–†â–…â–‚â–†â–‡â–‚â–†â–†â–…â–‡â–ƒâ–…â–ƒâ–â–‡â–‚â–‡â–„â–…â–†â–„â–ˆâ–…â–„â–…â–†â–†â–…â–…â–…â–‡â–‡â–‡â–„â–„
wandb:      train/ensemble_f1 â–‡â–‚â–‚â–‡â–…â–…â–†â–„â–ˆâ–…â–…â–…â–‚â–„â–‚â–ƒâ–â–†â–„â–„â–‚â–†â–ƒâ–…â–„â–…â–‚â–…â–…â–ƒâ–‡â–†â–…â–„â–„â–†â–…â–†â–…â–…
wandb:         train/mil_loss â–ƒâ–„â–ƒâ–…â–ˆâ–‡â–â–„â–…â–„â–…â–…â–ˆâ–…â–†â–„â–„â–ƒâ–„â–‡â–†â–†â–ƒâ–„â–…â–‡â–„â–…â–‡â–„â–‡â–…â–…â–‚â–…â–„â–‡â–‡â–†â–†
wandb:      train/policy_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77789
wandb: best/eval_avg_mil_loss 0.85578
wandb:  best/eval_ensemble_f1 0.77789
wandb:            eval/avg_f1 0.55811
wandb:      eval/avg_mil_loss 0.94075
wandb:       eval/ensemble_f1 0.55811
wandb:           train/avg_f1 0.64439
wandb:      train/ensemble_f1 0.64439
wandb:         train/mil_loss 0.84375
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run treasured-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eovjxikb
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_120947-eovjxikb/logs
wandb: ERROR Run eovjxikb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
