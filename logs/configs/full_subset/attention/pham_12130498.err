wandb: Agent Starting Run: tmghv61g with config:
wandb: 	actor_learning_rate: 8.183053463181886e-06
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9061640147326836
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041753-tmghv61g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-1
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmghv61g
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 186-197, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–…â–…â–ˆâ–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–„â–‚â–ˆâ–ˆâ–ƒâ–â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–…â–…â–ˆâ–ˆâ–ˆ
wandb:            eval/avg_f1 â–…â–„â–‚â–„â–ƒâ–ˆâ–ƒâ–‡â–„â–„â–ƒâ–ƒâ–„â–…â–„â–ƒâ–‚â–‡â–„â–…â–†â–‡â–â–ˆâ–‚â–„â–â–…â–…â–†â–ƒâ–„â–‡â–…â–‡â–ˆâ–…â–‡â–‡â–…
wandb:      eval/avg_mil_loss â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–…â–…â–ƒâ–ˆâ–ƒâ–„â–…â–‚â–‚â–„â–ƒâ–„â–ƒâ–„â–„â–…â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–†
wandb:       eval/ensemble_f1 â–ƒâ–…â–ˆâ–‡â–„â–â–„â–„â–„â–…â–„â–ˆâ–…â–„â–„â–‡â–â–„â–â–„â–…â–…â–„â–†â–„â–…â–„â–…â–„â–ˆâ–…â–‡â–„â–‡â–‡â–‡â–…â–…â–…â–‡
wandb:           train/avg_f1 â–‡â–‚â–„â–„â–ƒâ–„â–„â–â–„â–‚â–‡â–„â–‚â–…â–…â–â–„â–‚â–†â–…â–ƒâ–…â–â–ƒâ–…â–…â–†â–„â–ˆâ–ˆâ–„â–â–‡â–ƒâ–„â–„â–…â–…â–„â–‡
wandb:      train/ensemble_f1 â–„â–‚â–ƒâ–…â–‚â–‚â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‚â–‚â–„â–‡â–â–…â–‡â–†â–‡â–ˆâ–„â–…â–ƒâ–„â–…â–„â–…â–„â–‡â–„â–„â–„â–†â–…â–‡â–†â–
wandb:         train/mil_loss â–…â–†â–‚â–‡â–…â–†â–‚â–ƒâ–„â–â–„â–†â–†â–„â–„â–…â–ƒâ–‚â–…â–ƒâ–‡â–ƒâ–…â–‚â–†â–„â–ƒâ–ƒâ–†â–â–â–‚â–„â–ˆâ–ƒâ–ƒâ–ƒâ–…â–„â–†
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–„â–„â–„
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83697
wandb: best/eval_avg_mil_loss 0.79615
wandb:  best/eval_ensemble_f1 0.83697
wandb:            eval/avg_f1 0.74571
wandb:      eval/avg_mil_loss 0.90628
wandb:       eval/ensemble_f1 0.74571
wandb:           train/avg_f1 0.73874
wandb:      train/ensemble_f1 0.73874
wandb:         train/mil_loss 0.65097
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run sparkling-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmghv61g
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041753-tmghv61g/logs
wandb: ERROR Run tmghv61g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 582, in main_sweep
wandb: ERROR     policy_network = train(
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/attention_pham.py", line 517, in train
wandb: ERROR     policy_network.load_state_dict(torch.load(early_stopping.model_address))
wandb: ERROR   File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
wandb: ERROR     raise RuntimeError(
wandb: ERROR RuntimeError: Error(s) in loading state_dict for AttentionPolicyNetwork_pham:
wandb: ERROR 	Missing key(s) in state_dict: "selector.transformations.0.0.weight", "selector.transformations.0.0.bias", "selector.transformations.0.2.weight", "selector.transformations.0.2.bias", "selector.transformations.1.0.weight", "selector.transformations.1.0.bias", "selector.transformations.1.2.weight", "selector.transformations.1.2.bias", "selector.transformations.2.0.weight", "selector.transformations.2.0.bias", "selector.transformations.2.2.weight", "selector.transformations.2.2.bias", "selector.heads.0.weight", "selector.heads.0.bias", "selector.heads.1.weight", "selector.heads.1.bias", "selector.heads.2.weight", "selector.heads.2.bias", "selector.heads.3.weight", "selector.heads.3.bias". 
wandb: ERROR 	Unexpected key(s) in state_dict: "attn_layer.weight", "attn_layer.bias". 
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8sc5dms7 with config:
wandb: 	actor_learning_rate: 3.128973254728881e-05
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7228414776924362
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042119-8sc5dms7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-2
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sc5dms7
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–ƒâ–„â–‡â–‡â–‡â–‡â–ˆ
wandb: best/eval_avg_mil_loss â–‡â–…â–…â–†â–ˆâ–ˆâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–ƒâ–„â–‡â–‡â–‡â–‡â–ˆ
wandb:            eval/avg_f1 â–ƒâ–„â–‡â–„â–‡â–ƒâ–†â–„â–‡â–‡â–‡â–ƒâ–â–†â–…â–…â–ˆâ–‡â–†â–†â–„â–ˆâ–‡â–†â–…â–†â–ˆâ–„â–ƒâ–…â–‡â–„â–‡â–„â–„â–ƒâ–…â–â–ˆâ–‚
wandb:      eval/avg_mil_loss â–…â–„â–†â–ƒâ–‚â–†â–ƒâ–â–…â–…â–ƒâ–„â–‡â–…â–…â–‡â–‚â–â–†â–†â–â–ƒâ–„â–‚â–â–„â–„â–ƒâ–…â–…â–‡â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–„â–‚
wandb:       eval/ensemble_f1 â–â–„â–„â–‡â–…â–ƒâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–„â–‡â–†â–ˆâ–‡â–„â–ˆâ–„â–†â–†â–†â–‡â–†â–†â–†â–ˆâ–„â–‡â–ƒâ–‡â–ƒâ–†â–„â–„â–†â–…â–ˆ
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–†â–…â–‚â–„â–ƒâ–â–‡â–…â–‡â–„â–…â–…â–†â–†â–„â–‚â–ƒâ–â–‡â–†â–ˆâ–†â–†â–†â–‡â–†â–…â–„â–„â–‚â–‚â–ˆâ–‡â–…â–‡â–†â–„â–„â–†â–„
wandb:      train/ensemble_f1 â–…â–…â–…â–…â–‡â–‚â–…â–…â–ƒâ–ƒâ–â–„â–†â–„â–ƒâ–…â–†â–†â–†â–†â–„â–…â–â–‡â–†â–ˆâ–‡â–ƒâ–†â–†â–ˆâ–‡â–†â–…â–…â–†â–„â–ˆâ–‚â–ƒ
wandb:         train/mil_loss â–ƒâ–†â–†â–ƒâ–„â–‚â–„â–„â–ƒâ–†â–„â–‚â–ˆâ–„â–ƒâ–‚â–…â–…â–…â–â–â–â–ƒâ–„â–…â–…â–†â–ƒâ–…â–„â–…â–ƒâ–ƒâ–„â–‚â–„â–…â–…â–‚â–ƒ
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77262
wandb: best/eval_avg_mil_loss 0.76713
wandb:  best/eval_ensemble_f1 0.77262
wandb:            eval/avg_f1 0.43827
wandb:      eval/avg_mil_loss 0.95597
wandb:       eval/ensemble_f1 0.43827
wandb:            test/avg_f1 0.55253
wandb:      test/avg_mil_loss 0.84701
wandb:       test/ensemble_f1 0.55253
wandb:           train/avg_f1 0.61737
wandb:      train/ensemble_f1 0.61737
wandb:         train/mil_loss 0.96808
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run lunar-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8sc5dms7
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042119-8sc5dms7/logs
wandb: Agent Starting Run: y9yczkmc with config:
wandb: 	actor_learning_rate: 0.0004093592216090446
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 79
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14269761607415243
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042302-y9yczkmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9yczkmc
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ˆâ–…â–ƒâ–ƒâ–‚â–
wandb:  best/eval_ensemble_f1 â–â–ƒâ–‡â–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–ƒâ–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–‡â–‚â–…â–ƒâ–â–‚â–‡â–ƒâ–‚â–…â–‡â–‚â–…â–…â–†â–„â–„â–„â–ƒâ–ˆâ–„â–…â–‚â–ƒâ–„â–†â–…â–…â–†â–ˆâ–…â–…â–‡
wandb:      eval/avg_mil_loss â–†â–…â–„â–†â–ˆâ–…â–„â–ƒâ–‡â–„â–†â–ƒâ–…â–â–…â–‚â–„â–‡â–„â–…â–„â–„â–ƒâ–„â–ƒâ–‡â–„â–…â–„â–„â–„â–„â–†â–„â–„â–…â–ƒâ–„â–ƒâ–‚
wandb:       eval/ensemble_f1 â–ƒâ–„â–„â–â–‚â–‚â–‡â–‚â–…â–„â–‡â–†â–ƒâ–‚â–„â–‚â–ƒâ–…â–†â–„â–†â–„â–„â–„â–ˆâ–…â–„â–â–‚â–†â–…â–…â–ˆâ–†â–„â–†â–â–„â–„â–†
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–â–‚â–…â–…â–…â–…â–„â–„â–…â–†â–…â–„â–„â–„â–…â–â–„â–…â–†â–„â–…â–„â–†â–‡â–ˆâ–†â–†â–…â–‡â–…â–†â–„
wandb:      train/ensemble_f1 â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–â–‚â–…â–„â–…â–„â–ƒâ–…â–„â–…â–…â–ƒâ–„â–…â–…â–„â–…â–„â–„â–…â–â–„â–„â–…â–„â–ˆâ–†â–†â–†â–†â–…â–‡â–ˆâ–ˆ
wandb:         train/mil_loss â–‡â–…â–…â–ˆâ–…â–…â–…â–‡â–„â–„â–†â–„â–…â–ƒâ–ƒâ–„â–†â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–…â–„â–‚â–„â–‚â–…â–„â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb:      train/policy_loss â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–…â–…â–…â–„â–†â–…â–…â–„â–…â–…â–ƒâ–…â–…â–…â–…â–„â–ˆâ–…â–…â–…â–ƒâ–…â–…â–…â–â–…â–…â–…â–…â–…
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77923
wandb: best/eval_avg_mil_loss 0.68143
wandb:  best/eval_ensemble_f1 0.77923
wandb:            eval/avg_f1 0.76999
wandb:      eval/avg_mil_loss 0.6585
wandb:       eval/ensemble_f1 0.76999
wandb:            test/avg_f1 0.79078
wandb:      test/avg_mil_loss 0.49598
wandb:       test/ensemble_f1 0.79078
wandb:           train/avg_f1 0.75844
wandb:      train/ensemble_f1 0.75844
wandb:         train/mil_loss 0.58513
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y9yczkmc
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042302-y9yczkmc/logs
wandb: Agent Starting Run: do0wxj9u with config:
wandb: 	actor_learning_rate: 0.0004436808120775917
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 93
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14399557390090223
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042425-do0wxj9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-4
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/do0wxj9u
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 91-94, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb: best/eval_avg_mil_loss â–ƒâ–â–ˆâ–ˆâ–†â–‡
wandb:  best/eval_ensemble_f1 â–â–‚â–ƒâ–‡â–ˆâ–ˆ
wandb:            eval/avg_f1 â–†â–†â–ˆâ–…â–ˆâ–„â–†â–‡â–…â–†â–†â–…â–ˆâ–†â–ƒâ–†â–†â–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–ƒâ–…â–„â–…â–„â–…â–…â–†â–…â–†â–†â–…â–†â–‡â–â–†â–…
wandb:      eval/avg_mil_loss â–„â–…â–…â–‡â–‚â–ƒâ–ƒâ–ƒâ–â–†â–†â–„â–ƒâ–‚â–â–ˆâ–ƒâ–ˆâ–„â–†â–‚â–‚â–‚â–‚â–…â–…â–„â–‚â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‡â–â–ƒ
wandb:       eval/ensemble_f1 â–„â–‡â–â–„â–…â–„â–ƒâ–…â–‡â–„â–ˆâ–…â–†â–†â–ƒâ–…â–‡â–ˆâ–â–ƒâ–â–„â–†â–ˆâ–…â–†â–‚â–ˆâ–…â–„â–…â–„â–†â–…â–†â–†â–†â–…â–†â–„
wandb:            test/avg_f1 â–
wandb:      test/avg_mil_loss â–
wandb:       test/ensemble_f1 â–
wandb:           train/avg_f1 â–ƒâ–†â–„â–…â–†â–ƒâ–„â–†â–…â–…â–…â–…â–…â–…â–ƒâ–„â–„â–„â–…â–‚â–„â–ˆâ–†â–†â–†â–ƒâ–‡â–†â–â–…â–‡â–…â–ƒâ–†â–…â–…â–…â–ƒâ–„â–…
wandb:      train/ensemble_f1 â–ˆâ–‡â–…â–„â–…â–†â–‡â–‚â–†â–†â–†â–…â–ˆâ–†â–†â–†â–†â–ƒâ–ƒâ–‚â–†â–„â–â–„â–„â–„â–‡â–ˆâ–…â–ƒâ–…â–ˆâ–†â–…â–ƒâ–†â–…â–‡â–„â–†
wandb:         train/mil_loss â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–†â–ƒâ–ƒâ–„â–ˆâ–„â–…â–â–„â–„â–â–‚â–„â–‚â–„â–‚â–…â–…â–„â–„â–‚â–‚â–ƒâ–…â–‚â–„â–â–ƒâ–ƒâ–„
wandb:      train/policy_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/reg_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train/total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:       train/value_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82127
wandb: best/eval_avg_mil_loss 1.0712
wandb:  best/eval_ensemble_f1 0.82127
wandb:            eval/avg_f1 0.73644
wandb:      eval/avg_mil_loss 0.903
wandb:       eval/ensemble_f1 0.73644
wandb:            test/avg_f1 0.86435
wandb:      test/avg_mil_loss 0.67687
wandb:       test/ensemble_f1 0.86435
wandb:           train/avg_f1 0.7395
wandb:      train/ensemble_f1 0.7395
wandb:         train/mil_loss 0.86423
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: ğŸš€ View run fiery-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/do0wxj9u
wandb: â­ï¸ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042425-do0wxj9u/logs
wandb: Agent Starting Run: ze1lcut0 with config:
wandb: 	actor_learning_rate: 2.8741824090481746e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13324131499936165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042603-ze1lcut0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-5
wandb: â­ï¸ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: ğŸ§¹ View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/cfz59uci
wandb: ğŸš€ View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ze1lcut0
