wandb: Agent Starting Run: kvpqjt09 with config:
wandb: 	actor_learning_rate: 0.007708266201778426
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27293589611146685
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.45080043965063865
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_041134-kvpqjt09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kvpqjt09
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 789-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ███▇▇▇▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▃▂▃▂▃▄▄▄▃▄▄▅▅▄▅▅▅▅▅▅▅▅▆▆▅▆▆▆▆▇▆▇▇██
wandb:      train/ensemble_f1 ▁▁▁▁▁▂▂▃▂▂▃▄▄▄▄▄▃▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▆▇▇███
wandb:         train/mil_loss █▇▆▆█▆▆▅▇▆▅▅▆▅▅▄▃▅▄▄▃▅▄▃▂▃▃▄▃▂▂▂▁▁▂▂▁▁▂▁
wandb:      train/policy_loss ▃▅▃▃▃▃▃▂▅▅▅▅▅▅▅▃▇█▇█▅▅▅▅▅▅██▅▁▇▅▅▅▅▅▃▂▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83015
wandb: best/eval_avg_mil_loss 0.79847
wandb:  best/eval_ensemble_f1 0.83015
wandb:            eval/avg_f1 0.83015
wandb:      eval/avg_mil_loss 0.78734
wandb:       eval/ensemble_f1 0.83015
wandb:            test/avg_f1 0.88031
wandb:      test/avg_mil_loss 0.54479
wandb:       test/ensemble_f1 0.88031
wandb:           train/avg_f1 0.82999
wandb:      train/ensemble_f1 0.82999
wandb:         train/mil_loss 0.74167
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kvpqjt09
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_041134-kvpqjt09/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g7l7zip0 with config:
wandb: 	actor_learning_rate: 0.0020525371209657254
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24933129485033032
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6713730659469996
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042449-g7l7zip0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7l7zip0
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▃▃▃▄▃▆▅▄▂▅▅▃▆▅▆▁▂▅▅▃▄▆▂▃▂▂▁▄▄▂▅█▄▆▄▄▂
wandb:      train/ensemble_f1 ▅▇▅▄▇▃█▄▃▆▂▆▆▃▇▁▃▂▄▅▃▅▄▄▅▄▅▂▄▃▆▄▅▇▅▅▂▇▄▄
wandb:         train/mil_loss ▂▅▇█▅▆▆▅▅▄▄▁▃▄█▅▄▃▅▃▇▃▃▃▄▆▅▆▄▄▅▆▅▃▃▆▃▄▄▆
wandb:      train/policy_loss ▅▅▃▇▃▄█▃▄▄▁▄▅▅▄▅▅▅▄▆▃▃▅▅▅▂▆▃▆▆▄▅▂▃▆▇▂▆▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▂▇▄▃█▄▄▄▄▅▂▄▅▅▆▁▄▅▅▄▆▃▃▃▃▆▃▆▆▅▄▃▃▃▂▆▅▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.33501
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.26771
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.48341
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33877
wandb:      train/ensemble_f1 0.33877
wandb:         train/mil_loss 0.95201
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7l7zip0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042449-g7l7zip0/logs
wandb: Agent Starting Run: xfi1ef8x with config:
wandb: 	actor_learning_rate: 1.194729717697474e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.272259976448876
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5652966698333444
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042632-xfi1ef8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xfi1ef8x
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▁▁▁▂▂▂▃▃▃▃▃▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆█▃▇▃▃▂▄▃▄▆▅▂▃▄▃▅▂▃▅▂▄▄▃▅▄▆▆▁▅▅▃▆▃▂▅▃▃▆
wandb:      train/ensemble_f1 ▃▇▄▂▂▁▆▁▃▃▆▄▁▃█▃▅▄▇▅▃▄▄▃▅▄▃▂▄▆▅▃▃▅▂▄▃▆▄▄
wandb:         train/mil_loss ▄▄▅▂▇▇▄▇█▆▅▇▄▄▂▅▄▄▇▂▇▆▅▂▁▄▅█▄▃▂▄▅▃▂▆▃█▆▅
wandb:      train/policy_loss ▅▃▇▃▅▂▄▄▂▄▄▆▄▅▄▅▅▆▅▄▇▂▄▅▄▅▃▂█▅▂▅▃▄▆▃▆▂▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▂▇▇▅▁▄▁▃▂▆▃▅▄▆▂▃▅▆▃▄▁▄▄▄▅▃▁▄█▂▁▄▅█▃▁▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.92761
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.87097
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29704
wandb:      test/avg_mil_loss 1.96032
wandb:       test/ensemble_f1 0.29704
wandb:           train/avg_f1 0.34004
wandb:      train/ensemble_f1 0.34004
wandb:         train/mil_loss 1.3237
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xfi1ef8x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042632-xfi1ef8x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: flcq4l42 with config:
wandb: 	actor_learning_rate: 0.00750701660279077
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3077709166041104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3282656156576732
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_042822-flcq4l42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flcq4l42
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▃▂▃▂▄▂▃▄▄▃▄▄▇▃▆▅▄▁▆▅▁▅█▇▇▇▃▅▄▅▄▃▂▃▅▃▂
wandb:      train/ensemble_f1 ▅▅▆▆▃▅▇▄▃▃▄▄▅▄▅▂▇▄▇▃▆▇▅▁▄▁▅▆▅██▃▆▅▃▂▃▅▃▄
wandb:         train/mil_loss ▄▆▆▅▄▄▅▆▃▄▇▄▆▄▆▅█▇▆▅▇▄▇▃▅▇█▄▅▄▆▄▄▆▁▃▄▆▆▄
wandb:      train/policy_loss ▆▄▄▅▆▂▄▇▇▂▇▆▅▆▆▄▅▅▄▁▂▄█▃▄▅▇▄▄▄▄▅▄▄▄▃▄▅▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▄▃▂▃▅▁▆▂▆▅▂▅▅▁▃▃▃█▁▇▅▁▁▇▁▂▁▃▅▁▅▆▄▆▃▆▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.26069
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.23217
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.41677
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32657
wandb:      train/ensemble_f1 0.32657
wandb:         train/mil_loss 1.01732
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/flcq4l42
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_042822-flcq4l42/logs
wandb: Agent Starting Run: pfznqp43 with config:
wandb: 	actor_learning_rate: 0.007444311890431547
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2572847144130722
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5098977662512396
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043005-pfznqp43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pfznqp43
wandb: uploading wandb-summary.json
wandb: uploading history steps 273-283, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▅▃▃▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▅▅▅▅▅▅▆███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▅▅▅▅▆▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▃▃▂▂▄▄▄▂▃▃▄▂▃▃▃▅▂▅▃▂▅▅▄▇▂▅▅▆██▆▆▆▇▇█▇
wandb:      train/ensemble_f1 ▃▁▃▂▄▃▃▄▃▅▃▄▃▃▃▃▄▃▃▅▄▄▄▆▅▅▇▅▅▅▃▇▅▃▆▅▇█▆▆
wandb:         train/mil_loss ▄▆▆█▄▆▄▃▃█▅▅▄▅▅▄▅▄▄▄▁▄▂▅▂▁▃▅▃▃▅▄▂▃▂▄▁▂▁▃
wandb:      train/policy_loss ▆██▇▆▇█▇▅▆▆▅▇▇▇▄▄▄▄▁▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆█▆▇▆▅▆▇▇▅▇▇▇▆▇▇▄▄▂▂▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71206
wandb: best/eval_avg_mil_loss 1.51292
wandb:  best/eval_ensemble_f1 0.71206
wandb:            eval/avg_f1 0.71206
wandb:      eval/avg_mil_loss 1.3765
wandb:       eval/ensemble_f1 0.71206
wandb:            test/avg_f1 0.72295
wandb:      test/avg_mil_loss 1.23059
wandb:       test/ensemble_f1 0.72295
wandb:           train/avg_f1 0.69223
wandb:      train/ensemble_f1 0.69223
wandb:         train/mil_loss 1.23861
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pfznqp43
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043005-pfznqp43/logs
wandb: Agent Starting Run: 6hp0kmri with config:
wandb: 	actor_learning_rate: 2.0856403505390096e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6059729934395187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9355814882378508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043437-6hp0kmri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6hp0kmri
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▆▇▇█
wandb: best/eval_avg_mil_loss ▂█▄▄▂▂▂▂▁▂
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▆▇▇█
wandb:            eval/avg_f1 ▃▂▁▁▂▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▆▆▅▅▆████▇▆▇▇▇▇████▆
wandb:      eval/avg_mil_loss ▆▆▆█▇▆▇▇▇▇▇██▇▇▆▆▃▃▃▃▂▁▂▁▁▁▁▁▁▁▂▂▁▂▂▁▁▂▂
wandb:       eval/ensemble_f1 ▁▁▂▂▂▃▃▂▃▂▃▃▃▂▂▃▄▄▄▄▄▄▄▄▄▅▆██▇▇▆▆▆▇▇▇▇▇▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▂▂▄▆▄▅▃█▆▃▃▂▂▆▄▃▅▆▅▅▆▆▃▅▄▇▆▇▆▅▄▆▄▇▄▅▆▃
wandb:      train/ensemble_f1 ▂▄▆▅█▅▃▅▁▂▂▃▆▅▇▅▇▆▂▃▃▆▅▆▇▆▅▆▇▅▇▃▃▄▃█▅▄▄▄
wandb:         train/mil_loss ▆▆▅▄▃▂▂▅▅▃▂▅▄▂▅▆▅▆▂▁▂▇▄▄▁▇▅▆▅▄█▃▃▂▆▆▆▃▂▃
wandb:      train/policy_loss ▁▅▅▄▅▅▃▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅█▅▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▄▅▅▅█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68566
wandb: best/eval_avg_mil_loss 0.58509
wandb:  best/eval_ensemble_f1 0.68566
wandb:            eval/avg_f1 0.66618
wandb:      eval/avg_mil_loss 0.58551
wandb:       eval/ensemble_f1 0.66618
wandb:            test/avg_f1 0.70146
wandb:      test/avg_mil_loss 0.55843
wandb:       test/ensemble_f1 0.70146
wandb:           train/avg_f1 0.67267
wandb:      train/ensemble_f1 0.67267
wandb:         train/mil_loss 0.56077
wandb:      train/policy_loss 0.13666
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.13666
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vague-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6hp0kmri
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043437-6hp0kmri/logs
wandb: Agent Starting Run: 4r49x9cu with config:
wandb: 	actor_learning_rate: 0.007037717393912894
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7953952563286601
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4548420341926426
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_043916-4r49x9cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4r49x9cu
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss ▁▇█▇
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▄█▁▁▁▂▂▂▃▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▃▃▃▃▃▃███████▄▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▄▂▁▁▁▁▁▂▃▅███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁██▃▂▁▂▁▂▂▃▅▇▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇
wandb:      train/ensemble_f1 ▁▁▁▂▁▂▁▃█▃▁▂▃▂▂▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇
wandb:         train/mil_loss ▃▃▂▂▃▂▄▅▂▆▅▅█▂▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▂▂▁▁▁▁▂▂▂▁▁
wandb:      train/policy_loss ▇▇▇▆▅▄▆▅█▂▃▄▄▄▁▆▇▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82952
wandb: best/eval_avg_mil_loss 1.14213
wandb:  best/eval_ensemble_f1 0.82952
wandb:            eval/avg_f1 0.75083
wandb:      eval/avg_mil_loss 0.41571
wandb:       eval/ensemble_f1 0.75083
wandb:            test/avg_f1 0.86739
wandb:      test/avg_mil_loss 1.10715
wandb:       test/ensemble_f1 0.86739
wandb:           train/avg_f1 0.79416
wandb:      train/ensemble_f1 0.79416
wandb:         train/mil_loss 0.46115
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4r49x9cu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_043916-4r49x9cu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: na7afqov with config:
wandb: 	actor_learning_rate: 0.0047675472150524095
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3361004287217314
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16572542814786395
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044138-na7afqov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/na7afqov
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▃▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▂▂▁▁██████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ██████████████▃▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▇▆▆▆▇██▇▇█▂▂▂▂▂▂▂▃▂▂▁▃▂▃▂▂▂▃▃▂▄▃▄▃▃▂▃
wandb:      train/ensemble_f1 ▇▆█▇▇▇▇▇█▇█▆█▃▂▂▂▂▂▂▃▃▃▂▁▃▃▂▃▂▂▃▃▃▃▄▃▂▃▂
wandb:         train/mil_loss ▁▂▅▃▂▆▅▂▃▅▅█▇▂▄▄▄▃▄▄▄▅▅▄▅▅▃▅▄▅▃▄▂▃▅▅▄▃▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▆█▆▅▆▇▁▅▆▄▆▆▆▆▆▅▅▆▆▆▇▅▅▅▅▃▆▆▄▅▇▅▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61412
wandb: best/eval_avg_mil_loss 2.26037
wandb:  best/eval_ensemble_f1 0.61412
wandb:            eval/avg_f1 0.55745
wandb:      eval/avg_mil_loss 2.37002
wandb:       eval/ensemble_f1 0.55745
wandb:            test/avg_f1 0.64209
wandb:      test/avg_mil_loss 1.63946
wandb:       test/ensemble_f1 0.64209
wandb:           train/avg_f1 0.55334
wandb:      train/ensemble_f1 0.55334
wandb:         train/mil_loss 1.61241
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/na7afqov
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044138-na7afqov/logs
wandb: Agent Starting Run: nx40ctl5 with config:
wandb: 	actor_learning_rate: 0.001339247248494177
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8772398230645562
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03419013409381355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044322-nx40ctl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nx40ctl5
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▂▅▂▁▅▆▃▁▄▂▆▅▄▄█▁▆▃▃▅▁▃▄▆▃▂▁▆▁▂▂▄▃▅▅▅▂
wandb:      train/ensemble_f1 ▄▄▇▄▄▃▆▁▄▆█▄▅▅▆▃▇▆▄▅▅▄▂▄▃▄▄▆▇▅▄▅▄▅▃▃▃▂▆▆
wandb:         train/mil_loss ▂▄▅▃▂▅▅▆▅▄▃▁▄▄▅▃▃▂▁▁▃█▂▄▂▁▂▆▄▃▂▃▂▁▂▃▂▃▃▁
wandb:      train/policy_loss ▃▆▇▃▃▇▇▃▅▆▁▅▇▄▃▆▂▇▆▆▆▇█▆▇▆▇▇▃▂▆▆▆▆▆▅▃▅▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▂▅▂▂▄█▁▄▇▄▇▅▅▇▅▄▅▇▁▅▅▄▄▇▄▇▅▄▅▅█▅▇▅▂▅▂▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47002
wandb: best/eval_avg_mil_loss 2.53115
wandb:  best/eval_ensemble_f1 0.47002
wandb:            eval/avg_f1 0.47002
wandb:      eval/avg_mil_loss 2.445
wandb:       eval/ensemble_f1 0.47002
wandb:            test/avg_f1 0.495
wandb:      test/avg_mil_loss 1.97636
wandb:       test/ensemble_f1 0.495
wandb:           train/avg_f1 0.47392
wandb:      train/ensemble_f1 0.47392
wandb:         train/mil_loss 0.57814
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nx40ctl5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044322-nx40ctl5/logs
wandb: Agent Starting Run: ipm63qkp with config:
wandb: 	actor_learning_rate: 1.869771585666333e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.44947420526241566
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2165939574401402
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044505-ipm63qkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipm63qkp
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▆▆▅▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▂▂▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅████▇▇▇▇▇▇▇▇▇██
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▃▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆██▇▇▇▇▇▇▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▄▃▃▂▂▃▃▅▂▄▃▄▂▃▆▃▄▄▄▅▃▃▅▆▆▅▅▅▇▇▆▅█▇▇█▆
wandb:      train/ensemble_f1 ▃▂▂▃▁▄▁▃▂▄▂▁▅▁▅▃▆▄▄▃▂▅▄▄▇▇▄▅▄▅▄▆▅▇▅███▇█
wandb:         train/mil_loss ▂▆▇▃▆▅▄▇▄▄▆▄█▆▁▄▃▄▄▄▁▆▂▅▃▄▆▂▂▃▄▄▄▂▄▄▆▃▆▅
wandb:      train/policy_loss ▅▄▆▃▇▅▅▅▂▂▃▆▁▇▅▅▄▅▂▄█▇▅▂▁▅█▄▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▆█████████████▁██████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58202
wandb: best/eval_avg_mil_loss 2.42647
wandb:  best/eval_ensemble_f1 0.58202
wandb:            eval/avg_f1 0.58202
wandb:      eval/avg_mil_loss 2.24541
wandb:       eval/ensemble_f1 0.58202
wandb:            test/avg_f1 0.57664
wandb:      test/avg_mil_loss 1.80515
wandb:       test/ensemble_f1 0.57664
wandb:           train/avg_f1 0.57489
wandb:      train/ensemble_f1 0.57489
wandb:         train/mil_loss 1.60596
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipm63qkp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044505-ipm63qkp/logs
wandb: Agent Starting Run: krwaoe6x with config:
wandb: 	actor_learning_rate: 0.0001513352248944561
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9935118262549246
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.747589149118415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_044927-krwaoe6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krwaoe6x
wandb: uploading history steps 126-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▅▁▆
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▃▃▆▆▆▇▇▇▇██████████████▃▃▁▁▃▁▃▃▃▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▃▂▁▁▂▁▂▂▂▂▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇████
wandb:       eval/ensemble_f1 ▄▄▄▄▄▆▆▆▅▇▇██████████████▄▄▂▂▄▆▁▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▂▆▃▆▆▇▃▄▅▃▃▂▃▆▃▄▃▃▅▄▇▄█▆▇▃▅▂▆▃▂▄▅▄▆▃▄▁
wandb:      train/ensemble_f1 ▃▃▅▄▂▃▅▂▅▄▆▃▃▅▄▃▄▄▃▄▃▅▅▄▃▄▄▃▇▄▄▂▂▁▁█▄▄▆▅
wandb:         train/mil_loss ▅▇▂█▅█▅▆▆▄▅▃▃▄▄▇▇▅▆▅▅▆▇▆▆▅█▁▅▅▅▆▅▅▄▇▅▂▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▁▄█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65053
wandb: best/eval_avg_mil_loss 0.68183
wandb:  best/eval_ensemble_f1 0.65053
wandb:            eval/avg_f1 0.63481
wandb:      eval/avg_mil_loss 0.69232
wandb:       eval/ensemble_f1 0.63481
wandb:            test/avg_f1 0.67661
wandb:      test/avg_mil_loss 0.54124
wandb:       test/ensemble_f1 0.67661
wandb:           train/avg_f1 0.60677
wandb:      train/ensemble_f1 0.60677
wandb:         train/mil_loss 0.51061
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krwaoe6x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_044927-krwaoe6x/logs
wandb: Agent Starting Run: s2s6m987 with config:
wandb: 	actor_learning_rate: 5.128368401258084e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6369002040771482
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.046345921392763056
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_045147-s2s6m987
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s2s6m987
wandb: uploading history steps 617-628, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▆▆▅▄▄▄▃▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▇▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▃▂▁▃▃▁▂▃▂▃▃▄▄▄▅▄▃▅▅▆▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇█
wandb:      train/ensemble_f1 ▁▃▃▃▄▃▄▄▂▄▄▄▅▄▅▆▅▆▅▅▅▆▅▅▅▇▆▇▆▆▇▆▇▇▇▇█▆▇▇
wandb:         train/mil_loss ▇▆▅▂▅█▂▆▄▃▄▅▄▄▄▃▃▃▄▄▂▄▁▄▄▅▄▃▄▃▃▃▄▄▂▅▄▃▂▂
wandb:      train/policy_loss ▁▁▁▆▇▁▁▁▁▁▁▁▁▁▁▁▃▁█▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6284
wandb: best/eval_avg_mil_loss 1.8596
wandb:  best/eval_ensemble_f1 0.6284
wandb:            eval/avg_f1 0.6284
wandb:      eval/avg_mil_loss 1.76715
wandb:       eval/ensemble_f1 0.6284
wandb:            test/avg_f1 0.66037
wandb:      test/avg_mil_loss 1.32754
wandb:       test/ensemble_f1 0.66037
wandb:           train/avg_f1 0.62639
wandb:      train/ensemble_f1 0.62639
wandb:         train/mil_loss 0.94028
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s2s6m987
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_045147-s2s6m987/logs
wandb: Agent Starting Run: j6t8fc26 with config:
wandb: 	actor_learning_rate: 1.0606942606704252e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.37233255856607694
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5121665647841279
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050150-j6t8fc26
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6t8fc26
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▅▇▃▅▅▅▆▅▆▆▇▆▃▅▇▄▇▄▆▅▄▃▅▁▅▆▄▅█▆▆▇▅▇▃▁█
wandb:      train/ensemble_f1 ▅▇▄▆▄▄▆▃▃▅▅▄▆▆▇▃▅▄▅▆▅▅▅▄▁▆▅▄▇▂▆▆▃▆█▅▇▅▃▆
wandb:         train/mil_loss ▄▄▆▇▄▅▃▄▆▃▄▄▇▁▃█▁▅▅▄▂▅▃▂▅▄▅▃▄▃▃▅▆▆▄▃▆▁▄▅
wandb:      train/policy_loss ▅▅▄▆▆▄▄▅▅▆▆▅▅▃▇▄▆▄▄▄▅▅▁▇▃▃█▄▆▅▅▄▄▄▅▅▄▆▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▂▅▆▆▄▄▅▃▅▄▄█▆▃▄▅▄▅█▃▇▃▆▅▅▅▅▅▆▂▁▅▂▆▃▅▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.03076
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.99331
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.13561
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.34214
wandb:      train/ensemble_f1 0.34214
wandb:         train/mil_loss 0.80775
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6t8fc26
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050150-j6t8fc26/logs
wandb: Agent Starting Run: se1vqxka with config:
wandb: 	actor_learning_rate: 0.00030780270236846014
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9005759458038916
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4822694859881721
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050333-se1vqxka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/se1vqxka
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▄▄▂▅▅▅▂▄▂▃▄▃▅▃▅▄▃▃▃▅▁▃▄▄▁█▂▁▃▄▃▄▁▃▄▃▄
wandb:      train/ensemble_f1 ▄▅▃▄▆▆▃█▃▆▃▆▅▅▄▄▅█▁█▅▇▅▇▁▅▆▁▅▂▇▄▆▄▅▄▃▆▇▆
wandb:         train/mil_loss ▁▄▂▂▄▂▃▃▆▂▄▅▆▄▄█▃▂▅▁▄▂▂▅▁▄▆▅█▆▁▂▁▂▃▁▄▂▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3225
wandb: best/eval_avg_mil_loss 1.12994
wandb:  best/eval_ensemble_f1 0.3225
wandb:            eval/avg_f1 0.3225
wandb:      eval/avg_mil_loss 1.11209
wandb:       eval/ensemble_f1 0.3225
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.26909
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33372
wandb:      train/ensemble_f1 0.33372
wandb:         train/mil_loss 0.49963
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/se1vqxka
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050333-se1vqxka/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g1lsfxk6 with config:
wandb: 	actor_learning_rate: 0.004484357976320171
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8274500269372553
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7041487202230451
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050545-g1lsfxk6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1lsfxk6
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁█▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▂▁▄▅▄▇▃▅▄▃▇▄▄▅▁▇▅▅▃▅▂▆▁▅▄▃▆▄█▇▃▂▃▄▇█▃▆█
wandb:      train/policy_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▆▇▅▅▅▆▃█▆▄▆▂▄▁▇▂▃▃▅▆▃█▆▂▃▄▇▂▇▆▂▂▇▁▄▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74365
wandb: best/eval_avg_mil_loss 0.79962
wandb:  best/eval_ensemble_f1 0.74365
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.02906
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.81654
wandb:      test/avg_mil_loss 0.45035
wandb:       test/ensemble_f1 0.81654
wandb:           train/avg_f1 0.3276
wandb:      train/ensemble_f1 0.3276
wandb:         train/mil_loss 0.64848
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1lsfxk6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050545-g1lsfxk6/logs
wandb: Agent Starting Run: cfdimcmo with config:
wandb: 	actor_learning_rate: 8.841707792354208e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.005791906494762689
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.494537094053184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_050728-cfdimcmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cfdimcmo
wandb: uploading history steps 613-620, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ███▇▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▆▆▆▇▇▇▆▇▆▆▆▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▄▆▆▆▆▇▆▇▇▇█▇▇▇██▇▇█▇
wandb:      train/ensemble_f1 ▂▁▁▂▃▄▃▃▃▄▅▅▅▅▅▅▆▅▅▆▆▆▇▆▅▆▆▇▆▇▇▆▇▇▇▇███▇
wandb:         train/mil_loss ██▇▆▆▅▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:      train/policy_loss ██████████████████████████▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▄███████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81403
wandb: best/eval_avg_mil_loss 0.46093
wandb:  best/eval_ensemble_f1 0.81403
wandb:            eval/avg_f1 0.8105
wandb:      eval/avg_mil_loss 0.44308
wandb:       eval/ensemble_f1 0.8105
wandb:            test/avg_f1 0.87348
wandb:      test/avg_mil_loss 0.24755
wandb:       test/ensemble_f1 0.87348
wandb:           train/avg_f1 0.84651
wandb:      train/ensemble_f1 0.84651
wandb:         train/mil_loss 0.40481
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cfdimcmo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_050728-cfdimcmo/logs
wandb: Agent Starting Run: 32u93o8z with config:
wandb: 	actor_learning_rate: 0.0001797218209753534
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23629338256660593
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21565174428641576
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051711-32u93o8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/32u93o8z
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄▄▅▅▅███
wandb: best/eval_avg_mil_loss █▇▇▅▅▄▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▄▄▅▅▅███
wandb:            eval/avg_f1 ▁▄▅▅████████████████████████████████████
wandb:      eval/avg_mil_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▄▄▅████▇▇███▇▇▇▇▇██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▇▇██▇▇▆▇▇▇▇▆▇▆▆▆▇▇▇█▇▇▇▇▇█▇▇▆▇▇▇▆▆▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▇▇▆▅▆▅▃▂▅▅▇▄▆▅▅▄▃▅▇▄▅▆▆▆▆▅▆▇▆▅▇▆▄▅█▆▆▇
wandb:         train/mil_loss █▆▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂
wandb:      train/policy_loss ▁████▇██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86702
wandb: best/eval_avg_mil_loss 0.63398
wandb:  best/eval_ensemble_f1 0.86702
wandb:            eval/avg_f1 0.86024
wandb:      eval/avg_mil_loss 0.60488
wandb:       eval/ensemble_f1 0.86024
wandb:            test/avg_f1 0.87967
wandb:      test/avg_mil_loss 0.29725
wandb:       test/ensemble_f1 0.87967
wandb:           train/avg_f1 0.83924
wandb:      train/ensemble_f1 0.83924
wandb:         train/mil_loss 0.44577
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/32u93o8z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051711-32u93o8z/logs
wandb: Agent Starting Run: 912o8oyh with config:
wandb: 	actor_learning_rate: 4.869535234881138e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9727834230115564
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34842395956557237
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_051909-912o8oyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/912o8oyh
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ██▅▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆█▆████████▆▃▆▆▆
wandb:      eval/avg_mil_loss █████████▇▆▇▆▆▆▆▆▆▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅█████████▅▅▅▅▅▁▁▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▅▆▅▄▃▃▄▁▄▃▄▄▂▃▄▃█▆▃▂▃▃█▄▂▄▆▄▄▇▆▆▅▄▅▇▃
wandb:      train/ensemble_f1 ▇▇▆▄▅▄▅▃▄▂▅▃▁▁▃▄█▆▂▆▅▂▅▅▅▂▂▆▄▅▇▄▇▅▄▇▄▅▄▄
wandb:         train/mil_loss ▃▂▄▂▂▂▄▄▃▃█▁▄▂▂▄▁▂▃▃▃▂▅▃▃▃▄▂▂▂▃▂▃▅▄▃▁▂▂▁
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73881
wandb: best/eval_avg_mil_loss 1.06675
wandb:  best/eval_ensemble_f1 0.73881
wandb:            eval/avg_f1 0.73414
wandb:      eval/avg_mil_loss 1.04523
wandb:       eval/ensemble_f1 0.73414
wandb:            test/avg_f1 0.7846
wandb:      test/avg_mil_loss 0.73166
wandb:       test/ensemble_f1 0.7846
wandb:           train/avg_f1 0.75301
wandb:      train/ensemble_f1 0.75301
wandb:         train/mil_loss 0.50746
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/912o8oyh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_051909-912o8oyh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7s2y4gvm with config:
wandb: 	actor_learning_rate: 2.4806543245057556e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5091968194843832
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2690053874960794
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_052322-7s2y4gvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7s2y4gvm
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▂▂▂▃▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ████▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▃▃▄▄▅▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇▇████▇
wandb:      train/ensemble_f1 ▁▁▂▂▃▃▄▃▄▄▅▆▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇███
wandb:         train/mil_loss ▆█▅▄▆▆▅▄▅▆▄▃▄▅▃▃▃▃▃▃▃▃▁▂▁▂▂▁▂▂▂▂▁▂▁▂▂▂▂▁
wandb:      train/policy_loss ▄▄▄▄▄▆▄▄▄▄▄▅█▅▄▅█▆▃▃▄▅▄▇▄▃▄▄▁▅▃▃▄▄▇▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆█▆▆▆▆█▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▂▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88674
wandb: best/eval_avg_mil_loss 0.54348
wandb:  best/eval_ensemble_f1 0.88674
wandb:            eval/avg_f1 0.88674
wandb:      eval/avg_mil_loss 0.50662
wandb:       eval/ensemble_f1 0.88674
wandb:            test/avg_f1 0.8766
wandb:      test/avg_mil_loss 0.53676
wandb:       test/ensemble_f1 0.8766
wandb:           train/avg_f1 0.86264
wandb:      train/ensemble_f1 0.86264
wandb:         train/mil_loss 0.56589
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7s2y4gvm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_052322-7s2y4gvm/logs
wandb: Agent Starting Run: t7i6g6ds with config:
wandb: 	actor_learning_rate: 0.0020749344771952877
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6711506574176338
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.915099223745967
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_053524-t7i6g6ds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t7i6g6ds
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▄▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▇▆▆▆▇▇█████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇██▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▂▄▄▅▄▄▃▃▄▃▄▂▁▃▆▆▆▆▅▅▄▄▆▇▅▇▇▆▆▄▇▇▆▅█▅▇▇
wandb:      train/ensemble_f1 ▁▃▃▁▁▃▂▁▂▃▄▂▂▅▃▃▅▃▅▃▅▄▅▃▃▄▆▆▄▆▆▄▆▄▆▆▆▇█▅
wandb:         train/mil_loss ▆▅██▆▅▇▄▆█▄▇▃▄▃▄▄▅▃▃▄▃▃▄▃▂▅▁▇▄▃▇▄▄▄▅▆▄▄▃
wandb:      train/policy_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆█▇▆▆▆▆▆▆▆▆▆▆▇▇▅▄▆▅▆▄▂▄▆▃▄▁▃▄▄▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51865
wandb: best/eval_avg_mil_loss 1.44546
wandb:  best/eval_ensemble_f1 0.51865
wandb:            eval/avg_f1 0.51865
wandb:      eval/avg_mil_loss 1.36619
wandb:       eval/ensemble_f1 0.51865
wandb:            test/avg_f1 0.53353
wandb:      test/avg_mil_loss 1.07971
wandb:       test/ensemble_f1 0.53353
wandb:           train/avg_f1 0.54815
wandb:      train/ensemble_f1 0.54815
wandb:         train/mil_loss 0.91856
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t7i6g6ds
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_053524-t7i6g6ds/logs
wandb: Agent Starting Run: ohmw3re1 with config:
wandb: 	actor_learning_rate: 0.00010657981624548964
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.49359445949456815
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4645019817695667
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_054227-ohmw3re1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ohmw3re1
wandb: uploading history steps 684-688, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss █▇▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb:      eval/avg_mil_loss █▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▃▄▄▅▄▅▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▃▃▄▃▄▄▄▄▅▅▄▆▆▅▅▆▅▆▅▆▆▆▆▇▆▇▇▇▇▆█▇▇▇██
wandb:      train/ensemble_f1 ▁▂▂▃▄▄▄▄▄▄▄▄▄▅▆▆▆▆▆▅▆▇▇▆▇▇▇█▇███▇▇██▇███
wandb:         train/mil_loss █▄▆▄▅▃▄▃▃▃▃▄▂▃▂▂▂▂▂▂▂▃▁▁▂▂▃▂▂▂▃▂▂▃▁▃▂▂▂▁
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▁▅▆▆▆▄▆▆▆▆█▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79503
wandb: best/eval_avg_mil_loss 0.57269
wandb:  best/eval_ensemble_f1 0.79503
wandb:            eval/avg_f1 0.79503
wandb:      eval/avg_mil_loss 0.56731
wandb:       eval/ensemble_f1 0.79503
wandb:            test/avg_f1 0.84171
wandb:      test/avg_mil_loss 0.28704
wandb:       test/ensemble_f1 0.84171
wandb:           train/avg_f1 0.79268
wandb:      train/ensemble_f1 0.79268
wandb:         train/mil_loss 0.51751
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ohmw3re1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_054227-ohmw3re1/logs
wandb: Agent Starting Run: 2r1kms6w with config:
wandb: 	actor_learning_rate: 0.003503414473404303
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4500092493845075
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9710116812221384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055321-2r1kms6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2r1kms6w
wandb: uploading history steps 112-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂███
wandb: best/eval_avg_mil_loss ▇▆█▁▂▃
wandb:  best/eval_ensemble_f1 ▁▁▂███
wandb:            eval/avg_f1 ▁▂▆██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █████▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▇▆█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▁████▇▇▆▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇█▇▇█▇
wandb:         train/mil_loss ▄█▆▅▂▂▁▂▁▂▂▁▃▃▂▂▂▂▁▃▂▁▁▁▃▃▂▂▁▁▂▂▁▁▁▂▁▂▁▁
wandb:      train/policy_loss █████████████████▁▄████████▅████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▂▃▃▂▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃█▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83075
wandb: best/eval_avg_mil_loss 0.90025
wandb:  best/eval_ensemble_f1 0.83075
wandb:            eval/avg_f1 0.80164
wandb:      eval/avg_mil_loss 0.59468
wandb:       eval/ensemble_f1 0.80164
wandb:            test/avg_f1 0.84616
wandb:      test/avg_mil_loss 0.39699
wandb:       test/ensemble_f1 0.84616
wandb:           train/avg_f1 0.78537
wandb:      train/ensemble_f1 0.78537
wandb:         train/mil_loss 0.53698
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2r1kms6w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055321-2r1kms6w/logs
wandb: Agent Starting Run: 1parmv1j with config:
wandb: 	actor_learning_rate: 0.007339768559418281
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18101283473359076
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5364011221627326
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_055514-1parmv1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1parmv1j
wandb: uploading history steps 544-557, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss ▂██████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▂▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ▃█▇▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇█▇████▇████▇
wandb:      train/ensemble_f1 ▁▁▃▃▄▄▄▅▄▅▆▅▆▆▆▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇███▇██▇███
wandb:         train/mil_loss █▄▅▅▄▃▄▃▄▄▃▃▄▃▃▃▃▃▂▃▃▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁
wandb:      train/policy_loss █▁██████▃██▇████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁██████████▇████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91796
wandb: best/eval_avg_mil_loss 0.5735
wandb:  best/eval_ensemble_f1 0.91796
wandb:            eval/avg_f1 0.91069
wandb:      eval/avg_mil_loss 0.4978
wandb:       eval/ensemble_f1 0.91069
wandb:            test/avg_f1 0.92251
wandb:      test/avg_mil_loss 0.3053
wandb:       test/ensemble_f1 0.92251
wandb:           train/avg_f1 0.89998
wandb:      train/ensemble_f1 0.89998
wandb:         train/mil_loss 0.35262
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1parmv1j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_055514-1parmv1j/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c0tpms8o with config:
wandb: 	actor_learning_rate: 0.0001169546795982148
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.912396470350258
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9213386052658804
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060410-c0tpms8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c0tpms8o
wandb: uploading history steps 266-276, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss ██▇▆▅▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▄▄▄▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇█████████████▇▇▇
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇███████████████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▁▄▃▄▃▁▂▃▃▂▅▆▄▂▃▅▄▄▄▆▄▆▆▇▆▄▄▅▅▆▅█▇▇▇▅
wandb:      train/ensemble_f1 ▃▁▂▄▄▅▃▄▂▃▃▄▄▆▄▃▅▄▆▆▅▅▇▅▆▄▆█▇▇▆▆▇█▆▇▇█▇█
wandb:         train/mil_loss █▄▆▂▇▆▃▆▄▂▅▆▄▅▅▆▅▆▄▁▆▆█▃▄▃█▇▅▄▅▄▄▇▃▃▆▄▅▄
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▆▇▆▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▇▇▅▇▅▆▆▇▇▇█▅█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65573
wandb: best/eval_avg_mil_loss 1.4376
wandb:  best/eval_ensemble_f1 0.65573
wandb:            eval/avg_f1 0.65036
wandb:      eval/avg_mil_loss 1.37615
wandb:       eval/ensemble_f1 0.65036
wandb:            test/avg_f1 0.69532
wandb:      test/avg_mil_loss 0.91972
wandb:       test/ensemble_f1 0.69532
wandb:           train/avg_f1 0.67955
wandb:      train/ensemble_f1 0.67955
wandb:         train/mil_loss 0.4633
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c0tpms8o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060410-c0tpms8o/logs
wandb: Agent Starting Run: l4iquysh with config:
wandb: 	actor_learning_rate: 0.005699253808589607
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02704096912105491
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10790097613089622
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_060839-l4iquysh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l4iquysh
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▅▃▄█▆▃▅▄▅▂▃▆▂▄▄▄▄▂▆▂▂▃▆▄▄▄▃▂▄▄▁▃▃▃▃▁▃▂▁▃
wandb:      train/policy_loss █▂▂▂▁▂▁▂▁▁▁▁▁▂▁▁▁▂▂▁▂▂▁▁▁▂▁▂▁▂▁▁▁▁▂▁▁▁▂▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▃▂▂▂▁▂▂▂▁▂▁▂▂▂▁▁▂▂▁▁▂▁▂▁▁▂▁▁▂▁▂▁▁▁▂▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71847
wandb: best/eval_avg_mil_loss 0.9455
wandb:  best/eval_ensemble_f1 0.71847
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.98693
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.73685
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.34056
wandb:      train/ensemble_f1 0.34056
wandb:         train/mil_loss 0.93411
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l4iquysh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_060839-l4iquysh/logs
wandb: Agent Starting Run: sz9suaey with config:
wandb: 	actor_learning_rate: 0.0027682937265971837
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7169337279621428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6062385726733763
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061022-sz9suaey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sz9suaey
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████████▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▃▅▅▇▅▅▄▄█▆▃▃▅█▃▁▅▄▃▆▆▅▆▆▄▂▄▅▇▅▄▇▄▆▄▅▅
wandb:      train/ensemble_f1 ▃▆▅▆▃▅▅▇▄▄▃▄█▂▂▂▁▁▄▃▃▅▆▆▆▄▆▆▇▃▃▇▆▂▃▆▄▄▂▄
wandb:         train/mil_loss ▄▆▅▁▁▄▄▄▂▇▆▅▇▁▃▄▁▇▄▃▅▄▄▄▂▄▁▄▆▇█▄▅▆▃▅▄▂▆▅
wandb:      train/policy_loss ▁▄▅▇▅▇▅▄▇▇▅▄▅▆▅▆▄▆▄▄▅▅██▅▅▄▃▇▄▄▅▄▂▄▅▄▆▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▁▅▅▇▇█▅▄▄▇▇▅▇▆▆▇▅▅▅▅▅▅▇█▅▄▅▄▃▅▅▇▂▄▇▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 0.97502
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.94985
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.05043
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33475
wandb:      train/ensemble_f1 0.33475
wandb:         train/mil_loss 0.52375
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sz9suaey
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061022-sz9suaey/logs
wandb: Agent Starting Run: 0wt6ny7a with config:
wandb: 	actor_learning_rate: 0.0001974677778452608
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5269637275783958
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9086459036272628
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061205-0wt6ny7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0wt6ny7a
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 127-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▅▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▅▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇
wandb:      eval/avg_mil_loss █████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▁▂▆▆▇▇▇▇▇▆▇▇▇▆▇█▇▇▆▇▇█▇▇▇██▇▇▇▆▇█▇▇▇▇
wandb:      train/ensemble_f1 ▁▂▁▁▂▇▆▆▇▇▆▆▇▆▇▇▇▇▇▇▆▇▆▇█▇▆▇▆▆▇▇▇▇█▇▇▇█▇
wandb:         train/mil_loss █▃▇▇▃▄▄▄▃▃▂▃▂▃▂▃▃▂▁▂▂▁▃▃▂▃▃▂▃▁▃▂▂▃▂▂▂▃▃▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62772
wandb: best/eval_avg_mil_loss 0.65604
wandb:  best/eval_ensemble_f1 0.62772
wandb:            eval/avg_f1 0.61117
wandb:      eval/avg_mil_loss 0.63964
wandb:       eval/ensemble_f1 0.61117
wandb:            test/avg_f1 0.6598
wandb:      test/avg_mil_loss 0.54174
wandb:       test/ensemble_f1 0.6598
wandb:           train/avg_f1 0.66774
wandb:      train/ensemble_f1 0.66774
wandb:         train/mil_loss 0.58715
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0wt6ny7a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061205-0wt6ny7a/logs
wandb: Agent Starting Run: 11a8ymzr with config:
wandb: 	actor_learning_rate: 0.0001899181637273141
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6455258362829995
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.640486599038252
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061420-11a8ymzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/11a8ymzr
wandb: uploading history steps 237-245, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▇▆▅▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▂▄▄▄▄▄▄▄▄▂▂▂▃▃▃▃▃▇▅▇▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇██
wandb:      eval/avg_mil_loss ███▇▇▆▆▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▄▅▄▄▄▄▄▄▂▂▃▇▅▅▅▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▁▄▃▄▃▂▄▃▄▃▄▃▂▄▄▅▄▄▄▄▅▂▅▆▃▅▇▇▇▆▅▅▇▅█▆▅
wandb:      train/ensemble_f1 ▃▁▃▃▄▄▄▂▂▆▄▂▃▅▅▄▅▄▁▅▆▄▄▅▅▅▄▅▅▃▆▇██▇▆▅▆▆▆
wandb:         train/mil_loss ▂▅█▇▂▄▃▁▅▇▄▅▆▇▆▄▃▇▂▄▂▄▅▄▄▄▆▇▁▄▅▄▃▇▅▆▃▄▂▄
wandb:      train/policy_loss ▄▄▄▄▁▄▄▄▄▄▄▄▁▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████████████▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.35876
wandb: best/eval_avg_mil_loss 1.59194
wandb:  best/eval_ensemble_f1 0.35876
wandb:            eval/avg_f1 0.35167
wandb:      eval/avg_mil_loss 1.50523
wandb:       eval/ensemble_f1 0.35167
wandb:            test/avg_f1 0.33693
wandb:      test/avg_mil_loss 1.76853
wandb:       test/ensemble_f1 0.33693
wandb:           train/avg_f1 0.38434
wandb:      train/ensemble_f1 0.38434
wandb:         train/mil_loss 0.92474
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/11a8ymzr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061420-11a8ymzr/logs
wandb: Agent Starting Run: 4rw6v8ou with config:
wandb: 	actor_learning_rate: 1.833899821807852e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8154106948928912
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5596740066533735
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_061818-4rw6v8ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rw6v8ou
wandb: uploading config.yaml
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▇▅▅▅▁▃▂▃▅▄▆▄▅▄▅▃▄▃▅▅▁▃▂▅▇▄▂▃▃▅▂▅▃▃▃█▅▄
wandb:      train/ensemble_f1 ▅█▃▆▇▃▆▅▃▃▅▅▄▁▄▃▅▄▇▅▅▃▃▆▆▆▁▄▆█▃▇▅▆▄▄▃▃▄▅
wandb:         train/mil_loss █▄▅▄▅▄▄▃▆█▃▄█▄▄▂▆▃▅▄▆▅▅▂▄█▅▅▆▄▁▄▄▅▆▅▄▃▂▃
wandb:      train/policy_loss ▃▂▅▆█▅▄▃▁▅▆▆▇▃▆▅▅▅▇▃▇▇▄▂▆▇▄▄▅▃▁▅▅▅▃▅▂▄▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▆▅▆▆▆▆▇▆▅▆▆▃▅▃▇▅▅▂▅▃▁▃▃▃▅▃▆▆▂█▂▃▃▁▃▅▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.99858
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.9296
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 2.05961
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33211
wandb:      train/ensemble_f1 0.33211
wandb:         train/mil_loss 0.6417
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4rw6v8ou
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_061818-4rw6v8ou/logs
wandb: Agent Starting Run: pvxle2ij with config:
wandb: 	actor_learning_rate: 3.4982354707715163e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4980401997651911
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0845047151400522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_062001-pvxle2ij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pvxle2ij
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb: best/eval_avg_mil_loss ████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:      eval/avg_mil_loss █▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▂▂▃▂▃▄▃▃▄▅▄▅▅▆▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█
wandb:      train/ensemble_f1 ▁▂▂▃▃▄▄▄▃▃▄▄▄▄▅▅▆▅▆▅▆▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇█
wandb:         train/mil_loss ▆▄▅█▃▅▄▄▅▅▁▅▅▃▃▃▄▄▅▃▄▃▃▃▄▂▃▂▃▃▃▂▂▂▃▃▄▂▁▂
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▆▅▅▁▅▅▅▅▆▄▇▆▅▅▆▅▅▅▅▅▅▅▅▅▄▅▆▅▅█▇▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67871
wandb: best/eval_avg_mil_loss 1.06027
wandb:  best/eval_ensemble_f1 0.67871
wandb:            eval/avg_f1 0.67871
wandb:      eval/avg_mil_loss 1.05102
wandb:       eval/ensemble_f1 0.67871
wandb:            test/avg_f1 0.72295
wandb:      test/avg_mil_loss 0.79421
wandb:       test/ensemble_f1 0.72295
wandb:           train/avg_f1 0.69211
wandb:      train/ensemble_f1 0.69211
wandb:         train/mil_loss 0.9272
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pvxle2ij
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_062001-pvxle2ij/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xnem3nw6 with config:
wandb: 	actor_learning_rate: 0.0003778624620690792
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6692154671072404
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7122034929464034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_063254-xnem3nw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xnem3nw6
wandb: uploading history steps 755-764, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▂▃▃▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███████████
wandb:      eval/avg_mil_loss ████▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▃▃▃▄▄▃▄▅▅▅▅▆▆▆▆▅▅▇▆▆▇▇▇▆▇▇▇▇█▇▇▇█▇▇▇▇
wandb:      train/ensemble_f1 ▂▂▂▁▂▃▂▃▃▅▄▅▅▅▅▅▅▆▅▅▆▆▆▇▆▆▇▇▇▆▇████▇██▇█
wandb:         train/mil_loss ▇▆▅▅▆▆▂██▃▅▄▄▄▄▃▃▃▃▄▄▅▄▃▃▄▂▁▄▅▄▂▃▁▃▂▂▃▂▂
wandb:      train/policy_loss ▃▃▃▅▅▁▃▃▃▇▃▃▃▃▃▃▃▃▃▃▃▄▃█▇▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77859
wandb: best/eval_avg_mil_loss 1.17703
wandb:  best/eval_ensemble_f1 0.77859
wandb:            eval/avg_f1 0.77859
wandb:      eval/avg_mil_loss 1.11713
wandb:       eval/ensemble_f1 0.77859
wandb:            test/avg_f1 0.82724
wandb:      test/avg_mil_loss 0.79423
wandb:       test/ensemble_f1 0.82724
wandb:           train/avg_f1 0.77731
wandb:      train/ensemble_f1 0.77731
wandb:         train/mil_loss 0.77892
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xnem3nw6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_063254-xnem3nw6/logs
wandb: Agent Starting Run: i6ih6a0f with config:
wandb: 	actor_learning_rate: 1.62566546585926e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15200042369483913
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6233828021987442
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064510-i6ih6a0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6ih6a0f
wandb: uploading history steps 143-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅█████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅███████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▂▄▃▄▅▃▃▅▅▄▅▄▁▅▅▃▃▅▅▄▆▄▄▄▅▃▄▄▅▆▄█▃▄▄▄▄
wandb:      train/ensemble_f1 ▁▅▂▂▁▃▄▃▁▄▃▃▅▅▅▅▄▆▄▂▄▄▃▆▃▃▃▄▆▇▆▅▅▄█▄▃▄▄▅
wandb:         train/mil_loss ▆▅▄▇█▆▇▇▆▆▇▇▇▅▇▆▅▅▅▄▅▄▇▅▅▅▅▄▅▄▃▆▃▆▃▅▅▄▁▅
wandb:      train/policy_loss ▆▆▇▇▆▆▄█▄▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▅▇▆▇▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51865
wandb: best/eval_avg_mil_loss 1.97073
wandb:  best/eval_ensemble_f1 0.51865
wandb:            eval/avg_f1 0.51865
wandb:      eval/avg_mil_loss 1.72433
wandb:       eval/ensemble_f1 0.51865
wandb:            test/avg_f1 0.58353
wandb:      test/avg_mil_loss 1.41296
wandb:       test/ensemble_f1 0.58353
wandb:           train/avg_f1 0.53108
wandb:      train/ensemble_f1 0.53108
wandb:         train/mil_loss 1.40738
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i6ih6a0f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064510-i6ih6a0f/logs
wandb: Agent Starting Run: c7zqk8li with config:
wandb: 	actor_learning_rate: 0.006764341557832533
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3854408615400329
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06913139566772131
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064741-c7zqk8li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7zqk8li
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▃▄▂▄▅▃▁▃▅▃█▇▄▆▄▄▄▄▆▅▁▄▆▄▇▃▅▄▆█▄▂▅▅▇▄▅
wandb:      train/ensemble_f1 ▃▅▅▃▃▁▇▃▂▃▃▃▅▇▄▆▃▅▅▄▄▆█▄▄▅▄▇▄▄▂▂▂▅▃▄█▄▄▂
wandb:         train/mil_loss █▆▅▆▆▄▆▄▃▆▇▇▅▃▅▄▇▅▅▇▆▁▆▅▇▅▃▆▆▆▅▄▄▅▅▄▄▄▃▅
wandb:      train/policy_loss ▂▅▄▆█▄▆▂▄▅█▆▇▄▅▆▃▅▄█▅▆▅▄▁▆▄▂▃▆▆▅▄▆▃▆█▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▅▂▆▃▆▇▆▄▃▅▃▁▄▃▄▆▃▄▁█▂▃▃▃▃▂▃▃▆▃▄▃▅▄▅▅▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.03011
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.99307
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.13486
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32822
wandb:      train/ensemble_f1 0.32822
wandb:         train/mil_loss 0.79227
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7zqk8li
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064741-c7zqk8li/logs
wandb: Agent Starting Run: f5w6hdjk with config:
wandb: 	actor_learning_rate: 3.7065214506078656e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28163107626972106
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7691780638355217
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_064924-f5w6hdjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f5w6hdjk
wandb: uploading history steps 543-545, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇██████████████████
wandb:      eval/avg_mil_loss █▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▄▄▆▆▆▆▆▆▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▃▃▄▃▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇████▇▇████
wandb:      train/ensemble_f1 ▁▂▂▁▃▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇█▇████████████
wandb:         train/mil_loss ▅█▇▆▆▆▄▆▆▅▅▄▅▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▄▇▂▇▅▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.89149
wandb: best/eval_avg_mil_loss 0.46456
wandb:  best/eval_ensemble_f1 0.89149
wandb:            eval/avg_f1 0.88788
wandb:      eval/avg_mil_loss 0.43582
wandb:       eval/ensemble_f1 0.88788
wandb:            test/avg_f1 0.88977
wandb:      test/avg_mil_loss 0.27682
wandb:       test/ensemble_f1 0.88977
wandb:           train/avg_f1 0.88269
wandb:      train/ensemble_f1 0.88269
wandb:         train/mil_loss 0.38052
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f5w6hdjk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_064924-f5w6hdjk/logs
wandb: Agent Starting Run: 2b8kk59f with config:
wandb: 	actor_learning_rate: 1.1800234783332564e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7335378012647809
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02608976027117549
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_065800-2b8kk59f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2b8kk59f
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▄▄███████████████▄▄▄█████▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▆▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄█████████████▄▄▄█████▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▂▂▁▆▆▄▅▄▅▂▃▄▄▄▇▅▃▆▄▄▅▇▃▇▆█▃▆▆▇▅▄▆▂▂▃▅
wandb:      train/ensemble_f1 ▅▂▂▂▂▅▂▅▄▄▃▅▄▆▃▄▆▃▃▄▁▄▅▃▅▆▆▄▆▅▂▃▇▅▅█▇▆▇▇
wandb:         train/mil_loss ▄▅▃▃▅▂▄▃▄▂▃▄▄▅▃▃▃▂▃▃▁▃▂█▁▃▃▂▂▂▄▄▃▄▂▂▃▁▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▃▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86934
wandb: best/eval_avg_mil_loss 0.65136
wandb:  best/eval_ensemble_f1 0.86934
wandb:            eval/avg_f1 0.86217
wandb:      eval/avg_mil_loss 0.63695
wandb:       eval/ensemble_f1 0.86217
wandb:            test/avg_f1 0.8719
wandb:      test/avg_mil_loss 0.27926
wandb:       test/ensemble_f1 0.8719
wandb:           train/avg_f1 0.84269
wandb:      train/ensemble_f1 0.84269
wandb:         train/mil_loss 0.48706
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2b8kk59f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_065800-2b8kk59f/logs
wandb: Agent Starting Run: myihy77u with config:
wandb: 	actor_learning_rate: 4.6401400129378705e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3466098330154197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14396792204056907
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070111-myihy77u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myihy77u
wandb: uploading history steps 464-477, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▂▂▂▂▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █▆▆▆▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▃▃▃▄▃▄▆▇▆▆▆▆▇▇▆▇▇▇████▇███▇██▇██▇██▇
wandb:      train/ensemble_f1 ▁▂▄▄▃▅▆▆▆▆▇▆▆▇▇▇▇█▇▇▇▇█▇██▇██▇███▇█▇██▇▇
wandb:         train/mil_loss ▅█▇▄▄▄▅▄▄▄▃▄▃▄▃▂▃▃▃▂▂▂▂▂▂▂▂▂▁▃▂▁▂▂▁▁▁▁▂▂
wandb:      train/policy_loss ▁▄▃▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.91104
wandb: best/eval_avg_mil_loss 0.52243
wandb:  best/eval_ensemble_f1 0.91104
wandb:            eval/avg_f1 0.90742
wandb:      eval/avg_mil_loss 0.49236
wandb:       eval/ensemble_f1 0.90742
wandb:            test/avg_f1 0.90296
wandb:      test/avg_mil_loss 0.34323
wandb:       test/ensemble_f1 0.90296
wandb:           train/avg_f1 0.89432
wandb:      train/ensemble_f1 0.89432
wandb:         train/mil_loss 0.51634
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myihy77u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070111-myihy77u/logs
wandb: Agent Starting Run: 1zidjimi with config:
wandb: 	actor_learning_rate: 5.754109732571027e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3844829249184337
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3908707605329722
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_070845-1zidjimi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zidjimi
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss ██▇▅▄▃▃▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▅▇███████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▅▅▆▆▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▁▂▃▃▂▄▄▂▃▄▅▄▃▄▄▅▅▅▅▅▅▄▄▅▅▅▅█▆▇▆▆▆▇▇▆
wandb:      train/ensemble_f1 ▂▂▂▁▃▃▂▃▃▄▁▃▄▄▆▄▅▄▅▅▅▅▆▅▄▅▆▇▇▆▅█▇▆▇▇▇▇█▇
wandb:         train/mil_loss ▇▆▃█▅▄▅▄▃▅▄▃▃▅▄▄▃▁▃▅▃▄▃▃▂▄▃▁▂▂▃▃▂▂▂▃▃▂▃▁
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▆▃▂▃▅████████▇▆▄▆▄██████████▇▆▆▅▃▄▁▄▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65259
wandb: best/eval_avg_mil_loss 1.24503
wandb:  best/eval_ensemble_f1 0.65259
wandb:            eval/avg_f1 0.65259
wandb:      eval/avg_mil_loss 1.12049
wandb:       eval/ensemble_f1 0.65259
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.72385
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.68872
wandb:      train/ensemble_f1 0.68872
wandb:         train/mil_loss 0.81566
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zidjimi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_070845-1zidjimi/logs
wandb: Agent Starting Run: 4fecr5bf with config:
wandb: 	actor_learning_rate: 0.00807518185353684
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9019558213903692
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6921635006267818
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071452-4fecr5bf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4fecr5bf
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆████
wandb: best/eval_avg_mil_loss ▂█▂▁▁▂▂
wandb:  best/eval_ensemble_f1 ▁▄▆████
wandb:            eval/avg_f1 ▂▁▁▅████████████████████████████████████
wandb:      eval/avg_mil_loss ▂▂██▆▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▁▇████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▁▄█▆▇▇▆▇▇▆▇▇▇▆▆▇▆▇▆▇▇▇▇▆▆▆▆▇▇▇▇▆▇▇▇█▅
wandb:      train/ensemble_f1 ▂▄▁▅▇▆▇▇▇▆▆▇▆▇▆▆▅▇▆▆▆▆▇█▆▅▆▆▆▆█▆▇▇▅▆▇▇▇▅
wandb:         train/mil_loss ▇█▄▄▄▃▂▄▄▄▅▂▃▃▃▃▁▁▃▄▃▃▃▃▄▃▃▄▃▃▃▃▂▄▂▄▄▃▄▂
wandb:      train/policy_loss ▃▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▄▃▃▃▃▃▁▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████████▁███████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82846
wandb: best/eval_avg_mil_loss 0.75645
wandb:  best/eval_ensemble_f1 0.82846
wandb:            eval/avg_f1 0.82208
wandb:      eval/avg_mil_loss 0.71298
wandb:       eval/ensemble_f1 0.82208
wandb:            test/avg_f1 0.87455
wandb:      test/avg_mil_loss 0.28059
wandb:       test/ensemble_f1 0.87455
wandb:           train/avg_f1 0.77544
wandb:      train/ensemble_f1 0.77544
wandb:         train/mil_loss 0.48675
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4fecr5bf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071452-4fecr5bf/logs
wandb: Agent Starting Run: cj293i8e with config:
wandb: 	actor_learning_rate: 0.0006439085023538638
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19230550964806936
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7828892841630821
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_071646-cj293i8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cj293i8e
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 257-261, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▇▇███████
wandb: best/eval_avg_mil_loss █▃▃▂▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅▆▇▇███████
wandb:            eval/avg_f1 ▁▅▇██▆▇▆▆▇▇▇▇▇▇▇▇▆▆▆▇▇██████████████████
wandb:      eval/avg_mil_loss █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁███████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇███▇██████████
wandb:      train/ensemble_f1 ▄▅▆█▆▃▆▃▄▅▅▁▄▁▃▅▅▅▂▆▄▂▆▃▅▃▅▄▅▄▇█▆▅▄▆▇▇▆▅
wandb:         train/mil_loss ██▅▂▂▃▃▂▁▂▂▃▁▁▂▂▃▁▁▂▂▂▃▂▂▂▁▂▂▂▂▂▂▃▁▁▂▁▂▁
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅▅▅▅▃▁▄▂▂▂▄▃▂▃▂▂▅▅▇▅▇▇█▅▅▅▅▅▅▅▅▅▅█▅▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84153
wandb: best/eval_avg_mil_loss 0.69673
wandb:  best/eval_ensemble_f1 0.84153
wandb:            eval/avg_f1 0.83772
wandb:      eval/avg_mil_loss 0.645
wandb:       eval/ensemble_f1 0.83772
wandb:            test/avg_f1 0.82371
wandb:      test/avg_mil_loss 0.46505
wandb:       test/ensemble_f1 0.82371
wandb:           train/avg_f1 0.81507
wandb:      train/ensemble_f1 0.81507
wandb:         train/mil_loss 0.51881
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cj293i8e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_071646-cj293i8e/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sfugm2au with config:
wandb: 	actor_learning_rate: 0.00019982145140764085
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5965467558316045
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7969835006891476
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072103-sfugm2au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfugm2au
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ████▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▆▇▇▇█████▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▆▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▁▁▃▂▄▄▄▄▅▅▅▅█▇▆▆▇▇▇▇█▆▇▇███▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▅▆▇▆▇▇▇██▇██▇▇█▇▇▇███▇
wandb:      train/ensemble_f1 ▁▁▂▂▂▂▃▂▃▃▃▄▄▅▄▄▄▄▅▅▅▇▆▆▆▇▇▇▇▇▇██▇▇▆▇▇▇▇
wandb:         train/mil_loss █▆▇▅▆▂▅▆▅▅▄▃▃▂▂▃▃▃▃▂▃▂▂▂▂▃▁▂▂▂▂▂▂▂▂▂▂▂▁▂
wandb:      train/policy_loss ▆▆▆▆▆▄▆▆█▆▆▆▆▆▆██▃▁▆▆▆▆▄▇▆▆▇▆▆▆▆▆▆▅▅▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▇▅▅▆▅▅▅▅▁▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅█▆▄▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.5054
wandb: best/eval_avg_mil_loss 0.85591
wandb:  best/eval_ensemble_f1 0.5054
wandb:            eval/avg_f1 0.48847
wandb:      eval/avg_mil_loss 0.80313
wandb:       eval/ensemble_f1 0.48847
wandb:            test/avg_f1 0.53186
wandb:      test/avg_mil_loss 0.7527
wandb:       test/ensemble_f1 0.53186
wandb:           train/avg_f1 0.55192
wandb:      train/ensemble_f1 0.55192
wandb:         train/mil_loss 0.62599
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfugm2au
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072103-sfugm2au/logs
wandb: Agent Starting Run: pba9403l with config:
wandb: 	actor_learning_rate: 0.0003004717271007502
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7869794634058636
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8950443151586783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_072704-pba9403l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pba9403l
wandb: uploading history steps 284-290, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▄▃▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▆▆▆▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▃▅▆▆▆▆▆▆▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▅▁▂▂▅▄▅▆▅▅▅▅▃▄▄▆▆▆▆▅▇▆▅▆▇▆▇▇▅▅▆▇▇▆█▇▇
wandb:      train/ensemble_f1 ▁▁▅▃▃▄▃▂▃▆▄▄▃▅▄▄▅▆▆▅▆▇▇▇▇█▇▇▆▆▆▇▆▇▆██▇▇▇
wandb:         train/mil_loss ▄▄▆█▂▃▂▄▂▅▄▄▃▆▃▅▆▅▅▁▂▅▄▂▂▅▅▄▂▃▂▄▃▅▃▂▃▄▅▃
wandb:      train/policy_loss ▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄█▄▄▆▆▇▆▆▇▁▁▂▂▂▂▂▃▂▂▂▂▃▁▂▂▁▃▂▅▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66634
wandb: best/eval_avg_mil_loss 0.91041
wandb:  best/eval_ensemble_f1 0.66634
wandb:            eval/avg_f1 0.66106
wandb:      eval/avg_mil_loss 0.88293
wandb:       eval/ensemble_f1 0.66106
wandb:            test/avg_f1 0.68963
wandb:      test/avg_mil_loss 0.58236
wandb:       test/ensemble_f1 0.68963
wandb:           train/avg_f1 0.67818
wandb:      train/ensemble_f1 0.67818
wandb:         train/mil_loss 0.5333
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pba9403l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_072704-pba9403l/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ltf7epxx with config:
wandb: 	actor_learning_rate: 6.540890345551803e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4404351820036294
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2776527937880755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073153-ltf7epxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ltf7epxx
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▇▅▃▄▃▅▄▅▆▃▄▄▆▁▆▄▅▃▄▆▇▃▆█▇▄▃▅▄▄█▄█▅▆▂▆▅
wandb:      train/ensemble_f1 ▄▅▇▄▄▂▆▄▂▇▄▁▅▂▅▄▂▃▅▆▅▇▄▅▇▂▂██▇▅▅▂▃▄▃█▄▄▆
wandb:         train/mil_loss ▄▄▃▃▃▄▄▂▅▄▅▆▃█▆▄▁▄▄▄▄▆▄▁▄▄▅▄▃▄▄▆▅▃▄▃▃▃▃▄
wandb:      train/policy_loss ▃▄▆▇▅▅▃▆▇▄▃▄▄▁▃▃▆▆▇▄▃▆▇▅▆▃▃▆▅█▅▃▄▆▅▅▅▄▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▅▄▆▃▂▅▃▆▆▇▂▃▄▆▇█▆▁▇▅▃▅▆▂▃▅▅▄▄▂▃▅▄▅▅▅▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.86443
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.69135
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 2.01636
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.3274
wandb:      train/ensemble_f1 0.3274
wandb:         train/mil_loss 1.10022
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ltf7epxx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073153-ltf7epxx/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fzet8xwy with config:
wandb: 	actor_learning_rate: 0.008629662392770411
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8744669268266999
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0874179697779669
wandb: creating run
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073345-fzet8xwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fzet8xwy
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▅▄▄▄▄▃▃▃▃▂▄▃▃▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▁▄▃▄▅▅▆▆▆▅▅▆▄▃▂▃▄▆▃▂█▇▄█▆▃▆▄▅▅▂▅▃▆▄▆▇▄
wandb:      train/ensemble_f1 ▄▅▇▁▃▆▁▃▄▄▆▅▆▃▄▃▄▆▄▃▂▂▂▇▄█▆▆▄▅▅▃▂▅██▆▄▁▄
wandb:         train/mil_loss ▇▆▇▅▆▄▆▅▃▃▃▇▂▆█▅▅▅▆▃▃▃▄▃▅▅█▅▄▂▆▄█▄▃▅▄▆▁█
wandb:      train/policy_loss ▅▆▂▅▆▅▆▅▅▇▆▃▇▇▆▆▇▅▃▇▁▇█▃▇▄▃▇▇▆▂▆▆▆▇▇▇▆▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▂▄▄▇▄▄▅▅▇▅▇▅▂▇▅▅▄▆▇▁▇▅█▇▇▅▅▄█▅▇▄▆█▇▆▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.03615
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.0241
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.14531
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33272
wandb:      train/ensemble_f1 0.33272
wandb:         train/mil_loss 0.59051
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fzet8xwy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073345-fzet8xwy/logs
wandb: Agent Starting Run: o9x1pzha with config:
wandb: 	actor_learning_rate: 0.0015189330179390002
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.516394470311755
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5398349246814755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073530-o9x1pzha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o9x1pzha
wandb: uploading history steps 96-112, summary; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄█
wandb: best/eval_avg_mil_loss █▇▆▃▁
wandb:  best/eval_ensemble_f1 ▁▁▂▄█
wandb:            eval/avg_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▆▆█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▇█▇█▇▃▄▃▄▂▂▃▂▃▂▂▃▃▁▂▃▂▂▂▃▁▂▃▂▃▂▂▁▃▃▃▂▂▂▂
wandb:      train/policy_loss █▂▃▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▅▅▅▃▅▁▄▄▃▁▂▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▄▁▆▄▂▆▂▃▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69842
wandb: best/eval_avg_mil_loss 0.66305
wandb:  best/eval_ensemble_f1 0.69842
wandb:            eval/avg_f1 0.32811
wandb:      eval/avg_mil_loss 0.95389
wandb:       eval/ensemble_f1 0.32811
wandb:            test/avg_f1 0.69659
wandb:      test/avg_mil_loss 0.69016
wandb:       test/ensemble_f1 0.69659
wandb:           train/avg_f1 0.33939
wandb:      train/ensemble_f1 0.33939
wandb:         train/mil_loss 0.72107
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o9x1pzha
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073530-o9x1pzha/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gnlf6f2w with config:
wandb: 	actor_learning_rate: 0.000210157866700771
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.007960047011455584
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5053271502122855
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_073728-gnlf6f2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gnlf6f2w
wandb: uploading history steps 790-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▁▁▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▂▃▃▄▄▄▅▅▄▄▅▅▅▅▆▆▅▆▇▆▇▇▇▇▇█▇▇▇█▇█████
wandb:      train/ensemble_f1 ▁▁▁▂▂▃▃▄▃▄▄▄▄▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇████
wandb:         train/mil_loss █▇▇██▇▇▆▆▇▆▄▅▆▅▄▅▄▄▄▄▄▃▃▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8828
wandb: best/eval_avg_mil_loss 0.42287
wandb:  best/eval_ensemble_f1 0.8828
wandb:            eval/avg_f1 0.8828
wandb:      eval/avg_mil_loss 0.4158
wandb:       eval/ensemble_f1 0.8828
wandb:            test/avg_f1 0.90964
wandb:      test/avg_mil_loss 0.32144
wandb:       test/ensemble_f1 0.90964
wandb:           train/avg_f1 0.89883
wandb:      train/ensemble_f1 0.89883
wandb:         train/mil_loss 0.39676
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gnlf6f2w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_073728-gnlf6f2w/logs
wandb: Agent Starting Run: vvixkvbc with config:
wandb: 	actor_learning_rate: 1.4947761013844363e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5588262049673703
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8814466321188499
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075000-vvixkvbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vvixkvbc
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▃▆▃▇▄▄▇▃▃▅▆▂▆▇▁▅▅▃▃▁▅▆▅▅▂▅▄▄▄▅▇▅▄▅▂▄▆▆
wandb:      train/ensemble_f1 ▃█▆▅▅▄▁▄▃▂▂▇▄▆▃▅▃▂▆▅▄▅▃▅▄▃▁▄▃▃▂▄▅▂▄▁▄▂▅▂
wandb:         train/mil_loss ▆▆▆▅▂▃▁█▃▅▄▄▄▄▁▄▃▄▅▃▅▄▂▃▃▂▅▃▃▃▄▂▃▂▂▂▃▄▁▃
wandb:      train/policy_loss ▄▃▄▃▄█▇▆▃▅▅▆▅▅▄▄▄▅▃▅▆▅▃▄▄▅▄▃▅▄▅▁▄▅▃▂▂▇▂▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▄▅▂▅▆▄▆▇▄▅▇▆▆▅▆▃▅▇▇▇▆▃▅▁▃▆▄▆▇█▆▄▆▆▆▃▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.6128
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.15385
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.8328
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32532
wandb:      train/ensemble_f1 0.32532
wandb:         train/mil_loss 0.6758
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vvixkvbc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075000-vvixkvbc/logs
wandb: Agent Starting Run: 7lm7bsvr with config:
wandb: 	actor_learning_rate: 6.30713043758931e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.94447530893691
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.686323929683037
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075144-7lm7bsvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lm7bsvr
wandb: uploading history steps 437-439, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆██
wandb: best/eval_avg_mil_loss █▅▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▃▆██
wandb:            eval/avg_f1 ▁▁▃▃▃▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆████████████
wandb:      eval/avg_mil_loss █▅███▇▇▇▇▇▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▁▁▁▁▁▁▁▁▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▅▂▅▂▆▂▄▃▃▆▂▄▅▆█▁▆▃▁▅▅▃▃▇▆█▇▄▇▅▃▆▂▄▇▃▅█
wandb:      train/ensemble_f1 ▂▄▃▆▄▃▁▃▃▃▄▄▄▄▄▅▄▃▅▄▁▃▄▄▂▄▄▂▆▆▅▂▅▅▂▇▁▅▅█
wandb:         train/mil_loss ▇▂▆▁▄▆▇▇▆▇▄▄▅▆▂▇▄▅▅▆▆▅▄▅▇▃█▄▃▆▇▂▅▃▄▄▄▅▇▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▅█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88012
wandb: best/eval_avg_mil_loss 0.61661
wandb:  best/eval_ensemble_f1 0.88012
wandb:            eval/avg_f1 0.88012
wandb:      eval/avg_mil_loss 0.61817
wandb:       eval/ensemble_f1 0.88012
wandb:            test/avg_f1 0.91037
wandb:      test/avg_mil_loss 0.25896
wandb:       test/ensemble_f1 0.91037
wandb:           train/avg_f1 0.87692
wandb:      train/ensemble_f1 0.87692
wandb:         train/mil_loss 0.43669
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lm7bsvr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075144-7lm7bsvr/logs
wandb: Agent Starting Run: md5s1smu with config:
wandb: 	actor_learning_rate: 0.0028530802033537262
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5190181540956382
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3370084508559057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_075852-md5s1smu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/md5s1smu
wandb: uploading history steps 112-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄█
wandb: best/eval_avg_mil_loss ██▅▁
wandb:  best/eval_ensemble_f1 ▁▁▄█
wandb:            eval/avg_f1 ▇▇▇▇▇██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▆▆▆▆▄▂▁████████████████████████████████
wandb:       eval/ensemble_f1 ▇▇▇▇▇██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▇▇██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▇▇▇▇▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▅▅▄▂▂▅▄▇▄▅▅▅█▅▄▆▅▄▅▆▄▇▃▅▆▃▅▆▄▄▇▂▄▃▅▃▃▆▅▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▄▃▂▄▂▆▄▄▅▅▂▃▄▅▂▄▃▃▁▃▆▃▄▂▆▃▆▆▄▃▃█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▆▆▆▃▃▆▅▅▄▆▂▇▃▆▅▅▆▄▅▄▄▅▂▆▆▄▄▆▃▄▆▄▄▃█▁▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79614
wandb: best/eval_avg_mil_loss 0.56519
wandb:  best/eval_ensemble_f1 0.79614
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.27051
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.84616
wandb:      test/avg_mil_loss 0.42717
wandb:       test/ensemble_f1 0.84616
wandb:           train/avg_f1 0.33394
wandb:      train/ensemble_f1 0.33394
wandb:         train/mil_loss 0.60544
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/md5s1smu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_075852-md5s1smu/logs
wandb: Agent Starting Run: bmxtstbp with config:
wandb: 	actor_learning_rate: 0.0019575316289797257
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02809685625585467
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4590402297269706
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080045-bmxtstbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmxtstbp
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▇█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃
wandb:      eval/avg_mil_loss ▅▁▅██▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂█▇█▂▁▁▁▁▂▁▁▁▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▂▃▃▃
wandb:      train/ensemble_f1 ▂▂▁▁▁▂▂▂▂▃▂▃▂▃▃▃▂▃▄▃▃▃▄▄▄▃▅▄▄▄▅▅▆▅▅▆▇▇▇█
wandb:         train/mil_loss ▅▃▁█▆████▇█▇▇▇▇▆▅▅▅▅▅▅▆▆▅▅▅▅▅▅▄▄▄▄▃▄▃▃▃▂
wandb:      train/policy_loss ▅▅▃▅▅▅█▅▅▅▅▄▅▅▅▅▅▅▄█▅▇▅▆▅▄▅▅▆▅▅▁▆▄▅▇▆▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▇▅▅▅▅█▅▄▅▅▅▅▅▅▅▄▅▅▂▆▅▃▅▅▅▅▅▅▁▄▆▄▅▇▅▂▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82584
wandb: best/eval_avg_mil_loss 0.7583
wandb:  best/eval_ensemble_f1 0.82584
wandb:            eval/avg_f1 0.45744
wandb:      eval/avg_mil_loss 1.23901
wandb:       eval/ensemble_f1 0.45744
wandb:            test/avg_f1 0.81891
wandb:      test/avg_mil_loss 0.52518
wandb:       test/ensemble_f1 0.81891
wandb:           train/avg_f1 0.4827
wandb:      train/ensemble_f1 0.4827
wandb:         train/mil_loss 0.94561
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmxtstbp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080045-bmxtstbp/logs
wandb: Agent Starting Run: 0niug0zi with config:
wandb: 	actor_learning_rate: 0.00020407755242205855
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.35440332205111613
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17634918295084523
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_080229-0niug0zi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/pdj98xhp
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0niug0zi
wandb: uploading history steps 443-452, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█████
wandb: best/eval_avg_mil_loss █▇▇▆▆▆▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█████
wandb:            eval/avg_f1 ▁▂▄▄▅▅▆▇▇▇▆▇▇▇▇▇█▇▇▇▇██████████████████▇
wandb:      eval/avg_mil_loss █▇▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▁▁▂▄▄▅▅▅▆▅▅▅▆▆▇▇▇▇▇▇▇██▇▇▇▇▇█▇██▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▄▄▄▄▆▆▅▆▆▆██▇▇█▇▇▆▇▆▇▇▇█▇▇▇▆▇▇▇▇▇▆▆▇█▇
wandb:      train/ensemble_f1 ▃▁▃▅▆▆▇▆▇▇█▇▇█▇▇█▇█▇█▇▇█▇▇▇█▇▇▇▇▇▇██▇▇▇▇
wandb:         train/mil_loss █▇▆▅▄▃▄▂▃▃▂▂▃▂▂▁▁▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▂▂▂▂▂▂
wandb:      train/policy_loss ▄▁██████████████████████████▅███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.87014
wandb: best/eval_avg_mil_loss 0.57811
wandb:  best/eval_ensemble_f1 0.87014
wandb:            eval/avg_f1 0.85915
wandb:      eval/avg_mil_loss 0.5817
wandb:       eval/ensemble_f1 0.85915
wandb:            test/avg_f1 0.89763
wandb:      test/avg_mil_loss 0.24218
wandb:       test/ensemble_f1 0.89763
wandb:           train/avg_f1 0.85189
wandb:      train/ensemble_f1 0.85189
wandb:         train/mil_loss 0.40975
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0niug0zi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_080229-0niug0zi/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 5n20xbla with config:
wandb: 	actor_learning_rate: 0.0018676695331129463
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41129511519645146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3882829429845527
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081003-5n20xbla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5n20xbla
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇▇█
wandb: best/eval_avg_mil_loss █▅▅▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▅▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb:      eval/avg_mil_loss █████▆▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▂▂▅▆▆▅▆▆▇▇▅▆▇▆▅▆▅▇▇▇▇▆▆▅█▅▇▇▆▇▆▆▇▆▅▇
wandb:      train/ensemble_f1 ▂▂▃▂▁▃▅▄▄▄▆▆▆▇▆▅▇▇▇▇▇▆▆▅▇▇▇▇▆▇▇▆▆▇▆▇█▇▇█
wandb:         train/mil_loss ▄▅▆█▄▆▃▃▄▅▃▆▄▃▄▂▃▃▄▃▅▂▅▆▁▂▄▂▂▅▃▁▂▃▂▆▂▃▄▂
wandb:      train/policy_loss ▆▅▃▁▃▆██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▅▁▆███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78649
wandb: best/eval_avg_mil_loss 0.52086
wandb:  best/eval_ensemble_f1 0.78649
wandb:            eval/avg_f1 0.78649
wandb:      eval/avg_mil_loss 0.50622
wandb:       eval/ensemble_f1 0.78649
wandb:            test/avg_f1 0.80862
wandb:      test/avg_mil_loss 0.38609
wandb:       test/ensemble_f1 0.80862
wandb:           train/avg_f1 0.8198
wandb:      train/ensemble_f1 0.8198
wandb:         train/mil_loss 0.46017
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5n20xbla
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081003-5n20xbla/logs
wandb: Agent Starting Run: 1fpykfxc with config:
wandb: 	actor_learning_rate: 0.0003845018761137217
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5400956512007651
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8726281538786388
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081335-1fpykfxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1fpykfxc
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▃▄▅▅▅▅▅▇▆▆███▇▇▆▆▅▅▇▇▇▆▆▅▅▃▃▃▂▄▃▃▂▂▃▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▆▇▁▂▆▆▅▄▄▄▁▇▁▄▆▄▅▅▄▄▄▃▇▅▄▃█▅▅▃▃▅▅█▆▅▃▇
wandb:      train/ensemble_f1 ▂▅▄▅▅▁▄▃▃▅▃▆▃▁▆▄▃▄▄▄▄█▃▂▃▄▄▃▃▄▃▄▇▄▅▄▄▂▅▃
wandb:         train/mil_loss ▅▄▃▃▆▃▃▄▃▄▆▁▁▁▃▃▃▃▄▃▂▃▂▅▅▄▃▄▃▃█▂▃▄▆▂▃▄▃▄
wandb:      train/policy_loss ▅▄▇▅▅▆▄▄▂▂▅█▅▅▁▄▄▆▄▆▅▇▃▅▄▆▃▆▆▄▆▂▃▅▃▄▅▃▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▇▅▄▂▄▄▃▃▄▆▅▇█▅▅▁▇▆▄▆▅▇▃▃▆▆▆▃▂▃▅▅▅▃▃▂▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84052
wandb: best/eval_avg_mil_loss 0.48335
wandb:  best/eval_ensemble_f1 0.84052
wandb:            eval/avg_f1 0.84052
wandb:      eval/avg_mil_loss 0.48233
wandb:       eval/ensemble_f1 0.84052
wandb:            test/avg_f1 0.8777
wandb:      test/avg_mil_loss 0.38612
wandb:       test/ensemble_f1 0.8777
wandb:           train/avg_f1 0.8367
wandb:      train/ensemble_f1 0.8367
wandb:         train/mil_loss 0.52287
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1fpykfxc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081335-1fpykfxc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2rxb2nqj with config:
wandb: 	actor_learning_rate: 0.00043248603643884786
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5483624645870547
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8693207282590841
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081557-2rxb2nqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rxb2nqj
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▃▃▃▃▃▃▂▂▃▃▃▃▃▂▂▂▂▂▁▂▁▁▂▂▃▃▂▂▂▅▅▄████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▆▃▆▂▃▄▆▄▂▆▃▃▃▁▇▃▄▅▆▄▅▄▃▄▇▃▇▁▂▄▃▂▇▄▅▆▅▃
wandb:      train/ensemble_f1 ▆▅▄▆▃▄▅▆▃▄▆▄▄▄▃▄▄▅▆▄▄▅▆▄▄▃▇▆▁▅▃▄▅▆█▅▅▆▅▄
wandb:         train/mil_loss ▂▁▇▆▇▄█▅▄▂▅▅▇▅▄▃▆▅▅▆▂▆▇█▄▄▂▇▆▃▃█▄▄▆▇▅▄▇█
wandb:      train/policy_loss █▄▂▃▃▁▅▅▄▁▂▅▆█▅▆▃▃▆▅▅▄▇▁▃▄▄▃▃▄▆▅▆▃▃▅▃▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▂▃█▃▅▄▄▄▄▄▄▄▄▄▅▅▂▄▅▄▃▅▂▅▄▃▄▂▃▄▂▁▃▃▄▃▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.08103
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.08711
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.20321
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32925
wandb:      train/ensemble_f1 0.32925
wandb:         train/mil_loss 0.83568
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sage-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2rxb2nqj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081557-2rxb2nqj/logs
wandb: Agent Starting Run: 2kpmo69s with config:
wandb: 	actor_learning_rate: 0.0009073554176184212
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4203635902459883
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5952443449590047
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_081742-2kpmo69s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2kpmo69s
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████
wandb:      eval/avg_mil_loss ▄▄▄▃▃▃▃▂▂█▆▇██▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▄▆▃▅▆▆▇▄▃▄▁▅▁▆▄▄▆▃▃▃█▃▇▃▅▄▄▅▄▆▅▆▄▄▄▆█▆
wandb:      train/ensemble_f1 ▆█▇█▄█▄▄▄▆▁▅▅▂▇▅▅▅▆▇▅▇▅▆▄▃▇▇▆▆▅▇▇▃▅▆▄▆▄▅
wandb:         train/mil_loss ▃▄▃▄▃▃▄▄▃▃▂▄▄▂█▅▃▃▅▄▃▄▃▄▅▁▅▂▆▅▄▁▃▃▃▃▃▅▃▃
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▃██▆▃▁▆▄▄▄▄▆▄▇▆█▇▆▆█▃▄▄▇▄██████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65036
wandb: best/eval_avg_mil_loss 0.72208
wandb:  best/eval_ensemble_f1 0.65036
wandb:            eval/avg_f1 0.64494
wandb:      eval/avg_mil_loss 0.70707
wandb:       eval/ensemble_f1 0.64494
wandb:            test/avg_f1 0.71205
wandb:      test/avg_mil_loss 0.54264
wandb:       test/ensemble_f1 0.71205
wandb:           train/avg_f1 0.66635
wandb:      train/ensemble_f1 0.66635
wandb:         train/mil_loss 0.51547
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2kpmo69s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_081742-2kpmo69s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d6qnz6lp with config:
wandb: 	actor_learning_rate: 3.553418308088061e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17872885987407627
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9108238236870736
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082004-d6qnz6lp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6qnz6lp
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▃▆██████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▃▃▃▃▃▃▆██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▁▃▅▅▄▄▄▃▅▅▅▃▄▄▅▄▃▅▆▄▄▇▄▆▄▇▆▇▅▇█▇▅▇▄▇▆
wandb:      train/ensemble_f1 ▁▃▄▁▄▂▅▄▄▃▅▅▃▄▃▅▅▃▃▄▅▃▆▄▅▇▄▅▇▆▅▅▇▇▆█▅▅▄▇
wandb:         train/mil_loss ▅█▆▄▆▆▅▇▅▇█▄▇▇█▇▇▄▇▃▇▆▅▅▄▅▄▂▅▅▇▄▄▇▃▂▅▃▁▅
wandb:      train/policy_loss ▇▂▂▂▁▂▁▁▂▃▂▃▃▂▂▂▁▄▆▇▇▇▆▇█▆▇▇▇▅▇█▆▇▇█▇▇▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▂▁▂▂▁▁▃▃▂▂▃▁▄▇█▇▇██▇███▇█▆█▇▇███▇█▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77311
wandb: best/eval_avg_mil_loss 0.53937
wandb:  best/eval_ensemble_f1 0.77311
wandb:            eval/avg_f1 0.77311
wandb:      eval/avg_mil_loss 0.51466
wandb:       eval/ensemble_f1 0.77311
wandb:            test/avg_f1 0.78948
wandb:      test/avg_mil_loss 0.39731
wandb:       test/ensemble_f1 0.78948
wandb:           train/avg_f1 0.76703
wandb:      train/ensemble_f1 0.76703
wandb:         train/mil_loss 0.45902
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6qnz6lp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082004-d6qnz6lp/logs
wandb: Agent Starting Run: s4r8qzfm with config:
wandb: 	actor_learning_rate: 0.0009130561712765716
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6622229067276827
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.342296240779437
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082237-s4r8qzfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4r8qzfm
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁██████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 █████████▁▁▁▁▁██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▅▅▅▃▄▅▄▄▄▄▁▄▅▆▇▅▇█▇▄▆▆▄▅▆▆▄▇▅▇▅▅▆▆▇▇▆
wandb:      train/ensemble_f1 ▄▅▂▅▁▁▅▃▂▃▃▃▁▄▄▂▄▄▆▅▃▅█▆█▇▇▃▃▂▆▄▇▅▃▄▄▇▅▅
wandb:         train/mil_loss ▃▄▅▁▅▃▄▇▆▂▄█▄▄▁▅▄▆▃▄▄▃▂▄▄▄▄▄▅▃▄▅▃▄▂▄▄▅▂▅
wandb:      train/policy_loss ▆▆▅▆▄▆▅▄▄▄▄▁▆▃▅▃▆▃▂▅█▅▆▄█▇▆▆▇▇▆▆▃▆▆▇▁▄▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▆▅▄▆▃▃▃▃▂▃▃▆▆▆▅▂▃▅▇▄▃▄▃▃▆█▆▅▆▅▅▅▃▄▆▁▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65573
wandb: best/eval_avg_mil_loss 0.68341
wandb:  best/eval_ensemble_f1 0.65573
wandb:            eval/avg_f1 0.65573
wandb:      eval/avg_mil_loss 0.66077
wandb:       eval/ensemble_f1 0.65573
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.52887
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.67405
wandb:      train/ensemble_f1 0.67405
wandb:         train/mil_loss 0.58617
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s4r8qzfm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082237-s4r8qzfm/logs
wandb: Agent Starting Run: hf0spxkk with config:
wandb: 	actor_learning_rate: 0.00023347872897763657
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8432481155409743
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7960695116040067
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082420-hf0spxkk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hf0spxkk
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▇█
wandb: best/eval_avg_mil_loss █▇▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆▇█
wandb:            eval/avg_f1 ▁▁▁▃▃▆▇████▇▇▇▇▇▇▇▇▇▆▆▆▇▇▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▅▅▅▅▅▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▃▆▆▆██▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▆▆▇▇▇▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▂▃▄▃▃▆▆▅▄▄▇▄▅█▅▆▇▅▆▇▇▇▆▅▆▆▅▆▃█▂▆▄▄▇▅▅
wandb:      train/ensemble_f1 ▃▂▄▁▃▂▂▅▄▄▃▅▃▃▃▇▄▇▆▆▅▆▄▅▆▆▄▅▄▅▃█▆▇▄▅▅▆▇▃
wandb:         train/mil_loss ▄▃█▂▆▃▇▁▅▁▆▅▄▄▂▂▄▅▄▆▃▇▅▃▆▅▄▂▄▂▄▂▅▃▃▅▂▄▂▂
wandb:      train/policy_loss ▅▅▅█▇▂▂▄▂▅▃▂▂▄▂▃▂▃▃▂▃▃▂▂▂▄▃▃▂▁▂▃▄▁▃▃▃▁▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▅█████████████████▁████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67678
wandb: best/eval_avg_mil_loss 0.74665
wandb:  best/eval_ensemble_f1 0.67678
wandb:            eval/avg_f1 0.66634
wandb:      eval/avg_mil_loss 0.7351
wandb:       eval/ensemble_f1 0.66634
wandb:            test/avg_f1 0.70095
wandb:      test/avg_mil_loss 0.4791
wandb:       test/ensemble_f1 0.70095
wandb:           train/avg_f1 0.68183
wandb:      train/ensemble_f1 0.68183
wandb:         train/mil_loss 0.51569
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hf0spxkk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082420-hf0spxkk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kd95n808 with config:
wandb: 	actor_learning_rate: 1.3827184316000249e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6655582915395515
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6642479254789311
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_082639-kd95n808
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kd95n808
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆█
wandb: best/eval_avg_mil_loss █▆▅▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▃▄▄▄▆▆▆▆█████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▃▆▁▄▅▆▄▆▅▃▄▅▄▅▅▄▅▆▇▆▅▅▆▇▇▆▆█▇▆▅▆▅▇▆▇▆▇
wandb:      train/ensemble_f1 █▃▆▅▇▄▄█▁▃▃▅▅▄▅▃▅▄▅▇▇▄▇▆▆▆▅▅▆▅▆▅▆▄▇█▄▅▇▅
wandb:         train/mil_loss ▄█▄█▂▅▃▆▄▄▃█▅▄▇▅▄█▅▁▃▃▆▅▅▄▄▄▅▃▃▂▁▄▃▄▇▆▃▄
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▂▃▃▃▅▄▅▄█▅▂▅▆▄▅▄▇▄▆▂▄▄▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅▅▅▅▄▅▇▁▅▅▅▆▆▅▆▆▆▄▆▆▆▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76405
wandb: best/eval_avg_mil_loss 0.56421
wandb:  best/eval_ensemble_f1 0.76405
wandb:            eval/avg_f1 0.76405
wandb:      eval/avg_mil_loss 0.54876
wandb:       eval/ensemble_f1 0.76405
wandb:            test/avg_f1 0.76472
wandb:      test/avg_mil_loss 0.43817
wandb:       test/ensemble_f1 0.76472
wandb:           train/avg_f1 0.75502
wandb:      train/ensemble_f1 0.75502
wandb:         train/mil_loss 0.49203
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kd95n808
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_082639-kd95n808/logs
wandb: Agent Starting Run: 9z5dvv8o with config:
wandb: 	actor_learning_rate: 0.0006513015855550438
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.643170314420461
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.704240327622126
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083027-9z5dvv8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9z5dvv8o
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▆▅▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▃▅▆▆▆▆▆▆▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▅▁▇▅▄▄▆▄▅▆▅▆▇▆▆█▆█▅▇▅▅▅▆█▅▅▇▅▆▇▇▆▅▇▇▅
wandb:      train/ensemble_f1 ▅▅▁▇▅▅▄▄▄█▆▃▅▆▅▇▆▅▅▅▄█▄▆▅▇▆▇▆▆▆▆▇▇█▆▆▇▆▆
wandb:         train/mil_loss █▅▇▄▃▅▄▄▄▅▅▄▃▂▁▄▅▄▄▂▇▄▄▄▄▆▃▃▅▃▅▆▄▁▃▅▄▂▅▄
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67158
wandb: best/eval_avg_mil_loss 0.66006
wandb:  best/eval_ensemble_f1 0.67158
wandb:            eval/avg_f1 0.66634
wandb:      eval/avg_mil_loss 0.63959
wandb:       eval/ensemble_f1 0.66634
wandb:            test/avg_f1 0.72295
wandb:      test/avg_mil_loss 0.51158
wandb:       test/ensemble_f1 0.72295
wandb:           train/avg_f1 0.68081
wandb:      train/ensemble_f1 0.68081
wandb:         train/mil_loss 0.53087
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9z5dvv8o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083027-9z5dvv8o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ipftrl76 with config:
wandb: 	actor_learning_rate: 6.646931830357472e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41071664147208287
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8793912354023662
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083357-ipftrl76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipftrl76
wandb: uploading history steps 268-270, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆█████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▃▃▆▆▆▆█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▂▂▄▃▂▂▂▅▅▃▅▂▃▁▄▆▄▆▅▆▇▃▇▆▇▅▆▆▇▆▆▅▆█▇██
wandb:      train/ensemble_f1 ▅▄▃▆▃▄▁▂▄▅▃▅▄▆▅▄▅▅▆▆▇▇▆▇▆▆▆▇▇▇█▆█▆▆▆▆███
wandb:         train/mil_loss ▆▂▆▇█▅▆█▅▅▇▄▆▃▆▆▆▆▅▅▄▆▆▅▇▅█▆▄▇▃▆▆▃▃▅▅▅▆▁
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65036
wandb: best/eval_avg_mil_loss 0.7542
wandb:  best/eval_ensemble_f1 0.65036
wandb:            eval/avg_f1 0.65036
wandb:      eval/avg_mil_loss 0.72764
wandb:       eval/ensemble_f1 0.65036
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.53587
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.68869
wandb:      train/ensemble_f1 0.68869
wandb:         train/mil_loss 0.53669
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ipftrl76
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083357-ipftrl76/logs
wandb: Agent Starting Run: 6r7q8xka with config:
wandb: 	actor_learning_rate: 0.0002974559849076991
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2863807998594211
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03379009509223285
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_083820-6r7q8xka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6r7q8xka
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████▅▄▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▃
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▆▆▆▆▇▇██████████████▇█▆▆▆▆
wandb:       eval/ensemble_f1 ██████▅▄▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇█▇█▇▇▇▇▄▂▂▂▁▂▁▂▂▁▁▁▁▁▂▁▂▁▂▂▂▂▂▃▃▁▂▂▃▂
wandb:      train/ensemble_f1 █▇▇█▇█▇▇██▄▃▂▂▂▃▁▁▁▂▂▁▂▂▂▂▂▂▂▂▃▂▃▂▂▂▂▂▂▃
wandb:         train/mil_loss ▇▅▃▄▆▅▅█▅▅▇█▄▅▆▁█▅▅▁▇▆▆▅▅▅▅▄▃▅▃▅▅▆▄▄▅▅▅▅
wandb:      train/policy_loss ▆▆▆▆▆▆▄▆▆▆▄▆▁▆▆▇▆▅▆▆▆█▆▆▇▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▃▄▆▁▆▅█▇▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63605
wandb: best/eval_avg_mil_loss 0.70478
wandb:  best/eval_ensemble_f1 0.63605
wandb:            eval/avg_f1 0.49959
wandb:      eval/avg_mil_loss 0.77423
wandb:       eval/ensemble_f1 0.49959
wandb:            test/avg_f1 0.64812
wandb:      test/avg_mil_loss 0.60776
wandb:       test/ensemble_f1 0.64812
wandb:           train/avg_f1 0.5143
wandb:      train/ensemble_f1 0.5143
wandb:         train/mil_loss 0.59478
wandb:      train/policy_loss 0.05812
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.05812
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6r7q8xka
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_083820-6r7q8xka/logs
wandb: Agent Starting Run: n03t9r1t with config:
wandb: 	actor_learning_rate: 0.004558358316460634
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07793630546205266
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6991196428531267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084004-n03t9r1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n03t9r1t
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▄▄▃▃▄▄▆▃▄▄▁▇▄▆▄▃▃▅▂▅▆▆▅▄▇▅▅▆▆▅▅▆▇█▅▄▃
wandb:      train/ensemble_f1 ▄▃▅▃▅▄▃▆▄▅▃▄▅▂▆▆▃▄▁▇▆▇▅▅█▅█▄▆▅▃▆▆▆▅▆██▆█
wandb:         train/mil_loss ▇▆▅▆▃▂▅█▇▆▆▅▇▅▆▅▅▅▁▆▄▅▆▃▃▄▄▆▇▂▆▄█▆▅▄█▆▄▇
wandb:      train/policy_loss ▄▄▂▁▄▁▂▂▅▁▅▂▂█▂▃▅▁▅▄▄▂▄▇▂▁▂▃▁▁▄▂▂▂▄▁▅▄▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▁▄▁▃█▄▃▄▆▁▁▆▆▃▅▃▁▃▄▄▄▁▆▁▄▄▁▅▃▁▄▁▁▄▆▄▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61141
wandb: best/eval_avg_mil_loss 1.10711
wandb:  best/eval_ensemble_f1 0.61141
wandb:            eval/avg_f1 0.61141
wandb:      eval/avg_mil_loss 1.046
wandb:       eval/ensemble_f1 0.61141
wandb:            test/avg_f1 0.66037
wandb:      test/avg_mil_loss 0.73561
wandb:       test/ensemble_f1 0.66037
wandb:           train/avg_f1 0.61424
wandb:      train/ensemble_f1 0.61424
wandb:         train/mil_loss 1.14855
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n03t9r1t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084004-n03t9r1t/logs
wandb: Agent Starting Run: 1n8xy2kx with config:
wandb: 	actor_learning_rate: 0.0003663081522464354
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.448589044627814
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22343935493183475
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084147-1n8xy2kx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1n8xy2kx
wandb: uploading history steps 188-204, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇██▂▂▂██████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▂███████▂████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▁▅▃▇▆▃▅▅▆▄▅▅▇▄▆▆▄▅▅▅▇▅▃▄▄▇▆▆▄▅▇▅▆▄▅█▅
wandb:      train/ensemble_f1 ▄▄▂▃▄▆▅▂▃▅█▃▄▂▄▃▅▂▅▅▃▁▃▄▂▂▇▅▄▇▃▄▆▇▅▅▆▇▅▄
wandb:         train/mil_loss ▁▅▃▃▄▃▃▂▆▄▅▄▄▅▂▃█▅▅▄▃▄▃▅▅▃▅▂▃▁▃▅▅▇▃▄▅▅▂▁
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84499
wandb: best/eval_avg_mil_loss 0.47429
wandb:  best/eval_ensemble_f1 0.84499
wandb:            eval/avg_f1 0.84499
wandb:      eval/avg_mil_loss 0.47219
wandb:       eval/ensemble_f1 0.84499
wandb:            test/avg_f1 0.88607
wandb:      test/avg_mil_loss 0.3791
wandb:       test/ensemble_f1 0.88607
wandb:           train/avg_f1 0.84784
wandb:      train/ensemble_f1 0.84784
wandb:         train/mil_loss 0.4998
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1n8xy2kx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084147-1n8xy2kx/logs
wandb: Agent Starting Run: 3uzjcrj1 with config:
wandb: 	actor_learning_rate: 0.0011575611101402189
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03935305832213498
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7399847797639592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084508-3uzjcrj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3uzjcrj1
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▇▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▂▄█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██████████▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▆█▆▆▅▃▄▂▁▄▂▂▅▁▃▃▄▄▄▄▄▄▄▅▃▅▂▃▄▃▄▃▅▄▄▅▄
wandb:      train/ensemble_f1 ▇▇█▅▆▇▇▇█▆▆▆▅▃▅▆▂▃▄▃▃▃▁▅▃▄▄▄▄▄▃▅▅▃▄▄▃▃▄▄
wandb:         train/mil_loss ▂▂▁▂▁▂▁▇▄▆▇▇▆▅▆▅█▆▇▅▆▅▇▆▇▆▇▆▅▇▇▆▅▇▄▆▅▆▇▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇██▇▇▇▇▇███▇████▇▇▇▇▇█▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇▇██▇▇██▇▇██▇▇██▇█▇▇██▇██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72181
wandb: best/eval_avg_mil_loss 0.69734
wandb:  best/eval_ensemble_f1 0.72181
wandb:            eval/avg_f1 0.67158
wandb:      eval/avg_mil_loss 0.95262
wandb:       eval/ensemble_f1 0.67158
wandb:            test/avg_f1 0.74938
wandb:      test/avg_mil_loss 0.47159
wandb:       test/ensemble_f1 0.74938
wandb:           train/avg_f1 0.67876
wandb:      train/ensemble_f1 0.67876
wandb:         train/mil_loss 1.01003
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3uzjcrj1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084508-3uzjcrj1/logs
wandb: Agent Starting Run: fkjca1sl with config:
wandb: 	actor_learning_rate: 0.0003832069859548538
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5314107027178427
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16251260410469726
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_084652-fkjca1sl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fkjca1sl
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▂▄▂▂█▄▃▅▆▃▃▅▆▂▂▃▃▄▄▅▅▄▁▅▄▄▄▄▅█▅▄▄▁▂▅█
wandb:      train/ensemble_f1 ▄▃▂▃▄▄▃▆█▅▄▁▃▆▆▄▃▂▄▂▄▃▆▅▃▅▃▃▅▇▁▇▆▄▃▅▆▄▅█
wandb:         train/mil_loss ▄▂▄▃▁▄▃▅▂▃▃▃▃▂▁▃▂▅▂▃█▂▃▆▂▂▄▃▃▃▄▂▂▄▄▃▂▃▂▃
wandb:      train/policy_loss ▅▂█▆▄▄▅▄▂▅▄▄▃▅▅▂▄▅▄▅▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆█▃▅▅▃▄▂▆▅▅▆▁▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84499
wandb: best/eval_avg_mil_loss 0.47623
wandb:  best/eval_ensemble_f1 0.84499
wandb:            eval/avg_f1 0.84499
wandb:      eval/avg_mil_loss 0.4742
wandb:       eval/ensemble_f1 0.84499
wandb:            test/avg_f1 0.88607
wandb:      test/avg_mil_loss 0.38141
wandb:       test/ensemble_f1 0.88607
wandb:           train/avg_f1 0.84515
wandb:      train/ensemble_f1 0.84515
wandb:         train/mil_loss 0.49739
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fkjca1sl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_084652-fkjca1sl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k1y4ogh0 with config:
wandb: 	actor_learning_rate: 8.513983066429841e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07206392859507615
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4416351251375411
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085052-k1y4ogh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1y4ogh0
wandb: uploading history steps 175-178, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆█
wandb: best/eval_avg_mil_loss █▆▅▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▄▄▄▅▅▅▆▆█████████████████████████
wandb:      eval/avg_mil_loss ███████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▅▆▆██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▂▂▃▂▂▃▃▂▅▄▃▇▅▄▅▆▂▁▆▃▄▅▅▄▅▆▄▃▆▅▄▇▅▇▇█▆
wandb:      train/ensemble_f1 ▃▄▁▃▂▃▂▂▁▄▅▃▄▄▄▅▄▆▃▅▄▅▅▂▄▄▆▃▅▅▃▅▆▄▆▅▅▆▇█
wandb:         train/mil_loss ▅▅▅▅▅▄▅▅▄▆█▄▅▃▅▄▅▆▅▄▆▂▄▂▄▄▅▆▄▂▆▂▂▃▆▄▂▇▁▄
wandb:      train/policy_loss ██████████▃█████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75948
wandb: best/eval_avg_mil_loss 0.75733
wandb:  best/eval_ensemble_f1 0.75948
wandb:            eval/avg_f1 0.75948
wandb:      eval/avg_mil_loss 0.72178
wandb:       eval/ensemble_f1 0.75948
wandb:            test/avg_f1 0.75454
wandb:      test/avg_mil_loss 0.48069
wandb:       test/ensemble_f1 0.75454
wandb:           train/avg_f1 0.74994
wandb:      train/ensemble_f1 0.74994
wandb:         train/mil_loss 0.74508
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1y4ogh0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085052-k1y4ogh0/logs
wandb: Agent Starting Run: n97u97fc with config:
wandb: 	actor_learning_rate: 0.0002583475173087705
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10937885280160642
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16109855505552384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085347-n97u97fc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n97u97fc
wandb: uploading history steps 333-348, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆██
wandb: best/eval_avg_mil_loss █▆▅▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▃▆██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▆▆█████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▁▄▅▂▅▄▃▅▅▄▄▃▄▄▅▄▄▄▅▅▅▄▄▅▃▃▅▅▇▅▆▆▅█▇█▆
wandb:      train/ensemble_f1 ▃▂▁▂▂▃▂▃▄▃▃▃▂▄▄▄▃▅▄▄▂▄▁▄▄▅▅▆▅▅▆▆█▆█▆▆▆█▆
wandb:         train/mil_loss ▃▅▄▃▆▄▅▄▅▁▅▄▃▃▄▅▆▃▁▁█▄▂▄▄▂▂▂▃▄▃▂▃▃▂▄▃▃▅▃
wandb:      train/policy_loss ▆▇▃▆▆▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85335
wandb: best/eval_avg_mil_loss 0.46959
wandb:  best/eval_ensemble_f1 0.85335
wandb:            eval/avg_f1 0.85335
wandb:      eval/avg_mil_loss 0.46715
wandb:       eval/ensemble_f1 0.85335
wandb:            test/avg_f1 0.91105
wandb:      test/avg_mil_loss 0.38012
wandb:       test/ensemble_f1 0.91105
wandb:           train/avg_f1 0.86807
wandb:      train/ensemble_f1 0.86807
wandb:         train/mil_loss 0.50742
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n97u97fc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085347-n97u97fc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kuewam46 with config:
wandb: 	actor_learning_rate: 0.008274893324808722
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3132280508060612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9708023059048682
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_085933-kuewam46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuewam46
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▇▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▄▃▃▃▃▃▂▂▂▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇█
wandb:       eval/ensemble_f1 ████████▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▄▃▃▃▃▂▂▂▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄█▇▇▇▇▃▃▆▇▅▃▅▄▄▆▄▅▃▄▂▇▄▂▆▃▄▄▅▃▅▃▄▄▁▄▅▅
wandb:      train/ensemble_f1 █▄▆▃▄▇▆█▆█▃▃▄▇▅▅▅▅▄▆▄▅▂▂▂▄▆▄▅▅▅▃▇▄▄▁▄▄▆▅
wandb:         train/mil_loss ▅▄▄▃▅▁▃▄▅▄▄▄▆▇▂▅▄▆█▅▄▄▇▆▁▄▅▇▆█▃▄▄▇█▇▇▄▅▅
wandb:      train/policy_loss ▆▇▆▆▇▇▇▆▇▇█▁▆▇█▅▇▅▄█▆▆▄▆█▆▅▅▇▆▇▇▄▄▄▃▂▂▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▇▇▆▇█▇▂▃▁▆██▆▆▇▄▆▆▆▇▄▆██▂▆▆▆▄▄▄▄▄▂▂▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84408
wandb: best/eval_avg_mil_loss 0.47661
wandb:  best/eval_ensemble_f1 0.84408
wandb:            eval/avg_f1 0.78371
wandb:      eval/avg_mil_loss 0.55341
wandb:       eval/ensemble_f1 0.78371
wandb:            test/avg_f1 0.86615
wandb:      test/avg_mil_loss 0.41319
wandb:       test/ensemble_f1 0.86615
wandb:           train/avg_f1 0.82743
wandb:      train/ensemble_f1 0.82743
wandb:         train/mil_loss 0.51666
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuewam46
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_085933-kuewam46/logs
wandb: Agent Starting Run: mmn51nto with config:
wandb: 	actor_learning_rate: 0.0017186998590554591
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39747657606674847
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9557403601609348
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090117-mmn51nto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mmn51nto
wandb: uploading history steps 189-198, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▇▃▄▆▃▄▅▃▃▁▂▇▆▅▄▂▅▄▆▆▃▂▇▃▅▆▄▆▆█▅▆▅▂▄▇▆▂
wandb:      train/ensemble_f1 ▂▄▅▃▄▄▅▁▄▄▃▅▂▄▆▂█▄▂▄▂▆▅▇▅▆▅▂▂▅▄▄▅▂▃▆▇▄▅▄
wandb:         train/mil_loss ▄▃▃▇▄▆▇▅█▃▃▄▆▂▆▄▇▂▃▄▆▅▃▆▅▅▂▅▂▆▅▆▆▃▆▄▆▅▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68706
wandb: best/eval_avg_mil_loss 0.97125
wandb:  best/eval_ensemble_f1 0.68706
wandb:            eval/avg_f1 0.68706
wandb:      eval/avg_mil_loss 0.91932
wandb:       eval/ensemble_f1 0.68706
wandb:            test/avg_f1 0.70095
wandb:      test/avg_mil_loss 0.62342
wandb:       test/ensemble_f1 0.70095
wandb:           train/avg_f1 0.70588
wandb:      train/ensemble_f1 0.70588
wandb:         train/mil_loss 0.70788
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mmn51nto
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090117-mmn51nto/logs
wandb: Agent Starting Run: dxvlib6j with config:
wandb: 	actor_learning_rate: 0.00114612658175892
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14870470047245476
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17467647064109748
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090433-dxvlib6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxvlib6j
wandb: uploading history steps 111-116, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▃▃▃▄▄▄▃▁▂
wandb:      eval/avg_mil_loss ▆▆▆▆▅▅▅▅▅▆▆▆▇▇▇▇▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▆▆▆▆▁
wandb:       eval/ensemble_f1 ▆▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▄▄▄▃▄▄▃▄▃▂▂▁▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▄▄▆▆▅▇▇▇▇▆▆▄█▄▅▆▄▃▄▃▅▄▃▂▃▂▇▆▅▄▄▁▂▄▃▅▄▄
wandb:      train/ensemble_f1 ▄█▄▆▆▄▅▇▄▇▇▇▅▅▇▆▄▅▃▄▄▄▄▃▃▄▂▅▆▄▁▄▄▅▃▃▄▄▄█
wandb:         train/mil_loss ▃▄▅▇▅▆▆▆▁▃▃▆▂▅█▂▇▅▆▇▄▇▃▂▆▆▃▆▄▇▆▁▄▅▂▄▅▄▁▇
wandb:      train/policy_loss ▁▆▇██▇█▇▄▄▄▄▄▄▄▄▄▄▄▄▄▇▆▅▇▆▆▄▄▄▅▅▅▅▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▅▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆███▄▁▁▁▄▅▄▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51802
wandb: best/eval_avg_mil_loss 0.7038
wandb:  best/eval_ensemble_f1 0.51802
wandb:            eval/avg_f1 0.49632
wandb:      eval/avg_mil_loss 0.70074
wandb:       eval/ensemble_f1 0.49632
wandb:            test/avg_f1 0.54733
wandb:      test/avg_mil_loss 0.66152
wandb:       test/ensemble_f1 0.54733
wandb:           train/avg_f1 0.57003
wandb:      train/ensemble_f1 0.57003
wandb:         train/mil_loss 0.63827
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxvlib6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090433-dxvlib6j/logs
wandb: Agent Starting Run: kdigy2ba with config:
wandb: 	actor_learning_rate: 0.003899019582447897
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11103485136190938
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.909766642624182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090627-kdigy2ba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kdigy2ba
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 141-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▄▄▄▆▆▆▆▆████████████▄▄▄▄▄▄▄▄▄▄▃▁▁▁▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅███▇▇▇
wandb:       eval/ensemble_f1 ▄▄▅▅▅▅▇▇▇▇▇▇▇▇█▇▇▇▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▂▁▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▆▃▄▇▁▄▃▃▄▂▅▆▆▃█▅▅▆▂▅█▄▄▂▂▆▄▄▄▃▃▃▃▅▂▅▆
wandb:      train/ensemble_f1 ▇▅▄▅▅▄▆▆▄▆▄▄▅▆▇▇▄▆▄█▅▆▅▅▄▅▄▆▃▁▄▄▃▄▆▄▆▄▅▄
wandb:         train/mil_loss ▆▆▆▁▅▄▃▁▂▄█▃▄▆▆▇▅▂▃▂▄▆▅▅▂▂▃▇▇▃▄▄▂▃▄▅▇▃▃▆
wandb:      train/policy_loss ▄▄▄▄▄▄▁▂▂▂▂▁▁▂▄▁▁▂▂▂█▇▇▇▇▇██▇▇▇▄▄▇█▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▁▂▁▁▁▁▁▁▂▁▁▂▂▂▇▇█▇▇▇███▇█▇▇▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83544
wandb: best/eval_avg_mil_loss 0.56561
wandb:  best/eval_ensemble_f1 0.83544
wandb:            eval/avg_f1 0.82013
wandb:      eval/avg_mil_loss 0.59555
wandb:       eval/ensemble_f1 0.82013
wandb:            test/avg_f1 0.86068
wandb:      test/avg_mil_loss 0.36135
wandb:       test/ensemble_f1 0.86068
wandb:           train/avg_f1 0.82681
wandb:      train/ensemble_f1 0.82681
wandb:         train/mil_loss 0.54325
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kdigy2ba
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090627-kdigy2ba/logs
wandb: Agent Starting Run: fw8onztx with config:
wandb: 	actor_learning_rate: 0.0002646151396437691
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3334428930681844
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2595203241219105
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_090901-fw8onztx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fw8onztx
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▅▅▅▅▄▃▃▃▄▄▄▃▃▃▃▃▃▃▂▂▂▁▂▁▁▁▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃█▇▇▇▅▆▆█▅▇▄▇▆▇▇▄▁▅▅▄█▇█▇▅▄▆▁▆▆▆▇▅▇▄▇▅
wandb:      train/ensemble_f1 ▅▆▃▃▇▆███▂▇▆▅▇▇▅▇▇▇▄▃▄▅▄▆█▅▃▄▆▇▁▆▆▃▄▄▅▇▄
wandb:         train/mil_loss ▆▆█▅▁▅▅▄▇▁▁▆▄▅▃▅▄▆▃▆▇▇█▃▆▄▄▆▄▁▅▆▇▅▃▂▁▃▃▄
wandb:      train/policy_loss ▂▁▅▄▅▃▂▆▃▆▅▃▄▅▃▅▅▅▄▆▃▃▂▆▅▆▅▆▄▂▃▇▄▆▃█▇▃▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▄▆▄▄▄▆▄▅▂▆▃▅▇▄▇▄▃▆▃▂▁▄▃▅▂▅▆▇▂▆▄▆▅█▆▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 0.93211
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.92517
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.00923
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33211
wandb:      train/ensemble_f1 0.33211
wandb:         train/mil_loss 0.6786
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fw8onztx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_090901-fw8onztx/logs
wandb: Agent Starting Run: vctdcfgu with config:
wandb: 	actor_learning_rate: 0.0001202253462665872
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8383364704439217
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.050571493425127345
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091045-vctdcfgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vctdcfgu
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▅▆▅▆▅▅▄▄▃▃▁▁▂▂▂▂▂▃▂▂▂▇▇▇███▇▇▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▂▅▅▇▂▄▆▅▄▆▄▂▅▁▅▅▅▄▄▂▇▆▆▆▄▇▆▄▅█▅▅▅▅▅▂█
wandb:      train/ensemble_f1 ▅▄▂▁▆▃▄▄▂▅▇▄▄▂▂▅▅▁▅▄▂▂▃▆▄▅▃▆▄▃▁█▅▂▇▅▁▂▄█
wandb:         train/mil_loss ▂▇▄▂▃▄▂▃▃▆▂▅▁▅▄▂▅█▇▂▂▃▄▄▄▁▃▂▃▂▂▅▅▄▂▂▂▅▁▂
wandb:      train/policy_loss ▇▇▄▆▁▃▂▇▄▇▅▇▅▃▆▂▆▆▅▄▇█▄▃▄▇▄▆▄▆▃▇▆▇▄▆▄▆▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▆▇▇▇▅▄▇█▅▅▅▆▅▁▄▄▅▅▅▅▇▅▅▇▅▅▆▅▆▅▇▇▅▄▅▅▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 0.9905
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.98713
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.07047
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.34234
wandb:      train/ensemble_f1 0.34234
wandb:         train/mil_loss 0.51384
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vctdcfgu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091045-vctdcfgu/logs
wandb: Agent Starting Run: tp66ibwt with config:
wandb: 	actor_learning_rate: 0.001932950895686177
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6167715912243994
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7158554787259461
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091229-tp66ibwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tp66ibwt
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▆▄▁▅█▂▄▂▃▂▆▃▄▆▄▄▄▄▆▆▆▅▅▄▃▅▆▅▃▆▄▃▃▅▂▆▃
wandb:      train/ensemble_f1 ▆▆▅▃▆▄▁▆▅█▅▇▄▃▅▆▃▂▃▄▄▄▃▃▆▆▆▄▆▅▅▃▁▄▃▅▃▂▃▄
wandb:         train/mil_loss ▅▂▅▄█▆▂▃▄▅▃▂▁▅▃▅▆▆▄▃▅▄▃▅▄▁▆▄▆▅▅▄▃▃▄▅▄▃▆▄
wandb:      train/policy_loss ▃▆▆▃▇▃█▇█▄▆▅▄▅▆▁▆▆▆▅▄▆▆▆▄▆▄▅▅▆▅▆▅▅▆▅▆▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▇▅▅▅▁▂▅▄▅▄▅▅▄▄▃▆▄▇▆▅▄▆▅▅▇▄▅▄▅▆▅▄▃▅█▅▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.03593
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.02859
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.13827
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33089
wandb:      train/ensemble_f1 0.33089
wandb:         train/mil_loss 0.66023
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tp66ibwt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091229-tp66ibwt/logs
wandb: Agent Starting Run: e2kdkrit with config:
wandb: 	actor_learning_rate: 6.37009820250276e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4767563913620295
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23159172578380935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091413-e2kdkrit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2kdkrit
wandb: uploading history steps 205-206, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss █▆▅▅▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▄▄▆▆▆██████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▄▄▅▅▅▅▅▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▂▃▆▄▁▅▃▅▂▅▅▃▅▆▆▅▇▆▅▄▆▇▅▅▅▄▃▄▆▆▄█▇▇▇▆▇█
wandb:      train/ensemble_f1 ▃▃▁▄▃▆▅▇▃▁▅▅▄▆▄▄█▆▆▆▆▇▅▇▅▆▄▄▅▆█▆▆█▆▇▅▇▇█
wandb:         train/mil_loss ▆▆▅▄▆█▄▇▃▅▂▂█▅▃▄▅█▇▄▁▂▂▄▃▆▄▅▄▃▅▄▄▃▃▃▃▅▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76405
wandb: best/eval_avg_mil_loss 0.56414
wandb:  best/eval_ensemble_f1 0.76405
wandb:            eval/avg_f1 0.76405
wandb:      eval/avg_mil_loss 0.54442
wandb:       eval/ensemble_f1 0.76405
wandb:            test/avg_f1 0.76472
wandb:      test/avg_mil_loss 0.43811
wandb:       test/ensemble_f1 0.76472
wandb:           train/avg_f1 0.76573
wandb:      train/ensemble_f1 0.76573
wandb:         train/mil_loss 0.49751
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2kdkrit
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091413-e2kdkrit/logs
wandb: Agent Starting Run: lteccvmt with config:
wandb: 	actor_learning_rate: 6.654541687752174e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.866896067871246
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6516390228381701
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_091733-lteccvmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lteccvmt
wandb: uploading wandb-summary.json
wandb: uploading history steps 171-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▁▁▁▁▁▁▅▅▅▅▅▅▁▁▅▅▅▅███████████▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▁▁▁▁▁▁▁▁▅▅▁▁▁▅▅████▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▄▃▁▃▆▄▆▄▅▃▂▅▅▃▆▂▃▃▄▅▄▄▄▃█▅▆▃▃▄▅▆▇▄▆▃█
wandb:      train/ensemble_f1 ▄▅▃▇▃▂▆▄▂▄▅▂▃▅▃▁▄▄▃█▄▆▁▆▃▄▆▃▅▄▄▂▆▄▄▇██▃▄
wandb:         train/mil_loss ▄▃▅▃▆▅▃▁▄▃█▄▃▅▂▅▃▄▆▅▂▃▂▅▂█▅▃▁▅▃▅▂▄▇▄▃▇▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▅▂▆▃▄▃▁██▂▂▅▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71206
wandb: best/eval_avg_mil_loss 0.67709
wandb:  best/eval_ensemble_f1 0.71206
wandb:            eval/avg_f1 0.70714
wandb:      eval/avg_mil_loss 0.66696
wandb:       eval/ensemble_f1 0.70714
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.4901
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.71844
wandb:      train/ensemble_f1 0.71844
wandb:         train/mil_loss 0.48936
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lteccvmt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_091733-lteccvmt/logs
wandb: Agent Starting Run: 1eq3c7ck with config:
wandb: 	actor_learning_rate: 0.0009827691656328606
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0025743212098943147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5270086310735416
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092040-1eq3c7ck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1eq3c7ck
wandb: uploading history steps 285-286, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▇█
wandb: best/eval_avg_mil_loss █▇▄▄▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▅▅▇▇▇▇▇▇█████████████████
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▂▄▃▅▃▄▂▄▅▇▆▂▄▅▄▂▆▅▇▇▆▄▅▄▅▆▆▇▆▅▆▅█▆▇███
wandb:      train/ensemble_f1 ▄▆▅▄▄▁▄▅▇▅▄▂█▅▆▃▄▄▅▆█▆▆▆▇▄▇▇▇▆▆█▅▇▇▇▇█▆▆
wandb:         train/mil_loss ▅▇▃▇▆█▄▆▅▆▄▅▇▇█▆▃▄▂▃▆▇▄▄▃▆▄▆▃▄▁▄▂▄▂▂▁▂▃▁
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▁█████████▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67678
wandb: best/eval_avg_mil_loss 1.02629
wandb:  best/eval_ensemble_f1 0.67678
wandb:            eval/avg_f1 0.67678
wandb:      eval/avg_mil_loss 0.96957
wandb:       eval/ensemble_f1 0.67678
wandb:            test/avg_f1 0.71205
wandb:      test/avg_mil_loss 0.67478
wandb:       test/ensemble_f1 0.71205
wandb:           train/avg_f1 0.68773
wandb:      train/ensemble_f1 0.68773
wandb:         train/mil_loss 1.02182
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1eq3c7ck
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092040-1eq3c7ck/logs
wandb: Agent Starting Run: qjzfevqy with config:
wandb: 	actor_learning_rate: 0.0001830592561162269
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7162626757859113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6163391496260942
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092518-qjzfevqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjzfevqy
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▄▃▃▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▆█▆▅▅▃▇▄▆▇▅▆▆▆▄▅▆▅▅█▇▆█▆▅█▃▆▅▄▅▄▂▆▇▄▅
wandb:      train/ensemble_f1 ▄▅▄▃▄▅▆▆▄▃▅▆▄▅▄▄▅▂▄▇█▆▆▄▃▁▅▂█▅▅▄▁▅▅▅▁▄▅▅
wandb:         train/mil_loss █▄▅▆▁▆▅▃▂▇▁▅▂▇▃▅▂▁▅▃▄▃▂▂▃▂▁▅▅▃▃▂▄▅▄▄▂▃▂▄
wandb:      train/policy_loss ▁▄▆▃▆▁▅▆▆▄▆▆▆▆▇▃▆▅▅▆██▃▆▆▅▄▆▇▆▅▅▄▆▅▄▆▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▅▂▇▆▅▃▅▅▇▇▆▄▅▃▅▇▄▅▃▇▆▆▇▆▆█▇▅▆▃▄▅▃▃▅▄▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 0.95489
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.94556
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.00721
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33515
wandb:      train/ensemble_f1 0.33515
wandb:         train/mil_loss 0.62364
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run electric-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjzfevqy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092518-qjzfevqy/logs
wandb: Agent Starting Run: w5h4husx with config:
wandb: 	actor_learning_rate: 0.0001376551585567145
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4611951320455168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5298237525952805
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_092701-w5h4husx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w5h4husx
wandb: uploading history steps 189-200, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆█
wandb: best/eval_avg_mil_loss █▆▅▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▂▂▃▄▄▄▅▅▆▆██████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▃▄▄▅▅▅▅▆▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▃▃▄▅▄▃▂▆▅▄▅▇▅▇▄▃▂▇▄▇▁▇▃▇▅▅▅▆▄▄▆▆▄▇▇▇█
wandb:      train/ensemble_f1 ▂▂▄▃▄▄▆▂▅▃▂▃▅▄▇▄█▆▇▄▄▅▄▅▆▁▇▃▅▃▆█▄▅▄▄▄█▇▅
wandb:         train/mil_loss ▅▇▄█▄▃▄▄▆▅▄▂▆▆▅▅▅▅▃▄▄▂▄▁▃▄▂▄▂▄▃▂▂▃▃▄▂▁▂▃
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅█▅▅▅▆▅▅▃▁▂▅▃▁▁▁▂▃▁▄▃▃▅▃▃▅▂▁▁▇▃▃▂▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76405
wandb: best/eval_avg_mil_loss 0.56417
wandb:  best/eval_ensemble_f1 0.76405
wandb:            eval/avg_f1 0.76405
wandb:      eval/avg_mil_loss 0.54385
wandb:       eval/ensemble_f1 0.76405
wandb:            test/avg_f1 0.76472
wandb:      test/avg_mil_loss 0.43812
wandb:       test/ensemble_f1 0.76472
wandb:           train/avg_f1 0.7594
wandb:      train/ensemble_f1 0.7594
wandb:         train/mil_loss 0.50713
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w5h4husx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_092701-w5h4husx/logs
wandb: Agent Starting Run: ahc2vbb8 with config:
wandb: 	actor_learning_rate: 3.3431073913536186e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08975486990763815
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30761476457966774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093018-ahc2vbb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahc2vbb8
wandb: uploading history steps 111-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇▇▇██████████▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▃▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇████████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▅▂▃▃▄▃▄▃▃▄▁▆▅▃▂▄▃▂▃▃▄▃▅▆▄▄▄▅▆▃▄▆█▅▃▆▃▄
wandb:      train/ensemble_f1 ▃▁▄▃▃▅▃▄▄▄▂▃▂▃▄▂▅▃▂▃▃▃▄▅▆▄▄▂█▄▃▅▅▇▄▆█▅▅▄
wandb:         train/mil_loss ▇▄▆▂▅▁█▆▄▄▄▇▃▅▆▄▅▃▁▅▂▅▃▆▃▆▄▃▂▁▄▄▇▆▅▃▄▂▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▇███▇▇▇██▇███▇█▇▇▁▂▁▂▁▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66634
wandb: best/eval_avg_mil_loss 0.90391
wandb:  best/eval_ensemble_f1 0.66634
wandb:            eval/avg_f1 0.63396
wandb:      eval/avg_mil_loss 0.8706
wandb:       eval/ensemble_f1 0.63396
wandb:            test/avg_f1 0.68963
wandb:      test/avg_mil_loss 0.63954
wandb:       test/ensemble_f1 0.68963
wandb:           train/avg_f1 0.64938
wandb:      train/ensemble_f1 0.64938
wandb:         train/mil_loss 0.81795
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahc2vbb8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093018-ahc2vbb8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pqmmqils with config:
wandb: 	actor_learning_rate: 0.009022083824531011
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7151153963298892
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5264211249719052
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093245-pqmmqils
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqmmqils
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▆▄▄▆▅▄▁▃▁▂▇▄▅▄▄▄▅▄▆█▄▇▃▅▂▅▃▅▅▃▅▄▃▅▆▄▃
wandb:      train/ensemble_f1 ▄▅▇▆▄▃▁▇▄▄▂▇▁█▆▃▃▅▂▄▅▇▅▇▆▂▂▇▄▂▅▁▄█▅▄▆▄▄▄
wandb:         train/mil_loss ▆▆▅▃▄▄▅▇▆▆▄▄▃▆▄▆▁▂▅▇▄▆▄▃▄▃▅▅▄▂▇▄▃▅▄▄▃▃█▄
wandb:      train/policy_loss ▃▂▂▅▄▇▃▆▂▄▅▇▂▃▃▇▅▃▇▁▃▄▄▅▇▄▆▂▃▄▅▆▂▇▄▆▄▅█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇▇▂▄▅▂▃▅▃▂▁▄▅▅▄▆▂▁█▄▂▃▄▄▃▆▂▃▂▅▅▂▇▃▆▁▄▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60564
wandb: best/eval_avg_mil_loss 1.17761
wandb:  best/eval_ensemble_f1 0.60564
wandb:            eval/avg_f1 0.60564
wandb:      eval/avg_mil_loss 1.13879
wandb:       eval/ensemble_f1 0.60564
wandb:            test/avg_f1 0.62321
wandb:      test/avg_mil_loss 0.78426
wandb:       test/ensemble_f1 0.62321
wandb:           train/avg_f1 0.60987
wandb:      train/ensemble_f1 0.60987
wandb:         train/mil_loss 0.77885
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqmmqils
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093245-pqmmqils/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xittahuf with config:
wandb: 	actor_learning_rate: 2.0923651130162977e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07597810567600949
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4883922268368924
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093438-xittahuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xittahuf
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▇▄▃▁▂▄▅▄▃▄▃▄▄▆▄▃▄▄▄▂▅▆▆▄▆▄▆▄█▅▄▂▃▄▄▅▅▃
wandb:      train/ensemble_f1 ▃▄▅▃▄▄▁▂▄▃▄▄▅▄▅▆▄▄▃▃▄▅▄▃▄▆▃▅▃▄▃▄▅█▄▆▄▄▅▃
wandb:         train/mil_loss ▄▅▅▅▅▅▆▃▄▄▄▁▄▃▄▆▄▆█▇▄▄▆▃▅▄▅▃▃▄▂▆▂▂▅▄▅▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63396
wandb: best/eval_avg_mil_loss 1.09172
wandb:  best/eval_ensemble_f1 0.63396
wandb:            eval/avg_f1 0.63396
wandb:      eval/avg_mil_loss 1.03286
wandb:       eval/ensemble_f1 0.63396
wandb:            test/avg_f1 0.6781
wandb:      test/avg_mil_loss 0.70124
wandb:       test/ensemble_f1 0.6781
wandb:           train/avg_f1 0.64627
wandb:      train/ensemble_f1 0.64627
wandb:         train/mil_loss 1.00108
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xittahuf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093438-xittahuf/logs
wandb: Agent Starting Run: qdiyrx2g with config:
wandb: 	actor_learning_rate: 0.00011525281450065262
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2075958016486852
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.476353232502625
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093622-qdiyrx2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qdiyrx2g
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▃▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▆▆▆▆▆▆█████▆▆▆▆▆████████████▅▅▅
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▅▆▆▆▆█████▆▆▆█████████████▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▇▃▃▃▂█▅▁▆▃▃▆▆▂▁▃▇█▅▅▃▅▅▄▇▅▂▇▇▅▅▅█▄▃▆▅▆
wandb:      train/ensemble_f1 ▄▄▂▃▁▂▅▃▅▅▆▆▁▄▂▃▅▅▇▆▇▂▅▃▇▃▃▅▄▄▅▆▇▄▅▃█▇▅▅
wandb:         train/mil_loss ▇▄▅█▆▄▅▅▃▅▄▃▇▄▄▂▄▅▄▇▄▅▄▃▄▄▅▆▃▅▅▃▆▃▃▅▂▃▁▃
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73618
wandb: best/eval_avg_mil_loss 0.79539
wandb:  best/eval_ensemble_f1 0.73618
wandb:            eval/avg_f1 0.72663
wandb:      eval/avg_mil_loss 0.76943
wandb:       eval/ensemble_f1 0.72663
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.51666
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.72613
wandb:      train/ensemble_f1 0.72613
wandb:         train/mil_loss 0.7856
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qdiyrx2g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093622-qdiyrx2g/logs
wandb: Agent Starting Run: f9td4pbe with config:
wandb: 	actor_learning_rate: 0.0002814648144611262
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6828811667116937
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3774898099587076
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_093852-f9td4pbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f9td4pbe
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▇▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆██████████
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▆███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▂▂▂▁▃▆▂▄▄▃▇▄▅▄▆▃▇█▃▄▅▅▇▆▇▆▆▆▇▆▇█▆▇▇▇▇
wandb:      train/ensemble_f1 ▁▄▃▃▁▃▄▃▃▂▂▃▃▅▄▄▅▄▄▃▃▄▄▄▅▄▆▄▅▅▅▆▇▆▆▅█▆▇▆
wandb:         train/mil_loss ▄█▃▂▆▄▄▅▅▄▆▁▆▅▄▅▇▃▃▂▇▅▁▁▂▂▃▄▄▁▄▃▅▁▄▆▃▃▄▅
wandb:      train/policy_loss ██████████████████████▁█████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65573
wandb: best/eval_avg_mil_loss 0.7166
wandb:  best/eval_ensemble_f1 0.65573
wandb:            eval/avg_f1 0.65573
wandb:      eval/avg_mil_loss 0.69581
wandb:       eval/ensemble_f1 0.65573
wandb:            test/avg_f1 0.71753
wandb:      test/avg_mil_loss 0.54113
wandb:       test/ensemble_f1 0.71753
wandb:           train/avg_f1 0.68753
wandb:      train/ensemble_f1 0.68753
wandb:         train/mil_loss 0.52337
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f9td4pbe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_093852-f9td4pbe/logs
wandb: Agent Starting Run: dv6foevh with config:
wandb: 	actor_learning_rate: 2.1837740981716697e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7486381133932756
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.006540137437113236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094417-dv6foevh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dv6foevh
wandb: uploading wandb-summary.json
wandb: uploading history steps 233-246, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅█
wandb: best/eval_avg_mil_loss █▆▅▄▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▂▂▄▄▄▄▄▅▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▄▄▄▅▅▅▅▅▅▅▅▅▅▅██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▅▃▄▅▃▃▂▄▃▂▄▃▂▃▅▅▃▇▃▄▄▅▃▅▁▄▄▇▃▅██▆▅▃▃▇
wandb:      train/ensemble_f1 ▇▂▅▃▂▅▃▄▄▅▄▅█▃▆▄▃▄▄▅▆▆▃▄▇▄▅▁▅▃▁▄▅▅▄▃▆▇▃▆
wandb:         train/mil_loss ▆▅▄▅▅▇▄██▇▅▃▆▇▅▆▅▅▅▇▃▆▅█▅▁▃▅▃▃▅▅▂▇▆▅▄▃▇▅
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▇▅██▅▅▅▅▅▅▅▅▅▅▅▅▄▄▁▂▄▁▃▄▂▂▃▃▅▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7409
wandb: best/eval_avg_mil_loss 0.78482
wandb:  best/eval_ensemble_f1 0.7409
wandb:            eval/avg_f1 0.7409
wandb:      eval/avg_mil_loss 0.76627
wandb:       eval/ensemble_f1 0.7409
wandb:            test/avg_f1 0.73366
wandb:      test/avg_mil_loss 0.53998
wandb:       test/ensemble_f1 0.73366
wandb:           train/avg_f1 0.72373
wandb:      train/ensemble_f1 0.72373
wandb:         train/mil_loss 0.54935
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dv6foevh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094417-dv6foevh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hwvbfbu7 with config:
wandb: 	actor_learning_rate: 1.8530101171018293e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24593641571148683
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3444047125735712
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_094829-hwvbfbu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hwvbfbu7
wandb: uploading history steps 173-182, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▆▇█
wandb: best/eval_avg_mil_loss █▇▃▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▆▇█
wandb:            eval/avg_f1 ▅▄▅▄▄▃▄▄▃▃▃▁▁▁▂▃▃▃▄▄█▇▇▇▇▇▆▅▆▆▄▄▃▅▆▅▅▆▆▄
wandb:      eval/avg_mil_loss ███▇▆▅▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁
wandb:       eval/ensemble_f1 ▅▆▄▄▃▃▂▂▃▁▁▂▂▂▂▅▅▃▄██▇▆▅▅▆▆▇▆▆▅▄▄▄▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▆▂▅▄▃▂▄▁▂▅▅▄▄▅▄▄▂▅▅▃▂▄▅▂▂▄▄▇▃▄▄▂▆▇▄▆▅▅
wandb:      train/ensemble_f1 ▂▇█▄▂▃▂▂▄▃▅▁▅▅▃▃▂▄▂▆▆▇▆▂▅▁▂▄▅▄▆▅▂▆▅█▆▅▆▆
wandb:         train/mil_loss ▆▄▆▅█▄▃▅▃▃▅▄▂▃▇▆▄▆▅▅▅▂▅▄▃▄▄▁▇▆▃▅▆▃▄▄▂▄▆▄
wandb:      train/policy_loss ▄▄▄▄▁▄▄▄▆▄▄▂▄█▄▄▄▄▄▄▄▄▅▅▄▄▃▃▄▂▁▄▄▄▅▄▄▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄█▃▃▇▁▄▁▄▄▅▁▃▃▄▄▄▄▄▄▄▄▄▄▄▃▃▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65281
wandb: best/eval_avg_mil_loss 0.71444
wandb:  best/eval_ensemble_f1 0.65281
wandb:            eval/avg_f1 0.61921
wandb:      eval/avg_mil_loss 0.7012
wandb:       eval/ensemble_f1 0.61921
wandb:            test/avg_f1 0.67033
wandb:      test/avg_mil_loss 0.64221
wandb:       test/ensemble_f1 0.67033
wandb:           train/avg_f1 0.62474
wandb:      train/ensemble_f1 0.62474
wandb:         train/mil_loss 0.61441
wandb:      train/policy_loss 0.22488
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.22488
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hwvbfbu7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_094829-hwvbfbu7/logs
wandb: Agent Starting Run: 8ywytz3p with config:
wandb: 	actor_learning_rate: 0.0052952671915429345
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0686077280659606
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3620554685304056
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095131-8ywytz3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ywytz3p
wandb: uploading history steps 95-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:      eval/avg_mil_loss ▁▁██████████████████████████▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▇▇██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇█▁▁▁▁▁▂▂▂▁▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂
wandb:      train/ensemble_f1 ███▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/mil_loss ▁▁▁▁██▇▇▇▇▆█▇▇▇▇▆▇▇▆▆▇▆▅▇▆▆▅▆▆▆▇▆▆█▆▆▇▅▆
wandb:      train/policy_loss ███▄▄▁▂▁▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▂▁▁▁▂▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▅▁▁▁▂▁▁▁▂▁▂▂▁▂▂▂▂▂▁▁▁▁▂▁▂▁▂▂▂▂▁▂▁▅▅▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83544
wandb: best/eval_avg_mil_loss 0.48792
wandb:  best/eval_ensemble_f1 0.83544
wandb:            eval/avg_f1 0.62279
wandb:      eval/avg_mil_loss 1.08582
wandb:       eval/ensemble_f1 0.62279
wandb:            test/avg_f1 0.87291
wandb:      test/avg_mil_loss 0.38384
wandb:       test/ensemble_f1 0.87291
wandb:           train/avg_f1 0.64059
wandb:      train/ensemble_f1 0.64059
wandb:         train/mil_loss 1.11594
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ywytz3p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095131-8ywytz3p/logs
wandb: Agent Starting Run: h2jsw5cu with config:
wandb: 	actor_learning_rate: 5.5606723286105185e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04649361674961594
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15951029342097178
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095319-h2jsw5cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2jsw5cu
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▆▅▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▅▅▅▅▅▅▅▇▆█████████████
wandb:      eval/avg_mil_loss ▆█▅▅▄▆▅▅▆▆▅▆▄▇▇▆▆▆▄▄▅▃▄▃▃▃▃▂▁▂▁▂▅▅▅▄▅▅▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▃▅▅▅▅▅▇▇▆▆▆▆▆▆██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▅▃▅▄▃▄▅▃▃▁▆▇▅▅▄▃▃▆▄▅▅▇▆█▄▆▄▆▄▇▄█▄▆▄▆█
wandb:      train/ensemble_f1 ▇█▅▃▇▄▄▆▅▅▅▄▆▇▆▁█▅▄▆█▆▆▃▆▃▇▄▇█▆█▆▄▃▆▄▇▆▇
wandb:         train/mil_loss ▇▃▃▁▂▆▇▅▅▇▃▂█▃█▇▇▆▃▁▄▄▂▆▆▃▇▆▅██▄▄▄▁▃▆▂▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▂▂▁▁▂▂█▂████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.35186
wandb: best/eval_avg_mil_loss 0.87516
wandb:  best/eval_ensemble_f1 0.35186
wandb:            eval/avg_f1 0.35186
wandb:      eval/avg_mil_loss 0.878
wandb:       eval/ensemble_f1 0.35186
wandb:            test/avg_f1 0.32633
wandb:      test/avg_mil_loss 0.87699
wandb:       test/ensemble_f1 0.32633
wandb:           train/avg_f1 0.38058
wandb:      train/ensemble_f1 0.38058
wandb:         train/mil_loss 0.77275
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2jsw5cu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095319-h2jsw5cu/logs
wandb: Agent Starting Run: 7kn678qs with config:
wandb: 	actor_learning_rate: 2.110793400847929e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22771947603550757
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6770859535445086
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_095746-7kn678qs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7kn678qs
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss ██▆▆▆▆▅▅▅▅▄▄▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▃▃▃▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇████████
wandb:      eval/avg_mil_loss ███▆▆▆▆▆▆▆▅▆▅▅▅▅▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▃▂▂▃▃▁▃▃▂▅▄▄▃▆▅▃▅▅▆▆▅▅▆▆▇▆▇▇▇▆▆▇▇▅▆▇█
wandb:      train/ensemble_f1 ▃▁▁▃▃▂▁▃▂▃▃▃▄▅▅▄▅▆▅▅▅▄▆▆▇▇▇█▆▇▇▆▇▇██▆▇▇▇
wandb:         train/mil_loss ▆██▆▇▆▄▄▅▄▄▄▅▄▄▃▃▃▂▂▂▃▃▃▂▁▂▂▃▅▁▂▁▂▂▂▃▂▃▂
wandb:      train/policy_loss ▃▂▂▂▂▄▄▁▄▄▄▁▄▆▄▄▄▄▄▄▄▂▁▂▄▄▄▄▄▄▇▇▆█▇▇▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅█▅▅▅▅▅▅▅▅▅▅▃▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86012
wandb: best/eval_avg_mil_loss 0.46681
wandb:  best/eval_ensemble_f1 0.86012
wandb:            eval/avg_f1 0.86012
wandb:      eval/avg_mil_loss 0.46409
wandb:       eval/ensemble_f1 0.86012
wandb:            test/avg_f1 0.88332
wandb:      test/avg_mil_loss 0.3812
wandb:       test/ensemble_f1 0.88332
wandb:           train/avg_f1 0.85874
wandb:      train/ensemble_f1 0.85874
wandb:         train/mil_loss 0.44361
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7kn678qs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_095746-7kn678qs/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dby4p0o0 with config:
wandb: 	actor_learning_rate: 1.0272979070424834e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5391457647339796
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22661639120632415
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101016-dby4p0o0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dby4p0o0
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁███▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▅▂▄▁▅▃▄▃▃▄▃▄▄▃▄█▃▃▃▄▃▄▃▂▅▇▂▅▄▂▄▂▅▄▅▅▇
wandb:      train/ensemble_f1 ▇▃▂▃▅▅▂▃▆▃▃▄▂▂▆▆█▅▁▄▇▅▄▅▄▆▄▆▅▇▂▆▄▆▅▃█▄▅▇
wandb:         train/mil_loss ▅▃▄▄▅▃▆▃▂▁▃███▄▅▃▃▄▃▅▆▄▅▄▄▄▄▅▇▄▃▅▂▄▄▄▅▄▄
wandb:      train/policy_loss ▆▃▅▃▅▄▆▆▆▅▄▆▄▅▅▂▆▅▄█▃▄▅▇▁▅▄▃▇▄▇▅▆▅▁▄▅▅▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄█▅▄▅▅▆▂▄▆▁▅▄▄▄▄█▆▄▄▅▁▅▅▄▄▃▇▄▇▄▄▄▄▅▆▄▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66106
wandb: best/eval_avg_mil_loss 0.93638
wandb:  best/eval_ensemble_f1 0.66106
wandb:            eval/avg_f1 0.65573
wandb:      eval/avg_mil_loss 0.95654
wandb:       eval/ensemble_f1 0.65573
wandb:            test/avg_f1 0.68389
wandb:      test/avg_mil_loss 0.63989
wandb:       test/ensemble_f1 0.68389
wandb:           train/avg_f1 0.6804
wandb:      train/ensemble_f1 0.6804
wandb:         train/mil_loss 0.74653
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dby4p0o0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101016-dby4p0o0/logs
wandb: Agent Starting Run: 8121keut with config:
wandb: 	actor_learning_rate: 0.004085108719166853
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10208591310038984
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3609144163310286
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101159-8121keut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8121keut
wandb: uploading history steps 174-181, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅▆▆█
wandb: best/eval_avg_mil_loss ██▇▇▆▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆▆▆▆██████████████████████
wandb:      eval/avg_mil_loss ███▇██▇▇▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▅▅▆▆▆▆▆▆▆▆▆█████████████▇██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▁▂▁▄▄▄▆▃▅▃▆▅▅▇▄▅▅▅▃▃▃▄▄▆▄▄▅▄▅▄▄▆▇▆▅█▅▆
wandb:      train/ensemble_f1 ▂▂▁▁▂▂▁▂▃▃▂▅▃▄▆▄▄▅▅▆▅▆▇▄▆▄▄▅▆▅▆▅▄▅▆█▅▅▅▆
wandb:         train/mil_loss ██▇██▅▇▇▆▆▅▃▄▃▄▃▂▃▃▂▃▂▁▃▃▂▃▃▂▄▃▃▂▃▃▂▁▃▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▂▅▅██▅▅▅▅▅▁▁▂▂▂▂▂▁▂▁▃▁▁▁▂▂▁▅▂▁▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁██████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72663
wandb: best/eval_avg_mil_loss 0.67906
wandb:  best/eval_ensemble_f1 0.72663
wandb:            eval/avg_f1 0.72663
wandb:      eval/avg_mil_loss 0.65144
wandb:       eval/ensemble_f1 0.72663
wandb:            test/avg_f1 0.74419
wandb:      test/avg_mil_loss 0.45585
wandb:       test/ensemble_f1 0.74419
wandb:           train/avg_f1 0.73343
wandb:      train/ensemble_f1 0.73343
wandb:         train/mil_loss 0.57121
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8121keut
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101159-8121keut/logs
wandb: Agent Starting Run: ys78jf46 with config:
wandb: 	actor_learning_rate: 2.606374953686395e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28869166189762985
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3262956386327016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101455-ys78jf46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ys78jf46
wandb: uploading history steps 268-272, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆█████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▆▆▆▆▆██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▄▃▃▁▁▃▂▃▃▃▃▃▄▃▂▄▄▅▁▃▄▆▁▄▅▄▄▅▄▇▅▅▅▅▆█▅
wandb:      train/ensemble_f1 ▃▃▅▅▇▄▆▅▃▄▃▄▂▅▅▅▇▆▃▇▄█▁▆▄▅▇▅▆▅▆▅▇▆▅▅█▆█▇
wandb:         train/mil_loss ▂▅▆█▄▆▄▅▆█▃▁▇▃▂▂▅▁▂▇▃▇▆▄▁▂▂▁▂▄▃▄▂▃▃▂▃▄▄▅
wandb:      train/policy_loss █████████████████▁██████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75948
wandb: best/eval_avg_mil_loss 0.9642
wandb:  best/eval_ensemble_f1 0.75948
wandb:            eval/avg_f1 0.75948
wandb:      eval/avg_mil_loss 0.92366
wandb:       eval/ensemble_f1 0.75948
wandb:            test/avg_f1 0.77474
wandb:      test/avg_mil_loss 0.60203
wandb:       test/ensemble_f1 0.77474
wandb:           train/avg_f1 0.76403
wandb:      train/ensemble_f1 0.76403
wandb:         train/mil_loss 0.8041
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ys78jf46
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101455-ys78jf46/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zjb2qxc9 with config:
wandb: 	actor_learning_rate: 0.00015998728846194617
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.285007638112166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8754529066491111
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_101928-zjb2qxc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjb2qxc9
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▆▆▆▆▃▇▇▅▅▅▅▅▇▇███▃▃▃▃▃▃▃▃▃▃▄▄▃▃▂▁▁▇▇▇
wandb:       eval/ensemble_f1 ████▇▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆███▄▂▃▂▃▂▂▃▁▂▁▄▂▄▃▄▂▃▄▂▃▄▃▃▂▄▄▁▁▄▁▃▂▄▄
wandb:      train/ensemble_f1 ▆█▅▆▅▃▃▃▄▁▂▃▄▃▃▂▃▄▃▂▃▁▃▅▁▃▃▄▃▁▃▄▂▂▂▃▃▃▃▆
wandb:         train/mil_loss █▇▇▄▇▅▆▃▃▃▃▅▄▅▆▄▇▅▅▇▅▃▆▇▄▄▅▇▆▅▅▃▆▁▄▅█▂▆▅
wandb:      train/policy_loss ████▁▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁▅██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62921
wandb: best/eval_avg_mil_loss 0.66361
wandb:  best/eval_ensemble_f1 0.62921
wandb:            eval/avg_f1 0.58138
wandb:      eval/avg_mil_loss 0.6643
wandb:       eval/ensemble_f1 0.58138
wandb:            test/avg_f1 0.57203
wandb:      test/avg_mil_loss 0.62486
wandb:       test/ensemble_f1 0.57203
wandb:           train/avg_f1 0.59355
wandb:      train/ensemble_f1 0.59355
wandb:         train/mil_loss 0.64292
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zjb2qxc9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_101928-zjb2qxc9/logs
wandb: Agent Starting Run: te3nxb6i with config:
wandb: 	actor_learning_rate: 9.267419683319968e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04734739440021352
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5713116751333565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102112-te3nxb6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/te3nxb6i
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▆▆▆▆▆▆▆▆▇▆▇█▇██▇▇▇▆▆▂▂▁▁▆▅▇▇▇▇▇▇▇▆▆▇▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▄▄▄█▁▄▄▄▃▄▅▅▁▃▄▃▄▅▅▅▃▆▄▄▄▄▃▅▃▂▃▄▃▄▃▆▅
wandb:      train/ensemble_f1 ▄▅▆█▆▄▁▂▆▂▄▄▇█▁▄▆▇▅▄▇█▇▃▆▃▆▆▂▆█▄▃▆▄▅▅▄█▃
wandb:         train/mil_loss ▄▅▅▄▂▃▃█▆▃▁▄▄▇▇▇▇▄▅▄▄▄▃▁▅▄▇▅▂▅▆▅▄▅▄▅▆▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58138
wandb: best/eval_avg_mil_loss 0.75824
wandb:  best/eval_ensemble_f1 0.58138
wandb:            eval/avg_f1 0.58138
wandb:      eval/avg_mil_loss 0.75806
wandb:       eval/ensemble_f1 0.58138
wandb:            test/avg_f1 0.54449
wandb:      test/avg_mil_loss 0.80398
wandb:       test/ensemble_f1 0.54449
wandb:           train/avg_f1 0.57498
wandb:      train/ensemble_f1 0.57498
wandb:         train/mil_loss 0.83222
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/te3nxb6i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102112-te3nxb6i/logs
wandb: Agent Starting Run: wzjwi68m with config:
wandb: 	actor_learning_rate: 1.456912668055904e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1443033252305009
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6297936065163161
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102256-wzjwi68m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzjwi68m
wandb: uploading history steps 237-251, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss ████▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▃▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇██▇▇▇▇▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃▃▁▇▄▄▅▆▅▆▆▆▄▄▆▄▆▄▇▇▇▆▅▄▆▅▆▇▅▅██▇▇▄▇▆▅
wandb:      train/ensemble_f1 ▁▂▁▂▂▂▁▃▄▆▆▅▆▃▄▅▅▃▅▅▄▇▆▂▆▆▂▆▅██▅▄▇▇▆▇▆▆▅
wandb:         train/mil_loss ▃▄▄▆▃▄▃▄▅█▄▄▄▃▇▂▃▆▁▆▄▅▃▁▃▄▂▁▃▅▅▄▂▁▆▄▂▅▁▂
wandb:      train/policy_loss █████▆███████████▅████▁█████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▅██████████████████▁██████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82306
wandb: best/eval_avg_mil_loss 0.50394
wandb:  best/eval_ensemble_f1 0.82306
wandb:            eval/avg_f1 0.82306
wandb:      eval/avg_mil_loss 0.49725
wandb:       eval/ensemble_f1 0.82306
wandb:            test/avg_f1 0.8766
wandb:      test/avg_mil_loss 0.38601
wandb:       test/ensemble_f1 0.8766
wandb:           train/avg_f1 0.83014
wandb:      train/ensemble_f1 0.83014
wandb:         train/mil_loss 0.50219
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzjwi68m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102256-wzjwi68m/logs
wandb: Agent Starting Run: dpgz2uj2 with config:
wandb: 	actor_learning_rate: 0.008733640060448074
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5960218545608791
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9256524926824986
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_102658-dpgz2uj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpgz2uj2
wandb: uploading history steps 187-199, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▆▇▇██
wandb: best/eval_avg_mil_loss █▆▄▃▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▇▇▇████████████████████████████████
wandb:      eval/avg_mil_loss ███████▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▆▇▇▇▇▇▇▇▇▇██████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▁▂▂▃▆▇▇▅▇▆▅▆▇▆▇██▅█▆▆▆▇▇█▇▇▇█▆▇██▇█▇▇
wandb:      train/ensemble_f1 ▃▁▁▃▃▃▂▅▆▆▅▆▇▇▇▆▇▆▇▆█▇▅▆▆▆▇▆▇█▆▅▇▆█▇▆█▇▆
wandb:         train/mil_loss ▅▅█▇▇▆▄▄▄▃▄▄▅▃▂▂▃▆▄▄▄▅▅▅▅▄▄▅▃▃▄▂▁▁▁▄▂▃▄▂
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃█▁█▄▆█▄█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71695
wandb: best/eval_avg_mil_loss 0.81909
wandb:  best/eval_ensemble_f1 0.71695
wandb:            eval/avg_f1 0.71695
wandb:      eval/avg_mil_loss 0.79726
wandb:       eval/ensemble_f1 0.71695
wandb:            test/avg_f1 0.72833
wandb:      test/avg_mil_loss 0.51869
wandb:       test/ensemble_f1 0.72833
wandb:           train/avg_f1 0.70977
wandb:      train/ensemble_f1 0.70977
wandb:         train/mil_loss 0.5317
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dpgz2uj2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_102658-dpgz2uj2/logs
wandb: Agent Starting Run: lodx5bxu with config:
wandb: 	actor_learning_rate: 0.0002712221080456982
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.44610533989817913
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6281210896344923
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103015-lodx5bxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lodx5bxu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▅▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▄▄▄▅▅▅▅▅▆▆▆▆▆█████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▂▂▂▃▄▄▅▅▅▅▅▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▃▃▂▃▅▆▄▆▂▃▃▃▅▁▂▃▃▄▅▄▃▄▄▁▇▆▆▆▄▆▃▄▄▆▆▇█
wandb:      train/ensemble_f1 ▃▃▃▆▄▁▄▃▄▅▄▄▄▃▄▃▅▇▅▆▃▂▄▇▄▁▄▆▆▆▆▇▆▄▆█▆▅▅▇
wandb:         train/mil_loss ▃▇▆▇▃▅█▇▅▂▆▆▅▆▁▅▆▄▂▆▃▂▆▇▃▄▂▄▆▂▃▆▁▁▃▁▄▃▂▂
wandb:      train/policy_loss ▇▇▇▇█▇▇▁▇▇▇▇▇▂▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75948
wandb: best/eval_avg_mil_loss 0.57402
wandb:  best/eval_ensemble_f1 0.75948
wandb:            eval/avg_f1 0.75948
wandb:      eval/avg_mil_loss 0.55323
wandb:       eval/ensemble_f1 0.75948
wandb:            test/avg_f1 0.76472
wandb:      test/avg_mil_loss 0.43793
wandb:       test/ensemble_f1 0.76472
wandb:           train/avg_f1 0.76697
wandb:      train/ensemble_f1 0.76697
wandb:         train/mil_loss 0.49747
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lodx5bxu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103015-lodx5bxu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9fx4ipz7 with config:
wandb: 	actor_learning_rate: 0.001995903652490386
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9683550088015306
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6468951391839389
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103341-9fx4ipz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9fx4ipz7
wandb: uploading history steps 155-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▇▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆█▄▇▆▅▅▂▄▄▁▃▆▇▄▅▄▆▇▄▅▄▃▂▄▇▄▅▆▂▄▅▅▃▄▃▂▅█
wandb:      train/ensemble_f1 ▂█▄▅▇▆▆█▄▅▂▅▆▇▆▆▄▅▆▇▇▇▄▅▅▅▄▇▅▄▆▄█▂▃▄▅▃▇▁
wandb:         train/mil_loss ▄▅▄▃▅▃▄▇▅▃▅▆▄▃▅▄▆█▆▄▅▁▇▂▃▆▄▃▂▆▂▃█▅▁▄▇▄█▅
wandb:      train/policy_loss ▇▅█████▇████▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▆▇████████▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61712
wandb: best/eval_avg_mil_loss 0.88748
wandb:  best/eval_ensemble_f1 0.61712
wandb:            eval/avg_f1 0.61712
wandb:      eval/avg_mil_loss 0.88657
wandb:       eval/ensemble_f1 0.61712
wandb:            test/avg_f1 0.6781
wandb:      test/avg_mil_loss 0.59803
wandb:       test/ensemble_f1 0.6781
wandb:           train/avg_f1 0.65863
wandb:      train/ensemble_f1 0.65863
wandb:         train/mil_loss 0.46146
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9fx4ipz7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103341-9fx4ipz7/logs
wandb: Agent Starting Run: 92ijpnkm with config:
wandb: 	actor_learning_rate: 3.7811070351832095e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8755769416644863
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.013459336368283892
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103621-92ijpnkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92ijpnkm
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▄▄▄▃▂▇██▇██▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▅▄▄█▄▁▃▃█▆▃▂▅▃▃▅█▅▃▄▃▃▄▄▄▅▄▄▂▃▄▅▅▆▂▅▆
wandb:      train/ensemble_f1 ▃▅▅▃▄▁▅▅▃▇▅▂▆▅█▄█▆▄▅▃▇▆▅▃▄▃▄▆▄▄▁▄▆▆▆▆▃▂▃
wandb:         train/mil_loss ▁▄▃▃▂▄▅▇▃▄▆▇▆█▇▅▄▄▇▅█▅▇▂▄█▆▂▄▃▇▇▅▄▅▇▅▇▅▅
wandb:      train/policy_loss ▃▆▇▃▇▅▇█▇▅▇▅▅▇▃▇▅▇▇▇▅▃█▇▄▃▇▅▆▃▃▃▇▃▃▇▇▅▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▃▅▇▂▃▇▇█▅▅▇▇▇▇▆▅▅▆▃▇▇▆▆▆▅▆▇▆▅▇▇▇▆▆▇▆▆█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 0.94014
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 0.93914
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.02698
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33232
wandb:      train/ensemble_f1 0.33232
wandb:         train/mil_loss 0.64143
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/92ijpnkm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103621-92ijpnkm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v8gxy0lo with config:
wandb: 	actor_learning_rate: 0.005336125282696343
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7756544218983784
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3672899514859683
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_103814-v8gxy0lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3wokqd2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v8gxy0lo
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▂▅▇▅▆▅▃▄▇▃▅█▅▁▆▄▆▃▆▃▄▅▃▃▆▆▆▁▁▁▄▅▄▃▅▃▄▇
wandb:      train/ensemble_f1 ▅▄▂▄▇▆▇▆▄██▅▃▇▁▃▃▇▄▆█▇▃▇▃▇▅▅▂▂▆▇▄▄▅▄▅█▇▆
wandb:         train/mil_loss ▅▃▆▄▃▄▆▇▄▃▃▅▃▄▇▃▅▂▄▇▅▃▆▄▆▃▂▁▄▇▅▃▅▆█▅▅▇█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58138
wandb: best/eval_avg_mil_loss 0.77833
wandb:  best/eval_ensemble_f1 0.58138
wandb:            eval/avg_f1 0.58138
wandb:      eval/avg_mil_loss 0.77457
wandb:       eval/ensemble_f1 0.58138
wandb:            test/avg_f1 0.54449
wandb:      test/avg_mil_loss 0.84068
wandb:       test/ensemble_f1 0.54449
wandb:           train/avg_f1 0.5709
wandb:      train/ensemble_f1 0.5709
wandb:         train/mil_loss 0.5511
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v8gxy0lo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_103814-v8gxy0lo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: uq2c3lrm with config:
wandb: 	actor_learning_rate: 9.579197477345956e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4099349223174902
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05505987090948894
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104029-uq2c3lrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uq2c3lrm
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▃█▆▃▁▅▅▄▄▄▂▅▂▃▆▂▄▅▄█▃▄▄▂▄▅▂▄▅▂▅▅▂▃▅▅▃
wandb:      train/ensemble_f1 ▅▆▃▅▅▇▆▆▁██▆▆▄▆▆▅▇▄█▅▅▆▅█▃▆▇▆▄▆▄▇▃▃▃▄▅▆▅
wandb:         train/mil_loss ▃▇▅▇▁▆▆▅▃▄▃▂▂▄▃▇▄▁▅▅▆▇▆▆▄▅▃▂▂▂▄▄▆▃▂▆▅▄▅█
wandb:      train/policy_loss ▂▃▃▇▆▅▅▃▅▅▅▄▅▂▄▅▃▄▇▂▁▅▄▃▄▆▅▇▄▅▂▄▅█▅▁▃▄▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▂▄█▆▄▅▃▅▄▆▅▆▄▅▄▅▂▅▄▆▃▇▃▅▂▄▇▄▅▄▅▅▅█▅▄▃▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.09315
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.07347
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.21098
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33293
wandb:      train/ensemble_f1 0.33293
wandb:         train/mil_loss 0.95561
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uq2c3lrm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104029-uq2c3lrm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qenw9a97 with config:
wandb: 	actor_learning_rate: 0.004509245643956671
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.798253956345557
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.035794381305024436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104228-qenw9a97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qenw9a97
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▆▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▆▆▆▆▆████████████████████████
wandb:      eval/avg_mil_loss █████████▇▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▁▃▃▄▆▇▆▆▆▇▆▆▇▇▇█▇▆▇▆▇▇▆▇█▇▇██▇▇█▇▇██▇
wandb:      train/ensemble_f1 ▂▂▁▂▂▃▃▂▂▃▄▅▄▆▆▆▆▆▆▆▇▆▆▇▇▇▆▆▇███▇▇▇▇▇█▇█
wandb:         train/mil_loss ▄▄▇█▅▇▅▃▃▃▅▄▅▃▁▂▂▃▆▃▄▃▄▃▁▅▃▃▂▅▆▄▂▄▆▄▂▅▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▇▇▇▄▆▆▄▄█▆▆▆█▅▇▆█▅▄▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47002
wandb: best/eval_avg_mil_loss 1.47992
wandb:  best/eval_ensemble_f1 0.47002
wandb:            eval/avg_f1 0.47002
wandb:      eval/avg_mil_loss 1.41425
wandb:       eval/ensemble_f1 0.47002
wandb:            test/avg_f1 0.47885
wandb:      test/avg_mil_loss 1.06043
wandb:       test/ensemble_f1 0.47885
wandb:           train/avg_f1 0.50326
wandb:      train/ensemble_f1 0.50326
wandb:         train/mil_loss 0.50665
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qenw9a97
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104228-qenw9a97/logs
wandb: Agent Starting Run: 2sbhf7d4 with config:
wandb: 	actor_learning_rate: 0.00018900287104112415
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5272088057595992
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5605621325577566
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_104534-2sbhf7d4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sbhf7d4
wandb: uploading history steps 795-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██
wandb:      eval/avg_mil_loss █▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▃▃▄▄▄▄▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▃▃▄▄▂▃▃▄▃▄▄▄▄▄▄▅▅▅▅▅▆▄▅▆▆▆▆▇▇▇▇▇▇▇█▇█
wandb:      train/ensemble_f1 ▂▁▁▂▃▃▄▃▃▃▃▃▄▅▅▅▄▅▅▄▅▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇███
wandb:         train/mil_loss ▄█▄▂▃▄▂▃▃▅▃▄▄▃▂▄▃▂▁▂▂▂▂▃▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▁
wandb:      train/policy_loss █▁██████████████████████████████▅███████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████▄██▂██████████████████▁████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71994
wandb: best/eval_avg_mil_loss 0.80149
wandb:  best/eval_ensemble_f1 0.71994
wandb:            eval/avg_f1 0.71994
wandb:      eval/avg_mil_loss 0.79301
wandb:       eval/ensemble_f1 0.71994
wandb:            test/avg_f1 0.74938
wandb:      test/avg_mil_loss 0.48767
wandb:       test/ensemble_f1 0.74938
wandb:           train/avg_f1 0.69237
wandb:      train/ensemble_f1 0.69237
wandb:         train/mil_loss 0.63958
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sbhf7d4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_104534-2sbhf7d4/logs
wandb: Agent Starting Run: 5os5j097 with config:
wandb: 	actor_learning_rate: 0.00017663940627642163
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4534684958933942
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.54549289131034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_105844-5os5j097
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5os5j097
wandb: uploading history steps 294-304, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▆▅▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▂▃▅▅▅▅▅▅▆▆▆▇▇▇████████████▆▇▇
wandb:      eval/avg_mil_loss ████▇▆▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▃▃▃▅▅▅▅▅▅▅▅▅▆▆▇████████████▆▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▄▃▃▄▃▁▄▅▅▆▂▆▄▅▄▆▆▇▄▅█▇▅▆▅▅▆▇▇▅▆▇▆▇▇▇▆
wandb:      train/ensemble_f1 ▁▄▂▅▃▄▃▂▂▄▃▃▅▅▅▄▄▅▅▅▅▇▅▆▃█▅▅▇▇▆▇▇▆▆█▅▅▆▆
wandb:         train/mil_loss ▄█▅▃▅▅▄▃▄▄▅▂▄▃▃▄▂▃▃▂▃▆▄█▄▃▃▄▃▇▃▁▂▃▃▁▃▂▄▁
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▆▁▃▂▁▁▅▃▅▁▄█▅▅▆▂▂▂▂▂▄▇▄▅▂▇▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▆▄▂▁▆▅▆▆▄▃▃▃▃▃▃▃▃▃▆▇█▇▄▅▃▅▂▅▆▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81002
wandb: best/eval_avg_mil_loss 0.81178
wandb:  best/eval_ensemble_f1 0.81002
wandb:            eval/avg_f1 0.80689
wandb:      eval/avg_mil_loss 0.78513
wandb:       eval/ensemble_f1 0.80689
wandb:            test/avg_f1 0.81952
wandb:      test/avg_mil_loss 0.49079
wandb:       test/ensemble_f1 0.81952
wandb:           train/avg_f1 0.81349
wandb:      train/ensemble_f1 0.81349
wandb:         train/mil_loss 0.58616
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5os5j097
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_105844-5os5j097/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1hlix8hv with config:
wandb: 	actor_learning_rate: 4.8763605633472965e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4906288311946938
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8665695865446877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110352-1hlix8hv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1hlix8hv
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▃▄▅▅▅▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇████████████▇▇█▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▆▄▅▃▅▂▄▅▄▄▁█▅▃▅▄▅▄▆▄▃█▃▂▆▃▇▆▄▅▆▄▅▅▃▄▄
wandb:      train/ensemble_f1 ▃▅▆▄▅▃▄▂▄▆▆▄▄▇▁█▅▅▄▇▅▄▃▃▆▁▅▄▃▃▄▅▅▆▅▇▃▆▄▆
wandb:         train/mil_loss █▇▄▆▃▃▅▆▄▄▃▆▅▄▃▂▃▆▅▅▂▆▄▃▃█▃▁▄▄▅▇▂▅▇▇▆▄▃▇
wandb:      train/policy_loss ▆▁▆▃▅▄▄▇▃▄▃▆▅▆▆▅▆▄█▃█▃▆▅▃▃▃▃▇▅▄▆▇▆█▃▃▁▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▄▃▄▇▃▅▆▇▆▅▆▄▆▇▄▃█▃▆▃▃▇▄▅▃▃▅▃▄▇▇▃▇▅▄▃▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.38594
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.4801
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.59139
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33717
wandb:      train/ensemble_f1 0.33717
wandb:         train/mil_loss 0.86384
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1hlix8hv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110352-1hlix8hv/logs
wandb: Agent Starting Run: g1zamset with config:
wandb: 	actor_learning_rate: 0.00015549253394657803
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5268511494630227
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4405552807510989
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_110538-g1zamset
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1zamset
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██████▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▂▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb:      eval/avg_mil_loss █▇▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▃▃▃▅▅▅▅▅▆▆▅▆▆▆▆▇▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█
wandb:      train/ensemble_f1 ▁▁▄▃▃▅▄▅▆▅▆▅▆▆▆▆▆▆▆▆▇▇▆▆▆▇██▇▇▇█████████
wandb:         train/mil_loss ▇█▆▆█▄▃▇▅▆▇▅▇▅▃▃▄▆▄▄▂▃▆▂▂▁▂▃▃▄▂▁▃▃▁▂▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄█▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80554
wandb: best/eval_avg_mil_loss 0.69211
wandb:  best/eval_ensemble_f1 0.80554
wandb:            eval/avg_f1 0.79776
wandb:      eval/avg_mil_loss 0.69551
wandb:       eval/ensemble_f1 0.79776
wandb:            test/avg_f1 0.82263
wandb:      test/avg_mil_loss 0.39191
wandb:       test/ensemble_f1 0.82263
wandb:           train/avg_f1 0.79205
wandb:      train/ensemble_f1 0.79205
wandb:         train/mil_loss 0.67888
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g1zamset
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_110538-g1zamset/logs
wandb: Agent Starting Run: btdm8w89 with config:
wandb: 	actor_learning_rate: 0.0005455179252347797
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.43363759009298386
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47072001067319624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_111731-btdm8w89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btdm8w89
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▄▄▄▅▅▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▄▂▁▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▄▄▄▅▅▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▃▄▄▄▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇██████▇
wandb:      eval/avg_mil_loss █▅▅▅▅▅▅▃▃▂▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▂▂▃▅▅▇▆▆▆▇▇▆▆▇▇▇▇▇▇█▇▇▇▇▇▇███████▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▃▃▃▄▄▄▄▅▄▄▅▅▄▆▆▆▆▇▇▆▇▇▇█▆▇▇█▇█▇███▇█
wandb:      train/ensemble_f1 ▁▂▂▃▂▃▃▃▃▄▄▄▄▅▄▅▄▅▅▅▆▆▆▆▆▇▇▆▇▆▆▇▇▇██▇▇▇▇
wandb:         train/mil_loss █▃▃▄▅▂▅▄▄▂▁▂▂▅▃▃▄▃▄▅▃▂▄▄▃▃▄▃▄▄▃▄▄▃▂▄▄▃▂▃
wandb:      train/policy_loss ▆█▇▇▆▆▆▆▆▃▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▂▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60564
wandb: best/eval_avg_mil_loss 0.93074
wandb:  best/eval_ensemble_f1 0.60564
wandb:            eval/avg_f1 0.59394
wandb:      eval/avg_mil_loss 0.89716
wandb:       eval/ensemble_f1 0.59394
wandb:            test/avg_f1 0.59706
wandb:      test/avg_mil_loss 0.61453
wandb:       test/ensemble_f1 0.59706
wandb:           train/avg_f1 0.58151
wandb:      train/ensemble_f1 0.58151
wandb:         train/mil_loss 0.73115
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btdm8w89
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_111731-btdm8w89/logs
wandb: Agent Starting Run: f6kxq213 with config:
wandb: 	actor_learning_rate: 5.305282903183935e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6456787117359172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.36407933896223155
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112439-f6kxq213
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f6kxq213
wandb: uploading history steps 109-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▆█▆▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅
wandb:      eval/avg_mil_loss ▁▁▂▂▂▇███████▇██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▆▆▆▅▅▅▅▅▅▆
wandb:       eval/ensemble_f1 █████▃▃▃▃▃▃▃▃▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▅▅▇█▅▅▅▇▆▆▄▂▄▄▄▆▅▁▅▃▅▅▄▆▅▄▄▂▆▅▄▅▃▇▇▃▄▆
wandb:      train/ensemble_f1 ▇▅▅▄█▄▆▃▅▅▃▇▅▇▁▅▄▄▂▆▅▅▅▃▄▅▆▄▆▄▃▆▅▃▃▇▅▇▄▇
wandb:         train/mil_loss ▆▅▂▄▇▇▆▆▁▂▄▆█▂▆▆▅▇▂▁▃▆▄▅▅▆▄▃▅▁▄▃▂▃▇▄▆▃▅▃
wandb:      train/policy_loss ▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▃▄▅▅▃▅▇█▄▄▇▁▄▆▄▄▃▄▅▅▇▃▃▆█▄▇▆▃▇▅▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55028
wandb: best/eval_avg_mil_loss 0.63595
wandb:  best/eval_ensemble_f1 0.55028
wandb:            eval/avg_f1 0.53825
wandb:      eval/avg_mil_loss 0.64126
wandb:       eval/ensemble_f1 0.53825
wandb:            test/avg_f1 0.54785
wandb:      test/avg_mil_loss 0.64484
wandb:       test/ensemble_f1 0.54785
wandb:           train/avg_f1 0.58005
wandb:      train/ensemble_f1 0.58005
wandb:         train/mil_loss 0.51556
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f6kxq213
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112439-f6kxq213/logs
wandb: Agent Starting Run: 9p27eaae with config:
wandb: 	actor_learning_rate: 2.7226290855518943e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8286733790451787
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32871754617620774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112632-9p27eaae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9p27eaae
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▇▅▇▅▆▄▄▅▁▅▂▆▆▇▅▃▇▃▄▆█▄▂▄▁▃▂▅▆█▅▆▆▄▆▂▇▇
wandb:      train/ensemble_f1 ▁▆▄▇▆▆▅▆▆▆▄▅▆▆▇▆▄▄▂▇▅▃▆▁▃▃▄▂▆█▅█▆▆▆▆▄▇█▇
wandb:         train/mil_loss ▅▅▃▆▆▆▂▄▅▆▄█▇▄▃▅▂▅▆▆▆▇▁▆▅▃▄▅▄▆▅▁▅▆▃▂▄▄▆▂
wandb:      train/policy_loss ▃▃▅▇██▄▄▃▄▇▁▄▆▅▁▃▅▅▅▅▄▅▄▅▄▄▁▇▄▂▅▃▇▁█▄▅▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▅▅▃█▃▃▄▃█▄▇▄█▄▆▇▇▃▅▅▃▄▅▁▅▃▇▆▄▆▁▅▃▄▁▅▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.07601
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.06591
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.17793
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33937
wandb:      train/ensemble_f1 0.33937
wandb:         train/mil_loss 0.59426
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9p27eaae
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112632-9p27eaae/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0q3lb3uo with config:
wandb: 	actor_learning_rate: 4.575698961870824e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4852361763645928
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42204377135202975
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_112827-0q3lb3uo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0q3lb3uo
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇▆▅▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▃▂▂▂▂▁▁▁▁▂
wandb:      eval/avg_mil_loss ▁▁▂▃▄▄▄▅▅▅▅▅▆▆▆▅▆▆▆▅▅▆▆▆▆▇▇▇▇▇▇▇▇██████▇
wandb:       eval/ensemble_f1 █▇▆▆▄▄▄▄▄▃▃▃▃▃▃▂▂▃▃▃▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▄▄▃▃▃▃▂▂▁▁▂▂▂▁▂▂▂▁▁▁▁▂▁▂▂▁▂▁▂▂▁▁▂▁▁▂▂▂
wandb:      train/ensemble_f1 █▅▄▄▄▃▃▃▃▃▂▃▂▁▁▂▂▂▂▁▁▃▁▂▂▂▂▁▂▂▂▃▂▁▂▁▂▂▁▂
wandb:         train/mil_loss ▁▅▃▅▄▅▆▅▅▆▃▇▄▅▆▇▃▃▅▅▆▅▄█▇▄▇▇▅▆▃▆▅▆▇▅▄▇▇▆
wandb:      train/policy_loss ▁▅▅▅▅▅▅▅▄▂▅▆▄█▁▄▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▁▄▃▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▅▅▅▅▅▅▅▃▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▂▄▄█▅▅▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59308
wandb: best/eval_avg_mil_loss 0.75843
wandb:  best/eval_ensemble_f1 0.59308
wandb:            eval/avg_f1 0.40685
wandb:      eval/avg_mil_loss 1.04547
wandb:       eval/ensemble_f1 0.40685
wandb:            test/avg_f1 0.4951
wandb:      test/avg_mil_loss 0.9598
wandb:       test/ensemble_f1 0.4951
wandb:           train/avg_f1 0.40752
wandb:      train/ensemble_f1 0.40752
wandb:         train/mil_loss 0.67613
wandb:      train/policy_loss 0.01608
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.01608
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0q3lb3uo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_112827-0q3lb3uo/logs
wandb: Agent Starting Run: 8a6dnxl9 with config:
wandb: 	actor_learning_rate: 0.00010142149052399244
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6585629179123115
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3086182214100597
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113009-8a6dnxl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8a6dnxl9
wandb: uploading history steps 280-287, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▇▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▄▄▅▅▅▅▅▇▇▇▇██▇▇▇▇▇▇▇▇▇▇███
wandb:      eval/avg_mil_loss █████▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▄▅▅▄▅▇▇▇▇▇████▇█▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▁▃▂▂▄▂▂▁▂▅▄▃▄▃▃▅▆▄▆▆▇▄█▆▆▆▇▃▃▇▇█▆▇▆▇▇▆
wandb:      train/ensemble_f1 ▂▂▂▁▂▁▂▃▄▃▃▅▅▄▆▅▄▅▆▆▇▆▇▇▅▆▇▅▅▆▆█▇█▅▇▄▆▇▇
wandb:         train/mil_loss ▆▄▇▃▄▅█▂▅▆▆▆▂▂▇▂▂▃▅▅▂▄▅▄▃▆▂▁▃▃▂█▅▆▃▂▃▄▃▅
wandb:      train/policy_loss ███████████████▁████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.51193
wandb: best/eval_avg_mil_loss 1.5516
wandb:  best/eval_ensemble_f1 0.51193
wandb:            eval/avg_f1 0.51193
wandb:      eval/avg_mil_loss 1.47642
wandb:       eval/ensemble_f1 0.51193
wandb:            test/avg_f1 0.53353
wandb:      test/avg_mil_loss 1.13282
wandb:       test/ensemble_f1 0.53353
wandb:           train/avg_f1 0.55046
wandb:      train/ensemble_f1 0.55046
wandb:         train/mil_loss 0.99417
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8a6dnxl9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113009-8a6dnxl9/logs
wandb: Agent Starting Run: 5a7esvyj with config:
wandb: 	actor_learning_rate: 4.244030688689608e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9407039660429148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03465984289548618
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113454-5a7esvyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5a7esvyj
wandb: uploading history steps 124-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▅▅▅█████████████████████████████████
wandb:      eval/avg_mil_loss █▇▇▇▆▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▅▅█████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▂▂▆▅▁▂▂▁▄▅▄▇▇▂█▂▆▃▃▇▃▅▄▁▄▄▅▄▅▃▆▃▄▆▅█▆▅
wandb:      train/ensemble_f1 ▂▃▂▃▄▂▂▄▃▄▅▄▆▅▃▆▅▆▅▅▄▄▄▆▆▄▄▃▆▄▃▃▃▄▅▆▁▅█▅
wandb:         train/mil_loss ▅▄█▃▇▄▁▄▇▅▁▂▅▅▂▄▁▂▄▂▇▂▄▂▃▁▂▅▆▂▅▃▃▇▂▄▂▂▃▂
wandb:      train/policy_loss ████▁███▆███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████▁██▆████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.43275
wandb: best/eval_avg_mil_loss 1.64714
wandb:  best/eval_ensemble_f1 0.43275
wandb:            eval/avg_f1 0.43275
wandb:      eval/avg_mil_loss 1.61743
wandb:       eval/ensemble_f1 0.43275
wandb:            test/avg_f1 0.42759
wandb:      test/avg_mil_loss 1.32242
wandb:       test/ensemble_f1 0.42759
wandb:           train/avg_f1 0.42753
wandb:      train/ensemble_f1 0.42753
wandb:         train/mil_loss 0.48934
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5a7esvyj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113454-5a7esvyj/logs
wandb: Agent Starting Run: xv83yva4 with config:
wandb: 	actor_learning_rate: 0.0024986305299496544
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.007750195501763257
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34611548670267334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_113703-xv83yva4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv83yva4
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▃▃▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▃▃▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇█▇▇▇█
wandb:      train/ensemble_f1 ▂▁▂▁▂▂▃▃▃▂▄▄▄▄▄▅▆▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:         train/mil_loss ▇█▇▇█▆▆▆▆▅▆▆▆▆▅▅▅▄▄▃▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:      train/policy_loss ▃▃▅▅▅▅▅▅▅█▅▁▁▁▅▅▅▁▅▅▅▅▅▅▁▁██▅▅▁▁███▅▁▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7409
wandb: best/eval_avg_mil_loss 0.70204
wandb:  best/eval_ensemble_f1 0.7409
wandb:            eval/avg_f1 0.7409
wandb:      eval/avg_mil_loss 0.69082
wandb:       eval/ensemble_f1 0.7409
wandb:            test/avg_f1 0.77969
wandb:      test/avg_mil_loss 0.47433
wandb:       test/ensemble_f1 0.77969
wandb:           train/avg_f1 0.74252
wandb:      train/ensemble_f1 0.74252
wandb:         train/mil_loss 0.70425
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xv83yva4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_113703-xv83yva4/logs
wandb: Agent Starting Run: elhcvrss with config:
wandb: 	actor_learning_rate: 1.3081135557765151e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.146744540387584
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5287011014094022
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_114947-elhcvrss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/elhcvrss
wandb: uploading history steps 455-470, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▅▄▄▄▃▃▃▃▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▆▅▆▆▆▇▆▇▇████▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▃▂▂▃▃▄▅▄▄▅▄▆▆▅▆▅▆▅▇▇▆▆█▇▆▇██▆▇▇▇▇▇▇█
wandb:      train/ensemble_f1 ▂▁▂▂▁▂▂▁▂▃▄▃▃▄▄▅▄▅▄▄▅▅▄▆▅▇▇▆▆▇▇▇▆██▇▇███
wandb:         train/mil_loss ▆▅▇█▆▅▆▅▄▆▃▄▅▄▃▅▄▃▁▃▃▃▄▄▃▁▃▄▄▂▃▃▂▃▃▂▃▂▃▂
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▄▄▄▆▇█▇▇█▇█▇▇▄▄▄▁▁▄▁▇▄▄▂▁▄▄▄▄▄▄▄▄▄▄▄▇▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64723
wandb: best/eval_avg_mil_loss 1.04348
wandb:  best/eval_ensemble_f1 0.64723
wandb:            eval/avg_f1 0.60842
wandb:      eval/avg_mil_loss 0.9798
wandb:       eval/ensemble_f1 0.60842
wandb:            test/avg_f1 0.67225
wandb:      test/avg_mil_loss 0.69075
wandb:       test/ensemble_f1 0.67225
wandb:           train/avg_f1 0.62768
wandb:      train/ensemble_f1 0.62768
wandb:         train/mil_loss 0.93845
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/elhcvrss
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_114947-elhcvrss/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c806v1sy with config:
wandb: 	actor_learning_rate: 0.007961335272108763
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6607106229344888
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04004581781006389
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115731-c806v1sy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c806v1sy
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▆▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▆▇██████████████████████████████████▇
wandb:       eval/ensemble_f1 ████▄▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▃▃▂▁▁▁▂▁▂▁▁▁▁▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂
wandb:      train/ensemble_f1 ████▅▃▃▁▂▂▁▂▁▁▂▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂
wandb:         train/mil_loss ▁▁▁▄▅▅▅▄▅▇▄▆▄▄▃█▆▄▆▃▃▄▃▄▄▆▃▄▄▆▂▅▄▅▄▅▆█▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▄▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▁▇█▇▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65818
wandb: best/eval_avg_mil_loss 0.60957
wandb:  best/eval_ensemble_f1 0.65818
wandb:            eval/avg_f1 0.47721
wandb:      eval/avg_mil_loss 1.75734
wandb:       eval/ensemble_f1 0.47721
wandb:            test/avg_f1 0.70789
wandb:      test/avg_mil_loss 0.62071
wandb:       test/ensemble_f1 0.70789
wandb:           train/avg_f1 0.45755
wandb:      train/ensemble_f1 0.45755
wandb:         train/mil_loss 0.70826
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c806v1sy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115731-c806v1sy/logs
wandb: Agent Starting Run: 7mzow66u with config:
wandb: 	actor_learning_rate: 0.00022776211413451416
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19620616025369195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8034759721421159
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_115914-7mzow66u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7mzow66u
wandb: uploading history steps 796-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▃▃▃▃▄▄▄▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇██████████
wandb:      train/ensemble_f1 ▁▁▁▂▁▁▂▃▃▂▃▃▃▄▄▅▅▅▆▅▇▇▇▇▇▇▇▇▇▇██▇███████
wandb:         train/mil_loss █▅▆▅█▇▆▆▆▆▆▇▆▅▅▅▅▄▄▆▄▄▅▄▃▃▂▃▂▂▂▂▃▂▁▃▁▁▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████▁██████▆██████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82725
wandb: best/eval_avg_mil_loss 0.56003
wandb:  best/eval_ensemble_f1 0.82725
wandb:            eval/avg_f1 0.81621
wandb:      eval/avg_mil_loss 0.56887
wandb:       eval/ensemble_f1 0.81621
wandb:            test/avg_f1 0.8625
wandb:      test/avg_mil_loss 0.32817
wandb:       test/ensemble_f1 0.8625
wandb:           train/avg_f1 0.82774
wandb:      train/ensemble_f1 0.82774
wandb:         train/mil_loss 0.671
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7mzow66u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_115914-7mzow66u/logs
wandb: Agent Starting Run: vch80mip with config:
wandb: 	actor_learning_rate: 5.717363116980899e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.408384980589072
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17001904001020085
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121208-vch80mip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vch80mip
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▃▆▇▂▅▇▄▆▅▄▃▄▃▁▃▂▃▄▇▆▆▄▅█▅▅▄▃█▆▃▆▃▄▅▅▅
wandb:      train/ensemble_f1 ▇▆▆▄▁▅▃▆█▁▃▁▇▅▅▂▃▃▄▂▁▇▆▅▇▃▁▃▆▅▅▆▂▃▄▅▂▃▅▄
wandb:         train/mil_loss ▅▄▅█▃▂▅▇▆▅▆▄▇▃▄▃▁▂▃▆▆▆▃▃▆▂▄▂▃▅▇▅▃▄▃▃▆▃▄▄
wandb:      train/policy_loss ▃▂▁▁▇▃▆▅▃▄▅▃▃▇▄▃▃▃▅▄█▃▂▄▄▆▅▆▂▅▆▆▄▄▄▃▃▃▆▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▃▁▄▅▄▄▃█▃▆█▅▄▆▄▄▆▇▃▄▇▂▅▅▇▁▅▄▅▃▄▆▃▄▆▃▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.07977
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.06265
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.20325
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33394
wandb:      train/ensemble_f1 0.33394
wandb:         train/mil_loss 0.76165
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wandering-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vch80mip
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121208-vch80mip/logs
wandb: Agent Starting Run: q77pq6zp with config:
wandb: 	actor_learning_rate: 3.3057311346536984e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.303467976527373
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6112277842746207
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_121353-q77pq6zp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q77pq6zp
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▃▂▃▂▃▄▄▄▄▄▄▅▅▅▆▆▅▅▅▆▆▇▆▇▇▆▇▇▇▆▇▇█▇█
wandb:      train/ensemble_f1 ▂▁▁▁▁▁▁▂▂▃▃▃▃▃▄▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇█▇██▇▇██
wandb:         train/mil_loss ▇▇▇▄▅█▃▇▆▆▅▆▇▇▆▇▄▅▅▅▃▅▂▂▄▄▄▃▂▃▂▃▂▂▂▁▁▂▃▂
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████▁████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67678
wandb: best/eval_avg_mil_loss 0.60381
wandb:  best/eval_ensemble_f1 0.67678
wandb:            eval/avg_f1 0.67678
wandb:      eval/avg_mil_loss 0.60112
wandb:       eval/ensemble_f1 0.67678
wandb:            test/avg_f1 0.70095
wandb:      test/avg_mil_loss 0.49666
wandb:       test/ensemble_f1 0.70095
wandb:           train/avg_f1 0.70853
wandb:      train/ensemble_f1 0.70853
wandb:         train/mil_loss 0.57823
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q77pq6zp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_121353-q77pq6zp/logs
wandb: Agent Starting Run: 4qmsm45p with config:
wandb: 	actor_learning_rate: 0.0011756037072804893
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.37594468373932666
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9036431084691212
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122651-4qmsm45p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4qmsm45p
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▃▆▆▄▂▅▃▄▅▅▄▇▅▂▅▅▄▅▄▄▄▃▆▅▅▂▆▄▅▄▅▅▂▁█▇
wandb:      train/ensemble_f1 ▆▇▆▅▂▇▁▆▄▅▆▇▅▅▇▆▇▆▃▇▇▄▅▄▄██▇▇▂▄▃█▆▇▅▃▄▅▃
wandb:         train/mil_loss ▇▃█▂▇█▇▆▆▇▇▇▇▄▄▅▄▆▆▄▄▅▁▅▆█▆▇▄▇█▅▆▆▅▅█▅▄▆
wandb:      train/policy_loss ▇▂▄▄█▄▅▁▆▇█▂▄▆▆▅▄▅▃▄▁█▄▅▇▂▆▁▆▄▆▅▅▅▄▅▆▄▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▆▁▅▁█▇▂▃▆▆▄▄▆▅▃▆▄▆▄▂▆▄▄▆▂▅▅▂▅▅▄▅▄▆▄▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.77842
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.76741
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 2.01489
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.34175
wandb:      train/ensemble_f1 0.34175
wandb:         train/mil_loss 1.12993
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4qmsm45p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122651-4qmsm45p/logs
wandb: Agent Starting Run: p1b7a2o8 with config:
wandb: 	actor_learning_rate: 1.0523673986116957e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7654198895009088
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33387588565812565
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_122834-p1b7a2o8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p1b7a2o8
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss ██▇▇▆▆▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇███████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▁▂▂▁▁▃▃▃▅▃▃▄▃▄▄▄▆▅▅▆▅▆▆▅▆▆▆▆▅▅█▅▅▇▆█▆▆
wandb:      train/ensemble_f1 ▂▂▁▃▃▃▂▄▁▄▃▃▃▂▄▅▄▅▄▅▅▅▆▄▅▅▆▅▇▅▇█▇▇▅█▆▆▇█
wandb:         train/mil_loss ▃▅▅▅▅▆▃▂▅▃▁▃▄▅▄▁▂▅▃█▂▄▃▄▄▂▂▃▃▁▄▁▂▅▄▂▅▃▄▄
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50515
wandb: best/eval_avg_mil_loss 1.24481
wandb:  best/eval_ensemble_f1 0.50515
wandb:            eval/avg_f1 0.50515
wandb:      eval/avg_mil_loss 1.18475
wandb:       eval/ensemble_f1 0.50515
wandb:            test/avg_f1 0.495
wandb:      test/avg_mil_loss 1.00578
wandb:       test/ensemble_f1 0.495
wandb:           train/avg_f1 0.51399
wandb:      train/ensemble_f1 0.51399
wandb:         train/mil_loss 0.70135
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p1b7a2o8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_122834-p1b7a2o8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c7u60nnd with config:
wandb: 	actor_learning_rate: 0.0028917805800380155
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5133592728326447
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22987492858426917
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_123354-c7u60nnd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7u60nnd
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▆▆▆▄▃▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆████████
wandb:      eval/avg_mil_loss ██████▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▁▂▄▃▂▂▂▃▄▃▄▂▄▅▃▅▄▂▄▅▄▅▆▆▅▅▇▇▇▇▇▆▇▆█▆▇
wandb:      train/ensemble_f1 ▁▂▂▂▂▃▂▃▃▄▄▄▃▅▃▅▅▆▅▅▅▅▄▄▅▅▆▇▆▆▆▅▆▆▆█▆█▆▇
wandb:         train/mil_loss ▆▇▄▅▄▆▁▅▅▇▇▇█▅▄▃▄▆▄▂▄▆▇▅▇▅▃▆▆▃▂▅▄▄▄▄▅▄▄█
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.48431
wandb: best/eval_avg_mil_loss 1.2454
wandb:  best/eval_ensemble_f1 0.48431
wandb:            eval/avg_f1 0.48431
wandb:      eval/avg_mil_loss 1.16635
wandb:       eval/ensemble_f1 0.48431
wandb:            test/avg_f1 0.48698
wandb:      test/avg_mil_loss 1.01351
wandb:       test/ensemble_f1 0.48698
wandb:           train/avg_f1 0.50703
wandb:      train/ensemble_f1 0.50703
wandb:         train/mil_loss 0.84113
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7u60nnd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_123354-c7u60nnd/logs
wandb: Agent Starting Run: glzgrsm2 with config:
wandb: 	actor_learning_rate: 0.0003784397907736922
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.021530293994188043
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09152776957221076
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_124042-glzgrsm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/glzgrsm2
wandb: uploading history steps 789-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ████▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇███
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▃▄▄▅▅▅▅▅▆▆▆▇▇▇▆▆▇▇▇██
wandb:      train/ensemble_f1 ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▃▄▄▄▄▄▄▄▄▅▄▅▅▅▅▇▇▇▇▇██▇██
wandb:         train/mil_loss █▇▇▆▇▆▆▅▅▅▅▄▅▄▄▄▃▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:      train/policy_loss ████████████████████████████████████▄█▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71206
wandb: best/eval_avg_mil_loss 0.78047
wandb:  best/eval_ensemble_f1 0.71206
wandb:            eval/avg_f1 0.71206
wandb:      eval/avg_mil_loss 0.78047
wandb:       eval/ensemble_f1 0.71206
wandb:            test/avg_f1 0.75965
wandb:      test/avg_mil_loss 0.50729
wandb:       test/ensemble_f1 0.75965
wandb:           train/avg_f1 0.75261
wandb:      train/ensemble_f1 0.75261
wandb:         train/mil_loss 0.80348
wandb:      train/policy_loss -0.01451
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.01451
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/glzgrsm2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_124042-glzgrsm2/logs
wandb: Agent Starting Run: msfg29ky with config:
wandb: 	actor_learning_rate: 0.00012465540746710736
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06289960249491522
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26999760489141755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_125330-msfg29ky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/msfg29ky
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss █▆▆▅▅▅▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▂▁▁▁▂▃▃▅▅▆▆▆▆▇▇▇▇▇▇███████▇▇▇▇▇▇▇▇▇▆▆▅
wandb:      eval/avg_mil_loss █▆▆▆▅▄▄▄▃▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▂▃▃▃▃▄▄▄▄▄▅▅▆▆
wandb:       eval/ensemble_f1 ▂▂▁▁▁▂▃▃▄▆▆▆▆▇▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▃▃▃▄▅▄▅▅▅▅▅▅▇▆▇▇▇█▇▇▇█▇▆▇▇▆▆▇▆▇▆▆▆▅▅▄
wandb:      train/ensemble_f1 ▁▁▃▂▃▃▄▃▅▅▅▆▆▆▆▇▇▇▇██▇▇██▇█▇▆▆▆▆▆▇▆▆▆▆▅▅
wandb:         train/mil_loss ▆▄▅▄▅▁▃▃▃▂▃▁▃▂▂▃▂▂▃▂▂▃▃▃▄▃▄▂▄▃▅▄▄▃▆▅▅▆▆█
wandb:      train/policy_loss ▄▄▄▃▅▆▁▄▃▅▄▄▄▃▄▄▄▄▃▅▅▄▄▄▃▄▄▄▅▄▄▅▄▄▂▃▄▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▃▃▄▃▁▂▃▂▁▂▅▃▅▃▃▃▃▄▃█▄▃▄▃▃▂▃▃▃▃▄▁▅▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60555
wandb: best/eval_avg_mil_loss 0.76776
wandb:  best/eval_ensemble_f1 0.60555
wandb:            eval/avg_f1 0.5374
wandb:      eval/avg_mil_loss 0.89921
wandb:       eval/ensemble_f1 0.5374
wandb:            test/avg_f1 0.57731
wandb:      test/avg_mil_loss 0.88202
wandb:       test/ensemble_f1 0.57731
wandb:           train/avg_f1 0.48298
wandb:      train/ensemble_f1 0.48298
wandb:         train/mil_loss 1.03879
wandb:      train/policy_loss -0.02385
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.02385
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/msfg29ky
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_125330-msfg29ky/logs
wandb: Agent Starting Run: w09jqhp5 with config:
wandb: 	actor_learning_rate: 3.819929393183598e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7538244861100739
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.090799439944085
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_125738-w09jqhp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w09jqhp5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▇▇▇▇▇▇▇▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█████
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▂▄▃▄▄▃▄▄▄▅▅▅▆▅▅▆▅▆▇▆▇▆▆▆▆▆▆▇▇▆▇▇▇█▇
wandb:      train/ensemble_f1 ▂▁▁▁▁▃▂▂▃▂▃▃▄▄▄▄▄▆▅▄▅▄▄▄▅▆▅▆▇▆▅▆▆▆▆▆▇▆██
wandb:         train/mil_loss ▅▆█▃▅▄▂▅▄▇▃▆▄▅▂▄▃▄▃▂▅▇▅▄▆▁▅▅▄▃▅▆▅▃▅▃▂▄▄▃
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64494
wandb: best/eval_avg_mil_loss 0.77429
wandb:  best/eval_ensemble_f1 0.64494
wandb:            eval/avg_f1 0.63947
wandb:      eval/avg_mil_loss 0.77107
wandb:       eval/ensemble_f1 0.63947
wandb:            test/avg_f1 0.62957
wandb:      test/avg_mil_loss 0.61575
wandb:       test/ensemble_f1 0.62957
wandb:           train/avg_f1 0.63723
wandb:      train/ensemble_f1 0.63723
wandb:         train/mil_loss 0.59764
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w09jqhp5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_125738-w09jqhp5/logs
wandb: Agent Starting Run: eece6cc6 with config:
wandb: 	actor_learning_rate: 0.00037852959522627794
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1248310317998873
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.032842702555151426
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_131052-eece6cc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eece6cc6
wandb: uploading history steps 794-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█
wandb: best/eval_avg_mil_loss ███▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▅▆▆▇▇▇▇▇███
wandb:      train/ensemble_f1 ▁▂▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇█
wandb:         train/mil_loss ▆▆▇█▇▆▆▅▆▇▅▄▆▄▃▄▆▅▄▄▃▄▄▃▄▃▃▃▃▃▂▃▂▂▁▁▂▂▂▁
wandb:      train/policy_loss ▅▅▅▂▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74559
wandb: best/eval_avg_mil_loss 0.74066
wandb:  best/eval_ensemble_f1 0.74559
wandb:            eval/avg_f1 0.74559
wandb:      eval/avg_mil_loss 0.71305
wandb:       eval/ensemble_f1 0.74559
wandb:            test/avg_f1 0.7846
wandb:      test/avg_mil_loss 0.50043
wandb:       test/ensemble_f1 0.7846
wandb:           train/avg_f1 0.73918
wandb:      train/ensemble_f1 0.73918
wandb:         train/mil_loss 0.69459
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eece6cc6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_131052-eece6cc6/logs
wandb: Agent Starting Run: xp7r6jl0 with config:
wandb: 	actor_learning_rate: 0.00012189529133004362
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2563761734467148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.307733322304963
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132351-xp7r6jl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xp7r6jl0
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▆▆▄▅▅▅▅▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▄▂▂▁▁▁▁▁▁▁▁▁▂▂
wandb:      eval/avg_mil_loss ▆▆▆▆▅▅▅▅█▅▃▂▂▁▁▂▂▁▂▂▂▂▃▃▃▃▄▄▃▃▄▄▄▄▄▄▅▆▅▆
wandb:       eval/ensemble_f1 ████▆▄▅▅▅▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▄▂▁▁▁▁▁▁▁▁▁▂▂▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▅▁▄▂▇▅▇▆██▄▃▇▃▄▇▃▆█▆▄▅▂▇▅▄▂▂▄▃▇▆▇▅▄▅▄
wandb:      train/ensemble_f1 ▁▆▄▅▃▂▃▆▆▃▇▄▃▇▃▄▆▇▃▃▅▆▃▄▄█▃▅▃▄▅▅▃▅▄▇▂▄▅▃
wandb:         train/mil_loss ▆▅█▇▅▄▄▆▄▅▅▄▅█▆▅▆▅▅▄▄▆▅▇█▆▃▆▇▆▃▆▄▁▄▇▅▆▃▄
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▁▁▃▂▄▂▅▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54056
wandb: best/eval_avg_mil_loss 0.77651
wandb:  best/eval_ensemble_f1 0.54056
wandb:            eval/avg_f1 0.52138
wandb:      eval/avg_mil_loss 0.77613
wandb:       eval/ensemble_f1 0.52138
wandb:            test/avg_f1 0.54934
wandb:      test/avg_mil_loss 0.79827
wandb:       test/ensemble_f1 0.54934
wandb:           train/avg_f1 0.54471
wandb:      train/ensemble_f1 0.54471
wandb:         train/mil_loss 0.65691
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xp7r6jl0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132351-xp7r6jl0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: j7auc4wn with config:
wandb: 	actor_learning_rate: 0.00022210872997164007
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1100286605988583
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8362402295151232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132605-j7auc4wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j7auc4wn
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▅▆▆▅▆▅▃▄▄▄▅▅▅▆▄▃▅▄▄▅▄▁▆▃▆▇▄▅▅▃▃▅▆▃█▄▅
wandb:      train/ensemble_f1 ▄▅▃▂▃▄▅▃▄▄▂▂▃▅▃▃▃▃▄▄▃▄▄▄▅▄▄▅▅▇▄▃▃▄▆▁▆▄█▅
wandb:         train/mil_loss ▅▅▇▆▆▃▃▂▅▆▄█▅▃▄▆▄▇▁█▆█▅▃▅▁▆▅▅▄▄▄▃▃▄▃▅▅▄▅
wandb:      train/policy_loss ▄█▂▇▁▁▅▇▂▅▂▄▄▁▁▇▂▂▂▄▁▂▄▄▂▂▂▂▄▅▄▅▄▅▄▄▁▄▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▃▃█▁▆▃▆▆▃▄▁▃▅▃▆▃▆▅▅▅▆▃▃▅▆▃▅▃▃▅█▆▃▃▅▅▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.08054
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.05591
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.19334
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33435
wandb:      train/ensemble_f1 0.33435
wandb:         train/mil_loss 0.96277
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j7auc4wn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132605-j7auc4wn/logs
wandb: Agent Starting Run: cemhb9nx with config:
wandb: 	actor_learning_rate: 0.001895987021408679
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5084739309337118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2782395992252278
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132754-cemhb9nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cemhb9nx
wandb: uploading history steps 105-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇█▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▄▄▄▄▅▅▅▅▅▇▇▇███████
wandb:      eval/avg_mil_loss ▂▁▁▁▁▁▁▁▅▅▆▇▇▇▇█████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅
wandb:       eval/ensemble_f1 ▇▇▇▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▅▅▅▅▅▅▅▅▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▇▇▇▁▃▂▁▃▃▃▃▃▅▅▄▆▃▅▃▂▅▄▄▃▄▃▃▅▄▄▆▅▄▇█▅█▆
wandb:      train/ensemble_f1 ▅▇██▅▄▃▂▁▁▃▄▅▄▅▄▅▄▇▄▅▄▆▄▅▅▅▅▅▄▅▅▅▅▄▆▆█▇▆
wandb:         train/mil_loss ▁▂▅▂▃▅▅▄▄▂▄▅▄▅▆█▃▅▄▄▇▄▃▅▃▅▄▄▃▇▅▄▂█▆▄▃▄▃▃
wandb:      train/policy_loss ▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45538
wandb: best/eval_avg_mil_loss 1.44664
wandb:  best/eval_ensemble_f1 0.45538
wandb:            eval/avg_f1 0.45538
wandb:      eval/avg_mil_loss 1.54146
wandb:       eval/ensemble_f1 0.45538
wandb:            test/avg_f1 0.45377
wandb:      test/avg_mil_loss 1.17202
wandb:       test/ensemble_f1 0.45377
wandb:           train/avg_f1 0.44186
wandb:      train/ensemble_f1 0.44186
wandb:         train/mil_loss 0.93731
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cemhb9nx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132754-cemhb9nx/logs
wandb: Agent Starting Run: c1mnwygy with config:
wandb: 	actor_learning_rate: 0.0032093523411200445
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7249523314079457
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11894321764785663
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_132957-c1mnwygy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1mnwygy
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▇▇▄▃▅▅▅▄▂▄▆▄▃▃▅▂▄▃▆▁▆▇▃▇█▄▄▆▅▃▆▃▇▆▃▄▄▅
wandb:      train/ensemble_f1 ▇▄▆▄▃▅▅▅▄▆▂▄▄█▆▇▂▃▃▆█▃▃▅▂▄▅▁▂▆▁▇▄▆▂▆▄▄▄▁
wandb:         train/mil_loss ▆▅▃▅▂▅▅▇▃▆▃▄▇▄▄▄█▄▄▄▇▄▂▄▁▇▃▃▄▅▂▅▅▃▅▁▃▅▃▅
wandb:      train/policy_loss ▁▅▄▇▆▄▄▆▁▅▇▅▅▅▁▄▄▅▅▅▄▆▁▄█▅▄▇▅▄▅▅▂▆▃▁▄▃▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▄▆▅▅▅▃▄▄▄▄▅▆▂▄▅▁▅▂▄▅▆▅█▄▆▄▄▅▆▅▅▅▃▂▄▅▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.05464
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.03128
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.15453
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33232
wandb:      train/ensemble_f1 0.33232
wandb:         train/mil_loss 0.62644
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1mnwygy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_132957-c1mnwygy/logs
wandb: Agent Starting Run: smaryc7c with config:
wandb: 	actor_learning_rate: 5.2411712042899886e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.692710363398364
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.060062662167134295
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_133146-smaryc7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smaryc7c
wandb: uploading history steps 120-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████
wandb:      eval/avg_mil_loss ▇▇▇▇█▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▄▄▃▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▆▅▃▆▂▅▃█▂▅▄▁▅▄▆▇▆▇▃▆▇▆▇▆▃▅▂▆▇▅▄█▃▇▄▃▅▄
wandb:      train/ensemble_f1 ▄▃▃▆▅▅▅▁▅▆▅▇▅█▆▄▃▆▇▆▆▇▆▅▆▅▅▆▄▇▂▆▆▅▇▄▆▃▅▄
wandb:         train/mil_loss ▅▂▆▄▂▃▃█▁▆▃▄▄▄▇▃▂▇▄▅▃▇▂▄▃▄▂▂▃▂▄▄▄▄▃▂▂▅▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47864
wandb: best/eval_avg_mil_loss 0.81849
wandb:  best/eval_ensemble_f1 0.47864
wandb:            eval/avg_f1 0.47864
wandb:      eval/avg_mil_loss 0.81132
wandb:       eval/ensemble_f1 0.47864
wandb:            test/avg_f1 0.45482
wandb:      test/avg_mil_loss 0.90846
wandb:       test/ensemble_f1 0.45482
wandb:           train/avg_f1 0.51817
wandb:      train/ensemble_f1 0.51817
wandb:         train/mil_loss 0.59722
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/smaryc7c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_133146-smaryc7c/logs
wandb: Agent Starting Run: fsikih5c with config:
wandb: 	actor_learning_rate: 0.00015981939140075817
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24555965832047633
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6013700520053579
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_133355-fsikih5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fsikih5c
wandb: uploading history steps 790-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆█████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▂▃▃▃▃▃▃▃▄▅▅▄▅▅▄▅▅▅▅▅▆▆▆▆▆▆█▇▇▇▇▇▇▇██
wandb:      train/ensemble_f1 ▁▂▂▂▁▂▂▂▃▃▃▃▃▄▃▄▄▄▅▅▄▄▅▅▄▅▅▆▅▄▆▆▆▆▆▇▇▇▇█
wandb:         train/mil_loss ▇▄▅▇▅▅▄▇█▄▅▃▄▄▄▅▄▄▄▄▃▄▄▃▃▄▄▃▂▂▃▃▃▁▃▃▂▂▁▁
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68194
wandb: best/eval_avg_mil_loss 0.95697
wandb:  best/eval_ensemble_f1 0.68194
wandb:            eval/avg_f1 0.68194
wandb:      eval/avg_mil_loss 0.95489
wandb:       eval/ensemble_f1 0.68194
wandb:            test/avg_f1 0.72833
wandb:      test/avg_mil_loss 0.61907
wandb:       test/ensemble_f1 0.72833
wandb:           train/avg_f1 0.69572
wandb:      train/ensemble_f1 0.69572
wandb:         train/mil_loss 0.8082
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fsikih5c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_133355-fsikih5c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rt73g8lv with config:
wandb: 	actor_learning_rate: 1.0492008595622016e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2803195636715461
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.783410025696279
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_134714-rt73g8lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rt73g8lv
wandb: uploading history steps 270-272, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▆▅▄▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▅▅▅▅▆█████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▃▂▃▃▃▃▂▂▅▂▃▂▅▂▄▂▃▅▄▃▅▆▆▅▇▅▅▇▆▇▅▆█▅▇█▇
wandb:      train/ensemble_f1 ▁▂▂▁▂▁▂▃▃▂▂▃▃▃▄▄▄▆▆▄▅▇▅▆▆▅▅▆▆▅▅█▇▇▆▇██▅█
wandb:         train/mil_loss █▄▄▇▅█▄▃▅▆▅▄▅▆▇▇▅▄▆▆▆▄▃▃▆▃▅▁▂▄▃▅▆▄▃▃▅▃▄▇
wandb:      train/policy_loss █▄▄▃▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46275
wandb: best/eval_avg_mil_loss 1.39726
wandb:  best/eval_ensemble_f1 0.46275
wandb:            eval/avg_f1 0.46275
wandb:      eval/avg_mil_loss 1.29936
wandb:       eval/ensemble_f1 0.46275
wandb:            test/avg_f1 0.47885
wandb:      test/avg_mil_loss 1.0463
wandb:       test/ensemble_f1 0.47885
wandb:           train/avg_f1 0.48983
wandb:      train/ensemble_f1 0.48983
wandb:         train/mil_loss 1.02253
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rt73g8lv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_134714-rt73g8lv/logs
wandb: Agent Starting Run: 786eo1hf with config:
wandb: 	actor_learning_rate: 0.0002498852791815719
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5506983718945508
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9447370888904056
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_135151-786eo1hf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/786eo1hf
wandb: uploading history steps 694-700, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb: best/eval_avg_mil_loss █▆▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:            eval/avg_f1 ▁▂▃▃▃▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▃▅▄▃▄▅▄▄▄▄▅▅▆▇▅▅▅▅▆▆▇▆▆▅▇▇▆▆▆▇▇▇▆▇█▇
wandb:      train/ensemble_f1 ▁▁▂▂▁▂▄▂▄▅▄▃▅▄▄▄▃▆▅▄▅▄▇▇▅▆▅▆▆▆▅▆▇▆▅▇▆█▅▆
wandb:         train/mil_loss ▄█▅▆▄▇▆▅▆▆▅▄▄▄▄▃▃▄▄▂▄▄▃▃▃▃▂▂▂▄▂▂▂▁▂▁▄▃▂▃
wandb:      train/policy_loss ████████████████▁██▃████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81223
wandb: best/eval_avg_mil_loss 0.40769
wandb:  best/eval_ensemble_f1 0.81223
wandb:            eval/avg_f1 0.8052
wandb:      eval/avg_mil_loss 0.42028
wandb:       eval/ensemble_f1 0.8052
wandb:            test/avg_f1 0.82322
wandb:      test/avg_mil_loss 0.34665
wandb:       test/ensemble_f1 0.82322
wandb:           train/avg_f1 0.80416
wandb:      train/ensemble_f1 0.80416
wandb:         train/mil_loss 0.44265
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/786eo1hf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_135151-786eo1hf/logs
wandb: Agent Starting Run: 58eo83s8 with config:
wandb: 	actor_learning_rate: 0.005088296705882963
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8540037125241748
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8810415892408934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_140332-58eo83s8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/58eo83s8
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ███▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▂▂▃▂▂▂▂▂▂▃▃▃▃▂▂▂▃▂
wandb:      train/ensemble_f1 ▇▇██▇▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▃▂▂▂▂▂▂▂▃▂▂▃▂▂▂▂▂▁▃▂
wandb:         train/mil_loss ▄▄▃▄▄▂▃▄▅▄▅▄▂█▅█▅▅▃▃▂▇▅▆▇▄▇▁▄▅▄▂▆▄▅▂▅▄▅▄
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55745
wandb: best/eval_avg_mil_loss 1.61373
wandb:  best/eval_ensemble_f1 0.55745
wandb:            eval/avg_f1 0.45538
wandb:      eval/avg_mil_loss 1.74791
wandb:       eval/ensemble_f1 0.45538
wandb:            test/avg_f1 0.61678
wandb:      test/avg_mil_loss 1.187
wandb:       test/ensemble_f1 0.61678
wandb:           train/avg_f1 0.43079
wandb:      train/ensemble_f1 0.43079
wandb:         train/mil_loss 0.67455
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/58eo83s8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_140332-58eo83s8/logs
wandb: Agent Starting Run: 7uuqygt4 with config:
wandb: 	actor_learning_rate: 0.0006838146375407119
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11819958146903288
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46119333260683526
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_140520-7uuqygt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7uuqygt4
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅▆▆▇███
wandb: best/eval_avg_mil_loss █▇▇▆▆▅▄▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅▆▆▇███
wandb:            eval/avg_f1 ▁▁▃▄▆███████████████████████████████████
wandb:      eval/avg_mil_loss █▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▆▆████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▇████▇█▇█▇█▇█▇███▇▇█▇▇▇█▇▇▇██▇▇▇▇█▇▇▇
wandb:      train/ensemble_f1 ▁▁▁▄▅▇███▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇▇█
wandb:         train/mil_loss ▆█▆▅▃▃▂▃▂▃▃▃▃▂▃▃▂▃▂▂▂▂▂▃▁▂▂▁▃▂▂▃▂▁▂▁▂▃▂▂
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71405
wandb: best/eval_avg_mil_loss 0.90072
wandb:  best/eval_ensemble_f1 0.71405
wandb:            eval/avg_f1 0.7008
wandb:      eval/avg_mil_loss 0.88864
wandb:       eval/ensemble_f1 0.7008
wandb:            test/avg_f1 0.72346
wandb:      test/avg_mil_loss 0.55151
wandb:       test/ensemble_f1 0.72346
wandb:           train/avg_f1 0.67171
wandb:      train/ensemble_f1 0.67171
wandb:         train/mil_loss 0.83408
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7uuqygt4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_140520-7uuqygt4/logs
wandb: Agent Starting Run: ytsk1g4j with config:
wandb: 	actor_learning_rate: 0.00058055606308792
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.028571971953748165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00025806669278194416
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_140714-ytsk1g4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ytsk1g4j
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▇▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▇▆▇▇▇▇▇██
wandb:      train/ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▃▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇█
wandb:         train/mil_loss ▇███▆▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:      train/policy_loss ███████████████▁█████████████████████▁██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70714
wandb: best/eval_avg_mil_loss 0.80499
wandb:  best/eval_ensemble_f1 0.70714
wandb:            eval/avg_f1 0.70714
wandb:      eval/avg_mil_loss 0.80026
wandb:       eval/ensemble_f1 0.70714
wandb:            test/avg_f1 0.74419
wandb:      test/avg_mil_loss 0.52894
wandb:       test/ensemble_f1 0.74419
wandb:           train/avg_f1 0.71592
wandb:      train/ensemble_f1 0.71592
wandb:         train/mil_loss 0.81667
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run morning-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ytsk1g4j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_140714-ytsk1g4j/logs
wandb: Agent Starting Run: n89vys79 with config:
wandb: 	actor_learning_rate: 1.2334922099031089e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.273196133696315
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.434267116292353
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_141957-n89vys79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n89vys79
wandb: uploading history steps 800-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇█████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇██
wandb:      train/ensemble_f1 ▁▁▂▁▂▁▂▃▃▂▄▃▃▃▄▆▅▆▆▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:         train/mil_loss ██▆▇▆▇▆▆▅▄▅▅▅▅▄▅▃▄▄▃▃▄▄▂▃▃▃▁▃▁▁▁▂▁▁▁▁▁▁▁
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7409
wandb: best/eval_avg_mil_loss 0.58567
wandb:  best/eval_ensemble_f1 0.7409
wandb:            eval/avg_f1 0.7409
wandb:      eval/avg_mil_loss 0.58455
wandb:       eval/ensemble_f1 0.7409
wandb:            test/avg_f1 0.75454
wandb:      test/avg_mil_loss 0.43832
wandb:       test/ensemble_f1 0.75454
wandb:           train/avg_f1 0.73747
wandb:      train/ensemble_f1 0.73747
wandb:         train/mil_loss 0.57954
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n89vys79
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_141957-n89vys79/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dr8mhzvw with config:
wandb: 	actor_learning_rate: 0.004309997079113845
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7061080812532727
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6976253514863477
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_143256-dr8mhzvw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dr8mhzvw
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▁▆▄▅▄▅▂▅▅▅▂▂▅▄▅▅▅▂█▂▇▄▃▅▄█▆▄▅▆▅▄▁▃▄▅▆▇
wandb:      train/ensemble_f1 ▄▅▇▆▂▄▄▅▄▄▃▅▄▃▅▇▅▄▁▃▆▅▃▁▂▅▄▅▅▄▇█▅▅▄▄▃▅▂▆
wandb:         train/mil_loss ▃▃▅▇▄▄▃▃▃█▂▃▄▂▂▆▅▆▃▅▄▆▄▂▁▃▅▅▅▅▃▄▅▂▃▂▇▄▄▇
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▃▃▆▇█▆▃▃▅▆▅▄▄▂▃▅▃▃▆▇█▃▄▃▂▄▄▁▁▅▄▄▅▅▃▁▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.08047
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.06677
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.19374
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33737
wandb:      train/ensemble_f1 0.33737
wandb:         train/mil_loss 0.72525
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dr8mhzvw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_143256-dr8mhzvw/logs
wandb: Agent Starting Run: 8d95nm32 with config:
wandb: 	actor_learning_rate: 0.00011179981209948327
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.08121346679535413
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8315126722515581
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_143440-8d95nm32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8d95nm32
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▅▅▇▁▅▇▅▅▃█▄▅▃▅▆▄▃▅▆▅▄▄▅▅▆▁▅██▆▇▂▄▆▆▅▇▂
wandb:      train/ensemble_f1 ▃▄▇▅▁▆▄▇▁▆▆▆▅█▅▆▆▅▇▆▅▄▇▅▅▄▅▄▇▆▇▄█▇▆▄▅▇█▃
wandb:         train/mil_loss ▄█▅▁▃▅▆▄▇▅▅▅▄▅▇▅▁▃▆▄▄▆▄▄▃▅▅▄▄▂▄▄▅▂▃▃▂▃▆▂
wandb:      train/policy_loss █▆▁▆▆█▃▁▆▄▆▁▁▁▄▁▁▁▁▆▃▆▆▆█▆▁▁▃█▃▃▃▃▃▃▃▆▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃█▆▆▁▁█▆▆▁▁▁▃▃▃▃▁▃▁▆▁▆▄▃█▃▃█▆▃▃▃▆▆▃▃█▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.24054
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.17578
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.37366
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32636
wandb:      train/ensemble_f1 0.32636
wandb:         train/mil_loss 1.02377
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8d95nm32
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_143440-8d95nm32/logs
wandb: Agent Starting Run: 4sfx0uod with config:
wandb: 	actor_learning_rate: 8.930072691615589e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4496332562169636
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27321888150578744
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_143623-4sfx0uod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4sfx0uod
wandb: uploading history steps 732-733, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ████▇▆▆▆▆▅▅▅▄▃▃▃▃▂▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▅▅▆▆▇▇▇▇████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▁▃▃▂▃▃▄▃▅▅▅▆▅▅▆▅▆▆▆▆▇▇▆▇▇▇▆▆▇▇▇██▇▆█
wandb:      train/ensemble_f1 ▂▁▁▁▃▂▂▃▂▃▄▄▄▃▄▃▄▅▅▆▆▆▆▅▆▇▇▆▇▇▆▇▇█▆▇█▇██
wandb:         train/mil_loss ▄▆█▇▄▂▇▂▅▅▄▄▄▃▄▆▃▄▃▄▃▃▁▂▁▅▄▂▃▃▄▂▁▂▃▃▃▂▂▃
wandb:      train/policy_loss ███████████████████████████▁████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58801
wandb: best/eval_avg_mil_loss 1.21672
wandb:  best/eval_ensemble_f1 0.58801
wandb:            eval/avg_f1 0.58801
wandb:      eval/avg_mil_loss 1.14336
wandb:       eval/ensemble_f1 0.58801
wandb:            test/avg_f1 0.56967
wandb:      test/avg_mil_loss 0.8882
wandb:       test/ensemble_f1 0.56967
wandb:           train/avg_f1 0.5728
wandb:      train/ensemble_f1 0.5728
wandb:         train/mil_loss 0.92552
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4sfx0uod
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_143623-4sfx0uod/logs
wandb: Agent Starting Run: eo4rv6du with config:
wandb: 	actor_learning_rate: 0.000785369611966679
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7064077373671166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24492542445288512
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_144815-eo4rv6du
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eo4rv6du
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 757-766, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇█████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▁▁▃▃▃▄▄▄▄▄▄▄▅▄▆▅▅▅▅▆▇▆▆▇▇▆▇██▇▇▇▇▇▇██
wandb:      train/ensemble_f1 ▂▁▁▂▂▂▂▁▁▃▃▂▃▃▃▄▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█▇██
wandb:         train/mil_loss ▆█▆▆▇▂▆▆▅▁▆▄▂▄▆█▆▇▄█▂▆▇▁▄▂▅▅▁▃▁▃▄▃▃▃▄▂▃▁
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▂▅▅▅▅▇▅▇▇▅▅▅▅▅▅▅▆█▃▅▅▅▅▅▆▅▅▅▄▃▇▁▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68194
wandb: best/eval_avg_mil_loss 0.82947
wandb:  best/eval_ensemble_f1 0.68194
wandb:            eval/avg_f1 0.68194
wandb:      eval/avg_mil_loss 0.80168
wandb:       eval/ensemble_f1 0.68194
wandb:            test/avg_f1 0.67225
wandb:      test/avg_mil_loss 0.63142
wandb:       test/ensemble_f1 0.67225
wandb:           train/avg_f1 0.68108
wandb:      train/ensemble_f1 0.68108
wandb:         train/mil_loss 0.53019
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eo4rv6du
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_144815-eo4rv6du/logs
wandb: Agent Starting Run: 82w6q9t4 with config:
wandb: 	actor_learning_rate: 0.00043940793683719186
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18563796438174196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.406982534985195
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_150046-82w6q9t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82w6q9t4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ▆▆▆██▆▆▆▆▅▄▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████▇▇▇▇▇
wandb:      eval/avg_mil_loss ▆▆▆▇█▆▄▄▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▃
wandb:       eval/ensemble_f1 ▁▁▁▂▃▃▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▆▇▇▇██████████▇▇██▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▃▃▂▂▂▂▃▄▅▄▄▄▅▅▄▅▆▆▆▅▇▆▇▆▇▇▇█▇▇▇█▇▇▇█
wandb:      train/ensemble_f1 ▂▁▂▂▃▃▃▂▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇█▇▇▇█▇▆
wandb:         train/mil_loss ▇█▇█▇▆▆▆▆▆▅▇▅▅▅▄▅▅▆▅▄▃▄▃▄▃▃▃▃▂▃▁▂▂▁▂▂▃▃▁
wandb:      train/policy_loss ▄▄█▄▁▄▄▃▄▄▇▄▄▄▄▄▄▄▆▄▄▄▄▄█▆▄▄▄▁▄▄▄▇▆▄▄▂▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▁████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82231
wandb: best/eval_avg_mil_loss 0.48109
wandb:  best/eval_ensemble_f1 0.82231
wandb:            eval/avg_f1 0.80336
wandb:      eval/avg_mil_loss 0.55617
wandb:       eval/ensemble_f1 0.80336
wandb:            test/avg_f1 0.80495
wandb:      test/avg_mil_loss 0.44098
wandb:       test/ensemble_f1 0.80495
wandb:           train/avg_f1 0.81178
wandb:      train/ensemble_f1 0.81178
wandb:         train/mil_loss 0.48667
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/82w6q9t4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_150046-82w6q9t4/logs
wandb: Agent Starting Run: 4o9cgj86 with config:
wandb: 	actor_learning_rate: 0.0033984845992730407
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9025262515828149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18231261538660015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_150830-4o9cgj86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4o9cgj86
wandb: uploading history steps 124-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▇██▅▅▄▄▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▄▄▄▄▄▃▄▃▁▂▂▂▂▂▅████████████████████████
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇▇██▅▄▅▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇█▇█▇█▇▆██▅▃▂▁▂▁▃▂▃▃▂▂▂▃▃▃▃▃▂▃▃▂▂▂▃▁▂▃▃
wandb:      train/ensemble_f1 ▇█▇██▇▇▆▅▆▇█▇▅▂▂▃▃▂▃▃▃▃▃▃▄▂▃▃▃▁▂▃▂▂▃▃▃▂▃
wandb:         train/mil_loss ▅▃▁▅▅▆▄▃▆█▄▂▅▅▅▁▇▂▆█▅▅▃▄▅▄▁▅█▄▆▃▆▃▅▃▇▇▃▆
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▇▄▆▁▄▁▇▇▇▇▇█▇▄▄▄▄▄▄▄▄▄▄▄▄▄▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▆▆▁▄▄▁█▆▇▇▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▆█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70146
wandb: best/eval_avg_mil_loss 0.48749
wandb:  best/eval_ensemble_f1 0.70146
wandb:            eval/avg_f1 0.59885
wandb:      eval/avg_mil_loss 0.76493
wandb:       eval/ensemble_f1 0.59885
wandb:            test/avg_f1 0.72044
wandb:      test/avg_mil_loss 0.50899
wandb:       test/ensemble_f1 0.72044
wandb:           train/avg_f1 0.60422
wandb:      train/ensemble_f1 0.60422
wandb:         train/mil_loss 0.51332
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4o9cgj86
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_150830-4o9cgj86/logs
wandb: Agent Starting Run: 2l76wyh7 with config:
wandb: 	actor_learning_rate: 0.003442655041782427
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4691731953014237
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5869930358804686
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_151044-2l76wyh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2l76wyh7
wandb: uploading history steps 797-801, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▂▂▃▄▃▄▃▃▄▄▄▃▄▄▄▃▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇██▇█
wandb:      train/ensemble_f1 ▂▁▂▂▁▂▃▃▁▃▄▃▃▄▅▅▅▅▅▄▄▆▇▅▆▆▆▆▇▅▇▇▇▆▆█▇▇▇█
wandb:         train/mil_loss ▆▅▅█▅▅▄▃▃▅▆▄▆▅▄▅▃▁▄▃▄▅▅▃▃▂▃▂▂▁▂▂▃▄▂▃▁▂▁▂
wandb:      train/policy_loss ███████████████████████████████▁████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58801
wandb: best/eval_avg_mil_loss 1.04301
wandb:  best/eval_ensemble_f1 0.58801
wandb:            eval/avg_f1 0.58801
wandb:      eval/avg_mil_loss 1.03875
wandb:       eval/ensemble_f1 0.58801
wandb:            test/avg_f1 0.60371
wandb:      test/avg_mil_loss 0.77106
wandb:       test/ensemble_f1 0.60371
wandb:           train/avg_f1 0.59188
wandb:      train/ensemble_f1 0.59188
wandb:         train/mil_loss 0.85079
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2l76wyh7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_151044-2l76wyh7/logs
wandb: Agent Starting Run: zuk80b5a with config:
wandb: 	actor_learning_rate: 0.00461771194223571
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6505924877580607
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5437545577838961
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_152338-zuk80b5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zuk80b5a
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▁▂▁▁▂▁▂▁▂▂▁▂▂▂▃▃▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▅▅▂▅▃▄▆▃▂▄▆▁▄█▃▃▅▄▃▃▃▆▃▃▃▃▄▂▆▄▅▃▄▄▃▂▇▅
wandb:      train/ensemble_f1 ▄▁▅█▆▇▆▄▇▂▂▅▃▄▅▄▁▄▄▄▃▆▃▆▃▅▃▃▁▃▁▄▃▂▅▅▇▅▄▅
wandb:         train/mil_loss ▅▄▄▂▃▃▆▄▄█▅▂▂▄▅▂▄█▄▂▄▇▄▅▁▅▄█▄▁▃▇▆▃▃▇▄█▄▅
wandb:      train/policy_loss █▇▇▄▄▅▆▅▃▅▆▁▇▇▇▅▄▃▇▆▅█▅▅▄▅▄▄▄▃▅▆▃▄▄▅▅▄▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▄▅▄▄▆▆▆█▄▆█▇▁██▅▂▅█▇▃█▆▆▆▅▆▅▄▄▆▃▇▇▇▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.32931
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.42429
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.51839
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.33897
wandb:      train/ensemble_f1 0.33897
wandb:         train/mil_loss 0.70921
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zuk80b5a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_152338-zuk80b5a/logs
wandb: Agent Starting Run: 3766pex2 with config:
wandb: 	actor_learning_rate: 0.0005331121408889831
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4727078743936025
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.635932725394821
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_152522-3766pex2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3766pex2
wandb: uploading wandb-summary.json
wandb: uploading history steps 95-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▇█▆▅▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃
wandb:      eval/avg_mil_loss ███▇▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▇▇▇▇██▆▄▂▂▁▁▁▁▁▂▁▁▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇██▆▄▂▂▄▃▃▃▄▃▁▅▃▂▂▂▃▂▂▂▃▃▃▂▃▂▃▃▂▃▃▄▂▃▃
wandb:      train/ensemble_f1 ▇██▆▇▂▂▂▂▂▂▄▂▃▄▃▃▄▁▅▂▃▃▃▂▂▂▂▁▃▂▃▃▃▃▃▃▂▃▃
wandb:         train/mil_loss ▅▆▅█▅▅▄▅▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▁▂▂▁▂▂▂▂▂▂▂▁▁▁
wandb:      train/policy_loss ▃▃▃▃█▃▃▃█▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃█▃▃▃▃▃▃▃▃▃▁▃▃▃▇▃▃▃▃▃▃▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73451
wandb: best/eval_avg_mil_loss 0.98457
wandb:  best/eval_ensemble_f1 0.73451
wandb:            eval/avg_f1 0.60373
wandb:      eval/avg_mil_loss 0.67313
wandb:       eval/ensemble_f1 0.60373
wandb:            test/avg_f1 0.72547
wandb:      test/avg_mil_loss 0.61131
wandb:       test/ensemble_f1 0.72547
wandb:           train/avg_f1 0.63569
wandb:      train/ensemble_f1 0.63569
wandb:         train/mil_loss 0.53677
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3766pex2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_152522-3766pex2/logs
wandb: Agent Starting Run: 38abvrnx with config:
wandb: 	actor_learning_rate: 0.0003636997532081234
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8218054761596714
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4254428126312507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_152710-38abvrnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/38abvrnx
wandb: uploading history steps 249-255, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▅▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▃▂▂▂▃▂▃▄▅▅▅▄▆▅▃▆▅▄▅█▅▅▅▅▂▆▄▆▆▆▇▄▆▆█▆
wandb:      train/ensemble_f1 ▂▁▂▁▂▃▂▁▃▄▁▄▂▃▄▅▃▄▄▄▅▆▄▃▃▅█▄▄█▃▇▅▆▅▆▅▆▆▇
wandb:         train/mil_loss ▁▄▅▆▄▄▆▄▅▂▃▄▆▄█▅▃▄▄▄▂▆▆▃▃▆▄▄▅▄▄▆▄▅▄▅▂▅▁▅
wandb:      train/policy_loss █▅▅▅▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆▆▄▇▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.43275
wandb: best/eval_avg_mil_loss 1.58028
wandb:  best/eval_ensemble_f1 0.43275
wandb:            eval/avg_f1 0.43275
wandb:      eval/avg_mil_loss 1.524
wandb:       eval/ensemble_f1 0.43275
wandb:            test/avg_f1 0.43645
wandb:      test/avg_mil_loss 1.22276
wandb:       test/ensemble_f1 0.43645
wandb:           train/avg_f1 0.43435
wandb:      train/ensemble_f1 0.43435
wandb:         train/mil_loss 0.6976
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/38abvrnx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_152710-38abvrnx/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uw4jutnt with config:
wandb: 	actor_learning_rate: 8.242014746971043e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5873666641096994
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5025737650638501
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_153129-uw4jutnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw4jutnt
wandb: uploading history steps 110-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▃▆▆██████████████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▃▃▃▃▆▆███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▁▂▁▂▃▂▄▄▄▄▃▃▅▆▅▄▆▅▄▄▅▅█▅▆▆▅▇▅▇▆█▄▆▃▇▅
wandb:      train/ensemble_f1 ▄▃▂▂▁▄▃▃▄▄▄▅▅▅▃▄▆▄▆▅▆▆▆▅▄▆█▅▅▇▇▅█▅▆▅▄▆▆▆
wandb:         train/mil_loss ▄▅▃▆▅▂▄▆█▆▇▆▄▆█▄▇█▄▃▆▃▄▅▄▆▁▄▅▆█▆▅▄▅▄▄▄▆▄
wandb:      train/policy_loss ▁█▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47721
wandb: best/eval_avg_mil_loss 1.72284
wandb:  best/eval_ensemble_f1 0.47721
wandb:            eval/avg_f1 0.47721
wandb:      eval/avg_mil_loss 1.61458
wandb:       eval/ensemble_f1 0.47721
wandb:            test/avg_f1 0.46225
wandb:      test/avg_mil_loss 1.36183
wandb:       test/ensemble_f1 0.46225
wandb:           train/avg_f1 0.50068
wandb:      train/ensemble_f1 0.50068
wandb:         train/mil_loss 1.0855
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw4jutnt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_153129-uw4jutnt/logs
wandb: Agent Starting Run: 4fjao12p with config:
wandb: 	actor_learning_rate: 0.0002733200161818883
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2673539778218321
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7022549109894778
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_153333-4fjao12p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4fjao12p
wandb: uploading history steps 141-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂█████
wandb: best/eval_avg_mil_loss ▇█▆▆▁▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂█████
wandb:            eval/avg_f1 ▁▁▁▁▁▂██▇▇▇█████████████▇▇▇▇▇▇▇█▇▇██▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁██▇▇▇███▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▁▂█▇▆▇█▇▇▇▇▆▇▇▇▆▇▇▇▆█▆▆█▇██▇▇▆▆▇▇▆▆▇▇
wandb:      train/ensemble_f1 ▁▃▇▆▇▆▇▇▆▆█▇▇▇▇▇▇▇▇▆▇▆█▇▇█▇▇▇▇▆▆▆▇▇█▇▇▇▇
wandb:         train/mil_loss ▇▅▅█▅▆▆▁▃▂▃▃▂▅▃▃▄▄▃▃▄▃▂▁▃▃▃▃▃▄▃▁▄▁▄▄▂▂▃▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆█▆▁▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70963
wandb: best/eval_avg_mil_loss 0.54523
wandb:  best/eval_ensemble_f1 0.70963
wandb:            eval/avg_f1 0.69144
wandb:      eval/avg_mil_loss 0.55249
wandb:       eval/ensemble_f1 0.69144
wandb:            test/avg_f1 0.72619
wandb:      test/avg_mil_loss 0.55338
wandb:       test/ensemble_f1 0.72619
wandb:           train/avg_f1 0.68856
wandb:      train/ensemble_f1 0.68856
wandb:         train/mil_loss 0.54564
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4fjao12p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_153333-4fjao12p/logs
wandb: Agent Starting Run: ry1a9qwp with config:
wandb: 	actor_learning_rate: 2.793987079221384e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8020104621749529
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.044723921404480005
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250602_153553-ry1a9qwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py2gcd0l
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry1a9qwp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▁▅▃▇▂▆▅▃▄▅▄▇▅▅█▂▅▆▇▄▅▆▆▆▃▅▄▆▅▅▆▄▁▇▅▄▃▃
wandb:      train/ensemble_f1 ▃▇▆█▅▃▃▄▁▆▃▃▅▆▆▄▃▅▃▂▆▇▃▂▅▄▁▄▅▅▇▂▄▆▃▆▂▅▂▁
wandb:         train/mil_loss ▅▁▆▅▂▇▃▇▇█▅▆▆▆▃▅▃▄▅██▅▇▁█▂▃▃▂▄▂█▆▃▇█▅▄▅▅
wandb:      train/policy_loss █▇▅▅█▃▇█▃▆▃█▁▇▇▃▇▅█▇█▇▆▇▇▄▇▁▄▆▆▃▇▆▆▄▄▅▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▄▆▇▇▄▇▅▂█▅▄▆▅▄▃▄▅▆▇▇▆▆▆▆▆▃▆▆▅▁▄▄▁▆▅▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.315
wandb: best/eval_avg_mil_loss 1.08734
wandb:  best/eval_ensemble_f1 0.315
wandb:            eval/avg_f1 0.315
wandb:      eval/avg_mil_loss 1.06503
wandb:       eval/ensemble_f1 0.315
wandb:            test/avg_f1 0.29016
wandb:      test/avg_mil_loss 1.20238
wandb:       test/ensemble_f1 0.29016
wandb:           train/avg_f1 0.32945
wandb:      train/ensemble_f1 0.32945
wandb:         train/mil_loss 0.5967
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ry1a9qwp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250602_153553-ry1a9qwp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
Traceback (most recent call last):
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/run_rlmil.py", line 681, in <module>
    args = parse_args()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/configs.py", line 333, in parse_args
    sweep_config = load_yaml_file(sweep_config_file_address)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/utils.py", line 182, in load_yaml_file
    data = yaml.load(f, Loader=SafeLoader)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/composer.py", line 36, in get_single_node
    document = self.compose_document()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/composer.py", line 55, in compose_document
    node = self.compose_node(None, None)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/composer.py", line 84, in compose_node
    node = self.compose_mapping_node(anchor)
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/composer.py", line 127, in compose_mapping_node
    while not self.check_event(MappingEndEvent):
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/parser.py", line 98, in check_event
    self.current_event = self.state()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/parser.py", line 428, in parse_block_mapping_key
    if self.check_token(KeyToken):
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/scanner.py", line 115, in check_token
    while self.need_more_tokens():
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/scanner.py", line 152, in need_more_tokens
    self.stale_possible_simple_keys()
  File "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/yaml/scanner.py", line 291, in stale_possible_simple_keys
    raise ScannerError("while scanning a simple key", key.mark,
yaml.scanner.ScannerError: while scanning a simple key
  in "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/yaml_configs/hp_rl_policy_only_loss_epsilon_greedy_reg_sum.yaml", line 40, column 1
could not find expected ':'
  in "/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/yaml_configs/hp_rl_policy_only_loss_epsilon_greedy_reg_sum.yaml", line 41, column 1
