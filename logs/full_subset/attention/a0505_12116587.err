wandb: Agent Starting Run: eb8qlacs with config:
wandb: 	actor_learning_rate: 0.00023889025593211625
wandb: 	attention_dropout_p: 0.4928155252252482
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5242507122921614
wandb: 	temperature: 6.063872897909599
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152806-eb8qlacs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb8qlacs
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml; uploading history steps 98-118, summary
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▆▅█▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▃▆▁▁▅▁▃█▄▄█▄▃▃▃▅▁▃▃▂▄▃▆▃▄▂▁▃▁▄▁▃▁▁▃▄▁▁▃
wandb:      eval/avg_mil_loss ▂█▄▃▂▃▃▁▃▂▂▂▂▃▃▂▃▂▃▃▄▂▃▂▃▂▃▃▃▃▂▃▃▂▃▃▂▂▂▂
wandb:       eval/ensemble_f1 ▃▅▃▃▃▄▅▁▃█▄▁▃▅▃▄▃▃▃▂▁▃▃▄▂▃▄▄▄▁▃▃▁▃▄▃▃▁▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▂▅▄█▁▆▂▅▃▂▅▃▆█▅▅▃▅▅█▄▂▆▃▅▂▅▂▅▅▅▇▃▂▃▅▆
wandb:      train/ensemble_f1 ▄▂▂▂▄▂▂▂▃▃▂▂█▂▃▂▄▅▁▄▅▃▄▃▂▅▃▃▄▂▁▄▃▄▄▅▅▃▄▂
wandb:         train/mil_loss ▃▃▂▄▅▂▇▃▄▁▃▃▄▃▄▄▃▆▅▃▁▅▃█▂▃▆▆▃▂▃▆▃▃▁▃▂▄▁▂
wandb:      train/policy_loss ▄▄▃▄▃▄▁▄▃▃▃▄▄▃▁▄▃▃▄▃▄▄▄▄▃▄▃██▃▃▃▃▄▃▄▃▄▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▃█▅▃▅▅▅▃▃▅▃▃▁▃▅▅▅▅▃▃▃▃▅█▃▅▅▅▆▃▃▃▅▁▁▃▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78897
wandb: best/eval_avg_mil_loss 0.68845
wandb:  best/eval_ensemble_f1 0.78897
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.89465
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.6532
wandb:      test/avg_mil_loss 1.43557
wandb:       test/ensemble_f1 0.6532
wandb:           train/avg_f1 0.57933
wandb:      train/ensemble_f1 0.57933
wandb:         train/mil_loss 0.81053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb8qlacs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152806-eb8qlacs/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fyyttjbb with config:
wandb: 	actor_learning_rate: 1.0965286240076591e-05
wandb: 	attention_dropout_p: 0.15010571959540553
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8513873296372875
wandb: 	temperature: 5.414511217382998
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152950-fyyttjbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fyyttjbb
wandb: uploading history steps 62-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▁▆▃▅▄▃▇▁▇▁▄▁▅▄▄▁▄█▄▃▂▇█▇▆▃▄▃▄▄▁▃▄▅▆▇▆▄▃▃
wandb:      eval/avg_mil_loss █▂▂▅▂▃▁▇▁▇▂▂▂▃▂▁▁▁▂▂▂▁▁▃▂▂▂▇▃▂▁▂▂▃▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▇▄▆▆▁██▄▅█▄▁▄▁▆█▇▃█▇▃▅▄█▅▁▄█▅▃▆▆▇▃▄▃▁▁▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆▆▄▆▄▇▅█▄▆▂▅▄▄▅▆▄▃▆▆▁▃▅▃▅▄▅▅▆▆▆▃▄▅▅▆▃▄
wandb:      train/ensemble_f1 ▃▃▇▆▇▃▇▄▂▄▂▅▆▇▄▆▆▅▃▇▆▁▄▃▄▅▅█▄▅▅▆▆▆▃▅▅▇▃▆
wandb:         train/mil_loss ▃▂▃▁▃▄▃▁▁▁▂▂▃▃▄▁▁█▁▁▂▁▂▂▂▁▁▃▃▁▁▁▁▃▃▁▁▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82861
wandb: best/eval_avg_mil_loss 0.60405
wandb:  best/eval_ensemble_f1 0.82861
wandb:            eval/avg_f1 0.66731
wandb:      eval/avg_mil_loss 0.93843
wandb:       eval/ensemble_f1 0.66731
wandb:            test/avg_f1 0.70997
wandb:      test/avg_mil_loss 0.67587
wandb:       test/ensemble_f1 0.70997
wandb:           train/avg_f1 0.63239
wandb:      train/ensemble_f1 0.63239
wandb:         train/mil_loss 2.24349
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fyyttjbb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152950-fyyttjbb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ttz557oo with config:
wandb: 	actor_learning_rate: 0.00029898815592532607
wandb: 	attention_dropout_p: 0.4525494045760618
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33543888381773546
wandb: 	temperature: 2.466376850771014
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153057-ttz557oo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttz557oo
wandb: uploading history steps 125-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▆▇██
wandb: best/eval_avg_mil_loss ▄█▄▄▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▆▇██
wandb:            eval/avg_f1 ▅▂▂▆▇▂▅▂▂▆▆▇▂▆▃▇▇▂▁▁▆█▂▂▇▇▂▇▂▂▂▂▁▆▇▆▆▂▆▂
wandb:      eval/avg_mil_loss ▅▅▆▇▃▆▅▆▅█▆▅▆▆▆▅█▆▅▆▆▆▄▆▆▆▅▅▁▆▅▇▅▇▅▅▄▆▅▆
wandb:       eval/ensemble_f1 ▂▁▃▃▇▃▂▁▃▁▇▃▂▃▁▁▃▂▁▂▁▁▃▁▆▁▂▂▃▃▁▁▁▄█▃▃▄▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▁▂▅▇▇▅▂▅▁▂▆▅▃▂▅▆▁█▂▅▂▃▂▆▃▂▂▄▅▂▅▆▁▂▁▂▂
wandb:      train/ensemble_f1 ▁▁▃▂█▃▂▇▇▁▂▃▇▄▇▃▂█▃▂▅▇▂▃▆▇▂▄▃▃█▇▆▃▁▂▃▂▂▃
wandb:         train/mil_loss ▄▅▅▆▆▆▄▇▂▆█▅▅▄▃▂▅▃▅▂▃▄█▄▄▃▄▁▄▅▁▂▄▃▃▄▃▅▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.67298
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04799
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.8129
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.60034
wandb:      train/ensemble_f1 0.60034
wandb:         train/mil_loss 0.93675
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ttz557oo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153057-ttz557oo/logs
wandb: Agent Starting Run: jfqvn7wj with config:
wandb: 	actor_learning_rate: 1.4667989370002322e-06
wandb: 	attention_dropout_p: 0.2690688981819549
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22102446488245597
wandb: 	temperature: 5.422355036370517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153235-jfqvn7wj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jfqvn7wj
wandb: uploading history steps 104-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▆█▂▄▄▄▄▅▆▄▃▄▁▄█▁▄▄▆▃▆▄▄▄▂▆▇▆▆▄▄██▄▇▃▁▂▄
wandb:      eval/avg_mil_loss ▂▂▁▁▁▂▂▁▂▁▁▂▁▁▆▂▁▁▄▂▁▂▂▁▁▁▂▁▂▂▁▁▁▂▁▁█▂▁▂
wandb:       eval/ensemble_f1 ▁▁█▄▇▇▄▄▃▆▆▃▁▇▄▄▃▁▇▆▂▄▁▄▃▃▇▄▃▄▇▆▄▂▁▁▂▁▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂█▂▃▃▅▃▆▄▄▃▄▅▃▃▅▇▅▄█▄▃▄▅▄▄▆▆▄▅▇▄▁▂▆▄▄▄
wandb:      train/ensemble_f1 ▄▅▃▂▆▅▂▄█▄▆▇▁▅▄▃▃▃▅▃▄▅▅▄▄▅▅▂▅▄▆▆▆▄▄▂▁▄▄▄
wandb:         train/mil_loss █▂▅▇▃▂▄▃▄▃▂▁▂▃▂▃▄▂▁▁▂▃▁▅▁▂█▂▂▄▂▂▁▂▁▂▁▂▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.69208
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.99098
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.7702
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.55694
wandb:      train/ensemble_f1 0.55694
wandb:         train/mil_loss 1.36648
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jfqvn7wj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153235-jfqvn7wj/logs
wandb: Agent Starting Run: rwtoclxk with config:
wandb: 	actor_learning_rate: 1.005148244032379e-06
wandb: 	attention_dropout_p: 0.4023772792812743
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.917118866070421
wandb: 	temperature: 5.0494102202881574
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153358-rwtoclxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rwtoclxk
wandb: uploading history steps 62-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄█
wandb: best/eval_avg_mil_loss ▂▂▁█▄
wandb:  best/eval_ensemble_f1 ▁▁▂▄█
wandb:            eval/avg_f1 ▃▁▁▃▂▁▂▁▁▁▁▁▁▂▅▁▄▅▄▁▁▅▃▃▁▁▄▄▁▁▂▃▄▅▄▄█▁▁▁
wandb:      eval/avg_mil_loss ▃▅▄▂▃▃▃▄▄▄▃▄▃▂▄▂▅█▃▂▅▄▄▄▄▄▄▄▄▂▄▃▄▃▁▂▅▃▄▄
wandb:       eval/ensemble_f1 ▁▃▁▁▁▂▁▃▁▁▂▁▁▄▁▁▅▁▄▁▁▁█▄▃▁▁▁▄▁▂▃▁▄▄▇▁▁▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▅▇▄▃▇▆▆▂▅▄▄▇▃▄▄▆▆▃▇▃▁▂█▄▄▅▄▅▁▄▁█▅▂▅▄▄
wandb:      train/ensemble_f1 ▃▃█▅▇▄▆▆▂▅▃▄▆▃▇▅▂▃▇▃█▃▂▆█▃▅▅▄▃▄▁▇▄▁▅▃▁▄▃
wandb:         train/mil_loss ▄▅▃▅▅▅▆▅▃▆▅▅▅▆█▄▅▄▄▅▃▄▄▅▆▆▃▃▄▄▄▅▅█▃▂▁▄▅▃
wandb:      train/policy_loss ▁▃▁▁▃▃▁█▆▁▁▁▆▆▁█▁▃▁▃▁▁██▁▃▁▃▁▃▁▃▁█▃▁▃▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▁▃▁▃▁▃▁█▁▃▃▆▃▁▁▆▁▁▁▃▃▁█▃▃█▃▃▁█▃▆▁▃▃▁▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72678
wandb: best/eval_avg_mil_loss 1.04811
wandb:  best/eval_ensemble_f1 0.72678
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.89621
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.84809
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.47335
wandb:      train/ensemble_f1 0.47335
wandb:         train/mil_loss 0.8855
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rwtoclxk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153358-rwtoclxk/logs
wandb: Agent Starting Run: 8ueq2x3t with config:
wandb: 	actor_learning_rate: 1.596364095498354e-06
wandb: 	attention_dropout_p: 0.3183584670477771
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 190
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8661150503849179
wandb: 	temperature: 8.014207731196166
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153455-8ueq2x3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ueq2x3t
wandb: uploading history steps 82-102, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄█▂▁▃▇▁▂▁▃▇▄▁▃▄▄▂▆▁▄▅▇▃▁▃▃▂▂▆█▆▆▁▇▁█▇▇▃▁
wandb:      eval/avg_mil_loss ▁▅█▁▂▁▂▂▇▂▂▂▂▁▂▂▁▂▂▁▇▂▂▂▃▁▂▁▂▂▂▂▂▂▁▂█▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▅▃██▁▁▃▃█▄▇▁▁▄█▄▄▄▇▃▁▃▁▄█▄██▁▁▁▂█▁▁▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▂▁▄▄▆▁▃▆▃▃▃▄▃▄▂▃▃▃▃▃▂█▂▅▃▇▁▅▃▅▂▄▅█▃▂▆
wandb:      train/ensemble_f1 ▇▄▄▆█▅▄▅▇▅▄▆▃▃▄▆▄▃▆▃▆▄▃▄▃▅▃▅▁▅▆▅▆▅▅▆▃█▅▆
wandb:         train/mil_loss ▁▂▄▅▄▁▁▆▂▆█▁▄▂█▂▅▅▁▇▂▄▅▁▄▂▄▃▄▅▅▁▁▁▁▂▆▅▂▄
wandb:      train/policy_loss ▃▃▅▃▁█▃▃▅██▅▃▁▅▁▃█▁▆▃▅▅█▁▅█▃██▁▅▁▃▅▅▅▃▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▃▄▆▃█▃▄▄█▃█▄▄▁▃▄▁█▆▄▄█▁▃▃▄▄▁█▁▄▁▃▄▄▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.40161
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.98911
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81416
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.64875
wandb:      train/ensemble_f1 0.64875
wandb:         train/mil_loss 1.58537
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ueq2x3t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153455-8ueq2x3t/logs
wandb: Agent Starting Run: 9y90ih6s with config:
wandb: 	actor_learning_rate: 5.262448508095421e-06
wandb: 	attention_dropout_p: 0.4189504744935662
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2366543660941257
wandb: 	temperature: 7.288494217073359
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153618-9y90ih6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9y90ih6s
wandb: uploading history steps 103-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁███
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁███
wandb:            eval/avg_f1 ███▁▇███▄▆▁▆▆▄▆▆██▁▆▂▄▇▁▃▁▁▆▆▄▆▁▁█▁▁▁▃▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▁▅▂▃▂▂▂▂▂▂▂▂▂▂▃▂▂▃▂▂▇▂▂▂▂▂▇▂▂▂▅█▂▂
wandb:       eval/ensemble_f1 ▁█▃█▁██▁▄█▇▆▁▁▆▁▄▁▁▆▁▇██▁▁▆▆▆▁▁▁▁▁▃▁▁▄▁▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▃▄▅▄▄▃▇▅▄▄▃▅▆▃▆▅▅█▃▃▃▅▄▅▃▄▅▂▃▅▅▄█▁▄▆▅
wandb:      train/ensemble_f1 ▆▇▃▅▄▅▅▇▅▄▃▃▅▁▃▄▅▂▆▅▂▅▄█▅▆█▅▃▂▄▆▃▅▅▃▄▂▅▃
wandb:         train/mil_loss ▇▃▄▂▂▃▃▂▃▅▆▄▂▅▂▂▂▃▂▄▃▄▃▃▂▃▂█▃▂▁▄▂▃▆▅▃▅▃▄
wandb:      train/policy_loss ▃▃▄▄█▄▃██▄▁▃▃▁▃▁▄▄▃█▄▃▄█▄▃▃▁▄█▄▃▁▄▄█▄█▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▅▅██▁▃▁▃▅▁▅▃▃█▅▅▅▅▅█▅█▃▅█▁▅█▃▃▁▅▅▅▃▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.69166
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.22054
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.56469
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.5964
wandb:      train/ensemble_f1 0.5964
wandb:         train/mil_loss 0.88304
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9y90ih6s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153618-9y90ih6s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4un08c9y with config:
wandb: 	actor_learning_rate: 2.79025700162169e-06
wandb: 	attention_dropout_p: 0.3912636708309283
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5766044877690557
wandb: 	temperature: 2.496122525677107
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153803-4un08c9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4un08c9y
wandb: uploading history steps 102-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▁▆▇▂▁▆▆▃▅▆▁▁▁▄▆▆▃▆▁▁▁▁▂▄▆▄▁▁▆█▅▆▆▆▄▇▁▆▁▃
wandb:      eval/avg_mil_loss ▅▅▁▅▁▂▆▁▁▂▁▁▅▅▆▅▂█▁▁▂▇▃▁▆▆▂▁▂▁▁▂▂▁▂▂▆▁▁▆
wandb:       eval/ensemble_f1 ▇▅▄▆▆▂█▁▂▁▁▆▆▆▁▆▄▁▅▆█▁▆▄▁▁▆▁▇█▂▁▆▆▄▁▇▆▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▄▅▃▄▄▆▆▇▅▁▄▅▆▅▄▅▁▄▅▁█▂▁▃▂▄▃▄▆▄▄▃▅▁▅▁▄▄
wandb:      train/ensemble_f1 █▅▄▄▃▅▅▆▃▂▆▇▂▅▅▄▆▃▆▆▆▃▂▅▃▅▂▄▆▄▅▃▆▃▃▅▆▁▆▅
wandb:         train/mil_loss ▂▂▂▁▆▃▁▅▆▁▃▄▇▄▇▂▄▅▂█▂▅▄▃▃▄▂▇▅▄▂█▂▇▅▆▁▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82957
wandb: best/eval_avg_mil_loss 0.39826
wandb:  best/eval_ensemble_f1 0.82957
wandb:            eval/avg_f1 0.77965
wandb:      eval/avg_mil_loss 0.74461
wandb:       eval/ensemble_f1 0.77965
wandb:            test/avg_f1 0.76979
wandb:      test/avg_mil_loss 0.78879
wandb:       test/ensemble_f1 0.76979
wandb:           train/avg_f1 0.63467
wandb:      train/ensemble_f1 0.63467
wandb:         train/mil_loss 2.48787
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4un08c9y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153803-4un08c9y/logs
wandb: Agent Starting Run: n6qrhm8k with config:
wandb: 	actor_learning_rate: 2.508217620135532e-06
wandb: 	attention_dropout_p: 0.4234665557055411
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 193
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6687800735635306
wandb: 	temperature: 0.7428952980328618
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153937-n6qrhm8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n6qrhm8k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃███
wandb: best/eval_avg_mil_loss █▇▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃███
wandb:            eval/avg_f1 ▂▄▂▂▁▁▄▁▃▃▄▁▃▄▄▃▃▂▃▃▃▂▄▂▁▄▃▃▂▃▄█▃▃▄▃█▄▇▃
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▁▃▃▁▃▃▁▄▃▄▄▄▂▂▃▁▁▃▃▃▃▁▁▃▁▃▁▄▃█▄▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▅▁▂▄▂▂▂▃▅▂█▂▅▂▄▁▃▃▁▂▃▁▃▂▄▂▂▂▂▅▃▄▄▄▄▁▇
wandb:      train/ensemble_f1 ▃▁▂▂▂▂▃▂█▂▁▃▃▄▃▂▁▁▂▅▃▂▃▄▃▃▂▂▂▃▅█▃▂▂▂▅▅▆▂
wandb:         train/mil_loss ▂▃▁▂▂▃▁▂▂▁▂▃▁▂█▃▂▁▃▂▃▆▂▂▂▂▂▂█▂▂▂▁▂▂▂▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80983
wandb: best/eval_avg_mil_loss 0.54353
wandb:  best/eval_ensemble_f1 0.80983
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.74494
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.76801
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.51112
wandb:      train/ensemble_f1 0.51112
wandb:         train/mil_loss 0.75465
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n6qrhm8k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153937-n6qrhm8k/logs
wandb: Agent Starting Run: f8t37coa with config:
wandb: 	actor_learning_rate: 4.520814313025385e-06
wandb: 	attention_dropout_p: 0.3739876824951285
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8252751709522856
wandb: 	temperature: 0.49818678037264474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154201-f8t37coa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8t37coa
wandb: uploading history steps 102-122
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▃▃▁▄▅▆▇▃▃█▄▁▁█▇▁▄▆▃▁▄▄▁▅▇▁▁██▃█▃▃▆▃▆▄▄▄█
wandb:      eval/avg_mil_loss ▄▁█▂▆▁▂▁▁▃▁▇▁▅▁▅▂▁▂▂▆▁▅▁▂▂▇▁▁▁▁▂▆▁▂▁▁▁▁▂
wandb:       eval/ensemble_f1 ▃▃▃▁▁▆▂▃▁▃▁▄▇▁█▇▇▃▄▁▄▄▄▃▅▁▁▆█▄▄▆▃▄▁▄▇▄▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▇▅▅▃▂█▂▄▄▄▆▄▃▄▄▅▅▅▁▅▄█▁▂▄▁▇▄▅▅▂▂▂▂▅▃▃
wandb:      train/ensemble_f1 ▅▄█▅▂▆▅▃▂▅▅▆▄▁▄▃▃▃▅▁▂▃▄▁█▃▆▄▃▆▇▂▅▇▂▆▃▆▅▇
wandb:         train/mil_loss ▂▆▂▁▅▂▃█▂▂▄▂▂▃▄▃▂▂▁▅▆▅▄▄▂▂▃▆▅▃▄▂▁▁▆▁▂▁▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78375
wandb: best/eval_avg_mil_loss 0.79337
wandb:  best/eval_ensemble_f1 0.78375
wandb:            eval/avg_f1 0.77263
wandb:      eval/avg_mil_loss 0.7936
wandb:       eval/ensemble_f1 0.77263
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79895
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.53974
wandb:      train/ensemble_f1 0.53974
wandb:         train/mil_loss 1.79006
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8t37coa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154201-f8t37coa/logs
wandb: Agent Starting Run: z3jqufty with config:
wandb: 	actor_learning_rate: 1.90594364963394e-06
wandb: 	attention_dropout_p: 0.23901354576263545
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.843367794529837
wandb: 	temperature: 2.1697886368356234
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154339-z3jqufty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z3jqufty
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆█▆█▅▅▅▆▅▃▂▁▂▁▃▇▆▆▁▇▆▁▆▃▅▅▂▆▆▅▆▇▂▃▄▆▅▆▇▆
wandb:      eval/avg_mil_loss ██▄▁▁▁▁▁█▂▁▁▁▂▁▄▂▁▁▁▁▂▄▁▁▁▁▁▁▁▄▁▂▁▁▂▁▁▁▂
wandb:       eval/ensemble_f1 █▇▂▆▅▁▆▆▄▄▆▃▆▂▂▆▆▆▆▆▅▇▆▆▆▅▆▆▇▂▄▆▄▂▆▇▅▆▆▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃█▂▂▂▄▃▁▃▃▂▅▅▄▃▁▃▄▃▂▂▃▂▁▃▃▆▃▆▂▄▃▄▄▂▄▃▃
wandb:      train/ensemble_f1 ▃▃▁▃▄▂█▃▃▃▃▂▃▄▃▂▃▄▄▁▂▃▃▆▄▅▄▅▄▅▂▆▂▂▁▄▄▃▂▂
wandb:         train/mil_loss ▂▂▃▂▄▆▁▂▂█▁▆▂▄▂▄▃▁▁▂▂▂▁▂▁▂▂▂▁▂▂▂▂▂▂▂▁▃▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 2.4943
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.98691
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.52257
wandb:      test/avg_mil_loss 2.41817
wandb:       test/ensemble_f1 0.52257
wandb:           train/avg_f1 0.49582
wandb:      train/ensemble_f1 0.49582
wandb:         train/mil_loss 0.86121
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z3jqufty
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154339-z3jqufty/logs
wandb: Agent Starting Run: dyvcqzye with config:
wandb: 	actor_learning_rate: 4.1037572970069186e-06
wandb: 	attention_dropout_p: 0.44608382477441866
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7788030901503668
wandb: 	temperature: 1.414706303866642
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154502-dyvcqzye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dyvcqzye
wandb: uploading history steps 142-143, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▅▆█
wandb: best/eval_avg_mil_loss ▆█▄▃▁▇▂
wandb:  best/eval_ensemble_f1 ▁▂▄▅▅▆█
wandb:            eval/avg_f1 ▃▁▁▁▁▆▁▆▆▁▆█▄▁▅▆▇▁▃▆▁▆▁▁▁▁▁▆▁▆▁▃▄▁▄▃▆▁▁▁
wandb:      eval/avg_mil_loss ▁▃▁▂▁▂▁▁▁▃▁▆▂▁▁▁▇▁▁▂▁▁▁▁▂▂▂▃▁▂▂█▁▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▁▁▄▁▁▆▁▃▁▃▆▄▄▁▁▁▄▁▁▇▃▁▃▁██▁▇▁▁▆▁▄▄▄▁▆▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▅▇█▅▄▇▅▅▄▅▅▅▆▄▂▆▆▂▅▆▆▂▅▂▆▇▇▂▃▆▂▃▆▁▂▂
wandb:      train/ensemble_f1 █▆▂▂▄▄▆▆▇▅▃▆▅▆▁▅▆▅▆▆▁▅▆▆▂▆▅▄▇▄▄▄▆▄▆▅█▃▇▆
wandb:         train/mil_loss ▁▆▂▃▂▂▁▅▅▅▃▄▇▂▁▃▆▂▃▂▁▂▄▃▆▂█▅▃▂▆▂█▂▁▅▇▁▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79798
wandb: best/eval_avg_mil_loss 0.71236
wandb:  best/eval_ensemble_f1 0.79798
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04063
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 0.90758
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.49063
wandb:      train/ensemble_f1 0.49063
wandb:         train/mil_loss 0.9982
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dyvcqzye
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154502-dyvcqzye/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qzuv1zh6 with config:
wandb: 	actor_learning_rate: 1.029102178996167e-06
wandb: 	attention_dropout_p: 0.2656887020699451
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6333791515551304
wandb: 	temperature: 5.1736010057209665
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154701-qzuv1zh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzuv1zh6
wandb: uploading history steps 142-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇██
wandb: best/eval_avg_mil_loss █▃▃▄▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇██
wandb:            eval/avg_f1 ▃▃▁▃▁▁▃▁▃▆▄▁▇▃▃▁▁▁▁▁▄▁▁▁▃▃▁▁█▁▃▁▁▄▄▂▆▁▄▃
wandb:      eval/avg_mil_loss ▁▁▁▂▁▂▂▁▂▃▁▁▁▃█▅▂▃▁▁▁▁▄▁▁▁▁▁▁▃▃▁▁▁▁▁▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▃▁▁▃▁▁▁▄▁▁▄▃▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁█▃▁▁▁▄▂▃▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▅▂▂▃▅▄▁▃▃▄▄▆▅▃▇▃▇▃▄▂▃█▄▄▄▂▄▄▄▅▄▃▃▃▄▄▅
wandb:      train/ensemble_f1 ▄▆▆▃█▆▅▅▃▅▄▄▅▃▅▅▅▂▆▇▁▃▃▅▇▄▃▄▁▇▅▅▄▄▆▄▇▂▄▅
wandb:         train/mil_loss ▂▂▂█▃▃▅▃▂▄▁▂▁▂▃▁▅▂▆▄▂▁▂▃▃▂▁▂▁▄▇▁▄▂▃▂▄▃▄▂
wandb:      train/policy_loss ▃▃▃▃▁▃▁▃▁▃▃▃▃▃▃▃▁▃▃▁▃▁▃▃▃▃▃▃▃█▃▁▁▃▃▃██▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▁▃▃▃▁▁▃▃▃▃▃▃▃▆▃▃▃█▃▁▃▃▁▃▃█▃▃▁▁▃▃█▃▁██▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.56627
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.71717
wandb:      eval/avg_mil_loss 1.0852
wandb:       eval/ensemble_f1 0.71717
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.77725
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.49424
wandb:      train/ensemble_f1 0.49424
wandb:         train/mil_loss 1.05961
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzuv1zh6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154701-qzuv1zh6/logs
wandb: Agent Starting Run: qzxdmvuj with config:
wandb: 	actor_learning_rate: 4.383427956366539e-06
wandb: 	attention_dropout_p: 0.17061652788445353
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 132
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4150673731931538
wandb: 	temperature: 4.197146879674753
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154855-qzxdmvuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzxdmvuj
wandb: uploading history steps 124-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▄▅▆▆█
wandb: best/eval_avg_mil_loss ▇▃▂▂▁█▅▁
wandb:  best/eval_ensemble_f1 ▁▁▄▄▅▆▆█
wandb:            eval/avg_f1 ▁▁▅▁▅▅▁▃▄▂▅▅▅▆▃▁▆▅▁▂▅▅▅▂▁▁▄▄█▁▂▃▂▅▄▅▁▆▄▁
wandb:      eval/avg_mil_loss ▆▃█▃▂▂▂▂▃▂▃▃▂▃▂▁▅▂▃▃▂▂█▂▃▅▂▂▁▂▇▁▂▃▂▂▂▂▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▆▃▇▁▇▅▂▁▇▇▁▆▆▂▆▁▅▆█▁▆▆▇██▆▂▃▅▆▁▁▄▇▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▄▅▅▅▁▆▃▇▃▃▆▄▄▇█▃▇▅▂▅▂▃▇█▅▄▄▆▂▃▃▃▆▃▃▄▃▅
wandb:      train/ensemble_f1 ▆▃▄▄▄▅▂▇▃▄▃▂▄▂▃▁▄▄▂▇▆▃▄▃▅▅▂▆▄▂▄█▄▃▆▇▃▂▄▃
wandb:         train/mil_loss ▂▂▅▇▅▇▁▂▂▃▂▁▃█▅▃▁▄▇▁▂▁▂▁▃▁█▂▁▂▁▁▇▂▆▇▁▁▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.69448
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.9968
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.82347
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.51442
wandb:      train/ensemble_f1 0.51442
wandb:         train/mil_loss 0.94156
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qzxdmvuj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154855-qzxdmvuj/logs
wandb: Agent Starting Run: e0dpo0am with config:
wandb: 	actor_learning_rate: 0.0007528841454982433
wandb: 	attention_dropout_p: 0.2233895976430305
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4782371850586265
wandb: 	temperature: 5.7844097408431505
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155038-e0dpo0am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0dpo0am
wandb: uploading history steps 136-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▆▆█
wandb: best/eval_avg_mil_loss ▇▃█▇▁▁
wandb:  best/eval_ensemble_f1 ▁▄▆▆▆█
wandb:            eval/avg_f1 ▂▂▂▃▃▆▃▂▃▃▄█▇▂▇▅▄▃▅▂▇▁▆▆▃▃▄▂▂▃▂▂▃▃▁▆▃▂▄▄
wandb:      eval/avg_mil_loss ▂▁▅▄▁▁█▄▁▂▆▁█▁▂▁▁█▁▂▁▃▁▁▁▁▁▄▂▂▅▁▁█▆▂▁▁▅▁
wandb:       eval/ensemble_f1 ▂▆▂▂▃▃▂█▄▁▄▄▃▁▂▂▂▂▄▅▆▂█▄▆▆█▃▁▁▂▃▅▃▃▂▁▄▃▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▂▆▄▅▇▄▁▃▆▄▃▇▆▄▁▄▇▆▄▆▅▇█▄▄▆▁▅▅▅▃▆█▆▄▄▇▅
wandb:      train/ensemble_f1 ▆▆▅▅▁▅▅▃▄▄▄▃█▆▃▅▄▄▄▆█▃▂▄▄▃▅▂▁▄▂▄▆▆▄▆▃▅▅▅
wandb:         train/mil_loss ▃█▁▃▃▂▄▁▄▁▄▁▁▃▁▃▅▃▁▂▅▅▂▅▁▁▂▄▂▂▄▁▅▅▂▆▅▄▂▅
wandb:      train/policy_loss ▅▄▁▅▆▅▄▄▆▅▄▅▃▅▁▅▅▆▅▅▅▆▅▄▅▄▅▄▅▆▁▅█▃▅▁▅▅▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▆▄▆▄▄▁▁▄▃▄▄▄▄▄▅▆▄▄▄▃▆▆▄▆▅▆█▅▄▄▄▆▄▄▄▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76942
wandb: best/eval_avg_mil_loss 0.61674
wandb:  best/eval_ensemble_f1 0.76942
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.80731
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.80225
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.57412
wandb:      train/ensemble_f1 0.57412
wandb:         train/mil_loss 1.62755
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e0dpo0am
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155038-e0dpo0am/logs
wandb: Agent Starting Run: 4bg689uz with config:
wandb: 	actor_learning_rate: 2.794228055527735e-05
wandb: 	attention_dropout_p: 0.13219969777966034
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38755845472244554
wandb: 	temperature: 5.89460962415146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155243-4bg689uz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4bg689uz
wandb: uploading history steps 61-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇▇███
wandb: best/eval_avg_mil_loss ▄▇▁▂██▆
wandb:  best/eval_ensemble_f1 ▁▄▇▇███
wandb:            eval/avg_f1 ▆▃█▆▃▆█▃▆█▇▅▇▄███▆█▆▅█▁▅▅▅█▃█▆█▆█▃▆█▃▆█▃
wandb:      eval/avg_mil_loss ▁▂▂▁▂▁▁▂▂▁▂▂▂▁▁▁▁▂▁▂▂▁▂▅▁█▃▂▂▁▃▁▂▁▅▂▁▂▁▂
wandb:       eval/ensemble_f1 ▅▂▇▆▂█▇▂▂▆▇▆▇█▂▅▆█▆██▄▅█▂▆▄▆█▂▆▂█▁▂█▆▄▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▄▄▇▄▅▅▇▆▆▇▆▃▄▄▅▅▇▆▆▇▇▇▆▆▆▅▄▇▆▆▁▆▄▆▅█▇▇
wandb:      train/ensemble_f1 ▆▇▆▄▆▇▄▅▇▆▇▆▄▃▆▆▄▄▅▇▆▅▇▇▆▆▅▄▇▆▄▆▆▁▄▅▄█▇▇
wandb:         train/mil_loss ▄▂▁▅▅▂▅▁▄▃▄▅▇▄▅▂▂▂▂▆▂▁▇▆▅▃▃▂▂▅▄▂█▄▁▃▄▂▁▃
wandb:      train/policy_loss ▄▄█▄▁▄██▄▄█▄▄███▄▄▄▃█▄█▄▃▄▄▄▁▁▁▄▄██▁▄▁▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄█▄██▁▄▄█▄▄█▄▄██▄▄▃█▄█▄▃▄▄▄▄▁▃▄▄▄▄█▁▄▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.68458
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.95311
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.81439
wandb:      test/avg_mil_loss 0.4219
wandb:       test/ensemble_f1 0.81439
wandb:           train/avg_f1 0.75431
wandb:      train/ensemble_f1 0.75431
wandb:         train/mil_loss 0.83017
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4bg689uz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155243-4bg689uz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jj8f2p4j with config:
wandb: 	actor_learning_rate: 3.089346752359428e-06
wandb: 	attention_dropout_p: 0.4798046776846951
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 72
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7833033101838902
wandb: 	temperature: 4.820540989832788
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155345-jj8f2p4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jj8f2p4j
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▆▆▇█
wandb: best/eval_avg_mil_loss ▄▇▃█▃▄▁▂
wandb:  best/eval_ensemble_f1 ▁▂▃▄▆▆▇█
wandb:            eval/avg_f1 ▃▁▁▁▃▄▄▃▄▄▄▁▇▁▁▁▄▃▁▄▇▅▇▄▁▂▄▇▅▁▆▄▁▁█▁▇▁▇▁
wandb:      eval/avg_mil_loss ▂█▃▁▁▁▁▂▁▂▁▂▆▂▃▂▁▂▂▁▂▂▁▂▁▂▂▁█▂▂▂▁▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▃▁▄▄▄▃▄▄▁▃▁▂▁▄▁▁▆▃▅▁▂▄▆▄▁▆▁▁▁▄▁█▁▆▁▆▃▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▁▄▃▃▅▆▆▆▃▃▅▂▄▄▆▄▃▂▁▆▄▃▂▂█▅▃▄▂▃▇▅▃▂▄▆▁▆
wandb:      train/ensemble_f1 ▃▁▄▃▅▇▆▄▆▁▃▄▂▅▄▂▄█▄▂▄▂▃▂▂▆▄▃▄█▃▅▄▅▃▂▃▅▆▂
wandb:         train/mil_loss ▂▂▂▁█▁▁▂▄▅▁▁▁▁▂▆▂▁▁▁▂▂▂▁▂▁▁▁▁▂▁▃▁▁▁▁▂▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.73574
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.06474
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78512
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.63375
wandb:      train/ensemble_f1 0.63375
wandb:         train/mil_loss 1.03138
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jj8f2p4j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155345-jj8f2p4j/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: l5mkq7bz with config:
wandb: 	actor_learning_rate: 0.0002779384196721401
wandb: 	attention_dropout_p: 0.18277347385164008
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8772512385477814
wandb: 	temperature: 1.633219629266239
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155452-l5mkq7bz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l5mkq7bz
wandb: uploading history steps 124-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁█
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▆▁█▇█▂▄▇▁▁█▄▁▅▂▄▅▄▄▁▄▄▇▅▄▄▅▁▄▁▁▅▅▁▅▃▄▅▅
wandb:      eval/avg_mil_loss ▁▂▁▂▁▁▁▁▁▂█▁▄▂▂▂▂▂▁▁▂▁▁▂▁▁▂▂▁▂▂▁▂▂▁▁▂▅▂▂
wandb:       eval/ensemble_f1 ▄█▄▄▇█▄▁▇▄▄▄▅▁▄▄▁▇▄▄▄▄▄▁▄▇▄▄▄▁▄▁▁▄▅▄▃▄▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▆▄▄▄▅▄▄▄▅▅▆▂▂▄▆▃▂▅▅▅▄▂▃▅▅▁▄▅█▆▃▆▃▆▅▅▅
wandb:      train/ensemble_f1 ▃▅▅▄▅▂▄▄▄▅▅█▃▆▇▂▂▆▆▅▄▅▄▂▇▅▃▆▆▁▆▇▃▇▇▃▆▇▆▆
wandb:         train/mil_loss ▂▂▂▄▄▁▁▂▄▁▁▂▂▂█▂▁▂▂▂▂▄▂▂▂▃▁▂▂▂▂▃▁▃▂▁▂▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68286
wandb: best/eval_avg_mil_loss 0.90693
wandb:  best/eval_ensemble_f1 0.68286
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.9071
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.83721
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.58479
wandb:      train/ensemble_f1 0.58479
wandb:         train/mil_loss 1.37263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l5mkq7bz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155452-l5mkq7bz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xusehhzb with config:
wandb: 	actor_learning_rate: 2.552508497449383e-06
wandb: 	attention_dropout_p: 0.4299997770311543
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4012778955385753
wandb: 	temperature: 7.263563930556055
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155641-xusehhzb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xusehhzb
wandb: uploading history steps 102-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇██
wandb: best/eval_avg_mil_loss █▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▇▇██
wandb:            eval/avg_f1 ▄▁▃▇▇▃▂▇▇▇▃▆▁▆▇▅▃█▃▁▂██▇▄▇▆▇▁▇▇▆▇▁██▃▇█▁
wandb:      eval/avg_mil_loss ▁▁▃▁▁▅▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▂▁▁▁▁▁▁▁▂▁█▁▃▁▁
wandb:       eval/ensemble_f1 ██▆▁██▇▃▁▇▇▆█▁█▆▆▆▇▆▅▁▇▃█▆▆▇▇▅▆█▃▇▁▇▆██▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▆▄▅█▄▃▅▆▅▃▆▆▇▅▄▄▅▄▅▅▆▆▁▄▅▅▅▃▆▆▆▃▄▄▅▆▆▆
wandb:      train/ensemble_f1 ▇▃█▃▅▄▆▄▅▆▅▃▄▆▄▃▂▃▄▄▄▄▃▆▅▅▄▆▇▅▂▆▄▆▂▁▃▆▅▆
wandb:         train/mil_loss ▃▄▁█▁▂▃▄▁▁▁▁█▃▂▁▂▃▁▄▂▂▂▁▁▂▁▁▁▂▂▁▃▁▁▂▄▃▁▃
wandb:      train/policy_loss ▅▁▁▁▅▁▁▅▅▅▁█▅▁▁▅▅▁▃▅▃▁█▅▃▃█▃█▅▁▁▁▁▅▃▃▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▁▅▁▁▅▅▅▅█▁█▁▁▁▁▅▃█▃▃▁█▃▅▅█▁▁▁▃██▅▃▁▁▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83838
wandb: best/eval_avg_mil_loss 0.62792
wandb:  best/eval_ensemble_f1 0.83838
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.42414
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.79475
wandb:      test/avg_mil_loss 0.49942
wandb:       test/ensemble_f1 0.79475
wandb:           train/avg_f1 0.7577
wandb:      train/ensemble_f1 0.7577
wandb:         train/mil_loss 1.34212
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xusehhzb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155641-xusehhzb/logs
wandb: Agent Starting Run: bvxsxg50 with config:
wandb: 	actor_learning_rate: 4.916039065636204e-06
wandb: 	attention_dropout_p: 0.33663539533325687
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8731813867026635
wandb: 	temperature: 2.3113248221107794
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155809-bvxsxg50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvxsxg50
wandb: uploading history steps 164-177, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆▇█
wandb: best/eval_avg_mil_loss ▇▇▁██
wandb:  best/eval_ensemble_f1 ▁▅▆▇█
wandb:            eval/avg_f1 ▁▁▅▇▁▁▁▄▁▆▁█▁▅▅▃█▄▂▅█▇▄▄▁▁▂▁▁▁▆▇▁▁▇▇▅▅▇▁
wandb:      eval/avg_mil_loss █▂▁▂▃▂▃▃▄▄█▁▂▃▄▃▆▇▁▅▃▂▁▃▂▅▂▃▂▃▄▂▄▃▂▃▂▂▂▄
wandb:       eval/ensemble_f1 ▁▁▂▇▇▁▆▁▁▁▁▅▁▂▅▅▁▆▁▁▁▅▁█▃▁█▁▁▆▁▄▁▇▁▇▄▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▅▂▂▂▂▇█▅▄▁▃▇▅▄▄▁▂▆▆▇▃▃▃▅▄▃▅▂▄▇▃▄▅▆█▅▃▄
wandb:      train/ensemble_f1 ▇▄▆▅▆▆▂▁▂▄█▇▄▅▂▂▆▄▅▄██▆▄▂▁▄▄█▆▅█▅▅▄▄▅▄▅▇
wandb:         train/mil_loss ▃█▅▂▄▂▄▄▆▄▄▃▅▄▄▄▅▃▄▂▂▁▂▆▃▅▃█▃▂▃▂▁▂▄▄▃▃▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.69507
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 0.8224
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.65278
wandb:      test/avg_mil_loss 0.89516
wandb:       test/ensemble_f1 0.65278
wandb:           train/avg_f1 0.51074
wandb:      train/ensemble_f1 0.51074
wandb:         train/mil_loss 1.17839
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvxsxg50
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155809-bvxsxg50/logs
wandb: Agent Starting Run: 871lcl4y with config:
wandb: 	actor_learning_rate: 3.3435433945651128e-06
wandb: 	attention_dropout_p: 0.3535681931454638
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7982275526247716
wandb: 	temperature: 1.3190036929428706
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160024-871lcl4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/871lcl4y
wandb: uploading history steps 144-161, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄██
wandb: best/eval_avg_mil_loss ▇▇█▂▁
wandb:  best/eval_ensemble_f1 ▁▄▄██
wandb:            eval/avg_f1 ▃▁█▁▁▁▃▂▁▁▁▆▁▁▁▃▆▂▃▁▆▂▁▃▃▃▁▃▁▁▆▁▁▁▂▂▁▃▁▁
wandb:      eval/avg_mil_loss ▁▁▂█▁▁▁▃▃▂▂▁▅▁▁▁▂▁▂▄▁▁▄▂▁▁▁▁▁▄▂▅▁▁▄▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁██▂▁▃▁▁▄▃▁▁▃▃▁▄▂▃▁█▁▁▁▄▄▁▄▃▁▄█▁▁█▁▄▁▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▇▄▄▃▄▄▄▄▄▄▄▂▇▃▆▃▅▅▅█▄▅▄▄▄▅▇▄▂▁▁▄▃▃▅▄▅▇
wandb:      train/ensemble_f1 ▄█▄▅▄▄▅▄▄▄▅▄▃▆▆▄▆▅▆▅▄▃▃▅▄▂▄▁▇▆▂▆▄▅▃▅▄▅▄▆
wandb:         train/mil_loss ▃▃▂▃▁▃▄▂▃▂▁▁▅▃▄▃▄▁▃▃▂▁▁▃▅▂▁▁█▂█▆▄▄▃▄▅▁▂▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80998
wandb: best/eval_avg_mil_loss 0.58308
wandb:  best/eval_ensemble_f1 0.80998
wandb:            eval/avg_f1 0.63958
wandb:      eval/avg_mil_loss 0.63482
wandb:       eval/ensemble_f1 0.63958
wandb:            test/avg_f1 0.65781
wandb:      test/avg_mil_loss 1.16546
wandb:       test/ensemble_f1 0.65781
wandb:           train/avg_f1 0.60608
wandb:      train/ensemble_f1 0.60608
wandb:         train/mil_loss 0.92368
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/871lcl4y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160024-871lcl4y/logs
wandb: Agent Starting Run: 5423pbc2 with config:
wandb: 	actor_learning_rate: 1.2247818522421711e-05
wandb: 	attention_dropout_p: 0.4220145226011585
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 140
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9085746079538252
wandb: 	temperature: 0.6436414537209334
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160228-5423pbc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5423pbc2
wandb: uploading history steps 103-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▇▆▇▇▆▆▄▁█▆▆▆▇▆▆▂▇█▁▆▆▄▂▆█▆▇▆█▆█▇▆▆█▆▆▆█▆
wandb:      eval/avg_mil_loss ▃▃▂▂▄▇▂▂▁▁▁▂▂▂▂▁▂▁▃▄▂▁▂▂▃█▂▃▂▁▁▃▁▁▁▆▃▂▃▁
wandb:       eval/ensemble_f1 ▆▆▆▆▆█▄▁▆█▄▆▇▆▆▇▄▄▆▆▂█▆█▆▆▇▆▆▆▇▇▇▂▆█▇█▆▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▆▆▇▇▆▇▇▅▅▆▅▆▆▇▇▃▇▆▆▅█▄▇█▄▆▃▇█▃▅▇▇▇▁▄▇
wandb:      train/ensemble_f1 ▆▅▅▇▆▆▆▆▆▇▄▆▂▅▁▂█▅▅▄▆▃▆▃▄▄▆▆▁▅▅▄▆▇▆▄▆▅▁█
wandb:         train/mil_loss ▂▄▇▃▁▂▃▃▃▆▁▇▃▇▄▅▇▂▂▁▃▇▄▇▃▄▃▁▂█▃▂▃▃▃▆▃▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82957
wandb: best/eval_avg_mil_loss 0.63006
wandb:  best/eval_ensemble_f1 0.82957
wandb:            eval/avg_f1 0.81935
wandb:      eval/avg_mil_loss 0.58454
wandb:       eval/ensemble_f1 0.81935
wandb:            test/avg_f1 0.60728
wandb:      test/avg_mil_loss 0.67956
wandb:       test/ensemble_f1 0.60728
wandb:           train/avg_f1 0.8125
wandb:      train/ensemble_f1 0.8125
wandb:         train/mil_loss 1.11009
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5423pbc2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160228-5423pbc2/logs
wandb: Agent Starting Run: l7q26vrw with config:
wandb: 	actor_learning_rate: 4.6695354998838905e-05
wandb: 	attention_dropout_p: 0.27471807290387823
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7831135903284152
wandb: 	temperature: 1.317745872646231
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160400-l7q26vrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l7q26vrw
wandb: uploading history steps 82-97, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▅▃▁▁█▁▃▇▄▁▄▄▄▁▁▁▄▁▁▇▅▆▇▁▁▃▁▁▁▂▄▁▇▁▁▁▁▁▇
wandb:      eval/avg_mil_loss ▂▂▁▆▁▁▁▆▇▁▅▆▃▂▃▃▁▂▇▃▂▂▁▁▂▇▂▂▃▃▂▅█▂▂▂▁▃▁▅
wandb:       eval/ensemble_f1 ▁▅▃▁▁▃▁▁▁▁▄▄▆▁▁▁█▇▇▁▅▁▃▁▇▁▁▆▂▇▁▃█▁▇▁▂▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▁▄▅▅▅▅▃▅▆█▁▂▄▄▄▁▆▅▃▄▅▁▃▁▄▄▄▂▅▄▅▃▄▂▅▇▃▄
wandb:      train/ensemble_f1 ▆▆▄▁▇▄▂▅▆█▁▅▆▅▅▁▆▆▂▂▃▆▆▂▄▇▂▅▅▂▄▆▂▄▅█▅▂▅▄
wandb:         train/mil_loss ▁▁▅▅▄▃▅▂▂▆▆█▄▃▂▂▃▃▇▆▅▃▆▅▂▆▃▂▆█▅▃▂▃▄▁▆▃▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.66879
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.81549
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 0.91436
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.55095
wandb:      train/ensemble_f1 0.55095
wandb:         train/mil_loss 2.51105
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l7q26vrw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160400-l7q26vrw/logs
wandb: Agent Starting Run: w76fvloj with config:
wandb: 	actor_learning_rate: 1.8375859724968203e-06
wandb: 	attention_dropout_p: 0.49992572050703143
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7506866063129048
wandb: 	temperature: 0.07283757663807955
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160518-w76fvloj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w76fvloj
wandb: uploading history steps 164-170, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁████
wandb: best/eval_avg_mil_loss █▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁████
wandb:            eval/avg_f1 █▃▆▃▅▅▃▁▆▃▁▆▆█▇▆▆▂█▁▇█▆█▆█▆▁▂▁▆▁▆█▆▆█▃█▆
wandb:      eval/avg_mil_loss ▂▅▂▅▄▄▃▅▄▆▃▄█▆▄▆▂▂▃▄▃▂▂▅█▆▂▂▇▅▅▆▃▆▄▁▄▁▁▃
wandb:       eval/ensemble_f1 ▁██▄▃▃▂▃▃▁▃▃█▁▃▇▆▆▁▆▃▅▂█▃▆▆▆▆██▁▃▇▁█▃█▁▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▆▂▄▆▄▅▆▄▁▄█▆▄▇▄▆▄▆▅▂▆▆▄▆▇▆▂▆▄▅▃▆▆▃▂▅▆
wandb:      train/ensemble_f1 ▇▃▃▇▅▆▁▄▅▃▇▄▄▆▇▅▅█▃▅▇▅▄▆▇▆▆▇▃▇▅▅▂▃▄▇▄▅▅▆
wandb:         train/mil_loss ▅▆▅▅▆▃▄▆▆▅▄▃▄▆▅█▆▄▂▇▅▇▃▅▁▅▂▆▆▄▄▅▃▆▄▆▃▄▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80983
wandb: best/eval_avg_mil_loss 0.54133
wandb:  best/eval_ensemble_f1 0.80983
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 0.77922
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.90225
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.69261
wandb:      train/ensemble_f1 0.69261
wandb:         train/mil_loss 0.95404
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w76fvloj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160518-w76fvloj/logs
wandb: Agent Starting Run: fqn016c4 with config:
wandb: 	actor_learning_rate: 5.225113925130554e-06
wandb: 	attention_dropout_p: 0.4544680349220891
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 173
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8534959107688214
wandb: 	temperature: 0.286305978168675
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160727-fqn016c4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqn016c4
wandb: uploading history steps 164-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇██
wandb: best/eval_avg_mil_loss ▄█▅▃▁▃
wandb:  best/eval_ensemble_f1 ▁▄▅▇██
wandb:            eval/avg_f1 ▃▆▃▁▇█▁█▁▁▇▆▁▆▆▂▁▇▇▇▁▇█▁▇▃▁▇█▃▃█▆█▃▁▇▆▇▂
wandb:      eval/avg_mil_loss ▂▂▂▂▂█▂▂▂▁▂▂▂▁▁▂▂▃▁▂▁▃▂▁▂▂▂▁▂▁▁▂▁▁▃▁▂▁▂▂
wandb:       eval/ensemble_f1 ▇▃▇██▇▁▁▁▅▅▁▁▁▅▆▄▁█▃▁▆▃▇▇▆▁▇▆▃▃█▄█▃█▆▆▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▁▅▄▅▆▄▃▂▄▂▅▄▅▆█▇▃▅▆▅▄▅▆▇▁▅▆▅▆▅▆▄▄▆▅▆▆▅
wandb:      train/ensemble_f1 ▇▅▃▅▇█▅▄▅▃▅▅▆▅▇▅▅▇▆▆▅▇▁▇▄▄█▆▆▇▄▆▆▄▇▄▅▁▇▆
wandb:         train/mil_loss ▂▁▂▂▂▁▄▂▁▁▇▇▂▂▁▄▁▂▂▂▂▂▂▁▂▁▂▂█▂▂▂▂▃▁▂▂▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.71958
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.80906
wandb:      eval/avg_mil_loss 0.60349
wandb:       eval/ensemble_f1 0.80906
wandb:            test/avg_f1 0.76068
wandb:      test/avg_mil_loss 0.44601
wandb:       test/ensemble_f1 0.76068
wandb:           train/avg_f1 0.66133
wandb:      train/ensemble_f1 0.66133
wandb:         train/mil_loss 0.8997
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fqn016c4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160727-fqn016c4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2n7w5kc3 with config:
wandb: 	actor_learning_rate: 1.0815344130058224e-06
wandb: 	attention_dropout_p: 0.3161902553591848
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6385060466627829
wandb: 	temperature: 0.11999603371909862
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161010-2n7w5kc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2n7w5kc3
wandb: uploading history steps 102-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 █▃▂▃▃▄▁▅▆▂▂▂▇▃▃▅▃▃█▃▆▆▆▃▃▁▂▃▂▄▃▅▆▇▃▃▃▇▆█
wandb:      eval/avg_mil_loss ▁▂▂▂▂▁▁▄▃▆▂▂▅▂▂▃▂▂█▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▆▁
wandb:       eval/ensemble_f1 ▆▃▂▇▁▄▃▇▅▂█▆▂▂▂▃▃▃▃█▆▃▆▃▇▃▄▃▇▃▆▇█▆▃▆▁▇▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▄▄▅▄▆▆▇▅▆▄▄▁▄▅▃▄▆▃▅▄▄▂▅▅▆▅▇▅▄▂▄▆▅▁▅█▄
wandb:      train/ensemble_f1 ▃▄▄▅▆▆▂▇▆▁▃▅█▅▆▅▆▄▄▆▄▅▃▅▄▅▄▂▇▅▂▄▆▄▆▅▄▄▄▁
wandb:         train/mil_loss ▃▃▂▁▁▃▄▃▅▁▅█▃█▂▂▂▄▃▁▄▃▁▃▃▂▁▂▆▂▄▄▃▂▆▃▁▃▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.67607
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.79928
wandb:      eval/avg_mil_loss 0.58581
wandb:       eval/ensemble_f1 0.79928
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 7.12661
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.50015
wandb:      train/ensemble_f1 0.50015
wandb:         train/mil_loss 1.53743
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2n7w5kc3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161010-2n7w5kc3/logs
wandb: Agent Starting Run: 1t5001ms with config:
wandb: 	actor_learning_rate: 1.3695236700194829e-06
wandb: 	attention_dropout_p: 0.22150476592141127
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3945651863016464
wandb: 	temperature: 0.2849601014937697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161133-1t5001ms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t5001ms
wandb: uploading history steps 143-152, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▇█
wandb: best/eval_avg_mil_loss ▅█▅▁▅
wandb:  best/eval_ensemble_f1 ▁▂▅▇█
wandb:            eval/avg_f1 ▁▁█▁▇▁▁▁▇▁▁▁▁▇▇▁▁▇▇▁▁█▇▁▁▁▁▁▁▁▆▁▇▁█▂▁▇▁▁
wandb:      eval/avg_mil_loss ▁▅▂▃▅▃▂▇▁▃▁▁▁▆▄▁▆▇▁▁▃▃▁▃▃▁▃▂▆▇▄█▃▃▄▆▁▃▄▂
wandb:       eval/ensemble_f1 ▁▁▇▃▁▁▁▁▁▁▁▆▄▇▆▁▁▆▃▆▁▁▇▇▁▇█▆▁▆█▁▁▁▁▇▁▁▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▇▃▂▆▆▇▄▅▅▂▇▂▅▅▁▁▆▅▁▁▄▄▂▅▅▂▃▁▇█▆██▁▁▅▂▇
wandb:      train/ensemble_f1 ▅▁▄▂▄▂▁▁█▅▂▁▄▇▅▃▂▅▂▂▂▁▇▅▅▅▁▄▅▂▇▂▇▂▇▂▃▇▂▆
wandb:         train/mil_loss ▄▅▄▂▇▁▂▃▃▇▃▂▃▄▂▅▁▃▄▃▄▅▃▂▅▃█▃▄▂▃▂▃▄▃▄▃▃▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.74928
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.71754
wandb:      eval/avg_mil_loss 0.60034
wandb:       eval/ensemble_f1 0.71754
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.04628
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.6404
wandb:      train/ensemble_f1 0.6404
wandb:         train/mil_loss 2.79842
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1t5001ms
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161133-1t5001ms/logs
wandb: Agent Starting Run: 2b437ete with config:
wandb: 	actor_learning_rate: 1.2440353575992569e-06
wandb: 	attention_dropout_p: 0.48441220197263185
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 118
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9676014900975204
wandb: 	temperature: 0.3625980752068503
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161332-2b437ete
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2b437ete
wandb: uploading history steps 103-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▇▇██
wandb: best/eval_avg_mil_loss █▆▅▁▅▄▃
wandb:  best/eval_ensemble_f1 ▁▂▃▇▇██
wandb:            eval/avg_f1 ▄▃▂▁▁▃▆▅▁▄▁▅▄▂▄▂▃█▄▁▁▁▃▂▃▄▅▄▁▁▁▁▃▃▃▂▅▇▁▄
wandb:      eval/avg_mil_loss ▁▇▇▁▁▁▁▁▁█▁▂▁▅▁▂▁▁▁▅▁▁▂▁▁▁▁▁▁▁▁▂▇▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▇▃█▃▄▆▅▃▁▃▃▃▃▁▃▃▄▃▁▂▂▃▃▃▃▃▁▅▁▃▁▁▄▂▁▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▁▆▃▇▃▃▂▆▆▃▁▂▇▃▃▂▅▄▂▂▄▁█▇▄▂▃▂▆▃█▄▁▅▅▇▇
wandb:      train/ensemble_f1 ▃▆▅▅▂▃▂▄▃▃▃▃▄▄▆▃▅▇▇▃▃▇▃▇▆▆▇▆▂▄▁▄▆▆█▄▃▂▅▅
wandb:         train/mil_loss ▁▁▃▂▅▁▆▂▂▁█▇▂▄▂▁▁▁▂▁▄▂▄▄▁▃▂▁▁▄▁▁▂▁▁▁▁▃▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.72686
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 1.00498
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78251
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.59607
wandb:      train/ensemble_f1 0.59607
wandb:         train/mil_loss 0.89528
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2b437ete
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161332-2b437ete/logs
wandb: Agent Starting Run: ywry0kwv with config:
wandb: 	actor_learning_rate: 2.34043319380573e-06
wandb: 	attention_dropout_p: 0.41347083740626606
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9180949070265452
wandb: 	temperature: 0.2701191179751783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161505-ywry0kwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ywry0kwv
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▃
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▃█▃▅▃▃▆▁█▅▁▁▃▁▃▆▁▆▁▆▇▃▁▇▇▁▄▃▃██▅▁▄▆▁█▅█
wandb:      eval/avg_mil_loss ▂▁▁▂▁▂▁▁▄▂▂▁█▁▁▁▁▂▁▂▂▃▁▂▁▂▂▁▁▁▁▁▆▁█▁▁▂▂▇
wandb:       eval/ensemble_f1 ▄█▃▄█▃▃▁▅▁▄▇▃▁▃▄▆▆▇▃▆▇▄▁▅▁▁▄▇▃▃▃▁▁█▄▆▁██
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▃▆▃▅▆▄▄▇▄▇█▃▆▆▅▄▄▄▃▄▅▅▆▇▁▄▄▄█▇▅▅▆▄▃▃▆
wandb:      train/ensemble_f1 ▄▅▆▅▅▅▄▄▃▆▅▇█▄▃▄▆▇▃▇▆▄▄▃▃▇▂▃▄▂▆▅▅▃▁▆▆▁▆▆
wandb:         train/mil_loss ▂▆▅▁▂▁▂▁▁▁▂▂▃▁▃▂▂█▂▃▂▂▂▅▁▂▁▂▂▁▂▂▆▂▂▁▁▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.6964
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.8616
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.81193
wandb:      test/avg_mil_loss 0.44955
wandb:       test/ensemble_f1 0.81193
wandb:           train/avg_f1 0.38901
wandb:      train/ensemble_f1 0.38901
wandb:         train/mil_loss 1.15061
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ywry0kwv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161505-ywry0kwv/logs
wandb: Agent Starting Run: cetqxixk with config:
wandb: 	actor_learning_rate: 0.00015108258506036764
wandb: 	attention_dropout_p: 0.1184267668953468
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 180
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8528255017719717
wandb: 	temperature: 4.339710568173931
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161628-cetqxixk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cetqxixk
wandb: uploading history steps 121-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄▅▆█
wandb: best/eval_avg_mil_loss █▄▃█▄▄▁
wandb:  best/eval_ensemble_f1 ▁▁▂▄▅▆█
wandb:            eval/avg_f1 ▃▃▅▄▅▂▁▃▄▅▆▄▄▄█▃▁▄▃▂▃▃▃▃▄▃▆▄▁▄▃▄▄▃▃▃▃▃▄▃
wandb:      eval/avg_mil_loss ▃▃▃▃▃▆▃▃▃▆▁▃▃▃▁▁▃▄▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃█▃▃▃▃▃▆
wandb:       eval/ensemble_f1 ▅▄▄▄▃▅▅▆▃█▆▅▄█▄▃▂▄▄▄▃▁▃▄▃▄▄▆▄▁▃▁▄▄▃▄▄▄▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▃▃▅▂▅█▁▂▂▃▄▅▃▂▇▅▁▂▆▃▄▂▃▃▆▃▆▃▄▂▁▂▂▄▃▆▅▂
wandb:      train/ensemble_f1 ▃▂▂▃▁▃▄▄▃▅▅▂▄▅▆▂▇▃▁▃▇▇▄▁▇▅▁▃▇▃█▆▃▁▂▂▆▆▄▇
wandb:         train/mil_loss ▂▃▂▂▂▂▂▂▁▃▂▃▃▆▂▃▃▃▃▇▃▄▃▂▄▂▄▃▃▃▄▄▃▃▃▂█▂▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75845
wandb: best/eval_avg_mil_loss 0.57646
wandb:  best/eval_ensemble_f1 0.75845
wandb:            eval/avg_f1 0.48718
wandb:      eval/avg_mil_loss 1.49806
wandb:       eval/ensemble_f1 0.48718
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.81312
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.49451
wandb:      train/ensemble_f1 0.49451
wandb:         train/mil_loss 0.87659
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cetqxixk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161628-cetqxixk/logs
wandb: Agent Starting Run: 5klbotbo with config:
wandb: 	actor_learning_rate: 1.1806156558908e-06
wandb: 	attention_dropout_p: 0.19458092911157043
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06850263909201093
wandb: 	temperature: 0.4076331045903592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161816-5klbotbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5klbotbo
wandb: uploading history steps 102-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss █▇▂▁
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▅▅██▃▇██▃▃▅█▆█▅▇█▅▃▂▇▃▅▆▆▅█▃▁█▂█▅▇▃▂▅▂█▆
wandb:      eval/avg_mil_loss ▂▁▁▁▂▂▁▄▅▂▂▂▁▂▂▁▂▃▁▁▂▁▂▂▄▁▂█▁▂▁▅▁▁█▂▂▄▄▂
wandb:       eval/ensemble_f1 █▅█▃▂▂▂▃▃▂▆█▅█▆▆▅█▅▆▆▇▂█▅▁█▅██▅▇▃█▂▅▂██▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▅▆▅▆█▅▂▅▇▇▆▄▆█▆▆▇▃▅▅▆▅▃▅▆▄▇▅▇█▅▅▃▁▃▅▇
wandb:      train/ensemble_f1 ▆▆▃▅▆▅▆▆▇▆▅▆▆▇▇▄▇▅▆▄▆▆▆▆▃▇▅▄▄▅▇▅▅▅█▄▁▄▅▅
wandb:         train/mil_loss ▂▇▅▃▂▄▂▆▄▂▃█▄▂▂▂▃▄▂▂▃▂▁▂▂▆▃▃▂▂▁▂▃▆▁▂▃▂▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.56971
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.72678
wandb:      eval/avg_mil_loss 0.83756
wandb:       eval/ensemble_f1 0.72678
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.77281
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.72011
wandb:      train/ensemble_f1 0.72011
wandb:         train/mil_loss 0.99893
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5klbotbo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161816-5klbotbo/logs
wandb: Agent Starting Run: w70meucj with config:
wandb: 	actor_learning_rate: 0.00010376549411308532
wandb: 	attention_dropout_p: 0.4296940269047786
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 173
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.782679030984578
wandb: 	temperature: 0.017176599553538896
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161940-w70meucj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w70meucj
wandb: uploading history steps 163-174, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇██████
wandb: best/eval_avg_mil_loss █▅▄▂▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▇██████
wandb:            eval/avg_f1 ▅▂▂▆▁▆▇▂▆▁▁▁▁▁▁▄▁▅▁▅█▃▁▇▁▂█▂█▄▂▂█▅█▁▅▅▆▅
wandb:      eval/avg_mil_loss ▆▆▂▃▁▃▂▁▁▂▅▄▆▁█▇▄▃▁▄▃▁▁▂█▂▇▁▃▁▃▂▃▂▄▂▂▂▃▃
wandb:       eval/ensemble_f1 ▅▂▃▁▂▃▂▆▁▁▁▅▂▁▄▁██▂▄▇▁▁▇▁▆▂█▁▅▁▅▄▁█▂▆█▆▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▅▁▇█▅▆▅▆▄▅▅▃▄▃▄▅▅▅▄▄▇▇▁▅▆▂▆▄▆▆▇▄▅▂█▇▇▅
wandb:      train/ensemble_f1 ▂▆▃▅▄▄▅▆▆▄▇▅▄▅▄▇▂▅█▇▃▆▄▆▁▇▅▇▇▆▇▆▂▇█▄▂▁▆▅
wandb:         train/mil_loss ▄▂▂▂▅▅▃▂▆▁▄▄█▄▂▄█▄▄▃▅▄▄▄▄▃▃▆▇▅▇▆▂▇▅▄▄▁▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.58235
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 1.96272
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.36886
wandb:      test/avg_mil_loss 2.17228
wandb:       test/ensemble_f1 0.36886
wandb:           train/avg_f1 0.70288
wandb:      train/ensemble_f1 0.70288
wandb:         train/mil_loss 3.14249
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w70meucj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161940-w70meucj/logs
wandb: Agent Starting Run: b715cbhl with config:
wandb: 	actor_learning_rate: 2.136613942422986e-06
wandb: 	attention_dropout_p: 0.1277113812138269
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3727053829548213
wandb: 	temperature: 0.3563200555544921
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162154-b715cbhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b715cbhl
wandb: uploading history steps 163-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ██▄█▆▄▁█▄▁▆██▆▃▁▄▇█▂▃▁▁▆▁▆▄▅▅█▃█▇▇█▅▁██▄
wandb:      eval/avg_mil_loss ▄▁▂▂▁▄▅▃█▁▁▁▁▅▁▁▁▁▁▅▂▂█▁███▂█▁▁▄▁▂▁▂▁▁█▁
wandb:       eval/ensemble_f1 ██▇▄▅▆▅▄▂█▅▄▁▁█▆▁▄▄▇▁█▄▆▁█▅▇█▅▄▇▄▃▂▆▄▅▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇█▆▇▃▆▅▅▇▆▆▄▃▆▄▆▆▆▃▅▇▄▅▄▇▇▆▇▆▆▂▁▆▄▃▄▇▅
wandb:      train/ensemble_f1 ▅█▄▇▄▆▃▆▃▄▅▃▆▆▄▇▅▄█▇▆▃▆▇▄█▅▅▆▅▃▆▅▁▆▆▇▆▃▅
wandb:         train/mil_loss ▂▁▁▂█▃▁▃▃▁▇▃█▂▁▂▇▁▃▄▁▁▂▇▂▇▃▁▆▂▃▅▅▁▁▃▄▁▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.67659
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.65986
wandb:      eval/avg_mil_loss 0.74224
wandb:       eval/ensemble_f1 0.65986
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.40721
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.66256
wandb:      train/ensemble_f1 0.66256
wandb:         train/mil_loss 1.56088
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b715cbhl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162154-b715cbhl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0m6y70bw with config:
wandb: 	actor_learning_rate: 1.2175887854683242e-06
wandb: 	attention_dropout_p: 0.15838938787166912
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.703304492043074
wandb: 	temperature: 0.2333270800140752
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162418-0m6y70bw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0m6y70bw
wandb: uploading history steps 143-161, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▅▇█
wandb: best/eval_avg_mil_loss █▄▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▅▇█
wandb:            eval/avg_f1 ▂▄▄▁▂▃▅▃▇█▂▃▅▄▃▂▂▅▄▄▇▁▇▅▂▅▅▃▁▃█▃█▁▃▂▅▇▄▇
wandb:      eval/avg_mil_loss ▄▄▂▂▂▂▂▂▂▂▂▆▂▂▂▂▂▂▃▂▅█▅▄▂▃▂▁▅▂▂▂▂▅▂▂▂▂▁▂
wandb:       eval/ensemble_f1 ▂▄▂▂▇▂▅▃▁▂▃▂▂▆▅▂▂▃▅▂▄▃▃▂▇█▇▄█▃▁▂▁▆▂▂▁▁▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▄▇▁▄▁▃▆▃▂▃▃▆▆▂▅▄▅▃▃▄▄▅▃▆▃▂▄▃▇█▅▄▄▅▄▃▃
wandb:      train/ensemble_f1 ▅▅▃█▆▅▁▁▄▄▃▃▃▃▃▂▇▄▄▄▃▃▇▅▅▅▅▄▄█▆▃▅▃▄▄▅▃▄▇
wandb:         train/mil_loss ▄▁▅▄▃▃▃▃▆▁▃▅▁▃▃▄▁▃▂▄▃▃▂▃▃▄▁▃▃▁▃▄█▃▂▄▂▃▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83974
wandb: best/eval_avg_mil_loss 0.47214
wandb:  best/eval_ensemble_f1 0.83974
wandb:            eval/avg_f1 0.56854
wandb:      eval/avg_mil_loss 1.72286
wandb:       eval/ensemble_f1 0.56854
wandb:            test/avg_f1 0.4579
wandb:      test/avg_mil_loss 1.62804
wandb:       test/ensemble_f1 0.4579
wandb:           train/avg_f1 0.62349
wandb:      train/ensemble_f1 0.62349
wandb:         train/mil_loss 1.47064
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0m6y70bw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162418-0m6y70bw/logs
wandb: Agent Starting Run: m29fdft7 with config:
wandb: 	actor_learning_rate: 2.855353606017962e-06
wandb: 	attention_dropout_p: 0.16884853169998482
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24631740864148
wandb: 	temperature: 2.3865554846721393
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162623-m29fdft7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m29fdft7
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▁▃▂▁▁▁▁▆▁▁▁▁▃▅▁▁▅█▅▃▅▁▁▇▂▄▂▅▃▁▁▁▃▃▄▁▇▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▇▁▂▁▁▄▁▂▁▃▁▁▃▁▂▄█▁▁▁▄▁▂▂▅▁▁▂▄▄▁▁▁▁▄
wandb:       eval/ensemble_f1 ▁▃▁▁▁▂▂█▁▅▃▁▁▁▃▁▁▂▁▁▁█▁▁▂▇▁▁▄▂▁▃▁▁▃▁▂▁▄▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▆▃▂▆▇▂▅▆▁▆▂▆▆▂▅▆▇▅▆█▅▄▆▅▆▆▅█▆▁▆▅▂▇▇█▅▅
wandb:      train/ensemble_f1 ▅▆▆▇█▇▁▇▆▆▆▆▆▆▆▂▇▆▇▇▆▇▆▇▆▄▅▆▅▆▄▆▆▆▆▄▇▅▆▂
wandb:         train/mil_loss ▂▂▁▁▂▂▃▂▁▇▆▄▂▂▂▂▂▄▂▄▁▂▂▃▃▁▆▇▂▂▃▄▅▂▂█▂▂▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62667
wandb: best/eval_avg_mil_loss 0.74548
wandb:  best/eval_ensemble_f1 0.62667
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.88422
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.82356
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.4772
wandb:      train/ensemble_f1 0.4772
wandb:         train/mil_loss 1.22326
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m29fdft7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162623-m29fdft7/logs
wandb: Agent Starting Run: mdnixeg2 with config:
wandb: 	actor_learning_rate: 9.002113626587744e-06
wandb: 	attention_dropout_p: 0.47586753262276615
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8574215155088493
wandb: 	temperature: 4.045112822507554
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162801-mdnixeg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdnixeg2
wandb: uploading history steps 142-147, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▇▇█
wandb: best/eval_avg_mil_loss █▃▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▄▄▇▇█
wandb:            eval/avg_f1 ▅▁▄▁▂▁▁▅▁▁▄▇▂▃▁▁▇▄▃▆█▁▃█▁▁▃▃▆▂▂▃▅▁▃▄▁▁▄▇
wandb:      eval/avg_mil_loss ▂▃▁▃▄▃▃█▃▆▂▃▆▂▂▃▂▂▇▆▂▄▇▃▂▃▇█▆▆▂▆▃▄▅▃▅▆▃▂
wandb:       eval/ensemble_f1 ▅▆▁▃▄▅▂▃▇▁▁▇▂▁▁▅▇▁▇▃▁▁▃█▁▇▃▂▃▂▂▁▁▃▁▁▁▂▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▆▅▅▅▆▅▆▆▂▄▅█▆▅▅▄▄▆▅▄▅▅▆▄▅▆▄▃▅▇▅▆▅▇▆▄▆▅
wandb:      train/ensemble_f1 ▅▃▃▂▄▄▄▆▃▂▅▅▄▄▄▄▃▃▃▅▃▄▅▁▄▂▄▃▂▅▄▁▃▄▄▅▃█▇▄
wandb:         train/mil_loss ▂▂▂▃▃▂▁▅▅▄▄▅▄▄▄▃▄▃▃▃▃▂▂▃▅▅▃▄▄▃▂▃▃█▄▅▂▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84998
wandb: best/eval_avg_mil_loss 0.53322
wandb:  best/eval_ensemble_f1 0.84998
wandb:            eval/avg_f1 0.51645
wandb:      eval/avg_mil_loss 0.96231
wandb:       eval/ensemble_f1 0.51645
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.83573
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.54324
wandb:      train/ensemble_f1 0.54324
wandb:         train/mil_loss 1.04961
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mdnixeg2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162801-mdnixeg2/logs
wandb: Agent Starting Run: 63q000fr with config:
wandb: 	actor_learning_rate: 3.1974816623728216e-06
wandb: 	attention_dropout_p: 0.3368585389314146
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 170
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7580758946049158
wandb: 	temperature: 0.14221112587871287
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162954-63q000fr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63q000fr
wandb: uploading history steps 141-160, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▄▇▇█
wandb: best/eval_avg_mil_loss █▄▃▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▃▄▇▇█
wandb:            eval/avg_f1 ▇▄▁▁▄▁▁▄▁▁▂▁▁▇▇▂▁▁▃▂▁▁▁▁▁▁▂▁▁▄▁▁▁▃▁█▁▇▂▁
wandb:      eval/avg_mil_loss ▄▂▂▂▂▃▂▁▂▂▂▂▂▂▁▂▁▂▂▂▂▄▁▂▂▁▂▂▁▂▁▂▂▂▂▂▂▂▂█
wandb:       eval/ensemble_f1 ▄▇▁▁▇▄▂▁▁▃▁▁▁▂▁▁▁▁▁▁▄▁▁▂▁▅▁▂▁▁▃▁█▇▁▁▁▁▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▄▅▁▄▂▇█▆▇▆█▇▁▆█▄▇▅▄▁█▄▆▇▆▁▆▆▁▄▆▇▂▆▇▅▇▁
wandb:      train/ensemble_f1 ▄▂▆█▅▅▂█▃▁▅▄▁▄▅▄▅▂▄▃▆▅▅▆▆▂▂▆▅▅▄▇▄▆▄▅▆▆▁▁
wandb:         train/mil_loss ▂█▃▂▁▃▆▃▄▂▅▆▃▂▁▇▅▄▂▇▆▇▂▇▃▁▁▂▂▆▄▂▅▅▂▃▂▂▆▂
wandb:      train/policy_loss ▁▃▆▅▃█▅▅▆█▆▅▃▃▃▆▆▃▁▅▃▅▃▃▃▅▅▆▃▃▁▆█▃▃▃▃▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▁█▃▆▃▄▃▄▆▃▃▆▄▃▃▆▄▃▄▃▃▃▄▃▄▃▃▄▃█▃▆▄▄▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.69959
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.92104
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.3555
wandb:      test/avg_mil_loss 0.81275
wandb:       test/ensemble_f1 0.3555
wandb:           train/avg_f1 0.41897
wandb:      train/ensemble_f1 0.41897
wandb:         train/mil_loss 0.92296
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/63q000fr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162954-63q000fr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f82ofjsr with config:
wandb: 	actor_learning_rate: 2.9957912139917324e-06
wandb: 	attention_dropout_p: 0.05473570696218477
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05568146509551186
wandb: 	temperature: 1.9373170100600556
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163220-f82ofjsr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f82ofjsr
wandb: uploading history steps 143-158, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss █▆▁▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▁▃▁▁▁█▇▁▅▁██▁▆█▇▁▇█▁▁▂▁▁█▇▇▂▃▁▁▇▆▁▅▃▁▁█▁
wandb:      eval/avg_mil_loss ▄▁▃▁▁▃▁▂▁▃▅█▁▆▃▄▄▃▄▃▁▂▄▂▁▁▂▃▁▃▃▆▂▄▃▃▂▃▂▁
wandb:       eval/ensemble_f1 ▁▄▇█▃▃▆▁█▂▆▁▁█▁▂▁▁▁▁█▁▁██▁▁▁▂▇▇▂▃▁█▆▁▂▃▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▅▄▇▄▅▃▆▄▇▅▅▇█▃▅▇▄▅▇▇▂▂▅▄▃▄▁▃▆▁▆▅▃▅▃▅▇▂
wandb:      train/ensemble_f1 ▅▆▃▄▅▆▅▆▆▆▅▆▁▇▅█▅▆▅▃▅▂▅▂▃▃▅▅▅▆▄▃▅▆▇▂▅▅▅▅
wandb:         train/mil_loss ▂▂▄▁▆▆▁▆▃▂▁▂▃▃▂▂▄▂▃▂█▂▃▃▂▇▄▂▂▁▁▂▃▂▁▂▂▅▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.71464
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.06402
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.82067
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.63727
wandb:      train/ensemble_f1 0.63727
wandb:         train/mil_loss 0.96274
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f82ofjsr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163220-f82ofjsr/logs
wandb: Agent Starting Run: 7b1up3w4 with config:
wandb: 	actor_learning_rate: 5.328321483600574e-06
wandb: 	attention_dropout_p: 0.1876959972370591
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 196
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37881592984223544
wandb: 	temperature: 3.087217178339011
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163423-7b1up3w4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7b1up3w4
wandb: uploading history steps 182-196, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▃▆▁▁▁▁▇▁▇▁▅▁▁▁▃▁▁▄▁▁▇▂▃▁▁▁▁█▇▄▁▁▇▁▅▁▁▂▁▇
wandb:      eval/avg_mil_loss ▁▃▂▂▂▁▂▁▂▂▄▁▄▂▁▂▂▂▄▁█▂▂▂▂▂▃▁▄▂▁▃▃▁▂▃▃▁▁▃
wandb:       eval/ensemble_f1 █▁▁▁▁▃▁▃▇▁▅▁▁▁▃▁▄▁▁▄▁▂▁▄▃▁▁▁█▁▁▁▅▅█▂▇▆█▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▅█▅▅▁▄▆▇▅▄▅█▄▄▃▅▂▄▆▇▅▇▂▆▅▇▅▅▆▆▇▅▄▄█▆▅
wandb:      train/ensemble_f1 ▂▄▅█▁▅▆▃▆▇▄▁▅▇▅▅▅▅▃▅▅▅▅▄▇▄▄▆▂▅▄▇▆▅▆▅▅▂▁▅
wandb:         train/mil_loss █▂▄▂▂▃▃▂▄▂▃▃▅▃▂▆▄▃▁▁▃▃▄▃▄▃▃▃▄▂▄▅▆▄▂▂▂▂▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.70682
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.70857
wandb:      eval/avg_mil_loss 1.06659
wandb:       eval/ensemble_f1 0.70857
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.929
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.60593
wandb:      train/ensemble_f1 0.60593
wandb:         train/mil_loss 2.51925
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7b1up3w4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163423-7b1up3w4/logs
wandb: Agent Starting Run: p3xzlow9 with config:
wandb: 	actor_learning_rate: 0.00047647275038529766
wandb: 	attention_dropout_p: 0.1989641613072809
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 193
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7888210425614149
wandb: 	temperature: 5.636005855866715
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163653-p3xzlow9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p3xzlow9
wandb: uploading history steps 153-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▄▂▆▅▂▇▁▆▃▇▅▄▁▃▅█▁▂▄▂▆▆▅▃▁▁▁▄▇▃▁▁▁▁▆▂▆▁▆
wandb:      eval/avg_mil_loss ▂▇▂▁▁▁▃▄▄▃▁▂▂▂▁▁█▂▂▄▂▃▄▃▂▇▇▂▄▄▅▃▇▁▂▂▂▇▂▁
wandb:       eval/ensemble_f1 ▅▁▄▆▇▂▁▇▁▁▁▁▁▅█▄▄▃▁▂▁▆▄▅▁▁▁▆▁▁▁▁▂▁▃▂▁▁▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆▅▅▄▅▄▄▃▅▅▃▄▄▆▇▃▇▄▄▁▆▅▁▅▅▅▂▅▆▃▆█▅▂▄▅▄▄
wandb:      train/ensemble_f1 ▆▄▆▅▄▃▇▂▅▄▆▆▄▅▆▅▆▆██▅▆▃▅▅▅▁▃▆▅▇▃▇▇▄▃▅▃▆▅
wandb:         train/mil_loss ▇▄▂▅▇█▂▂▆▆▃▄▅▄▅▂▁▅▄▆▇▅▄▃▅▇▇▄▅▅▅▄▄▂▃▁█▄▇▃
wandb:      train/policy_loss ▇▃█▄▅▆▆▅▅▅▅▅▅▁▅▅▆▅▄▅▆▆▃▃▄▆▅▃▆▅▄▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▇▄▅▅▇▃▅▇▆▃▇▅▅▄▁▅▅▅▃▅▇▇▃▇▅▅▅▇▇▅▅▅▅█▅▇▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.5135
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.58959
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.6532
wandb:      test/avg_mil_loss 1.10152
wandb:       test/ensemble_f1 0.6532
wandb:           train/avg_f1 0.5487
wandb:      train/ensemble_f1 0.5487
wandb:         train/mil_loss 1.91743
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p3xzlow9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163653-p3xzlow9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: by493s7k with config:
wandb: 	actor_learning_rate: 0.0007048861364412395
wandb: 	attention_dropout_p: 0.1730289855452818
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8111722301359874
wandb: 	temperature: 8.785597977476183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163908-by493s7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/by493s7k
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▅▇█
wandb: best/eval_avg_mil_loss █▅▇▄▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▅▇█
wandb:            eval/avg_f1 ▄▃▅▅▄▄▃▄▄▇▆▁▅▆▇▆▇▇▇▆▆█▄█▇▇▅▄▆▆▆▇▁▇▅▄▆▇▂▇
wandb:      eval/avg_mil_loss ▁▄▇▂▁▇▃▄▂▁▂▄▄▃▁▂▁▃█▁▂▂▄▂▇▁▁▁▃▂▇▁▃▃▂▃▁▂▇▂
wandb:       eval/ensemble_f1 ▇▄▅▄▃▆▃▄▄▁▆▅█▁█▆▁▄▆██▇▇▇▇▄▆▅█▄▅▆▅▅▇▇█▆▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▄▂▂▂▁▄▆▄▄▄▇▃▂▃▅▄▃▂▄▃▁▁▂▂▆▃▂▃▁▆▅█▅▃▆█▃
wandb:      train/ensemble_f1 ▄▅▃▇▂▆▆▆▄▆▁▇▆▅▄▆▄▅▃▆▅▄▆▅▆▄▃▅▇▆▆▄▆▅▆▃▆█▆▇
wandb:         train/mil_loss █▂▃▅▃▂▂▃▄▃▄▄▅▄▃▂▄▄▃▅▆▅▂▄▃▄▄▃▄▂▁▂▄▂▄▅▄▃▆▂
wandb:      train/policy_loss ▁▆▄▄▃▆▄▃▄▄▆▆▄▆▄▄▄▆▄▃█▃▅▆▃▆▆▄▃▄▃▄▆▅▅▆▃▆▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.49919
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.64583
wandb:      eval/avg_mil_loss 1.19957
wandb:       eval/ensemble_f1 0.64583
wandb:            test/avg_f1 0.43578
wandb:      test/avg_mil_loss 4.06419
wandb:       test/ensemble_f1 0.43578
wandb:           train/avg_f1 0.66379
wandb:      train/ensemble_f1 0.66379
wandb:         train/mil_loss 2.47968
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/by493s7k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163908-by493s7k/logs
wandb: Agent Starting Run: clkdzdqu with config:
wandb: 	actor_learning_rate: 0.000730003436547878
wandb: 	attention_dropout_p: 0.17072720397139485
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9512034246079752
wandb: 	temperature: 5.18213135301091
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164127-clkdzdqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/clkdzdqu
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▆▇▇▇▇▇█
wandb: best/eval_avg_mil_loss ▃█▂▂▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▆▇▇▇▇▇█
wandb:            eval/avg_f1 ▅▃▁▂▁▁▅▂▃▂▅█▁▇▁▁▇▇▇▇▅▄▃▇▆▇▆▆▄▇▇▃▅▆▅▂▇▃▁▄
wandb:      eval/avg_mil_loss ▆▁▄▃▂▇▂▆▃▅▂▆▁▂▃▅▄▂▁▂▅▃▁▁▂▂▃▂▄▄▁▇██▂▁▁▂▁▅
wandb:       eval/ensemble_f1 ▇▃▃▇▂▂▁▇▆▆▁▅▇█▁█▇▅▃▂▇▅█▇▁▅▁▄▇▇▆▇▇▄▅▁▅▂▇▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆█▅▅▁▇▅▆█▆▅▁▄▂▅▄▆▅▅▅▆▁█▅▆▃▇▃▁▄▆▄▅▆▅▆▃▅
wandb:      train/ensemble_f1 ▃▅▇▅▅▆▆▄▁▄▅▃▇▂▃▅▄▆▄▆▅▁▃▇█▅▅▂▁▃▅▅▅▄▄▃▅▄▄▄
wandb:         train/mil_loss ▂▂▄▃▃▄▃▂▅▃▃▇▇▁▄▇█▇▃▅▃▄▄▅▂▅▂▄▇▂▃▅▃█▇▂▂▇▇▂
wandb:      train/policy_loss ▆▆▄▄▄▆▇▆▆▃▄▄█▆▄▄▄▆▃▄▄▄▄▄█▆▃▄▄▄▁▄▆▄▄█▄▄█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▁▃▆▆▁█▆█▁▃▄▃██▁▃▆▃▃▃▃▃▂▂▃▃█▃▃▃▃▂▆▆▃▆▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85978
wandb: best/eval_avg_mil_loss 0.36173
wandb:  best/eval_ensemble_f1 0.85978
wandb:            eval/avg_f1 0.42827
wandb:      eval/avg_mil_loss 1.79936
wandb:       eval/ensemble_f1 0.42827
wandb:            test/avg_f1 0.53535
wandb:      test/avg_mil_loss 1.52693
wandb:       test/ensemble_f1 0.53535
wandb:           train/avg_f1 0.52638
wandb:      train/ensemble_f1 0.52638
wandb:         train/mil_loss 1.21186
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/clkdzdqu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164127-clkdzdqu/logs
wandb: Agent Starting Run: hmtwq4n1 with config:
wandb: 	actor_learning_rate: 5.534829598612651e-05
wandb: 	attention_dropout_p: 0.20521543126474612
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7160674950880636
wandb: 	temperature: 6.245857130601838
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164408-hmtwq4n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmtwq4n1
wandb: uploading history steps 135-153, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆▇█
wandb: best/eval_avg_mil_loss █▆▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆▇█
wandb:            eval/avg_f1 ▄▂▂▁▄▁▂▁▇▃▄▂▂▃▇▃▅▇▁▂▃▃▅▁▆▃▂▁▁█▁▁▁▇▆▁█▇▇▁
wandb:      eval/avg_mil_loss ▄▆▆▇▄▄▃▄▁▄▄▃▄▅▃▃▅▁█▆▂▄▂▅▄▄▃▃▆▂▇▄▃▆▄▇▃▂▄▂
wandb:       eval/ensemble_f1 ▃▅▁▁▂▁▁▇▂▁▄▂▃▄▃▅▆█▁▁▂▄█▂▁▁▃▄▃▇▁▂▁▂▂▄██▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▅▆▇▇▄▆█▅▄▆▂█▆▆▅█▅▆▅█▄▅▇▆▆▅▅▇▆▇█▆▅▇▆▆▁
wandb:      train/ensemble_f1 ▃▅▄▄▆▄▇▇▆▆▂▃▅█▅▇▅▆▇▆▄▆▅▆▇▆▇▇▆▇▃▃▆▄▃▇▇▅▄▁
wandb:         train/mil_loss ▄▅▅▄▅▅▅█▇▆▁▇█▅▄▅▄▄▆███▆▅▆▅▄▄█▆▆▂▅▅▇▃▇▂▄▅
wandb:      train/policy_loss ▅▆▅▅▅▄▆▅▅▆▅▅▃▃▅▁▅▃▆▅▅▅▅▃▅▅▅▅▂▄▅█▅▅▅▅▄▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅██▅██▂▁▇▅▂▅█▂█▅█▅▂▂▅▇▅▅▁▄▂▅▇▅▅▅▅▅▂█▄▅█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78897
wandb: best/eval_avg_mil_loss 0.72571
wandb:  best/eval_ensemble_f1 0.78897
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.53771
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.57464
wandb:      test/avg_mil_loss 2.42976
wandb:       test/ensemble_f1 0.57464
wandb:           train/avg_f1 0.50737
wandb:      train/ensemble_f1 0.50737
wandb:         train/mil_loss 3.601
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hmtwq4n1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164408-hmtwq4n1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5clr5drx with config:
wandb: 	actor_learning_rate: 1.888410633039754e-06
wandb: 	attention_dropout_p: 0.12955662751398506
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 160
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14894782159566833
wandb: 	temperature: 1.7138146002946608
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164632-5clr5drx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5clr5drx
wandb: uploading history steps 102-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▇█
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅▇█
wandb:            eval/avg_f1 ▁▂▇▆▂▆▁▆▂▅▂▆▁▆▂▄▄▁▁▁▂▅▂▂▆▂▆█▂▅▆▄▄▇▁▆▄▄▅▁
wandb:      eval/avg_mil_loss ▅▅▂▁▁▁▂▂▄▂▁▂▃▁▁▁▄▅▁▂▂▁▂▂▁▂▁▃█▂▁▂▁▁▁▄▁▁▂▁
wandb:       eval/ensemble_f1 ▂▂▅▁▂▄▁▇▆▂▁▆▁▅▄▆▁▁▄▆▁▁▄█▁▃▂▂▆▆▇▂▂▁▇▁▄▄▄▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▃▄▁▆▄▅▅▄▁▅▅▆▅▆▄▄▆▄▅▃▆▄▇▅▅▃▇▄█▅▆▄▆▄▅▆▇
wandb:      train/ensemble_f1 ▇▆▄▆▇▄▄▅▄▁▆▅▇▅▄▃▃▅▅▄▆▅▃▆▅▆▆▅▅▄█▄▅▆▅▆▄▅▇▇
wandb:         train/mil_loss ▅▄▁▁▅▁▃▂▅▂▃▆▆▁▄▃▃▁▆▃▁▁▂▃▄█▄▂▂▁▂▆▃▂▆▂▃▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.74224
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.38938
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81175
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.68114
wandb:      train/ensemble_f1 0.68114
wandb:         train/mil_loss 2.28095
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5clr5drx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164632-5clr5drx/logs
wandb: Agent Starting Run: 6q5zy9hd with config:
wandb: 	actor_learning_rate: 1.1010275333863476e-06
wandb: 	attention_dropout_p: 0.4471350000984176
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8866751787707314
wandb: 	temperature: 9.023471853293186
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164805-6q5zy9hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6q5zy9hd
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▆▆█
wandb: best/eval_avg_mil_loss ▇▇█▄▁
wandb:  best/eval_ensemble_f1 ▁▁▆▆█
wandb:            eval/avg_f1 ▁▂▁▁▂▂▁▂▁▁▁▁█▂▁▄▄▅▅▄▂▄█▂▂▁▃▃▂▂▅▁▂▅▇▂▂▁▄▄
wandb:      eval/avg_mil_loss ▄▄▄▄▄▄▅▅▄▄▄▄█▄█▄▄▄▄▃▂▂▃▄▂▃▄▄▄▃▄▄▄▇▄▁▄▄▅▄
wandb:       eval/ensemble_f1 ▁▇▂▃▃▁▃▁▃▁▅▅▂▁▅▁▅▃▁▃▃▃▂▃▁▆▄▅▆▂▃▁▃▁█▃▁▂▅▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▅▅▅▆▅▇▅▆▆▅▁█▁▅█▅▇▆▂▅▅▅▃▅▅▃▅▇▇▅▆▆▃▅▄▃▇▆
wandb:      train/ensemble_f1 ▃▄▁▅▅▇▄▆▄▃█▅▇▄▅▅▃▅▆▅▅▅▅▃▅▇▅▁▆▃▄▅▆█▅▁▄▂▄▆
wandb:         train/mil_loss ▅▆▅▂▄▇▅▄▄▅▄▂▅▄▄▃▅▅▃▃▂▃▄▁▆▅▅▃█▃▂▃▂▂▃▅▂▃▃▃
wandb:      train/policy_loss ▄▅▅▅█▅▅▅▃▇▅▅▆▅█▅▅▃▅▆▅▅▅▄▅▅▃▅▅▅▅▁▅▅▅▅▁▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▅▅▅▇▃▁▅▅▅▅▄▅▅▅▅▅▅▅▅▅▄█▅▁▅▁▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.6663
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.90635
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.66875
wandb:      test/avg_mil_loss 0.66572
wandb:       test/ensemble_f1 0.66875
wandb:           train/avg_f1 0.54865
wandb:      train/ensemble_f1 0.54865
wandb:         train/mil_loss 0.82875
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6q5zy9hd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164805-6q5zy9hd/logs
wandb: Agent Starting Run: q10ev6z2 with config:
wandb: 	actor_learning_rate: 1.7288989644485414e-06
wandb: 	attention_dropout_p: 0.34992153189251934
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 154
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3940738070166441
wandb: 	temperature: 8.222122123176835
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165005-q10ev6z2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q10ev6z2
wandb: uploading history steps 123-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅██
wandb: best/eval_avg_mil_loss ▃▂█▅▁▂
wandb:  best/eval_ensemble_f1 ▁▂▄▅██
wandb:            eval/avg_f1 ▆▅█▁▃▆▂▁▅▆▃▅▅▁▃▃▃█▃▁▆▅█▆▃▂▃▁█▁▄▃▇▇▃▅▇▁▇▄
wandb:      eval/avg_mil_loss ▁▂▁▇▁▁▂▁▂▂▁▇▁▁▁▁▁▂▁▁▁▂▁▁▁▁▂▅▁▁█▆▁▁▁▂▁▁▆▂
wandb:       eval/ensemble_f1 ▁▆█▂▄▆▂▄▁▇▄█▃▅▃▁▃▂▁▃▄▅▄▆▆▄▇█▃▄█▃▃▁▄▇▂▁▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▇▄▇▃▅▄▄▄▄▄▄█▆▁▅▅▃▄▄▇▇▃▃▄▃▃▇▄▄▆▄▆▆▄▅▄▅▅
wandb:      train/ensemble_f1 ▃▃▆▃▂▄▃▃▄▆▆▄▂█▅▆▄▁▄▇▂▂▅▂▂▄▆▆▇▆▆▁▆▅▆▅▃▆▅▅
wandb:         train/mil_loss ▂▁▄▁▂▆▆▃▆█▄▂▃▂▃█▄▁▂▆▅▃▃▆▁▃▃▂▄▅▆▁▃▃▃▃▃▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.72398
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.78743
wandb:      eval/avg_mil_loss 0.50523
wandb:       eval/ensemble_f1 0.78743
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.6957
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.63426
wandb:      train/ensemble_f1 0.63426
wandb:         train/mil_loss 1.78517
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q10ev6z2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165005-q10ev6z2/logs
wandb: Agent Starting Run: uymsrrea with config:
wandb: 	actor_learning_rate: 4.830311021776889e-05
wandb: 	attention_dropout_p: 0.046433559541685154
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05550850270109908
wandb: 	temperature: 5.503966951520713
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165143-uymsrrea
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uymsrrea
wandb: uploading history steps 101-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄████
wandb: best/eval_avg_mil_loss █▆▃▃▁▃
wandb:  best/eval_ensemble_f1 ▁▄████
wandb:            eval/avg_f1 █▆▄▁█▆▄█▃█▅█▁▃▄▅▆▃▆▅▆▅▂▇██▅█▆▄▁█▁▃▃▃▇▁▄▄
wandb:      eval/avg_mil_loss ▂▁▂▁▁▁▁▁▂▂▁▂▁▂▁▃▂▂▂▂▃▂▂▂▁▄▁▁▁▁▁▂▁▂▁▁▂█▂▁
wandb:       eval/ensemble_f1 ▁▁█▇█▆▃█▁█▆▇▄▆▄▃▁█▅▆▄▄▂▆▄▄▅▆█▃▆▁▇▅▁▁▆▁▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▃▅▂▁▆▆▁▂▇▅▅▃▆▁▃▄▄▇▄▅█▄▄▇▃▄▃▄▂▄▃▂▆▅▄▅▆
wandb:      train/ensemble_f1 ▂▆▄▁▄▄▃▆▅▆▃▂▇▆▂▅▃▂█▃▁▁▄▅▅▄▄▅▄▇▃▅▂▄▄▁▆▄▂▅
wandb:         train/mil_loss ▄▃▃▄▂▂▇▂▄▆▄█▅▅▂▄▆▃█▂▂▂▂▃▅▄▁▅▂▃▁▂▂▁▄▆▇▄▄▅
wandb:      train/policy_loss ▅▆▅▃▃▃▅▃██▁█▅▅▁█▅▅▃▅▅▅▅▅▃▁▅▃▃▁█▃█▅█▅▅███
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆█▃█▃██▃▅█▃█▅▅▁▅▅▅██▃▅▅▃▅▃▁▅▁▃█▃█▁▃▅▅██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.71262
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.91517
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.61948
wandb:      test/avg_mil_loss 0.62795
wandb:       test/ensemble_f1 0.61948
wandb:           train/avg_f1 0.58373
wandb:      train/ensemble_f1 0.58373
wandb:         train/mil_loss 1.10534
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uymsrrea
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165143-uymsrrea/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iikm2z9u with config:
wandb: 	actor_learning_rate: 0.0008905265678542012
wandb: 	attention_dropout_p: 0.00011905482426949332
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 78
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6572049340535421
wandb: 	temperature: 2.4973232602919992
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165326-iikm2z9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iikm2z9u
wandb: uploading history steps 77-79, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▂▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▃▁▆▃▃▁▂▄▅▃▁▁▄▇▂▄▇▃▁▃▆▇▆▃▆▂▂▆▇█▄▆▆▆▆▃▄▃▆▄
wandb:      eval/avg_mil_loss █▆▃▂▃▃▂▂▂▂▄▁▃▂▂▂▃▃█▄▂▃▂▂▂▂▂▂▁▂▄▃▁▂▃▂▂▂▁▃
wandb:       eval/ensemble_f1 ▃▁▄▃▆▂▄▅▇▄▁▇▇▇▄▅▅█▃▂▂▆▇▂▁▆▄▂▁▇▆▃▃▂▆▆▄▅▃▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▄▆▄█▅▅▄▅▂▆▆▄▇▇▂▅▂▄▄▅▄▅▅▄▂▅▄▅▁▃▅▃▅█▇▃▄
wandb:      train/ensemble_f1 ▄▆▃▄▁▇▄▆▅▇▅▆▅▆▃▇▇▆▇▁▄▆▅▅▅▅▆█▅█▃▇▃▄▅█▃▃▄▇
wandb:         train/mil_loss ▄▃▄▃▁▃▃▄▃▆▅▆▄▆▂▂▅▃▃▄▃▄▂▄▄▄▇█▃▃▁▅▄▅▅▅▃▃▅▂
wandb:      train/policy_loss ▄▅▆▁▄▄▆▁▄▄▅▄▆▅▅▄▄▄█▆█▄▇▅▄▄▆▄▆▄▃▃▆▄▄▄▃▄▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▆▄▁▅▅▄▁▅▅▅▅▅▇▆▅▇▅▇▇▅█▆▄▄▇▇▄▄▃▃▅▇▅▄▅▇▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.49598
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.86859
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.59411
wandb:      test/avg_mil_loss 0.63707
wandb:       test/ensemble_f1 0.59411
wandb:           train/avg_f1 0.61652
wandb:      train/ensemble_f1 0.61652
wandb:         train/mil_loss 0.82057
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iikm2z9u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165326-iikm2z9u/logs
wandb: Agent Starting Run: pemdhied with config:
wandb: 	actor_learning_rate: 4.2346710767563015e-05
wandb: 	attention_dropout_p: 0.03548736228600946
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23961559974341215
wandb: 	temperature: 9.516996327501673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165434-pemdhied
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pemdhied
wandb: uploading history steps 101-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▆▁▁▃▁▃▂▇▃▁▃▁▁▃▁▁▃▁▆▁█▆▁█▂▁▃▃▁▆▁▃▆▇▁▂▁▄▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▄▁▅▁█▁▁▅▁▇█▁▇▅▅▁▁▂▂▁▁▁▁▇▁▁▂▅▁▁▂▇▁▆▄▁
wandb:       eval/ensemble_f1 █▅▆▁▃▃▃▁▃▁▁▃▇▁▁▁▃▁▄▇▃▃▂▂▆▁██▂▃▁▁▆▇▇▇▁▃▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅██▄▄▆▅▇▄▃▄▅▇▇▆▅▇▇▆▅▇▄▇▇▅▃▄▃█▇▄█▁▇▅▆▁▄▇▇
wandb:      train/ensemble_f1 ▄▇█▆█▆▄▅▄▅▅▃▅▄▅▇▆▅▅▅▆▅▅▆▄▇▄▅▇▄▇▅▁▆▅▆▇▅▇▆
wandb:         train/mil_loss █▄▁▅▃▅▆▁▅▅▆▇▃▅▄▄▅▇▄▃▃▆█▃▂▇▃▂▆▄█▂▄▃▄▅▆█▄▃
wandb:      train/policy_loss ▁▄▄▄▄▁▄▃▄▃▄▁▃▄█▄█▄▃▄▄▃▄▃▄▃▃▄▄▄██▄▄▄▄▄▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▄▄▁▄▃▄▄▄█▄▄▄▃▄▃▄▄▄▃▄▄▄▄▃▄▁▄██▄▄▄▄▄▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.58897
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.94277
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.74485
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.61128
wandb:      train/ensemble_f1 0.61128
wandb:         train/mil_loss 4.00529
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pemdhied
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165434-pemdhied/logs
wandb: Agent Starting Run: vq4t4kuu with config:
wandb: 	actor_learning_rate: 0.0001516438322537099
wandb: 	attention_dropout_p: 0.12615718724300456
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 74
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4932466080875473
wandb: 	temperature: 2.180851582618825
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165602-vq4t4kuu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/py55irhe
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vq4t4kuu
wandb: uploading history steps 58-75, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▄▁▄▇▁█▁█▄▇▁▁▁▄▁▁▁▁▅▁▁▁▇▄▁▅▇▁▁▁▁▁▁▂▅▁▃▅▁
wandb:      eval/avg_mil_loss ▄▁▃▃▆▃▁▂█▁▁▄▆▁▆▂▆▃▁▁▄▄▄▁▂▅▂▇▁▄▂▃▄▂▂▁▁▂▄▁
wandb:       eval/ensemble_f1 ▁▁▆▆▁▁▁█▁█▇▆▁▂▇▁▂▁▁▁▅▁▁▂▇▁▆▁▁▅▁▁▆▁▁▂▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅▆▆▅▂▆█▇▅▇▅▇▄▂▅▄▇▃▄▃▆▄▄▅▅▅▄▇▇▁▇▄▆▅▁▆█
wandb:      train/ensemble_f1 ▆▆▆▆▅▆▆▅▅▅▆█▁▇▇▄▂▅▄▃▆▃▃▆▄▅▅▅▄▆▄▆▇▁▇▇▆▆▅█
wandb:         train/mil_loss ▃▃▆▅▄▅▂▄▅▅▆▂▃▃▆▂▅▄▇▅▁▂▁▇█▄▂▅▃▃▃▄▃▃▄▆▅▂▆▃
wandb:      train/policy_loss ▄▂▄▆▆▄▄▆▄▂▃▂▄▂▄▄▃▄▄▆▄▄▆▄▄▆▄▃▆▄▄▄▃█▁▄▂▄▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂▄▆▆█▆▄▅▂▃▂▄▄▄▃▄▃▄▄▄▆▄▄▄▄▃▄▂▆▆█▄▆▁▄▂▄▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7552
wandb: best/eval_avg_mil_loss 0.49642
wandb:  best/eval_ensemble_f1 0.7552
wandb:            eval/avg_f1 0.36228
wandb:      eval/avg_mil_loss 1.1125
wandb:       eval/ensemble_f1 0.36228
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.1292
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.59691
wandb:      train/ensemble_f1 0.59691
wandb:         train/mil_loss 2.42909
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vq4t4kuu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165602-vq4t4kuu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: pw793r7n with config:
wandb: 	actor_learning_rate: 2.1600256759861256e-05
wandb: 	attention_dropout_p: 0.3996731016017696
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9701253028073455
wandb: 	temperature: 6.713111393638807
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165720-pw793r7n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pw793r7n
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 75-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▂▁█▂▁▄▆▂▅▅▆▄▄▅▂▄▃▇▆▇▃▇▇▇▇▂▂▁▆▅▆▃▄▃▂▇▂▂█▂
wandb:      eval/avg_mil_loss ▇▂▂▇▁█▂▅▂▁▁▃▁▂▃▁▃▂▂▁▁▄▁▁▂▁▇▇▁▂▁▂▂▂▃▁▂▄▂▂
wandb:       eval/ensemble_f1 ▁▁▃▂█▄▄▆▅▆▄▄▂▆▅▄▃▃▅▅▂▅▁▇▆▂▁▆▅▃▃▄▂▁▂▇▆▆▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▃▂▄▃▂▃▅▅▆▄▁▃▆▇▂▅▄▆▄▅▄▆▅▃▃▅▅▆▆▂▂█▃▂▇▂▂
wandb:      train/ensemble_f1 ▂▄▃▃▅▆▂▁▃▄▆▅▂▃▃▇▄▅▃▄▄▂▃▃▆▃▅▃▆▆▅█▃▇▁▇▃▂▅▂
wandb:         train/mil_loss ▄▆▅▄▃▂▅▅▂▄▇▅▃▅▄▂▆▃▄▃▆▄▂▁▄▄▅█▇▆▅▄▇▃▅▄▄▆▄▂
wandb:      train/policy_loss ▅▂▂▂▁▅▁█▂▅▂▂▂▂▂▅▁▁▂▂▂▂▄▁▂▄▂▂▄▅▅█▂▂▂▄▂▅▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▅▂▆▅▂▁▃▃▃▆▃▂▂▃▃▅▄▁▂▃▂▁▃▄▃▅▃▄▆▄▆█▃▃▁▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75913
wandb: best/eval_avg_mil_loss 0.80068
wandb:  best/eval_ensemble_f1 0.75913
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.88544
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.61948
wandb:      test/avg_mil_loss 0.6327
wandb:       test/ensemble_f1 0.61948
wandb:           train/avg_f1 0.51533
wandb:      train/ensemble_f1 0.51533
wandb:         train/mil_loss 1.02789
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pw793r7n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165720-pw793r7n/logs
wandb: Agent Starting Run: 2sdtif2o with config:
wandb: 	actor_learning_rate: 0.0005726410551241948
wandb: 	attention_dropout_p: 0.20097682317814136
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 135
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7944535566743852
wandb: 	temperature: 4.68395505026079
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165837-2sdtif2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sdtif2o
wandb: uploading history steps 117-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆██
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▆██
wandb:            eval/avg_f1 ▂▁▇▃▂▃▃▆▅▄▇▁▃▄▄█▄▄▄▅▄▃▃▃▇▂▂▂▂▇▆▂▂▄▇▇▃▃▇▂
wandb:      eval/avg_mil_loss ▂▁▇▂▃▂▄▂▅▂▂▃▃▄▄▃▂▂▂▄▂▂▇▂▆▂▂▂█▂▄▄▄▇▂▆▂▂▂▁
wandb:       eval/ensemble_f1 ▆▁▂▁▃▅▂▃▂▅▅▇▅▂▄▃▄█▄▄▂▄▃▄▂▂▁▄▃▂▁▂▇▃▃▄▃▆▆▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▇▇▇▅█▃▄▄▅█▆▆▁█▄▄▅▃▄▅▅▂▅▆▄█▄▆▃▇▅▃▂▄▅▄▄▃
wandb:      train/ensemble_f1 ▅▆▄▄▅▆▃▅█▁▄▆▂▅▇▂▅▅▅▄▃▃▅▃▄▄▄▄▇▃▃▂▆▄▆▁▃▄▅▃
wandb:         train/mil_loss ▄▄▅▄▃▂▂▂▂▄▃▂▄▄█▂▂▂▃▃▁▁▄▂▃▁▃▂▃▂▂▂▂▃▄▂▃▃▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▄▅█▆▅▆▇▁▅█▄▅▆▆▅▁▅▇▅▃▇▅▇▁▆▅▄▃▆▄▆▃▅▃▃▆▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84926
wandb: best/eval_avg_mil_loss 0.5208
wandb:  best/eval_ensemble_f1 0.84926
wandb:            eval/avg_f1 0.84816
wandb:      eval/avg_mil_loss 0.45346
wandb:       eval/ensemble_f1 0.84816
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.83444
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.56019
wandb:      train/ensemble_f1 0.56019
wandb:         train/mil_loss 0.96525
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2sdtif2o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165837-2sdtif2o/logs
wandb: Agent Starting Run: k1y78j59 with config:
wandb: 	actor_learning_rate: 0.0009276482199528048
wandb: 	attention_dropout_p: 0.1839737004160164
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 171
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24868866007196863
wandb: 	temperature: 3.417998377709286
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170027-k1y78j59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1y78j59
wandb: uploading history steps 125-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▁▃██
wandb: best/eval_avg_mil_loss █▆▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▁▁▃██
wandb:            eval/avg_f1 ▁▁▁▂▁▁▃█▁▃▃▃▄▆▁▁▃▆▃▄▃▁▃▃▂▂▃▁▂▃▁▄▁▁▃▃▂▃▃▁
wandb:      eval/avg_mil_loss ▂▁▁▁▁▁▁▁▂▁▃▁▁▁█▃▂▁▁▁▁█▁▁▁▁▇█▁▁▃▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▃▂▁▁▁▃▁▁▁▃▁▁▃▁▃▂▄▃▁▇▃▄▃▂▁▄▁▃▃█▄▂▃▃▄▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▃▃▂▄▁▆▄▄▂▃▅▆▆▁▅▅▁▃▅▃▃▄▄▅▂▅▁▄▃▆▅▄█▁▂▅▂
wandb:      train/ensemble_f1 ▁▃▅▆▇▃▄▆▅▃▃▇▄▃▁▁▅▇▁▇▆▁▁▁▄▂▅▆▃▆▂█▅▅▃▁▃▃▃▄
wandb:         train/mil_loss ▃▂▁█▂▂▂▁▁▂▅▂▂▃▁▁▁▁▁▁▁▅▂▅▄▂▁▂▁▄▁▃▂▂▁▂▁▁▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.57331
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.87577
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.82417
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.54419
wandb:      train/ensemble_f1 0.54419
wandb:         train/mil_loss 0.83727
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1y78j59
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170027-k1y78j59/logs
wandb: Agent Starting Run: brx6kh78 with config:
wandb: 	actor_learning_rate: 5.0587820808881725e-06
wandb: 	attention_dropout_p: 0.49990249637498735
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 138
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16258310605734003
wandb: 	temperature: 2.055071549226631
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170210-brx6kh78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/brx6kh78
wandb: uploading history steps 98-118
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▆█▂▆▂▄▆█▃▃▄▂▄▆▅▄▄▇▁▂▃▁▇▆▇▃▃▆▅▆▃▇▇▇▂▇▁▇▅▁
wandb:      eval/avg_mil_loss ▃▃▁▃▃▆▁▁▁▁▂▁▁▁▁▄▃▁▁▂▁▁▂█▁▃▁▁▇▁▂▃▁▁▁▄▁▁▁▆
wandb:       eval/ensemble_f1 ▇▇▂▁▅▃▂▆▆▇▄▁▇█▅▁█▁▅▆▄█▅▂▅▃▃▂▅██▆▂▄█▃▇▅█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▂▄█▁▄▅▅▄▁▅▄▃▂▇▅▅▂▄▇▇▄▅▂▄▃▅▇▃▅▅▅▆▄▅▇▆▇▆
wandb:      train/ensemble_f1 ▄▆▅▇▃▃▅▆▇▅▆▅▄▅▂▂▄▃▂█▅▅▃▅▁▅▄▁▅▃▄▅▃▆▃▂▅▇▇▆
wandb:         train/mil_loss ▄▄▄▃▃▃▅▂▅▃▂▃▂▂▃█▁▂▄▄▄▄▃▅▁▅▄▃▃▅▄▂▂▂▃▃▅▄▅▄
wandb:      train/policy_loss ▆▆▅▅▆▅▅▄▆▆▆▄▅▆▅▅▁▆▅▃█▅▅▅▅▁▄▅▆▃▆▆▅▅▅▅▄▃█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▅▆▄▆▆▄▅▅▄▃█▄▁█▄▄▃▇▅█▅▁▄▄▅▆▁▄█▄▄▆▆▄▄▄▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79475
wandb: best/eval_avg_mil_loss 0.66542
wandb:  best/eval_ensemble_f1 0.79475
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.06459
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.51691
wandb:      test/avg_mil_loss 2.63864
wandb:       test/ensemble_f1 0.51691
wandb:           train/avg_f1 0.5687
wandb:      train/ensemble_f1 0.5687
wandb:         train/mil_loss 1.85011
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/brx6kh78
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170210-brx6kh78/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wpdrcbu5 with config:
wandb: 	actor_learning_rate: 0.00011833516048027916
wandb: 	attention_dropout_p: 0.2329122455519394
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 114
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8443793512866914
wandb: 	temperature: 3.4684506391807624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170353-wpdrcbu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wpdrcbu5
wandb: uploading history steps 98-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▇█
wandb: best/eval_avg_mil_loss ▂▂█▁▃
wandb:  best/eval_ensemble_f1 ▁▅▅▇█
wandb:            eval/avg_f1 ▆▄▄▅▃▂▃▅▄▃█▃▇█▆▄▃▃▇▆▄▆▄▂▄▄▃▄▃▅▇▃█▄▄▃▅▅▁▇
wandb:      eval/avg_mil_loss ▁▂▃▂█▁▂▂▂▃▂▁▂▂▂▃▄▂▂▂▁▂▂▂▂▂█▂▃▂▁▁▂▁▂▂▂▁▆▁
wandb:       eval/ensemble_f1 ▅▃▃▂▇▂▃▅▄▄▃▄▃▂▃█▃▆▄▃▅▂▃▂▄▃▄▅▃▂▁▂▄▃▇▅▁▃▃▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▅▃▆▄▃▄▅▅▅▅█▅▃▄▅▃▁▅▄▄▇▂▄▄▁▆▂▄▄▄▂▆▂▄▃▄▅▅
wandb:      train/ensemble_f1 ▆▁▃▄▄▂▄▃▄▅▅▅▅▅█▄▁▄▄▃▄▃▅▅▄▅▃▅▄▅▅▅▇▄▄▃▃▄▄▅
wandb:         train/mil_loss ▃▃▃▃▄▃▂▃▅▅▃▅▅█▃▁▁▅▁▇▃▅▄▃▁▆▁▂▄▄▃▁▄▇▃▅▇▄▃▂
wandb:      train/policy_loss ▄▆▄▆▂██▇▂▃▄▃▂▆▇▆▆▆▆▂█▄▃▄▂▂▆▆▂▁▆▆▆▁▆▃▃▃▇▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▃▁▃▃▂▂▁▆▂▃▆▇▄▆▆█▄▃█▄▂▂▇▁▃▂▂▂▆▃▆▂▃▁▃▂█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76139
wandb: best/eval_avg_mil_loss 0.79996
wandb:  best/eval_ensemble_f1 0.76139
wandb:            eval/avg_f1 0.68847
wandb:      eval/avg_mil_loss 0.62151
wandb:       eval/ensemble_f1 0.68847
wandb:            test/avg_f1 0.66875
wandb:      test/avg_mil_loss 0.59726
wandb:       test/ensemble_f1 0.66875
wandb:           train/avg_f1 0.57941
wandb:      train/ensemble_f1 0.57941
wandb:         train/mil_loss 0.99707
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wpdrcbu5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170353-wpdrcbu5/logs
wandb: Agent Starting Run: yei39sjv with config:
wandb: 	actor_learning_rate: 0.00013293038955572252
wandb: 	attention_dropout_p: 0.055233259424738224
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9577041592620265
wandb: 	temperature: 9.20133588683506
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170526-yei39sjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yei39sjv
wandb: uploading history steps 82-98, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▄▆▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▁▅▁▇▅█▃▃▁█▃▇▁▁▄▄▄▇▂▄▄▄▁█▁▁▁█▄▃▁▇▄▇▆▄▄▄█▃
wandb:      eval/avg_mil_loss ▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂█▁▂▂▃▁▂▂▂▂▂▂▂▁▂▂▂▂▂▃▂▂
wandb:       eval/ensemble_f1 ▅▅▃▁█▁▄▄▁▄▃▇▁▇▁▂▄█▄▄▄▁▆▁▁▆▄▄▁▄▃▄▇▆▁▃▄▄▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▆▆▃▅▄█▄▇█▄█▃▆▇▇▃▄▅▅▇▄▄▅▆▃▃▅▄▄▂▄▂▃▆▇▆▇▁
wandb:      train/ensemble_f1 ▃█▅▆▆▄▄█▅▅▄▃▃█▄▃▄▆▇▃▅▇▇▆▇▆▃█▅▄▂▆▅▃▅▆▇▅▆▁
wandb:         train/mil_loss ▃▇▂▂▁▂▂▂▂▃▅▂▂█▂▁▆▂▂▃▂▂▆▇▂▃▁▁▂▂▁▂▆▁▂▄▄▄▄▁
wandb:      train/policy_loss ▄█▃▃██▄▄▁▄▄▄▄▄▄▁█▄▄█▄▄▄▄▄▄████▄▄█▄▄▃▃▄█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄██▃██▄▄▄█▄▄█▄▁▃▁█▄█▆█▄▄▄█▄██▄▄▄▁▄███▃▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8
wandb: best/eval_avg_mil_loss 0.52806
wandb:  best/eval_ensemble_f1 0.8
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.894
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78406
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.65264
wandb:      train/ensemble_f1 0.65264
wandb:         train/mil_loss 0.76052
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yei39sjv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170526-yei39sjv/logs
wandb: Agent Starting Run: 5wc18c8j with config:
wandb: 	actor_learning_rate: 0.0005855570933222551
wandb: 	attention_dropout_p: 0.009403006233312194
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9954285320884104
wandb: 	temperature: 3.8716315945007422
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170643-5wc18c8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5wc18c8j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▃▅▆▃▂▆▆▆▃▄▇▃▅▂▆▃▆▁▄▇██▄█▆▃▂▁▃▅▆▃▆▄▅▂▆▆▂
wandb:      eval/avg_mil_loss ▄▂▃▁▇▂▁▁▂▄▁▁▅▁▃█▆▄▂▃▇▁▄▄▁▁▁▄▁▂▆▁▇▆▂▅▂▃▅▆
wandb:       eval/ensemble_f1 █▄▃▆▅▂▂▁▃▃▄▄▄▂▅▄▃▆▁▁▅▇▇▅▇▃▂▃▃█▂▂▆▄▆▅▂▇▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▇▄█▄▃▅▄▂▅▆▁▄▆▃▃▃▅▇▇▃▄▆▅▄▅▄▁▇▇▅▃▄▆▂▇▆▃
wandb:      train/ensemble_f1 ▃▄▃▃▄▄▁▃▅▄▅▆▆▃▃▅▃▃▅▅▆▃▃▅▆▄▄▄▄▁▅▆▆▆▄█▇▅▂▅
wandb:         train/mil_loss ▆▁▃▄▄▄▃▄▃▅▁▇▄▂▆▁▃▅▇▁▅▆▃▄▃▄▄▅▄▃▃▁▄█▄▃▄▁▅▃
wandb:      train/policy_loss ▄▁▃▅▅▆▁▆▂▆▅▃▅▅▆▅█▆▃▁▄▅▆▅▁▅▅▆▂▁▅▃▆▅▄▆█▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▃▁▄▄▄▆▆▃▃▆▃▆█▆▄▄▃▃▄▄▄▄▃▅▄▄▅▃▆▆▃▆▄▅▆▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.60465
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.42857
wandb:      eval/avg_mil_loss 4.40179
wandb:       eval/ensemble_f1 0.42857
wandb:            test/avg_f1 0.70877
wandb:      test/avg_mil_loss 0.60592
wandb:       test/ensemble_f1 0.70877
wandb:           train/avg_f1 0.5582
wandb:      train/ensemble_f1 0.5582
wandb:         train/mil_loss 2.15174
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5wc18c8j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170643-5wc18c8j/logs
wandb: Agent Starting Run: 8z3u0n9c with config:
wandb: 	actor_learning_rate: 0.0004408607897589969
wandb: 	attention_dropout_p: 0.27577619550704746
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9394297324497934
wandb: 	temperature: 3.168817363406504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170806-8z3u0n9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8z3u0n9c
wandb: uploading history steps 97-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄█
wandb: best/eval_avg_mil_loss ▇▇█▁
wandb:  best/eval_ensemble_f1 ▁▂▄█
wandb:            eval/avg_f1 ▅▆█▅▄████▄▄▆▆▇▇▆▅▇▅▄▄▅▆▆█▄▆▇▆▁█▃▇▆▃▄▆▄▃▇
wandb:      eval/avg_mil_loss ▃▃▁▃▂▃▁▁▂▂▂▃▂▁▃▂▂▅▅▄▂▁▃▅▂▅▂▄▆▅▆▆▂▂▂▃▂▁█▂
wandb:       eval/ensemble_f1 ▅▄▄▃█▅▅▆██▄▆▇▆▆▅▆▃▄▇▇▆▆█▇▂▆▇▁▆▇▄▅▃▂▅▄▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▃▄▅▄▃▄▄▅▄▄█▅█▅▅▄▆▄▄▅▆▆▅▇▆▅▂▆▁▆▆▄▅▆▅▆▄▅
wandb:      train/ensemble_f1 ▄▅▅▅▁▃▄▃▇█▅▆▅▆▃▆▅▅▄▅▄▂▅▇▅▅█▆▁▇▄▅▅▄▅▄▆▄▆▃
wandb:         train/mil_loss ▅▄▅▆▄▂▅▆▇▄▃▅▁▆▆▄▅█▃▃▄▆▅▆▅▃█▅▃▃▃▅▄▄▄▃▃▂▄▄
wandb:      train/policy_loss ▃▆▃▆▃▃▃▁▁▃▆▆▃▆▃▆▃▁█▆▆▃▃▃▁▃▇▆▃▃▃▃▆█▃█▃█▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▆▆▅▅▃▆▁▃▆▃▅█▅▅▅▅▅▁▅▅▁▁▅▇▆▅▅▅▅█▆▆▅██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.53769
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.72006
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.61948
wandb:      test/avg_mil_loss 0.62937
wandb:       test/ensemble_f1 0.61948
wandb:           train/avg_f1 0.65366
wandb:      train/ensemble_f1 0.65366
wandb:         train/mil_loss 0.82622
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8z3u0n9c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170806-8z3u0n9c/logs
wandb: Agent Starting Run: usyi5jl0 with config:
wandb: 	actor_learning_rate: 0.0002533965014337523
wandb: 	attention_dropout_p: 0.2991219685396997
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8159429494509003
wandb: 	temperature: 5.757036447029314
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170934-usyi5jl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/usyi5jl0
wandb: uploading history steps 102-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▁▁▂▃▁▃▁▁▁▁▁▁▁▁▂▂█▃▄▃▁▃▁▁▁▃▁▁▁▄▁▂▂▂▁▁▂▁▁▁
wandb:      eval/avg_mil_loss ▅▃▂▁▂▃▃▃█▃▃▃▃▁▃▃█▃▇▂▂▃▂▃▃▃▃▃▃▃▃▃▆▆▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▁▃█▁▁▃▁▁▁▁█▁▁▂▁▂▂▃▁▃▁█▁▁▁▃▁▁▂▂▁▂▁▅▁▁▁▁█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▆▆▂▆▄▇▅▂▅▄▆▇█▇▇▂▁▇▁▄▄▁▇▂▂▇▃▃▄▇▅█▄▄▃▇▇▅
wandb:      train/ensemble_f1 ▆▂█▄▂▂▆▆▇▅▅▇▆█▇▇▇▆▃▅▇▇▇▅▅▁▆█▃▃█▆▇▅▃▅▂▄▇▂
wandb:         train/mil_loss ▂▂▂▁▃▆▁▂▂▇▂▂▂▂▁▃▂▃▂▂▃▁▃▆▂█▁▁▂▁▂▁▁▂▂▁█▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▅▅▅▅▁▁█▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▅▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▅▅▁▅▅▁█▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▅▁▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78947
wandb: best/eval_avg_mil_loss 0.77802
wandb:  best/eval_ensemble_f1 0.78947
wandb:            eval/avg_f1 0.75913
wandb:      eval/avg_mil_loss 0.50625
wandb:       eval/ensemble_f1 0.75913
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.83169
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.43636
wandb:      train/ensemble_f1 0.43636
wandb:         train/mil_loss 0.85502
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/usyi5jl0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170934-usyi5jl0/logs
wandb: Agent Starting Run: 3gelttm3 with config:
wandb: 	actor_learning_rate: 7.356935310333047e-05
wandb: 	attention_dropout_p: 0.3216166220515512
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 129
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7888072271211595
wandb: 	temperature: 5.554283368528708
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171057-3gelttm3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3gelttm3
wandb: uploading history steps 121-130, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇███
wandb: best/eval_avg_mil_loss █▁▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▆▇███
wandb:            eval/avg_f1 ▄▃▁▂▁█▃▆▃▁▂▅▂██▂▁▁▆▃▆▁▄▁▂▁▅▁▁▄▁▃▂▄▅▁▁▃▁▂
wandb:      eval/avg_mil_loss ▁▁▁▅▁▂▁▁▁▂▁▃▂▁▂▁▂▁▁▅▁█▂▁▂▁▁▁▁▁▇▁▁▁▁▁▁▁▃▁
wandb:       eval/ensemble_f1 ▆▅▃▇▄▃▁▁▁▁▅▃▃▄▁▄▁▄▁▃▂▃▁▁▆▃██▃▂▅▆▁▁▂▃▆▁▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▁▅▄▇▇▂▅▅█▅▅▂▆▂▅▄▃▁▄▄▂▅▇▅▄█▄▃▅▅▄▇▅▅▂▅▆▄
wandb:      train/ensemble_f1 ▄▅▇▅▂▇▆█▅▄▂▅▂▂▅▁▅▅▄▂▄▄▆▄▇▂▄▃▃▅▅▄▆▇▅▅▇▃▅▆
wandb:         train/mil_loss ▁▃█▄▅▂▇▁▁▅▄▆▃▆▇▆▅▆▅▃▅▅▅▅▄▁▄▅█▂▆▂▄▄▃▄▄▄▆▁
wandb:      train/policy_loss ▄▃█▆▃▄▃▃▃█▄▃█▁█▆▁▆█▄▄▄▄▄▃███▄▃▁▆██▄▃▃█▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄█▃▄▄██▄▄▄▄█▃▃▁█▃▆▄▃█▃█▄▄▃▄████▃▃▄▃▃█▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8
wandb: best/eval_avg_mil_loss 0.86082
wandb:  best/eval_ensemble_f1 0.8
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 1.66788
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78841
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.57921
wandb:      train/ensemble_f1 0.57921
wandb:         train/mil_loss 1.63079
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3gelttm3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171057-3gelttm3/logs
wandb: Agent Starting Run: rrm6wmzy with config:
wandb: 	actor_learning_rate: 0.0002861483310813297
wandb: 	attention_dropout_p: 0.23303165910824017
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7179771825625727
wandb: 	temperature: 5.892759442924007
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171240-rrm6wmzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rrm6wmzy
wandb: uploading history steps 142-150, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss █▃▁▂
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▅▁▁▁▁█▁▁▁▆▁▆▄▄█▇▆▇▆▆▁▆█▇▇▆▇▆▁▁▇▃▇▄▁▁▆█▁▁
wandb:      eval/avg_mil_loss ▃▄▅▄▅▄▅▄▄▂▅▄▂▂▁▄▄▃▂▂▃▃█▅▅▄▄▃▅▃▄██▂▄▃▂▄▃▅
wandb:       eval/ensemble_f1 ▁▃▆█▁▁▁▇▆▁▁▁▇▇▇▆▇█▁▇▇▃▁██▆▁▁▁▁▁█▆▄▇█▁▁▁▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▅▃▄▄▂▅▂▅▃▄▄▃▄▃▃▂▆▄▄▃▃▅▃▅▇▂▅▂▁▄▃█▂▅▆▆▂
wandb:      train/ensemble_f1 ▆▆▂▄▄▄▄▂▆▂▆▂▅▂▂▃▅▅▃█▆▄▂▂▄▄▄▆▃▆▁▂▄▂▄▂▄▅▃▃
wandb:         train/mil_loss ▂▃▃▃▇▃▃▅▁▃▅▃▂▅▅▄█▁▂▂▄█▄▃▅▃▂▂█▃▂▅▂▄▃▃▄▆▅▃
wandb:      train/policy_loss ▃▄█▄█▁█▁▃██▃▄▃▃▄▄▁▄▃▃▁▃▄▃▄▃▄█▃▃▃██▁▄▄▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▃█▄▃█▄▃███▃▄▄▄▃▄▃▃▁▄█▁▄▃█▃▄▃▃▄▄▄▃▄▃▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.72516
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.0703
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.86238
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.68064
wandb:      train/ensemble_f1 0.68064
wandb:         train/mil_loss 0.93165
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rrm6wmzy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171240-rrm6wmzy/logs
wandb: Agent Starting Run: ige0fklf with config:
wandb: 	actor_learning_rate: 0.0003597817537597665
wandb: 	attention_dropout_p: 0.19146522067602667
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 178
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8228269401400159
wandb: 	temperature: 5.5784155722202104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171439-ige0fklf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ige0fklf
wandb: uploading history steps 122-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 ▃▁▃▃▃▃▃▃▃▁█▃▁▁▄▂▄▃▁▁▅▁▃▃▁▆▁▅▅█▃▁▁▁▁▇▁▃▃▃
wandb:      eval/avg_mil_loss ▁▂▂▂█▂▂▂▃▂▁▂▂▂▁▁▁▁▇▁▁▁▁▁▁▂▁▃▁▂▂▆▁▂█▁▁▁▆▁
wandb:       eval/ensemble_f1 ▆▃▃▁▁▁▃▃▃▃█▁█▁▂▁▃▁▆▁▃▃▃▆▁▁▃▁▁▃▁▁▃▁▇▁▁▃▂▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▃▃▅▅▂▂▁▄▂▄▃▄▂▄▃▄▄▅▂▃▂▄█▅▅▄▃▅▅▃▃▆▂▆▆▄▅
wandb:      train/ensemble_f1 ▁▅▅▃▅▃▂▅▆▄▃▂▄▆▃▃▁▃▂█▂▅▃▃▄▅▃▄▃▆▄▂▄▄▂▄▃▃▅▅
wandb:         train/mil_loss ▂▂▄▄▅▃▁▂▃▃▂▃▁▂▆▅▁▆▃▆▂▂▄▂▄▄▂▃▅▅▂▅█▂▄▂▂▂▄▁
wandb:      train/policy_loss ▃▃▆▄▄█▃▄▄▄▁▃▃█▃▄▄▁▃▃▄▄▄▃▃▄█▄▄▃▃▃▃▃▃▃▃▃▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▃▅▅▆▅▅▃██▃▃▁▅▆▅▅▃▃▅▁▃▅▅█▅▁▅▃▅▅▁▅▃▃▃▅▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81993
wandb: best/eval_avg_mil_loss 0.58412
wandb:  best/eval_ensemble_f1 0.81993
wandb:            eval/avg_f1 0.75649
wandb:      eval/avg_mil_loss 0.68786
wandb:       eval/ensemble_f1 0.75649
wandb:            test/avg_f1 0.75758
wandb:      test/avg_mil_loss 0.61939
wandb:       test/ensemble_f1 0.75758
wandb:           train/avg_f1 0.61722
wandb:      train/ensemble_f1 0.61722
wandb:         train/mil_loss 1.3962
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ige0fklf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171439-ige0fklf/logs
wandb: Agent Starting Run: u3tj1w40 with config:
wandb: 	actor_learning_rate: 0.0009352579163878654
wandb: 	attention_dropout_p: 0.31276120027535187
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7969586003191127
wandb: 	temperature: 3.830821183997525
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171627-u3tj1w40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u3tj1w40
wandb: uploading history steps 103-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss █▁▂▁
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▅▄▆▄█▄▂▁▃▁▄▄▄▄▅▁▂▄▅▃▁▅█▄▄▄▁▄▄▄▄▄▄▄▄▃▁▄▄▁
wandb:      eval/avg_mil_loss ▅▁▂▁█▁▃▁▁▁▁▁▁▂▁▁▁▁▁▃▁▁▂▂▁▁▁▁▃▁▁▃▁▃▁▁█▁▁█
wandb:       eval/ensemble_f1 ▅█▄▆▄▁▄▃▃▄▄▄▄▄▄▃▂▄▄▄▃█▁▄▁▄▂▁▇▁▄▄▄▄▁▂▁▁▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▃▇▅█▅▆▂▁▆▅▃▅▄▄▄▄▂▄▃▄▁▃▄▅▆▃▄▆▃▃▄▂▇▄▄▃▅
wandb:      train/ensemble_f1 ▃▁▅▇▅▃▃▂▆▆▆▄▂▁▃▄▄▇▅▅▅▃▄▆▁▄▅▄▄▄▅▄▃▃█▄▆▅▄▄
wandb:         train/mil_loss ▂▆▇▃▂▄▄▅▇▇▃▇▃▁▁▃▄▂▅▆▃▂▁█▆▁▁▇▁▂▁▂▄▆▄▁▁█▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80983
wandb: best/eval_avg_mil_loss 0.56566
wandb:  best/eval_ensemble_f1 0.80983
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.18453
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.06929
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.5382
wandb:      train/ensemble_f1 0.5382
wandb:         train/mil_loss 1.23851
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u3tj1w40
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171627-u3tj1w40/logs
wandb: Agent Starting Run: ricg0kso with config:
wandb: 	actor_learning_rate: 0.00012241583588504788
wandb: 	attention_dropout_p: 0.3512625104225853
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8916925621555548
wandb: 	temperature: 4.941258800027213
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171750-ricg0kso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ricg0kso
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆███
wandb: best/eval_avg_mil_loss █▅▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆███
wandb:            eval/avg_f1 ▁▃▃▄▃▃▄▁█▂█▃▃▄▁▂▃█▁▃▂▁▄▃▂█▁▃█▂▁▃▄▅▁█▇▂▁█
wandb:      eval/avg_mil_loss ▅█▃▄▄▃▃▁▄▄▄▄▃▄▃▆▅▂▃▅▅▂▄▃▂▄▂▃▄▁▂▃▃▁▅▃▁▁▄▃
wandb:       eval/ensemble_f1 ▁▁▃▂▄▅▁███▂▄▄▄▄▁▁▁█▁▁▁▂▁▄▂▄▂▁█▃▁▁▄▄▁▅▅▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▆▇▁▁▆▅▄▄▄▄▂▃▇▁▅▄▆▄▇▆█▁▄█▄▇▄▄▇▄▃▄▇▄▂▅▇▃
wandb:      train/ensemble_f1 ▃▃▃▃▃▁▄▇▇▂▃▃▆▄▅▄▄▅▂▄▆▂▆▄▂█▄▄▇▃▆▇▅▄▆▅▄▃▄▄
wandb:         train/mil_loss ▂▂▂▂▄▆▂▂▃▂▅▂▃▆▂▂▂▂▂▂▁▂▂█▃▅▂▂▂▆▂▂▄▂▂▆▂▁▂▆
wandb:      train/policy_loss ▅▅█▆▅▃▃▃▃▁▅█▃▅██▃▁▃▆▃▅▅▅▅▆██▅▆▅▅█▃▅▅▅▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃█▁▁█▅▃▅█▅▅▁▅▃▃▁▅▃██▅▅█▃▆▆▃▅█▅▅▃▅▅▅▅▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.72214
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.95689
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79991
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.52897
wandb:      train/ensemble_f1 0.52897
wandb:         train/mil_loss 1.49565
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ricg0kso
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171750-ricg0kso/logs
wandb: Agent Starting Run: j5ysif5q with config:
wandb: 	actor_learning_rate: 0.0004069870162614347
wandb: 	attention_dropout_p: 0.28112842862782034
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8304739927692482
wandb: 	temperature: 6.740193906365009
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171933-j5ysif5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5ysif5q
wandb: uploading history steps 101-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▃█▃▇▁▃▃▁▂▁▃▇▃▃▇▃▃▂▁▇▁▁▁▂▁▁▇▃▁▃▁▁▁▃▁▃▄▁▁▃
wandb:      eval/avg_mil_loss ▂▁▂▆▂█▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▂▃█▁▁▃▁▁▃▃▁▂▃▂▃▃▁▁▃▁▃▁▁▁▁▁▃▁▁▁▃▃▁▁▃▁▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▁▃▄▁▂▁▂▄▃▅▅▁▅█▃▄▃▂▁▄▄▄▄▄▃▁▄▃▅▄▄▄▃▅▄▂▁▅
wandb:      train/ensemble_f1 ▇▅▆▃▁▇▇▇▆█▆█▃▇▇▆▇▃▃▅▇▅▇▇▃▃▅▆▄▃▇▆▅▄▆▆▇▇▆▇
wandb:         train/mil_loss ▇▅▂█▂▃▄▄▂▃▂▁▂▂▂▅▃▃▂▂▂▄▂▁▅▂▂▄▂▅▂▁▂▅▁▃▂▁▃▃
wandb:      train/policy_loss ▁▁▆▃▃▁▆▁▁▆▁▆▁█▆▁▃▆▃▁▆▁▁▃▁▁▁▃▆▆▃▁▁▃▁▁▁▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▃▃▆▃▆▁▁▁█▁▃▆▃▁▁▆▁▃▁▁▆▆▁▆▁▆▃▁▁▁▁▁▃▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.76839
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.99919
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.35662
wandb:      test/avg_mil_loss 1.81409
wandb:       test/ensemble_f1 0.35662
wandb:           train/avg_f1 0.54494
wandb:      train/ensemble_f1 0.54494
wandb:         train/mil_loss 1.1221
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run tough-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j5ysif5q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171933-j5ysif5q/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2ggvv4i6 with config:
wandb: 	actor_learning_rate: 0.00026547940593501065
wandb: 	attention_dropout_p: 0.23898603789118256
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8241037444412398
wandb: 	temperature: 4.52516437913517
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172106-2ggvv4i6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ggvv4i6
wandb: uploading history steps 141-150, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇█
wandb: best/eval_avg_mil_loss ██▁▁
wandb:  best/eval_ensemble_f1 ▁▂▇█
wandb:            eval/avg_f1 ▂▁▁▇▁▂▄▅▆▄▄▄▁▃▄▄▆▆▂▆█▄▁▁▆▁▁▁▁█▅▃▁▇▁▇▁▄▁▆
wandb:      eval/avg_mil_loss ▇▁▃▁▂▃▂▃▃▂▁▂▁▃▇▁▁▃▅▇▇▁▂▁▁▁▇█▁▁▅▁▁▁▃█▁▃▂▄
wandb:       eval/ensemble_f1 ▁▁▇▆▂█▂▁█▄▆▄▄▃▁▄▂▃▆▃█▄█▇▁▃▁▁▁▆▁█▁▇▁▁▃▄▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▇▆▆▇▆▄▄▃▅▁▃▅▅▇▇▆▄▇▆▂▅▅▅█▇█▇▇▄▆▃▄▅▄▅▆█▅
wandb:      train/ensemble_f1 ▅▆▅▃▆▄▃▇▅▁▇▁▆▆▇▆▃█▅▄▅▅▇▃▃▅▇▇▄▂▆▆▄▇▇▆▆▄▂▃
wandb:         train/mil_loss ▄▂▆█▁▃▅▃▄▂▆▅▄▄▃▂▃▆▆▂▂▃▁▄▃▄▇▃▂▃▃▅▄▄▃▄▃▅▅▄
wandb:      train/policy_loss ▄▄▄▄▄▁█▄█▄▄▄▄█▄▄▄▄▄▆█▄▄▄▄▄▄▆▁█▁▄███▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▄█▄▄▄▄▃▁▁██▆▄▁▆▄███▄▄▄▄▁▄▄▄█▃▄▄▄▄▁█▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.60038
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.68474
wandb:      eval/avg_mil_loss 0.68808
wandb:       eval/ensemble_f1 0.68474
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.58388
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.62844
wandb:      train/ensemble_f1 0.62844
wandb:         train/mil_loss 2.91395
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2ggvv4i6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172106-2ggvv4i6/logs
wandb: Agent Starting Run: 9dizkn9f with config:
wandb: 	actor_learning_rate: 0.00025168235488519163
wandb: 	attention_dropout_p: 0.20297934063264772
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 161
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6450927699738559
wandb: 	temperature: 7.440544037084797
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172305-9dizkn9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dizkn9f
wandb: uploading history steps 154-162, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▃
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▂▂▄▂▃▃▂▃▂█▄▃▇▇▃▄▂▃▂▆▃▇▂▃▁▇▄▇▁▄▂▄▂▄▇▃▅▃▂▁
wandb:      eval/avg_mil_loss ▂▃▃▁▂▂▂█▂▂▂▃▂▃▂▃▂▂▂▂▃▂▂▃▂▅▂▁▂▃▂▂▅▃▂▅▂▅▃▁
wandb:       eval/ensemble_f1 ▇▇▃▁▂▃▄▅▂▃▄▄▂▇▁▇▄▄▄▇▄▄▅▂▂▇▂▂▆▄█▂▇▆▂▂▄▂▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▃▄▃▇▆▅▅▄▆▇▅▁▆▂▄▄▃▃▇▆▂▆▄▃▆▄▇▂▂▇▁▂▃██▃▅▃
wandb:      train/ensemble_f1 ▆▆▅▇▇▄▆▃▁▄▅▆▄▅▃▆▃▇▂▇▆▆▇▅▇▄▆▄▇▃▃▂▁▄▆▅▄▃█▃
wandb:         train/mil_loss ▅▇▄▃▇▆▄▄▅▃▅▆▆█▄▁▅█▅▇▇▁▇▃▃▆▂▅▄▄▂▃▄▇▃▅▃▃▄▄
wandb:      train/policy_loss ▂█▃▁▃▃▃▇▁▃▆▃▂▂▅▁▃▃▃█▂▃▁▃▇▂▆▂▇▃▃▃▁▃▇▃▁▃▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▂█▁▄▂▇█▂▁▄▄▇▄▂▁▁▄▁▄▂▄▇▇▄▁▄▄▇▄▄▂▄▄▄▄▄▄▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7457
wandb: best/eval_avg_mil_loss 0.60551
wandb:  best/eval_ensemble_f1 0.7457
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.80876
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.74366
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.5211
wandb:      train/ensemble_f1 0.5211
wandb:         train/mil_loss 0.83803
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dizkn9f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172305-9dizkn9f/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5eqxc6cw with config:
wandb: 	actor_learning_rate: 0.0003401615911986393
wandb: 	attention_dropout_p: 0.21041421106621297
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8661402080295247
wandb: 	temperature: 6.785812035534605
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172525-5eqxc6cw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5eqxc6cw
wandb: uploading history steps 162-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▁▄▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▆▇▃▁▇█▁▁▁▁▄█▁▃▁▇▄▃▃▆█▂█▇▆▂▄▁▆▆█▁▁█▆▇▇▁▄▄
wandb:      eval/avg_mil_loss ▁▂▁▃▁▂▁▁▂▂▁▁▂▁█▂▃▂▁▂▃▅▅▅▁▁█▂▂▂▂▄▁▁▁▁▂▂▇▁
wandb:       eval/ensemble_f1 ▆▄█▇▇██▁▆▁██▆▅▃▄▇▂▄▆▁▆▄█▁▅█▂▅▄▆▂▄▆▂▁▇▇▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▃▆▆▄▅▂▇▃▃▅▇▁▅▆▂▄▅▆▄▂▃█▃▄▄▄▄▄▆▆▁█▃▄▇▅▄
wandb:      train/ensemble_f1 ▅▆▄▃▆▄▇▅▂▂▃▄▄▆▆▄▅▁▃█▃▆▄▂▅▃▁▅▆▅▁▃▃▂▆▅▃▆▇▃
wandb:         train/mil_loss ▇▁▆▇▁█▃▃▄▅▄▁▆▆▁▆▅▅▁▁▅▁▂▅▂▆▃▁▃▃▄▂▆▅▅▃▁▄▁▇
wandb:      train/policy_loss ▁▅▅▁▅▅▆▅▅▅▅▁▆▅▅▅▃▃▆▅▁▃▁▃▅▆▅▅▅▁██▁▃▃▅▃▃▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▆▅▅▅▆▅▁▅▅▃▅█▁▅▁▅▁▃▅▆█▅▅▅▃▆▅▁▅█▁▅█▃▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.6984
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.7599
wandb:      eval/avg_mil_loss 0.71084
wandb:       eval/ensemble_f1 0.7599
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.80803
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.69073
wandb:      train/ensemble_f1 0.69073
wandb:         train/mil_loss 0.75924
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5eqxc6cw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172525-5eqxc6cw/logs
wandb: Agent Starting Run: ycfftrbf with config:
wandb: 	actor_learning_rate: 0.000672408477653131
wandb: 	attention_dropout_p: 0.3728308492921052
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7676141116447672
wandb: 	temperature: 6.305756958387446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172734-ycfftrbf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ycfftrbf
wandb: uploading history steps 153-156, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▃▅▆▇▇▄▇█▁▆▆▇▄▆▆█▁▆▆▅▂▃▆▄▅▄█▆▆▆▂▇▆▄▅▇▆▄▂▂
wandb:      eval/avg_mil_loss ▅▂▃▃▂▂▁▂▅▂▁▂▂▄▂▄▁▁▂▃▂▁▂▂▁▂▁▁▂█▂▃▅▂▂▃▁▅▂▂
wandb:       eval/ensemble_f1 ▃▂▆▇▆▅▆▄▅▁▇█▅▅▅▅▂▄▇▆▃▅▇▇▇▆▄▆▇▄█▇▅▆▆▃█▂▅▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▆▅▄▄▄▂▂▃▃▄▅▂▃▁▇▅▆▃▃▇▄█▃▅▄▄▂▇▄▅▂▅▄▁▃▆▂▁
wandb:      train/ensemble_f1 ▆▆▇▃▆▃▄▁▃█▄▃▂▂▅▅▂▃▅▆▆▆▄▃▄▃▇▇▅▂▄▅▄▄▄▃▇▃▅▄
wandb:         train/mil_loss ▁▄▁▄▆▅▃▃▂▂▄▇▅▆▅▃▂▂▆▁█▅▄▆▂▃▂▄▁▃▁▄▃▄▂▃▄▂▃▃
wandb:      train/policy_loss ▃▃▆▃▆▆▆█▃▃▆▁▃▃▃▆▇▆▆▃▆▃▆▃█▇▅█▆█▆▃▆▃▆█▆▆▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████▁██████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.56314
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.41066
wandb:      eval/avg_mil_loss 0.76493
wandb:       eval/ensemble_f1 0.41066
wandb:            test/avg_f1 0.69892
wandb:      test/avg_mil_loss 0.56448
wandb:       test/ensemble_f1 0.69892
wandb:           train/avg_f1 0.68747
wandb:      train/ensemble_f1 0.68747
wandb:         train/mil_loss 1.1077
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ycfftrbf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172734-ycfftrbf/logs
wandb: Agent Starting Run: uw7pvxw2 with config:
wandb: 	actor_learning_rate: 0.0004534419704764715
wandb: 	attention_dropout_p: 0.239109551170907
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 120
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9442141465983056
wandb: 	temperature: 7.873682905360994
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172944-uw7pvxw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw7pvxw2
wandb: uploading history steps 115-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▅▇▂▃▇▃▅▆▆▃▇▄▁▆▄▇█▁▂▃▂▃▄▃▂▄▅▇▆▄▆█▅▄▆▂▂▃▆▆
wandb:      eval/avg_mil_loss ▄▁▁▁▁▁▁▁▇▁▁▁▇█▁▁▁▁▅▂▁▄▁▃▃▁▂▂▁▄▆▇▄▁▇▃▁▂▂▁
wandb:       eval/ensemble_f1 ▁█▅▃▅▆▆▂▂▇▃▆▇▂▃▆▃▂█▃▁▃▇▆▁▇▆▃▄▆█▅▄▂▅▃▆▃▆▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▆▁▅▄▆▄▅▇▄▃▄▃▇▆▄▅▆▇▄▅▄▆▃▅▃▃▂▆▅▂▆▄▄▇▄█▄
wandb:      train/ensemble_f1 ▃▃▄▆▄▃▅▅▄▆▁▂▅▃▆▂▇▃▃▁▃▂█▅▁▃▂▃▄▁▁▂▅▄█▃▃▂▇▅
wandb:         train/mil_loss ▄▃▂▅▄▂▄▄▅▂▂▄▅▅▆▅▃▄▆▆▃▅▁▅▁▃▃▆▂▁▃▅▁▆▃▄▄▄█▆
wandb:      train/policy_loss ▅▇▇▇▅▃▅▇▃▅▅▇▃▁▄▇▇▃▅▅▇▅▇▆▅▇▅▅▃▃▇█▅▄▁▃▃▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▃▁▃▆▆▃▄▄▄▃▃▆▃▁▄▄▄▄▄▆▄█▄▄▄▃▃▆▄▄▄▁▁▄▃▄▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78
wandb: best/eval_avg_mil_loss 0.65932
wandb:  best/eval_ensemble_f1 0.78
wandb:            eval/avg_f1 0.65986
wandb:      eval/avg_mil_loss 0.86142
wandb:       eval/ensemble_f1 0.65986
wandb:            test/avg_f1 0.6021
wandb:      test/avg_mil_loss 0.70731
wandb:       test/ensemble_f1 0.6021
wandb:           train/avg_f1 0.61016
wandb:      train/ensemble_f1 0.61016
wandb:         train/mil_loss 1.14292
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw7pvxw2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172944-uw7pvxw2/logs
wandb: Agent Starting Run: lbgemmwn with config:
wandb: 	actor_learning_rate: 0.000234478866528448
wandb: 	attention_dropout_p: 0.2125245273058592
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6445544938066475
wandb: 	temperature: 5.513320570532229
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173121-lbgemmwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lbgemmwn
wandb: uploading history steps 121-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆█
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▂▆█
wandb:            eval/avg_f1 ██▃▄▁▄▁▁██▁████▁▁▁▂▂▃▇█▂▃▃▁▂▂▂▁▂▅▃▃▁▅▃▃█
wandb:      eval/avg_mil_loss ▄▁▁▂▂▇▆▅▄▅▅▂▁▄▁▄▄▂▇▅▅▄▁▂█▁▄▂▁▄▁▂▁▁▄▅▃▃▁▂
wandb:       eval/ensemble_f1 ▃▃▁▁▁▇▆▁▁▇▆▃▆▆▂▆▁█▁▁▁█▆▂▂▅▁▃█▁▃▂▃▁▃▄▁▃▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▆▆▆▅▄▄▂█▁▅▂▅▅▅▇▂▆▅▄▆▇▄▇▅▅▅▅▇▇▄▄▅▄▄▁▅▆
wandb:      train/ensemble_f1 ▃▂▄▄▅▄▇▂▄▆▆▄▂█▃▄▄▇▄▅▆▄▄▇▆█▇▇▃▂▄▇▄▄▃▄▄▄▁▆
wandb:         train/mil_loss ▅▂▁▆▅▃▅▆▇▄▆▅▄▄▆█▆█▅▅▅▇▃▅▂▃▃▅▅█▄▆▄▄▆▃▇▇▆▇
wandb:      train/policy_loss ██▁▃█▅▃█▅▁▅▃▃▅▅▁▃▁▁▅▅█▅▃▃▃▅██▁▅▅█▁▃▅▅▃▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▄▄▄▄▄▃▃▁▄▄▃▃▄▃▁▁▄██▄▄▄▄█▃▃▄███▄▁▄▄█▃█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.86967
wandb: best/eval_avg_mil_loss 0.45958
wandb:  best/eval_ensemble_f1 0.86967
wandb:            eval/avg_f1 0.56044
wandb:      eval/avg_mil_loss 1.4558
wandb:       eval/ensemble_f1 0.56044
wandb:            test/avg_f1 0.64714
wandb:      test/avg_mil_loss 1.10454
wandb:       test/ensemble_f1 0.64714
wandb:           train/avg_f1 0.35376
wandb:      train/ensemble_f1 0.35376
wandb:         train/mil_loss 3.745
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lbgemmwn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173121-lbgemmwn/logs
wandb: Agent Starting Run: 89c1l0g9 with config:
wandb: 	actor_learning_rate: 0.00021767435053393787
wandb: 	attention_dropout_p: 0.21989529930652868
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8922950945597252
wandb: 	temperature: 9.011223857173484
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173300-89c1l0g9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/89c1l0g9
wandb: uploading history steps 154-173, summary; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅▆▆▇██
wandb: best/eval_avg_mil_loss ▄▆▃█▃▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▅▆▆▇██
wandb:            eval/avg_f1 ▂▃▁▄▄▂▄▃▂▄▆▃▃▆▃▂▅▄█▆▁▃▁▇▂▃▅▅▆▂▂▄▅▆▅▆▇▂▅▅
wandb:      eval/avg_mil_loss ▂▁▇▅▁▂▂▆▂▂▄▁▅▂▁▂▂▂▄▇▃▂▇▃▁▁▃▃▂▂▁█▃▁▂▂▁▁▁▃
wandb:       eval/ensemble_f1 ▂▃▂▃▃▅▂▄▅▄▁▂█▆▄▃▆▆▇▃▄▅▁▄▄▅▄▆▆▁▂▆█▄▄▅▆▄▆▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▅▄▃▄█▄▄▄▆▃▅▆▅▅▄▅▅▆▆▄▆▆▆▃█▄▄▅▅▃▁▄▅▄▅▆▃▆
wandb:      train/ensemble_f1 ▅▃▃▃▂▃▄▇▃▄▃▂▄█▄▅▁▃▇▁▃▂▅▃▃▅▃▄▁▄▆▅▄▄▄▃▂▄▅▁
wandb:         train/mil_loss ▃▂▆▃▂▅▅▃▃▄▃▁▄▁▅▄█▃▃▃▂▂▄▃▂█▃▄▅▃▃▃▄▂▂▃▇▄▅▆
wandb:      train/policy_loss ▄▇▄▄▆▆▁▄▄▆▆▇▃▄▄▄▄▄▄▄▃▆█▇▄▆▄▃▆▆▆▆▄▄▆▄▆▄▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▃▆▆▇▆▃▄▃▆▁▇▃▃▁▇▃▆▇▂▄▃▁▄▃▇▆▇▆▃▆▃▃▆▄▂▇█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83994
wandb: best/eval_avg_mil_loss 0.50279
wandb:  best/eval_ensemble_f1 0.83994
wandb:            eval/avg_f1 0.64672
wandb:      eval/avg_mil_loss 0.64043
wandb:       eval/ensemble_f1 0.64672
wandb:            test/avg_f1 0.53989
wandb:      test/avg_mil_loss 1.22934
wandb:       test/ensemble_f1 0.53989
wandb:           train/avg_f1 0.58919
wandb:      train/ensemble_f1 0.58919
wandb:         train/mil_loss 2.05137
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/89c1l0g9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173300-89c1l0g9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yxgfmr2e with config:
wandb: 	actor_learning_rate: 0.0007580355130206468
wandb: 	attention_dropout_p: 0.19213603674727353
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9823290768564896
wandb: 	temperature: 5.531518013110793
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173532-yxgfmr2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yxgfmr2e
wandb: uploading history steps 121-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆█
wandb: best/eval_avg_mil_loss █▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▆█
wandb:            eval/avg_f1 ▂▃▃▂▂▂▂▃▂▃▂▂█▂▃▇▃▄▇▂▂▂▅▂▇▂▂▂▂▃▂▄▃▂▂▄▁▃▆▂
wandb:      eval/avg_mil_loss ██▅▂▁▄▇▃▄▁▆▁▃▆▂▄▇█▃▅▄▂▁▂▂█▂▁▃▃▄▅█▆▃▆▇▃▂▆
wandb:       eval/ensemble_f1 ▁▆▂▁█▁▁▁▂▅▅▁▃▁▁▁▄▁▄▁▁▁▁▁▂▁▃▇▂▂▁▁▁▁▁▁▄▁▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▅▄▃▅▂▆▅▇▅▃▃▄▂▃▂▅▄▄▅▄▂▂▃▆▄▁▆▆█▅▅▂▃▅▄▂▆
wandb:      train/ensemble_f1 ▂▆▅▅▄▂█▆▇▂▆▂▅█▆▅▅▁▂▂▄▃▇█▄▃▃▁▂▄▁▃█▇▇▁▄▆▄▇
wandb:         train/mil_loss █▁▃▅▄▅▃▄▄▄▂▂▃▃▅▃▂▄▆▃▃▄▄▃▄▃▃▂▂▁▃▂▂▃▂▅▃▄▄▄
wandb:      train/policy_loss ▅█▃▅▅▅▅▃▃█▅▃▁▅▁█▃▅▆▆▅▁▃▃▅▃█▅▃▅▃▅█▅▅▅▅▅▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▄▁▄▄▄▄▆▄█▃▃█▄▃▄▄▄█▄▄▆█▄▄█▄▄▄▄▃▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74977
wandb: best/eval_avg_mil_loss 1.14316
wandb:  best/eval_ensemble_f1 0.74977
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.93586
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.13709
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.52042
wandb:      train/ensemble_f1 0.52042
wandb:         train/mil_loss 1.71265
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yxgfmr2e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173532-yxgfmr2e/logs
wandb: Agent Starting Run: 6mla6kpq with config:
wandb: 	actor_learning_rate: 0.00018404400061502893
wandb: 	attention_dropout_p: 0.24903931255508205
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9321691180028204
wandb: 	temperature: 6.374934703669074
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173710-6mla6kpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6mla6kpq
wandb: uploading history steps 141-143, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss ▅▁█
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▂▃▂▄▂▅▁▄▁▄▂█▆▄▅█▇▁▄▇▄▁▂▄▇▄█▃▃▅▄▄▄▄▁▂▇▄▃▇
wandb:      eval/avg_mil_loss ▂▂▂▆▂▃▂▁▂▂▂▂▁▂▂▂▂▁▄▃▁▂▂▁▄▁▂▁▂▂▂▂▁▂▂▁▂█▁▂
wandb:       eval/ensemble_f1 ▃▂█▃▄▅▁▁▂█▂▇▁▇▄▁▄▇▃▇▂▁▁▄▄██▄▄▃▄▄▁▄▄▂▇▄▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▂▅▅▁▄▂▄▁▅▂▆▃▅█▄▆▆▅▃▃▆▆▄▃█▃▄▄▄▄▄▇▆▅▅▃▅
wandb:      train/ensemble_f1 ▆▃▅▅▁▄▆▂▄▂▁▄▅▅▆▅▄█▄▆▅▅▇▅▄▄▄▃▆▄▄▃▄▅▂▃▅▁▃▇
wandb:         train/mil_loss ▃▆▂▁▁▁▁▂▄▂▁▃▂▂▁▂▃▁▂▂▁▁▃▂▂▂▂▂▂█▂▂▃▂▂▁▂▃▂▁
wandb:      train/policy_loss ▅▅▅▁█▁██▃▃▅▃▁▅▅▃█▁▅▅▃▅▅▅▆▁█▆▃▃█▅█▃███▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▁▄██▁█▄▃▁▃▃█▁▁▃████▄▁▄███▁██▆▄▃██▃▁▄▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.7244
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.88227
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.81663
wandb:      test/avg_mil_loss 0.3724
wandb:       test/ensemble_f1 0.81663
wandb:           train/avg_f1 0.59937
wandb:      train/ensemble_f1 0.59937
wandb:         train/mil_loss 0.92667
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6mla6kpq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173710-6mla6kpq/logs
wandb: Agent Starting Run: 7wk6ysgl with config:
wandb: 	actor_learning_rate: 0.0006213816289640972
wandb: 	attention_dropout_p: 0.1899039162628016
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8197698610429658
wandb: 	temperature: 5.462130764648148
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173904-7wk6ysgl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7wk6ysgl
wandb: uploading history steps 173-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆▆▆▇█
wandb: best/eval_avg_mil_loss ▄█▂█▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▅▅▆▆▆▇█
wandb:            eval/avg_f1 ▆▄▁▁▁▃▃▅▆▅▂▄▃▆▁▂▆▂▃▃▃▆▃▄▁▃▃▆▂▅▂▁▁▆▃▁█▆▂▁
wandb:      eval/avg_mil_loss ▂▃█▃▆▂▅▂▃▂▄▂▂▃▂▂▂▃▂▂▂▄▂▂▃▂▂▂▁▂▅▄▂▃█▂▂▂▁▂
wandb:       eval/ensemble_f1 ▁▅▂▆▇▁▃▆▆▇▂▇▂▁▂▂▃█▁▁▃▄▂▄▃▃▂▄▆▃▄▅▆▂▇▄▂▇▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▂▆▆▆▁▄▃▅▃▆▆▇▆▂▆▄▄▇▄▃▆▄▆▃▅█▅▇▆█▆▇▅▆▆▄▅
wandb:      train/ensemble_f1 ▄▅▇▅▅▇▇▃▅▅▄▇▃█▄▅▆▄▁▆▄▂▇▆▃▇▆▄▇▄▆▇▄▅▇▇▇▆▆▄
wandb:         train/mil_loss ▄▁▂▄▆▂▃▄█▅▂▂▂▂▁▃▄▃▂▇▁▂▂▂▃▅▅▁▁▃▂▃▂▁▁▁▂▂▂▂
wandb:      train/policy_loss ▆▃▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄▄▅▄▄▄▄▅▁▆▅▄▄█▁▆▄▄█▄▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▅▄▄▃▄▆▆▄▅▃█▅▆▅▅▅▅▅▄▁▅▅▆▅▅▅▁▄▆▅▆▅█▄▄▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79871
wandb: best/eval_avg_mil_loss 0.66182
wandb:  best/eval_ensemble_f1 0.79871
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.55206
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.75264
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.55741
wandb:      train/ensemble_f1 0.55741
wandb:         train/mil_loss 2.00563
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vague-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7wk6ysgl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173904-7wk6ysgl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jyryexz0 with config:
wandb: 	actor_learning_rate: 5.6489309041411054e-05
wandb: 	attention_dropout_p: 0.17255954269968
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.90975102626339
wandb: 	temperature: 6.737926385763098
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174154-jyryexz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jyryexz0
wandb: uploading history steps 153-159, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss █▁▂▁
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 ▅▂▇▂▁▁▄▅▇▁▁▁▁▇▂▃▄▃▁▂▄▁▁▂▁▃▂▁▁▂▁▂██▂▁▁▁▂▂
wandb:      eval/avg_mil_loss ▂▆▇█▇▃▇▇███▇▆▆▇█▇▂▇▇▇▅▇▄▇▂▇▅▇▇▆▇▆▇▆▁▆▅▆▇
wandb:       eval/ensemble_f1 ▄▄▁▂▁▅▂▁█▂▆▂▂▂▅▁▁▂▆▃▁▇▁▅▃▁▁▅▅▂▁▄█▂▃▁▁▁▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▇█▃▆▇▆▆█▄▆▇▃▅▆▄▄▆▄▃▆▄▄▆▃▂▁▅██▄▄▇▄▂▂▄▃▆
wandb:      train/ensemble_f1 ▅▂▂▃▅▁█▃▆▅▆▄▄▄▃▅▄▄▆▂▆▅▄▆▄▄▄▅▃▆▅▄▄▆▅▅▃▄▆▄
wandb:         train/mil_loss ▄▂█▄▄▂▅▆▃▃▄▆▃█▃▃▆▂▂▇▄▃▁▂▃▅▅▃▃▄▂▂▂▄▂▄▂▄▅▃
wandb:      train/policy_loss ▃▁▃█▃▁▃▃▃▃▁▁▁▃▃▃▃▃▃▃▃▁█▃▁▃▃▃▃▆▃▃▃▃█▃▆▁▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▃▁▃▁▃▁▃▃▁▃▃▆▃▃▁█▃▃▁▃▃▃▆▃▃█▃▃▁▃▁▃▆▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75
wandb: best/eval_avg_mil_loss 0.64445
wandb:  best/eval_ensemble_f1 0.75
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.83366
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78103
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.48263
wandb:      train/ensemble_f1 0.48263
wandb:         train/mil_loss 0.86879
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jyryexz0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174154-jyryexz0/logs
wandb: Agent Starting Run: wmewp7ta with config:
wandb: 	actor_learning_rate: 0.0008955522347367278
wandb: 	attention_dropout_p: 0.2960900008581922
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9908691157120862
wandb: 	temperature: 7.394213967824653
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174403-wmewp7ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wmewp7ta
wandb: uploading history steps 173-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄██
wandb: best/eval_avg_mil_loss █▄▂▁
wandb:  best/eval_ensemble_f1 ▁▄██
wandb:            eval/avg_f1 ▅▅▁█▂▂▄▅▁▂▆▄▅▁▇▃▇▂▂▁▁▂▂▃▁▂▄▆▆▆▅▄▂▄▂█▇▃▃▅
wandb:      eval/avg_mil_loss ▃▄▅▅▅▄▄▄▄▃▄▅▁▃▃▄▄▃▃█▄▄▄▅▅▄▄▄▁▄▃▄▃▂▅▂▁▄▄▄
wandb:       eval/ensemble_f1 ▁▂▄▂▆▃▂▄▁▄▂▁▆▄▂▁▄▃▇▂▂▂▂█▂▄▂▃▇▃▅▄▃▄▂▆▅▃▅▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▁▅▇▄▆▃▅▄▄▆▄▆▃▅█▃▂▃▄▃▆▅▃▅▄▅▅▃▆▆▃▅▅▆▄▄▂
wandb:      train/ensemble_f1 ▃▅▁▇▆▂▅▅▆▄▄▆▄▂▃▃▇▅▄▆▅▇▃▅▂▆▂▄▅▃▆▅▄█▆▅▆▆▅▃
wandb:         train/mil_loss ███▁▆▇▅▆▅▆▄▅▇▄▇▃▅▄▃▄▄▆▅▃▆▆▄▂▄▁▅█▄▄▅▆▄▄▁▄
wandb:      train/policy_loss ████▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▁████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.49591
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.60522
wandb:      eval/avg_mil_loss 0.74774
wandb:       eval/ensemble_f1 0.60522
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.7822
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.49541
wandb:      train/ensemble_f1 0.49541
wandb:         train/mil_loss 0.7142
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wmewp7ta
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174403-wmewp7ta/logs
wandb: Agent Starting Run: hbgqq3od with config:
wandb: 	actor_learning_rate: 0.00021761485895066668
wandb: 	attention_dropout_p: 0.27310907746302293
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9510479966776118
wandb: 	temperature: 5.742664030323853
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174633-hbgqq3od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hbgqq3od
wandb: uploading history steps 102-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▁▁█▂▇▁▃▁▃▂▁▅▁▁▁▂▁▂▁▆▁▁▆▁█▃▁▅▁▂▁▃▃▃█▆▁▂█▂
wandb:      eval/avg_mil_loss ▃▁▄▃▂▃▃▃▃▂▃▃▃█▃█▃▄▃▃█▃▃▃▃▅▃▄▃▃▆▃▁▂▃▃▁▃▂▃
wandb:       eval/ensemble_f1 ▁▁█▂▁▁▁▁▆▃▁▂▆▂▃▃▆▅▅▂▁▃▁▁▃▁▁▁▁▁▁█▃▃▁▃▃▂▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂█▇▁▂▂▂▄▂▂▃▂▂▅▂▁▃▃▂▅▂▁▂▂▄▂▃▂▂▆▅▅▄▃▃▂▄▄▅▁
wandb:      train/ensemble_f1 ▂▇▂█▃▃▂▂▄▂▂▃▂▁▂▁▂▄▄▃▅▁▅▂▂▂▃▆▆▂▅▆▂▄▂▃▃▂▄▆
wandb:         train/mil_loss ▆▃▃▃▃▆▃▂▄▆▃▁▃▄▅▅▂▂▄▂▅▄▆▆▅▃▂▂▂▄▂▂▂▃▂▁█▅▆▄
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▆▃▃▃██▃▃▃▃▆▃▆▃▆▁▃▃▃▃█▃▃▃▃▃▃▆▃▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▆▃▃▃▃▃▅▃▅▃▆▆▃▆▃▃█▃▃▃▃▅▁▃▃▃▆▃▃▃█▃▃▃▃▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.60529
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.07348
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.89553
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.56326
wandb:      train/ensemble_f1 0.56326
wandb:         train/mil_loss 0.90261
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lemon-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hbgqq3od
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174633-hbgqq3od/logs
wandb: Agent Starting Run: vnqij2ze with config:
wandb: 	actor_learning_rate: 0.0003003406252629048
wandb: 	attention_dropout_p: 0.25739944334553605
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7389476620683106
wandb: 	temperature: 6.015177137342045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174757-vnqij2ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vnqij2ze
wandb: uploading history steps 96-110, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▆▇██
wandb: best/eval_avg_mil_loss █▆▂▁▁▃▃
wandb:  best/eval_ensemble_f1 ▁▄▅▆▇██
wandb:            eval/avg_f1 ▁▃▃▁▂▁▂▃▁▄▁▄▄▃▄▁▃▃▁▁▄▇▁▁▁▂▁▃▂▆█▁█▄▃█▃▂▃▃
wandb:      eval/avg_mil_loss ▄▃▄▄▅▃▄▃▄▄▁▂▄▂▄▃▄▄▃█▁▄▃▄▃▄▂▃▃▂▄▄▃▂▃▂▂▂▃▃
wandb:       eval/ensemble_f1 ▁▃▁▁▁▁▁▄▁▃▃▃▁▃▃▂▂▄▆▇▇▂▁▁▁▁▁▁▁▆▁▃▄▂█▂▁▁▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▁▃▃▅▄▄▅▂▅▃▄▄▄▂▅▄▄▃▄▄▃▄▂▅▃▅▃▃█▃▂▆▇▃▆▄▆
wandb:      train/ensemble_f1 ▃▆▆▄▆▇▇▁▅▃▂▃▅▂▅▃▆▅▄▄▅▂▂▆▃▃▆▃▆▄▃▂▂█▅▃▄▃▆▄
wandb:         train/mil_loss ▅▇▅█▅▇▅▅▄▄▃▃▄▆▁▅█▆▇▅▃▄▃▄▂▄▄▇▅▅▆▄▅▄▄▂▅▄▃▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▄▅▅▅█▅▅▅▅▅█▅▅▄▅▄▅▅▅▅█▅▄▁▅▇▅▇▅▅▄▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▅▅▅▅▅▅▄▅▄▅▄▅▆▅█▅▅▅▅▅▄▅▄▁▅▆█▄▆▅▅▇▄▄▄▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70833
wandb: best/eval_avg_mil_loss 0.82359
wandb:  best/eval_ensemble_f1 0.70833
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.88652
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.83223
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.51958
wandb:      train/ensemble_f1 0.51958
wandb:         train/mil_loss 0.84608
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vnqij2ze
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174757-vnqij2ze/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.229.4:34242->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 3wlmsxvr with config:
wandb: 	actor_learning_rate: 0.00032701554176079036
wandb: 	attention_dropout_p: 0.22447398011084063
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6869713442882892
wandb: 	temperature: 4.037379901567827
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174955-3wlmsxvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3wlmsxvr
wandb: uploading history steps 155-168, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▆▆▆▆▇▇█
wandb: best/eval_avg_mil_loss █▅▄▃▂▂▁▁▁▂
wandb:  best/eval_ensemble_f1 ▁▂▅▆▆▆▆▇▇█
wandb:            eval/avg_f1 ▅▃▇▄▅▆▃▆▆▃▄▁▁▁▃▃▆▆▃▁▄▇▂▃▂▂▅▁▂▅▆█▁▃▃▂▂▆▆▆
wandb:      eval/avg_mil_loss ▃▂▄▂▄▁▁▄▂▂▄▂▁▆▆▂▁▁▄▄▄▂▁▁▂▄█▄▁▄▁▄▄▁▄▁▂▂█▂
wandb:       eval/ensemble_f1 ▅▇▃▃▃▃▇▁▇▆▂▁▂▄▃▃█▆▇▆▄▃▃▆▆▂▄██▆▃▆▇▁▃▂▇▇▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▃▅▄▅▅▅▅▁▅▄▄▆▅▄▂▄▄▆▂▃▅▅█▅▃▃▅▅▇▄█▄▆▄▅▅▅
wandb:      train/ensemble_f1 ▄▅▇▃▆▆▇▇▆▅▅▁▄▁▅▄█▇▅▃▅▃▁▅▇▄▆▅▄▅▄▆▇▅▅▄▅▆▅▅
wandb:         train/mil_loss ▆▅▄▄▃▁▆▆▃▅▅▃▅▆▅▂▅▆▇▆▄▄▇▄▇▅▁▂▄▃▄▅▆▅▆▄█▅▅▃
wandb:      train/policy_loss ▅▅▅▄▅▃▆▅▄▅▅▅▅▅▅▆▅▅▅▅▆▆▄▄▆▅▃▅▅▁▅▅▃▃▅█▆█▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▆▅▄▄▆▃▄▄▃▄▆▅▄▄▄▄▄▆▄▁▄▃█▄▄▆▄▃▃▄▄▃▄▇▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.72832
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.82101
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.51691
wandb:      test/avg_mil_loss 2.94029
wandb:       test/ensemble_f1 0.51691
wandb:           train/avg_f1 0.61863
wandb:      train/ensemble_f1 0.61863
wandb:         train/mil_loss 1.48248
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3wlmsxvr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174955-3wlmsxvr/logs
wandb: Agent Starting Run: 1ttxlp2i with config:
wandb: 	actor_learning_rate: 0.0005832631858377686
wandb: 	attention_dropout_p: 0.04754815444468219
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8655589440586737
wandb: 	temperature: 7.627245016697176
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175213-1ttxlp2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1ttxlp2i
wandb: uploading history steps 173-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇██
wandb: best/eval_avg_mil_loss █▂▃▂▁
wandb:  best/eval_ensemble_f1 ▁▇▇██
wandb:            eval/avg_f1 ▁▅▄▃▄▁▁▁▁▁▆▄▁▁▁▄▃▁▁▂▁▁▃▁▁▁▅█▁▃▁▁▁▇▁▁▄▁▁▁
wandb:      eval/avg_mil_loss ▃▃▂▃▃▁▂▃▃▃▃▃▃▃▃▂▂▂█▂▃▃▂▂▂▂▁▃▁▇▁▂▂▂▃▇▂▇▂▂
wandb:       eval/ensemble_f1 ▁▅▁▁▁▁█▇▁▇▁▁▁▁▁▄▁▆▁▆▁▇▁▁▁▁▆▄█▁▁▁▂▁▁▁▂▁▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅█▃▃▆▅▅▅██▅▃█▆▃▅▄▃▁▅▁▄▄▄▄▇▂▃▅▅▇▆▃▃▃▆▄▄▅
wandb:      train/ensemble_f1 ▄▃▆▃▄▆▆▅▅▁▄▄▄▃▂▃▆█▄▃▄▅▄▁▄▄▄▅█▄▄▅▇▄▄▅▄▅█▅
wandb:         train/mil_loss ▅▂▄▅▅▆▄▃█▂▅▆▆▇▃▁▅▃▃▃▂▁▄▆▇█▂▁▃▆▅▄▅▄▆▃▄▃▅▃
wandb:      train/policy_loss ▆▆▆▆█▆▃▆▆▆█▆▆▇█▆▆▆▆▆▆▆▃▆▆▆█▁▂▆▆▆▆▆▂▆▆▆▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▃▆▆█▆▆▇▆▆▆▆▆█▆▆▆▆▃▆▆▇▁█▃▆▃▆▃▆▂▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76887
wandb: best/eval_avg_mil_loss 0.64377
wandb:  best/eval_ensemble_f1 0.76887
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.95994
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.53846
wandb:      test/avg_mil_loss 1.04687
wandb:       test/ensemble_f1 0.53846
wandb:           train/avg_f1 0.50684
wandb:      train/ensemble_f1 0.50684
wandb:         train/mil_loss 0.91256
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1ttxlp2i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175213-1ttxlp2i/logs
wandb: Agent Starting Run: cgvciaeq with config:
wandb: 	actor_learning_rate: 0.0007897900929297599
wandb: 	attention_dropout_p: 0.2776002823375876
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7229444834351095
wandb: 	temperature: 8.777132795723315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175443-cgvciaeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgvciaeq
wandb: uploading history steps 101-112, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▅▅▁▁▅▃▁▂▄▁▁▁▄▂▅▄▁▁▁▁▄▂▂▅▆▄▅▅▁▅▅▁█▁▆▁▂▂▆▅
wandb:      eval/avg_mil_loss ▁▁█▁▆▂▁▁▂▁▂▁▁▁▁▁▆▂▁▁▁▁█▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▁▅▂▃▇▂▃▁▁▁█▄▃▃▁▃▅▁▁▂▂▁▅▃▁▄▁▃▄▁▅▂▂▁▂▂▄▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▇▃▅▆▅▆▆▇▇▇▅▅▅▆▆▆▄▆▇▅▅▁▆▅▆▅▆▅▅▃▆▄▅▅▆▅█▇
wandb:      train/ensemble_f1 ▅▃▆▃▅▇▅▇█▆▅▇▅▇▇▅▄█▄▆▆▆▅▅▁▅▃▇▇▆█▆▅▅▄▅▅█▄▇
wandb:         train/mil_loss ▃▃▃▆▂▅▅▂█▄█▆▁▁▂▁▃▂▃▂▃▅▁▁▄▅▆▄▃▃▄▄▃▃▅▂▄▃▃▂
wandb:      train/policy_loss ███████████████████████████████████████▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████████████████▁██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76979
wandb: best/eval_avg_mil_loss 0.6785
wandb:  best/eval_ensemble_f1 0.76979
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.9388
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.82753
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.61693
wandb:      train/ensemble_f1 0.61693
wandb:         train/mil_loss 1.2987
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cgvciaeq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175443-cgvciaeq/logs
wandb: Agent Starting Run: aqtm23rc with config:
wandb: 	actor_learning_rate: 0.0004731446333265881
wandb: 	attention_dropout_p: 0.22691313979497185
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 126
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9023501304758136
wandb: 	temperature: 5.5913355467056185
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175611-aqtm23rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqtm23rc
wandb: uploading history steps 115-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▇▇▇█
wandb: best/eval_avg_mil_loss █▆▄▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▃▇▇▇█
wandb:            eval/avg_f1 ▂▃▇▄▇▂▁▆▂▂▄█▁▆▃█▄▂▄█▁▁▁▃▃▁▁▃▇▅▃▆▃▂▆▁▆▃▁▂
wandb:      eval/avg_mil_loss ▃▂▆▂▅▂▇▁▂▁▁▂▂▃▁▁▂▃▂▅▂▁▁▅▂▁▂▁▄▂▆█▁▂▂▃▃▄▁▂
wandb:       eval/ensemble_f1 ▂▂▇▆▄▇▂▇▁▆▅▂▇▃▁▆▆▁▄▇▄▇▂▆▁█▆▇▆▆▃▂▂▂█▅█▅▃▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▆▆▄▇▁▅▅▇▅█▆▄▄▃▇▃▅▃▆▆▅▆▅▅▆▅▅▃▅▅▄▆█▅▄▅▅▅
wandb:      train/ensemble_f1 ▃▅▆▃▆▄▆▃▃▇▆▂▄▆▂▂▇▁▄▄▄▄▅▅▄▃▆▂▇▄▅▄█▄▅▂▂█▄▃
wandb:         train/mil_loss ▄▂▃▄▃▃▅▅▂▂█▃▁▄▆▄▂▂▅▄▄▁▃▂▅▃▅▃▆▄▃▅▄▄▅▃▂▂▁▃
wandb:      train/policy_loss ▅▆▅█▅▃▆▆▅▅▅▆▅▃▅▅▁██▆▅▆▆▆▅▄▅▅▅▅▅▅▅▄▅█▅▄▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▃▇▃█▁█▆█▆▆▆█▃▆▅▇█▆▅█▃█▆█▆▆▃▇▆▅▆▆▆▆█▆▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77778
wandb: best/eval_avg_mil_loss 0.65586
wandb:  best/eval_ensemble_f1 0.77778
wandb:            eval/avg_f1 0.38667
wandb:      eval/avg_mil_loss 1.8869
wandb:       eval/ensemble_f1 0.38667
wandb:            test/avg_f1 0.53535
wandb:      test/avg_mil_loss 2.70604
wandb:       test/ensemble_f1 0.53535
wandb:           train/avg_f1 0.58147
wandb:      train/ensemble_f1 0.58147
wandb:         train/mil_loss 1.34205
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sage-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqtm23rc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175611-aqtm23rc/logs
wandb: Agent Starting Run: eb8ypc1v with config:
wandb: 	actor_learning_rate: 0.0004377342809317662
wandb: 	attention_dropout_p: 0.22951437630751695
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 158
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7233820685336558
wandb: 	temperature: 5.4051089611761105
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175755-eb8ypc1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb8ypc1v
wandb: uploading history steps 101-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▇█▁▇▃▁▃▁▁▁▁▁▃▇▇▄▁▇▇▁▂▆▇▂▇▁▃▂▁▆█▇▇▁▁▃▃▆▃▃
wandb:      eval/avg_mil_loss ▁▁▂▁▂▁▁▂▆█▁▁▁▁▁▂▁▇▁▁▆▂█▁▂▇▁▁▂▁▂▁▁▁▁▁▁▁▂▁
wandb:       eval/ensemble_f1 ▄▁▂█▄▄▃▁▇▇▁▄▇▁▃▁▇▇▄▂▃▇▁▁▃▁▂▁▂▁▃▂▇▃▃▇▂▁▄▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▄▄▇▅▅▄▂▃▂▃▁▆▂▆▇▄▅▄▅▄▃▃▆▄▅█▆▄▃▃▅▅▄▅▃▄▄▁
wandb:      train/ensemble_f1 ▆▆▃▂▄▃▂▅█▆▄▂▂▆▅▁▇▆▆█▅▄▄▆▅▅▆▃▄▆▅▆▄▁▅▆▃▄▃▂
wandb:         train/mil_loss ▃▅▂▃▇▁▂▅█▂▆▄▂▃▂▂▂▁▄▆▇▄▃▅▄▃▂▅▂▄▅▃▂▄▃▁▂▃▁▂
wandb:      train/policy_loss ██▅▁▅▅▁▁▅█▅▁█▅▅▁▁▅███▁█▅▁▁▁▁▁▅▅▅▁▅█▁▁██▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▆▃▃▃▃▁▆▆▁▆▁▁▁▆▆▁▆▁▁▆▁█▃▃▁▆▁▁▁▁▃▁▃▁█▃▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.92897
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.83522
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78109
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.45637
wandb:      train/ensemble_f1 0.45637
wandb:         train/mil_loss 0.90407
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eb8ypc1v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175755-eb8ypc1v/logs
wandb: Agent Starting Run: i9qz2ti6 with config:
wandb: 	actor_learning_rate: 0.00017207637471360743
wandb: 	attention_dropout_p: 0.2677823053136582
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5663300362192386
wandb: 	temperature: 9.73801458826101
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175917-i9qz2ti6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9qz2ti6
wandb: uploading history steps 161-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▆▇█
wandb: best/eval_avg_mil_loss █▆█▄▁▂
wandb:  best/eval_ensemble_f1 ▁▂▆▆▇█
wandb:            eval/avg_f1 ▁▆▅▁▁▃▃▃▃▁▁▁▁▁▂▃▄▁▃█▁▆▃▅▃▇▁▂▅▄▇▅▁▃▇▆▃▁▅▆
wandb:      eval/avg_mil_loss ▂▅▂▂▁█▃▄▁▆▆▁▁▂▅▁▁▃█▁▁▃▁▂▁▁▁▁▄▂▁▁▂▆▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▁█▄▄▁▄▃▄▄▁▁▁▁▄▇▄▄▄▁▃▆▁▄▁▇▃▂▁▄▇▁▄▇▃▂▁▂▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▃▅▇▇▄▃▄▃▅▅▇█▃▁▆▅▇▆▇▆▆▅▇▅▆▅▇██▆▆▆▇▆▅▆▅▇
wandb:      train/ensemble_f1 ▆▆▅▅▅▅▄▃▃▄▆▅▁▆██▆▅▅▆▆▅█▅▅▇▆▆▅▅▇▇█▇▄█▅▅▆▅
wandb:         train/mil_loss ▆▃▃▆▅▄▅▃▅▄▂▅▄▄▂▇▆█▆▂▄▂▃▆▂▁▅▆▂▂▃▂▃▇▆▄██▃▄
wandb:      train/policy_loss ▃█▁▃▃▃▃▃▃▁█▃▆▃▁█▁▃█▃▃▃▃▃▃▁█▃▁▃▃▁▃▃▃▆▃▃█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▃▁▄█▄▄▄▁▃▄▄█▃▄▁▄▄▃▄▄▄█▃▄▃▄▄▄▄▁▄█▄▄▄▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.73593
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.44808
wandb:      eval/avg_mil_loss 2.46446
wandb:       eval/ensemble_f1 0.44808
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81683
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.64144
wandb:      train/ensemble_f1 0.64144
wandb:         train/mil_loss 3.23656
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i9qz2ti6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175917-i9qz2ti6/logs
wandb: Agent Starting Run: acpfcna1 with config:
wandb: 	actor_learning_rate: 0.00010463861978316912
wandb: 	attention_dropout_p: 0.08148001180553999
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.838405518049403
wandb: 	temperature: 5.6344740932019
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180127-acpfcna1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/acpfcna1
wandb: uploading history steps 162-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆█
wandb: best/eval_avg_mil_loss █▆█▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆█
wandb:            eval/avg_f1 ▇▁▁▆▁▂▄▆▂▁▅▂▃▁▁▆▃▁▄▁▁▆▂▅▁▇▁▁▇▁▁▂▆▁▁█▃▁▁█
wandb:      eval/avg_mil_loss ▁▆▂▂▂▂▂▂▂▂▃▂▂▇▃▂█▂▇▂▁▂▂▁▂▃▂▂▂▁▁▆█▂▃▂▂▂▄▂
wandb:       eval/ensemble_f1 ▁▅▁▁▁▁▄▁▂▂█▇▅▂▄▆▆▁▂▆▁▆▁▅▁▁▁▆▇▁▃▇▁▁▁▁▆▇▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▅▄▄▂▅▃▁▄▅▄▇▅▇▅▄▆▅▃▇▆▅▆▇▄▃▆▄▅▄▄█▄▃▅█▃▆
wandb:      train/ensemble_f1 ▇▆▆▁▅▃▃▂▆▃▆▃▆▇█▃▆▃▆▆▁▅▄▇▆▆▅▄▅▃▅▇▅▅▅▁▃▅█▅
wandb:         train/mil_loss ▆▄▅▃▃▃▂▆▂▅▄▅▁▁▂▆▆▇▂▃▄▂▆▆▅▅▃█▅▂▂▁▂▅▅▃▂▃▄▆
wandb:      train/policy_loss ▄█▄█▄▁▄▄██▄██▄█▄▃▄▃▄▄█▄▄▃▄▃▄▃▁█▄▄▃█▄█▄▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▅█▅▅▅▃█▅▅▅█▅▃▅▃▁▅▅▅▁▁▅▅▁▁▁█▅▅▅█▅▅▅▅▁▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.54163
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.12348
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.91777
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.61309
wandb:      train/ensemble_f1 0.61309
wandb:         train/mil_loss 2.33908
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/acpfcna1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180127-acpfcna1/logs
wandb: Agent Starting Run: eq9jzzia with config:
wandb: 	actor_learning_rate: 0.00029395185380117866
wandb: 	attention_dropout_p: 0.22191231459584443
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8222220255241405
wandb: 	temperature: 6.785443125119182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180335-eq9jzzia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eq9jzzia
wandb: uploading history steps 154-170, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▆▆█
wandb: best/eval_avg_mil_loss ██▂█▄▁
wandb:  best/eval_ensemble_f1 ▁▆▆▆▆█
wandb:            eval/avg_f1 ▁█▁▁▁▅▅▄▁▄▁▂▇▅▂▁▂▇▄▃▁▅██▂▄▁▇▁▁▇▄▁▇█▂▃▆▁█
wandb:      eval/avg_mil_loss ▃▃▁▁▂▃▂▃▇▃▂▅▃▂▆▆▆▅▃▃▆▇▃▁▃█▁▄▂▇▁▅▃▃▅▄▂▂▆▃
wandb:       eval/ensemble_f1 ▁█▇▁▇▅█▆▇▁▇▄█▁█▅▇▁▇▇▅▇▇███▄▁▁▃▁▂▇▁▂▂█▇█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▆▅▅▄▄▅▆▃▅▆▆▄▂▄▄▅▂▅▆▄▇▄▆▄▇▂▄▃▄▄▅▇▅▄▅█▆▄
wandb:      train/ensemble_f1 ▅▆▆▄▅▆▂▃▅▄▅▅▄▄▅▄▅▆▅▂▄▁▁▄▇▅▇▅█▃▅▄▂▃▄▄▃▂▇▅
wandb:         train/mil_loss ▃█▄▃▄▃▅▃▄▇▃▅▃▃▂▅▆▃▄▇▁▃▃▅▅▄▂▄▃▅▅▅▅▇▄▃▃▃▅▂
wandb:      train/policy_loss ▃▆▇▅▅▅▆▅█▅▅▅█▅▅▅▅▅▅▁▅▆▅▆▁▅▅▅▅▃▅▅▅▁▅▅▅▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▃█▄███▆▆▆▁▆▆▆▆▆▁▃▁▆▆▆▆▆▆▆▆█▆▁▆▆▆█▆▃▇▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82916
wandb: best/eval_avg_mil_loss 0.48199
wandb:  best/eval_ensemble_f1 0.82916
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.02252
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.62008
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.54897
wandb:      train/ensemble_f1 0.54897
wandb:         train/mil_loss 1.59709
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eq9jzzia
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180335-eq9jzzia/logs
wandb: Agent Starting Run: tpfc4yjg with config:
wandb: 	actor_learning_rate: 0.00088144293064027
wandb: 	attention_dropout_p: 0.07691498045680362
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8995000942748794
wandb: 	temperature: 4.947658377177092
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180555-tpfc4yjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpfc4yjg
wandb: uploading history steps 181-191, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▄█
wandb: best/eval_avg_mil_loss ▂▂▂█▁
wandb:  best/eval_ensemble_f1 ▁▁▂▄█
wandb:            eval/avg_f1 ▅▂▆▃█▃▄▂▃█▂▆▅▄▄▂▃▅█▅▃▄▄▄▆▁▇▁▆▄▄▆▆▃▁▂▆▅▄▅
wandb:      eval/avg_mil_loss ▁▁▂▇▁▁▄▁▁▁▂▂▄█▁▁▂▂▁▂▁▁▃▂▃▇▁▂▁▁▁▂▁▂▁▁▇▁▄█
wandb:       eval/ensemble_f1 ▅▅▂▅▆▁▆▃▄▃▃▅▃▂▆▆▄▄▅▆▄▄▆▆▄▂▆▅▃▃▄▆▆▂▇█▂▄▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄█▆▄▇▇▆▄▂▄▆▇▃▂▂▃▄▄▅▃▄█▆▆▆▆▇▁▄▆▃▂▃▄▅▃▃▅▄
wandb:      train/ensemble_f1 █▃▃▅▇▇▇▄▃▅▃▂▃▅▇▂▃▄▄▇▂▃▇▁▄▆▄▄▅▅▂▃▃▆▆▃▅▅▆▆
wandb:         train/mil_loss ▅▆▆▇▃▂▃▂▂▃▆▄▁▂▃█▃▃▂▂▆▄▂▄▂▄▂▂▃▂▁▃▂▄▂▂▃▅▂▁
wandb:      train/policy_loss ▃▄▄▄▄▆▃▃▄▆█▆▆█▄▄▃█▃▆▄█▆▄█▁▄▄▃▃▃▄▆▃▃▄▃▄▃█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▆▄▃█▃▃▄▄▃█▄▄██▆▄▆█▄▄▁▃▆██▃▆▆▄▃▄█▃▆█▄▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83897
wandb: best/eval_avg_mil_loss 0.7798
wandb:  best/eval_ensemble_f1 0.83897
wandb:            eval/avg_f1 0.45437
wandb:      eval/avg_mil_loss 3.31475
wandb:       eval/ensemble_f1 0.45437
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.75507
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.44775
wandb:      train/ensemble_f1 0.44775
wandb:         train/mil_loss 0.86622
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpfc4yjg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180555-tpfc4yjg/logs
wandb: Agent Starting Run: 1cc3ir0c with config:
wandb: 	actor_learning_rate: 0.00033688305060073265
wandb: 	attention_dropout_p: 0.23677614976891692
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 145
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9178929130638448
wandb: 	temperature: 9.626615292111154
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180824-1cc3ir0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cc3ir0c
wandb: uploading history steps 101-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▁█
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▇▃▃▁▃█▅█▁▃▄▃▃▃▆▇▆▇▄▇█▁▇█▄▁▃▆▄▃▂▃▄▃█▃▅▃▃▃
wandb:      eval/avg_mil_loss ▅▅▂▆▆▄▆▄▅▄▁▄▆▅▂▂▅▄▂▂▆▁▂▄▆▂▄▄█▅▅▅▅█▄▅▂▆▅▃
wandb:       eval/ensemble_f1 █▁▃▁▃██▄▃▇▇█▄██▁▁█▃▄▃▁▃▂▃▁█▄▃▃▃▁▃▄▅▄▇▃█▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄█▇▂█▂▇▃▇▆▁▄▇▆▆▃▆▅▄▆▆▅▂▄▇▅█▁▆█▇▆▇▆▄█▅▇▁
wandb:      train/ensemble_f1 ▃▅▇▆▆▆█▃▆▂▁▅▆▃▇▄█▃▅▄▅▄▄▅▃▆▇▄▅▃▂▅▁▆▄▆▅▄▇▄
wandb:         train/mil_loss ▅▆▆▃▃▄▅▅▄▆▃▅▄▆▇█▇▅▂▄▃▅▄▄▄▆▁▄▆▄▄▇▄▅▄▄▄▆▃▂
wandb:      train/policy_loss ▅▅▁▅▃▅▅▃▅▅▅▃▃▅▅▅▅▅▅▅▅▅▅▁▅▅█▅▅▁▅▅▅▅▅▅█▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▃▅▃█▁▅▅▃▃▅▅▃▅▅▅█▅▁▁▅▅▁▅▅▅▃▅▅▅▅▅▅█▁█▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.7094
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.90301
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.8037
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.57196
wandb:      train/ensemble_f1 0.57196
wandb:         train/mil_loss 0.75055
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1cc3ir0c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180824-1cc3ir0c/logs
wandb: Agent Starting Run: tczp040i with config:
wandb: 	actor_learning_rate: 7.688107224116989e-05
wandb: 	attention_dropout_p: 0.2904945140063075
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9476168198161176
wandb: 	temperature: 8.177695428647606
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180957-tczp040i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tczp040i
wandb: uploading history steps 142-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▄▁▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▇▂▆▆▁▆▄▆▂▂▅▃▇▇▂▅▂▂▂█▇▆▇▂▂▂▂▁▆▇▂█▆▇▃▂▃▅█▆
wandb:      eval/avg_mil_loss ▆▆▅▇▆▅▁▆▇▇▇█▃▇▆▆▃█▇▂█▆▇▇▆▁▇▆▇▇▆▅█▅▄▆▆▃▅▆
wandb:       eval/ensemble_f1 ▄▅▂▅▅▁█▂▅▂▂▃▂▅▆▂▆▂▄▂▅▂▅▂▅▂▅▂▅▄▂▇▅▃▅▅▆▂▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▃▅▂▄▅▇▅▃▆█▄▃▁▃▄▆▆▅▇▅▄▆▇▅▅▅▆▆▄▆▅▆▆▇▄▄▄
wandb:      train/ensemble_f1 ▆▄▇█▄▂▆▄▇▅▆▆▄█▄▁█▃▁▅█▆▄▅▆█▅▆▆▆▆▆▅▅▄▇▅▇▃▅
wandb:         train/mil_loss ▇▅█▅▆▅▆▅▇▆█▅▇▆▇▄▇▃▂▃▅▃▆▄▇▅▃▄▃▂▁▆▂▄▂▄▃▇▃▄
wandb:      train/policy_loss █▃█▁▁▁▆▆▁▁▁▃▃▃▆▃█▆▃▁█▃▁▃▆▆▆█▁▁▃▁▁█▁█▁█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆▃▁▃▁▁▃▆▁▁█▁▁██▁▃▁█▃▃▁▆▁▁▁█▁▁▁█▁▃█▁█▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6397
wandb: best/eval_avg_mil_loss 0.63344
wandb:  best/eval_ensemble_f1 0.6397
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.92693
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.80084
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.48166
wandb:      train/ensemble_f1 0.48166
wandb:         train/mil_loss 0.7997
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tczp040i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180957-tczp040i/logs
wandb: Agent Starting Run: y80mdc6e with config:
wandb: 	actor_learning_rate: 0.00044893326574190753
wandb: 	attention_dropout_p: 0.19363880591697608
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 175
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9560802414372114
wandb: 	temperature: 8.888837069253182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181150-y80mdc6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y80mdc6e
wandb: uploading history steps 160-176, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▆▆▇▇█
wandb: best/eval_avg_mil_loss ▂▂█▁▁▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▃▆▆▇▇█
wandb:            eval/avg_f1 ▂▄▂▂▁▂█▁▄▄▇▂▁▂▃▁▁▄▂▂█▃▂▄▂▃▂▁▄▁▃▂▂▂▄▄▇▇▂█
wandb:      eval/avg_mil_loss ▃▆▇▃▃▃▃▃▃▃█▄▃▃▃▆▃▂▃▃▃▃▃▄▃█▃▃▃▄▃▃▃▄▃▃▃▃▁▁
wandb:       eval/ensemble_f1 ▂▁▄▁▄▁▁▁▂▁▁█▂█▁▁▁▂▃▄▃▁▂▂▁▄▂▁▇▁▃▃▁▄█▄▁▁▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▅▇▃▆▂█▅▂▃▆▄▆▇▃▅▄▇▅▅▂▄█▆▆█▆▆▄▅▅▄▆▄▅▁▂▇▅
wandb:      train/ensemble_f1 ▂▅▂▇▃▅▁▂▂▇▆▇▆█▄▃▄▆▅▅▂▄▅▆▁▄▄▆▄▄▇▇▅▆▅▃▆▇▅▇
wandb:         train/mil_loss ▂▆▅▃▂▃▃▂▂▇▁▆▃▃▃▅▇▃█▃▆▂▂▂▂▂▄▅▂▂▆▂▄▂▇▂▆▂▆▁
wandb:      train/policy_loss ▄▄▆▄▄█▆▃▃▃▃▄▄▃█▃▄▄█▃▁▆▄▄▃▄▃▄▆▄▃▆▆▃▄▄▆█▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▄▆▄▄▄▄▃▃▄█▄▆▃▄▄▁▄▆▃▄▄▄▄▃▆▁▆▆▄▄▄▄▆▄▆▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.76909
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.95439
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.35675
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.68738
wandb:      train/ensemble_f1 0.68738
wandb:         train/mil_loss 0.7975
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y80mdc6e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181150-y80mdc6e/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y1lzj9ar with config:
wandb: 	actor_learning_rate: 9.328650080595531e-05
wandb: 	attention_dropout_p: 0.1675150874568983
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8883996374649645
wandb: 	temperature: 8.798935196951327
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181445-y1lzj9ar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1lzj9ar
wandb: uploading history steps 101-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▂▁▆▁▆▆▁▁▅▁▂▁▄▅▄▅▄▄▁▁▄▁▂▁▁▄▇▇▁▅▆▁▁█▁▂▄▄▄
wandb:      eval/avg_mil_loss ▂▂▂▁▁▂▂▂▂▁▄▂▃▂▂█▂▂▃▂▇▂▂▂▂▂▂▃▁▂▂▃▂▃▂▂▁▁▂▂
wandb:       eval/ensemble_f1 ▁▂▆▁▁▄▆▁▁█▁▅▅▄▁▄▄▇▃▁▃▁▄▅▄▁▄▄▁▆▆▆▄▄▄▄▂▄▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▄▄▃▄▁▄▅▄▅▅▃▄▄▃▄▃▃▄▅▄▅▆▇▆▅▅▆█▆▅▄▁▄▄▃▅▅
wandb:      train/ensemble_f1 ▆▄█▄▂▅▅▃▇▅▂▁▇▅▆▄▄▄▄▃▅▃▁▇▇▅▆▃▆▅▃▂▇▆▇▆▅▂▇▆
wandb:         train/mil_loss ▅▃▄▃▂▂▂▃▃▇▄▂▂▃▃▆▂▂▅▂▃▅▂▂▂▂▂▂▅▃▆▅▇▂▂▁▄▃██
wandb:      train/policy_loss ▃▄▃▃▆▁▄▃▃█▁▃▄▄▄▆▄▃█▄▄▄▄▃▃▃▄▃▃█▄▆▃▃▄▃▄▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▆▃▃▃▃▁▅▅▁▅▅▃▃█▆▃▃▃▃▅▃▃▃▃▅▃▁▃█▅▃▃▅▅▅▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78375
wandb: best/eval_avg_mil_loss 0.77335
wandb:  best/eval_ensemble_f1 0.78375
wandb:            eval/avg_f1 0.56854
wandb:      eval/avg_mil_loss 0.86982
wandb:       eval/ensemble_f1 0.56854
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.88744
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.57565
wandb:      train/ensemble_f1 0.57565
wandb:         train/mil_loss 0.79392
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1lzj9ar
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181445-y1lzj9ar/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d2lchdz9 with config:
wandb: 	actor_learning_rate: 0.00026033484956131873
wandb: 	attention_dropout_p: 0.26167894440649514
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 91
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6624353963722193
wandb: 	temperature: 2.923883911032259
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181616-d2lchdz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d2lchdz9
wandb: uploading history steps 77-92, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅██
wandb: best/eval_avg_mil_loss █▆▃▃▁█
wandb:  best/eval_ensemble_f1 ▁▃▅▅██
wandb:            eval/avg_f1 ▅▃▄▁▄▃▂▃▅▅▅▅█▃▅▃▅▆▅▄▃▅▆▅▄▆▄▅▄▃█▅▅▃▅▂▅▄▅▇
wandb:      eval/avg_mil_loss ▄▅█▅▅▇▆▃▄▃▁▅▄▂▂▅▅▂▃▆▅▅▄▃▂▄▆▃▆▃▅▃▅▅▄▄▂▄▆▆
wandb:       eval/ensemble_f1 ▄▄▆▁▂▅▆▅▆▆▆▆▇▄▄▇▇▆▇▇▇▇▇▆▅▆▃▇▆▃▄▆▃▆▅▂▇▃▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▅▂▃█▃▆▄▂▅▁▄▅▄▂▇▄▇▆▄▃▅▄▅▃▄▂▅▅▅▄▄▆▃▅▇▃▃
wandb:      train/ensemble_f1 ▃▄▄▃▃▂▅▅▃█▃▆▄▆▄▁▅▆▂▆▆▄▄▅▄▄▆▂▃▄▄▄▄▇▄▇▃▇▄▃
wandb:         train/mil_loss ▅▅▄▅▆▅█▄▃▄▄▂█▆▅▃▅▃▅▇▄▅▂▃▆▄▆▃▅▄▅▄▁█▇▄▃▄▄▄
wandb:      train/policy_loss ▇▅▁▃▅▅▅▅▃▇▅▇▇▇▇▃▇▇█▇▅▇▃▄▇▁▇▄▇▁▇▄▇▅▁▇▇▇▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▆▃▁▃▅▁▆▆▃▆█▁██▃███▆█▃▃▆█▆▁█▆█▅▆█▁█▅▅▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6387
wandb: best/eval_avg_mil_loss 0.86166
wandb:  best/eval_ensemble_f1 0.6387
wandb:            eval/avg_f1 0.58242
wandb:      eval/avg_mil_loss 0.6452
wandb:       eval/ensemble_f1 0.58242
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.7443
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.50387
wandb:      train/ensemble_f1 0.50387
wandb:         train/mil_loss 0.87495
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run noble-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d2lchdz9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181616-d2lchdz9/logs
wandb: Agent Starting Run: ucxdmvjy with config:
wandb: 	actor_learning_rate: 0.00014933449568338476
wandb: 	attention_dropout_p: 0.20992572834797785
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 109
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8564534980984276
wandb: 	temperature: 2.942771880703152
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181735-ucxdmvjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucxdmvjy
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss ▁█▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▁█▄▂██▁▃▁▄▁▃▂▄▁▅▂▆▂▂▁▄▂▁▇▃▁▂▂▂▃▄▅▄▁▅▂▂▃
wandb:      eval/avg_mil_loss ▁▂▃▂▁▁█▂▂▁▁▁▁▁▁█▁▁▂▁▂▁█▁▆▁▁▁▁▁▁▁▁▆█▂▁▁▃▁
wandb:       eval/ensemble_f1 ▁▁▁█▆▅█▁▃▄▄▃▄▁▄▄▆▄▁▁▅█▂▂▄▄▄▁▃▁▁▂▂▂▅▅▆▁▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▄▅▇▅▇▄▂▆▇▆▅▄▂▅▆▃▇▃▄█▅▅▆▄▅▃▃▄▃▂▃▅▆▃▆▃▁
wandb:      train/ensemble_f1 ▇▃▅▅▅▇▇▄█▆▇▆▃▄▇▁▅▄▄█▁▆▇▄▆▃▃▆▄▄▃▇▅▃▇▆▃▇▃▅
wandb:         train/mil_loss ▃▄▄▂▃▂▃▃▄▃█▁▇▃▅▁▁▁▄▆▄▄▃▃▂▅▄▁▄▄▂▄▂▄▂▃▁▁▁▃
wandb:      train/policy_loss ▁▁▃▃▁▁▃▁▃▁▃▃▃▆▁▃▁█▁▁▃▁▁█▃▃▁▃▆▃█▃▁▃▁▃▃▃▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▃▁▁▁▃▆▃▃▃▃▁▁▃▁█▁▁▁▁▃▃▃▃▁▃▃▁▃▃▃▁▃▁▃▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74977
wandb: best/eval_avg_mil_loss 0.82712
wandb:  best/eval_ensemble_f1 0.74977
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.94003
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 6.6211
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.47666
wandb:      train/ensemble_f1 0.47666
wandb:         train/mil_loss 3.24117
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ucxdmvjy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181735-ucxdmvjy/logs
wandb: Agent Starting Run: 3m4igxf0 with config:
wandb: 	actor_learning_rate: 0.0007251279204020877
wandb: 	attention_dropout_p: 0.1915951620963364
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7536524553864038
wandb: 	temperature: 8.517138987426344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181903-3m4igxf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3m4igxf0
wandb: uploading history steps 154-169, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇█
wandb: best/eval_avg_mil_loss █▃▁▁▂
wandb:  best/eval_ensemble_f1 ▁▆▇▇█
wandb:            eval/avg_f1 ▃▄▅▇▄█▃▇▇▆▁▄▄▅▃▅▆▄█▇▂▅▆▆▃▇▇▁█▂▇▅▂▁▇▇▄▄▇▃
wandb:      eval/avg_mil_loss ▁▁▁▂█▁▁▃▂▂▄▁▁▁▂▁▂▄▃▁▃▁▃▁▆▁▂▅▅▁▂▂▁▆▁▁▂▃▁▂
wandb:       eval/ensemble_f1 ▃▂▅▆▂▅▃▆▄▅▅▃▇▂▂▆▄▂▄▃▇▅▅▆▂▅▆▅▄▅▄▂▄█▂▂▁▃▃▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▅▅▃▄▅▆▄▃▃▅▁▅▄▄▆▅▄▄▃▆▇▄█▆▇▅▅▂▃▂▆▆▃█▄▄▂▅
wandb:      train/ensemble_f1 ▅█▅▅▄▆▄▅▂▆▇▇▆▅▄▃█▄▅█▁▇█▅▄▄▇▄▅▅▄▇▆▅▇▆▄██▆
wandb:         train/mil_loss ▅▅▄▃▂▃▂▂▄▂▃▃▂▁▂▂▆▄▄▁▁▂▆▃█▂▄▂▂▁▃▄▄▂▄▁▅▄▄▃
wandb:      train/policy_loss ▅▆▆▁▆▆▁▆▅▅▁▄▆▆▅▆▅▃▃▃▆▅▁█▅▅▆▆▅▆▅▆▃▅▁▆█▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▆▆█▃▆▃▅▁▅▃▅▅▆▃▆▆▆▃▃▆▃▃█▅▅▅▆▆▅▆█▃▃▁▃▆▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80435
wandb: best/eval_avg_mil_loss 0.77173
wandb:  best/eval_ensemble_f1 0.80435
wandb:            eval/avg_f1 0.60114
wandb:      eval/avg_mil_loss 3.28612
wandb:       eval/ensemble_f1 0.60114
wandb:            test/avg_f1 0.45055
wandb:      test/avg_mil_loss 4.82376
wandb:       test/ensemble_f1 0.45055
wandb:           train/avg_f1 0.61998
wandb:      train/ensemble_f1 0.61998
wandb:         train/mil_loss 1.2543
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3m4igxf0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181903-3m4igxf0/logs
wandb: Agent Starting Run: qbrdcl3h with config:
wandb: 	actor_learning_rate: 0.000199832276893613
wandb: 	attention_dropout_p: 0.24061502383955105
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 88
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8315892502682081
wandb: 	temperature: 2.6595160827460553
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182122-qbrdcl3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbrdcl3h
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▃▄▇▅▆▂▂▅▄▁▄▄█▃▂▅▃█▃▄▁▆▅▅▁▂▄▄█▆▃▃█▄▇▆▄▂▅▄
wandb:      eval/avg_mil_loss ▁▂▂▁▁▂▃▂▂▃▁▄▁▂▂▂▁▂▂▂▁▂▄▂▇▂▂▂▁▇▂▁▂▂▁█▆▆▅▂
wandb:       eval/ensemble_f1 ▄▄▇▅▄▇▅▄▁▃▅▂▆▅▆▅█▃█▁▂▆▅▇▅▅█▆▃▂▃█▄▅▃▅▂▁▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▅▃▅▄▄▄▆▄▅▆▆▄▃▂▁▆▄▅▃▄▆▃▅█▆▁▄▅▄▃▅▇▄▅▅▃▇
wandb:      train/ensemble_f1 ▆▄▅▃▅▄▅▄▃▅▅▄▁▅▆▇▅▃▆▃▄▅█▅█▄▅▅▄▃▃▄▅▅▅▄▄▃▇▅
wandb:         train/mil_loss ▅▄▂▂▃▄▂▁▃▄▅▁▄▃█▅▃▆▁▁▁▃▅▃▅▅▆▅▅▃▁▇▇▄▄▆▁▂▂▅
wandb:      train/policy_loss ▃▃▃▆▂▆▃▁▃▆▆▃▃▃▃▃▂▇▃▂▁▆▁▃▇▆▃▃▃▃▁▃█▁▇▆▁▆▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▃▅▆▅▆▃▅▆▅▆▄▁▆▆▆▃▅█▃▆▅▄▅▆▆▃▆█▅▆▃▃▆▅▆▆▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77679
wandb: best/eval_avg_mil_loss 0.48193
wandb:  best/eval_ensemble_f1 0.77679
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.83216
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79366
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.60799
wandb:      train/ensemble_f1 0.60799
wandb:         train/mil_loss 1.74295
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbrdcl3h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182122-qbrdcl3h/logs
wandb: Agent Starting Run: 0ktk8ot8 with config:
wandb: 	actor_learning_rate: 0.000583607024567025
wandb: 	attention_dropout_p: 0.30971960179928965
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8375063375760142
wandb: 	temperature: 6.0932890398066695
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182240-0ktk8ot8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ktk8ot8
wandb: uploading history steps 121-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ▂▁█
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▄▄▄▃▂▄▄▄██▄▅▂▅▄▄▅▄▄▄▂▂▄▂▂▁▄▄▃▄▂▄▂▄▄▄▆▄▄▂
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▄▁▁▁▁█▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▄▂▄▃▄▂▄▃▄▄▄▃▂▄▄▂▂▄▄▂█▃▁▂▂▄▂▁▃▃▄▆▃▄▄▂▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▅▄▅▅▁▃▂▅▃▇▃▃▇▂▂▇▂▅▂▆▁▅▂▄▃▄▇▆█▃▄▂▂▆▆▂▆
wandb:      train/ensemble_f1 ▇▄▄▄▅▆▃▃▃▆▃▇█▂▂█▄▆▄▄▃▁▄▇▃▄▄▇▆▃▄▃▂▄▂▂▆█▇▂
wandb:         train/mil_loss ▂▂▂▂▅▁▄▂▁▁▂▄▃▁▂▂▃▂▂▁▂▁▁▂▆█▁▁▁▁▃▃▁▆▁▂▁▃▂▁
wandb:      train/policy_loss ▄▄▄▄██▃▄▄▄▄▃▄▄▄▄▃█▄▄▄▄▄▄▄▄█▄██▁▃▄▄▃▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▄▆▄▃██▄█▃▄▄▄▄▄▄▄█▄▄█▄█▄▆█▄▄▄▁▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67825
wandb: best/eval_avg_mil_loss 1.0327
wandb:  best/eval_ensemble_f1 0.67825
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.9133
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78865
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.56781
wandb:      train/ensemble_f1 0.56781
wandb:         train/mil_loss 0.80374
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ktk8ot8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182240-0ktk8ot8/logs
wandb: Agent Starting Run: txs9hlcr with config:
wandb: 	actor_learning_rate: 0.00012758134666746043
wandb: 	attention_dropout_p: 0.26249176145959263
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9726828887078386
wandb: 	temperature: 2.8035090396077553
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182423-txs9hlcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/txs9hlcr
wandb: uploading history steps 97-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆████
wandb: best/eval_avg_mil_loss █▅▇▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▆████
wandb:            eval/avg_f1 ▁▄▃▄▃▃▃▁▆▇▇▃▄▃▇▇▄▂▃▂▂██▅▇▂▆▄▇▁▃▅▆▇▄▄▇▂▃▆
wandb:      eval/avg_mil_loss ▆▆▅▄▂▆▆▆▄▃▆▇▂▃▄▄▆▂▃▆▅▁▆█▆▃▃▅▄▃▁▅▅▃▅▅▃▆▆▆
wandb:       eval/ensemble_f1 ▄▆▄▄▄▃▃▁▂▂█▅▂▆▂▄▄▇▄▃▆▅█▅▇▅▆▄▇█▂█▃▄▄▄▇▆▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▅▃▃▅▄▄▃▅▆▄▁▆▆▅▄▁▅▆▄▆▃██▄▃▄▅▅▄▅▄▆▅▄▇▃▇
wandb:      train/ensemble_f1 ▅▃▃▅▃▆▄▃▅▂▁▆▁▁▃▅▄▁▆▆▃▆▆█▆▆▄▄▅▄▆▅▄▇▅▅▅▃▂▇
wandb:         train/mil_loss ▂▆▂▇▂▃▆▃▅▃▆▄█▅▄▂▅▆▇▃▁▇▅▄▄▅▅▅▁▄▅▂▃▄▆█▆▅▄▆
wandb:      train/policy_loss ▆▃▄▄▄▄▃▃▄▃▄▄▄▄▃█▆█▄▃▇▆▄▄▁▄▃▆▆▄▃▆▇▄▄█▄▇▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▆▅▆▃▅▇▅▃▁▅▅▆▅▆▅▆▅▇▅▄▃▃▄▆▆▆▃▆▄▆▆█▆▅▄▃▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82998
wandb: best/eval_avg_mil_loss 0.48678
wandb:  best/eval_ensemble_f1 0.82998
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.85007
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.77827
wandb:      test/avg_mil_loss 0.46076
wandb:       test/ensemble_f1 0.77827
wandb:           train/avg_f1 0.69149
wandb:      train/ensemble_f1 0.69149
wandb:         train/mil_loss 0.85818
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/txs9hlcr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182423-txs9hlcr/logs
wandb: Agent Starting Run: 8nbiijvd with config:
wandb: 	actor_learning_rate: 0.00027866947248857273
wandb: 	attention_dropout_p: 0.29021305158334004
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8856373544705419
wandb: 	temperature: 5.302847038575607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182546-8nbiijvd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8nbiijvd
wandb: uploading history steps 122-128, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▆▆██
wandb: best/eval_avg_mil_loss █▆▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▆▆▆██
wandb:            eval/avg_f1 ▂▆▆▁▆▆▄▆▆▂▄▇▆▇▂▁▁█▁▆██▆▄▆▁▅▄▇▁▆▇▁▆▄▂▁▁▂▁
wandb:      eval/avg_mil_loss ▆▁▇▇▁▂▁▁▁▁▃▂▁▇▁▃▁▁▃▁▁▁▁▁▁▃█▂▁▁▁▆▁▁▁▅▁▁▆▁
wandb:       eval/ensemble_f1 ▁▁▆▁▆▆▃▅▄▆▄▇▁▆▁▁▇▁▆▂▄█▆▄▆▆▃▂▆▁▆▄▁▆▁▁▆▄▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▁▃▂▄▆▄▆▄▆▇▆█▃▅▅▆▃▅▆▆▆▇▆█▄▆▅▂▆▅▃▆▆▆▃▄▅▅
wandb:      train/ensemble_f1 ▄▆▆▂▇▄▅▆▅▅▄▇▆▅▄▆▅▅▆▅▆▄▆▆▅▅▅▁▆▅▅▄▃▅█▅▆▃▂▅
wandb:         train/mil_loss ▃▃▂▂▅▂█▆▁▄▆▃▇▄▄▄▇▃▄▄▃▃▂▆▃▅▁▁▃▃▆▅▆▃▆▃▆▇█▁
wandb:      train/policy_loss ▅▁▃█▁▃█▁▁▅▅▅▅▅▁▅▁▅▅█▅▅▅▅▅█▅█▅▅▁▁▅▅▁█▅▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▁▅█▁█▁▅▅▅▅▅▁▅▅▅▅▅▅▅█▅▅▅█▅▅▅▅▅▅▁▁██▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.71001
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.25476
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.68972
wandb:      test/avg_mil_loss 0.92278
wandb:       test/ensemble_f1 0.68972
wandb:           train/avg_f1 0.61925
wandb:      train/ensemble_f1 0.61925
wandb:         train/mil_loss 0.56042
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8nbiijvd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182546-8nbiijvd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0rab0x7x with config:
wandb: 	actor_learning_rate: 0.0006707919818183768
wandb: 	attention_dropout_p: 0.27311355237045104
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 136
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8871692707517324
wandb: 	temperature: 4.759526637378238
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182736-0rab0x7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/myc2hcl9
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0rab0x7x
wandb: uploading history steps 120-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▁▁█▁▁▁▁▅▆▅█▃▃▁▁▃▂▂█▆█▅▂▅▇▁▁▅▂▄▁▃▁▁▂▁▁▂▇▁
wandb:      eval/avg_mil_loss ▄▂▁▁▁▂▄▄█▂▁▁▁▁▁▁▁▂▁▁▁▁▁▂▂▂▄▁▁▁▁▄▁▁▁▁▁▁▁█
wandb:       eval/ensemble_f1 ▁▆▇▇█▁▃▁▅█▁▂▃▄▃▇▁▃▇█▃▄▅▇▁▅▁▃▂▄▁▁▁█▁▇▁▁▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▄█▆▇▁▅▄▆██▄█▆▆▇▂▆▅█▄▆▅▃▄▇▃▄▃▇▅▆▅▅▅▆▆▄
wandb:      train/ensemble_f1 ▅▁▅▆▇▄▆▆▆▄▄▆▆▃▃▇███▇▆▆▇▃▆▄▆▃▆▄▃▅▇▇▅▆▆▅▄▇
wandb:         train/mil_loss ▇▁▃▅▂▃▃▄▄▂▂▂▃▅▁▄▂▂▂▅▇▇▂▄▄█▆▅▄▂▅▂▄▁▆█▂▃▃▅
wandb:      train/policy_loss ██████████████████████████████████▁█████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▃█▅▅▃▆▅▃▁▆▅▆▅▁▃▅▁▃▅▃▅▅▅▆▅▆▁▅▅▅▅▁▃▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.63489
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 6.36793
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.62364
wandb:      test/avg_mil_loss 1.65938
wandb:       test/ensemble_f1 0.62364
wandb:           train/avg_f1 0.57326
wandb:      train/ensemble_f1 0.57326
wandb:         train/mil_loss 1.86397
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0rab0x7x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182736-0rab0x7x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: yzrmtmxk with config:
wandb: 	actor_learning_rate: 0.00026913437579637414
wandb: 	attention_dropout_p: 0.4729227411767354
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 144
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11734714605571284
wandb: 	temperature: 7.349783921472618
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182954-yzrmtmxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yzrmtmxk
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 137-145, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇██
wandb: best/eval_avg_mil_loss ▃▃▃▁█
wandb:  best/eval_ensemble_f1 ▁▂▇██
wandb:            eval/avg_f1 ▃▁▅▁▁▃▁▁▃▃█▁▃▁▁▁▅▁▃▁▄▁▁▃▃▃▄▁▁▁▃▃▁▁▁▃▁▁▁▂
wandb:      eval/avg_mil_loss ▁▁▁▁▂▁▂▁▃▁▁█▁▁▁▁▁▁▁▁▁▁▂▁▁▄▁▁▁▁▁▁▁▃▁█▁▁▁▃
wandb:       eval/ensemble_f1 ▇▃▁▃▅▁▃▄█▁▁▁▃▃▃▁▁▁▁▃▁▃▁▃▁▄▁▃▃▅▁▃█▁▃▁▄▃▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▅▅▁█▇▅▄▇▇▅▆▇▇▁█▆▅▅▅▇▅▇▅▇▇▆▅▆▅▇█▆▆▂▇▅▇▇
wandb:      train/ensemble_f1 ▄▅▁▅▅▁█▇█▄▅▅▆▇▅▁▆▅█▅▅▅▆▆▅▇▇▅▆▇▄▆▆█▆▆▆▇▇▇
wandb:         train/mil_loss ▆▄▁▄▄▃▃▇▇▄▄▂▇▂▄▃▄▁▃▁▂▄▆▃▇▂█▇▅▂▅▅▆▆▁▁▂▅▂▄
wandb:      train/policy_loss ▃▃▃▆▁▃▁▃▁▁▆▁█▁▃▁▃▁▁█▁▃▆▃▁▃▃▃▃▃▁▆▃▆▃▃▁▆▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▆▃▃▃▃▆▁█▁▁▁▁▁▁▁▁▃▆▁▃▃▆▁▃▃▆▃▁▃▃▁▃▃▆▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54226
wandb: best/eval_avg_mil_loss 1.39821
wandb:  best/eval_ensemble_f1 0.54226
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.22177
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79393
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.54094
wandb:      train/ensemble_f1 0.54094
wandb:         train/mil_loss 2.70677
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yzrmtmxk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182954-yzrmtmxk/logs
wandb: Agent Starting Run: lzlqydk2 with config:
wandb: 	actor_learning_rate: 1.115240645935278e-05
wandb: 	attention_dropout_p: 0.3128901586382911
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.030153169846760863
wandb: 	temperature: 5.500302446870497
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183153-lzlqydk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lzlqydk2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▆▅▃▂█▇█▅▆▂▇▁▂▅▄█▇▇▇▅▆▂▂▆██▆▆▆▅▇▅▇▇▅▆▆▇▁▄
wandb:      eval/avg_mil_loss ▂▅▁▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▄▂▁█▂▁▂▂▄▁▁▂▁▁▂▂▂▂▁▂▃▂
wandb:       eval/ensemble_f1 ▇▃▇▇█▆▅▇▂▄▇▄▅▅▁▆▂▅▅▅▂█▁▄█▆▅▇▆█▅▇▅▇▅▆▄▅▇▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅█▆▄▅▂▄▆▇▄▇▃▃▃▅▂▆▆▆▃▅▄▆▄▃▁▆▂▄▆▄▄▆▄▄▄▄▄
wandb:      train/ensemble_f1 ▅▅█▆▄▅▄▄▆▆▅█▆▃▅▄▄▅▂▄▆▃▄▄▁▄▆▆▂▄▄▂▅▅▁▄▄▄▄▄
wandb:         train/mil_loss ▃▄▃▄▂▄▃▄▅▂▆▂▃▆▃▃▃▆▄▄▂▃▅▂▃▃▇▃▅▄▄▃█▂▂▃▅▃▁▄
wandb:      train/policy_loss █▁▅▃▅▅▆▆▅▆█▄▇▆▅▅▃▃▅▆▅▃▃▆▃▆▁▄▃▃▁▅▆▅▅▃▆▆▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄█▆▆▆▅▆█▆▆▃▆▄▄▃▃█▆▁▆▃▄▃▃▁▆▃▄▆▁▃▄▁▄▆▆▄▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.69083
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.5671
wandb:      eval/avg_mil_loss 0.93747
wandb:       eval/ensemble_f1 0.5671
wandb:            test/avg_f1 0.67987
wandb:      test/avg_mil_loss 1.60342
wandb:       test/ensemble_f1 0.67987
wandb:           train/avg_f1 0.66639
wandb:      train/ensemble_f1 0.66639
wandb:         train/mil_loss 1.36489
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lzlqydk2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183153-lzlqydk2/logs
wandb: Agent Starting Run: rbnj27hf with config:
wandb: 	actor_learning_rate: 1.3155467698722656e-05
wandb: 	attention_dropout_p: 0.15111665854008657
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 111
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1383892236433424
wandb: 	temperature: 3.331079671518
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183321-rbnj27hf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbnj27hf
wandb: uploading history steps 101-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▁▃▂▃█▆▄▇▁▃▁█▇▁▂▃▁██▂▇▃█▃▁▁▇▃█▇▁▆▇▂▅▇▂▃▆▂
wandb:      eval/avg_mil_loss ▃▁▂▂▁▁▁▃▁▁▁▁▃▁▁██▁▁▁▁▁▂▁▁▃▃▁▁▁▃▁▁▁▁▂▁▂▃▃
wandb:       eval/ensemble_f1 ▂█▆▂▇▄▅▇▁▃▁▃█▆▄█▇▁▁▂▁▃▃▃▂▁▂▂▃▂▇▃▅▇▁▂▂▇▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▄▅▇▁▃▄▄▃▇▅▄▆▇▆▂▄▄▆█▄▄▃▄▆▆▂▃▁▄▄█▄▅▄▂▆▃▅
wandb:      train/ensemble_f1 ▇▃▂▄▂▅▅▅▅▇▄▄▁▅▅█▇▅▅▄█▄▄▃▃▄▂▄▆▂▁▆▄█▄▅▃▂▅▄
wandb:         train/mil_loss ▃▇▂▃▁▃▁▃▃▂▁▅▃█▂▂▂▄▅▃▂▅▃▁▂▄▆▅▂▃▂▃▃▅▂▂▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.71886
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.79708
wandb:      eval/avg_mil_loss 0.71001
wandb:       eval/ensemble_f1 0.79708
wandb:            test/avg_f1 0.84615
wandb:      test/avg_mil_loss 0.40886
wandb:       test/ensemble_f1 0.84615
wandb:           train/avg_f1 0.72613
wandb:      train/ensemble_f1 0.72613
wandb:         train/mil_loss 1.07384
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rbnj27hf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183321-rbnj27hf/logs
wandb: Agent Starting Run: fdcbmyzn with config:
wandb: 	actor_learning_rate: 2.0294374627918786e-06
wandb: 	attention_dropout_p: 0.3617270770562791
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.667668473635963
wandb: 	temperature: 3.551665331525524
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183449-fdcbmyzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdcbmyzn
wandb: uploading history steps 102-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅▆▆▆▇█
wandb: best/eval_avg_mil_loss ▂▆█▂▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▅▆▆▆▇█
wandb:            eval/avg_f1 ▁▇▂▇▁▁▁▁▆▁▁▆▃▃▄▁▇▇▅█▂▁▁▃▂▁▅▁▄▁▂▇▇▂▁▁▅▃▁▇
wandb:      eval/avg_mil_loss ▂▄▅▅▂▂▅▅▂▂▂▂▂▂▂▁▂▂▂█▁▂▁▅▂▅▁▂▅▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▂▁▂▁▁▁▁▅▁▁▂▅▁▃▄▆▁▁▁▆▁▂▅▆▁▂█▁▁▃▁▆▂▂▆▁▁▁▅▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄█▆▃▅▅▄▄▆█▄▃▅▄▆▆▅▄▄▆▅▄▄▄▆▆▅▅▃▄▅▂▆▄▅▅▆▁
wandb:      train/ensemble_f1 ▅▃█▅▅▂▅▄▄▅▃▃▄▄▄▄▅▆▄▂▂▃▆▅▃▃▆▆▅▃▄▅▆▄▃▅▁▅▅▅
wandb:         train/mil_loss ▂▂▃▇▁▅█▄▄▅▃▂▃▃▆▃▄▃▃▂▄▄▂▃▂▃▂▆▂▁▃▂▅▃▂▂█▆▂▁
wandb:      train/policy_loss ▁▆▆██▁▆▆▆▃█▆▆▆█▃▁▆█▆▁▃▆▃▆▆█▆█▆▆█▆█▃█▆▁▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▆▆▁▁▆▁▃▁▅▅▅▆▅▅▅▅▅▃▅▅▆▅▆▁▁▅█▅▃▃▃▆▅█▃▅▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.72922
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.67794
wandb:      eval/avg_mil_loss 0.98327
wandb:       eval/ensemble_f1 0.67794
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.40839
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.4381
wandb:      train/ensemble_f1 0.4381
wandb:         train/mil_loss 0.83282
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fdcbmyzn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183449-fdcbmyzn/logs
wandb: Agent Starting Run: 7zg63l7e with config:
wandb: 	actor_learning_rate: 1.2706446435935264e-06
wandb: 	attention_dropout_p: 0.48355407771813946
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 99
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5021306017705487
wandb: 	temperature: 3.772992324787896
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183611-7zg63l7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7zg63l7e
wandb: uploading history steps 82-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▄
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▄▂█▃▂▄▄▄▁▂▂▁▁▁▃▄▁▁▄▃▁▅▁▂▄▁▁▃▄▄▄▄▁▄▂▃▃▄▁▁
wandb:      eval/avg_mil_loss ▂▂▁▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂
wandb:       eval/ensemble_f1 ▇▁▄▂▄▁▁▃▁▃▂▁▄▁▁▁▁▄▁▅▄▂▂▃▃▄▄▄▂▂▂▄▄▂▄▅▃█▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▂▅▆▂▄▁▆▄▃▄▃▄▆▄▇▇█▅▂▆▄▁▄▃▄▆▃▄▃▃▄▅▁▆▅▅▃
wandb:      train/ensemble_f1 ▄▄▂▂▇▄▅▄▂▆▂▄▃▂▆▂▇▇█▃▄▁▅▂▃▆▃▃▃▅▃▄▄▃▆▁▅▃▆▂
wandb:         train/mil_loss ▂▄▅█▂▂▃▃█▆▃▃▂▁▂▄▂▃▂▁▂▂▇▄▃▂▅▅▂▃▂▃▄▁▂▁▂▃▂▃
wandb:      train/policy_loss ▃▆█▃▆▆▃▅▃▃▅▆▃▅▆▃▆▅▃▃█▅▃█▅▅▃█▃▃▅▃▅▆▅▃▃▅▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▃▃▅▆▃▅▅▁▃▃▃▃▆▅▃▃█▅▃▃▆▅▆▅▃▅▆▃▅▅▅▅▃█▃▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79798
wandb: best/eval_avg_mil_loss 0.76517
wandb:  best/eval_ensemble_f1 0.79798
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.31263
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.77182
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.49811
wandb:      train/ensemble_f1 0.49811
wandb:         train/mil_loss 0.9558
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7zg63l7e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183611-7zg63l7e/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5di86wqs with config:
wandb: 	actor_learning_rate: 5.5385515632343246e-05
wandb: 	attention_dropout_p: 0.025353455996389215
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10131481226008
wandb: 	temperature: 2.821154034409195
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183739-5di86wqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5di86wqs
wandb: uploading history steps 174-184, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▇█
wandb: best/eval_avg_mil_loss ██▃▁
wandb:  best/eval_ensemble_f1 ▁▅▇█
wandb:            eval/avg_f1 ▅▂▁▄▄▃▄▂▁▂█▆▂▂▃▂█▄▂▄▂▂▅▄▁▂▃█▁▆▂▄▄▁▃▆▄▄▄▃
wandb:      eval/avg_mil_loss █▆█▆▇▇▇▃█▇▅▆█▇▇▆▄▄▅▇▆▅▆▅▃▇▆▄▁▆▄▄▇▅▇▅▄▅▆▅
wandb:       eval/ensemble_f1 ▄▆█▄▁▄▅▂▃▃▄▇▄▄▃█▁▃▄▂▂▁▃▂▃▅▃▇▃▄▂▃▄▂▅▂▁█▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▁▅▆▆▇▄▂▂▄▃▅▃▃▂▄▁▂▆▆▂▇▃▄▄▅▂▃▅▄▄█▄▆▄▅▃▅
wandb:      train/ensemble_f1 ▄▃▂▅▆▃▅▆▆▄▅▅▃▅▄▃▁▄▆▄▅▄▄▇▄▄▆▅█▂▃▅▃█▄▆▂▅▆▃
wandb:         train/mil_loss ▃▆▆██▂▇▅▆▅▇▃▃▄▄▁▄▅▄▃▅▅▃▃▃▃▅▄▃▄▃▃▁▅▂▅▄▂▅▂
wandb:      train/policy_loss ▆▆▃▅▄▅▆▆▅▄█▅▃▃▅▁▃▅▅▆▅▃▆▅▅▅▅▄▅▅▇▁▅▇▅▆▅▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▇▁▁▅▂█▅▁▄▇▄▇▁▄▁▇▂▄▄▁▄▄▄▄▄▄▁█▄▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80952
wandb: best/eval_avg_mil_loss 0.42596
wandb:  best/eval_ensemble_f1 0.80952
wandb:            eval/avg_f1 0.71955
wandb:      eval/avg_mil_loss 0.76745
wandb:       eval/ensemble_f1 0.71955
wandb:            test/avg_f1 0.76942
wandb:      test/avg_mil_loss 0.70167
wandb:       test/ensemble_f1 0.76942
wandb:           train/avg_f1 0.49313
wandb:      train/ensemble_f1 0.49313
wandb:         train/mil_loss 0.80591
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jolly-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5di86wqs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183739-5di86wqs/logs
wandb: Agent Starting Run: eprlshwa with config:
wandb: 	actor_learning_rate: 0.0009211697330455284
wandb: 	attention_dropout_p: 0.4481896683712695
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8054696940480269
wandb: 	temperature: 3.1280297111780673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184008-eprlshwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eprlshwa
wandb: uploading wandb-summary.json; uploading history steps 83-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▅▅▅▆▁▁▁▁▅▁▁▁▅▄▅▆▅▅▅▆▁▄▁▇▇▁▅▆▄▅▁▁▂▄▁▅▆▁▅█
wandb:      eval/avg_mil_loss ▁▁▁▁▅▅▁▁▅▆▁▅▁▆▁▁▁▇▁▇▄█▁▁▆▅▇▅▆█▁▇▁▁▃▁▁▇▁▁
wandb:       eval/ensemble_f1 █▄▄▁▄▁▁▄▁▁▁▂▄▁▄▄▁▆▄▁▁▁▄▁▁▄▆▄▅▁▁▂▅▃▁▄▅▁▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▆▁▅▇▆▆▇▅▇▂▇▅▇▇▆▅▄▂▆▆▅▆▇▇▇▅▅▇▂▆▆▁▆▆▇▆██
wandb:      train/ensemble_f1 ▆▆▇▇▅▆▇▇▆▆▆▅▇█▇▆▇▇▆▇▇▇▅▇█▃▆▇▇▁▇▅█▇▂▇█▇█▆
wandb:         train/mil_loss ▇▆▅▅▃▇▆▄▆▄▆▃█▁▃▄▄▇█▄▄▄▃▁▂▃▆▃▄▅▃█▆▃▃▅▄▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70927
wandb: best/eval_avg_mil_loss 0.81408
wandb:  best/eval_ensemble_f1 0.70927
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.83168
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 4.60937
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.49542
wandb:      train/ensemble_f1 0.49542
wandb:         train/mil_loss 4.14544
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eprlshwa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184008-eprlshwa/logs
wandb: Agent Starting Run: nkd4f2wo with config:
wandb: 	actor_learning_rate: 0.0008839643206122297
wandb: 	attention_dropout_p: 0.3839380834228138
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 100
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.657327555515334
wandb: 	temperature: 3.7190052592616016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184131-nkd4f2wo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nkd4f2wo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆██
wandb: best/eval_avg_mil_loss █▁▄▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆██
wandb:            eval/avg_f1 ▂▂▂▂▂▂▃█▅▅▃▃▄▄▇▄▂▂▂▂▁▂▃▄▆▆█▃█▂▁▂▁▅▃▂▁▂▂▂
wandb:      eval/avg_mil_loss █▁▁▁▁▃▄▁▁▆▁▁▁▂▁▁▁▃▄▁▁▁▁▁▁▃▂▁▃▁▁▁▁▁▅▁▁▁▁█
wandb:       eval/ensemble_f1 ▄▁▁▁▅▁▄▄▁▂▃▁▆▆▁▂▁▁▇▁▆▁▃▁▃▆▆▁▂▁▂▁▄▁█▂▁▁▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▁▃▂▇▂▂▃▄▄▅▄▂▂▆▄▄▂▂▂▃▆▄▂▆▁▅▆█▂▃▃▄▇▃▄▅▃▃
wandb:      train/ensemble_f1 ▆▅▄▇▇▇▅▅▇▅▄▇▅█▆▄▅▅▆▄▇▅▄▆▇▆▄██▁▅▇▅▅▆▆▃▅▅▅
wandb:         train/mil_loss ▂▂▁█▁▁▄▂▁▃▁▁▄▁▂▄▁▂▁▁▄▁▄▁▃▁▁▁▁▆▁▂▁▄▁▃▃▄▂▄
wandb:      train/policy_loss ▅▅▅▁▅▅▄▅▅▅▅▅▅▅█▅▅▇▅▅▅▃▅▅▇▅▆▄▅▅▅▅▅▃▇▅▅▇▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▁▅▅▅█▅▅▅▅▁▅▄▅▅▅▅▆▁▄▅▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75
wandb: best/eval_avg_mil_loss 0.69732
wandb:  best/eval_ensemble_f1 0.75
wandb:            eval/avg_f1 0.36228
wandb:      eval/avg_mil_loss 4.60838
wandb:       eval/ensemble_f1 0.36228
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.79732
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.49407
wandb:      train/ensemble_f1 0.49407
wandb:         train/mil_loss 1.32063
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nkd4f2wo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184131-nkd4f2wo/logs
wandb: Agent Starting Run: 48uxp0yi with config:
wandb: 	actor_learning_rate: 5.24751096033432e-06
wandb: 	attention_dropout_p: 0.038552082023308565
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 168
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07559860229871651
wandb: 	temperature: 5.337280118488684
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184254-48uxp0yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/48uxp0yi
wandb: uploading history steps 103-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃█
wandb: best/eval_avg_mil_loss ▆█▄▁
wandb:  best/eval_ensemble_f1 ▁▂▃█
wandb:            eval/avg_f1 ▂▂▁▁▃▁▄▂▁▁▁█▁▄▁▅▁▄▁▂▆▁▁▁▁▁█▁▁▃▁▇▄▁▁▆▇▁▁▁
wandb:      eval/avg_mil_loss ▁▂▁▂▂▂▂▁▂▃█▂▁▁▂▄▂▂▁▂▂▂▂▁▁▂▂█▂▂▃▂▁▂▄▂▇▂▂▁
wandb:       eval/ensemble_f1 ▁▂▁▂▁▁▅▁▁█▄▁▁▁▁▅▃▂▇▁▁▄▆▁▃▁▁▄▁▂▃▁▁▁▁▁▂▁▆▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▂▇█▅▅▄▂▇▅▁▄▃▃▃▆▂▅▅▆▅▆▂▇▆▄▇▇▅▇▇▆▃▆▅▆▁▆
wandb:      train/ensemble_f1 ▅▂▆▇▆█▄▅▅▅▇▂▅▅▃▇▆▁▃▅█▆▄▃▅▄▆▆▅▄▆▇▅▅▃▅▇▄▇▅
wandb:         train/mil_loss ▄▁▄▂▄▂▂▆▂▅▁▄▂▄▁▁▄▂█▅▅▁▁█▅▃▁▂▁▁▃▂▁▂▃▄▄▁▂▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75962
wandb: best/eval_avg_mil_loss 0.57916
wandb:  best/eval_ensemble_f1 0.75962
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 4.79495
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.84267
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.5431
wandb:      train/ensemble_f1 0.5431
wandb:         train/mil_loss 2.40614
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/48uxp0yi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184254-48uxp0yi/logs
wandb: Agent Starting Run: ofwjslpm with config:
wandb: 	actor_learning_rate: 2.9221704615670637e-05
wandb: 	attention_dropout_p: 0.19441097685495912
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 85
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06684319384612625
wandb: 	temperature: 3.278330859032513
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184416-ofwjslpm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ofwjslpm
wandb: uploading history steps 82-86, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅███
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅███
wandb:            eval/avg_f1 ▅█▁▅▇▄▆▁▁▂▁▁▁▅▁▁▃▅▁▁▁▅▁▃▃▇▁▁▁▁▁▅▁▁▄▁▅▁█▁
wandb:      eval/avg_mil_loss ▄▁▁▂▁▂▄▁▂▂▄▄▂▄▁▂▁▂▂▅▂▂▂▂▂▂▂▁▂▃▂▂█▁▄▃▂▃▂▄
wandb:       eval/ensemble_f1 ▁▅▁█▂█▄▁▁▁▁▁▁▁▁▇▃▁▁█▁▂▃▇▁▁▃▁▁▆▁▂▅▁▁▂▁▄▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▅▅▅▆▁▂▆▇▆█▂▃▅▄▇▄▅▆▆▅▅▅▄▅▅▅▅▂▇▇▄▃▅▄▂▅▅▄
wandb:      train/ensemble_f1 ▇▃▄▅▆▅▄▆█▁▅▄▃▇▄▆▅▄▅▅▆▅▄▅▃▅▄▅▅▅▇▇▄▃▃▄▄▄▄▅
wandb:         train/mil_loss ▃▄▄▄▃▆▂▄▇▆▂▁▂▅▇▂▂▂▄▁▂▂▃▂▂▃▂▃▃▄█▃▁▆▄▂▃▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.71499
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.77168
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.8492
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.52867
wandb:      train/ensemble_f1 0.52867
wandb:         train/mil_loss 0.91348
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ofwjslpm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184416-ofwjslpm/logs
wandb: Agent Starting Run: ixhyft0o with config:
wandb: 	actor_learning_rate: 0.0003274183802552022
wandb: 	attention_dropout_p: 0.002720492959905118
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11082135899446066
wandb: 	temperature: 3.837553431956719
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184523-ixhyft0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ixhyft0o
wandb: uploading history steps 133-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▇█
wandb: best/eval_avg_mil_loss █▂▁▂▃
wandb:  best/eval_ensemble_f1 ▁▄▄▇█
wandb:            eval/avg_f1 ▇▂▁█▅▃▂▂██▆▃▄▄▃▄▁▃▆▆▄▇▇▁▄▄█▇▄▁▃▂▇▁▇▇▃▂▁▁
wandb:      eval/avg_mil_loss ▃▁▆▆▁▂▂▁▃▇▆▂▂▁▁▄▁▂▁▇█▆▁▂▃▁▂▅▇▅▁▆▂▁▁▄▂▇▅▇
wandb:       eval/ensemble_f1 ▇▄█▃▇▁▃▃▃▄▃▇▅▄▄▆▂▅▄▃▃▅▇█▇▂▁▂▅▁▇▂▄▅▇▇▄▄▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▆▁▃▄▇▅▄▄▅▅▇▄▄▄▆▅█▆▄▇▃▆▄▅▃▁▅▂▄▇▆▄▆▅▅▄▆▄
wandb:      train/ensemble_f1 ▅▆█▅▆▅▄▃▄▅▇▆▇▄▅▄▆▁█▇▆▆▆▅▇▆▅▆▄▄█▆▇▆▅▆▅▇▅▅
wandb:         train/mil_loss ▆▃▁▁▅▃▅▃▂▇▃▂▅▄▃█▄▃▃▃▂▂▄▁▄▄▂▂▅▄▄▂▃▄▃▃▃▃▄▄
wandb:      train/policy_loss ▄▅▆▃▅▅▆▄▄▅▅▅▆▅▅▅█▅▃▆▅▇▅▅▅▅▁▅▅▃▃▆▃▁▆▆▅▃▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▃▅▃▆▄▄▅▄▃▅▄▅▆▅▇▅▅▆▃▅▆▆▆▁▅▆▃▅█▄▆▃▅▃▅▃▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71062
wandb: best/eval_avg_mil_loss 1.12771
wandb:  best/eval_ensemble_f1 0.71062
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.62561
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.5
wandb:      test/avg_mil_loss 3.94527
wandb:       test/ensemble_f1 0.5
wandb:           train/avg_f1 0.54493
wandb:      train/ensemble_f1 0.54493
wandb:         train/mil_loss 2.77388
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ixhyft0o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184523-ixhyft0o/logs
wandb: Agent Starting Run: 715179gj with config:
wandb: 	actor_learning_rate: 0.00011743959111859514
wandb: 	attention_dropout_p: 0.1066777702592897
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19145491841758033
wandb: 	temperature: 2.3277565418302073
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184717-715179gj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/715179gj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇██
wandb: best/eval_avg_mil_loss █▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▃▇██
wandb:            eval/avg_f1 ▃▃▆▃▃▃▁▄▆▄█▄▆▁▂▂▆▂▇▂▃▅▆▇▃▇▃▂▇▅▂▃▂▄▅▃▄▇▇▄
wandb:      eval/avg_mil_loss ▁▁▂▂▂▃▂▂▂▁▁▁█▂▁▁▁▂▁▂▂▂▁▂▁▁▅▂▂▂▂▂▁▂▃▁▁▁▁▆
wandb:       eval/ensemble_f1 ▆▁▂▆▆▆▄▆██▁▁▃▆▂█▂▆▂▂▂▇▄▄▃▇▃▇▇▁▆▄▂▃▄▆▄▂▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▄▆▆▃▅▇█▅▇▃▂▁▆▁▆▅▄▇▅▇▆▄▅▇▃▅▄▅▅▂▄▂▄▂▃█▆
wandb:      train/ensemble_f1 ▄▆▅▅▄█▁▅▇▇▄▃▂█▆▇▅▇▄▇▄▃▆▄▅▃▅▄▅▅▄▅▅▂▄▄▂█▆▄
wandb:         train/mil_loss ▆▂▂▂▇▃▃▂▂▂▅▅▆▁▅▃▂▄▅▇▂▃▅▅▄▆▆█▄█▆▇▃▄▆▆▂▂▁▃
wandb:      train/policy_loss ▇▄▅▃▃▅█▁▆▅▁▅▆▄▅▇▄▄▆▁█▅▁▅▅▅▅▅▇▇▃▅▅▆▃▅▄▆▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▄▅▆▄▄▃▇▃▃▃██▄▅█▇█▅▅▃▅▅▇▇▁▃▇▄▅▃▄▁█▇▅▅▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.52368
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.57033
wandb:      eval/avg_mil_loss 0.74777
wandb:       eval/ensemble_f1 0.57033
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.71513
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.58984
wandb:      train/ensemble_f1 0.58984
wandb:         train/mil_loss 1.57558
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/715179gj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184717-715179gj/logs
wandb: Agent Starting Run: n2lfh1sr with config:
wandb: 	actor_learning_rate: 2.7405737415106452e-06
wandb: 	attention_dropout_p: 0.24403230987701147
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 98
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6595736393702996
wandb: 	temperature: 3.777633266532191
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184905-n2lfh1sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n2lfh1sr
wandb: uploading history steps 82-99, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▃▇▂▇▆▇▁█▄▃▂█▄▃▁▄▁▇▄▃▆▄▇▁▄▇▄▃▇▇▄▁▄▇▄▃▃▇
wandb:      eval/avg_mil_loss ▅▁▄▄▂█▄▃▄▄▆▅▂▄▄▄▄▃▃▆▂▄▃▄▅▄▃▆▂▄▆▆▁▃▂▄▇▅▂█
wandb:       eval/ensemble_f1 ▆▇▃▇▁▂▇█▆▇▇▄▃▃▆▄▄▁▃▁▇▄▇▁▁▆▇▃▃▃▇▇▁▇▇▇▇▃▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▆▅▅▅▄▅▄▄▄▆▄▇▆▅▄▆▃█▄█▁▃▄▇▇▅▅▆▅▄▆▄▆▂▄▅▆▁
wandb:      train/ensemble_f1 ▇▆▃▅▄▇▄▃▁▄▆▇▂▅▅▆▇▃█▄▃▇▇▅▅▆▇▄▄▅▄▄▃▄▆▄▅▁▁▆
wandb:         train/mil_loss ▄▅▇▁▆▄▄▂▂▄▂▄▄▇▃▂▆█▅▅▄▅▆▃▅▄▅▅▁▄▇▃▇▂▅▃█▄█▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79968
wandb: best/eval_avg_mil_loss 0.61265
wandb:  best/eval_ensemble_f1 0.79968
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 1.30804
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.70974
wandb:      test/avg_mil_loss 0.93078
wandb:       test/ensemble_f1 0.70974
wandb:           train/avg_f1 0.69852
wandb:      train/ensemble_f1 0.69852
wandb:         train/mil_loss 0.9771
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n2lfh1sr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184905-n2lfh1sr/logs
wandb: Agent Starting Run: 25ii14ki with config:
wandb: 	actor_learning_rate: 1.4637604204758348e-06
wandb: 	attention_dropout_p: 0.4048425227597511
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 99
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7001885305024671
wandb: 	temperature: 4.367038866668315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185023-25ii14ki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25ii14ki
wandb: uploading history steps 81-100, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂█
wandb: best/eval_avg_mil_loss █▆▆▁
wandb:  best/eval_ensemble_f1 ▁▁▂█
wandb:            eval/avg_f1 ▁▄▄▃▄▃▃▂▄▃▃▁▃▃▃▃▂▄▁█▄▄▄▁▃▂▄▁▄▃▃▄▄▃▁▄▃▁▁▃
wandb:      eval/avg_mil_loss ▂▁▁▁▁▁▂▁▁▁▂▂▂▂▁▂▂▂▂▁▁▂▁▁▂▁▁▁▁█▁▁▁▂▁▂▂▁▂▂
wandb:       eval/ensemble_f1 ▄▃▄▃▃▄▄▁▄▄▃▄▃▁▃▁▃▄▁█▄▄▃▃▄▄▁▃▄▄▂▄▄▃▃▃▁▁▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▄▄▃▆▃▅▄▄▂▁█▆▂▂▆▃▃█▇▁▆▂▃▄▃▃▆▆▇▅▃▃▇▃▃▃▂▅
wandb:      train/ensemble_f1 ▅▃▃▄▇▄▄▄▃▄▄▁▁█▆▄▆▃▃▄▂▂▂▃▃▃▄▆▂▂▂▂▇▃▃▂▄▅▂█
wandb:         train/mil_loss ▅▃▄▃▁▂▅▃▅▃▄▃▄▄▂▁▄▂▃▆▄▂▄▃▄▂▂▃▄▃▄▅▅▁▂▂▄█▃▄
wandb:      train/policy_loss ▃▁▁▁▃▃▁▃▃▁▃▃█▃▁▁█▁▃▃▁▁▃▁█▃▁▃▁▁▁▁▁▁█▃▃▃▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▁▃▃▃▁▃▃█▁█▃▃▁▁█▃▁▃▃▁▃█▁█▁▃▁▁▃▁▁▆▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72678
wandb: best/eval_avg_mil_loss 0.82241
wandb:  best/eval_ensemble_f1 0.72678
wandb:            eval/avg_f1 0.44148
wandb:      eval/avg_mil_loss 0.97314
wandb:       eval/ensemble_f1 0.44148
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81047
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.57171
wandb:      train/ensemble_f1 0.57171
wandb:         train/mil_loss 0.89708
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25ii14ki
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185023-25ii14ki/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bmh55p6b with config:
wandb: 	actor_learning_rate: 3.972886716453134e-06
wandb: 	attention_dropout_p: 0.4119475335213197
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8386437315275477
wandb: 	temperature: 4.418031440577831
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185151-bmh55p6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmh55p6b
wandb: uploading history steps 80-82, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▂▃▇▂▂▁█▁▂▄▁▇▇▁▁▅▇▄▇▄▁█▂▁▅▂▂▂▇▁▁▆▃▇▁▆▂▁▂▆
wandb:      eval/avg_mil_loss ▁▁█▁▂▂▂▂▆▂▂▃▂▂█▂▃▂▂▂▂▂▂▂▂▂▂█▂▂▁▂▃▂▂▂▁█▂▂
wandb:       eval/ensemble_f1 ▂▃▆▂▂▁█▁▅▂▁▇▁▆▁█▇▂▇▂▇▁▁▆▁▄▂▂▁▃▂▇▃▃▂▃▇▂▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▅▁█▄▃▅▅▄▂▆█▅▆▅▅▆▅▄▂▇▅█▄▂█▁▂▃▂▃▄▄▃▂▂▇▅▅
wandb:      train/ensemble_f1 ▇▅▂▂▁▃▇▄▅▅▁▆█▆▆▁▅▄▇▅▆▅▅▇▁▆▄▃▅▅▄█▃▃▄▃▅▇▆▇
wandb:         train/mil_loss █▁▂▄▂▁▃▂▂▃▂▂▇▂▂▂▄▄▂▆▅▄▅▃▂▃▂▂▁▁▂▃▄▃▂▆▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.55012
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.72536
wandb:      eval/avg_mil_loss 1.04533
wandb:       eval/ensemble_f1 0.72536
wandb:            test/avg_f1 0.66003
wandb:      test/avg_mil_loss 0.82167
wandb:       test/ensemble_f1 0.66003
wandb:           train/avg_f1 0.70439
wandb:      train/ensemble_f1 0.70439
wandb:         train/mil_loss 1.53148
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmh55p6b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185151-bmh55p6b/logs
wandb: Agent Starting Run: c0jt5r0q with config:
wandb: 	actor_learning_rate: 0.0001806755091761734
wandb: 	attention_dropout_p: 0.09828464812713134
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14463514308629344
wandb: 	temperature: 2.2194639186094767
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185258-c0jt5r0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c0jt5r0q
wandb: uploading history steps 135-144, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂██
wandb: best/eval_avg_mil_loss █▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂██
wandb:            eval/avg_f1 ▃█▃▅▆▇▅▁▇▄▂▆▃▁▆▇▄▃▅▇▃▁▆▅▅▄▇▃▅▂▅▂▁▄▁▅▆▂▆▇
wandb:      eval/avg_mil_loss ▃▂█▃▁▄▇▅▁▂▂▅▂▂▂▁▄▂▂▃▂▁▂▄▇▃▄▁▂▃▆▅▂▂█▄▂▆▃▁
wandb:       eval/ensemble_f1 ▇▂▇▅▆▇▅▄▂▁█▂▃▆▃▄▇▇█▅▅▅█▄▃▅▄▅▅▂▁▄▂▇▁▂▇▅▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▂█▅▆█▁▃▇▆▃▇█▅▆▅▆█▆▆▇▄▆▄▅▆▆▂▅▆▅▇▆█▄▇▃▂▆
wandb:      train/ensemble_f1 ▄▇▅▆▅▆▃█▄▆▂▅▄▂▂▇▆▅▅▄▆▆▅▃▅▆▅▄▆▄▂▄▅▅▆█▄▇▁▅
wandb:         train/mil_loss ▁▃▃▄▅▄▂▃▁▄▃▄▄▂▇▃▂▃▃▃▃▆▃▃▂▃▃▄▅▄▆█▃▇▅▃▅▂▂▄
wandb:      train/policy_loss ▄▄▄▃▃▄▃▄▃▄▃▁▄█▆▆▁█▆▆▆▄▄▃▃▅▃▄▄▃▆▅▆▄▄▄▄▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▆▅▆▅▅▃▅▄▃▅▅▅▆█▁▅▃▅▅▃▅▅▆▅▄▃▅▆▅▃▅▅▅▃▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.62906
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.43214
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.42767
wandb:      test/avg_mil_loss 5.17853
wandb:       test/ensemble_f1 0.42767
wandb:           train/avg_f1 0.60569
wandb:      train/ensemble_f1 0.60569
wandb:         train/mil_loss 2.37042
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c0jt5r0q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185258-c0jt5r0q/logs
wandb: Agent Starting Run: efqlesyk with config:
wandb: 	actor_learning_rate: 2.084551562688694e-06
wandb: 	attention_dropout_p: 0.2863092338449552
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 95
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8591901887770345
wandb: 	temperature: 3.167402877694548
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185457-efqlesyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/efqlesyk
wandb: uploading history steps 82-96, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇██
wandb: best/eval_avg_mil_loss █▅▃▄▃▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇██
wandb:            eval/avg_f1 ▄▁▁▄▃▄▇▆▆▇▄█▃▇▃▇▆▄██▄▄▇██▁▁▄▄▇█▃█▂▃▃▃█▆▇
wandb:      eval/avg_mil_loss ▂▂▂▁▂▂▂▂▂█▁▂▂▁▂▂▂▂▇▂▁▁▂▁▁▅▁▂▂▂▂▂▂▁▂▂▁▁▂▁
wandb:       eval/ensemble_f1 ▃▁▆▃▃▇▆▃▃▃▂▅▇▃▇█▆▇██▁▄▄█▆▇█▁▆▄█▇▆▇▃█▇▄█▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▁▄█▂█▄▃▃▅▂▅█▄▃▃▆▆█▆▄▄▅▆▄▅▂▄▆▅▃▃▆▄▆█▃▄
wandb:      train/ensemble_f1 ▄█▁▄▆▂▇▃▃▆▄▃▃▂▇▃▇▅▄▂█▄▇▃▃▄▄▅▅▅▄▅▄▃▁▇▅▇▁█
wandb:         train/mil_loss ▃▂▃▄▁▃▂▂▁▁▂▁▂█▁▃▂▃▂▂▂▁▂▃▂▂▂▆█▂▃▂▂▁▃▁▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.62923
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.88791
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.70974
wandb:      test/avg_mil_loss 0.88543
wandb:       test/ensemble_f1 0.70974
wandb:           train/avg_f1 0.62897
wandb:      train/ensemble_f1 0.62897
wandb:         train/mil_loss 0.78165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/efqlesyk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185457-efqlesyk/logs
wandb: Agent Starting Run: 0xbimzj8 with config:
wandb: 	actor_learning_rate: 1.1544769738722558e-05
wandb: 	attention_dropout_p: 0.11039757342522556
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 185
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08925125823441438
wandb: 	temperature: 2.1406759213586977
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185614-0xbimzj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0xbimzj8
wandb: uploading history steps 143-159, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇▇█
wandb: best/eval_avg_mil_loss ▆█▄▁▄
wandb:  best/eval_ensemble_f1 ▁▇▇▇█
wandb:            eval/avg_f1 ▄▁█▁▄▁▄▃▁▂▅▁▁▁▂▁▂▂▁▁▆▁▃▄▁▃▃▃▂▁▂▁▃▁▁▄▂▁▄▂
wandb:      eval/avg_mil_loss ▁▂█▁▁▆▁▂▇▂▁▁▂▁▁▁▁▄▂▅▁▁▁▁▂▁▁▁▁▁▂▁▁▆▁█▂▁▁▁
wandb:       eval/ensemble_f1 ▇▁▃▁▁▁▃▄▅▃▄█▅▃█▃▂▁█▂▁▁▄▂▄▄▁▂▃▂▁▂▁▄▁▄█▄▄▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▃▄▃█▅▃▅▄▄▄▁▆▆▄▄█▄▃▄▆▄▆▄▄▃▂▅▅▄▄▃▄▆▅▄▄▄
wandb:      train/ensemble_f1 ▅▄▄▆▄▅▅▄▄▄▇▁▅▆▂█▅▂▅▄▇▇▂▆▃▄▅▅▅▇▅▄▅▇▇▃▇▃▄▄
wandb:         train/mil_loss ▅▇▅▁▁▂▅▆▆▂▂▃█▅▄▇▅▆▁▆▄▃▃█▂▃▄▆▇▅▁▅▁▆▁█▇▇▃▃
wandb:      train/policy_loss ▃▃█▁█▃▁▃▃▃▆▃▃▃▁▃▁▃▃▁▃▃▃▁▃▃▁▃▃▁▁▃▁▃▁▃▁▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃█▃▁▃▃▁▃▃▃▃▃▃▃▃▃▃▃▁▃▃▁▁▃▁▃▁▃▃▃▃▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.75322
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.89688
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 7.0832
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.5389
wandb:      train/ensemble_f1 0.5389
wandb:         train/mil_loss 2.16891
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0xbimzj8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185614-0xbimzj8/logs
wandb: Agent Starting Run: ueh7t1ft with config:
wandb: 	actor_learning_rate: 1.899131787605474e-06
wandb: 	attention_dropout_p: 0.3182824137448515
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 78
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7761697509476085
wandb: 	temperature: 2.4387146712435004
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185818-ueh7t1ft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ueh7t1ft
wandb: uploading config.yaml
wandb: uploading history steps 62-79, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂██
wandb: best/eval_avg_mil_loss █▆▃▁
wandb:  best/eval_ensemble_f1 ▁▂██
wandb:            eval/avg_f1 ▃▁▃▄▃▄█▆▃▄▃▃▁▃▃▆▆▄▃▁▃█▂▁▁▁▆▃▄▃██▁▇▃▄▄▆▄▄
wandb:      eval/avg_mil_loss ▄▅▅▄▃▅▅▄▂▅▃▄▄▃▄▃▄▄▅▃▄▅█▃▄▃▂▃▃▅▅▃█▄▃▁▃▄▄▄
wandb:       eval/ensemble_f1 ▃▂▃▃▁▄▃▁▆▄▄▄▃▃▁▃▃▃▆▁▄▃▃▄█▃▂▁▃▁▃▄▃█▃▄▄▄▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▁▅▂▆▂▅▅▆▅▅▅▆▁▂▄▁▂▂▂▆▄▂▃▃▂▁▂▅▂▅▄▂▃▁▂█▅▂
wandb:      train/ensemble_f1 ▁▄▃▂▅▄█▇▆▇▃▇▇█▁▄▃▁▇▃▂▃▇█▅▃▂▄▆▄█▂▁▅▃▃▁▃▄▇
wandb:         train/mil_loss ▂▃▂▃▂▂▄▂▅▂▃▂▁▂▃▄▂▃▂▁▂▂▁▂▂▂▃█▂▂▂▂▃▂▂▂▁▄▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.67347
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.91263
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78104
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.61995
wandb:      train/ensemble_f1 0.61995
wandb:         train/mil_loss 0.89441
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ueh7t1ft
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185818-ueh7t1ft/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ws0i14q4 with config:
wandb: 	actor_learning_rate: 2.203395018443471e-05
wandb: 	attention_dropout_p: 0.11529599422857328
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2844917074535066
wandb: 	temperature: 1.5315877759291496
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_185930-ws0i14q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ws0i14q4
wandb: uploading history steps 174-182, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▆▇▁▄▃
wandb:  best/eval_ensemble_f1 ▁▅▅▅▆▇█
wandb:            eval/avg_f1 ▁▁▆▄▅▂█▂▄▅▇▆▁▃▅▆▅▆▃▃▆▄▃▇▄▅▆▂▆▇▄█▃▁▄▁▆▆▇▅
wandb:      eval/avg_mil_loss ▁▂▁▁▁▂▄█▄▁▂▃▂▂▂▁▂▆▂▂▁▁▁▅▂▁▁▄▁▁▁▃▂▂▁▂▁▆▁▁
wandb:       eval/ensemble_f1 ▆▃▁▆▃▅▄▁▂▄▇▂▆▄▂▅▆▅▆▆▆▃▅▃▃▄▇█▅▃▆▆▆▃▅▄▇▃▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▅▆▂▄▇█▆▁▂▃▁▄▂▃▄▂▄▄▅▆▂▁▄▄▁▇▄▄▅▃▅▃▄▄▂▄▂
wandb:      train/ensemble_f1 ▂▆▃▄▅▆▃▂█▂▅▄▄▄▅▂▄▅▃▂▅▅▂▇▄▇▁▃▄▆▄▅▁▄▄▅▅▄▂▄
wandb:         train/mil_loss ▅▇▄▄▄▄▃▂▄▂▂▆▂▂▄▅▂▃▃▂▄▄▇▅▂▅▃▅▅▅▇▂▇▂▄▅▆▁▁█
wandb:      train/policy_loss ▄▄▃▃▆▄▄▆▃█▃▆▄▃▆▆▆▁▄▃▃▄▄▄█▄▄▄▄▆▄▆▄▄▃▄▄▃▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▆▃▃▃█▁▆▃▃▄▆▃▂▁▁▃▃█▃▃▃▂▁█▃▃▂▃▂▆▃▁▁▆▆███▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.61834
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.56649
wandb:      eval/avg_mil_loss 1.04261
wandb:       eval/ensemble_f1 0.56649
wandb:            test/avg_f1 0.62818
wandb:      test/avg_mil_loss 3.95202
wandb:       test/ensemble_f1 0.62818
wandb:           train/avg_f1 0.58871
wandb:      train/ensemble_f1 0.58871
wandb:         train/mil_loss 2.01429
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ws0i14q4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_185930-ws0i14q4/logs
wandb: Agent Starting Run: qcqabgnj with config:
wandb: 	actor_learning_rate: 1.581354586536619e-05
wandb: 	attention_dropout_p: 0.2741097864719286
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21494671100520713
wandb: 	temperature: 2.162483442711215
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190155-qcqabgnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qcqabgnj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▆▆▇▇▇█
wandb: best/eval_avg_mil_loss ▄▅▄█▂▁▂▃▂▂
wandb:  best/eval_ensemble_f1 ▁▂▃▃▆▆▇▇▇█
wandb:            eval/avg_f1 ▄▃▇▃▇▂▆▃▁▃▇▇▅█▃▃▃▆▂▃▇▂█▇▅▃▂▆▁▅█▆▆▅▅▄▇▇▄▃
wandb:      eval/avg_mil_loss ▁▂▂▂▁▁▂▁▂▂▁▂▁▅▂▁▁▅▂▂▁▂▂▂▂█▂▂▁▂▂▃▁▂▁▂▁▂▂▂
wandb:       eval/ensemble_f1 ▆▅▇█▃▅▃▇▂▆▂▅▂▆▆▂▄█▇▂▄▆▂▅▅▅█▁▇▆▄▅▆▃▇▇▇▆▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅█▃▃▅▄▄▃▆▃▁▆▇▆▄▇▇▃▆▄█▃▆▆▆▃▄▃▇▂▅▄▆▆▇▄▃▃▃
wandb:      train/ensemble_f1 ▆▃▇▆▅▄▄▃▆▅▅▂▁▄▆▅▅▅▆▂▂▇█▃▇▇▅▆▁▂▂▄▃▆▂▅▇▂▄▄
wandb:         train/mil_loss ▂▃▁▂▄█▂▁▄▂▂▄▁▃▃▂▂▄▂▃▁▄▄▃▂▄▃▃▃▃▁▂▂▃▁▁▁▂▃▂
wandb:      train/policy_loss ▃▁▄▅▃▆▄▆▄▆▆█▅▅▅▅▅▃▆▆▆█▅▄▃▆▆▆▅▆▅▃▅▆▃▅▆▃▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▃▆▃▄▆▄▆▃▇▄▆▁▄█▆▁▃▄▄▆▄▄▆▃█▆▆▁▄▄▄▄▄▆▄█▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.63103
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.83056
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.48739
wandb:      test/avg_mil_loss 1.57227
wandb:       test/ensemble_f1 0.48739
wandb:           train/avg_f1 0.62539
wandb:      train/ensemble_f1 0.62539
wandb:         train/mil_loss 0.85674
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qcqabgnj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190155-qcqabgnj/logs
wandb: Agent Starting Run: fog9qwmb with config:
wandb: 	actor_learning_rate: 0.00015223892778697335
wandb: 	attention_dropout_p: 0.16377686892716092
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26075716821577877
wandb: 	temperature: 2.5020506721014293
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190435-fog9qwmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fog9qwmb
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▁▂
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▃▅▇▆▆▃▅▂▃▆▅▁▆▁▅▄▅▆▆▆▅▆▆▇▄▂▇▅▂▂█▂▁▇▆▁▃▁▄▂
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▁▁▁▂▁▁▂▂▁▁█▁▁▁▁▂▁▁▂▂▁▂▁▂▁█▁▁▂▂▁▂▁▂
wandb:       eval/ensemble_f1 █▃▅▆▃██▂▃▂▆▆▁▆▆▁▆▃▄▄▆▆▁▆█▃▂▇▂▆▁▃▅▁▃▄▆▃▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▆▆▆▃▆▅▄▃▆▇▅▆▃▄▃▃▅▅▆▆▄▄▁▂▆▁▂▄▅▁▆▅▃▄▆▂█
wandb:      train/ensemble_f1 ▅▂▄▃▄▆▃▆▄▅▄▁▅▁▃▃▃▅▆▆█▇▁▃▄▄▄▆▆▃█▃▇▆▂▄▄▁▂█
wandb:         train/mil_loss ▁█▅▁▁▄▁▂▁▂▁▁▁▅▁▁▁▁▁▄▂▁▁▁▄▁▁▅▁▅▄▂▃▁▁▁▂▁▁▁
wandb:      train/policy_loss ▁▁▃▁▁▃█▁█▁▁▁▃▁▁▃▃▁▁▆▃▁▆▁▆▁█▁▃██▃▃▆▃▆▃▁█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▃▁▁▁▃▁▁▃▃▆▁▁▆▃▁▃▆█▁▁▃▁█▁▁▃▃▆▆▁▃▆▁▁▃▆█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57033
wandb: best/eval_avg_mil_loss 0.7141
wandb:  best/eval_ensemble_f1 0.57033
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97949
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.77504
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.49047
wandb:      train/ensemble_f1 0.49047
wandb:         train/mil_loss 0.80246
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fog9qwmb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190435-fog9qwmb/logs
wandb: Agent Starting Run: 61tum2bj with config:
wandb: 	actor_learning_rate: 1.5999722871477677e-05
wandb: 	attention_dropout_p: 0.1027180327671976
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20536123527271155
wandb: 	temperature: 2.6084625455821744
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190618-61tum2bj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/61tum2bj
wandb: uploading history steps 102-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▃▁▄▁▄▁▁▁▄▁▃▃▁▁▄▁▁▄▄▁▁▅▁▂▁▁▁▁▁▁▁█▁▆▁▄▁▃
wandb:      eval/avg_mil_loss █▆▆▅▃▇▄▇▄▅█▅▄▅▅▄▅█▃▇▂▆▅▄▆▇▇▇█▆▅▆▁▇█▄▅▃▅▃
wandb:       eval/ensemble_f1 █▂▁▃▄▃▁▄▂▃▄▄▄▃▃▁▃▃▁▄▁█▁▄▃▁▆▄▁▁▁▁▁▃█▆▃█▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▃▄▂▂▅▃▂▁▃▂▄▃▃▅▂▅▅▅▂▅▄▃▄▃▄▃█▅▂▆▅▄▂▃▅▃▄
wandb:      train/ensemble_f1 ▃▄▆▅▅▂▅▂▂▂▃▂▂▄▂▃▆▂▃▁▅▂▄▂▂▁▄▃▆▄▅█▅▅▄▇█▆▂▃
wandb:         train/mil_loss ▇▅▅▅▄▄▃▄▅█▄▄▁▇▆▃▃▅▅▇▄▄▅▆▇█▁▅▅▃▅▂▃▂▃▆▆▃▃▄
wandb:      train/policy_loss ▅▄█▅▅███▅█▅▅▅▅▅██▅▅█▅▄█▄▅██▅▅█▅▅▅▁████▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▅▃▅▅▃▅▃▃█▃▃▃▅▃▃▃▅▅▃▅▃█▃█▃▃▃▅▅█▅▃▁▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78981
wandb: best/eval_avg_mil_loss 0.59126
wandb:  best/eval_ensemble_f1 0.78981
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.87479
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.85744
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.51945
wandb:      train/ensemble_f1 0.51945
wandb:         train/mil_loss 0.93663
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/61tum2bj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190618-61tum2bj/logs
wandb: Agent Starting Run: jkkvpxoi with config:
wandb: 	actor_learning_rate: 2.385260753587671e-05
wandb: 	attention_dropout_p: 0.12056767054369404
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04739159061548581
wandb: 	temperature: 1.7350691078708402
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190741-jkkvpxoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkkvpxoi
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▆▃▃▄▄▇▇█▄▁▆▄█▄▁▅▁▅▆▆█▂▄█▄▁▁▄▃▇▅▄▆▃▃█▆▆▆▄
wandb:      eval/avg_mil_loss ▂▁▁▁▁▁▂▁▁▂▁▁▁▂▁█▁▁▁▂▁▁▁▁▃▁▁▁▂▂▁▃▁▁▁▁▂▃▁▃
wandb:       eval/ensemble_f1 ▆▂▁▅▄▆█▄▁▄▄█▄▆▆▅▁▅▆▆▂▇▃▄▃▆▄█▄▆██▃▁▁▂▆▆▆▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▅▁▇▆▃▇▂▄▆▇▃▆▂▂▅▄▁▄▇▇▇▆▆▆▅▇█▃██▄▅▄▇▃▅▄▆
wandb:      train/ensemble_f1 ▅▄▅▅▅▃▂▁▂▆▅▆▃▆▅▃▂▆▁▃▆▆▅█▄▅▆▃▆▂█▃▆▇▄▅▇▅▃▇
wandb:         train/mil_loss ▂▂▁▂█▂▂▂▁▃▂▂▁▁▂▂▂▃▂▃▂▅▂▂▂▂▂▂▂▂▂▁▃▂▂▂▁▂▃▃
wandb:      train/policy_loss ▄██▄█▄▄▄▄▁▄███▆█▆▃█▄█▄▁█▄▃█▄▄█▄▄▁█▃▄▄▄█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▁▄▄▄▄██▄█▃▆█▁▃██▄▄█▄▄▄▄▄█▄▄▄▄█▃▁▄██▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81993
wandb: best/eval_avg_mil_loss 0.57148
wandb:  best/eval_ensemble_f1 0.81993
wandb:            eval/avg_f1 0.70501
wandb:      eval/avg_mil_loss 0.86572
wandb:       eval/ensemble_f1 0.70501
wandb:            test/avg_f1 0.57131
wandb:      test/avg_mil_loss 0.69635
wandb:       test/ensemble_f1 0.57131
wandb:           train/avg_f1 0.69741
wandb:      train/ensemble_f1 0.69741
wandb:         train/mil_loss 1.08461
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jkkvpxoi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190741-jkkvpxoi/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p34nv9kr with config:
wandb: 	actor_learning_rate: 2.153803567726748e-06
wandb: 	attention_dropout_p: 0.23834223291370388
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 121
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6342591566456037
wandb: 	temperature: 0.02951814205338854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_190950-p34nv9kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p34nv9kr
wandb: uploading history steps 103-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇██
wandb: best/eval_avg_mil_loss █▃▁▂▂
wandb:  best/eval_ensemble_f1 ▁▇▇██
wandb:            eval/avg_f1 ▅▇▃▃▆█▃▄▁▆▄▄▁▄▁▁▄▁▆█▃▃▁▃▃▇▄▆▄▁▁▁▃▆▃▁▄▇▃▆
wandb:      eval/avg_mil_loss ▄▂▂▁▅▂▂▅▂▂▁▂▂▂▃▂▁▁█▁▁▂▁▁▁▂▅▁▂▁▁▂▂▄▂▅▁▃▂▁
wandb:       eval/ensemble_f1 ▂▁▃▆▃▇▁▂▂▄▃▄▁▁▁▁▆█▆▃▄▂▄▂▁▄▁▁▄▃▁▂▂▅▄▁▇▃▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▅▂▅▂▇▃▄▃▆▄▃▆▅▆█▄▆▃▃▃▄▁▄▂▁▄▅▅▅▇▃▄▅▅▅▄▃▅
wandb:      train/ensemble_f1 ▃▅▅▁▅▄▆█▃▄▃▅▆██▃▇▂██▅▄▂▄▄▆▅▆▅▅▄▂█▂▄▂▆▆▃▆
wandb:         train/mil_loss ▁▄▁▁▃▂▂▃▂▂▂▅▁▁▃▃▂▆▅▁▁▂▆▅▃▃▂▂▃▁▁▁▂▄▁▂▁▂▃█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.71746
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.50397
wandb:      eval/avg_mil_loss 1.87826
wandb:       eval/ensemble_f1 0.50397
wandb:            test/avg_f1 0.66838
wandb:      test/avg_mil_loss 1.0693
wandb:       test/ensemble_f1 0.66838
wandb:           train/avg_f1 0.51499
wandb:      train/ensemble_f1 0.51499
wandb:         train/mil_loss 2.26817
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p34nv9kr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_190950-p34nv9kr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: varz22u9 with config:
wandb: 	actor_learning_rate: 1.0483922139865814e-05
wandb: 	attention_dropout_p: 0.24001873161121903
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22405577677501864
wandb: 	temperature: 1.423311783549388
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191142-varz22u9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/varz22u9
wandb: uploading history steps 122-134, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ▄▃▁█
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▆▄▂▃▇▁▃█▂▁▄█▄▂█▄▂▇▂▄▄▂▃▃▃▅▃▃▂▃▁▃▂▅▁▁▂▂▂▇
wandb:      eval/avg_mil_loss ▂▂▁█▇▃▂▁▂▁█▇▁▂▂▂▇▂▃▁▂▁▂▂▃▂▂▁▇▂▂▁▁▇█▁▁▃██
wandb:       eval/ensemble_f1 ▁▃▃▂▇▂▂▂▁▂▃█▄▁▄▄▁▄▆▁▃▄▄▂▄▁▃▁▃▃▃▁▁▄▃▁█▅▁▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▁▅▅▄▇▄▅█▇█▃█▅▇█▅▆▆▅▆▅▅▅▆▂▆▄▅▇▇▆▆█▇▄█▆
wandb:      train/ensemble_f1 ▃▄▁▃▃▄▅▃▃▃▃▂▃▆▅▃▅▃▅▄▄▅█▃▄▅▆▅▃▁▅▃▂▂▆▄▃▇▃▂
wandb:         train/mil_loss ▇▆▆▃▇▂▂▅▅▃▁▃▃▂▄▁▅▄▆▃█▅▄▄▃▁▂▄▂▂▅▄▂▃▂▄▃▁▅▂
wandb:      train/policy_loss ▅▃▅▅█▅▃█▅▅█▅▁▅▅▅▃▃▃▅▅█▁▁▃▅█▅▃▅▅▅▅▅▃▆▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▃▃▅█▅▃▃▅▅▁▅▁▅▅▃▁▅▁▅▁▃▅▃▅▅▅▅▅▅██▁▃▆▅█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.99985
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.56342
wandb:      eval/avg_mil_loss 1.92203
wandb:       eval/ensemble_f1 0.56342
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 2.4035
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.62615
wandb:      train/ensemble_f1 0.62615
wandb:         train/mil_loss 1.12164
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/varz22u9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191142-varz22u9/logs
wandb: Agent Starting Run: 31ohnw6b with config:
wandb: 	actor_learning_rate: 6.719881420076684e-05
wandb: 	attention_dropout_p: 0.04613079626501787
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 195
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17946387382341267
wandb: 	temperature: 1.4553922817625042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191326-31ohnw6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/31ohnw6b
wandb: uploading history steps 97-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▁█▂
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 █▂█▆▅▇▄▄▄▄▇▃▃▂▄▃▁▄▁▃▂▁▇▇▄▂▂▇▂▂▃▂▆▃▇▃▄▃▂▇
wandb:      eval/avg_mil_loss ▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▁▄▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▂
wandb:       eval/ensemble_f1 ▆█▂▃█▃▇▂▃▃▂▃▂▁▁▂▂▁▁▆▄▂▂▂▃▃▃▂▄▄▇▁▃▃▅▃▂▃▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▄▃▂▄▅▂▄▃▄▄▅▂▆▅▆▃▅▄▇▅▇▄▄▂▄▃▃█▅▃▁▆▄▃▆▅▅
wandb:      train/ensemble_f1 ▄▄▄▃▃▂▅▅▅▅▄▂▇▄▄▂▃▆▅▃▅▆▅▄▄▅▁▂▂▅▅▃█▅▁▆▄▆▇▅
wandb:         train/mil_loss ▇▂▂█▆▂▂▇▃▃▃▃▄▅▂▅▁▁▁▆▁▁▆▄▄▆▃▂▅▃▄▂▃▂▃▄▄▅▂█
wandb:      train/policy_loss ▇▇▂▂▂▃▇▃▃█▃▅█▁▇▆▁▃▃▂▇▃▃▃▃▃▂▆▂█▆▃▁▁▆▆▂▂▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▅▁▄▅█▅▄▅▅▅▇▇▅▅▇▅▃█▄▆▅▅▅▅▄▄▄▄▆▃▅▅▇▅▆▅▇▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75196
wandb: best/eval_avg_mil_loss 1.03557
wandb:  best/eval_ensemble_f1 0.75196
wandb:            eval/avg_f1 0.66667
wandb:      eval/avg_mil_loss 1.61561
wandb:       eval/ensemble_f1 0.66667
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.59487
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.57259
wandb:      train/ensemble_f1 0.57259
wandb:         train/mil_loss 0.90394
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/31ohnw6b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191326-31ohnw6b/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: akbs8w6j with config:
wandb: 	actor_learning_rate: 2.7747602111216053e-05
wandb: 	attention_dropout_p: 0.1433920624492545
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16555087190142115
wandb: 	temperature: 3.0942600487558645
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191511-akbs8w6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akbs8w6j
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▇▇█
wandb: best/eval_avg_mil_loss █▁▂▂▂
wandb:  best/eval_ensemble_f1 ▁▂▇▇█
wandb:            eval/avg_f1 ▁▁▁▇▁▁▁▆▅▆▆▁▁▅▁▇▁█▁█▂▁▇▄▁▃▁▁█▆▁▄▁▁▆███▂▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▅▆▁▂▃▁▁▂▃▁▁▆▁▁▂▃▁▇▁▄▆▆▄▁▁▁▂█▁▁▁▁▆
wandb:       eval/ensemble_f1 ▆█▁▁▆▃▂▆▁▁▁▅▁▃▁▁▃███▂▁▁▁▁█▁▁███▁▁▁▁▁▇▁█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▄▄▄▇▃▆▁▁▂▆▄▄▆▁▇▆▆▁▆█▅▄▇▆▅▄▇▅▅▇▅▅▃▇▅▇▇▅
wandb:      train/ensemble_f1 ▅▆▅▅▅█▄▇▇▂▃▂▄▁▆▅▆▂▇█▇▇▅▄▆▇▆▇▄▁▂▆▅█▃▄▅▄▇▅
wandb:         train/mil_loss ▅▇▇▁█▅▂▃▇▃▂▆▅▃▄▁▄▄▃▄▃▄▄▅▂▇▄▅▇▄▆▃▂▄▅█▃▄▇▄
wandb:      train/policy_loss ▃▅█▅▅▅▁▁▅▅▁▅▁▅▅▆▅▅▁▅▅▁▅▅▆▅█▅▅▆▁▃█▅▁▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▅▅▅▃▁▅▅█▅▅▁▃▁▅▅▁▅▁▅▁▅▅▅▆█▅▁▅▅█▅▁▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.72681
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81079
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.06852
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.56015
wandb:      train/ensemble_f1 0.56015
wandb:         train/mil_loss 1.42188
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/akbs8w6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191511-akbs8w6j/logs
wandb: Agent Starting Run: idn1ee1h with config:
wandb: 	actor_learning_rate: 1.8344879266165305e-05
wandb: 	attention_dropout_p: 0.12232505581300118
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 162
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14244404286356382
wandb: 	temperature: 1.3578922903432766
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191730-idn1ee1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/idn1ee1h
wandb: uploading history steps 143-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▇▇▇███
wandb: best/eval_avg_mil_loss ▇█▃▅▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▇▇▇███
wandb:            eval/avg_f1 ▁▆▁▁▆▁▁▁█▁▂▂█▄▁▃▁▃▆▁▃▆▂▁▇▇▁▇▇▆▆▁▆▁▂▇▇▁▁▁
wandb:      eval/avg_mil_loss ▁▃▂▂▂▂▄▃▄▁▂▂▄▂▂▁▂▁▂▁▁▁▁▁▂▃▁▁▂▁▁▁▁▂▁▂▃█▂▂
wandb:       eval/ensemble_f1 ▇▁▁▃▁▆▁▂▁▂▆▁▇▂█▆▁▁▃▂▆▇▁▃▇▁▁▇▇▁▅▁▆▆▂▃▁▁▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▁▄▅▂▆▂▄▄▃▄▅▅▄▁▅▆▄▆▄▆▂▃▅▄▆▅▅▆▃▅▅▄▁▂▅▃▅█
wandb:      train/ensemble_f1 ▅▅▂▆▆▄▆▅▆█▄▄▁▆▅▄▅▃▅▆▅▅▆▃▄▂▆▇▇▄▇▅▅▅▆▆▃▄▄▄
wandb:         train/mil_loss ▄▆▂▄▁▄▁▂▂▂▃▂▄▂▃▂█▂▃▂▄▃▄▃▂▄▃▄▅▆▃▂▃▄▂▂▃▅█▃
wandb:      train/policy_loss ▃▃██▃█▅▃▅▃▁▃▁█▅▅█▃▁▅▃▅█▃▅▅█▁▅▅▃▅▅▃▁█▃▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▃██▅▅▅█▁▃▃▁▅▅▅▃▁▁▃█▅█▁█▅▃█▅▅▃▃▁▁▃▁▅█▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.68712
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04361
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.76
wandb:      test/avg_mil_loss 0.83272
wandb:       test/ensemble_f1 0.76
wandb:           train/avg_f1 0.57495
wandb:      train/ensemble_f1 0.57495
wandb:         train/mil_loss 1.34341
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/idn1ee1h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191730-idn1ee1h/logs
wandb: Agent Starting Run: 5x9b2y47 with config:
wandb: 	actor_learning_rate: 1.0303106591711368e-05
wandb: 	attention_dropout_p: 0.1484494213396978
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 179
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23334456521737976
wandb: 	temperature: 2.245576938374705
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_191923-5x9b2y47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x9b2y47
wandb: uploading history steps 163-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇▇▇▇█
wandb: best/eval_avg_mil_loss █▄▄▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▆▇▇▇▇█
wandb:            eval/avg_f1 ▁▁▇▅▁▇▅▁▇▁▇▁▁▇▃▁▇██▁▂▅▁▆▆▁▁▁▅▆▁▆▃▁▄▇▆█▁▁
wandb:      eval/avg_mil_loss ▁▅▁▁▁▁▁▁▁▂▁█▁▁▂▁▄▂▁▁▁▁▁▁▁▁▁▁▃▁▁▄▁▁▁▁▁▁▇▁
wandb:       eval/ensemble_f1 ▁▁▇▅▂▁▆▇▁▃▁▅▁▁▇▇█▁▁▁▁▆▁▁▁▁▄▅▁▁▁▇▆▁▇▁▇▁█▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▃█▄▂▇▅▄▄▄▇█▄▄▃▆▁▅▃▅▃▅▅▆▄▅▅▆▆▂█▄▃▁▄▇▅▆
wandb:      train/ensemble_f1 ▆▇▄▇▅▂▇▆▆▅▆▇█▇▅▅▅▇▆▅▄▇▄▅▆▄▇▅▁█▅▄▅▄▄▅▅▁▇▅
wandb:         train/mil_loss ▃▂▁▁▂▂▅▃▂▂▃▃▁█▄▅▆▇▂▃▃▁▅▇▂▅▂▇▃▅▄▅▁▅▂▁▅▃▄▂
wandb:      train/policy_loss ▄▁▁▄▄▄▄▄█▄▁▁█▄▄▄▃▃▄█▄▄▄▄█▃▄▄▃█▄▃▄▄▁▄▄▃▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▃▁█▃▄▁▁▄▄▁█▄▄█▆▁▃▃▄▄█▃▄▃▄▄▄▄▃▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82
wandb: best/eval_avg_mil_loss 0.56422
wandb:  best/eval_ensemble_f1 0.82
wandb:            eval/avg_f1 0.66562
wandb:      eval/avg_mil_loss 0.89441
wandb:       eval/ensemble_f1 0.66562
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.11109
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.57846
wandb:      train/ensemble_f1 0.57846
wandb:         train/mil_loss 1.04564
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5x9b2y47
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_191923-5x9b2y47/logs
wandb: Agent Starting Run: gdjvggwc with config:
wandb: 	actor_learning_rate: 1.7833810943313593e-05
wandb: 	attention_dropout_p: 0.1893688300519092
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0282290303861088
wandb: 	temperature: 3.563891058943801
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192132-gdjvggwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdjvggwc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂█
wandb: best/eval_avg_mil_loss ▂██▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂█
wandb:            eval/avg_f1 ▃▆▁▁▃▃▃▁▂▇▁▃▃▆▁▅▄▁▃▂▁▇▁▄▅▇█▂▇▇██▁▁▁▁▃▇▇▃
wandb:      eval/avg_mil_loss ▅▆▃▂▃▂▂▄▄▁▃▃▂▂▃▆▂▃▃▂▄▂▁▁▆▁▂▃▂▃▂▂▃█▄▅▃▅▂▆
wandb:       eval/ensemble_f1 ▆▁▁▁▃▃▅▁▂▃▄▂▃▁▂▁█▅▃▂▁▇▂▇▁▄▁▇▂▇▇▇▃▆▅▁▁▁▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆▇▇▆▇▆▄▂▆▆▆▆▆▄▅▁▇▆▆█▅▄▇▆▅▅▅▅██▆█▄▆▇▆▆▅
wandb:      train/ensemble_f1 ▇▆▆▆▆▅▇▆▆▃▆▄▇▆▅▆▅▆▄▅▄▅▇▅▇▁▇█▇▅▄▅▆▅▆▇▆▆▆▅
wandb:         train/mil_loss ▃▄▅▁▇▆▃▄▅▂▇▅▄▂▅▆▃▂▂▄▃▃▂▄▂▄▃▆▂▅█▁▄▂▂▂▅▃▅▇
wandb:      train/policy_loss ▅▁▄▅▄▄▅▄▇▅▄▇▅▅▅▅▅▆▃▅▆▄▅▅▅▅▆█▅▅▅▅█▅▇▅▅▄▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▆▅▄▄▅▅▅▅▄▆▆▁▅▄▅▆▅▃▅▄▅▅▅▅█▅▅█▅▅▅▅▅▅▄▅▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78829
wandb: best/eval_avg_mil_loss 0.64198
wandb:  best/eval_ensemble_f1 0.78829
wandb:            eval/avg_f1 0.42956
wandb:      eval/avg_mil_loss 1.73523
wandb:       eval/ensemble_f1 0.42956
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 0.97287
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.53435
wandb:      train/ensemble_f1 0.53435
wandb:         train/mil_loss 1.14099
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gdjvggwc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192132-gdjvggwc/logs
wandb: Agent Starting Run: m8odgezb with config:
wandb: 	actor_learning_rate: 6.435930654966372e-05
wandb: 	attention_dropout_p: 0.18058501207566963
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18013663903083532
wandb: 	temperature: 1.7353003374669151
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192326-m8odgezb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m8odgezb
wandb: uploading history steps 102-120, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▄▅▁▁▁▄▄▁▁▅▁▆▁▁▄▆▁▄▄▄▁▃▄▅▃█▅▄▅▄▁▄▄▁▄▆▃▄▅█
wandb:      eval/avg_mil_loss ▁▅▁▁▇▁▂▇▁▁▁▁█▁▆▁▅▃▁▂▃▁▂█▁▅▁▂▁▂▁▇▁▂▁▁▁▁▁▂
wandb:       eval/ensemble_f1 ▄▅▄▁▁▄▄▄▂▄▅▄▄▁▅▄▆▁▁▄▄▁▄▁▃▄▄▁█▄▅▅▄▁▇▂▅▅▅▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▃▄▅▅▃▆▄▄▃▂▆▁▄▅▃▅▅▅▃▅▂▇▄▄▅▆▇▄▅▃▅▅▆▄▄█▃▇
wandb:      train/ensemble_f1 ▄▅▅▅▃▅▆▆▁▆▄▂▁▇▄▄▇▃▅▄▃▄▅▂▇▅▅▇▄▅█▄▆▆▆▅▅█▃▇
wandb:         train/mil_loss ▂▄▅▄▃█▃▁▃▂▁▁▂▁▅▄▄▃▃▂▅▂▆▂▅▂▂▄▆▄▄▄▄▁▁▁▃▃▂▁
wandb:      train/policy_loss █▅▃▃▅▅▆█▅▅▅▅▅▆▅█▃▃▅▆▅█▅▅▃▅▁▅▅▆▅▅▆▃▅█▅▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▃▃▃▃▅▅█▆▅█▃▅▅██▁▅▅▃▅▆▅▅▅▅▅▅▃▅▅▅█▅██▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76979
wandb: best/eval_avg_mil_loss 0.74902
wandb:  best/eval_ensemble_f1 0.76979
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04081
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.67886
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.56521
wandb:      train/ensemble_f1 0.56521
wandb:         train/mil_loss 1.25242
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run genial-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m8odgezb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192326-m8odgezb/logs
wandb: Agent Starting Run: 4e721llx with config:
wandb: 	actor_learning_rate: 1.429840290494068e-06
wandb: 	attention_dropout_p: 0.31884136751576053
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.949195397613904
wandb: 	temperature: 3.8123898311109823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192459-4e721llx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4e721llx
wandb: uploading history steps 83-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▆▂▇▇█▇█▇▃█▁█▇▁▁▇██▁█▁█▇▃▇███▃█▇▁▂▇▆█▇▁█
wandb:      eval/avg_mil_loss ▃▁▇▃▂▄▄▄▆▃▃▂▃▇▇▇▃▃▂▂█▂▃▄▃█▃█▂▅▃▇▃▂▃▃▂▂█▇
wandb:       eval/ensemble_f1 ███▃▇▇███▇▄▇▄▇▂▂▇▁▂███▇▂▇▇▂▄█▇▄█▁██▂▃█▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▇▃▄▆▃▂▆▆▃▁▆▅▄▇▄▃▇▆▆▆▄▅▄▆▄▇▅▆▄█▁▇▄▅▄▅▄▆
wandb:      train/ensemble_f1 ▃▇▁▅▇▄▇▄▆▆▃▂▆▅▄▆▄▃▇▅▆▅▆▅▃▂▁█▄▇▆▄▃█▇▃▅▆▆▄
wandb:         train/mil_loss ▇▆▅▄▄▅▄▂▅▅▆▆▄▆█▄▆▄▅▄▅▅▅▃▄▂▃▃▄▁▆▅▄▄▅▅▆▄▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.92428
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.93072
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.84456
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.52066
wandb:      train/ensemble_f1 0.52066
wandb:         train/mil_loss 0.93299
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4e721llx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192459-4e721llx/logs
wandb: Agent Starting Run: jdkjtgbc with config:
wandb: 	actor_learning_rate: 5.98282675081418e-05
wandb: 	attention_dropout_p: 0.10137973505526128
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 190
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0006710155220046587
wandb: 	temperature: 3.000499969794459
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192612-jdkjtgbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdkjtgbc
wandb: uploading history steps 143-148, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇█
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▆▆▇█
wandb:            eval/avg_f1 ▄▄▁▇▄▃▁▄▄▃▆▅▆▇▇▄█▆▂▆▄▄▃▁▄▃▁▁▆▇▆▁▆▆▇█▄▆▃▆
wandb:      eval/avg_mil_loss ▁▁▁▁▁▅▁▇▁▆▁▁█▁▁▅▇▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▆▁▁█▁▇▁▁
wandb:       eval/ensemble_f1 ▃▃▇▅▇▇▄▄▆▁█▇▃▄██▃▂▇▆▄▄▄▃▄▄▃▄▃▇▆▁▆▆▃▃▁▄▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▅▄▄▄▅▆▅▁█▅▇▅▇▅▅▄▆▇▅▅▅▅█▇▆▆▇▅▃▄▇▆▅▄▆▆▆
wandb:      train/ensemble_f1 ▃▅▅▂▅▄▅▅▄█▅█▆▃▆▆▄▃▁▃▄▃▆▁▅▄▄▇▃▆▅▆▅▆▄▅▇▂▆▄
wandb:         train/mil_loss ▄▄▂▆▁▄▁▃▂▁▃▃▃▃▁▂▆▃▅██▄▆▃▄▁▁▁▅▁▄▁▆▄▄▄▁▅▃▃
wandb:      train/policy_loss ▅█▅▅█▅█▃▅▁█▃▅▅▅▅▆▅▅▅▅▅▅▅▅▅█▅█▁▃▅▁▆▁▅▆▅▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅██▃▅▃█▁▅▅█▅▅▅▅▃▅▅▅██▅█▁▃█▅▁▁▁▅▅█▅▅▁▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80952
wandb: best/eval_avg_mil_loss 0.56595
wandb:  best/eval_ensemble_f1 0.80952
wandb:            eval/avg_f1 0.67949
wandb:      eval/avg_mil_loss 0.9345
wandb:       eval/ensemble_f1 0.67949
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 6.70902
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.65719
wandb:      train/ensemble_f1 0.65719
wandb:         train/mil_loss 0.97132
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdkjtgbc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192612-jdkjtgbc/logs
wandb: Agent Starting Run: 71azn4cr with config:
wandb: 	actor_learning_rate: 1.6370261027204451e-06
wandb: 	attention_dropout_p: 0.162080214486077
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 183
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07389775833476397
wandb: 	temperature: 4.345259242233203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192805-71azn4cr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71azn4cr
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▄▅█
wandb: best/eval_avg_mil_loss ▃█▂▁▃
wandb:  best/eval_ensemble_f1 ▁▁▄▅█
wandb:            eval/avg_f1 ▄▅▆▂▅▄▂▃▁█▁▇▇▂▂▁▁▂▁▂▆▁▆▆▇▅▆▆▄▁▆▃▂▂▇▁▄▂▁▅
wandb:      eval/avg_mil_loss ▁▁█▅▃▁▆▃▇▁▇▂▁▁▃▅▇▃▁▁▃▅▂▁▂▁▃▃▁▆▁▇▁▆▇▄▆▁▃▂
wandb:       eval/ensemble_f1 ▅▅▇▄▃█▆▇▂█▂▂▅▆▁▁▁▅▆▁▆▇▆▆▇▄▄▁▁▇▃▇▂█▃▁▅▃▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▄▄▃▄▄▅▆▅▁▅▂▆▄▂█▅▄▃▆▄▃▄▃▄▄▆▅▆▁▄▅▅▄▄▂▆▄
wandb:      train/ensemble_f1 ▃▅▄▄▄▄▃▅▅▅▇▁▅▆▆▄▄▄█▅▃▃▂▄▃▃▆▃▆▅▅▅▆▄▅▆▄▆▄▄
wandb:         train/mil_loss ▆▄▅▄▄▃▃▄▄▃▄▂█▃▃▆▃▄▁▆▄▆▃▄▄▃▂▂▄▃▇▂▆▄▆▇▄▂▆▃
wandb:      train/policy_loss ▆▂▃▂▆▁▃▃▆▆██▁▆▃█▆▆▃▁▁▃▆▂▁▄▁▃▂▃▃▃▃▆▆▃▃▆▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▂▃▁▅▁▆▃▃▃█▃▁▃▆▆▃▃▃▁▁▃▃▃▆▂▂▁▃▃▆▃▅▂▆▆▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77991
wandb: best/eval_avg_mil_loss 0.72598
wandb:  best/eval_ensemble_f1 0.77991
wandb:            eval/avg_f1 0.76998
wandb:      eval/avg_mil_loss 0.75288
wandb:       eval/ensemble_f1 0.76998
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 4.38916
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.5431
wandb:      train/ensemble_f1 0.5431
wandb:         train/mil_loss 1.74022
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/71azn4cr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192805-71azn4cr/logs
wandb: Agent Starting Run: nhgx2ste with config:
wandb: 	actor_learning_rate: 7.204521160309729e-06
wandb: 	attention_dropout_p: 0.13044038309192024
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12761877255889786
wandb: 	temperature: 3.5147753628007097
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_192939-nhgx2ste
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nhgx2ste
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▇█
wandb: best/eval_avg_mil_loss ▄█▅▂▁
wandb:  best/eval_ensemble_f1 ▁▁▃▇█
wandb:            eval/avg_f1 ▃▁▃▂▁▄▂█▂▆▇█▁▄█▂▂▁▇▆▃▃█▂▃▃▂▄▅▁▄▂▃▁▂▁▁▅█▅
wandb:      eval/avg_mil_loss ▂▂▃▂▃▂▂▂▂▃▂▃▁▂▂▄▂▂▂▂▂▃▂▂▂▂▃█▂▂▁▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▆▂▆▂▁▂▂▂▁▂▂▂▆▁▂▇▃▂▃▆▄█▂▂▃▁▃▆▂▃▄▇▃▁▂▇▄▆▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▃▅▅▃▄▆▅▆▇▇▄▃▃▇▆▅▅▄▄▅▆▅▅▇▁▅▇▄█▄▆▂▇▆▇▇▆
wandb:      train/ensemble_f1 ▆▇▅▂▆▅▅▅▅▅▅▇▄▃▆▇▅▇▇▃▄▅▅▅▄▅▃▁▇▄▃▄▄▄▇█▅█▇▇
wandb:         train/mil_loss ▁▂▄▄▅▃▂▂▂▃▃▃▃▂▃▂▃▂▂▂▄▆▂▂▄▄▁▃▂▃▆▃▃▂▅▂▃▂▅█
wandb:      train/policy_loss ▆▇▃█▃▆▁▆▅▇▆▃▃▄█▆▆▆▄▆▄▅▁▇▇▄▆▆██▆▇▆▆▆▃▆▇▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇▃▆▃▆█▁▁█▆▃█▆█▃██▆▆▄▇▆█▄▅▇▄▆▁▅██▆▄▄▆▆▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83942
wandb: best/eval_avg_mil_loss 0.46236
wandb:  best/eval_ensemble_f1 0.83942
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 0.69589
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.80855
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.59691
wandb:      train/ensemble_f1 0.59691
wandb:         train/mil_loss 1.38626
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nhgx2ste
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_192939-nhgx2ste/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: myzlc2p9 with config:
wandb: 	actor_learning_rate: 4.938861658146316e-06
wandb: 	attention_dropout_p: 0.011012859381881844
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 174
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.030305886071986587
wandb: 	temperature: 3.815228898168015
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193208-myzlc2p9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myzlc2p9
wandb: uploading history steps 163-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅▅▆▇█
wandb: best/eval_avg_mil_loss █▄▂▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▅▅▆▇█
wandb:            eval/avg_f1 ▄▃▇▅▃▃▄▁▅▃▄▃▅▄▁▃██▃▃▃▃▃▃▃▂▅▃▁▃▃▃▃▃▁▄▄▄▃▆
wandb:      eval/avg_mil_loss ▃▁▂▁▂▂▇▁▆▂▁▁▁▆▁▂▁▁▁▂▁▂▁▂█▁▁▁▁▁▂▃▁▁▁▆▆▁▁▁
wandb:       eval/ensemble_f1 ▄▅▄▄▇▅▄▄▄▁▄▃▇▃▆▇▄▆▄▄▄█▇▄▄▅▃▆▆▃▃▄▆▁▄▃▁▄▄▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▄▄▆▄▆▁▅▁▃▄▅▃▄▆▆▆▅▃▂▇▅▅▅▇▇▅▅▃▃▅▆█▃▁▄▆▅
wandb:      train/ensemble_f1 █▄▆▄▆▁▆▄▇▄▅▁▃▅▅▂▅▁▅▃▄▇▅█▃█▂▆▃█▃▆▄▄▅▆▂▂▃▆
wandb:         train/mil_loss ▄▂█▃▆▁▆▃▄▆▆▃▁▂▁▃▅▆▂▅▁▁▂▁▂▃▆▄▄▅▇▄▆▅▂█▅▁▂▄
wandb:      train/policy_loss ▄▄▄▄▄█▁█▄▄▄▄█▄▃▁▄▁▄▄▄▄██▄▄▄█▄▄██▄█▁█▄▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▄▄██▄▄▄▄▄▄█▄▄▄▄▄█▃██▄█▁█▄█▄▄█▁▄██▁▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.49821
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.6397
wandb:      eval/avg_mil_loss 1.17185
wandb:       eval/ensemble_f1 0.6397
wandb:            test/avg_f1 0.58996
wandb:      test/avg_mil_loss 1.56469
wandb:       test/ensemble_f1 0.58996
wandb:           train/avg_f1 0.62183
wandb:      train/ensemble_f1 0.62183
wandb:         train/mil_loss 1.72292
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/myzlc2p9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193208-myzlc2p9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5r9hunh0 with config:
wandb: 	actor_learning_rate: 0.00014072939343446326
wandb: 	attention_dropout_p: 0.13849906985998922
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08617301940427424
wandb: 	temperature: 2.468182143761851
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193501-5r9hunh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5r9hunh0
wandb: uploading history steps 174-190, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅█
wandb: best/eval_avg_mil_loss ▅█▅▁
wandb:  best/eval_ensemble_f1 ▁▂▅█
wandb:            eval/avg_f1 ▃▇▂▆▅▁▃▁▇▁▅▁█▇▇▃▄█▇▅▄▅▄▂▇▆▇▃█▄▆▂▆▅▂▄▃▇▇▂
wandb:      eval/avg_mil_loss ▁▁▂▁▂▂▆▄▁▇▂▁▆▃▂▂▂▁▄▂▄▂▁▁▁▁▂▂█▂▆▂▃▁▂▄▂▁▂▃
wandb:       eval/ensemble_f1 ▇▄▂▇▄▆▅▂▁▂▆▂▂▅▅▄▁▄▇▅▆▄▆▁▆▂▄▅▁▆▇▆▇▆▃▆▅█▄▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▅█▂▄▄▅▆▇▄▇▇▃▆▄▃▄▄▁▄▅▅▅▅▆▃▂▆▄▅▄▃▆▃▁▃▂▂
wandb:      train/ensemble_f1 ▃▂▄▅▂▄▃▅█▂▅▃▁▃▅▃▃▃▂▅▂█▇▃▃▂▄▄▅▅▂▄▃▃▂▃▄▃▂▄
wandb:         train/mil_loss ▇█▆▇▃▇▂▁▁▃▂▃▅▃▆▂▆▃▄▂▄▆▄▂▆▄▄▃▃▂▅▂▆▇▂▁▄▂▂▆
wandb:      train/policy_loss ▅▃▅▄▆▃▅▅▅▆▁▅▅▅▅▃▄▄▃▁▅▅▅█▅▁▄▅▅▅▅▅▃▅▅▅█▃▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▅▃▆▅▅▅▅▅▅▃▆▅▄▄▅▅▁▆▃▃▅▁▅▅▅▄▅▆▃▅▅▃▁▅▅▃█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.51922
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.4179
wandb:      eval/avg_mil_loss 1.81766
wandb:       eval/ensemble_f1 0.4179
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.78163
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.56052
wandb:      train/ensemble_f1 0.56052
wandb:         train/mil_loss 1.40612
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5r9hunh0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193501-5r9hunh0/logs
wandb: Agent Starting Run: gm40ii13 with config:
wandb: 	actor_learning_rate: 6.687346783781442e-06
wandb: 	attention_dropout_p: 0.1145593760866565
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 150
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2816918438798789
wandb: 	temperature: 4.134868032044096
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193736-gm40ii13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gm40ii13
wandb: uploading history steps 102-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▁█▂▃▃▁▃█▃█▁▃▃▁▆▃▁█▄▃▃▁▁▃▁▁▂▁▇▆▂▅▄█▃▁▂▂▃
wandb:      eval/avg_mil_loss ▃▂▁▂▁▂▁▁▁▂▂▁▅▁▂▃▃▂▂█▂▂▂▂▁▁▂▁▂▁▂▁▂▂▁▁▁▁▅▅
wandb:       eval/ensemble_f1 ▁▁▁▃▂▃█▁█▇▁▁█▃▄▃▁▃▃▃▃▁▁▄▃▃▁█▃▁▅▄▁▅▃▄▂▇▁▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▅▆▃▅▃▂▁▃▅▂▅▂▅▄█▃▆█▂▅▃▆█▃▂▂▄▆▂▁▂▅▅▆▃▆▄▃
wandb:      train/ensemble_f1 ▅▄▄▇▅▅▄▆▃▃▅▆▆▄▄▅▃▄▅▆▆▃▃▅▆▄▇▃▄▇▇▇▅▃█▆▄▆▂▁
wandb:         train/mil_loss ▂▁▄▄▃▅█▂█▅▆▂▄▂▂▆▃▃▂▄▅▃▃▆▂▁▃▄▄▂▁▅█▁▁▅▅▂▁▃
wandb:      train/policy_loss ▄▃▄▃▄█▄▄▄▄▄▄█▃▄██▄▄█▁▃▆▄▄▃▁▄▄▄▁▄▄▄▁▃▄▄▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▃▃▄▄▄▃▃▃█▃▁▄▄▄█▃▃▃█▃▄▄▃▄▄▄▁▄▄▃▄█▆▁▄▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.47889
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.89827
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78056
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.56619
wandb:      train/ensemble_f1 0.56619
wandb:         train/mil_loss 1.18911
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gm40ii13
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193736-gm40ii13/logs
wandb: Agent Starting Run: qu45ttuk with config:
wandb: 	actor_learning_rate: 8.094335919011102e-06
wandb: 	attention_dropout_p: 0.04452256688443501
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 169
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3018399764076837
wandb: 	temperature: 3.4723250570180033
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_193904-qu45ttuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu45ttuk
wandb: uploading history steps 163-170, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇▇█
wandb: best/eval_avg_mil_loss ▂█▆▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇▇█
wandb:            eval/avg_f1 ▂▆█▁▆▁▂▄▆▃▄▄▄▄▄▆▂▅▇▂▁▆▅█▄█▆▁▆▅█▇█▆▅▁▆▆▂▆
wandb:      eval/avg_mil_loss ▂█▁▂▂▂▁▁▅▁▁▁▂▂▁▄▁▁▁▁▂▁▂▁▁▅▁▁▁▃▂▁▁▅▁▁▁▅▁▁
wandb:       eval/ensemble_f1 ▂▂▅▆▂▂▂▂█▁▂▂▂█▆▄▄▇▁▆▅▇▂▅▇▂▆▅▆▆▇▆▆█▁█▇▆▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▃▄▃▃▃▃▅▃▅▄▅▄▁▅▇▄▄▄▂▂▄▆▅▅▇▅▃▆▄▅▂▅▅▅▄▁▃▄
wandb:      train/ensemble_f1 ▅▅▄▆▃▄▅▄▂▃▂▅▅▅▄▁█▅▆▃▄▂▇▃▄▃▅▄▅▆▆▄▅▅▂▃▅▁▅▅
wandb:         train/mil_loss ▇▃▃█▆▄▄▅▃▆▂▃█▃▄▁▄▄▃▁▁▄▁▄▅▆▄▁▂▄▄▃▃▃▃▅▁▅▂▃
wandb:      train/policy_loss ▃▄▄▄▄█▄█▄█▄▁▃▄▄██▄▄█▁█▄█▁▄▄█▄▄▄▄▄▆▄▁▄█▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄██▄▁▄▄▄▄█▆▄█▄█▄▄▄▄███▄▄▃▆▄▆▁█▄█▄▁▄▄▁▁▄█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.57432
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.40782
wandb:      eval/avg_mil_loss 4.20096
wandb:       eval/ensemble_f1 0.40782
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 5.28998
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.56903
wandb:      train/ensemble_f1 0.56903
wandb:         train/mil_loss 1.57108
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run autumn-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qu45ttuk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_193904-qu45ttuk/logs
wandb: Agent Starting Run: me13cwwm with config:
wandb: 	actor_learning_rate: 3.3525929116176515e-05
wandb: 	attention_dropout_p: 0.3234451870745663
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27923289063881973
wandb: 	temperature: 3.05698919660522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_194114-me13cwwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/me13cwwm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂███
wandb: best/eval_avg_mil_loss ▁█▄▁▇
wandb:  best/eval_ensemble_f1 ▁▂███
wandb:            eval/avg_f1 ▆▅▄▅▅▆▅▇▇▁▆▄▅▆▁▇▅▅▆▅█▆▇▇▄▇▆▄▆▇▆▁▂▆▅▅▄▁▅▃
wandb:      eval/avg_mil_loss ▂▃▂▂▂▂▁▁▄▂▄▄▂▂▁▁▂▂▁█▄▃▂▂▁▂▂▂▂▃▅▁▁▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▄▁▅▂▂▄▂▄▄▄▄▄▄▇▅▄▄▃▄▄▄▅▄▃▃█▄▄▃▁▄▄▅▃▄▄▁█▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▄▅▃█▃▄▄▄▅▃▂▂▄▆▆▆▄▁▂▄▄▃▄▂▂▄▄▅▄▃▅▇▄▄▁▂▃
wandb:      train/ensemble_f1 ▅▄▂▇▄▂▃▅▇▄▃▃▃▅▆▃▄▃▂▄▂▃▃▂▅▄▃▃█▁▇▅▇▂▄▄▅▁▂▄
wandb:         train/mil_loss ▂▂▂▁▅▂▄▆▂▃▂▇▁▂▃▆▄▂▂▃▂▂▅█▄▂▁▂▁▃▂▁▂▄▂▂▆▂▂▁
wandb:      train/policy_loss ███████████████████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▂▄▄▇▄▇▄█▂▂▄█▇▄▂▄▄▄▄▇▄▄▄▄▄▁▄▄▇▇▄█▄▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69212
wandb: best/eval_avg_mil_loss 1.3211
wandb:  best/eval_ensemble_f1 0.69212
wandb:            eval/avg_f1 0.65986
wandb:      eval/avg_mil_loss 1.10072
wandb:       eval/ensemble_f1 0.65986
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.75687
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.51895
wandb:      train/ensemble_f1 0.51895
wandb:         train/mil_loss 0.80882
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/me13cwwm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_194114-me13cwwm/logs
wandb: Agent Starting Run: 66ghivg5 with config:
wandb: 	actor_learning_rate: 8.881116219437645e-05
wandb: 	attention_dropout_p: 0.05935958190348584
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8210376405864421
wandb: 	temperature: 1.2513078673263245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_194354-66ghivg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66ghivg5
wandb: uploading history steps 103-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇██
wandb: best/eval_avg_mil_loss █▃▁▁▂
wandb:  best/eval_ensemble_f1 ▁▇▇██
wandb:            eval/avg_f1 ▂▁▆▆▁▇▁▆▁▁▁▁▂█▁▁▄▂▇▂▁██▃▁▁▁▂▇▁▇▄█▁▁▆▃▆▁▃
wandb:      eval/avg_mil_loss ▁▆▃▂▄▄▃▄▂▁▂▃▃▁▁▃▇▂▃▃▃▃▁▃▁▃▁▃█▂▁▃▃▁▂▃▁▅▃▃
wandb:       eval/ensemble_f1 ▇▆▆▆▃▇▁▆█▁▂▇▃▁█▄▂▄▁▁▇▂▁▃▁█▃▇▃▁▆▇▂▁▇█▁▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▃▅▇▄▄▄▆▄▆▃▁▃▄▆▃▅▂▄▂▄▆▅▆▃▆▂▄█▆▅▄▅▅▃▅▇▆▃
wandb:      train/ensemble_f1 ▁▆▅▄▇▅█▇▆▆▄▁▃▅█▂▆▆▂▅▇▆▆▇▆▂▃▅▅▇▆▇██▄▆▃█▄▄
wandb:         train/mil_loss ▁▃▄▂▄▂▄▄▇▅▄▅▅█▅▄▅▅▅▇▇▇▄▄▆▅▄▆▅▅▅▅▃█▄▄██▄▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.71862
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.99927
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.73906
wandb:      test/avg_mil_loss 1.27666
wandb:       test/ensemble_f1 0.73906
wandb:           train/avg_f1 0.60312
wandb:      train/ensemble_f1 0.60312
wandb:         train/mil_loss 0.82457
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/66ghivg5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_194354-66ghivg5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jemwgdxb with config:
wandb: 	actor_learning_rate: 7.795206950073764e-06
wandb: 	attention_dropout_p: 0.2076614520261156
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5352692375876874
wandb: 	temperature: 2.2655093354563127
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_194534-jemwgdxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jemwgdxb
wandb: uploading history steps 143-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▆██
wandb: best/eval_avg_mil_loss ▆▄▄█▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▆██
wandb:            eval/avg_f1 ▃▃▄▄▄▁▁▁▃▆█▃▁▃▃▁▁▃▁▃█▂█▃▅▁▄▃▇▃▃▁▃▄▁▃▄▃▆▁
wandb:      eval/avg_mil_loss ▁▁▂▂▁▁▂▂▂▂▁▁▂▂▁▂▁▂▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁█▂▁▂▁▂▁
wandb:       eval/ensemble_f1 ▁▃▆▁▃▃▄▁▁▁▄▃█▃█▃▄▁▆▁▃▁█▁▄▃▅▄▃▁▃▁▃▄▆▄▃▃▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▂▇▅▁▇▃▄▃▅▅▃▅▂▆▁▇▂▂▂▅▇▅▂▅▃██▆▄▅▅▅▃▇▅▅▄▂
wandb:      train/ensemble_f1 ▄▄▂▄█▂▃▃▅▇▃▄▇▄▆▂▄█▄▂▆▄▁▇▄▂▆▂▅▃▃▃█▄▅█▆▂▅▃
wandb:         train/mil_loss ▂▂▂▂▂▂▂▂▆▂▂▂▅▂▂▁▇▁▂▅▃▂▂▂█▂▂▁▂▂▂▄▅▂▃▆▂▃▂▁
wandb:      train/policy_loss ▄▄▁▄█▄▄▄▄▄▄▄▄▃▄▃▄█▄▄▄▄▃▄▃▄▃▄▄▁▄▃▃▄▄▆▄▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▄▄▄▄▄▄▄▄▄▄▄▃▄▄▃▃▃▁▄▃▄▃▄▄▆▄██▄▄▄█▁▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79968
wandb: best/eval_avg_mil_loss 0.58491
wandb:  best/eval_ensemble_f1 0.79968
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.90181
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.62364
wandb:      test/avg_mil_loss 1.74639
wandb:       test/ensemble_f1 0.62364
wandb:           train/avg_f1 0.51593
wandb:      train/ensemble_f1 0.51593
wandb:         train/mil_loss 0.94827
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jemwgdxb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_194534-jemwgdxb/logs
wandb: Agent Starting Run: hvrs1w8y with config:
wandb: 	actor_learning_rate: 1.5476102575106407e-05
wandb: 	attention_dropout_p: 0.476062368833744
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 189
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.761655413379324
wandb: 	temperature: 3.5355772609387657
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_194737-hvrs1w8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hvrs1w8y
wandb: uploading history steps 143-161, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆▇█
wandb: best/eval_avg_mil_loss █▂▆▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▆▇█
wandb:            eval/avg_f1 ▁▁▂▅▂▁▁▁▂▁▅▁▁▂▃▁▁▄▁▇▁▁▁▇█▇▁▂▁▄▁▁▂▁▁▁▁▁▂▁
wandb:      eval/avg_mil_loss ▁▃█▆▁▁▂▄▁▇▁▆▇▆▇▄▁█▂▇█▁▇▁▇▆▆▁▂▆▂▄▅▃▂▁▁▁▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▇▁▄▁▁▁▁█▁▁▄▅▁▁▁▂▂▁█▁▇▂▁▂▁▁▁▁▂▁▁▁▇▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▃▄▅▅▅▆▁▅▆▄▆▂▅▂▅▅▃▂▆▄▆█▄▅▄▄▃▁▄▆▁▆▃▅▆▆▂
wandb:      train/ensemble_f1 ▃▅▃▄▄▃▃▂▄▅▄▄▅▃▁▇▅▃▃▆▄▄▁▃▃▅▅▅█▆▁▃▆▄▇▃▄▁▄▂
wandb:         train/mil_loss ▃▇▄▃▆▂▅▃▅█▆▆▅▅▅▄▆▃▁▃▅▅▆▅▅▂▄▅▄▅█▆▆▃▄▅▄▃▆▅
wandb:      train/policy_loss ▅▅▅▆▆▅▅▅▃▃▅▅▅▅▅▅▅▅█▁▅▅▅▅▆▅▅▅▅▅▅▅▅▅▆▅▁▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁█▄▆▄▄▄▃▁▁▁█▄▄▄▄▄▄▄▃▄▄▄▄▄▄▆▄▃▄▄▄▄▃▄▄▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75845
wandb: best/eval_avg_mil_loss 0.79749
wandb:  best/eval_ensemble_f1 0.75845
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 6.10051
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81825
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.41369
wandb:      train/ensemble_f1 0.41369
wandb:         train/mil_loss 3.54024
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hvrs1w8y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_194737-hvrs1w8y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3df6zhu2 with config:
wandb: 	actor_learning_rate: 8.295929873934758e-06
wandb: 	attention_dropout_p: 0.23014761119285457
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 197
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05902397670589288
wandb: 	temperature: 2.920681064516021
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195019-3df6zhu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3df6zhu2
wandb: uploading history steps 102-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂█
wandb: best/eval_avg_mil_loss ▇██▇▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂█
wandb:            eval/avg_f1 ▁█▁▄▇▄▃▃▁▃▁▂▁▁▄▃▂▇▁▁▁▃▁▅▇▆▂▂▁▃▃▂▄▃▁▄▇▃▄▁
wandb:      eval/avg_mil_loss ▂▂▅▂▁▂▂▂▂▂▇▂▂▄▂▂▂▁▂▂▂▂▂▅▂▂▆▂▂▂▃▂▅█▂▃▂▂█▂
wandb:       eval/ensemble_f1 ▃▂▃▃▁▁▁▁▃▁█▁▁▄▅▃▄▂▁▁▁██▁▁▃▁▄▂▄▄▅▃▄▁▄▄▁▁▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▅▃▁▄▆▇▄▄▆▃▅▂██▃▄▄▃▃▄▃▃▃▄▄▃▄▅▄▄▄▄▂▃▄▆▆
wandb:      train/ensemble_f1 ▇▃▃▅▃▄▄▆▁▂▆▂▄▂▁▃▃▅▂▄█▇▂▅▂▃▂▃█▄▃▃▄▃▄▄▆▇▂▅
wandb:         train/mil_loss ▅▄▄▁▂▁▃▆▃▃▂▅▂▆▄▂▃▁▃▄▅▅▄█▅▆▂▃▂▄▃▂▄▃▅▄▃▃▂▂
wandb:      train/policy_loss ▁▃▃▁▃▁▃▃▁▁▃▁▃▃█▁▃▁▁▁▁▃▃▃▁█▁▁▁▃▃▁▁▃▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁█▃▃▃▃▃▆▃▁▃▁▁▃▁█▆▁▁▃█▃▃▃▃▃▃█▁▃█▃▃▁▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.88999
wandb: best/eval_avg_mil_loss 0.30188
wandb:  best/eval_ensemble_f1 0.88999
wandb:            eval/avg_f1 0.57033
wandb:      eval/avg_mil_loss 0.72541
wandb:       eval/ensemble_f1 0.57033
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 5.01744
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.60101
wandb:      train/ensemble_f1 0.60101
wandb:         train/mil_loss 2.58002
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3df6zhu2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195019-3df6zhu2/logs
wandb: Agent Starting Run: iurnppno with config:
wandb: 	actor_learning_rate: 4.270014753100236e-06
wandb: 	attention_dropout_p: 0.22788190042540815
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06381668873201785
wandb: 	temperature: 3.451730767017369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195305-iurnppno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iurnppno
wandb: uploading history steps 119-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss ▂█▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▂▂▄▁▁▁▂▁▃█▂▁▂▁▃▂▁▂▁▄▁▂▃▂▁▂▁▂▁▅▂▅▂▁▁▁▂▁
wandb:      eval/avg_mil_loss ▂▁▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▃▂▂█▁▂▂▂▄▁▁▂▂▄▃▂▂▂▂▂▂▂▄
wandb:       eval/ensemble_f1 ▁▁▁▄▁▁▂▂▂▂▁█▃▁▂▂▃▂▃▁▁▂▂▅▁▆▁▂▁▃▂▂▁▂▃▅▂▁▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▄▂▂▄▃▂▂▇▂▃▅▁▃▄▅▂▄▄▅▃▆▃▆▅▅▇▃▂▃▅▄█▃▂▁▅▁
wandb:      train/ensemble_f1 ▄▅▂▇▅▁▂▆▂▂▁▁▂▄▅▅▄▃▄▂▄▆▇▃▇▁▆▅█▃▃▄▂█▄▂▂▂▅▂
wandb:         train/mil_loss ▃▃▁▁▂▄▁▂▃▂▂▁▃▂▂▂▁▃▇▄▃▃▂▅▂▂▃▃▂█▄█▃▆▃▂▃▆▃▃
wandb:      train/policy_loss ▄▄▄▄▃▄▄▃█▄▄▄▃█▄▁█▄██▁▃█▃▄▄▄▄▄▄▄▄▁▄█▄▄▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄██▄▄▃▃▄▃▄▄▄▁█▃▄██▃█▄█▄▄▄▄▄▄▄▄▁▄▁████▄█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.60928
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.89808
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.77359
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.50973
wandb:      train/ensemble_f1 0.50973
wandb:         train/mil_loss 0.86632
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iurnppno
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195305-iurnppno/logs
wandb: Agent Starting Run: pbpuvy5e with config:
wandb: 	actor_learning_rate: 2.603029138580137e-06
wandb: 	attention_dropout_p: 0.2653929942961519
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32579004402403233
wandb: 	temperature: 5.064178405954868
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195450-pbpuvy5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pbpuvy5e
wandb: uploading history steps 121-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁██
wandb: best/eval_avg_mil_loss ██▁▃
wandb:  best/eval_ensemble_f1 ▁▁██
wandb:            eval/avg_f1 ▁▄█▃▆▂▃▇▃▃▄▄▄█▆▆▁▃▁▄▁▇▃▆▃▄▁▁▁▄▁█▃▃▁▁▄▄▁▂
wandb:      eval/avg_mil_loss ▁▂▂▃▃█▂▅▂▂▄▅▃▅▄▂▂▂▄▅▂▄▃▂▅▃▅▃▃▂▂▂▃▂▃▂▃▂▄▂
wandb:       eval/ensemble_f1 ▂▁▃█▇▁▅▅▄█▂▁▁▃▄▄▇▆▃▄▇▁▃▅▇▁▁▃▃▆▅▁▇▁▄▇▇▃▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▅▄▅▃▂▅█▄▇▁▃▂▃▅▃▇▇▄▁▅▄▄▅▃▄▆▅▅▁▇▇▆▄█▂▅▅
wandb:      train/ensemble_f1 ▅▃▄▄▃▁▄▃▃▂▄▃▅▄▁▂▆▂▅▄▆▄▁▃▁▁▂▆▅▃█▄▅▅▂▂▇▆▅▃
wandb:         train/mil_loss ▂▁▄▃▅▂▂▂▂▂▁▂▂▂▂▃█▅▅▁▁▂▃▂▂▂▂▁▂▁▄▂▂▁▂▂▄▁▆▆
wandb:      train/policy_loss ▃▃▂▂▂▅▆▃▂▂▆▃▁▂▂▂▃▃▆▂▃▂▃█▃▆▁▂▁▂▆▂▆▃▃▃▂▂▂▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▆▂▂▂▆▃▃▂▃▆▃▂▆▃▆▁▂▂▃▁▃▃▃▂▃▃█▂▃▂▂▆▆▂▂▆▃▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.70917
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.71989
wandb:      eval/avg_mil_loss 0.67423
wandb:       eval/ensemble_f1 0.71989
wandb:            test/avg_f1 0.3555
wandb:      test/avg_mil_loss 0.77127
wandb:       test/ensemble_f1 0.3555
wandb:           train/avg_f1 0.60117
wandb:      train/ensemble_f1 0.60117
wandb:         train/mil_loss 0.85398
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pbpuvy5e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195450-pbpuvy5e/logs
wandb: Agent Starting Run: 6nothm06 with config:
wandb: 	actor_learning_rate: 1.700056538417179e-06
wandb: 	attention_dropout_p: 0.17740636833642714
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20868802085568605
wandb: 	temperature: 4.180380938906973
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195633-6nothm06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6nothm06
wandb: uploading history steps 122-139, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss ▂▂█▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▅▁▁▁▁▁▁▁▁▆▁▅▅▁▁▁▁▁▁▁▁▂█▄▃▁▄▃▁▁▁▁▆▁▆▂▅▁▁
wandb:      eval/avg_mil_loss █▅█▁▇▁▁█▂▇▅▁▁▁█▁▂█▂▁▂▁▁▁▁▅▂▁▁▁▅▁▅▅▁▁▁▇▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▆▄▁▂█▅▁▁▅▁▁▅▁▁▃▁▂▁▁▅▂▅▁▁▁▁▁▁▆▅▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▆▇▇▂█▆▆▂█▄▄▆█▇▇▆▆▇▅▇█▄▅▇▅█▆▆▁▆▇▇▇█▇▇▃▂
wandb:      train/ensemble_f1 ▄▆▇▁▁▃▆▅█▆▁▆▂▄▇▆▇▇▅▁▆█▂▆▇▇▆▃▇▇▆▇▇▄▆▃▆▆▇▂
wandb:         train/mil_loss ▇▆▅▆▄▃▄▇▁▃▂▃▆▄▃▆▄▁▆▃▃▂▄▃▄▆▄▅▄▂▄▂▄▆▂▄▅▁▄█
wandb:      train/policy_loss ▆▃▃▁▃▁▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▁▁██▃█▃▃▃▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▃▃▃▁▃▁▃▃▃▃▃▃▃▁▃▃▃▃▃▃▁▁▁▃▃▃▁▃▁▃█▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 0.64551
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.09757
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08921
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.36342
wandb:      train/ensemble_f1 0.36342
wandb:         train/mil_loss 1.58799
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6nothm06
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195633-6nothm06/logs
wandb: Agent Starting Run: mbp47sbe with config:
wandb: 	actor_learning_rate: 2.1288970788537193e-06
wandb: 	attention_dropout_p: 0.2922997143888183
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13021977367990611
wandb: 	temperature: 4.707451654401101
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_195823-mbp47sbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mbp47sbe
wandb: uploading history steps 162-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▅███
wandb: best/eval_avg_mil_loss ▁▃▆█▃▃▃
wandb:  best/eval_ensemble_f1 ▁▃▅▅███
wandb:            eval/avg_f1 ▄▄▃▂▁▂▁▁▂▁▁▁▄▁▁█▁▇▄▇▁▄▃▁▁▁▁▁▄▁▄█▁▆▄▁▁▄▁▄
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▁▁▂▁▁▂▂█▂▁▂▂▁▁▂▁▁▂▁▂▄▂▁▁▁▁▂▁▁▂▁▂▂
wandb:       eval/ensemble_f1 ▄▁▁▄▁▁▁▂▁▄▄▁▁▁▆▁█▂▇▂▁▁▁▁▁▁▄▁▄█▂▁▃▂▄▁▄▂▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▇▇▆▆▆▄▃▇▃▄▇▄▅▆▅▄▅▇▆▅▆▆▄▃▆▆▆▁█▇▅▇▇█▅▇▄▆▆
wandb:      train/ensemble_f1 ▄▆██▆▄▂▅▄▃▆▇▆▃▅▆▅▆▅▅▃▃▅▄▅▁▃▆▅▇▆▆▅▂▆▅▄▆▅▂
wandb:         train/mil_loss ▄▂▂▂▃▂█▃▂▃▄▂▂▃▂▃▃▁▄▁▂▂▃▂▆▇▂▁▄▁▂▁▂▂▁▃▂▂▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃█▄▃▄▄▃▃▃█▃██▆▃▆▃▄█▄▆▃▃█▃█▄▃▃██▃▃▃▃▄▃▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70857
wandb: best/eval_avg_mil_loss 0.86995
wandb:  best/eval_ensemble_f1 0.70857
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.91793
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 0.82219
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.52865
wandb:      train/ensemble_f1 0.52865
wandb:         train/mil_loss 0.8455
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mbp47sbe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_195823-mbp47sbe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ighkija7 with config:
wandb: 	actor_learning_rate: 1.2390469725267745e-06
wandb: 	attention_dropout_p: 0.383636613628679
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 90
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7776959340552642
wandb: 	temperature: 3.8651359317917966
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200126-ighkija7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/t0zm7tev
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ighkija7
wandb: uploading history steps 82-91, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▁█▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▅▁▄▁▆▅▅▅▄▂▂▅▁█▃▅▁▁▄▁▁▅▁▁▂▅▄▂▁▁▅▁▁▅▁▂▄▁▅▁
wandb:      eval/avg_mil_loss ▁▁▂▆▁▂▂▂▃▁▁▁▂█▂▂▁▁▁▄▁▅▁▂▁▂▁▁▂▂▃▂▃▂▁▂▁▂▁▂
wandb:       eval/ensemble_f1 ▁▁▁▄▅▅▁▁▂▅▁█▅█▃▁▄▁▁▅▅▁▁▂▂▂▁▁▅▁▅▁▁▁▅▁▁▅▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▃▇▄▄▃▁▄▂▇▅▄▆▇▄▃▄▁▆▆▆▅▅▆▅▆▆▄▄▁▆▄▆▄▃▄▅▇▆
wandb:      train/ensemble_f1 █▆▆▃▅▅▁▄▂▁▅▅▅▂▇▅▃▄▇▂▄▇▇▇▄▆▅▅▅█▆▄▅▄▁▇▅▅▄▆
wandb:         train/mil_loss ▂▂▁▂▃▂▂▁▂▂▁▅▂▁▁▆▂█▁▂▁▅▁▂▂▄▂▁▄▂█▆▂▅▂▃▄▂▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68286
wandb: best/eval_avg_mil_loss 0.88909
wandb:  best/eval_ensemble_f1 0.68286
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.01291
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78847
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.54695
wandb:      train/ensemble_f1 0.54695
wandb:         train/mil_loss 0.87003
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ighkija7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200126-ighkija7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 5izt0i6d with config:
wandb: 	actor_learning_rate: 0.0001254957706320674
wandb: 	attention_dropout_p: 0.22051818786977845
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 116
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41428503741626166
wandb: 	temperature: 4.0982612456255465
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200251-5izt0i6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5izt0i6d
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 111-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▆▇██
wandb: best/eval_avg_mil_loss █▃▂▅▃▁▃
wandb:  best/eval_ensemble_f1 ▁▅▅▆▇██
wandb:            eval/avg_f1 ▅▄▁▂▃▁▂▅▇▃▂▂█▁█▄▅█▁▂▅▁▇▇▂▂▂▆▆▇▁▂▅▆▄█▃▇▃▄
wandb:      eval/avg_mil_loss ▁▇▂█▁▂▂▂▁▂▁▁▂▁▁▂▂▂▄▁▃▁▁▄▄▂▂▂▁▂▂▁▁▂▁▁▁▂▁▁
wandb:       eval/ensemble_f1 ▃▂▇▂▃▁▄▂▅▃▂▂▁█▇▃▇▃▃▃▅▅▇▇▇▃▅▇▃▇█▃▃▄▅█▃▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▂▆▅▃▁█▇▆▄▂▄▇▅▅▂▅▃▆▅▆▄▄▄▄▅▁█▇▄▇▂▅▃▅▅▃▆▅
wandb:      train/ensemble_f1 ▆▁▅▆█▁▅▇▅▆▃▆▆▄▄█▅▅▆▅█▃▅▃▃▄▄▅▄▄▅▆▄▃▅▇▄▆▅▅
wandb:         train/mil_loss ▂▃▇▄▆▂▅▄▃▂▂▂▆▁▁▁▆▇▃▄▄▆▂▄▄▆▄▄▂▇▁▃▄▄▃█▆▄▆▂
wandb:      train/policy_loss ▅▄▅▄▇▁▄▄▃▃▃▆▆▆▄▅▄▄▄▆▄▄▄▃▆▄▄▄▆▄▄▄▄▄▆█▄▃▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▇▅▃▅▃▆▃█▃▆▅▃▄▅▅▅▄▅▆▅▅▅▁▆▄▄▅▅▁▇▃▇▅▆▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74997
wandb: best/eval_avg_mil_loss 0.74068
wandb:  best/eval_ensemble_f1 0.74997
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.86898
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.5601
wandb:      test/avg_mil_loss 3.34298
wandb:       test/ensemble_f1 0.5601
wandb:           train/avg_f1 0.56478
wandb:      train/ensemble_f1 0.56478
wandb:         train/mil_loss 0.9362
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5izt0i6d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200251-5izt0i6d/logs
wandb: Agent Starting Run: 6ih1ayrn with config:
wandb: 	actor_learning_rate: 0.00012569731786602208
wandb: 	attention_dropout_p: 0.06233584128572589
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 51
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.060395827950036285
wandb: 	temperature: 2.818249759235236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200430-6ih1ayrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ih1ayrn
wandb: uploading history steps 41-52, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇█
wandb: best/eval_avg_mil_loss █▂▁▂
wandb:  best/eval_ensemble_f1 ▁▇▇█
wandb:            eval/avg_f1 ▃▇▁▁▇█▄▁▃▇▄▇▁▃▆▁▅▁▁▂▇█▆▄▁▃▁▇▁▁▃▄▁▆▆▃▆▅▇▆
wandb:      eval/avg_mil_loss ▆▂▂▂▄▅▃▆▄▂▂▂▃▄▃▃▂█▁▁▂▄▁▃▆▁▂▁▁▄▂▁▁▁▂▆▂▃▂▂
wandb:       eval/ensemble_f1 ▃▇▁▁▇█▄▁▃▇▄▇▁▃▆▁▅▁▁▁█▇█▆▄▃▆▁▇▇▁▃▄▁▆▃▆▅▇▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▄▄▄▃▆▃▅▅▆▃▂▆▂▅▆▆▄▅▁▄▁▇▆█▆▆▆▅▆▆▅▅▄▄▄▄▂▆
wandb:      train/ensemble_f1 ▆▆▄▄▄▃▆▃▅▅▆▃▂▆▂▆▅▆▄▅▁▄▁▇▆▄█▆▆▆▅▆▆▅▅▇▄▄▂▆
wandb:         train/mil_loss ▁▂▁▁▂▃▂▄▃▃▁▁▃▂▄▁▁▃▂▁▄▃▁▁▆▄▁▂▄▃▂▁▂▂▂█▂▃▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.75082
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.65781
wandb:      eval/avg_mil_loss 1.09896
wandb:       eval/ensemble_f1 0.65781
wandb:            test/avg_f1 0.38942
wandb:      test/avg_mil_loss 3.60135
wandb:       test/ensemble_f1 0.38942
wandb:           train/avg_f1 0.6881
wandb:      train/ensemble_f1 0.6881
wandb:         train/mil_loss 1.05543
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6ih1ayrn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200430-6ih1ayrn/logs
wandb: Agent Starting Run: y2ix03l3 with config:
wandb: 	actor_learning_rate: 0.00034973351970331464
wandb: 	attention_dropout_p: 0.35172995711367266
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 57
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8799062030464477
wandb: 	temperature: 5.785993762332991
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200511-y2ix03l3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y2ix03l3
wandb: uploading history steps 41-58, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂██
wandb: best/eval_avg_mil_loss ██▆▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂██
wandb:            eval/avg_f1 ▁▁▂█▁▃█▁▃▁▃▃▁▁▅▃▃▄▁▁▁▂▃▃▁▄█▇▃▁▆▅▃▁▁█▆▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▁▂▂▂▁▂█▂▂▂▂▂▂▂▂▂▂▇▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▁▂█▂
wandb:       eval/ensemble_f1 ▁▁▂█▁▃█▆▁▃▃▃▃▁▁▁▃▃▁▁▁▁▂▁▃▂▁▃▄█▃▆▅▁▁▂▆▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▁▂▅▇▄▅▆▄▄▇▅▆▇▄▆▂▃▆▄▆▁▂▄▄▄▆▅█▁▇▄▇▆▇▆▃▂▅
wandb:      train/ensemble_f1 ▄▆▄▄▅▁█▅▂▆▅▃▃▆▆▅▆▂▃▅▃▆▁▄▅▁▂▄▄▃▅▇▆▆▅▆▅▃▂▄
wandb:         train/mil_loss ▁█▅▃▂▁▃▁▄▂▄▁▃▂▁▂▃▄▁▃▂▁▄▂▁▁▃▅▁▁▄▃▂▂▃▂▁▂▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.63658
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.05416
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.85123
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.54393
wandb:      train/ensemble_f1 0.54393
wandb:         train/mil_loss 1.16346
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y2ix03l3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200511-y2ix03l3/logs
wandb: Agent Starting Run: g7nu8fd7 with config:
wandb: 	actor_learning_rate: 0.00027224684772785246
wandb: 	attention_dropout_p: 0.4651565927676067
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 157
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7459429850128475
wandb: 	temperature: 9.539350808523068
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200558-g7nu8fd7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7nu8fd7
wandb: uploading history steps 102-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁▂█▁▁▂▂▃█▂▂▇▂▆▁█▆▁▇▁▇▂▃▁▆▁▄█▁▆▃▂▁▂▄▁▁▃█▂
wandb:      eval/avg_mil_loss ▅▄▂▃▂▄█▂▁▄▃▁▅▃▂▃▃▄▂▄▃▅▂▂▃▅▂▂▂▂▂▁▃▅▂▂▃▄▂▃
wandb:       eval/ensemble_f1 ▁▇▄▁▂█▁▁█▇▂██▂██▄▆▇▁█▆▁▂▁█▆▂▁█▄▂▂▃▁▂▂▁▃▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▁▅▄▅▄▄▁▄▇▂▄▄▇▆█▄▅▅▂▄▅▇▅▃▇▄▄▇▂▄▃▂▄▄▅▅▂▄
wandb:      train/ensemble_f1 █▆▄█▅▃█▁▃▆▄▄▂▃█▄▆▃▂▄▆▄▂▄▂▄▄▅▄▃▄▃▄▂▆▄▇▄▆▃
wandb:         train/mil_loss ▄█▃▄▃▃▁▅▅▂▅▃▅▂▅▃▅▅▃▄▄▅▂▄▆▃▅▆▂▃▇▂▅▂▄▄▅▁▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79871
wandb: best/eval_avg_mil_loss 0.54531
wandb:  best/eval_ensemble_f1 0.79871
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.9993
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.82908
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.59178
wandb:      train/ensemble_f1 0.59178
wandb:         train/mil_loss 1.56301
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g7nu8fd7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200558-g7nu8fd7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: srhgjzkr with config:
wandb: 	actor_learning_rate: 9.59279663240787e-05
wandb: 	attention_dropout_p: 0.1221840203139527
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3657521090873749
wandb: 	temperature: 4.273201001905555
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200744-srhgjzkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/srhgjzkr
wandb: uploading wandb-summary.json
wandb: uploading history steps 97-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▇█
wandb: best/eval_avg_mil_loss ██▂▁
wandb:  best/eval_ensemble_f1 ▁▆▇█
wandb:            eval/avg_f1 ▆▂▁▁█▅▂▆▄▂▄▁▅▅▅▅▁▁▁▁▁▄▃▁▄▆▄▅▆▃▁▁▆▇▅▄▄▁▁▅
wandb:      eval/avg_mil_loss ▃▂▁▃▁▁▃▃▂▅▃▂▄▆▄▆█▁▄▁▁▁▄▄▂▂▁▂▆▁▂▁▂▆▅▁▅▆▂▁
wandb:       eval/ensemble_f1 ▁▇▂▁▆█▅▆▂▃▅▄▂▄▅▁▁▆▃▃▁▇▂▃▄▄▁▅▃▄▁▇▅▁▄▁▁█▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▄▄▆▆▄█▅▆█▅▆▄▆▆▆▅▆▅▆▅▃▅▄▇▅▆▆▄▄▆▅▆▄▆▆▅▅▇
wandb:      train/ensemble_f1 ▅█▃▆▅▇▃▆▆▆█▅▆▆▆▅▅▅▇▃▁▅▄▃▂▃▅▄▄▄█▆▇▇▅▆▅▄▃█
wandb:         train/mil_loss ▆▄▁▃▄▂▁▅▄▂▃▅▄▆▆▅▄▄▁▃▁▄█▃▁▅▄▄▅▅▂▃▄▃▁▄▁▅▅▃
wandb:      train/policy_loss ▃█▆▆▆▆▆▅▁▆▆▆█▃▆▆█▆▆▆█▃▆▆█▁▆▆▆█▃▃▆▃▃▆▅▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▇▆▆▅▁▆▃▆▆▆▆█▆▆▇▆▃▃▆▆▁▆▆▃▆▃▃▆▆▆▆▅▆▆▆█▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.46811
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.51648
wandb:      eval/avg_mil_loss 3.75848
wandb:       eval/ensemble_f1 0.51648
wandb:            test/avg_f1 0.54338
wandb:      test/avg_mil_loss 0.77615
wandb:       test/ensemble_f1 0.54338
wandb:           train/avg_f1 0.6269
wandb:      train/ensemble_f1 0.6269
wandb:         train/mil_loss 2.15455
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/srhgjzkr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200744-srhgjzkr/logs
wandb: Agent Starting Run: siu5zaip with config:
wandb: 	actor_learning_rate: 0.0006465055907101534
wandb: 	attention_dropout_p: 0.1030843413246842
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 110
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.882567883949843
wandb: 	temperature: 7.984863743282263
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_200916-siu5zaip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/siu5zaip
wandb: uploading history steps 102-106, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▇█▇▁▄▃▁▂▃▁▄▂▁▂▄▃▇▁▃▁▁▁▇▁▁▄▁▅▄▁▇▄▂▄▁▃█▁█▃
wandb:      eval/avg_mil_loss ▂█▂▂▂▂▂▂▂▃▆▂▂▃▆▂▂▂▂▂▂▃▂▂▂▂▄▂▄▁▃▂▂▂▃▂▃▂▁▂
wandb:       eval/ensemble_f1 ▂▃▁▃▃▁█▄▁▂▁▁▂▁▁▄▃▄▃▁▃▁▁▁▇▁▁▁▁▄▃███▁▃▁█▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅█▃▄▆▄▂▆▆▃▅█▃▅▃▁▇▃█▂▅▅▄▅▅▅▃▃▂▆▂▅▅▃▇▁▇▅▄
wandb:      train/ensemble_f1 ▇▇▆▄▆▅█▇▇▆▄▅▂▅▇▄▅▁█▅▇▆▆▄▅▆▅▃▆▆█▄▄▂▅█▂▃█▂
wandb:         train/mil_loss ▄▁▅█▅▃█▁▆▂▅▁▂▃▄▃▃▂▇▆▄▁▅▅▅▇▄▂▂▅▂▅▄▅▂▅▃▆▁▃
wandb:      train/policy_loss ▅▅▅▃█▃▃▅▃▅▃▃▅▃▆▅▃█▅▃▃█▅██▃▅▁▃▅▁▁▃▃▅▃▃▃▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▃█▃▅▅▃▅▅▆▅▅▃▃█▃▅▃▃▃▅▃██▁▅▁▃▁▅▃▁▃▅▃▅▃▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77858
wandb: best/eval_avg_mil_loss 0.75704
wandb:  best/eval_ensemble_f1 0.77858
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.99641
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.9308
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.61581
wandb:      train/ensemble_f1 0.61581
wandb:         train/mil_loss 1.38134
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sage-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/siu5zaip
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_200916-siu5zaip/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gb5f8gx6 with config:
wandb: 	actor_learning_rate: 5.079324420877353e-05
wandb: 	attention_dropout_p: 0.41811841957351953
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6644138292955433
wandb: 	temperature: 0.6856577269594133
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201048-gb5f8gx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gb5f8gx6
wandb: uploading history steps 123-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆██
wandb: best/eval_avg_mil_loss █▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅▆██
wandb:            eval/avg_f1 ▁▆▆▁▁▅▅▁▅▅▁▄▁▅▄▁▁▁▅▂▁▁▅▄▆█▁▁▁▅▅▄▅▇▄▁▄▄▁▁
wandb:      eval/avg_mil_loss ▁▁▆█▁▁▁▁▃▃▁▁▁▁▁▃▃▆▆▂▁█▁▁▁█▄▁▁▇▆▁▁▂▁▃▁▁▁▃
wandb:       eval/ensemble_f1 ▁▁▅▅▁▁▁▄█▁▁▄▁▄▅▅▆▁▁▄▁▁▁▁▁▅▃▇█▄▁▁▁▄▄▃▆▁▄▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▇▁▇▇█▇█▆▆▆▆▅▆▆▆▆▇▆▅█▆▅▆▇▅▂█▆▁▆▆▆▅▆▇▆▁▇
wandb:      train/ensemble_f1 ▄▆▁▇▅▅▇█▇▆▆▆▅▆▆▁▅▆▅▆█▅▇▆▂▆█▆█▁▅▆▆█▂▆▆▆▅▅
wandb:         train/mil_loss ▁▃▆▄▂▂▂█▃▃▃▃▄▂▄▄▂▂▁▃█▃▅▂▂▂▁▄▂▂▄▂▃▅▂▃▅▅▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70645
wandb: best/eval_avg_mil_loss 0.60413
wandb:  best/eval_ensemble_f1 0.70645
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.80421
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.91237
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.6851
wandb:      train/ensemble_f1 0.6851
wandb:         train/mil_loss 0.96944
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gb5f8gx6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201048-gb5f8gx6/logs
wandb: Agent Starting Run: wxie7iqi with config:
wandb: 	actor_learning_rate: 2.140423137523783e-06
wandb: 	attention_dropout_p: 0.2203521412369538
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 80
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4994296852535632
wandb: 	temperature: 0.3323849144873847
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201232-wxie7iqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wxie7iqi
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▆▂▃▁█▃▂▃▁▇▃▅▂▇▅▃▅▄▁▂▁▄▄▇▅▃▃▂█▂▄▁▂▂▆▁▂▄▁▇
wandb:      eval/avg_mil_loss ▂▁▁▁▂▂▁▂█▂▇▁▂▁▂▂▂▁▁▂▁▂▅▁▁▁▁▁▇▁▆▂▁▁▅▁▂▁▆▂
wandb:       eval/ensemble_f1 ▃▆▁▃▂▃▄▁▃▅▇▅▁▃▅▇▂▅▄▁▁▃▁▇▁▄▁▇▅█▃▁▄▁▄▁▂▅▆▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▂▄▃▄▁▂▃▄▂▁▂▃▁▃▅▇▃▅▁▅▃▂▄▇▃▂▄▅▄▅▂█▇▄▂▅▄▆
wandb:      train/ensemble_f1 ▃▂▄▅▄▂▄▄▅▂▂▂▃▂▁▅▇▅▃▂▅▃▂▇▄▄▆▄▆█▇▂▁▁▂▆▃▅▂▇
wandb:         train/mil_loss ▇▄▃▅▂▁▁▄▁▁▅▁▂▁▂▁▃▁▇▃▃▄▃▁▁▃▁▅▃▃█▁▂█▂▁▁▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79871
wandb: best/eval_avg_mil_loss 0.59789
wandb:  best/eval_ensemble_f1 0.79871
wandb:            eval/avg_f1 0.71492
wandb:      eval/avg_mil_loss 0.99513
wandb:       eval/ensemble_f1 0.71492
wandb:            test/avg_f1 0.81397
wandb:      test/avg_mil_loss 0.59959
wandb:       test/ensemble_f1 0.81397
wandb:           train/avg_f1 0.65856
wandb:      train/ensemble_f1 0.65856
wandb:         train/mil_loss 1.36414
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wxie7iqi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201232-wxie7iqi/logs
wandb: Agent Starting Run: v2a9bdoh with config:
wandb: 	actor_learning_rate: 0.0008963779044315727
wandb: 	attention_dropout_p: 0.46253562650070373
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25165416531104756
wandb: 	temperature: 7.971992931891347
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201339-v2a9bdoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v2a9bdoh
wandb: uploading history steps 81-97, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅█
wandb: best/eval_avg_mil_loss ▂█▇▁
wandb:  best/eval_ensemble_f1 ▁▄▅█
wandb:            eval/avg_f1 ▆▂▂▂▄█▂▃█▄▃▃▂█▃▂█▃▃▂█▁▂▆▂▂▂▂▅▃▂▅▆▄█▃▃▃▃█
wandb:      eval/avg_mil_loss ▁█▁▁▁▁▁▁▁▁▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁
wandb:       eval/ensemble_f1 ▄▃▃█▃▄▃▄█▅▁▄▄▄▃▃▆▃▃█▁▃▅▆▃▅▄▅▆▄█▆▄▆▄▁▂▆▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▄▄▁▂▁▅▁▆▅▅▇▅▅▅▂▅▄▆▄▂▄▄▅▁▆▄▁▅▄▆▁▅▁█▇▁▂
wandb:      train/ensemble_f1 ▅▁▆▄▃▄▅▂▃▆▅▆█▆▆▆▄▇▃▅▇▅▅▅▂▃▇▆▂▇▃▆▅▅▃▆██▂▆
wandb:         train/mil_loss ▂▁▂▂▃▂▁▁▂▂▁▂▁▁▁▂▁▁▄▁▂▂▃▃▂▂▁▁▇▂▂▃▂▂▂█▂▁▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76942
wandb: best/eval_avg_mil_loss 0.63946
wandb:  best/eval_ensemble_f1 0.76942
wandb:            eval/avg_f1 0.75369
wandb:      eval/avg_mil_loss 0.71534
wandb:       eval/ensemble_f1 0.75369
wandb:            test/avg_f1 0.70997
wandb:      test/avg_mil_loss 0.84112
wandb:       test/ensemble_f1 0.70997
wandb:           train/avg_f1 0.53775
wandb:      train/ensemble_f1 0.53775
wandb:         train/mil_loss 0.95954
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v2a9bdoh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201339-v2a9bdoh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tzr5mw71 with config:
wandb: 	actor_learning_rate: 0.0001554561621221582
wandb: 	attention_dropout_p: 0.3890917922808296
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 191
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9012621956874348
wandb: 	temperature: 1.336622656670995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201525-tzr5mw71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzr5mw71
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 ▁▅▁▇▁██▆▁█▆▁▇▁▂▁█▆▃▅▇▁▄▁▁▁▁▁▅▁▁▁▃▇▅▃▁▁▂▁
wandb:      eval/avg_mil_loss ▁▁▇▃▂█▁▁▂▃▂▁▂▇▁▅▁▂▁▁▁▁█▂▃▁▂▃▅▆██▁▇▅▁▅▂▃▃
wandb:       eval/ensemble_f1 ▁▆▁██▁▅▅▁▁█▁▁▁▁▃▁▂▁▁█▁█▆█▁█▁▁▇▁▅▁▅▁█▆▅▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▁▇▅▆▁▅▃▃▄▇▃▄▄▄▆▅▇▆▆▄▅▇▄▆▂▆▇█▆▅▅▅▆▄▆▄▄▄
wandb:      train/ensemble_f1 ▆▃▇▄▆▄▄▄▃▃▄▆▅▃▄▄▄▆▄▅▆▆▄▄▆▄▄█▄▅▅▅▅█▅▄▆▆▁▅
wandb:         train/mil_loss ▄▄▄▇▅▇▅▅▃▆▆▃▆▆▃▁▃▆▃▇█▁█▄▃▄▇▄▅▃▁█▃▇▆▃▃▇█▃
wandb:      train/policy_loss ███████████████████████████████████▁████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅█▅▅▃██▅▅▁▅▁█▅▅▅▃▅▃▅▅█▅▁▅▅▅█▅▃▅▅▅▁▁▅▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.52063
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.90951
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.48293
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.52179
wandb:      train/ensemble_f1 0.52179
wandb:         train/mil_loss 2.68614
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fine-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzr5mw71
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201525-tzr5mw71/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0v42w296 with config:
wandb: 	actor_learning_rate: 0.00021842212078838352
wandb: 	attention_dropout_p: 0.24552695644699613
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8737675253929176
wandb: 	temperature: 6.036757892187077
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201740-0v42w296
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0v42w296
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▂▁▃█▁▇█▁▂▁▂█▁▂▁▆▂▁▇▁▁▄▁▂▁▂▁▃▂▁▁▁▂▁▇▁█▁▂▁
wandb:      eval/avg_mil_loss ▃▃▂▂▂▅▃▂▄▃▂▅▅▃▂▂▂█▂▄▄▃▃▅▂▂▇▁▂▃▄▂▇▆▃▆▁▆▄▃
wandb:       eval/ensemble_f1 ▁▁▁▇▁▇▁▁▁▁▂▇▁▁▁▂▁▁▁▇▁▁▁▁▂▂▃█▄▁▁▁▁▁▆▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▇▆▆▃▅▆▇▆▅▅▅█▇▆▆▇▃▃▆▅▆▄▃▅▁▅▄▅▄▃▄▆▆▄▆▃█
wandb:      train/ensemble_f1 ▃▅▇▅▄▃▆▃▅▇▂▇▁▆▂▅▅█▄▆▇▃▃▃▆▅▆▆▅▃▁▅█▄▃▅▇▅▃█
wandb:         train/mil_loss ▃▃▃▂▄▆▁▅▆▅▃▄█▃▄▆█▅▅▃▂▅▄▆▇▅▅▃▄▄▃▃▃▄▂▆▇▆▅▃
wandb:      train/policy_loss ▄▄█▆▄▇▄▆▆▄▆▆▆▄▅▆▄▅▁▅▄▄▄▄▄▄▄▆▆▄▄▄▆▄▄▄▆▄▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄█▆▆▆▆▄▆▄▆▆▄▅▄▆▄▆▅▁▅▄▆▄▄▄▄▆▆▄▄▄▆▄▄▄▆▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68337
wandb: best/eval_avg_mil_loss 0.65098
wandb:  best/eval_ensemble_f1 0.68337
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.07635
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.38062
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.56454
wandb:      train/ensemble_f1 0.56454
wandb:         train/mil_loss 1.07924
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0v42w296
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201740-0v42w296/logs
wandb: Agent Starting Run: 2x2vmrpg with config:
wandb: 	actor_learning_rate: 6.0353495476637613e-05
wandb: 	attention_dropout_p: 0.4913070825315184
wandb: 	attention_size: 16
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 104
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7824159923311701
wandb: 	temperature: 3.1427358986806375
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201832-2x2vmrpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2x2vmrpg
wandb: uploading history steps 101-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁███
wandb: best/eval_avg_mil_loss █▅▁▅
wandb:  best/eval_ensemble_f1 ▁███
wandb:            eval/avg_f1 ▃▃█▁█▁▇██▄▄▃▁▄▁▁█▂▃██▃█▃▁█▆▁▁▁▂▁██▁▃▃▁▄▃
wandb:      eval/avg_mil_loss ▂▂▂▂▁▃▂▄▅▂▂▂▂▄▂▂▂▂▂▂▂▂▂▂▂▄▂▂▂▂▂▄▄▅▂▂▂█▂▄
wandb:       eval/ensemble_f1 ▃█▁█▁▃▅█▄█▃▃█▁▂▂▃▂██▄▃▃▄▄█▆▁▁▃▃▃▄▃▆▃▁▄▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▆▂▂▅▄█▅▄▅▆█▃▃▇▂▄▆▅▅▅▃▅▄▁▆▅▄▅▇▁▃▄▆▅▄▃▄
wandb:      train/ensemble_f1 ▂▄▃▆▃▂▂▅▄▃█▅▂▆▄▃▂▇▂▂▅▄▁▃▂▃▄▆▂▆▂▂▁▅▆▇▃▅▃▄
wandb:         train/mil_loss █▃▄▁▃▄▇▁▃▃▃▇▆▂▂▃▃▂▄▄▂▁▅▁▂▄▃▃▂▃▄▄▅█▄▂▂▄▁▄
wandb:      train/policy_loss ▆▅▅▅▃▃▅▅█▁▁▃▃▅▁▅▅▃▆▅▃▃▅▁▅▅▃█▆▃▅▆▅▁▃▃▃▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▅▃▅▃▃▃█▅▅▃▆▃▁▃▁▃▅▃▃▁▃▅▃▃▃▅▆▃▆▃▃█▃▃▆▅▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.7516
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.89981
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78554
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.58783
wandb:      train/ensemble_f1 0.58783
wandb:         train/mil_loss 1.15584
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2x2vmrpg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201832-2x2vmrpg/logs
wandb: Agent Starting Run: t4q72v7t with config:
wandb: 	actor_learning_rate: 0.0005868155633507256
wandb: 	attention_dropout_p: 0.1100674271581849
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8653327640081538
wandb: 	temperature: 1.026428785065303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_201955-t4q72v7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t4q72v7t
wandb: uploading history steps 171-185, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▅▇█
wandb: best/eval_avg_mil_loss ▄█▃█▄▁
wandb:  best/eval_ensemble_f1 ▁▁▂▅▇█
wandb:            eval/avg_f1 ▅▄▃▇▆▇▇█▄▄▄▂▇▃▇▃▃▇▃▇▄▄▅▄▂▆▄▂▁▂▄▃▃▃▃▃▁▇▂▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▂▁▂▂▄▂▆▃▄█▁▂▅▂▂▁▁▂▁▃▂▆▃▂▂▃▁▄▂▁▆▂▂▄
wandb:       eval/ensemble_f1 ▃▄▃▇▆▇▃▄▇▃▂▂▃▂▃▃▃▄█▃▄▁▄▅▄█▂▅▇▆▁▃▆▂▃▄▃▂▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▄▁▅▆▆▇▆▄▄▅▃▂▃▆▅▆▃▄▄▆▆▁▄▇▃█▅▂▁▄▄▅▄▆▄▆▆▇
wandb:      train/ensemble_f1 ▂▂▂▁▃▃▁▄▃▄▂▅▃▅▃▃▃▃█▅▆▄▃▅▆▅▄▃▄▆▃▃▃▄▂▁▄▃▅▅
wandb:         train/mil_loss ▃▅▅▁▄▄▂▆▃▄▅▂▆▆▄▄▁▃▇▆▃▃▃▃▃▄▃▃▅▃█▃▁▂▅▃▄▄▂▂
wandb:      train/policy_loss ▆█▆▆▃▃▆▂▆▃▆▆▃▂▂▃▁▃▃▁▇▁▂▂▁▄▃▄▃▆▁▆▂▃▄▆▂▄▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▆▄▄▃▄▄▄▆▆▃▄▃▃▄▄▃▁▄▅▃▄▃▆▃▄▄▅▅█▄▄▄▅▄▇▃▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78
wandb: best/eval_avg_mil_loss 0.52466
wandb:  best/eval_ensemble_f1 0.78
wandb:            eval/avg_f1 0.456
wandb:      eval/avg_mil_loss 1.63415
wandb:       eval/ensemble_f1 0.456
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.75937
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.57807
wandb:      train/ensemble_f1 0.57807
wandb:         train/mil_loss 0.95728
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t4q72v7t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_201955-t4q72v7t/logs
wandb: Agent Starting Run: 4unrn4vg with config:
wandb: 	actor_learning_rate: 4.180235297064563e-06
wandb: 	attention_dropout_p: 0.24004541395823736
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20569262826900617
wandb: 	temperature: 1.7245904934211065
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202224-4unrn4vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4unrn4vg
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇██
wandb: best/eval_avg_mil_loss ▇▅█▅▁
wandb:  best/eval_ensemble_f1 ▁▃▇██
wandb:            eval/avg_f1 ▅▄▇▃▁▂▄▂▂▃█▃▃▃▃▂▇▄▃█▇▃▆▃▇█▃▃▇▅▂▁▇▂▂█▇▂█▆
wandb:      eval/avg_mil_loss ▃▂▃▃▃▄▃▃▃▃▂▄▃▃▂▃▄▃▃▃▆▃▅▄▃▂▄▄▄▂▆▄▄▃▄▄▁▃▁█
wandb:       eval/ensemble_f1 ▄▅▃▄█▃▂▂█▄█▄▃▃▃▂█▅▃█▄▇▄▇▇▁▄▇▅▁▇▂▁▂▄██▂▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▅▄▇▇▅▅▂▇▇▆█▆▇▁▄▅▅▇▆▆▃▅▅█▅▅▄▅▆▄▇▇▇▆▄▄▄
wandb:      train/ensemble_f1 ▄▆▃▄▆▇▅▅▂▂▆▄█▆▇▁█▅▇▅▅▆▂▆▄▅█▅▅▅▁▄▇▇▅▄▃▅▆▄
wandb:         train/mil_loss ▃▅▄▆▃▄▅█▅▆▅▄▄▄▇▅▅▆▅▄▆▅▆▅▄▃▅▂▁▅▄▅▂▄▅▆▅▅▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76605
wandb: best/eval_avg_mil_loss 0.53195
wandb:  best/eval_ensemble_f1 0.76605
wandb:            eval/avg_f1 0.6862
wandb:      eval/avg_mil_loss 1.27025
wandb:       eval/ensemble_f1 0.6862
wandb:            test/avg_f1 0.49993
wandb:      test/avg_mil_loss 0.71906
wandb:       test/ensemble_f1 0.49993
wandb:           train/avg_f1 0.60896
wandb:      train/ensemble_f1 0.60896
wandb:         train/mil_loss 0.84322
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4unrn4vg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202224-4unrn4vg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: krp7t6pz with config:
wandb: 	actor_learning_rate: 0.0004713939284396687
wandb: 	attention_dropout_p: 0.20096979996465456
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 96
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2662226379578282
wandb: 	temperature: 8.633102515420731
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202330-krp7t6pz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krp7t6pz
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇▇█
wandb: best/eval_avg_mil_loss ▂▂▁▁▁█
wandb:  best/eval_ensemble_f1 ▁▄▆▇▇█
wandb:            eval/avg_f1 ▄▇▇▇▁▃▃▁▃▇▁▃▄▄▄▅▆▇▁▇▅▁▄▁▅▆▃▃▅▁▅▁▆▄▃▅▄▁▄█
wandb:      eval/avg_mil_loss ▂▁▂▁▂▂▁▂▁▂▂▂▂▂▁▁▂▂▁▁▂▁▁▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▂█
wandb:       eval/ensemble_f1 ▂▇▁▁▄▇▇▄▃▃▁▃▆▃▇▆▇▇▇▇▁▇▁▄▁▆▆▅▃▅▁▅▁▃▁▁▁▅█▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▃▁█▃▃▂▄▂▃▃█▃▂▂▃▃▆▄▁▂▄▂▄▃▂▂▄▅▅▃▂▁▂▃▃▆▃▄
wandb:      train/ensemble_f1 ▁▅▄▁▃▄▄▄▄▂▂▃▃▂▄▄▃▄▅▂▁▄▃▆▄▃▂▇▃▄▂▃▄▄▂▄█▃▄▄
wandb:         train/mil_loss ▂▃▃█▂▂▂▂▄▃▃▃▂▃▃▇▃▂▂█▂▃▃▃▃▂▃▄▃▂▃▃▁▂▂▃▃▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52381
wandb: best/eval_avg_mil_loss 1.73761
wandb:  best/eval_ensemble_f1 0.52381
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.77512
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.03789
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.48302
wandb:      train/ensemble_f1 0.48302
wandb:         train/mil_loss 0.88267
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/krp7t6pz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202330-krp7t6pz/logs
wandb: Agent Starting Run: 3muswsqj with config:
wandb: 	actor_learning_rate: 0.000330064136989917
wandb: 	attention_dropout_p: 0.11837055188346352
wandb: 	attention_size: 32
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 73
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4542518423446128
wandb: 	temperature: 3.138249565537979
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202447-3muswsqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3muswsqj
wandb: uploading history steps 61-74, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆██
wandb: best/eval_avg_mil_loss ▄▃▁█▆
wandb:  best/eval_ensemble_f1 ▁▄▆██
wandb:            eval/avg_f1 ▂▄▇▂▃▂▂▁▂▁▂▂▃▂▂██▅▂▆▂▂▂▃█▂▂▅▅▅▂▂▁▅▂▂▂▅▂▁
wandb:      eval/avg_mil_loss ▃▁▁▁▂▁█▁█▁▁▁▁▁▂▂▁▁▁▂▁▁▁▃▄▂▁▁▁▁▁▁▄▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▄▂▇▂▂▁▁▂▂▃▆▆▅▅█▅▁▂▂▂█▂▅▅▁▁▂▂▁▃▁▅▂▂▂▄▂▂▂▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▂▁▂▅▃▂▃▃▁▆▅▁▆▄▂▄▄▃▂▂▂▆▂▃▄▆▄▂█▂▂▂▅▆▆▁▂
wandb:      train/ensemble_f1 ▄▁▂▃▄▂▆▆▆▂▁▃▂▅▂▅▄▁█▁▂▅▂▂▇▃▅▆▄▂▂▃▄▆▆▃▆▁▃▃
wandb:         train/mil_loss ▁▂▂▄▅▁▂▃▄▆▂▁▁▁▁▂▂▃▁▁▂▄█▄▁▁▁▅▁▁▁▁▇▅▂▁▁▁▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64862
wandb: best/eval_avg_mil_loss 1.27161
wandb:  best/eval_ensemble_f1 0.64862
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.89341
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79645
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.49744
wandb:      train/ensemble_f1 0.49744
wandb:         train/mil_loss 0.89769
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3muswsqj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202447-3muswsqj/logs
wandb: Agent Starting Run: 8buptheh with config:
wandb: 	actor_learning_rate: 0.0005136706792613975
wandb: 	attention_dropout_p: 0.3825034673470082
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 130
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8226381712290486
wandb: 	temperature: 6.115686906708141
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202548-8buptheh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8buptheh
wandb: uploading history steps 122-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▄▄▁▃▂▂▅▆▄▆▄▃▃▆▂▇▃█▃▆▇▂▃▅▅▄▁▆▆▂▃▆▄▄▅▅▂▆▅▆
wandb:      eval/avg_mil_loss ▁▁█▆█▁▁▄▁▁▁▁▃▁▂▂▁▂▁▁▁▁▂▁▁▂▁▁▁▁█▁▁▁▁▂█▆▁▂
wandb:       eval/ensemble_f1 ▂▄▁▇▁▇▁▅▃▂▃▅▄▅▆▄▅▆▃▆▇▇▄▅▄▄▆█▆▄▂▁▃▅▅▃▄▅▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅█▂▅▆▆▂▇▃▆▃▃▆▆▃▃▁▆▂▄▄▁▃▅▅▄▅▃▂▃▃▂▄▅▂▅▃▄
wandb:      train/ensemble_f1 ▂▄▁▅▅▂▆▇▅▄▂▃▇▇█▁▃▄▃▆▃▅▂▂▇▆▇▅▄▃▂▃▇▆▃▄▂▆▂▄
wandb:         train/mil_loss ▂▄▁▂▂▆▅▄▁▅▃▂▁▁▆▇▂▃▁▂▁▇▂▁▃▁▄█▄▂▅▁▄▁▅▁▁▅▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75369
wandb: best/eval_avg_mil_loss 0.7358
wandb:  best/eval_ensemble_f1 0.75369
wandb:            eval/avg_f1 0.65503
wandb:      eval/avg_mil_loss 1.34268
wandb:       eval/ensemble_f1 0.65503
wandb:            test/avg_f1 0.56961
wandb:      test/avg_mil_loss 0.99855
wandb:       test/ensemble_f1 0.56961
wandb:           train/avg_f1 0.54618
wandb:      train/ensemble_f1 0.54618
wandb:         train/mil_loss 0.84812
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8buptheh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202548-8buptheh/logs
wandb: Agent Starting Run: 4vgjpegm with config:
wandb: 	actor_learning_rate: 0.0009328683083487904
wandb: 	attention_dropout_p: 0.20779192668945473
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15008505407307837
wandb: 	temperature: 4.234466513312734
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202732-4vgjpegm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4vgjpegm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇█
wandb: best/eval_avg_mil_loss █▄▂▁
wandb:  best/eval_ensemble_f1 ▁▇▇█
wandb:            eval/avg_f1 ▃▂▂▆▅▂▂▃▅▂▆▃▁▆▂▂▂▃▇▂▂▃▄▆▃▇█▂▃▂▂▅▃▂▂▃▃█▇▆
wandb:      eval/avg_mil_loss ▂█▃▃▅▂▅▂▆▄▂▃▂▄▅▅▃▃▃▃▁▄▇▃▃▄▃▂▄▂▂▄▂▇▃▃▄▅▂▂
wandb:       eval/ensemble_f1 ▁▇▃▂▇▃▄▂▄▃▁▃▇▇▇▃▂▆▁█▇▂▃▇▃▂▆▇▆▃▆▃▇▄▂▃▃▂█▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▁▂▃▄▄▃▃▃▄▅▄▅▄▅▇▃▆▅▆▂▃▂▃▃█▇▆▆▅▅▅▇▄█▅▆
wandb:      train/ensemble_f1 ▆▄▃▄▆▃▂▆▇▆▂▅▃▄▅▄▅▇▇▅▆▆▄▄▆▅▄▁▅▆▃▆█▇▇▆▃▆▆▆
wandb:         train/mil_loss ▁▄▄▅▂▃▂▄▄▃▁▃▄▃▄▅▃▃▄▂▄▃▃▃▅▄█▄▄▃▂▅▃▃▅▄▁▇▃▃
wandb:      train/policy_loss ▅▅▅▅▆▅▆▅▃▅▅█▄▅▆▁▅█▄▅▅▅▅▄▅▅▆▅▁▅▅▅▅▄▁▁▆▄▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▆▅▅▆▅▄▁▅▅█▅▆▅▅▄▃▅▅▄▆▅▄▆█▄▆▅▄▅▅▅▆▅▁▅▅▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7756
wandb: best/eval_avg_mil_loss 0.3318
wandb:  best/eval_ensemble_f1 0.7756
wandb:            eval/avg_f1 0.66933
wandb:      eval/avg_mil_loss 0.72812
wandb:       eval/ensemble_f1 0.66933
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.77557
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.59408
wandb:      train/ensemble_f1 0.59408
wandb:         train/mil_loss 0.91569
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4vgjpegm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202732-4vgjpegm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i7yd0h5w with config:
wandb: 	actor_learning_rate: 1.696087591101198e-06
wandb: 	attention_dropout_p: 0.08283190318156741
wandb: 	attention_size: 16
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5382308870126226
wandb: 	temperature: 9.097493749809216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_202950-i7yd0h5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i7yd0h5w
wandb: uploading history steps 81-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▆█
wandb: best/eval_avg_mil_loss █▇▇▅▁
wandb:  best/eval_ensemble_f1 ▁▂▂▆█
wandb:            eval/avg_f1 ▂▇▃▁▇▄▁▁▄▄▄▃▃▃▁▁▃▃▁▄▄▄▄▄█▄▄▁▇▂▃▂▃▄▃▃▂▇▄▂
wandb:      eval/avg_mil_loss ▃▄▅▄▄▃▄█▃▃▃▅▄▄▃▄▃▄▄▄▃▃▄▃▁▃▄▂▃▄▃▃▄▃▃▄▄▃▄▃
wandb:       eval/ensemble_f1 ▃▃▇▂▃▁▄▃▃▃▃▃▇▃▂▃▃▄▄▃▄▁█▄▄▄▄▂▇▃▃▂▃▄▃█▃▃▇▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁█▂▁▅▂▂▅▂▂▅▃▅▂▂▂▅▂▄▁▅▃▂▄▂▂▂▃▂▃▃▄▃▆▂▆▄▂▂
wandb:      train/ensemble_f1 ▂▂▇▇▂▂▅▂▆▂▅▅▂▅▂▁▄▂█▁▂▆▄▅█▃▂▂▃▄▃▁▅▂▄▆▂▂▄▂
wandb:         train/mil_loss ▅▃▄▂▂▃▂▂▂▂▂▂▃▂▂▃▃▂▄▃▁▂▂▃▃▂▃▃▃█▃▂▂▁▂▃▂▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.6269
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.57848
wandb:      eval/avg_mil_loss 1.51163
wandb:       eval/ensemble_f1 0.57848
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78468
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.49337
wandb:      train/ensemble_f1 0.49337
wandb:         train/mil_loss 1.12934
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i7yd0h5w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_202950-i7yd0h5w/logs
wandb: Agent Starting Run: e2vgovfu with config:
wandb: 	actor_learning_rate: 0.00012066676592917071
wandb: 	attention_dropout_p: 0.25025054642048344
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 164
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6619509468368684
wandb: 	temperature: 1.7623148648060103
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203100-e2vgovfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2vgovfu
wandb: uploading history steps 101-115, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇██
wandb: best/eval_avg_mil_loss █▂▁▁
wandb:  best/eval_ensemble_f1 ▁▇██
wandb:            eval/avg_f1 ▁▇▂▃▁▂▁██▄▁▁▄▁▃▁█▅▃▃▁▁▁▁▄▁▁▅▁▁▁█▄▄▂▇▃▅▅▂
wandb:      eval/avg_mil_loss ▂▁▂█▁▅▄▁▁▁▁▃▁▂▆▂▁▃▃▃▁▂▁▂▄▁▁▂▃▁▁▅▁▃▁▁▄▁▄▁
wandb:       eval/ensemble_f1 █▂▁▃█▆▁▁▁▁▆▁▄▁▄▄▆▁▁▃▁▆▁▄▄▄▃▆▁▁▄▃▃▄▄▃▅▆▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▃▂▅▆▆▄▄▇█▃▁▃▃█▄▅▅▄▆▃▅▄▄▆▅▂▇▃▄▅▅▄▆▆▄▃▆
wandb:      train/ensemble_f1 ▄▁▃▄▃▄▅▂▇▃▂▄█▄▇▃▂▃▅▅▃▄▆▇▆▅▂▃▇▆▂█▄▆▅▃▃▇▂▃
wandb:         train/mil_loss ▅▆█▅▄▇▄▃▃▄▃▅▅▄▂▁█▃▆▂▆▆▇▂▄▃█▂▂▃▆▃▆▅▁▆▃▆▁▃
wandb:      train/policy_loss ▅▁▅▅▅▅▅▆▃▅▅▆▅▁▅▃▆▃▁▅█▅████▅▅▆▁▅▅▅▃▆▆▃▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄█▄▄▄▃▄▆▃▄▆▁▄▄▄▁▃▄▄▆▄▆█▄█▆▄▆▃▆▃▄▄▄▄█▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76
wandb: best/eval_avg_mil_loss 0.70627
wandb:  best/eval_ensemble_f1 0.76
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.77624
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 0.87683
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.60245
wandb:      train/ensemble_f1 0.60245
wandb:         train/mil_loss 1.77012
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e2vgovfu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203100-e2vgovfu/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.54.24.4:36374->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 1qefiuij with config:
wandb: 	actor_learning_rate: 0.0004708418654068071
wandb: 	attention_dropout_p: 0.3236757994262106
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 65
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.497857076385211
wandb: 	temperature: 4.395613829563347
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203259-1qefiuij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1qefiuij
wandb: uploading history steps 61-66, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▁▁▁▃▁█▁▄▁███▄█▆▇▂█▁▂▁▄▁▁▂▁▅▂▄▁▇▂▁▄▁▂█▁▆
wandb:      eval/avg_mil_loss ▃▆▇██▇▄▇▆▇▆▇▅▄█▆█▄▅▆▆▃▇▇▇▆█▇▄▆▇▇▅▇▆▁▆█▆▄
wandb:       eval/ensemble_f1 █▁▁▁▁█▁█▁▄▁▁▆██▁█▁▆▂▂▇▁▁▄▁▇▁▂▁▁▁▁▇▄▄█▁▁▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▆▄▆▅▅▅▇▅▃▄█▃▄▇▅▅▃▆▃▃▅▅▂▆▃▅▃▆▆▄▆▆▂▄▆▅▄
wandb:      train/ensemble_f1 ▁▄▃▆▅▅▇▆▅▃▅▆▃▄█▆▅▄▄▃▅▆▃█▇▆▅▇▄▄▄▄▆▆▃▄▆▅▄▄
wandb:         train/mil_loss ▆▄▇▃▆▄▇▄▃▄▅▅▄▆▃▃▄▆▅▆█▁▂▄▄▄▄▄▅▄▃▆▄▄▅▄▃▅▄▅
wandb:      train/policy_loss ▃▁▁▁▁▁▃▃█▃▁▁▆█▁▁▁█▃▁▁▁▁▁█▁▁▁▁▃█▁█▁█▃▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▁▁▁██▃▃▃▁▆█▁▃▁█▁▁▁▁▁▁▁█▆▁▁▁▃▃█▃▁▁▁▁█▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59936
wandb: best/eval_avg_mil_loss 0.7847
wandb:  best/eval_ensemble_f1 0.59936
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.9344
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.84046
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.45444
wandb:      train/ensemble_f1 0.45444
wandb:         train/mil_loss 0.88668
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1qefiuij
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203259-1qefiuij/logs
wandb: Agent Starting Run: kjwucl12 with config:
wandb: 	actor_learning_rate: 0.0003549822252992873
wandb: 	attention_dropout_p: 0.3833192477621097
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41670581381902794
wandb: 	temperature: 7.1345635929918245
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203355-kjwucl12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kjwucl12
wandb: uploading history steps 80-82, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss ▆█▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▂▃▄▁▁▁▃▃▂▃▂▃▄▃▄▆▂█▃▃▁▁▃▅▂▃▃▂▂▃▄▄▃▁▇▆▃▃▂▃
wandb:      eval/avg_mil_loss ▂▁▂▁▁▂▂▁▆▂▁▁▃▁▁▁▁▁▁▁▁▂▄▂▁▂▃▁▁▁▁█▁▆▂▁▄▁▁▁
wandb:       eval/ensemble_f1 ▁▇▄█▄▄▁▁▁▁▂▃▂▂▄▃▃▄▃▄▇▃▄▁▁▄▃▆▄▃▃▃▅▃▂▇▃▁▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▅▃▆▂▃▅▅▁▇▄▆▇██▄▇▇▆▃▇▂▇▆▅▆▄▆▄█▅▅▃▅▄▅▃▃▄
wandb:      train/ensemble_f1 ▃▆▇▂▅▂▄▂▄▄▇▆▃▇▄▄▆▆▄▃▅▅▃▅▅▄▆▄▄▃▅▁█▃▆█▅▂▄▃
wandb:         train/mil_loss ▃▅▄▂▂▂▃▄▁▃▃▃▃▂▅▃▁▇▄▇▅▃▃▂▃▃▃▂▁▅▃█▅▃▆▅▂▂▃▅
wandb:      train/policy_loss ▃▃▁▃▃▃▄▃▃█▃▄▁▁▄▃▆█▃▄█▄▃▄█▃▄▄▃▃▃▆▄▆▃▃▄▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79475
wandb: best/eval_avg_mil_loss 0.77834
wandb:  best/eval_ensemble_f1 0.79475
wandb:            eval/avg_f1 0.47917
wandb:      eval/avg_mil_loss 2.33592
wandb:       eval/ensemble_f1 0.47917
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 3.59306
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.50966
wandb:      train/ensemble_f1 0.50966
wandb:         train/mil_loss 1.23191
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kjwucl12
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203355-kjwucl12/logs
wandb: Agent Starting Run: icnds33h with config:
wandb: 	actor_learning_rate: 0.000538814828814214
wandb: 	attention_dropout_p: 0.15725012779512798
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 68
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5062999761793952
wandb: 	temperature: 4.111029636709067
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203503-icnds33h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/icnds33h
wandb: uploading history steps 61-69, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄█
wandb: best/eval_avg_mil_loss ▂▂▁█
wandb:  best/eval_ensemble_f1 ▁▂▄█
wandb:            eval/avg_f1 ▃▄▂▆▃▂▂▃▃▅▃▁▃▂▃▃▂▃▃▆█▅▂▃▅▂▁▆▆▃▆▆▃▂▂▁▁▂▂▆
wandb:      eval/avg_mil_loss ▂▂▂▁▂▁▂▁▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂█▁▁▁▁▁▂▂▂▂▂▂▅▁
wandb:       eval/ensemble_f1 ▂▅▂▂▇▃▃▂▃▇▁▃▃▂▃▃▂▃▂▃▃▂▂▇▃▇▁▇▄▃▇▃▃▂▁▂▂▂▃█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▅▂▂▆▆▃▂▃▄▁▂▅█▆▃▆▃▅▂▆▇▇▆▃█▆▆▂▂▅▄▄▇▂▅▅▇▄
wandb:      train/ensemble_f1 ▂▃▂▂▃▃▃▃▃▄▂▅█▃▆▆▆▅▂▆▆▁▃▁█▆▃▄▁▂▂▅▃▄▃▅▇▅▂▅
wandb:         train/mil_loss ▂▂▆▄▂▁▂█▁▂▄▂▃▂▂▂█▂▂▃▃▂▂▂▄▂▂▂▂▃▂▄▂▇▂▂▂▂▂▁
wandb:      train/policy_loss ▆▃▁▁▁▃▆▁▁▃▃▆▃▁▃▁▆▁▃▆▁▆▃▁█▃▁▆▃▆█▁▁▁▁▃▁▆▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▁▃▁▁▆▁▁▆▃▆▃▁▃▆▃▁▆▆▃▆▁▃▆▁▁▃▁▆▁█▁▃▃▁▃▁▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59603
wandb: best/eval_avg_mil_loss 1.28659
wandb:  best/eval_ensemble_f1 0.59603
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.90598
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.78664
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.50212
wandb:      train/ensemble_f1 0.50212
wandb:         train/mil_loss 0.88628
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run frosty-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/icnds33h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203503-icnds33h/logs
wandb: Agent Starting Run: kgk16vbm with config:
wandb: 	actor_learning_rate: 0.00013645134638839862
wandb: 	attention_dropout_p: 0.16853439595014946
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 57
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4555160320546811
wandb: 	temperature: 1.9597883535703289
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203600-kgk16vbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgk16vbm
wandb: uploading history steps 41-58, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▇██
wandb: best/eval_avg_mil_loss ▆▅█▅▁▁
wandb:  best/eval_ensemble_f1 ▁▂▆▇██
wandb:            eval/avg_f1 ▃▃▃▆▇▂▂▃▁▁▃▁▁▅▃▂▃▃▃█▃▁▄▄█▇▁█▆▄▁▂▁▁▃▂▁▁▄▅
wandb:      eval/avg_mil_loss ▂▂█▂▂▂▂▂▂▂▇▅▃▇▂▄▂▂▁▂▁▃▃▂▁▁▂▃▂▂▃▃▃▄▅▁▂▂▃▁
wandb:       eval/ensemble_f1 ▃▃▆▇▄▃▁▁▃▃▁▅▁▄▂▃▃█▃▄▁▄▄█▇█▆▄▅▇▁▂▁▃▁▇▂▃▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▄▅▅▆▅▆▁▅▄▃▄▄▅▇▄▃▄▇▄▅█▅▄▅▅▅▄▅▄▅▆▄▆▆▆▇▅▅
wandb:      train/ensemble_f1 ▄▄▅▅▅▄▆▆▁▄▃▄▄▅▁▇▄▃▄▆▅▄▅█▅▅▅▄▅▄▆▄▄▆▆▆▅▇▅▅
wandb:         train/mil_loss ▃▅▆▃▃▄▄▂▄▆▇▁▄▃▄▃▄▃▂▂▂█▂▇▁▃▂▃▇▅▄▄▃▂▄▅▅▇▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78
wandb: best/eval_avg_mil_loss 0.67634
wandb:  best/eval_ensemble_f1 0.78
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.63953
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.76951
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.58324
wandb:      train/ensemble_f1 0.58324
wandb:         train/mil_loss 3.14088
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kgk16vbm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203600-kgk16vbm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fx4ddvsx with config:
wandb: 	actor_learning_rate: 0.00014918448006733545
wandb: 	attention_dropout_p: 0.28305451772708645
wandb: 	attention_size: 128
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 54
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5412200389750835
wandb: 	temperature: 4.730781475465476
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203656-fx4ddvsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fx4ddvsx
wandb: uploading history steps 38-55, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▃▇▄▃▃▄▃▇▂▁▅▃▁▃▄▄▄▄▆▇▃▃▂▄▂▃▃▃▃▄▂▅█▃▃▃▄▂
wandb:      eval/avg_mil_loss ▁▁▁▁▄▄▂▂▁▄█▂▅▁▁▂▁▁▁▁▂▄▄▂▂▁▂▁▁▂▁█▁█▁▁▂▂▁█
wandb:       eval/ensemble_f1 ▄█▄▃▄▃▄▃▇▆▁▅▅▃▁▃▄▄▄▄▃▆▇▃▂▂▃▃▃▃▄▂▄▅█▄▃█▃▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▄▃▃▄▁▅▃▆▄▃▄▇▆▄▃▆█▅▄▂▆▄▄▃▁▄▄▁▄▆▆▃▄▅▂▂▄▂
wandb:      train/ensemble_f1 ▁▆▄▃▃▃▁▅▃▆▄▃▄▆▆▃▃▆█▅▄▂▆▄▆▄▄▁▃▄▆▄▃▄▂▂▂▂▄▂
wandb:         train/mil_loss ▂▅▂▁▃▃▆▂▃▅▃▅▂▃▁▆▃▂▂▁▂▄▂█▃▁▃▄▄▂▅▂▁▂▆▄▄▃▅▂
wandb:      train/policy_loss ▄▄▆██▆▄▃▆▃▆▆▆█▆▆█▆▃▆█▆▄█▆██▆█▁███▆▇▆▄▄██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▆██▆▆▃▄█▆▆█▆█▆█▆▃▆█▆▆▄██▆█▁▆▁██▆▇▆▄▄██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75913
wandb: best/eval_avg_mil_loss 0.69422
wandb:  best/eval_ensemble_f1 0.75913
wandb:            eval/avg_f1 0.42857
wandb:      eval/avg_mil_loss 4.42814
wandb:       eval/ensemble_f1 0.42857
wandb:            test/avg_f1 0.52616
wandb:      test/avg_mil_loss 3.79175
wandb:       test/ensemble_f1 0.52616
wandb:           train/avg_f1 0.54583
wandb:      train/ensemble_f1 0.54583
wandb:         train/mil_loss 0.98887
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fx4ddvsx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203656-fx4ddvsx/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jqw1hg0o with config:
wandb: 	actor_learning_rate: 1.6548679275056134e-05
wandb: 	attention_dropout_p: 0.03646488609906123
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12153977878278456
wandb: 	temperature: 5.3321797821462
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203753-jqw1hg0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqw1hg0o
wandb: uploading history steps 94-104, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 █▇▃▅▂▇▅▂▁▂▄▃▁▄▃█▆▂▆█▅▆▅▄▄▆▂▃█▅▇▇▃▅▆▂▄▄▇▄
wandb:      eval/avg_mil_loss ▂▂▁▆▃▂▂▇▃▂▇▃▂▂█▁▁▂▁▆▂▂▄▅▆▂▂▂▂▁▂▃▂▁▂▆▆▂▁▂
wandb:       eval/ensemble_f1 ▅▇▆▂▆▆▄▂▆▆▂▃▆▇▃▂▇▆▃▆▆▆█▄▄▂▇█▆▇▃▄▆▂█▃▇▃▁▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▇▄▂▇▇▂▃▃▆▆▆▄▄▂▆▆▅▄▃▅▂▆▅▄▆▅▅▆▆▃█▆▂▁▅▃▄
wandb:      train/ensemble_f1 ▇▆▁▆▅▃▆▇▃▇▆▄▅▃▇▆▃▃▃▂▄▃▃▆▅▅▅▇▇▄▃▆▄▃█▆▄▅▆▄
wandb:         train/mil_loss ▃▅▄▅▁▃▄▆▄▁▂▅█▆▆▂▂▂▄▄▃▃▂▅▂▅▄▅▇▆▁▂▄▃▅▃▃▂▄▂
wandb:      train/policy_loss ▅▃▃▅▄▅▃▇▇▇▁▇▁▅▄▇▇▆▃▃▆▇▄▅▅█▅▇▇▇▇▄▅▅▅▁▇▆▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▃▄▄▃██▄▆▆▄▆▃▅▃▅▁▆▄▄▄▄▆▄▄▄▆▆▆▄▄▃▄▄▁▄▅▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.85859
wandb: best/eval_avg_mil_loss 0.38673
wandb:  best/eval_ensemble_f1 0.85859
wandb:            eval/avg_f1 0.66562
wandb:      eval/avg_mil_loss 0.83599
wandb:       eval/ensemble_f1 0.66562
wandb:            test/avg_f1 0.79475
wandb:      test/avg_mil_loss 0.54264
wandb:       test/ensemble_f1 0.79475
wandb:           train/avg_f1 0.61372
wandb:      train/ensemble_f1 0.61372
wandb:         train/mil_loss 1.08404
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jqw1hg0o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203753-jqw1hg0o/logs
wandb: Agent Starting Run: 22x6gq0t with config:
wandb: 	actor_learning_rate: 0.00018446683063925103
wandb: 	attention_dropout_p: 0.3841034459034264
wandb: 	attention_size: 16
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 153
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03772601931586128
wandb: 	temperature: 1.688227120340573
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_203921-22x6gq0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/22x6gq0t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss ▆█▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▃▆▆▆▂▇▂▃▇▆▆▄▆▆▇▃▃█▆▆▁█▇▅▆▃▁▅▇█▅█▇▃▄▇▁▇██
wandb:      eval/avg_mil_loss ▂▂▃▂▁▁▂▂▃▅▁▂▂▂▂▄▂▁▂▂▁▃▂▁▂▅▂▁▃▁▁▁▃▄▂▂█▃▁▁
wandb:       eval/ensemble_f1 ▆▅▂▅█▆▂▅▅▄▃▅▃▆▃▅▅▃▁▂▅▆█▃▂▃▁▅▅▇▅▅▁▇▃▄▇█▃▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▁▃▄▅▃▅▇▂▅▅▅█▆█▆▅▄▆▄▆▆▂▆▅▇▅▃▆▄▄▄▅▁▂▅▅▄
wandb:      train/ensemble_f1 ▅▇▄▄▄▅▃▅▄█▅▅▂▆▆▆▅▄▅▆▅▄▆▄▂▅▇▅▃▆▃▆▅▄▂▄▁▄▂▅
wandb:         train/mil_loss ▃▅▂█▂▅▃▇▄▂▅▂▄▃▄▅▄▂▄▂▆▅▄▃▆▄▅▅▅▅▄█▅▁▆▄▄▇▂▃
wandb:      train/policy_loss ▃▃▃▃▃▁▃▃▆▆▆▅▃▆▃▁▃▁▃▃█▁▁▆▆▃▂▃▂▃▁▁▆▁▆▁▃▅▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▃▅▃▆▃▁▅▆▃█▅▃▃▅▅▃▁▆▅▅▅▅▇▁▆▆▆▆▃▆▄▆▃▅▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.60189
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.7348
wandb:      eval/avg_mil_loss 0.91995
wandb:       eval/ensemble_f1 0.7348
wandb:            test/avg_f1 0.5778
wandb:      test/avg_mil_loss 1.14354
wandb:       test/ensemble_f1 0.5778
wandb:           train/avg_f1 0.61098
wandb:      train/ensemble_f1 0.61098
wandb:         train/mil_loss 1.09799
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/22x6gq0t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_203921-22x6gq0t/logs
wandb: Agent Starting Run: zqjin811 with config:
wandb: 	actor_learning_rate: 1.030242527833777e-06
wandb: 	attention_dropout_p: 0.33004092840447186
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 137
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9839320296199618
wandb: 	temperature: 4.90901488882697
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204059-zqjin811
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqjin811
wandb: uploading history steps 121-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅█
wandb: best/eval_avg_mil_loss ▁▄█▂
wandb:  best/eval_ensemble_f1 ▁▅▅█
wandb:            eval/avg_f1 ▅▄▂▄▃▁▄▄▅▁▂▄▄▃▃▄▆▅▁▃▂▂▅▇▂▂▁▃▃▃▄▂▂█▁▃▂▅▁▄
wandb:      eval/avg_mil_loss ▁▁▂▁▁▁▁▁▅▃▁▁▁▁▅▁▅▁▁▆▁▁▁▃▁▁▃▁▁▁▂▁█▁▁▁▁▃▁▁
wandb:       eval/ensemble_f1 ▇▄▂▁▂▆▃▄▆▂▆▁▄▃▄▃▇▄▃▃▁▃▅▂▅▄▄▃▂▃▃▃▁▂█▅▆▆▄▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇█▂▇▆▅▁▇▁▄▂▁▅▆▄▂▂▁▃▁▄▇▂▃█▃▅▄▄▅▅▂▅▂▄▆▅▃▆
wandb:      train/ensemble_f1 ▇▇▆▅▅▆▄▆▄▅▅▇▅▆▇▅▆▅▅▇▆▃▅▆▆▆▄▇▆▆▅▅▁█▄▆▆▇▇▅
wandb:         train/mil_loss ▂▁▃▅▃▁▁▃▁▁▁▃▇▆▁▆▂▁▇▁▁▅█▁▁▂█▂▄▃▆▁▁▅▄▂▃▁▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76998
wandb: best/eval_avg_mil_loss 0.76128
wandb:  best/eval_ensemble_f1 0.76998
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.95566
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.49993
wandb:      test/avg_mil_loss 0.76164
wandb:       test/ensemble_f1 0.49993
wandb:           train/avg_f1 0.56879
wandb:      train/ensemble_f1 0.56879
wandb:         train/mil_loss 1.8287
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqjin811
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204059-zqjin811/logs
wandb: Agent Starting Run: i76jwo7y with config:
wandb: 	actor_learning_rate: 0.00021736147352913196
wandb: 	attention_dropout_p: 0.08824791448178676
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6737686123377572
wandb: 	temperature: 9.920444924094246
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204248-i76jwo7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i76jwo7y
wandb: uploading history steps 41-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▅▇▇██
wandb: best/eval_avg_mil_loss █▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▅▅▇▇██
wandb:            eval/avg_f1 ▁▅▁▅▅▇▇▄▁▁▃▇▅▄█▂█▄▃▅▄▇▄▃▃█▃▇▆▃▄▃▇▄▅▄▄▇▅█
wandb:      eval/avg_mil_loss █▂▆▁▁▁▁██▂▁▅▁▁▁▁▁▁▂▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▅▅▄▇▄▁▁▅█▄▄▂█▃▅▄▄▇▆▃▃▅█▇▆▃█▄▃▇▄▄▅▄▄▇▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▄▂▃▅▁▆▅█▇▆▅▅▂▄▂▄▄▁▅▅▅▄▁▂▂█▃▆▅▆█▅▄▆▃▃▂▄
wandb:      train/ensemble_f1 ▅▂▅▄▂▄▅▂▆▅▅█▇▅▆▆▁▄▂▄▂▅▆▅▅▂▃▂█▄▅▆█▅▄▆▃▃▂▄
wandb:         train/mil_loss ▂▅▁▁▂▂▁▁▂▂▄▅▃▂▂▇▂▃█▂▇▁▄▄▂▅▅▆▁▁▆▂▁▇▂▄▁▆▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.68362
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.80767
wandb:      eval/avg_mil_loss 0.70564
wandb:       eval/ensemble_f1 0.80767
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.4238
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.63372
wandb:      train/ensemble_f1 0.63372
wandb:         train/mil_loss 1.84476
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i76jwo7y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204248-i76jwo7y/logs
wandb: Agent Starting Run: 3pf4u71z with config:
wandb: 	actor_learning_rate: 2.4855684322948274e-06
wandb: 	attention_dropout_p: 0.09903488771216136
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 165
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9439192961327388
wandb: 	temperature: 9.793179587653706
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204335-3pf4u71z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3pf4u71z
wandb: uploading history steps 152-166, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▆▆▇█
wandb: best/eval_avg_mil_loss █▁▁▄▄▂▁
wandb:  best/eval_ensemble_f1 ▁▄▆▆▆▇█
wandb:            eval/avg_f1 ▂▆▂▂▆▃▁▃▆▂▂▂▂▇▄▂▆▂▆▂▂▂▇▃▃▂▃▁▁▂█▁▆▂▁▂▃▆▂▃
wandb:      eval/avg_mil_loss ▄▁▁▆▂▂▂▆▁▇▅▁▂▂▂▃▂▆█▃▃▃▁▂▃▆▂▃▇▃▂▄▂█▇▃▁▄▂▄
wandb:       eval/ensemble_f1 ▂▁▁▂▆▆▆▂▁▃▆▂▂▆▃▄▁▃▆▂▂▆▂▃▅▃▆▁█▅▄▂▂▂▁▃▂▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▄▅▄▅▄▅▅▁▄▃▄▃▆▆▃▆▃▄▂▃▄▃▄▃▄▆▆▆▄▂▄▆▃▅▇▁▃▂
wandb:      train/ensemble_f1 ▅▆▅▇▇▆▄▆▇▇▅▇▇█▄▆▅▆▆▅█▄▆▁▄▅▇▆▇▆██▅▅▇▇▄▃▅▄
wandb:         train/mil_loss ▂▄▂▂▆▆▆▃▅▄▅▆▅▅▅▃▂▇▃▃▅▇▂▄▅▂▅▄▅▄▆▃▂▁▃█▅▁▅▄
wandb:      train/policy_loss ▆▄▆▆▆▆▆▃▃▆██▆▆▇▃▆█▆▆▄▆▁▆█▃▃▆▆█▃█▆▃▆▃█▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▂▃▃▆▆▃▇▂▄▄▃▁▁▃▃▃▆▃█▁▁▃▃▂▅▃█▆▃▁▃▃▁▆▂▆▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79798
wandb: best/eval_avg_mil_loss 0.46099
wandb:  best/eval_ensemble_f1 0.79798
wandb:            eval/avg_f1 0.44191
wandb:      eval/avg_mil_loss 2.22017
wandb:       eval/ensemble_f1 0.44191
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 1.23108
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.46134
wandb:      train/ensemble_f1 0.46134
wandb:         train/mil_loss 2.26394
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3pf4u71z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204335-3pf4u71z/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y7ie12n2 with config:
wandb: 	actor_learning_rate: 0.0004396179174845423
wandb: 	attention_dropout_p: 0.0009548871736278496
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38417339357829217
wandb: 	temperature: 0.14908173400195457
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204559-y7ie12n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y7ie12n2
wandb: uploading history steps 101-109, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss ▄█▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▇▃▆█▆▁▆▇▆▆▁▁▇▇▃▄▇▆▃▃▁▃▆▁▆▆▆▇▆█▁▁▇▇██▇▁▆▇
wandb:      eval/avg_mil_loss ▂▁▇▂▂▂▁▂▂▃▂▂▂▃▃▃▂▂▂▂▂▃▂▄▂▂▂▂▁▄█▃▂▅▃▃▁▂▁▂
wandb:       eval/ensemble_f1 ▇▇▃▆▆▃▅▇▇▁▁▇▁██▃▄▇▃█▆▃█▁▆▁▇█▇▇▁▇▁█▇▁██▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▄▃▆▆▄▆▇▆▇▅▁▅▅▅▆█▄▁▄▃▅▃▂▆▆▂▆▆█▅▄▆▄▆▄▆▅▆
wandb:      train/ensemble_f1 ▄▅▅▇▆▅▆▁▅▆▄▅▂▄▅▅▂▆█▃▅▄▇▇▄▅▅▆▃▆█▆█▆▃▆▆▇▇▆
wandb:         train/mil_loss ▁▄▂▃▂▄▂▃▂▃▁▅▄▄▂▃▄▃▂▁█▂▇▃▄▂▅▃▃▂▃▁▆▁▃▃▁▄▃▂
wandb:      train/policy_loss ▃▅▃▃█▅█▃▅▁▃▅▁▅█▃█▁▅▁▁█▃▃▃▅█▅▅▅█▅▃▅▃▁▅▃▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃▄▃▁▄▄▃▃▁█▃▄▁▁█▄▄█▁▄▁▁█▁▄▃▃▄▃▄▄▄██▃█▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.4959
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.74653
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.8651
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.68861
wandb:      train/ensemble_f1 0.68861
wandb:         train/mil_loss 0.69125
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y7ie12n2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204559-y7ie12n2/logs
wandb: Agent Starting Run: wdeafmv6 with config:
wandb: 	actor_learning_rate: 2.4666958460565588e-05
wandb: 	attention_dropout_p: 0.33872873369475826
wandb: 	attention_size: 128
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 86
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9335210299197872
wandb: 	temperature: 8.131737482446646
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204728-wdeafmv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wdeafmv6
wandb: uploading history steps 81-87, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▂█▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▃▂▄▃▁▂▅▃▃▂▁▁▄▁▃▁▁▃▄▅▂▄▃▄▃▂▃▅▁▁▄▁▁▃▅▁▁█▂▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▁█▁█▂▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▅▂▂▂▇▂▂▂▁▂▁█▂
wandb:       eval/ensemble_f1 ▃▂▁▃▁▂▃▇▃▃▃▁▄▄▁▁▂▄▅▂▁▃▃▄▂▁▁▁▄▁▄▃▄▅▁▁▄▁█▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▆▂▄▃▃▅▅▄▁▆▆█▃▅▅▆▅▄▇▃▅▆▄▁▃▃▅▆▃▄▅▃▃▄▅▅▃▄
wandb:      train/ensemble_f1 ▂▅▆▂▂▄▃▃▅▅▃▂█▅▄▅▇▆▃▄▄▂▃▃▄▅▄▁▅▂▂▃▄▅▂▅▅▆▆▄
wandb:         train/mil_loss ▇▄▄▃▂▃▂▂▇▆▂▅▃▂▂▁▄▄▆▅█▂▄▄▆▆▄▄▁▇█▃▇▂▂▂▂▂▃▁
wandb:      train/policy_loss ▃▁▆▅▅▃▅▁▅▃▃▃▃▅▃▃▃▅▃█▃▃▅▃▆▃▃▃▃▃▅▃▆▅▃█▃▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▅▃▅▃▅▅▃▅▃▆▅▅█▃▅▃▃▆▃▆▅▃▆▅▆▃▅▃▃▃▅▃█▃▅▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76979
wandb: best/eval_avg_mil_loss 0.70732
wandb:  best/eval_ensemble_f1 0.76979
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.01835
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.69365
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.53825
wandb:      train/ensemble_f1 0.53825
wandb:         train/mil_loss 0.81065
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wdeafmv6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204728-wdeafmv6/logs
wandb: Agent Starting Run: gq6tek6a with config:
wandb: 	actor_learning_rate: 3.0970040233979844e-06
wandb: 	attention_dropout_p: 0.4974272212341088
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9022678148790056
wandb: 	temperature: 5.30308230423607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_204840-gq6tek6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gq6tek6a
wandb: uploading history steps 135-142, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇█
wandb: best/eval_avg_mil_loss █▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▇█
wandb:            eval/avg_f1 ▁▅▃▁▁▁▇▃▄█▃█▂▁▁▃▁█▁▅▂▃▂▁▁▂▃▄▇▃▇▁▃▂█▇█▃▂▃
wandb:      eval/avg_mil_loss ▅▃▁▆▅▄▆▅▂▁▁▂▄▂▅▁▅▁▂▄▂▄▁▂█▃▄█▁▅▂▆▁▁▂▂▃▃▁▁
wandb:       eval/ensemble_f1 ▁▁▆▁▆▃▁▆▄▇█▅▃▂▂▇▂▆▆▄▃▄▂▆▁▆▂▁▆▁▆▁▁▂▂▆▃▂▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▅▆▇█▇█▆▅▇▇▆▇▇▇▇▇▅▇▆▄▆█▂▇▅▆▄▅▆▆█▅▇▁▃▇▇
wandb:      train/ensemble_f1 ▇▅▆▆▅▇▇▆▆▅▆▄▄▆▆▆▆▅▆▁▇▅▅▅▇▆█▅▅▇▆▆▅▅▆▆█▅▄▇
wandb:         train/mil_loss ▃▆▅█▄▄▄▅▂▃▄▃▅▅▅▃▅▁▅▅▄▂▅▄▂▅▃▄▃▃▄▁▂▆▂▃▃▆▃▅
wandb:      train/policy_loss █▃▁▄▆▆▆▃▆▆▃▆▆▆▃▆▆▇▆▆▃▃▇▆▄▇▄▆▆▆▆▆▇▆▇▆▆▆█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▁▄▅▄▄▄▆▄▃█▄▆▄▆▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▆▄▄▄▄▆▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77991
wandb: best/eval_avg_mil_loss 0.58593
wandb:  best/eval_ensemble_f1 0.77991
wandb:            eval/avg_f1 0.63054
wandb:      eval/avg_mil_loss 0.70714
wandb:       eval/ensemble_f1 0.63054
wandb:            test/avg_f1 0.71591
wandb:      test/avg_mil_loss 1.19886
wandb:       test/ensemble_f1 0.71591
wandb:           train/avg_f1 0.55999
wandb:      train/ensemble_f1 0.55999
wandb:         train/mil_loss 2.32476
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gq6tek6a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_204840-gq6tek6a/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1gln9egr with config:
wandb: 	actor_learning_rate: 1.6864379839831445e-06
wandb: 	attention_dropout_p: 0.07042186422207602
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 87
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5158737669248734
wandb: 	temperature: 3.8501263238766184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205047-1gln9egr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1gln9egr
wandb: uploading history steps 77-88, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▇▄▆▃▅▆▁▇▅▁▄▄█▆▆▁▃▅▇▄▁▇▄▂▆▃▁▃▂▄▆▂▂▄▄▃▇▁▇
wandb:      eval/avg_mil_loss ▁▂▁▃▄▄▂▂▄█▂▂▂▂▃▁▁▂▂▁▂▂▂▁▂▅▄▂▆▄▃▂▄▂▄▂▁▁▂▁
wandb:       eval/ensemble_f1 ▇▆▇▅▄▄▃▁▆▁▄▅▆▁▄▁█▇█▆▄▄▆▂▄▁▆▃▁▂▃▂▂▆▃▆▄▃▂▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂█▄▅▅▃▄▃▄▆▅▄▄▁▄▄▄▃▃▅▄▄▆▅▅▅▃▄▆▄▆▁▅▃▂▄▃▅▃▅
wandb:      train/ensemble_f1 ▃▅▆▅▆▆█▄▅▅▇▇▅▁▆▇▆▇▅▇▃▅▄▇▆▇█▆▆█▁▇▃▂▆▂▅▃█▅
wandb:         train/mil_loss ▄▅▁▄▇█▁▂▃▅▃▃▅▅▄▃▃▃▄▁▅▄▄▆▃▃▅▄▇▄▆▃▃▆▃▅▄▂▂▃
wandb:      train/policy_loss ▆▅▅▃▆█▁▅▅▃▃▂▄▁▆▃▆▆▃▅▅▅▆█▆▆▅▅▆▅▂▆▅▆▅█▂▅▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▄▆▃▅█▃▆▅▃█▃▆▂▁▆▄▃▄▄▄▄▃▄▄▄▄▆▄▄▆▄▇▄█▄▂▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82957
wandb: best/eval_avg_mil_loss 0.48985
wandb:  best/eval_ensemble_f1 0.82957
wandb:            eval/avg_f1 0.76998
wandb:      eval/avg_mil_loss 0.51136
wandb:       eval/ensemble_f1 0.76998
wandb:            test/avg_f1 0.85806
wandb:      test/avg_mil_loss 0.37946
wandb:       test/ensemble_f1 0.85806
wandb:           train/avg_f1 0.59898
wandb:      train/ensemble_f1 0.59898
wandb:         train/mil_loss 1.20621
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1gln9egr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205047-1gln9egr/logs
wandb: Agent Starting Run: 9k3tstub with config:
wandb: 	actor_learning_rate: 8.97165123458959e-06
wandb: 	attention_dropout_p: 0.25914115827541295
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 200
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8367306192794012
wandb: 	temperature: 7.608073003337842
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205201-9k3tstub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9k3tstub
wandb: uploading history steps 101-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss █▁▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▁▁▁▄▃▁▁▄▃▄▄▁▃▄▃▃▁▇█▄▃▄▁▁▄▃▁█▄▁▃▁▄▁▅▃▁▂▃▄
wandb:      eval/avg_mil_loss ▁▁▁▁▄▆▁▁▁▃▁▁▁▆▁▁▁▁▁▁▁▁▁▁▆▆▁▁▃█▁▁▁▃▁▃▁▁▂▁
wandb:       eval/ensemble_f1 ▁▃▁▅█▁▃▃▃▁▄▄▃▃▄▃▃▃▃▁▇▄▄▁▁▁▃▃▆▃▆▁▁▃▃▆▁▁▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▇▅▆▄▄▆▆▆▅▄▆█▆▆▆▆▇▇▆▆█▆█▅▆▆▅█▇▅▁▅█▅▅▆▆
wandb:      train/ensemble_f1 ▆▅▁▆▇▅▂▄▆▆▅▆▇▅▇▆▄▅▆▆▅█▇▂█▆▆▇▅█▇▅▇▆▅▇▅▇▆▆
wandb:         train/mil_loss ▆▆▆▄▅▆▁▁▃▆▂█▄▆█▄▅▃▇▄█▂▃▁▅▂▄▂▁▃▄▅▅▃▄▁▄▃▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77921
wandb: best/eval_avg_mil_loss 0.60595
wandb:  best/eval_ensemble_f1 0.77921
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.91622
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.697
wandb:      test/avg_mil_loss 0.89176
wandb:       test/ensemble_f1 0.697
wandb:           train/avg_f1 0.52336
wandb:      train/ensemble_f1 0.52336
wandb:         train/mil_loss 0.81774
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9k3tstub
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205201-9k3tstub/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kjjg3gc9 with config:
wandb: 	actor_learning_rate: 7.485056984036213e-06
wandb: 	attention_dropout_p: 0.3311713429611293
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 59
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8792456124061343
wandb: 	temperature: 5.468564229122929
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205333-kjjg3gc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kjjg3gc9
wandb: uploading history steps 41-60, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▂▄▂▁▁▂▂▂▄▂▃▁▁█▁▃▃▂▁▄▁▁▂▁▄▄▁▁▁▄▁▂▄▁▁▄▃▃▅
wandb:      eval/avg_mil_loss ▁▇▃▂▂▂▂▂▇▂▅▂▇▂▂▂▁▂▂▂▂▂▂█▂▂▁▂▂▂▂▁▃▂▂▂▁▇▂▂
wandb:       eval/ensemble_f1 █▂▁▂▁▂▂▂▄▃▃▁█▄▁▂▁▁▁▄▁▁▂▁▁▁▁▁▁▁▅▄▁▂▁▁▄▃▃▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▆▄▅▇▃▅▄▁▅▂▅▆▆▆▆▇▇▅▆▇▅▅▅▇▂█▅▆▄▂▆▅▆▆▆▄▃▆
wandb:      train/ensemble_f1 ▅▅▅▄█▂▄▃▁▄▄▁▄▄▃▅▅▄▅▅▁▄▄▄▄▂▆▄▅▄▂▄▅▃▄▄▃▃▂▅
wandb:         train/mil_loss ▁▃▅▁▅▅▃▂▃▆▄▂▅▁▃█▂▁▁▂▇▂▃▄▃▅▃▂▁▅▃▃▃▄▂▂▁█▃▃
wandb:      train/policy_loss ▃▄▃▃█▄▄▄█▄▃▆▄▃▄▃▄▁▃▄█▆█▄▃▃▄█▄▆▃▃▃▄▃▄▃▃█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▃▃▁█▃▃▃█▃▁▁▆▃▁▃▃▁▃▁▃▃▁██▃▃▁▃▁▃▆▃▁▁▁▆▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80563
wandb: best/eval_avg_mil_loss 0.73066
wandb:  best/eval_ensemble_f1 0.80563
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.90996
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78507
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.55367
wandb:      train/ensemble_f1 0.55367
wandb:         train/mil_loss 1.288
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kjjg3gc9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205333-kjjg3gc9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7d4apphh with config:
wandb: 	actor_learning_rate: 1.3062993138837572e-06
wandb: 	attention_dropout_p: 0.07840635690695502
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 102
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31723215068352206
wandb: 	temperature: 4.496790684836355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205454-7d4apphh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7d4apphh
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 █▇▆█▄▃▃▆▃▆▂▁▂▂▅▇▄▅▆▃▃▅▃▅▆█▃▅▇▅▆▂▂▄▅▃▃▄▂▃
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▂▂▄▆▂▃▂▁▅▁▃▂▅▂▂▂▇▂▂▂▂▁▂▂▅▂█▂▂▂▂▂▂▅
wandb:       eval/ensemble_f1 ▅█▆▂▆▆▇▃▃▂▂▆▅▅▄▁▂▇▃▄▅▆▄▄▅▃▂▃▆█▆▅▅▅▂▃▂▅▆▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄█▃▅▄▄▅▆▅▄▄▆▅▄▄▆▄▅▇▆▆▁▆▅▅▄▂▅▁▅▆█▇▇▇▃▅▂▆
wandb:      train/ensemble_f1 ▃▇▂▃▅▅▅▄▃▄▄▃▄█▄▃▄▄▄▄▄▆▆▃▃▅▂▅▇▄▄▄▆▄▆▅▁▂▆▅
wandb:         train/mil_loss ▂▅▅▁▃▄▁▄▁▃▆▆▄▂▁▃▁▄▃█▄▅▃▇▁▁▂▃▁▁▅▁▁▅█▂▁▆▁▄
wandb:      train/policy_loss ▆▅▃▇▅▄██▄▃▆▃▄▃▁▄▆▄▆▄▄▅▃▁▄█▆▄█▄▃▆▄▆▄▆█▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▅▃▇▄▄▆▄▇▆▄▆▄▄█▁▆▄▄▄▄▅▄▄▄█▄▄▆▆▆▄▆▄▃▆▄█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82916
wandb: best/eval_avg_mil_loss 0.39186
wandb:  best/eval_ensemble_f1 0.82916
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.83241
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.84188
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.63556
wandb:      train/ensemble_f1 0.63556
wandb:         train/mil_loss 2.35359
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7d4apphh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205454-7d4apphh/logs
wandb: Agent Starting Run: r1qevpy7 with config:
wandb: 	actor_learning_rate: 1.6794830043138909e-06
wandb: 	attention_dropout_p: 0.0943143623976776
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6637240185983803
wandb: 	temperature: 2.6758714565386077
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205622-r1qevpy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r1qevpy7
wandb: uploading history steps 57-76, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▅▄▄▄▄▂▇▃▄▄▂▂▃▃▆▇▇▁▇▁▃█▃▄▃▄▇▄▄▃▂▄▇▃▂▇█▄▇▃
wandb:      eval/avg_mil_loss ▃▂▁▂▁▂▂█▂▁▂▂▃▁▁▂▂▁▄▁▂▂▁▁▂▂▂▂▂▁▅▇▅▁▁▁▂▅▁▁
wandb:       eval/ensemble_f1 ▃▄▃▃▃▅▃▄▁▂▄▂▆▃▇█▄▂▆▂▃▆▃▅▇▁▃▂▂▄▃▂▂▅▆▆▃▆▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▂▇▄▃▂▄▁█▇▁▄▅▅▄▇▁▃▄▁▂▂▂▂▄▅▄▅▁▅▅▃▇▆█▄▃▂▃
wandb:      train/ensemble_f1 ▁▅▂▃▇▃▄▂▅▄▆▄▄▅▅▆▃█▄▄▃▂▂▆▅▅▄▁▂▄▄▄▃▄▅▄▃▂▂▃
wandb:         train/mil_loss ▃▁▄█▄▃▇▃▄▃█▃▁▂▂▂▅▁▃▂▄▄▄▃▂▂▄▁▄▃▄▃▁▇▂▁▂▁▃▄
wandb:      train/policy_loss █▇▆▇█▂▃▅▇▅▅█▃▅▇█▇▅█▂▂▅▁▅▅█▇▅▅▅▅▅▃▂▇▃▇█▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄██▁▇▂▄▄█▄▁▇█▇▇▄█▁▅█▄▄▄▄▄▇▂▂▄▂▄▂▄▇█▇▇▄█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82998
wandb: best/eval_avg_mil_loss 0.55324
wandb:  best/eval_ensemble_f1 0.82998
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.76933
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.46501
wandb:      test/avg_mil_loss 1.85937
wandb:       test/ensemble_f1 0.46501
wandb:           train/avg_f1 0.53564
wandb:      train/ensemble_f1 0.53564
wandb:         train/mil_loss 1.24369
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r1qevpy7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205622-r1qevpy7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ovjg7qax with config:
wandb: 	actor_learning_rate: 9.755414800705298e-06
wandb: 	attention_dropout_p: 0.08631475284870299
wandb: 	attention_size: 32
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 72
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4478352039748428
wandb: 	temperature: 3.000573163954373
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205749-ovjg7qax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ovjg7qax
wandb: uploading history steps 60-73, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 █▁▄▁▁▄▁▃▁█▁▁▄▄▇▄█▁▁▄▇▃▃▇▁▇▁██▅▄▄▄▃▄▂▃█▇▁
wandb:      eval/avg_mil_loss ▂▄▂▂▂▂▅▂▂▂▂▃▂█▂▁▂▂▂▂▁▁▂▂▂▂▂▂▃▂▂▁▂▂▂▂▂▂▁▂
wandb:       eval/ensemble_f1 ▁█▁▁▃▁▃▄▄▁▄▁▄█▁▃▄█▄▁▃██▃▁▇▁▇▅▄█▃▄██▃▅█▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▅▃█▄▆▅▇▂▅▅▃▂▅▇▅▇▄▃▆▆▄▅▆▁▄▄▇▅▃▄▄▃▆▁▆▄▅
wandb:      train/ensemble_f1 ▆▅▄▅▃█▄▆▅▇▂▅▃▂▅▅▄▇▄▃▄▄▅▃▆▁▄▄▄▇▄▄▅▄▄▆▅▆▄▅
wandb:         train/mil_loss ▃▃▃▄█▂▁▃▃▇▂▂█▂▄▅▅▃▅▂▃▃▂▃▃▂▄▄▅▃▅▆▂▁▄▁▃▅▂▂
wandb:      train/policy_loss ▃▄█▃▄▃█▄▃███▄▄▃█▁▄▆▃▃██▄▄▃█▄▃▃█▄▁▄▁▁▁▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▅▅▁█▁▃▅▃▃█▆▃██▃▃█▁▆▃▅▃█▅▃██▃▁▅█▅▅█▅▁▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73847
wandb: best/eval_avg_mil_loss 0.81181
wandb:  best/eval_ensemble_f1 0.73847
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.09106
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.41203
wandb:      test/avg_mil_loss 1.63805
wandb:       test/ensemble_f1 0.41203
wandb:           train/avg_f1 0.60192
wandb:      train/ensemble_f1 0.60192
wandb:         train/mil_loss 1.00269
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run classic-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ovjg7qax
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205749-ovjg7qax/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qbw7kfet with config:
wandb: 	actor_learning_rate: 3.2016165568929306e-06
wandb: 	attention_dropout_p: 0.001832752020768991
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 75
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5209782543991148
wandb: 	temperature: 1.9356613737557016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_205858-qbw7kfet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbw7kfet
wandb: uploading history steps 61-76, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅██
wandb: best/eval_avg_mil_loss ▄▄█▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅██
wandb:            eval/avg_f1 ▃▃▁▂▁▁▆▃▆▃▁▃▁▁▃█▄▃▃▃▁▄▃▁▁▁▁▁▂▁▁▃▁▄▆▁▁▁▁▃
wandb:      eval/avg_mil_loss ▁▂▂▁▂▁▁▁▁▂▂▂▂▁▁▁█▁▂▁▁▁▁▁▁▂▂▃▁▁▁▁▁▁▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▃▁▁▃▁▂▃▁▆▁▃▁▁▃▁▄▃▁▄▁▁█▁▁▁▁▃▁▁▁▁▄▆▁▃▁▁▁▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂█▄▂▅█▆▅▂▇▁▃▁▂▃▄▅▂▅▃▄▄▁▂▆▆▁▄▆▅▂▂▄▅▄▆▂▄▅
wandb:      train/ensemble_f1 ▁█▄▄▆▅▄█▆▂▂▇▁▆▃▃▃▄▄▅▂▅▃▄▃▁▆▂▆▄▃▂▃▂▂▂▇▅▃▃
wandb:         train/mil_loss ▂█▇▂▁▃▂▂▁▂▃▂▂█▂▃▂▁▇▃▂▂▁▂▂▂▂▁▁▂▂▂▁▂▁▂▂▂▂▂
wandb:      train/policy_loss ▁▁▁▅▁█▅█▁█▁▅▁▅▁▁▅▅█▅▅▅▁▅▁▁▅▁█▁██▅▁▅▁▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆▃▃▃██▆█▃▃▆▃▆▃█▃▆▃▆▆▆█▃▁▃▃▃█▃█▃▆▆▆▆▃▃▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77858
wandb: best/eval_avg_mil_loss 0.73623
wandb:  best/eval_ensemble_f1 0.77858
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.89245
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.85623
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.50035
wandb:      train/ensemble_f1 0.50035
wandb:         train/mil_loss 0.90187
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qbw7kfet
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_205858-qbw7kfet/logs
wandb: Agent Starting Run: bqeg2inx with config:
wandb: 	actor_learning_rate: 3.9755331597842915e-06
wandb: 	attention_dropout_p: 0.07571086579951797
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 89
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.46618870359201126
wandb: 	temperature: 5.735475889772619
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210000-bqeg2inx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqeg2inx
wandb: uploading history steps 76-90, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇▇█
wandb: best/eval_avg_mil_loss █▅▂▁▅▄
wandb:  best/eval_ensemble_f1 ▁▄▆▇▇█
wandb:            eval/avg_f1 ▂▂▅▇▁▃▃▂▂▄▃▆▂▅▇▂▂▃▁▁▃▃▆▃▃▂▂▃▂▃▁▁▆▂█▆▁▆▂▃
wandb:      eval/avg_mil_loss ▁▁▁▂█▂▁▁▃▁▁▁▁▁▂▃▁▁▁█▁█▁▁▄▁▁▁▁▁▁▁█▂▂█▂▂▁▁
wandb:       eval/ensemble_f1 ▂▇▃▃▁▃▃▆▂▃▅▇▃▁▇▂▃▂▂▃▁█▂▃█▁▃▆▃▄▂▂▂▃▆▆█▁▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▃▅▇▇▃▃▇█▆▅▄▅▇▄▅▅▇█▅▅▁▃▃▄▃▆▅▅▃▇▅▇▅▄▅▁▇▃
wandb:      train/ensemble_f1 ▆▄█▅▆▇▄▆▅▄▄▅▄▄▂▆▂▅▄▅▁█▃▄▃▅▃▇▄▅▅▇▆▆▄▁▅▇▆▅
wandb:         train/mil_loss █▄▂▂▂▃▂▃▃▄▆▁▁▂▃▆▄▂▁▄▄▂▃▁▂▁▃▄▅▃▃▄▁▁▃▃▁▁▆▁
wandb:      train/policy_loss ▄▅▅▄▅▃▅▅▄▅▅▆▅▆▅▅▇▅▆▄▆▅▅▄▁▅▇█▆▄▅▅▅▄▄▅▄▇▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅▅▅▄▅▅▅▅▅█▄▆▅▅▇▆▄▆▅▄▁▄▄▅▅▄█▆▅▅▅▁▅▄▅▄▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76887
wandb: best/eval_avg_mil_loss 0.70629
wandb:  best/eval_ensemble_f1 0.76887
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.88537
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.53834
wandb:      test/avg_mil_loss 1.39937
wandb:       test/ensemble_f1 0.53834
wandb:           train/avg_f1 0.54761
wandb:      train/ensemble_f1 0.54761
wandb:         train/mil_loss 1.48551
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bqeg2inx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210000-bqeg2inx/logs
wandb: Agent Starting Run: k17dptu8 with config:
wandb: 	actor_learning_rate: 0.0009562637575488292
wandb: 	attention_dropout_p: 0.16597344321679813
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 53
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4767493212255799
wandb: 	temperature: 2.879839042257737
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210117-k17dptu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k17dptu8
wandb: uploading history steps 41-54, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄██
wandb: best/eval_avg_mil_loss █▆▂▁
wandb:  best/eval_ensemble_f1 ▁▄██
wandb:            eval/avg_f1 ▁▁▄▁▁▁▃▁█▁▁▂▄▁▁▁▄▃▁▁▁▁▁▃▁▁▁▂▁▂▁▁▂▁▁▂▁▄██
wandb:      eval/avg_mil_loss ▃▆▂▃▃▃▂▃▁▃▂▃▃▃▃▃▃▂▂▃▃▃▂█▃▃▃▃▃▃▁▃▃▅▃▃▂▁▃▁
wandb:       eval/ensemble_f1 ▁▁▄▁▁▁▃▁█▁▁▂▄▁▁▆▁▄▃▁▁▁▁▁▁▂▁▂▁▁▁▂▁▁▃▁▄█▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▂▅▄▂▅▅▂▃▆▁▄▆▃▅▂▄▅▄█▆▂▆▂▃▆▆▅▂▃▄▆▂▂▄▅▅▆
wandb:      train/ensemble_f1 ▅▄▂▅▃▂▅▅▂▂▁▄▆▅▃▂▄▅▅▂█▆▂▆▄▃▆▆▅▅▂▃▄▆▂▂▄▅▅▆
wandb:         train/mil_loss ▅▆▄▄█▂▅▂▂▃▁▁▂▂▆▄▁▃▂▁▂▅▄▇▂▅▇▁▄▂▂▃▅▁▇▂▃▂▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78829
wandb: best/eval_avg_mil_loss 0.55784
wandb:  best/eval_ensemble_f1 0.78829
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.64741
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.85547
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.58555
wandb:      train/ensemble_f1 0.58555
wandb:         train/mil_loss 1.16824
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k17dptu8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210117-k17dptu8/logs
wandb: Agent Starting Run: sr2a46y5 with config:
wandb: 	actor_learning_rate: 0.0003127896511448599
wandb: 	attention_dropout_p: 0.16407492211853408
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 67
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4189861503419796
wandb: 	temperature: 3.1482488574966805
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210205-sr2a46y5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sr2a46y5
wandb: uploading history steps 61-68, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇██
wandb: best/eval_avg_mil_loss ▅▅█▁▂▄
wandb:  best/eval_ensemble_f1 ▁▄▅▇██
wandb:            eval/avg_f1 ▃▁▅▃▅▁▂▁▅▁▁▄▄▂▄▅▇▅▂▁▄▁▅▁▂▁▃▄▂▁▁█▂▅▄▄█▂▃█
wandb:      eval/avg_mil_loss ▂▆▃▁▃▁▆▂▆▁▁█▂▁▁▆▁▁▁▂▆▂▅▂▆▂▅▁▁█▆▂▂▁▁▂▂▂▂▁
wandb:       eval/ensemble_f1 ▃▁▁▁▅▂▁▇▁▃▂▄▁█▇▂▁▁▄▂▁▅▂▂▂▁▂▁▁▂▁█▂▁▅▄▁▁▂█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▄█▆▅▆▁▇▆▇▄▂▅█▆▇▆▁▆▃▇▃▅█▆▅▇▆▇▇█▆▅▅▅▅▆▅
wandb:      train/ensemble_f1 ▆▅▇▆▄▆▅▂▇▁▄▂▅▅▇▇▃▆▂▅█▆▅▅▆▆▅▆▇▆▆█▅█▅▅▅▆▅▅
wandb:         train/mil_loss ▄▁▃▅█▃▂▃▁▂▄▅▅▆▄▂▄▁▂▆▁▄▅▁▄▁▂▂▅▂▃▂▅▁▄▂▂▅▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64194
wandb: best/eval_avg_mil_loss 0.8623
wandb:  best/eval_ensemble_f1 0.64194
wandb:            eval/avg_f1 0.64194
wandb:      eval/avg_mil_loss 0.86204
wandb:       eval/ensemble_f1 0.64194
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79262
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.50815
wandb:      train/ensemble_f1 0.50815
wandb:         train/mil_loss 0.76496
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sr2a46y5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210205-sr2a46y5/logs
wandb: Agent Starting Run: bvf648wh with config:
wandb: 	actor_learning_rate: 1.5141812492839425e-06
wandb: 	attention_dropout_p: 0.01467841670406339
wandb: 	attention_size: 32
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 64
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5321941669937414
wandb: 	temperature: 3.265075143846637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210301-bvf648wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvf648wh
wandb: uploading history steps 57-65, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅██
wandb: best/eval_avg_mil_loss ▂█▁▁
wandb:  best/eval_ensemble_f1 ▁▅██
wandb:            eval/avg_f1 ▄▆▆█▇▇▇▄▆▁▂▆▃▆▃▆▇█▄▃▃█▇▇▆▇▆█▇▅▇▅▁▇▇▅▇▅▇▅
wandb:      eval/avg_mil_loss ▁▁▂▅▂▂▄▂█▂▃▂▄▂▄▄▂▇▁▁▂▁▂▃▁▃▃▂▂▄▂▂▂▄▂▁▂▁▂▂
wandb:       eval/ensemble_f1 ▄▆▆█▇▇▇▄▆▁▂▃▆▃▃▂▆▇▄█▃▇▇▆▆▆▇▆█▄▇▅▁▇▇▇▇▇▃▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▄▂▃▃▄▂▆▁▂▆▅▅▅▄▆▂▅▁▃▃▄▃▃▅▂▆▃▂▅▅▃▄█▅▄▅▃
wandb:      train/ensemble_f1 ▆▅▄▂▅▄▅▂▆▄▇▇▅▅▁▄▆▂▆▆▇▂▃▅▄▆▄▄▆▃▄▅▅▅█▅▄▅▃▃
wandb:         train/mil_loss ▁█▇▁▄▅▄▄▂▂▃▂▃▃▁▂▃▂▆▅▆▅▆▂▄▃▄▂▃▄▃▇▂▃▅▃▂▄▂▄
wandb:      train/policy_loss ▄▄▃▄▄▆▃▆▃▄▃▆▄▁▃▆▄▆▁▄▄▄▆▆▆▆▄▃▄▄▆▆▆▆▆▃█▆█▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▁▆▃▆█▃▄▄▆▆▄▃▆▆▄▁▃▄▄▆▆▄▄▃▄▄▃▆█▆▃█▆█▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.60882
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.87563
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.72997
wandb:      test/avg_mil_loss 0.93707
wandb:       test/ensemble_f1 0.72997
wandb:           train/avg_f1 0.66907
wandb:      train/ensemble_f1 0.66907
wandb:         train/mil_loss 0.97165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvf648wh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210301-bvf648wh/logs
wandb: Agent Starting Run: naj5zv5n with config:
wandb: 	actor_learning_rate: 0.0003947690699626759
wandb: 	attention_dropout_p: 0.2773136071721394
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 52
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6107235644158827
wandb: 	temperature: 1.937571626222554
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210358-naj5zv5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/naj5zv5n
wandb: uploading history steps 41-53, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▅▇█
wandb: best/eval_avg_mil_loss ██▇█▆▅▄▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▅▇█
wandb:            eval/avg_f1 ▂▃▃▃▃▃▄▃▃▄▇▁▄▇▇▃▃▄▄▂▃▃▁▂▁▃▃█▄▃▃▁▄▃▃▃▁▁▂▃
wandb:      eval/avg_mil_loss ▇▆▆▆▇▅▆▆▇▇▆▇▇▃▇█▃▃█▇▆▆▆▆▆▇▇▇▁▆▆▅█▆▆▆▆▇▆▇
wandb:       eval/ensemble_f1 ▂▂▃▃▃▅▃▄▃▁▄▁▁▇▁▄▇▇▃▃▄▂▃▃▃▂▁▃█▄▃▃▁▄▃▃▁▁▂▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃▃▂▂▂▅▄▂▃▂▁▂▂▂▂▂▅▁▁▂▂▂▄▃▁▄█▄▅▅▁▂▃▃▂▄▂▄
wandb:      train/ensemble_f1 ▄▂▂▃▂▁▂▅▄▁▂▁▁▂▂▁▂▅▁▂▂▂▄▁▃▄█▄▁▅▁▄▂▃▄▁▅▄▂▄
wandb:         train/mil_loss ▅▅▅▅▃▃▄▅▇▅▄▅▆▄▄▃▅▅▄▄▃▁▄▃▄▄▄▃▃▅▂▄▄▅▅▂█▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.49008
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.99147
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.85214
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.58709
wandb:      train/ensemble_f1 0.58709
wandb:         train/mil_loss 0.77297
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/naj5zv5n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210358-naj5zv5n/logs
wandb: Agent Starting Run: k6an0uxo with config:
wandb: 	actor_learning_rate: 0.0006249760868992872
wandb: 	attention_dropout_p: 0.045317194839325114
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 66
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4632602528348349
wandb: 	temperature: 3.608198585052032
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210445-k6an0uxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k6an0uxo
wandb: uploading history steps 61-67, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆█
wandb: best/eval_avg_mil_loss ▂▃▁█
wandb:  best/eval_ensemble_f1 ▁▆▆█
wandb:            eval/avg_f1 ▇▁▁▁▂▂▂▃▁█▄▁▁▂▂▆▁▂▁▁▂▂▇▃▂▁▇▁▂█▁▁▂▂▃▁▂▁▄▁
wandb:      eval/avg_mil_loss ▁▂▁▁▂▁▁▁▁▁▁▆█▇▃▇▃▂▁▁▆▁▃▅▅▁▂▁▂▁▂▁▁▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▆▇▁▂▁▃▂█▁▄▁▂▂▁▂▆▃▄▁▂▁▁▂▂▇▇▂██▁█▂▁▂▁▂▁▄▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▁▃▃▃▆▆▃▄▇▃▄▅█▂█▆▅▅▅▂▇▃▅▃▃▂▇▆▅▆▂▅▃▄▁▅▅
wandb:      train/ensemble_f1 ▅▃▄▃▆▅▄▅▇█▃▃▄▅▂▂▂▆▆▅▅▆▂▂▄▇▇▇▅▆▆▃▅▃▅▁▄▆▄▅
wandb:         train/mil_loss ▅▅▃▃▄▇▂▄█▃▃▄▂▃▁▄▄▁▃▅▄▂▅▂▅▂▃▁▅▃▂▄▄▂▂▁▄▂▇▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66372
wandb: best/eval_avg_mil_loss 1.33069
wandb:  best/eval_ensemble_f1 0.66372
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.02214
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.67532
wandb:      test/avg_mil_loss 1.13924
wandb:       test/ensemble_f1 0.67532
wandb:           train/avg_f1 0.51469
wandb:      train/ensemble_f1 0.51469
wandb:         train/mil_loss 1.15792
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run valiant-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k6an0uxo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210445-k6an0uxo/logs
wandb: Agent Starting Run: grgc184k with config:
wandb: 	actor_learning_rate: 1.4844767200345034e-06
wandb: 	attention_dropout_p: 0.07296654559926136
wandb: 	attention_size: 64
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 81
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6703545249732218
wandb: 	temperature: 4.214798691591798
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210542-grgc184k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/grgc184k
wandb: uploading history steps 80-82, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▇▇██
wandb: best/eval_avg_mil_loss █▇▂▁▄▁
wandb:  best/eval_ensemble_f1 ▁▃▇▇██
wandb:            eval/avg_f1 ▅▆█▂▂▅▂▁▁█▄▂▁▁▁▁▁▃▂▆▆▅▁█▇▃▁▁▁▃▇▃▅▅▁▆▅█▁▂
wandb:      eval/avg_mil_loss █▂▃▄▃▅▁▃▃▃▃▁▂▆▅▄▅█▂▄▂▂▂▂▃▃█▃▂▂▃▃▃▂█▃█▃▆▃
wandb:       eval/ensemble_f1 ▆█▂▁▃▃▅▂▁▁▅▆▃▁▁▁▁▃▂▁▆▃█▅▁▅▁▇▆█▁▁▃▅▁▆▅▁▁▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▆▅▃▃▂▃▃▄▂▃▃▇▆▃▇▃▃▁▃▂▅▅▅▅▅█▅▅▃▅▃▃▃▄▆▅▅
wandb:      train/ensemble_f1 ▃▆▄▄▄▄▅▃▄▁▄▂▆▅▇▄▄▄▂▄▃▄▅▃▅▇▅▇▆█▆▇▅▆▆▃▄▅▅▅
wandb:         train/mil_loss ▃▂▂▆▂▃▄▃▃▁▆▂▄▅▆▁▃▄▁▂▄▂▂█▄▂▂▅▄▄▂▃▃▃▂▅▃▂▃▂
wandb:      train/policy_loss ▅▄▃▄▂▂▂▃▃▃▃▃▃▁▁▆▃▅▂▄▃▁▃▁▂▃▂▁▄▁▆▂▂▃▂▁▆▂▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▅▆▅▃▅▁▅▅▅▅▆▅▃▆▃▃▃█▅▅▆▃▅▁▅▃▅▃▆▆▁▃█▅▅▁▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83766
wandb: best/eval_avg_mil_loss 0.42795
wandb:  best/eval_ensemble_f1 0.83766
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.01477
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.81626
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.59388
wandb:      train/ensemble_f1 0.59388
wandb:         train/mil_loss 0.87321
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/grgc184k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210542-grgc184k/logs
wandb: Agent Starting Run: imnmailt with config:
wandb: 	actor_learning_rate: 0.00036011294824724575
wandb: 	attention_dropout_p: 0.1941218882747946
wandb: 	attention_size: 128
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 70
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4869930436362019
wandb: 	temperature: 6.595021190373598
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210649-imnmailt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/imnmailt
wandb: uploading history steps 61-71, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▅███
wandb: best/eval_avg_mil_loss █▇▇▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▅███
wandb:            eval/avg_f1 ▁▂█▃▂▇██▄▂▄██▂▆█▃█▇▄▄▇▁▁▂▄▃▂▂▁▃▇▂▄▁▆▄▄▂▇
wandb:      eval/avg_mil_loss ▃▁▄█▂▂▁▂▂▃▁▂▂▁▂▂▂▁▂▁▂█▂▂▂▂▂█▄▁▁▂▂▂▂▁▂▄▂▂
wandb:       eval/ensemble_f1 ▁▁▂▂▁▆██▄▃█▁█▂▆██▂▇▄▇▁▁▁▂▂▂▃▇▂▇▁▁▄▄▂▇▄▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▄▆▆▅▇▇▅▃▅▄▃▇▆▇▄▇▅▂▅▆▆▂▂▅▄▅▅▄▇▅▁▆▃██▆▅▆
wandb:      train/ensemble_f1 ▄▅▆▃▆▇▇▃▅▃▄▄▆▃▃▄▇▄▂▆▆▂▁▄▄▆▃▆▄▇▅▂▄▁▆▇██▅▆
wandb:         train/mil_loss ▄▂▂▄▂▁▃▆▅▂▁▃▃▅▂▁▂▂▃▂▄▁▄▃▂▃▃▂▂▂▁▃▂▁█▃▃▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.70034
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.14181
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.79748
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.67839
wandb:      train/ensemble_f1 0.67839
wandb:         train/mil_loss 0.811
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run trim-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/imnmailt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210649-imnmailt/logs
wandb: Agent Starting Run: 2vvtob1k with config:
wandb: 	actor_learning_rate: 0.0004437515867470151
wandb: 	attention_dropout_p: 0.06465806561887594
wandb: 	attention_size: 64
wandb: 	batch_size: 256
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 97
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.339353191529395
wandb: 	temperature: 0.6632508585155306
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210747-2vvtob1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vvtob1k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▄▇█
wandb: best/eval_avg_mil_loss ▂▃█▁▂▂
wandb:  best/eval_ensemble_f1 ▁▁▃▄▇█
wandb:            eval/avg_f1 ▃▅▁▁▁▁▄▁▂▁▁▁▁▁▅▃▁▅▁▆▄▁▃▂▆▁█▁▁▇▁▇▁▅▁▁▁▂▁▁
wandb:      eval/avg_mil_loss ▁▃▁▂▂▁▂▁▅▂▄▂▁▁▁▁▃▅▃▁▁▃▁▅▁▁▂▂▂▂▁▆▂▅▂▁▂▂▁█
wandb:       eval/ensemble_f1 ▂▄▁▄▂▁▂▁▁▁▁▁▁▁▁▃▃▁▁▅▂▁▄▂▁▁▁█▆▂▇▇▁▁▁▂▂▆▁▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▅█▂▃▄▄▅▅▆▄▄▃▃▂▂▅▅▄▄▆▅▁▃▇▃▂▃▃▄▃▅▅█▆▄▂▅
wandb:      train/ensemble_f1 ▆▃▄█▂▅▇▆▅▄▅▆▆▆▄█▂▂▄▅▄▄▅▁▇█▃▄▃▄▄▅▄▅▂▆▄▆▇▅
wandb:         train/mil_loss ▃▅▁▁▂▂▅▁▃▁▄▄▇▃▄▂▅▁▂▇▅▄▁▆▅▅▄▂▂▂▃▂▅▅▄▂▅█▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.76408
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.35841
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.41414
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.56728
wandb:      train/ensemble_f1 0.56728
wandb:         train/mil_loss 0.90794
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vvtob1k
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210747-2vvtob1k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nres8z7s with config:
wandb: 	actor_learning_rate: 2.230283736472334e-06
wandb: 	attention_dropout_p: 0.04892703929501169
wandb: 	attention_size: 64
wandb: 	batch_size: 64
wandb: 	critic_learning_rate: 0
wandb: 	dropout_p: 0.5
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 78
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30325494409846054
wandb: 	temperature: 3.836689286556507
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_210933-nres8z7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/0scqfqaw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nres8z7s
wandb: uploading history steps 76-79, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇█
wandb: best/eval_avg_mil_loss █▃▁▂
wandb:  best/eval_ensemble_f1 ▁▄▇█
wandb:            eval/avg_f1 ▅▄▇▅█▇▁▁▄▄▇▂▂█▁▆▁█▁▃▄▃▂▄▅▅▇▅▁▇▂▂▃▂▄▇▆▄▇▇
wandb:      eval/avg_mil_loss ▂▁▂▂▁▁▂▃▂▃▁▇▁▂▇█▂▃▃▁▆▃▂▂▄▁▂▃▄▁▁▁▄▃▁▂▁▂▂▁
wandb:       eval/ensemble_f1 ▆▄▂▄▁▄▁▁▄▂▁▅▂▆▁█▁▃▄▃▂▃▆▅▅▇▇▇▄▁▇▃▂▇▂▄▇▄▁█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▅▁▅▂▆▅▄▄▄█▃▃▇▄▅▅▄▄▅▄▂▆▅▅▃▅▅▃▄▃▅▄▁▆▁▄
wandb:      train/ensemble_f1 ▅▄▅▂▅▃▂▃▆▅▄▄▄▆█▅▃▄▅▄▃▄▃▃▆▁▆▅▄▃▄▆▃▅▁▆▁▄▆▄
wandb:         train/mil_loss ▃▇▂▇▃▃▂▂▇▇▅▃▅▆▅▁▄▅▄▄▅▄▃▇▄▅▄▃▅▄▃▂▅█▃▅▄▅▅▂
wandb:      train/policy_loss ▅▆▃▃▆▄▆▃▅▅▄▆▄▆▄█▆▄▆▄▃▅▆▆▄▃▆▄▄▆▅▄▁▄█▄▆▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▆▃▃▆▄▄▆▃▄▅▃▆█▄▃▆▄▃▄▅▄▆▄▆▆▆▄▄▅▄▁█▆▄█▆▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79928
wandb: best/eval_avg_mil_loss 0.61307
wandb:  best/eval_ensemble_f1 0.79928
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.62818
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.68995
wandb:      test/avg_mil_loss 0.74756
wandb:       test/ensemble_f1 0.68995
wandb:           train/avg_f1 0.59579
wandb:      train/ensemble_f1 0.59579
wandb:         train/mil_loss 0.86609
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nres8z7s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_210933-nres8z7s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
