wandb: Agent Starting Run: swgtrt13 with config:
wandb: 	actor_learning_rate: 8.695393950296791e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6690598882460463
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1416542285203748
wandb: Agent Starting Run: ia9cdk63 with config:
wandb: 	actor_learning_rate: 0.004454370658335216
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22713890985125007
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47279191307869417
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Agent Starting Run: 3bqmpzvm with config:
wandb: 	actor_learning_rate: 1.7460566128575658e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.25307058411629546
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9143966011145784
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-ia9cdk63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ia9cdk63
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-swgtrt13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swgtrt13
wandb: Agent Starting Run: ysqhdbv2 with config:
wandb: 	actor_learning_rate: 0.0073365656244061455
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5075804338456829
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28955477772517424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182044-3bqmpzvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3bqmpzvm
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182045-ysqhdbv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ysqhdbv2
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▆▇▄▇▆▆▄▃▄▇▄▅▆▅▂▅█▄▃▄▄▃▂▅▅▄▄▇▃▅▆▃▂▂▁▃▂
wandb:      train/ensemble_f1 ▅▅▃▅▄▄▅▄▄▃▆▂▂▃▇▃▄▅▄▁█▃▄▅▄▂▄▃▁▄▂▃▆▃▅▃▇▄▂▃
wandb:         train/mil_loss ▁▅▄▆▆▄▅▇█▂▆▆▇▆▃█▃▄▆▅▆▅▆▄▅▃▆▆▄▃▆▅▃▅▅▅▆▇▆▅
wandb:      train/policy_loss ▄▄▂▂▅▅▆▃▂▁▃▆▇▄▃▄▂▁▄▄▃▅▃▃▄▅▃▆▂▃▂▃▆▇▃▃▆▃▂█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.04093
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9665
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.16478
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 0.79542
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ia9cdk63
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-ia9cdk63/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▆▂▃▆▆▅▃▅▄▆▄▄▅▄▁▅▄▇▅▆▄▂▅▅▃▅▃▅▄▅▆▆▃█▂▃▅
wandb:      train/ensemble_f1 ▆▃▅▅▆▃▄▅▃▄▇██▄▄▃█▅▁▆█▇▅▆▇▇▂▄▅▆▆▅▅▆▇▄▇▃▆▅
wandb:         train/mil_loss ▄▅▄▇█▄▅▄▂▃▅▆▄▆▄▄▃▇▇▆▃▆▅▂▄▆▄▃▄▄▁▆▅▅▂▃▆▇▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.11268
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04382
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.91173
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40902
wandb:      train/ensemble_f1 0.40902
wandb:         train/mil_loss 0.73367
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/swgtrt13
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-swgtrt13/logs
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▄▂▆▂▂█▅▆█▆▄▄▆▄▂▇▆▂▃▂▄▄▅▆▆▇▂▆▁▃█▄▅▆▇▆█
wandb:      train/ensemble_f1 ▆▄▆▅▃▆▂▃▄▁▆▅▅▅▃█▄▄▆▅▅▃▅▅▅▆▄▄▄▅▃▄▅▅▃▇▅▅▃▄
wandb:         train/mil_loss ▄█▅▅▄▇▃▆▆▄▄▆▅▇▅▃▅▄▅▃▅▄▅▆▄▃▅▇▄▆▁▁▂▄▄▆▄▅▃▄
wandb:      train/policy_loss ▄▅▄▅▅▄▆▇█▅▄▄▅▄▆█▁▆▆▆▄▃▄▅▇▃▄▅▂▇▂█▃▇▅▇▅▆▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▃▅█▃▃▃▄▄▃▅▇▅▄▄▃▆▅▇▃▅▇▄▄▄▄▃▂▃▂▃▇▇▄▆▃▄▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.90775
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.84236
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02436
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34319
wandb:      train/ensemble_f1 0.34319
wandb:         train/mil_loss 0.76448
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3bqmpzvm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182044-3bqmpzvm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: sd8g6u7i with config:
wandb: 	actor_learning_rate: 3.254123068418132e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5782989663013146
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7601732388304894
wandb: Agent Starting Run: kok2vz3f with config:
wandb: 	actor_learning_rate: 0.0008632179126262788
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6035605631730279
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4377063124504791
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182249-sd8g6u7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sd8g6u7i
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182249-kok2vz3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kok2vz3f
wandb: Job received.
wandb: Agent Starting Run: mn7sliko with config:
wandb: 	actor_learning_rate: 6.183368736719053e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7718019313441037
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38903641624256646
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182254-mn7sliko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mn7sliko
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▄▃▃▃▃▂▂▂▂▂▂▂▃▃▂▂▁▁▁▁▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▂▂▂▁▄▄▄▁▃▃█▆▆▅▃▃▅▅▅▅▂▅▅▄▅▂▂▄▆▇▃▅▅▃▃▅
wandb:      train/ensemble_f1 ▃▃▃▂▄▁▃▅▄▅▄█▅▅█▂▄▃▄▅▇▄▄▅▄▇▄▄▅▂▃▄▁▅▂▃▄▂▅▇
wandb:         train/mil_loss ▆▅▇▅▃▄▆▆▆▄▁▃▄▇▃▅▂▆▄▄▃▂▃▃▂▃▅▅▂▃▆█▄▄▄▄█▅▃▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▇▆▅▆▆▅█▆▆▄▅▅▄▄▄▄▅▄▅▅▆▃▄▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▇██▅▅▄▅▄▄▅▄▄▅▅▃▆▄▆▇▁▃▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83897
wandb: best/eval_avg_mil_loss 0.53007
wandb:  best/eval_ensemble_f1 0.83897
wandb:            eval/avg_f1 0.82916
wandb:      eval/avg_mil_loss 0.51698
wandb:       eval/ensemble_f1 0.82916
wandb:            test/avg_f1 0.88493
wandb:      test/avg_mil_loss 0.90688
wandb:       test/ensemble_f1 0.88493
wandb:           train/avg_f1 0.84251
wandb:      train/ensemble_f1 0.84251
wandb:         train/mil_loss 0.57162
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ysqhdbv2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182045-ysqhdbv2/logs
wandb: Agent Starting Run: bewxdmko with config:
wandb: 	actor_learning_rate: 1.5333653312039863e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7543433476940039
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.477521605597694
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182342-bewxdmko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bewxdmko
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████████▇▇▇▇▇▇▇▇▇▇▇▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▆▅▄▄▄▅▄▃▄▄▅▃▄▄▅▃▁▄▄▄▄▄▅▅▇▅▅▅▇▄▄▅▅▆▆█▅▅
wandb:      train/ensemble_f1 ▅▄▆▆▅▄▆▃▄▅▄▆▅▄▅▁▅▄▅▇▄▅▅▆▄▅▄▄▆▄▄█▄▅▅▅▄▆▆▂
wandb:         train/mil_loss ▅█▅▃▅▃▄█▅▅▄▄▅▅▃▅▇▆▅▃▃▄▃▃▂▅▃▄▂▆▃▃▃▅▅▅▁▄▄▄
wandb:      train/policy_loss ▄▁▆▃▇▆▇▃▄▄▅▆▅▃▆▅▆▃▂▃▆▄▇▅▄▃▅▃▅█▃▃▅▃▆▆▄▆▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▅▃▁▅▇▇▅▇▄▅▄▄▆▅▄▆▆▅▆▅▅▅▆▇▅▅▄▄▇▃▇▇▆▇▃▄▅▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.79928
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.4358
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.33215
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33665
wandb:      train/ensemble_f1 0.33665
wandb:         train/mil_loss 0.96218
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sd8g6u7i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182249-sd8g6u7i/logs
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▃▄▆▄▃▃▆▄▅▄▁▅▄▂▃▁▆▄▄▄▂▅▄▄█▅▆▅▆▅▂▃▇▅▅▁▇
wandb:      train/ensemble_f1 ▇▅▅▅▄▇▂▅▅▅▅▆▃▂▅▇▆▄▃▅▅▅▅▅▃▆▇▁█▆▅▅▃▇▅▇▆▆▆▇
wandb:         train/mil_loss █▄▄▆▅▄▃▅▄▇▅▁▆▅▃▂▅▃▄▆▅▆▅▂▃▄▁▂▂█▅▆▃▅▃▇▁▂▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.09225
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.0168
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.90027
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.44202
wandb:      train/ensemble_f1 0.44202
wandb:         train/mil_loss 0.89944
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kok2vz3f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182249-kok2vz3f/logs
wandb: Agent Starting Run: ek0qowtw with config:
wandb: 	actor_learning_rate: 0.004956434791784708
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7749556762970503
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31635022365329657
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182443-ek0qowtw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ek0qowtw
wandb: Agent Starting Run: mtpdqoz2 with config:
wandb: 	actor_learning_rate: 8.623644823947912e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5145168639301105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.451828000848392
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182448-mtpdqoz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mtpdqoz2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▃▇▅▆█▆▄▆▅▇▆█▄▇▅▂▇▄▃▇▄▆▅▄▇█▆▄▅▇▁▅▆▆▇▇█
wandb:      train/ensemble_f1 ▅▇▄▂▁▄▄▅▅▃▃▄▆▅▄▄▄▆▅▆▇▄▆▃▇▅▄▄▇▃█▆▆▄█▅▅▆▆▇
wandb:         train/mil_loss ▅▃█▂▆▄▁▄▅▆▁▆▆▄▃▄▃▄▄▆▇▆▄▅▄▆▄▃▃█▆▄▆▄▃▄▅▄▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.63683
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.54062
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.29491
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.40457
wandb:      train/ensemble_f1 0.40457
wandb:         train/mil_loss 0.73542
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bewxdmko
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182342-bewxdmko/logs
wandb: Agent Starting Run: nxhllgp5 with config:
wandb: 	actor_learning_rate: 0.0017004218738082492
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5999550326832918
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.049218387520496454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182535-nxhllgp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nxhllgp5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▆▂▃▄▃▆▆▄▆▆▄▅▆▆▅▅▄▃▄▁▅▅█▇▆▇▅█▃▄▄▁█▆▃▇▁
wandb:      train/ensemble_f1 ▆▆█▆▃▃▇▅▇▃▅▄▇▂▆▅▃▆▄▅▅▆▅▃▂▅▅▄▃▅▆▇▆▇▆▁█▃█▅
wandb:         train/mil_loss ▅▃▄▂▂█▃▄▃▆▇▂▅▃▂▁▆▃▅▃▁▅▄▂▅▃▄▄▅▃▂▂▃▄▄▃▃▄▃▂
wandb:      train/policy_loss ▄▃▅▆▄▆▂▅▇█▇▄▂▁▄▂▄▅▅▃▄▄▄▅▄▅▄▆▅▄▄▄▄▅▅▄▄▅▄▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▅▂▇▆▃▆▇▆▁█▆█▃▇▅▁▆▆▅▇▅▂▆▃▃▆▆▇▄▅▃▆▆▅▃▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.76432
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.55243
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.65045
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33665
wandb:      train/ensemble_f1 0.33665
wandb:         train/mil_loss 1.04654
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ek0qowtw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182443-ek0qowtw/logs
wandb: Agent Starting Run: 87jqstho with config:
wandb: 	actor_learning_rate: 1.0835326669131207e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06641409784537056
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.954132203056568
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182637-87jqstho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87jqstho
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂█▄▆▅▅▃▄▅▅▅▄▇▃▅▇▇▇▃▃▂▃▇▁▄▂▅▂▂▅▅▃█▂▃▂▆▃▄▃
wandb:      train/ensemble_f1 ▄▅▅▇▄▆▆▅▄▇▆█▇█▄█▆▅▅▂▁▆▃▅▇▄▆▆▃▇▆▇▇▅▅▄▃▇▅▄
wandb:         train/mil_loss ▁▇▄▆▇▅▅▄▅▄▆▇█▄▄▅▄▄▅▆▃▆▄▅▂▆▁▅▄▄▅▃▃▆▁▅▄▃▄▄
wandb:      train/policy_loss █▂▅▂▅▅▇▂▃▅▅▅▃▆▇▅▃▄▄▂▁▄▃▅▄▅▆▂▄▄▄▄▃▂▂▅▇▄▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▅▄▆▄▅▄▇▃▄▄▅▆▇▆▃▆▄▆▅▁▄▅▄▆▆▂▄▄▄▅▄▃▄▆▄▅▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.83966
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81134
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.94052
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 0.66779
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mtpdqoz2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182448-mtpdqoz2/logs
wandb: Agent Starting Run: 1io4a5py with config:
wandb: 	actor_learning_rate: 0.0006976201941293181
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3397188809377263
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7828309349593315
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182642-1io4a5py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1io4a5py
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▅▄▇▆▇█▄▅▆▆▇█▅▁▇▆▇▆▄▆▅▆▇▆▇▆▇▆▅▇▅▄▅▄▅▂▄▅
wandb:      train/ensemble_f1 ▅▃▄▅▄▄▅█▄▅▆▄▄▄▃▂▁▂▅▁▇▄▂▄▄▅▆▃▄▅▅▅▅▄▃▃▂▆▃▃
wandb:         train/mil_loss ▃▅▂▃▄▇▂▄▂▄▅▅▇▂▃▃█▃▅▇▄▁▄▆▇▆▆▆▆▃▃▅▅▄▇▁▄▃▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.48498
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.36568
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.15848
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.39396
wandb:      train/ensemble_f1 0.39396
wandb:         train/mil_loss 0.90324
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wise-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nxhllgp5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182535-nxhllgp5/logs
wandb: Agent Starting Run: lezyx1zj with config:
wandb: 	actor_learning_rate: 9.632858837935282e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8134662013251761
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9420811438277874
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182730-lezyx1zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lezyx1zj
wandb: uploading history steps 326-341, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▇█
wandb: best/eval_avg_mil_loss █▇▆▆▄▄▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▃▃▃▃▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▃▃▃▃▃▃▃▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇████▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▂▃▂▁▄▄▃▄▄▄▅▆▅▅▅▆▇▅▆▇█▅▇▄▅▇▆▆▆▅▅▇▆▇▇▆▇▇
wandb:      train/ensemble_f1 ▂▂▂▄▂▁▂▂▂▄▄▄▄▃▄▅▄▅▆▅▅▅▅▅▇▆▆▄▆▇▆▆▆▇▆▆▆▇█▅
wandb:         train/mil_loss ▆▆▆▄▆▆▆▆▄▄▇▇▆▃▄▄█▅▇▇▆▃▂▅▃▁▃▄▄▅▁▆█▇▁▄█▄▄▆
wandb:      train/policy_loss ▂▁▃▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.4397
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.79871
wandb:      eval/avg_mil_loss 0.43603
wandb:       eval/ensemble_f1 0.79871
wandb:            test/avg_f1 0.85288
wandb:      test/avg_mil_loss 0.3782
wandb:       test/ensemble_f1 0.85288
wandb:           train/avg_f1 0.86925
wandb:      train/ensemble_f1 0.86925
wandb:         train/mil_loss 0.53669
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mn7sliko
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182254-mn7sliko/logs
wandb: Agent Starting Run: pzwicbxm with config:
wandb: 	actor_learning_rate: 2.4675728070190105e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6897165176249314
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2447111184383367
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_182901-pzwicbxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pzwicbxm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▅▆▆▆█
wandb: best/eval_avg_mil_loss █▇▇▇▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▃▅▆▆▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▅▅▅▅▅▆▆▅▅▆▆▆▆█▆▅▅▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▅▅▅▅▅▅▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▅▅▅▅▅▅▅▅▅▆▆▆▆▆▅▅▆▅▅▅▆█▆▅▅▅▃▃▃▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▃▄▄▃▄▃▄▃▄▅▃▅▄▆▅▆▅▄▅▅▅▅▇▆▅▅▇▆▆▆▇▇█▇▇█▇
wandb:      train/ensemble_f1 ▃▂▁▁▂▃▃▃▄▂▂▃▃▄▅▆▄▅▆▅▅▅▃▅▆▇▆▄▇▄▆▆▅▅▇▆███▆
wandb:         train/mil_loss ▇▅▇▅█▄▆█▅▅▄▅▆▅▆▅▅▅▄▆▅▆▃▄▃▅▂▆▄▃▄▅▂▄▂▁▄▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72997
wandb: best/eval_avg_mil_loss 0.57258
wandb:  best/eval_ensemble_f1 0.72997
wandb:            eval/avg_f1 0.70974
wandb:      eval/avg_mil_loss 0.54162
wandb:       eval/ensemble_f1 0.70974
wandb:            test/avg_f1 0.59936
wandb:      test/avg_mil_loss 0.82581
wandb:       test/ensemble_f1 0.59936
wandb:           train/avg_f1 0.62622
wandb:      train/ensemble_f1 0.62622
wandb:         train/mil_loss 0.86131
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run good-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/87jqstho
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182637-87jqstho/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▆▇▆▅▅▅▅▇▆▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▅▅▅▃▅▄▂▆▅▇▄▅▁▇▃█▅▅▆█▆▃▆▂▂▂▆▅█▅▂▅▅▄▄▄▅▅
wandb:      train/ensemble_f1 ▄▁▃▆▄▇▄▅▅▄▆█▅▄█▃▇▄▃▃▆▅▄▇▃▆▂▂▃▂▅▇▄▂▅▃▄▂▇▅
wandb:         train/mil_loss ▅▂▃▄▄▅▅▃▅▇▃▄▄▃▄▅▄█▂▃▃▂▃▄▅▄▃▅▆▂▅▃▃▇▅▃▅▃▆▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61786
wandb: best/eval_avg_mil_loss 0.57654
wandb:  best/eval_ensemble_f1 0.61786
wandb:            eval/avg_f1 0.61786
wandb:      eval/avg_mil_loss 0.57108
wandb:       eval/ensemble_f1 0.61786
wandb:            test/avg_f1 0.60332
wandb:      test/avg_mil_loss 0.55987
wandb:       test/ensemble_f1 0.60332
wandb:           train/avg_f1 0.61107
wandb:      train/ensemble_f1 0.61107
wandb:         train/mil_loss 0.54591
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lezyx1zj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182730-lezyx1zj/logs
wandb: Agent Starting Run: w9p3e016 with config:
wandb: 	actor_learning_rate: 8.382526050483071e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8924737789464775
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5538396065072106
wandb: Agent Starting Run: 5knjenu3 with config:
wandb: 	actor_learning_rate: 1.1655114050660185e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.009527615347895924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3511789368560748
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183010-w9p3e016
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w9p3e016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183011-5knjenu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5knjenu3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▁▅▃▅▃▃▆▃▄▄▄▄▅▄▅▅▃▂▆▂▄▆▅▄▃▅▄▆▅▅▄▆▅▇██▇█
wandb:      train/ensemble_f1 ▁▃▁▅▃▃▃▆▃▁▄▆▅▅▅▃▃▄▃▃▅▄▆▃▅▅▇█▅▄▆▅██▆█▇▅▅▅
wandb:         train/mil_loss ▆▅█▅▃▅▅▆▄▄▆▄▃▃▄▂▅▃▆▅█▄▅▄▂▄▅▁▅▃▃▄▃▆▅▄▆▄▄▄
wandb:      train/policy_loss ▅▇▆▄▃▇▇▄▄▅▆▆▁▆▅▅▇▆▅▅▆▄▄▆▇▄▄█▅▄▇▂▂▅▄▂▂▄▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▇▆▅▇▄▄▆▇▆▆▃▁▆▆▇▇▆▃▅▂▄▆▇▅▂▃▂█▄▅▄▄▃▂▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 0.61532
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.55571
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.69948
wandb:      test/avg_mil_loss 0.45157
wandb:       test/ensemble_f1 0.69948
wandb:           train/avg_f1 0.72024
wandb:      train/ensemble_f1 0.72024
wandb:         train/mil_loss 0.54816
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pzwicbxm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182901-pzwicbxm/logs
wandb: uploading history steps 223-231, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▃▃▆▆▆▆▆▆▆█████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▄▃▂▆▄▃▄▅▂▃▁▁█▅▄▄▃▃▄▄▅▄▂▄▄▄▅▆▃▂▆▅▆▆▆█▄
wandb:      train/ensemble_f1 ▄▅▃▄▃▄▅▃▅▇▄▆▆▃▃▂▅▄▇▄▄▇▄▄▁▅▅▃▃▃▆▅▆▅▅▆▆▆▆█
wandb:         train/mil_loss ▅▄▆█▄▅▅▆▇▆▃▆▅▅▃▄▅▅▃▅▄▆▃▂▂▄▂▅▃▄▃▃▅▂▁▃▃▂▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.74582
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.6744
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.65569
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.49228
wandb:      train/ensemble_f1 0.49228
wandb:         train/mil_loss 0.74666
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run usual-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1io4a5py
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_182642-1io4a5py/logs
wandb: Agent Starting Run: d6r5a698 with config:
wandb: 	actor_learning_rate: 7.99297030251004e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9584597562615388
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3750255226724165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183054-d6r5a698
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6r5a698
wandb: Agent Starting Run: x1hv4grm with config:
wandb: 	actor_learning_rate: 0.00010566281744112064
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4089777985466976
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.747122972040259
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183055-x1hv4grm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x1hv4grm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▄▅▅█▅▅▁▆▅▄▇▅▄▅▅▆▅▅▆▄█▄▄▅▅▃▇▇▄▇▇▆▅▇▇▄▄▂
wandb:      train/ensemble_f1 ▆▄▆▆▄▂▄▅▃▄▆▄▄▃▄▃▃▃▂▅▄▅▆▅▃▃▄▂▃▃▂▅▁▃▃█▂▃▅▃
wandb:         train/mil_loss ▅▄▄▂▁▂▇▇▄▃▂▃▃▄▂█▇▄▇▇▄█▄▆▇▃▃▅▄▂▄▃▅▂▄▆▄█▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.67633
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.62511
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.32211
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39491
wandb:      train/ensemble_f1 0.39491
wandb:         train/mil_loss 0.58663
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w9p3e016
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183010-w9p3e016/logs
wandb: Agent Starting Run: uhzyv9q6 with config:
wandb: 	actor_learning_rate: 0.00648681563661514
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4793013857287187
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22750114370936816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183204-uhzyv9q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhzyv9q6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▃▁▂▁▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇███▇▇██
wandb:       eval/ensemble_f1 █▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▂▅▃▆▅▃▄▄▄▄▄▃▄▄▂▂▄▃▆▄▄▅▄▄▂▃▃▅▅▆▇▁▁▆▄▃▄▅▆
wandb:      train/ensemble_f1 ▆▂▂▅▂▃▇▄▄▄▄█▄▄▄▄▃▃▄▆▄▅▂▃▆▅▅▅▄▁▄▅▃▄▃▅▃▂▅▆
wandb:         train/mil_loss ▂▅▄▄▅▄▄▃▂▃▂▅▅▃▂▆▃▁▆▅▃▄▆▅▅▇▃▃▆▄█▄▅▃▁▃▅▅▅▃
wandb:      train/policy_loss ▆▁▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.37996
wandb: best/eval_avg_mil_loss 0.91461
wandb:  best/eval_ensemble_f1 0.37996
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.92489
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.38351
wandb:      test/avg_mil_loss 0.7984
wandb:       test/ensemble_f1 0.38351
wandb:           train/avg_f1 0.41599
wandb:      train/ensemble_f1 0.41599
wandb:         train/mil_loss 0.5318
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6r5a698
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183054-d6r5a698/logs
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▅▅▄▆▃▂▂▅▃▁▄▅▅▄▃▄▅▂▃▇▂▁▃▁▅▆▄▅██▆▃▃▃▅▇▄
wandb:      train/ensemble_f1 ▇▅▅▆▆▇▅▅▅▄▂▅▃▆▄▅▆▅▄▄▆▄▆▄▆▃▆▁▆▇█▃▅▆▆▇▅▆▄▅
wandb:         train/mil_loss ▆▆▂█▄▄▄▂▄▃▃▁▂▃▂▅▅▂▃▃▅▄▂▃▁▅▅▄▄▄▄▄▃▄▁▃▆▄▃▂
wandb:      train/policy_loss ▄▁▅▆▅▆▆▅█▆▆▇▇▇▅█▇▅▅▆▅▆▆▆▅▆▄▅▅▆▄▅▄▆▇▆▅▇▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▃▅▆▄▄▅▄▆▆▆▄▆▅▃▅█▃▄▅▃▇▄▄▄▅▅▅▃▃▄▃▇▄▁▄▂▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.59
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.47703
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.02751
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33222
wandb:      train/ensemble_f1 0.33222
wandb:         train/mil_loss 1.10927
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x1hv4grm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183055-x1hv4grm/logs
wandb: Agent Starting Run: aeicjw1t with config:
wandb: 	actor_learning_rate: 1.6901494606422276e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2383968788986669
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9977097221589306
wandb: Agent Starting Run: owyes9l0 with config:
wandb: 	actor_learning_rate: 0.0029205920457847064
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.912449405992628
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3397658432509755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183249-owyes9l0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/owyes9l0
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183249-aeicjw1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aeicjw1t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▄▅▅▆▆▄▃▃▅▅▅▄▅▅▅▅▅▇▇▄▄▄▂▄▄▆▅▃█▅▂▅▄▄▅▆▁
wandb:      train/ensemble_f1 ▅▆▄▇▅▆▆▅▇▆▃▄▅▃▅▅▂▃▅▅▃▇▄▄▂▄▅▆▅▅▆██▂█▄▇▄▆▁
wandb:         train/mil_loss █▃▇▅▁▄▅▂▃▁▃▄▄▆▅▆▃▆▁▂▄▅▂▄▁▅▅▃▄▆▄▃▄▂▃▅▃▅▃▅
wandb:      train/policy_loss ▅▇▃▃▄▁▄▄▇▇▆▆▅▃▃▃▅▆▃▅▄▃▆▅▄▅▅▅▆▃▆▇▇▅▇▅▄█▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▇▅▆▆▆▆▆▄▅▃▃▃▃▂▅▆▂▄▆▃▃▇▁▄▅▃▆▃▆▇▄█▂▅▃▅▅▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98182
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96558
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09232
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31624
wandb:      train/ensemble_f1 0.31624
wandb:         train/mil_loss 0.78034
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uhzyv9q6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183204-uhzyv9q6/logs
wandb: Agent Starting Run: a0u5obke with config:
wandb: 	actor_learning_rate: 0.005843622942746523
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4792889737536289
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19558694589785564
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183358-a0u5obke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a0u5obke
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄█▄▂▄▄▅▃▂▄▅▃▄▆▄▆▃▂▂▃▅▃▂▃▁▄▃▅▄▄▅▃▁▄▄▄▄▇
wandb:      train/ensemble_f1 ▄▃▄▆▄▄▄▃▄█▅▁▅▅▂▅▇▇▄▅▃▃▃▆▃▂▆▄▇▂▅▄▆▅▇▅▅▅▄▄
wandb:         train/mil_loss ▃▆▆▃▇▅▄▅▆▆▇▄▄▅▁▃▅█▆▃▇▂▂▄▆▇▃▂▅▄▄▅▅▄▃▅▄▂▄▂
wandb:      train/policy_loss ▄▆▄▄▆▄▆▆▆▄▃▄▆▅▆█▅▂▅▃▆▆▆▅▆▆▂▁▄▆▆▅▆▄▆▆▆▆▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▃▄▇▄▇▇█▄▆▆▇▃▅▆▄▆▃▆▄▃▇▅█▄▇█▆▂▁▅▆▇▄▆▅▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.88127
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.85298
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.96492
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34587
wandb:      train/ensemble_f1 0.34587
wandb:         train/mil_loss 0.75688
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aeicjw1t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183249-aeicjw1t/logs
wandb: Agent Starting Run: fjudjhkr with config:
wandb: 	actor_learning_rate: 1.2442933523885085e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13003852404864513
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.028034411355163824
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183443-fjudjhkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fjudjhkr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss ▆█▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▄▆▃▁▁▁▇▇▆▆██████████████████▇▇▇▇█▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▅▁▁▁▁█▁▁▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▁▄▅▄▃▃▅▅▅▄▅▅▃▄▅▅▄▃▄▅▄▅▄▆▂▃▅▅▇▅▇▇▃█▅▇▄
wandb:      train/ensemble_f1 ▂▄▃▃▂▄▂▂▄▅▃▄▆▁▃▂▃▃▅▅▄▁▃▂▁▁▃▇▁▂▃▂▆▅▅▁▅█▇▇
wandb:         train/mil_loss ▃▄▃▆▅▅▅▄█▄▃▅▃▃▃▅▂▂▃▂▅▃▅▄▄▄▄▃▅▃▁▃▂▄▆▅▃▅▃▅
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅█▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅█▅▅▅▅▅▁▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56854
wandb: best/eval_avg_mil_loss 0.75111
wandb:  best/eval_ensemble_f1 0.56854
wandb:            eval/avg_f1 0.53989
wandb:      eval/avg_mil_loss 0.81788
wandb:       eval/ensemble_f1 0.53989
wandb:            test/avg_f1 0.53605
wandb:      test/avg_mil_loss 0.66438
wandb:       test/ensemble_f1 0.53605
wandb:           train/avg_f1 0.57056
wandb:      train/ensemble_f1 0.57056
wandb:         train/mil_loss 0.57212
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/owyes9l0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183249-owyes9l0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u77z234s with config:
wandb: 	actor_learning_rate: 0.0015873247418243862
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3294124275111816
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7365855775476862
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183519-u77z234s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u77z234s
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▄▄▅▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss █▇▇▄▄▃▂▂▂▁▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▄▄▅▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▂▄▃▄▄▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▇██████████▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▂▂▃▃▄▄▆▆▆▅▆▇▇▇▇▆▆▆▆▆▇▇█████████████▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▄▄▃▅▆▆▅▆▇▆▆▆▆█▇█▇▇██▇██▇▇▇▇▇▇▇▇▇▇▇█▇▇
wandb:      train/ensemble_f1 ▂▂▁▄▄▄▃▄▅▅▆▆▅▄▅▆▆▇▆▆▆▅▇▇▇▇█▇▇▇██▇▇▇▇▇▇█▇
wandb:         train/mil_loss ▇█▇▇▇▅▅▆▆▅▄▃▅▄▄▄▅▄▂▃▄▃▄▃▃▂▁▃▂▃▃▁▂▂▃▂▂▃▂▃
wandb:      train/policy_loss ███████████▁██████████████▂█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████████████▁███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65946
wandb: best/eval_avg_mil_loss 0.58892
wandb:  best/eval_ensemble_f1 0.65946
wandb:            eval/avg_f1 0.61445
wandb:      eval/avg_mil_loss 0.60989
wandb:       eval/ensemble_f1 0.61445
wandb:            test/avg_f1 0.60902
wandb:      test/avg_mil_loss 0.71874
wandb:       test/ensemble_f1 0.60902
wandb:           train/avg_f1 0.62388
wandb:      train/ensemble_f1 0.62388
wandb:         train/mil_loss 0.64994
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5knjenu3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183011-5knjenu3/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▃▄▆▅▃▄▁▃▅▂▅▅▄▃█▃▅▆▅▇▅▄▄▂▅▇▃▆▅▃▄▆▂▂▆▆█
wandb:      train/ensemble_f1 ▄▄▃▅▁▃▃▄▅▆▅▆▅▅▃▅▃▂█▃▅▆▇▄▂▄▄▂▂▇▄▅▅▆▂▅▆▆▄▅
wandb:         train/mil_loss ▆▃▅▅▆▄▅▇▇▂█▃▄▅▄▆▃▆▂▃▂▂▅▂▃▅▁▆▂▄▄▄▂▁▃▄▃▄▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.16466
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.10936
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.91939
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.41736
wandb:      train/ensemble_f1 0.41736
wandb:         train/mil_loss 0.87639
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a0u5obke
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183358-a0u5obke/logs
wandb: Agent Starting Run: kzzz58wx with config:
wandb: 	actor_learning_rate: 5.0329655355223376e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.006780328831824334
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9817662868430904
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183547-kzzz58wx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kzzz58wx
wandb: Agent Starting Run: w03tyyq4 with config:
wandb: 	actor_learning_rate: 0.005584181504450411
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5075702029638643
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4274200331172957
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183552-w03tyyq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w03tyyq4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▅▆▄▆▃█▁▅▆▆▅▆▇▄▇▇▆▂▇█▇▆▇▅▄▆▃▆█▄▆█▅▄▆▆▇▆
wandb:      train/ensemble_f1 ▆█▄▇▅▅▅▂▆▄▃▅█▆▇▄▆▃▅▃▇█▁▄▆▃▇▆▆▇▄█▇▂▃▅▂▆▇▇
wandb:         train/mil_loss ▅▅▂▃▂▄▄▁▆▄▇▅▅▇▄▃▇▄▁▄▂▄▆▄▅▆▂▁▅▅▅▃█▄▆▄▄▃▄▇
wandb:      train/policy_loss ▅▇█▇▆▅▂▄▅▇▄▃▄▃▃▆▄▄▄▅▇▁▃▁▄▄▄▄▄▆▆▁▆▅▂▄▄▄█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▁▅▄▅▅▅▅▄▄▅▄▄▅▂▅▅▄▄▂▃█▂▂▆▄▄▂▄▂▅▄▄▄▅▄▇▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.04557
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97442
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.17769
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34102
wandb:      train/ensemble_f1 0.34102
wandb:         train/mil_loss 0.88324
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u77z234s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183519-u77z234s/logs
wandb: Agent Starting Run: irc6c4a2 with config:
wandb: 	actor_learning_rate: 0.002721991735906012
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8853527473695025
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09578223838585986
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183713-irc6c4a2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/irc6c4a2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▅▅▅▄▆▆▄▄▇▄▆▄▂█▆▅▃▇▆▅█▆▇▆█▆▅█▄▆▃▁▆▅▆▅▅█
wandb:      train/ensemble_f1 ▆▃▆▄▄▅▄▆▅▂▃▁▇▅█▂▅▅▅▇▄▅▄▃▁▆▅▇▅█▅▂▄▃▆▅▁▅▄▄
wandb:         train/mil_loss ▄▆▄▆▇▇▅▂▆▇▇▅█▆▄▃▄▃▃▅▃▃▄▅▇▄▆▂▆▄▆▅▄▁▅▅▄▃▁▅
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.89242
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.84078
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.0071
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34265
wandb:      train/ensemble_f1 0.34265
wandb:         train/mil_loss 0.86153
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kzzz58wx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183547-kzzz58wx/logs
wandb: Agent Starting Run: br24n8rz with config:
wandb: 	actor_learning_rate: 1.0369323318027463e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20736436169972428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.026139352113121128
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183745-br24n8rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/br24n8rz
wandb: uploading history steps 116-121, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇▇█
wandb: best/eval_avg_mil_loss █▁▂▁
wandb:  best/eval_ensemble_f1 ▁▇▇█
wandb:            eval/avg_f1 ▆██▇▇▇▃▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▁▁▁▃▇████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▆▆▆▇▇▇▇███▃▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▇▅██▂▃▂▁▂▃▂▂▂▂▂▄▃▁▁▃▂▃▂▃▃▃▂▁▃▁▂▃▃▃▄▄▃
wandb:      train/ensemble_f1 ▇▆▆██▆▄▃▂▃▂▃▂▂▂▂▁▂▃▂▃▂▁▂▂▂▂▃▂▂▃▂▃▃▃▂▂▄▄▃
wandb:         train/mil_loss ▃▂▂▂▂▁▃▁▅▄▂▆▄▆█▄▅▅▆▅▅▄▄▅▅▅▄▅▅▄▄█▅▅▅▄▅▅▄▅
wandb:      train/policy_loss ▆▆▆▇▆▆▆▆▆▆▆▆▆█▆▇▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82998
wandb: best/eval_avg_mil_loss 0.52296
wandb:  best/eval_ensemble_f1 0.82998
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 1.9339
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.84816
wandb:      test/avg_mil_loss 1.32936
wandb:       test/ensemble_f1 0.84816
wandb:           train/avg_f1 0.71581
wandb:      train/ensemble_f1 0.71581
wandb:         train/mil_loss 0.99391
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w03tyyq4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183552-w03tyyq4/logs
wandb: Agent Starting Run: 9ixsyx4d with config:
wandb: 	actor_learning_rate: 0.005035981454548662
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7533882549248933
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3925503876002931
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183801-9ixsyx4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ixsyx4d
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▄▄▄▄▁▃▁▆▅▁▂▅▇▆▃▂▄▄▄▅▆▆▃▄▄▅▄▅█▇▂▅▄▆▄▅██
wandb:      train/ensemble_f1 ▁▄▁▂▄▄▃▆▃▄▂▇▆▄▃▅▅▂▄▄▄▆▆▆▄▅▂▇▆▆▆▆▄▃▆▄▄▆▆█
wandb:         train/mil_loss ▆▆██▆▆▆▇▆▆▃▆▅▅▅▃▆▄▃▄▄▅▃▄▂▃▂▃▄▄▂▂▄▃▂▁▂▂▂▃
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.79959
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.71107
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.70526
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.52152
wandb:      train/ensemble_f1 0.52152
wandb:         train/mil_loss 0.89871
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fjudjhkr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183443-fjudjhkr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q2rv0yn7 with config:
wandb: 	actor_learning_rate: 0.001907937453124298
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7222571013989906
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01083581847063486
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183846-q2rv0yn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q2rv0yn7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▆▆▆▅▅▅▅▆███▇▇▆▇▇▇▇▆▆▆▆▆▆▅▅▅▄▃▂▂▁▁▁▂▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▇▅▆▆▆▅▅▅▄█▄█▆▆▇▆▅▆▂▅▁▅▄▄▃▃▅▅▃▅▁▅▃▂▆▄▃▃
wandb:      train/ensemble_f1 ▄▄▅▆▆▅▂▅▅█▇▁▄▇▄▃█▃▄▆▂▆▃▅▆▃▃▂▂▂▆▂▃▅▁▅▆▂▃▇
wandb:         train/mil_loss ▄█▄▅▄▂▄▄▄▅▃▂▅▅▂▂▅▄▂▆▂▄▄▄▃▅▂▅▅▃▃▃▃▃▄▃▃▁▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.53292
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.80767
wandb:      eval/avg_mil_loss 0.53255
wandb:       eval/ensemble_f1 0.80767
wandb:            test/avg_f1 0.85288
wandb:      test/avg_mil_loss 0.34084
wandb:       test/ensemble_f1 0.85288
wandb:           train/avg_f1 0.82615
wandb:      train/ensemble_f1 0.82615
wandb:         train/mil_loss 0.50512
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/irc6c4a2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183713-irc6c4a2/logs
wandb: Agent Starting Run: darhg6kh with config:
wandb: 	actor_learning_rate: 0.005879703055353706
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29316238719788046
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7514334290480547
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183907-darhg6kh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/darhg6kh
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▆▆▆█▇▇▇▆▆▆▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃▇▆▆▇▅▂▅▅▄▃▅▅▆▄▆▄▃▄▂▄▄▄▁▄█▆█▆▃█▄▃▇█▃▃█
wandb:      train/ensemble_f1 ▅▃▇▅▅▁▆▄▂▄▃▇▆▆▅▅█▄▅▇▃▃▂▃▄▃▃▆▆▅▃▆▃▅▄▄▇▆▃▆
wandb:         train/mil_loss ▅▆▂▅▁▄▅▆▅▃▂▄▇▂▅▄▆▂▂▅▃▃▆▅▃▃▄▂▆▅▃▆▆▂▂▅▃█▂▂
wandb:      train/policy_loss ▂▃▄▇▃▂▃▃▆▆▃▁▆▃▆█▄▁▄▆▂▆▆▃▃▅▁▅▄▃▆▄▄▄▂▆▄▁▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▆▄▃▃▅▃▅█▅▃▅▆▄▃▁▅▆▆▅▆▃█▆▆▆▃▅▁▃▄▆▄▄▄▃▃▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.20645
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.16464
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.69052
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34372
wandb:      train/ensemble_f1 0.34372
wandb:         train/mil_loss 1.49336
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fiery-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/br24n8rz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183745-br24n8rz/logs
wandb: Agent Starting Run: vmnu3gms with config:
wandb: 	actor_learning_rate: 1.212366217613319e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05552869394854077
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6758306651897003
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183944-vmnu3gms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmnu3gms
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▁▅▄█▄▆▂▂▄▄▃▄▅▂▄▂▇▆▃▆▄▃▇▅▄▄▅▂▄▄▆▄▅▇▅▄▃▅
wandb:      train/ensemble_f1 ▄▇▆▄▅▆▄▁▃▅▂▅▅▄▅▂▆▁▂▁█▃▂▂▇█▅▄▂▂▅▅▄▄▇▅▃▅▄▆
wandb:         train/mil_loss ▇▅▄▆▃▂▃▅▄▃█▂▅▃▁▄▂▃▅▄▃▄▆▂▂▅▂▄▂▁█▄▂▇▆▄▃▄▄▅
wandb:      train/policy_loss ▃▅▄▆▄▅▆▂█▃▄▂█▂▅▄▇▄▄▁▃▇▆▅▇▇▃▅▇▃▄▆▆▂▅▂▄▇▅▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▆▅█▇▅▃▆▄▅▅▃▇▆▅▄▇▆▅█▇▆▄▇▅█▄▆▇▆▄▁▇▅▆▄▅▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.93555
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.92626
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.99942
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 0.65484
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9ixsyx4d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183801-9ixsyx4d/logs
wandb: Agent Starting Run: 9cvmpbh8 with config:
wandb: 	actor_learning_rate: 0.008885209539871517
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3863276626308427
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6799226119033216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_183956-9cvmpbh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cvmpbh8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▅█████████████████████████████████▄████
wandb:      eval/avg_mil_loss █▆▆▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▃▃▃▃▂▂▂▁▁▁▁▁▁▂▂▂▂▄▅▅▄
wandb:       eval/ensemble_f1 █▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▅▁▃▁▅▂▅▂▆▃▄█▅▄▄▇▅▄▆▅▇▆▂▇▆█▁▆▇▅██▅▄▅▆▇
wandb:      train/ensemble_f1 ▄▅▁▆▃▃▆▅▆▂▆▃▆▄█▆▅▇▆▆▆▅▅▅▆▆▄▆▆▅▅█▆█▅▇█▇▆▅
wandb:         train/mil_loss ▅▅▆▆▇█▆▇▂▃▅▅▆▄▆▇▆▃▇▂▆▂▅▇▃▅▁▆▅▇▄▅▅▅▅▄▇▇█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78998
wandb: best/eval_avg_mil_loss 0.4519
wandb:  best/eval_ensemble_f1 0.78998
wandb:            eval/avg_f1 0.78998
wandb:      eval/avg_mil_loss 0.44013
wandb:       eval/ensemble_f1 0.78998
wandb:            test/avg_f1 0.80767
wandb:      test/avg_mil_loss 0.50965
wandb:       test/ensemble_f1 0.80767
wandb:           train/avg_f1 0.78495
wandb:      train/ensemble_f1 0.78495
wandb:         train/mil_loss 0.52377
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vmnu3gms
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183944-vmnu3gms/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▅▄▆▁▄▃▄▇▃▅▄▃▅▆▄▇▄▆▃▃▇▅▄▅▆▅▅▅▄▄▄▄▆▅▅▂▃▇
wandb:      train/ensemble_f1 ▃▄▄▆▂▄▅▄▇▅▄▆▅▆▅▅▇▇▅▆▇▄▁▄▅▆▄▄▅▃▄█▄▄▄▆▇▄▄▆
wandb:         train/mil_loss ▂▃▅▁▆▃▂▂▃▃▅▂▂▄▃▂▃▄▄▄▂▄▄▁▄▆▆▆▇▅▇▇█▆▅▆▅▆▅▅
wandb:      train/policy_loss █▃▆▆▇▂▆▄▇▄▁▅▆▂▆▅▁▅▆▄▃▃▃▃▅▃▅▄▄▃▃▆▃▄▃▂▆▃▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▄▆▆▆▇▂▇▅▇▄▅▆▄▅▁▄▆▃▆▃▃▃▃▄▆▇▃▃▅▂▂▃▃▆▄▂▃▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01035
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.24212
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12207
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33444
wandb:      train/ensemble_f1 0.33444
wandb:         train/mil_loss 0.90996
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9cvmpbh8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183956-9cvmpbh8/logs
wandb: Job received.
wandb: Agent Starting Run: dn4xkeon with config:
wandb: 	actor_learning_rate: 3.3727121468361754e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.007178459497308887
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.469889394299303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184148-dn4xkeon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dn4xkeon
wandb: Agent Starting Run: uq15g9n4 with config:
wandb: 	actor_learning_rate: 5.581816279491998e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6432858914118489
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11504873762992374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184150-uq15g9n4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uq15g9n4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss ▇▇█▄▄▄▄▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▂▂▃▂▂▃▃▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆██▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▇▇██▇▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▄▅▅▆▆▆▆▆▇▇▇▇▇▆▇▆▆▆██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▃▃▆▇▆▆▅▅▄█▅▇▇▇▆▇▇██▆▆▇▇▇▆▅▅▅▆▆▅▇▆▆▇▆▇▆
wandb:      train/ensemble_f1 ▃▂▂▁▃▄▄▆▄▅█▇▇▅▅▆█▄▄▆▆▆▆▄▅▇▆▆▆▇▆▇▆▄▆▅▆▇▆▆
wandb:         train/mil_loss ▇▆▅█▅▄▅▄▇▄▅▅▆▅▃▅▅▄▇▄▄▅▃▂▃▄▃▁▄▂▃▅▄▂▃▄▃▁▁▂
wandb:      train/policy_loss ▅▅▂█▅▅▅▆▅▅▇▅▅▆▅▅▅▅█▅▄▃▅▅▅▅▄▅▅▁▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▅▅▅▅▅▄▃▅▅█▅▅▅▄▅▅▅▅▃▅▆▁▄▂▄▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68474
wandb: best/eval_avg_mil_loss 0.5984
wandb:  best/eval_ensemble_f1 0.68474
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 0.55967
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.57924
wandb:      test/avg_mil_loss 0.62695
wandb:       test/ensemble_f1 0.57924
wandb:           train/avg_f1 0.66146
wandb:      train/ensemble_f1 0.66146
wandb:         train/mil_loss 0.63684
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/darhg6kh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183907-darhg6kh/logs
wandb: Agent Starting Run: l2poyso5 with config:
wandb: 	actor_learning_rate: 1.15944191952698e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4291925136170284
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8363679939420299
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184336-l2poyso5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l2poyso5
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▆▆▆▅▅▅▄▂▃▁▁▁▂▂▂▁▂
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▆▆▆▆▅▅▅▂▂▂▃▃▃▃▂▃▃▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇██▆▇█▆▆▆▆▆▆▇▇▆▄▅▆▅▆▄▆▅▆▄▃▃▃▃▂▂▃▂▁▂▂▃▃▃▃
wandb:      train/ensemble_f1 █▇▆▆█▇█▇█▆▇▇▆▆▄▆▄▆▅▅▄▅▄▅▄▃▃▂▃▃▃▁▂▂▁▁▁▂▃▃
wandb:         train/mil_loss ▄▅▇█▃█▆▄▅▅▅▅▇▃▆▆▆▂▆▅▅▃▆▆▅▅▄▄▄▁▃▄▃▂▃▁▂▂▃▅
wandb:      train/policy_loss ▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▁▂▂▂▁▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▁▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67825
wandb: best/eval_avg_mil_loss 0.71866
wandb:  best/eval_ensemble_f1 0.67825
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 0.68694
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.70515
wandb:      test/avg_mil_loss 0.6894
wandb:       test/ensemble_f1 0.70515
wandb:           train/avg_f1 0.54339
wandb:      train/ensemble_f1 0.54339
wandb:         train/mil_loss 0.69472
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dn4xkeon
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184148-dn4xkeon/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ██▇▇█▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▂▄▅▅▃▄▃▆▇▆▃█▄▇▁▁▅▃▂▃▃▆▇▂▃▄▅▅▆▂▆▂▁▄▇▇▇▃
wandb:      train/ensemble_f1 ▄▅▂▅▃▆▃▄▆█▅▇▅▅▇▆▄▃▁▄▆▆▇▆▄▂▆▆▅▆▇▆▅▄▃▇▆█▃▆
wandb:         train/mil_loss ▄▃▆▄▁▆▅▃▃▄▄▁▆▂▅▂▆▄▃▃▃▃▄▆█▃▄▃▅▃▅▃▂▃▄▂▄▅▇▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.59491
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 0.57886
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.53941
wandb:      test/avg_mil_loss 0.57908
wandb:       test/ensemble_f1 0.53941
wandb:           train/avg_f1 0.61123
wandb:      train/ensemble_f1 0.61123
wandb:         train/mil_loss 0.58254
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uq15g9n4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184150-uq15g9n4/logs
wandb: Job received.
wandb: Agent Starting Run: qfjq4cqo with config:
wandb: 	actor_learning_rate: 1.942330958839968e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.023444422185574965
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6638957250839714
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184352-qfjq4cqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qfjq4cqo
wandb: Agent Starting Run: v3vipr6y with config:
wandb: 	actor_learning_rate: 1.4745988090030218e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5621324726698435
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6770618623954753
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184354-v3vipr6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v3vipr6y
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▅▅▅▄▄▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▄▇▄▇▄▄▄▆▅▄▆▁▅▄▄▆▅▆▆▄▅▆▄▄▆▁█▅▃▆▇▆▄▅▄▆█
wandb:      train/ensemble_f1 ▄▄▇▄▆▆▆▄▄▆▄▁▆▄▄▂▅▄▄▇▇▄▄▅▅▅▄▃▄▃▆▅▆█▃▄▇▇▆▆
wandb:         train/mil_loss ▆▅▆▃▃▃▅▅█▄▃▇▂▆▁▄▄▂▄▃▇▃▄▅▃▂▄▆▃▆▅▇▃▂▂▆▅▆▅▅
wandb:      train/policy_loss ▃▂▄▃▅▅▂▁▂▄█▄▂▃▂▃▆▅▃▃▄▄▁▂▄▃▂▄▄▂▂▅▆▃▁▅▄▁▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▂▃▃▅▄▄▂▃▄▄█▃▂▆▂▃▄▆▅▅▂▄▄▇▇▅▅▅▆▃▅▅▄▅▁▄▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.84188
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.72336
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.0674
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34641
wandb:      train/ensemble_f1 0.34641
wandb:         train/mil_loss 1.26147
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l2poyso5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184336-l2poyso5/logs
wandb: Agent Starting Run: 5m7msdsd with config:
wandb: 	actor_learning_rate: 3.4208899683828436e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7454657657476034
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43589260811411934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184531-5m7msdsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5m7msdsd
wandb: uploading history steps 130-140, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▄▂▁▃▆▂▂▄▂▄█▁▄▁▃▅▂▅▅▄▄▇▁▅▆▇▁▇▁▅▃▆▆▃▅▅▄
wandb:      train/ensemble_f1 ▅▂▄▂▅▁▄▄▆▃▄▅█▄▃▅▅▄▃▃▂▆▆▂▆▂▆▅▂▄▆▄▁▆▄▄▄▅▂▄
wandb:         train/mil_loss ▄▃▅▄▄▆▆█▇▆▃▇▅▅▄▄▄▆▄▇▅▄▅▃▇▅▅▇▃▆▂▃▄▃▄▃▃▄▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 0.95831
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 0.87974
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.72901
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.55346
wandb:      train/ensemble_f1 0.55346
wandb:         train/mil_loss 0.79622
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v3vipr6y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184354-v3vipr6y/logs
wandb: Agent Starting Run: mgh2d0ec with config:
wandb: 	actor_learning_rate: 0.001143246065236527
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6731381705590612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5011038825140832
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184624-mgh2d0ec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mgh2d0ec
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▃▃▃▃▃▁▁▁▁▁▁▁▅▅▅▅▅█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▃▁▁▁▁▁▁▁▅▅▅▅▅█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▂▃▂▄▁▆▃▁▄▇▃▂▇▃▅▄▆▇▄▄▅▆▄▄▄▅▇█▆█▆▇▇▇▄█▇
wandb:      train/ensemble_f1 ▂▅▁▄▂▁▃▄▂▃▆▅▇▄▂▅█▄▅▅▇▁▇▆▆▄▇▂▃▄▆▇▄▅▆█▅▇▇▇
wandb:         train/mil_loss ▃▆▆█▅▇▄▆▇▃█▂▃▇▂▃▄▄▅▃▂▃▆▁▃▄▃▃▄▃▃▁▄▃▁▁▅▃▃▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65157
wandb: best/eval_avg_mil_loss 0.70233
wandb:  best/eval_ensemble_f1 0.65157
wandb:            eval/avg_f1 0.63385
wandb:      eval/avg_mil_loss 0.66725
wandb:       eval/ensemble_f1 0.63385
wandb:            test/avg_f1 0.57966
wandb:      test/avg_mil_loss 0.82013
wandb:       test/ensemble_f1 0.57966
wandb:           train/avg_f1 0.59666
wandb:      train/ensemble_f1 0.59666
wandb:         train/mil_loss 0.65497
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qfjq4cqo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184352-qfjq4cqo/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇█
wandb: best/eval_avg_mil_loss █▆▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▇▇▇▇▇███████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▄▄▆▆▅▅▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▄▄▃▄▅▁▅▃▃▂▄▄▂▆▆▆▃▃▄▄▄▃▄▅▁▄▆▅█▃▃▅▃▄▄▅▅
wandb:      train/ensemble_f1 ▅▄▃▃▄▄▃▃▅▇▅▃▅▃▅▇▆██▅▄▅▅▇▅▆▇▅▅▇▄▄▃▅▅▇▇▄▆▁
wandb:         train/mil_loss ▄▃▆▂█▄▄▆▄▄▄▂▄▂▃▂▅▆▄▃▃▃▁▃▂▄▃▅▄▅▂▅▂▂▅▂▃▂▂▃
wandb:      train/policy_loss █████████████████████████████▁██████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▁▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54772
wandb: best/eval_avg_mil_loss 0.61469
wandb:  best/eval_ensemble_f1 0.54772
wandb:            eval/avg_f1 0.54772
wandb:      eval/avg_mil_loss 0.59489
wandb:       eval/ensemble_f1 0.54772
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.62927
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.49944
wandb:      train/ensemble_f1 0.49944
wandb:         train/mil_loss 0.63312
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q2rv0yn7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_183846-q2rv0yn7/logs
wandb: Job received.
wandb: Agent Starting Run: ij0mwjc8 with config:
wandb: 	actor_learning_rate: 1.0426480498015e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06975233307553486
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.571917749286959
wandb: Agent Starting Run: 7tgtn1dz with config:
wandb: 	actor_learning_rate: 0.0007402465956303061
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5402739488380192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.79118716763774
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184712-ij0mwjc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ij0mwjc8
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184713-7tgtn1dz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7tgtn1dz
wandb: uploading history steps 128-132, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▄▆█
wandb: best/eval_avg_mil_loss █▇▅▄▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▄▆█
wandb:            eval/avg_f1 ▁▁▁▅▅▅▅▅▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▄▄▄▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▅▄▆▃▂▂▅▄▆▄▇▄▄▇▅▂▆▄▆▂▅▅▁▅▄█▆▄▄▆▄▅▄█▆▁▆
wandb:      train/ensemble_f1 ▄▆▂▂▁▅█▅▅▄▃▁▄▅▄▅▃▄▇▇▇▆▅▆▇▁▂▇▇▇▄▅▄█▄▄█▄▆▆
wandb:         train/mil_loss ▁▆▅█▆▃▆▆▇▆▃▅▇▆▁▄▄▄▃▅▅▃▄▅▄▆▂▃▃▅▁▇▅▄▄▅▇▂▄▅
wandb:      train/policy_loss ▇▇▆█▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62148
wandb: best/eval_avg_mil_loss 0.73147
wandb:  best/eval_ensemble_f1 0.62148
wandb:            eval/avg_f1 0.6124
wandb:      eval/avg_mil_loss 0.70015
wandb:       eval/ensemble_f1 0.6124
wandb:            test/avg_f1 0.55433
wandb:      test/avg_mil_loss 0.65813
wandb:       test/ensemble_f1 0.55433
wandb:           train/avg_f1 0.58165
wandb:      train/ensemble_f1 0.58165
wandb:         train/mil_loss 0.6164
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5m7msdsd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184531-5m7msdsd/logs
wandb: Agent Starting Run: rdc2mqia with config:
wandb: 	actor_learning_rate: 6.082871375237966e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6912720736187361
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2428474173370704
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184756-rdc2mqia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rdc2mqia
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▆▆▆▆▆▆▅▅▅▄▄▄▃▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▄▄▄▃▅▄▇▁▅█▇▃▃▃▄▅▆▂▃▅▇▃▇▃▅▅▃▃▃▆▂▃▆▅▆█▅
wandb:      train/ensemble_f1 ▃▅▄▆▄▄▃▄▄▆▆▇▇▆▅▁▃▃▃▃▆▆▂▃▅▅▄▇▇▆▆▆▄▃▄█▅▄▄▅
wandb:         train/mil_loss ▇█▄▆▇▆▅▇▄▂▆█▄▆▁▇▂▄▃█▄▅▄▆▃▅▅▇▅▇▅▆▂▅▆▅▄▃▆▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55437
wandb: best/eval_avg_mil_loss 0.62113
wandb:  best/eval_ensemble_f1 0.55437
wandb:            eval/avg_f1 0.55437
wandb:      eval/avg_mil_loss 0.61448
wandb:       eval/ensemble_f1 0.55437
wandb:            test/avg_f1 0.56363
wandb:      test/avg_mil_loss 0.59389
wandb:       test/ensemble_f1 0.56363
wandb:           train/avg_f1 0.5769
wandb:      train/ensemble_f1 0.5769
wandb:         train/mil_loss 0.68554
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mgh2d0ec
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184624-mgh2d0ec/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cng5ifnw with config:
wandb: 	actor_learning_rate: 0.0001797718856354843
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17012672098445203
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7743982579914305
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184824-cng5ifnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cng5ifnw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▁▆▅▅▅▆▃▅▅▆▄▅▄▅▅▅▅▆▅▆▆█▆▆▇▅▄█▃▇▆▇▅▅▅▇
wandb:      train/ensemble_f1 ▂▁▄▁▅▇▆▆▅▅▆▆█▆▃▅▇▅▆▅▇▆▅▆▆▇▅▄▅█▃▄▆▅▇▇▇▅▅▇
wandb:         train/mil_loss ▆▁▃▇▄▆▆▅▇▄▇█▆▄▆▇▄▆▄▅▅▁▅▇▆▆▆▅▄▄▅▇▅▆▃▃▅▄▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54004
wandb: best/eval_avg_mil_loss 0.66489
wandb:  best/eval_ensemble_f1 0.54004
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 0.65246
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.43464
wandb:      test/avg_mil_loss 0.71536
wandb:       test/ensemble_f1 0.43464
wandb:           train/avg_f1 0.53808
wandb:      train/ensemble_f1 0.53808
wandb:         train/mil_loss 0.58608
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7tgtn1dz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184713-7tgtn1dz/logs
wandb: Agent Starting Run: b5s5cyhm with config:
wandb: 	actor_learning_rate: 1.979470245346811e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7502116427496959
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3446357201708876
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184907-b5s5cyhm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b5s5cyhm
wandb: uploading history steps 99-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇█▄▃▃▂▂▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▄▄▄▄▄▄▄▄▄▃
wandb:      eval/avg_mil_loss █▇▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▅▄▄▄▃▃▂▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▄▄▄▄▄▄▄▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃█▄▄▅▂▅▆▆▅▇▄▅█▆▂▃▄▅▅▇▄▄▄▁▃▁▅▃▄▅▄▇▇▂▇▅▄
wandb:      train/ensemble_f1 ▇▄█▂▄▇▄▄▇▇▆▄▆▅▇█▃▄▆▃▄▇▇▁█▄▅▄▃▅▅▄▇▄▃█▅▃▆▄
wandb:         train/mil_loss ▂▃▃▃▃▄▅▄▃▁▃▁▃▄▄█▆▅▁▄▄▂▄▁▅▆▃▃▃▂▄▁▃▃▅▃▂▅▄▄
wandb:      train/policy_loss ▄▄▄▆▅▄▄▄▄▁█▄▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃█▃▁▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54955
wandb: best/eval_avg_mil_loss 0.8378
wandb:  best/eval_ensemble_f1 0.54955
wandb:            eval/avg_f1 0.49495
wandb:      eval/avg_mil_loss 0.76407
wandb:       eval/ensemble_f1 0.49495
wandb:            test/avg_f1 0.54044
wandb:      test/avg_mil_loss 0.73659
wandb:       test/ensemble_f1 0.54044
wandb:           train/avg_f1 0.53529
wandb:      train/ensemble_f1 0.53529
wandb:         train/mil_loss 0.62193
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rdc2mqia
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184756-rdc2mqia/logs
wandb: Agent Starting Run: 7a7du3be with config:
wandb: 	actor_learning_rate: 1.3990447880920865e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5085380081966586
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04196812906724656
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_184955-7a7du3be
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7a7du3be
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▅▃▃▆▄▅▂▃▃▂▅▂▃▁▆▅▄▆▄▅▆█▅▂▄▆▅▄▄▄▅▃▃▄▄▄▇
wandb:      train/ensemble_f1 ▄▃▄▃▃▃▂▄▂▅▄▂▆▁▂▂▄▄▃▄▁▁█▁▄▅▅▅▄▅▄▅▃▃▂▂▃▂▃▄
wandb:         train/mil_loss █▃▄▅▄▅▄▄▃▃▄▄▅▅▄▅▄▅▄▃▃▆▅▂▄▂▄▂▄▄▄▅▄▄▁▁▃▃▃▅
wandb:      train/policy_loss █▇▁▄▆▅█▄▇▇▄▂▃▃▇▇▄▂▇█▂▆▃▆▄▂▃▇▆▄▇▇▂▄▆▃▃▃▇▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▂▃▆▂▆▃▅▆▂▆▇▆▁▁▁▆▇▂▁▅▃▃█▄▄▃▁▆▃▂▁▆▃▃▂▄▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 1.82688
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.63888
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.35596
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.4577
wandb:      train/ensemble_f1 0.4577
wandb:         train/mil_loss 1.67281
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cng5ifnw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184824-cng5ifnw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2vzrlt73 with config:
wandb: 	actor_learning_rate: 0.009413246849530831
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9950626614409228
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6946372062077089
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185036-2vzrlt73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vzrlt73
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅█▄▇▅▄▃▄▄▃▂▂▄▂▂▅▂▃▆▃▂▁▇▄▂▃▅▄▅▅▂▃▄▇▅▂▄▄
wandb:      train/ensemble_f1 ▆▆▆▄▅█▆▅█▆▄▅▃▃█▅▆▄▃▆▃▅▄▇▆▇▄▃▁▇▃▅▅▅▄▅▆▃▁▅
wandb:         train/mil_loss █▄▄▄▄▃▃▄▅▆▂▄▅▃▅▆▂▅▃▂▁▂▃▄▃▁▃▄▃▂▃▃▂▇▄▅▃▂▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72678
wandb: best/eval_avg_mil_loss 0.8078
wandb:  best/eval_ensemble_f1 0.72678
wandb:            eval/avg_f1 0.72678
wandb:      eval/avg_mil_loss 0.90055
wandb:       eval/ensemble_f1 0.72678
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.62416
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.69139
wandb:      train/ensemble_f1 0.69139
wandb:         train/mil_loss 0.56116
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vzrlt73
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185036-2vzrlt73/logs
wandb: Agent Starting Run: 2arrduce with config:
wandb: 	actor_learning_rate: 5.780495910147439e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5293619234024309
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06178680267947967
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185230-2arrduce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2arrduce
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▄▂▂▄▄▄▄▂▃▄▅▁▅▄█▇▅▅▄▆▄▇▄▅▃▄▄▅▆▅▇▅▅▆▆▆▃
wandb:      train/ensemble_f1 ▂▅▂▅▁▃▅▅▅▃▄▇▂▅▅▅▄▆▅▆▆▆▆▄▄▄▆▅▄▁▆▂▅▄▆█▅▂▄▂
wandb:         train/mil_loss ▅█▅▅▂▄▄▆▃▃▄▄▅▃▃█▄▃▂▂▅▃▂▅▅▂▂▃▆▃▁▁▄▃▃▃▂▃▁▃
wandb:      train/policy_loss ████████████████▃▅▂▂▂▄▂▃▂▃▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▁██████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.7842
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.74563
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.67627
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.47055
wandb:      train/ensemble_f1 0.47055
wandb:         train/mil_loss 0.73587
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b5s5cyhm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184907-b5s5cyhm/logs
wandb: Agent Starting Run: zq8mz4gq with config:
wandb: 	actor_learning_rate: 0.0006456381673049853
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1447706164320247
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4151620728586679
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185417-zq8mz4gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zq8mz4gq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▅▅▆▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▇▇▇▆▆▆▆▆▅▅▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▅▅▆▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▂▄▄▄▅▆▆▇▇▇▇▆▇▇▇▇▇█████████▇▇▇█████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▅▅▄▅▅▆▆▆▇▇▇▇▇██▇█▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▆▆▆▇▇▆▆▇▇▆▇▇▆▆▇▇▇█▆▇▇▇▇▇▇▆▇█▇▇█▆▇▆▇▇▆
wandb:      train/ensemble_f1 ▁▅▃▆▇▆█▇██▆▆▆▆▇▅▇▇▇▆▅▆▆▇▆▆▆█▇▆█▇▆▇▆▆▇▇▆█
wandb:         train/mil_loss ▇▄▅▄▇█▅▃█▃▆▄▆▇▄▃▂▄▅▅▄▃▄▃▃▄▄▂▅▃▂▅▄▅▂▄▃▁▄▂
wandb:      train/policy_loss ▅▅▄▅▅▅▄▇▅█▅▅▆▅▅▅▅▄▁▂▅▅▃▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▅▅▃▃▄▄▄▃▄▄▄▄▄▃▄█▁▄▆▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68474
wandb: best/eval_avg_mil_loss 0.69815
wandb:  best/eval_ensemble_f1 0.68474
wandb:            eval/avg_f1 0.6568
wandb:      eval/avg_mil_loss 0.67953
wandb:       eval/ensemble_f1 0.6568
wandb:            test/avg_f1 0.6834
wandb:      test/avg_mil_loss 0.69074
wandb:       test/ensemble_f1 0.6834
wandb:           train/avg_f1 0.656
wandb:      train/ensemble_f1 0.656
wandb:         train/mil_loss 0.61296
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7a7du3be
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184955-7a7du3be/logs
wandb: Agent Starting Run: 68a9ofqk with config:
wandb: 	actor_learning_rate: 0.0013451394513760064
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4570019112500533
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6701204891265979
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185506-68a9ofqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68a9ofqk
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▂▆▆▂▆▇▃▄▄▅▄▃▇▁▆█▇▅▆▄▅▇▆▆▅▄▃▆▄▃▃▇▇▂▄▇▅▄
wandb:      train/ensemble_f1 ▄▄▆▂▄▄▄▆▁▂▃▃▁█▃▇▅▆▃▅▂▄▄▅▂▄▂▃▃▄▃▅▄▁▂▆▆▄▄▃
wandb:         train/mil_loss ▅▆▇▆▃▄▇▆▅▄▃▆▄█▄▆▆▆▄▄▄▃▆▃▆▆▄▂▂▆▄▁▆▄▃▃▃▃▃▃
wandb:      train/policy_loss ▅▂▇▃▅▅▅▃▅▃▅▅▄▃▅▅▄▂▅▂▃█▆▁▅▄▅▅▂▃▃▅▃▃▂▅▄▄▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▆▄▄▁▅▆▃▇▇▆▃▆▃▇▆▁▆▇▂█▂▆▃▆▆▇▅▄▃▄▃▆▇▄▄▅▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.45493
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.30001
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.88139
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 1.28886
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zq8mz4gq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185417-zq8mz4gq/logs
wandb: Agent Starting Run: 4lc8xnlg with config:
wandb: 	actor_learning_rate: 0.0018566778088458676
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23340677030181556
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26463432501685324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185611-4lc8xnlg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lc8xnlg
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▆▇▆▅▇▇▆▅▆▃▁▇▅▆▅█▂▅▆▃▄▆▇▇▅▅█▇▅▄▄▇▅▅▂▇▇▆
wandb:      train/ensemble_f1 ▅▇▅▂▅▆▇▅▇▄▅▆▂█▅▅▂▇▄▃▁▄▄▇▆▆▅▃▂▄▅▄█▅▃▃▂▇▂▄
wandb:         train/mil_loss ▃▃▅▂▃▆▅▂▄▃▆▃▅▅▅▁▂▃▄▃▄▂▃█▄▄▇▄▅▄▂▄▃▅▅▃▃▃▃▆
wandb:      train/policy_loss ▆▄▆█▆▆▆▇▅▆█▇▇▅▇▄▇▁▄▇▄▅▄▄▅▇▄▅▇▇▃▅▅▅▂▅▆▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▇▆▆▆▂▄▆▄▆▂▄▇▅▂▁▄▇▅█▃▃▅▃▆▅▅▄▃▄▅▅▄▅▆▇▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.04007
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97644
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.16373
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 0.83809
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68a9ofqk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185506-68a9ofqk/logs
wandb: Agent Starting Run: aqpdeft2 with config:
wandb: 	actor_learning_rate: 0.0024798567780986262
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8293064242191021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9062893081750788
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185701-aqpdeft2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqpdeft2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▅▆▇▇█
wandb: best/eval_avg_mil_loss █▆▃▃▃▃▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▂▃▃▃▃▅▅▆▇▇▇██████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁▂▂▂▆▇▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▄▂▁▂▄▄▅▆▃▄▃▃▅▆▅▅▅▅▅▅▅▆▇▆▆██▅▇███████▇
wandb:      train/ensemble_f1 ▃▁▁▁▃▁▂▂▄▂▂▃▂▄▃▃▃▃▃▅▃▅▅▄▅▄▅▅▆▅▆▆▆█▇▇▆▇▆█
wandb:         train/mil_loss ▆█▇▇▇▅▆▇▄▄▅▃▆▆▄▄▄▅▄▃▁▅▃▃▂▂▂▂▁▃▂▄▄▂▂▃▃▁▂▃
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄██▆▅▅▄█▅▃▅▃▄▁▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 0.86588
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.74334
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.65278
wandb:      test/avg_mil_loss 0.63861
wandb:       test/ensemble_f1 0.65278
wandb:           train/avg_f1 0.69567
wandb:      train/ensemble_f1 0.69567
wandb:         train/mil_loss 0.71485
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2arrduce
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185230-2arrduce/logs
wandb: Agent Starting Run: a5kjh31s with config:
wandb: 	actor_learning_rate: 0.001687748770987614
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6586612256266992
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30229578955114855
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185806-a5kjh31s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5kjh31s
wandb: uploading history steps 651-663, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb: best/eval_avg_mil_loss ██▇▇▆▆▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████
wandb:            eval/avg_f1 ▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇███████████▇
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▆▆▆▆▆▇▇▇████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▃▄▃▂▃▃▄▄▄▄▄▅▄▅▅▅▆▆▆▇▆▇▇▆▆▇▇▇▆▇▆▆█▇▇█
wandb:      train/ensemble_f1 ▁▁▂▂▂▄▃▄▄▃▄▃▄▅▅▅▅▅▆▅▆▆█▇▆▇▇▇▇▆▇▇▇▇██▇▇██
wandb:         train/mil_loss ███▇▇▅▅▅▅▅▄▄▃▃▂▃▃▃▃▃▂▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁
wandb:      train/policy_loss ▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▂▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76605
wandb: best/eval_avg_mil_loss 0.43715
wandb:  best/eval_ensemble_f1 0.76605
wandb:            eval/avg_f1 0.73737
wandb:      eval/avg_mil_loss 0.39298
wandb:       eval/ensemble_f1 0.73737
wandb:            test/avg_f1 0.59984
wandb:      test/avg_mil_loss 0.62331
wandb:       test/ensemble_f1 0.59984
wandb:           train/avg_f1 0.6541
wandb:      train/ensemble_f1 0.6541
wandb:         train/mil_loss 0.66664
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ij0mwjc8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_184712-ij0mwjc8/logs
wandb: Agent Starting Run: bmt9al6h with config:
wandb: 	actor_learning_rate: 1.2411723135161155e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.001978953790475302
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5780185704404384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185917-bmt9al6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmt9al6h
wandb: uploading history steps 184-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▅▅▃▃▃▅▆▃▄▃▃▂▅▂▇▆▄▄▁▅█▄▆▅█▇▄▄▄▇▆▅▇▆█▅▂
wandb:      train/ensemble_f1 ▃▄▃▄▅▄▄▂▃▅▃▆▄▄▄▂▇▄▂▅▃▆▃▄█▃▆▅▅▄▆▅▆▁▇▆▅▅▃▅
wandb:         train/mil_loss ▇▆█▇▅▆▆▇▅▄▆▅▄▇▄▄▅▅▃▃▆▆▅▂▇▃▅▄▃▃▅▄▄▄▃▃▁▂▃▂
wandb:      train/policy_loss ██████████▃▂▅▆▁▂▂▃▃▃▁▃▃▃▂▃▅▃▂▄▃▃▃▃▃▃▃▄▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38558
wandb: best/eval_avg_mil_loss 0.94984
wandb:  best/eval_ensemble_f1 0.38558
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.85133
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.78978
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.42023
wandb:      train/ensemble_f1 0.42023
wandb:         train/mil_loss 0.88298
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4lc8xnlg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185611-4lc8xnlg/logs
wandb: Agent Starting Run: cp22uxow with config:
wandb: 	actor_learning_rate: 0.00015287158293811294
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8273550642884648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4350927361376268
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_185944-cp22uxow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cp22uxow
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▁▂▄▁▂▁▂▆▄▅▂▂▃▆▄█▆▅▅▇▅▆▇▇▇▃▆▆▅▄▅▆▄▇█▇▅▃
wandb:      train/ensemble_f1 ▅▃▄▃▃▄▄▄▃▁▄▄▃▅▂▅▅▆▇▃▆█▇▅▃▃▄▄▆▇▆▇▃▅▅▅██▇▄
wandb:         train/mil_loss ▅▅▄▅▄▂▇▇▄▃▇▄▅▄█▅▇▆▆▅▅▃▅▃▅▃▁▆▇▂▄▃▅▆▆▄▃▃▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 1.17752
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 1.01198
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.54667
wandb:      test/avg_mil_loss 0.91514
wandb:       test/ensemble_f1 0.54667
wandb:           train/avg_f1 0.55391
wandb:      train/ensemble_f1 0.55391
wandb:         train/mil_loss 0.88116
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a5kjh31s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185806-a5kjh31s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5hexgglr with config:
wandb: 	actor_learning_rate: 0.00012607101005213578
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16691588324716022
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5460204469509098
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190036-5hexgglr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5hexgglr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████
wandb:      eval/avg_mil_loss ██▇▆▆███▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ████▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▄▆▇▅█▅▄▄▆▆▆▆▆▆▆▄▃▄▅▅▃▃▆▆▆▄█▄▄▄▂▅▁▃▄▅▅▅
wandb:      train/ensemble_f1 ▃▄▇▄▅█▅▄▇▆▆▅▆▆▅▄▅▂▃▄▅▃▆▅▃▄▇▆█▃▅▁▅▃▅▆▅▄▃▄
wandb:         train/mil_loss ▅▆▅▄▃▄▆▃▆▅▄▅▅▅▆▅▄▄▃▄▄▅▃█▄▆▅▁▅▁▅▆▅▅▃▃▂▄▆▅
wandb:      train/policy_loss █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84
wandb: best/eval_avg_mil_loss 0.45717
wandb:  best/eval_ensemble_f1 0.84
wandb:            eval/avg_f1 0.83994
wandb:      eval/avg_mil_loss 0.44215
wandb:       eval/ensemble_f1 0.83994
wandb:            test/avg_f1 0.75845
wandb:      test/avg_mil_loss 0.53062
wandb:       test/ensemble_f1 0.75845
wandb:           train/avg_f1 0.75361
wandb:      train/ensemble_f1 0.75361
wandb:         train/mil_loss 0.55848
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bmt9al6h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185917-bmt9al6h/logs
wandb: Agent Starting Run: vwgiiwyk with config:
wandb: 	actor_learning_rate: 1.099917805763477e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.00906170147570795
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7470752206508356
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190111-vwgiiwyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vwgiiwyk
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▂▂▅▆▃▃▅▆▇▅▅▅▆▄▂▅▅█▅▄▁▂▁▅▅▅▄▆▃▅▄▅▆▇▄▆▃█
wandb:      train/ensemble_f1 ▂▃▄▆▆▄▇▅▅▅▇▄▆▂▅▆▄▁▂▅▂▁▃▅▅▄▆▇▆▃█▇▃▆▄▄▄▆▁█
wandb:         train/mil_loss ▅▃▅▃▄▇▅▅▄▄▂▂▅▆▃█▅▄▅▃▇▂▃▇▃▁▁▄▃▁▃▄▂▆▃▃▁▃▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.09885
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.05409
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.90382
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.44189
wandb:      train/ensemble_f1 0.44189
wandb:         train/mil_loss 0.73161
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cp22uxow
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185944-cp22uxow/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m414cnfu with config:
wandb: 	actor_learning_rate: 6.502760386036701e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3700906567203581
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1942536278102921
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190150-m414cnfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m414cnfu
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▆▄▅▄▃▅▆▇▄▁▃▅▇▅▆█▅▃▅█▆▄▆▂▃▆▅▅▄▅▂▅▅▅▂▁▂▆
wandb:      train/ensemble_f1 ▅▆▅▂▃▂▅▅▃▂▄▃▆▂▆▅▇▃▅▅▆▆▃▃▂▅▅▄▃▄▄▂▅▆▂▁▁▂▃█
wandb:         train/mil_loss ▅▆▆▅▅▇▃▄▇▄█▃▅▄▅▅▅▄▁▇▆▄▆▄▆▄▅▅▆▆▇▅▃▄▅▄▆▆▄▄
wandb:      train/policy_loss ▃▅▆▄▃▁▅▂▃▅▄▆▆▅▅▇▄▆▇▄▃▆▄▃▅▅▇█▅▄▂▆▄▅▃▄▅▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▃▆▅▆▄▃▇▆▇█▃▁▄▅█▇▃▄▃▃▃▅▃▂▃▆▂█▄▆▃▄▄▂▆▃▃▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97519
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95887
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.07801
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34156
wandb:      train/ensemble_f1 0.34156
wandb:         train/mil_loss 0.83381
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5hexgglr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190036-5hexgglr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bw7pfzpd with config:
wandb: 	actor_learning_rate: 0.003206679243097954
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.033520185764887245
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3714136321226617
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190236-bw7pfzpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bw7pfzpd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▅▅▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▅▅▅▆▆▆▆▇▇█▇▇▇▇▇▇▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▆▆▆▆▆▆▇▇▇███████████▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▃▃▄▁▅▄▃▃▇▄▇▃▂▆▂▇▅▄▅▅█▄▆▃▆▄▄▄▇▇▇▄▆▆▆▆▅
wandb:      train/ensemble_f1 ▂▂▃▅▁▃▂▅▃▃▄▄▅▅▆▅▅▅▇▄▄▄▄▆▂▂▄▆▇▆▄▆██▇▅▆▇▆▆
wandb:         train/mil_loss ▄▆▄▆▅▄█▅▄▃▃▄▆▂▆▅▁▇█▅▃▅▂▃▅▃▄▂▆▂▄▃█▂▃▆▄▁▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▇█▇▆▇▅▃▃▄▁▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.54743
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.80845
wandb:      eval/avg_mil_loss 0.53491
wandb:       eval/ensemble_f1 0.80845
wandb:            test/avg_f1 0.79733
wandb:      test/avg_mil_loss 0.47469
wandb:       test/ensemble_f1 0.79733
wandb:           train/avg_f1 0.78203
wandb:      train/ensemble_f1 0.78203
wandb:         train/mil_loss 0.53766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aqpdeft2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_185701-aqpdeft2/logs
wandb: Agent Starting Run: gcw89rnc with config:
wandb: 	actor_learning_rate: 0.0004670876628091509
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4267307291150949
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6715966988343863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190328-gcw89rnc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gcw89rnc
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▆▁▅▃▁▁▄▄▆▅▆▂▃▅▂▄▅▄▄▅█▅▂▃▃▄▃█▅▂▄▁▅▄█▆▃
wandb:      train/ensemble_f1 ▅▃▆▆▅▃▃▆▆▅▇▂█▄▆▆█▅▅█▅▆▅▁▃▄▅▄▄▄▄▅▆▆▆▃▆▅█▆
wandb:         train/mil_loss ██▅▆▅▄▇▅▄▅▇▅█▆▄▄▄▆▅▄▆▅▂▂▃▅▄▃▃▇▄▄▆▅▁▆▆▅▅▆
wandb:      train/policy_loss ▆▄▄▄▄▄▅▄▅▁▄▆▄▃▄▅▅▆▃▄▅▃▅▇▇▅▃▅▃▅▂▄▄▄█▅▃▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▅▄▄▆▅▄▅▃▄▂▄▇▅▄▄▆▇▅▅▅▁▇▃▅█▄▂▃▅▄▄▃▇▆▃▄▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.00186
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95761
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12433
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.82136
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run drawn-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m414cnfu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190150-m414cnfu/logs
wandb: Agent Starting Run: 6eywgjmm with config:
wandb: 	actor_learning_rate: 8.031909268713943e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9854114275330446
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1053732702750233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190345-6eywgjmm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6eywgjmm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▃▃▄▄▂▅▆▅█▅▆▁▅▄▂▅▆▅▆▅▄▅█▇▇▅▄▆▄▆▆▅▆▇▆▅▄▇
wandb:      train/ensemble_f1 ▄▃▅▁▃▅▆▄▆▃▆▆▆▅▆▆▂▆▄▅▇▇▅▇██▆▅█▅▅▆▆▅▅▆▅▇▇▆
wandb:         train/mil_loss █▆▅▆▄█▆▄▆▅▆▄▅▆▄▃▄▃▃▅▃█▅▆▂▁▄▅▄▆▇▂▄▅▇▂▂▅▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79475
wandb: best/eval_avg_mil_loss 0.67025
wandb:  best/eval_ensemble_f1 0.79475
wandb:            eval/avg_f1 0.79475
wandb:      eval/avg_mil_loss 0.60889
wandb:       eval/ensemble_f1 0.79475
wandb:            test/avg_f1 0.83623
wandb:      test/avg_mil_loss 0.48369
wandb:       test/ensemble_f1 0.83623
wandb:           train/avg_f1 0.83309
wandb:      train/ensemble_f1 0.83309
wandb:         train/mil_loss 0.68002
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bw7pfzpd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190236-bw7pfzpd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3osqk8ix with config:
wandb: 	actor_learning_rate: 0.00012601952099745896
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07763151126314916
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8531657884661732
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190437-3osqk8ix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3osqk8ix
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▇▇▄▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▂▄▄▄▂▂▄▂▃▂▂▂▁▄▄▅▅▅▅▇▇██▇▇▆▆▅▅▅▅▆▆▆▆▆▄▄▄
wandb:      eval/avg_mil_loss █▇▆▅▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▄▂▄▂▃▂▁▁▁▃▄▄▄▄▆▅██▇▇▆▆▅▅▅▅▆▇▆▆▆▆▆▆▅▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▅▄▄▅▅▅▆▆▃▃▃▄▅▅▄▄▅▅▆▇▄▅▅▇▆▇▆▇▇▇█▇▇▆▇▇▆
wandb:      train/ensemble_f1 ▁▁▂▂▄▄▃▃▄▅▄▅▆▂▄▁▂▂▄▃▂▄▅▅▇▅▆▆▇▅▆█▇▇▆█▇█▆▇
wandb:         train/mil_loss █▄▇▅▆▄▅▆▇▄▄▄▄▄▄▅▅▄▄▄▃▅▄▃▂▄▃▃▂▂▁▂▁▂▃▂▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62148
wandb: best/eval_avg_mil_loss 0.62719
wandb:  best/eval_ensemble_f1 0.62148
wandb:            eval/avg_f1 0.57729
wandb:      eval/avg_mil_loss 0.62377
wandb:       eval/ensemble_f1 0.57729
wandb:            test/avg_f1 0.66933
wandb:      test/avg_mil_loss 0.60231
wandb:       test/ensemble_f1 0.66933
wandb:           train/avg_f1 0.65213
wandb:      train/ensemble_f1 0.65213
wandb:         train/mil_loss 0.6211
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vwgiiwyk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190111-vwgiiwyk/logs
wandb: Agent Starting Run: kn9kyjhx with config:
wandb: 	actor_learning_rate: 0.005522849021658457
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.017943468137440854
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9992155142486814
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190521-kn9kyjhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kn9kyjhx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▂▄▄▃▄▂▇▄▁█▅▅▆▇▂▅▄▄▃█▂▃▆▄▅▄▅▁▁▂▄▆▇▅▂▃▅▆
wandb:      train/ensemble_f1 ▅▁▄▆▂▄▅▃█▆▄▅▇▆▅▃▆▃▅▆▅▅▄▂▃▄▁▂▄▆▃▆▂▆▆▄▅▆▆▇
wandb:         train/mil_loss ▅▂▂▂▃▁▂▃▂▁▃▅▁▁▇▃▃▃▃▄▂▂▂█▅▁▁▂▂▅▂▂▂▄▅▂▅▄▂▃
wandb:      train/policy_loss ▄███▁██▄████▁███████▁▅█▁█▄▄██████▅▁█████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄███████▁██▄█▄██▄██▅███████▄▄██▄▄██▅█▅██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.4369
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.41245
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.87028
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3448
wandb:      train/ensemble_f1 0.3448
wandb:         train/mil_loss 0.60709
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6eywgjmm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190345-6eywgjmm/logs
wandb: uploading history steps 115-127, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:      eval/avg_mil_loss █▇▇▇█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▁▁▁▁▂▁▂███▇█████▇█▇███████▇██████▇███
wandb:      train/ensemble_f1 ▁▁▁▁▂▁▁▂▂▁▇▇▇█▇█▇▇█▇█▇█▇█▇█▇▇█▇▇█▇▇▇▇▇█▇
wandb:         train/mil_loss ██▇▅▇█▆▇▁▂▂▂▃▂▂▂▃▂▁▂▃▂▃▃▂▃▂▃▂▃▂▃▂▃▃▃▁▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78998
wandb: best/eval_avg_mil_loss 0.5106
wandb:  best/eval_ensemble_f1 0.78998
wandb:            eval/avg_f1 0.76942
wandb:      eval/avg_mil_loss 0.4984
wandb:       eval/ensemble_f1 0.76942
wandb:            test/avg_f1 0.82609
wandb:      test/avg_mil_loss 0.62722
wandb:       test/ensemble_f1 0.82609
wandb:           train/avg_f1 0.8166
wandb:      train/ensemble_f1 0.8166
wandb:         train/mil_loss 0.51015
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gcw89rnc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190328-gcw89rnc/logs
wandb: Agent Starting Run: ulaum01h with config:
wandb: 	actor_learning_rate: 0.0035062870054958523
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0030584095582865123
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4801836160190833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190543-ulaum01h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ulaum01h
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jbkxgyvq with config:
wandb: 	actor_learning_rate: 5.921262223203261e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12214892735718176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.028213836221971267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190553-jbkxgyvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jbkxgyvq
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▃▃▂▅▅▄▃▃▃▅▇▅▃▁▄▃▅▄▂▅▇▃▃▆▅▆▆▆▆▅▂█▆▄▅▆▅▅
wandb:      train/ensemble_f1 ▄▃▅▃▃▃▇▄▅▅▇▂▁▃▄▄▃▃█▅▅▄▅▇▆▆▄▅▅▄▆▅▆▄▇▆▄▆▅▄
wandb:         train/mil_loss █▅▃▇▄▇▄▅▅▄▄▅▆▅▆▅▄▅▆▁▅▅▇▅▆▄▅▅▂▅▆▅▄▆▄▆▆▄▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.00906
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.93175
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.81297
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.39952
wandb:      train/ensemble_f1 0.39952
wandb:         train/mil_loss 0.97766
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3osqk8ix
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190437-3osqk8ix/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k1x0yh3w with config:
wandb: 	actor_learning_rate: 5.531424076598046e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2494210434164864
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.563461572996085
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190658-k1x0yh3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1x0yh3w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▆▅▆▆▇▇▄▅▅▅▅▆▆▆▆▅▂▅▄▁▅▂▃▅▇▅▇▇█▆█▄▇▄▂█▆
wandb:      train/ensemble_f1 ▇▃▂▃▆█▂▇▆▇▄▅▄▂▄▅▆▅▅▅▆▅▃▅▄▄▁▁▂▃▄▄▇▆▆▅█▇▃▅
wandb:         train/mil_loss ▃█▅▇▆█▅▇▅▄▄▄▄▇▁▅▆▃▄▆▁▁▅▆▂▃▅▃▂▅▃▄▃▂▅▄▄▃▃▂
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.31995
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.12823
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.6918
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33601
wandb:      train/ensemble_f1 0.33601
wandb:         train/mil_loss 1.09754
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kn9kyjhx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190521-kn9kyjhx/logs
wandb: Agent Starting Run: x8m65svi with config:
wandb: 	actor_learning_rate: 1.1166223323875785e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1168186168233556
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6829226278346919
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190714-x8m65svi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x8m65svi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆▇▇█▇▇▇▂▁▁▁▁▂▂▁▁▁▂▁▂▁▁▂▁▂▁▁▁▁▂▂▂▁▁▂▁▁▁
wandb:      train/ensemble_f1 ▇█▆█▇█▇▂▁▂▁▂▁▂▂▂▂▁▂▂▂▂▁▁▂▁▂▁▂▂▂▁▂▂▁▂▂▂▁▁
wandb:         train/mil_loss ▂▂▂▁▂▁▂▇▇▆▇▇▇▇▇▇▆▆▆▆▇▆▆▆▆▅▇▆▆▇▇▆█▆▅▆▇▅▅▆
wandb:      train/policy_loss ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45907
wandb: best/eval_avg_mil_loss 0.88607
wandb:  best/eval_ensemble_f1 0.45907
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.50206
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.75818
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.32489
wandb:      train/ensemble_f1 0.32489
wandb:         train/mil_loss 1.64573
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ulaum01h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190543-ulaum01h/logs
wandb: Agent Starting Run: gqzbkdkl with config:
wandb: 	actor_learning_rate: 1.8382002429527795e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8032597900410815
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16649395753481266
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190737-gqzbkdkl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqzbkdkl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▅▄▄▂▂▂▅▃▃▅▆▅▄▂▅▆▂█▄▄▇▆▆▃▅▄▇▄▆▇▇▁▃▆▁▁▄▆
wandb:      train/ensemble_f1 ▇▄▆▅▅▅▄▃▃▅▄▇▆▇▅▆▃▄▃▇▆▁▆▆▇▃█▅▄▇▄▇▂▄▇▅▅▆▇▅
wandb:         train/mil_loss ▆█▅█▇▆▅▆▆▄▅█▅▅▆▆▆▄▆▄▅▅▅▄▄▆▁▄▄▅▅▂▃▄▄▄▄▄▂▃
wandb:      train/policy_loss ▆▃█▃▅▇▃▃▆▇▃▃▃▃▃▃▇▃▂▂▄▂▄▃▄▂▃▆█▃▁▂▃▇▄▃▆▆▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄█▄█▁▅▄▄█▇▂▄▄▅▅▅▄▄▄▅▅▂▅▄▅▁▂▇▇▄▂▄▂██▇▇▅▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01879
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.88943
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.11857
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.87576
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jbkxgyvq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190553-jbkxgyvq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yslr29mk with config:
wandb: 	actor_learning_rate: 0.0018674833817235825
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7181098689174812
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2977977322299141
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190752-yslr29mk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yslr29mk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▅▆▄▁▄▄▃▇▅▃▆▇▃▃▅▄▂▃▅▅▅▄▅▆▅▂▄▂▇▄▅▄▅▅▅█▇
wandb:      train/ensemble_f1 ▂▅▁▄▂▆▅▆█▅▇▇▆▅█▄▅▅▄▆▄▅▅▆▅▅▆█▃▄▂█▄▄▅▃▅▆▃▇
wandb:         train/mil_loss ▇▆▅▇▆▅▅▃█▅▃▄▅▅▆▄▂█▆▄▆▄▆▄▄▁▁▆▅▃▇▅▅▆▂▂▃▆▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.01548
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.92705
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.81264
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.41486
wandb:      train/ensemble_f1 0.41486
wandb:         train/mil_loss 0.84748
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k1x0yh3w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190658-k1x0yh3w/logs
wandb: Agent Starting Run: w8xwf288 with config:
wandb: 	actor_learning_rate: 0.0032970735060530837
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8737386818172516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25036631965029443
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190851-w8xwf288
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8xwf288
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄█▇▇▄▃▅▃█▄▇█▃▆▆▃▅▃▃▅▄▄▇▁▆▆▅▃▄▄▅▅▇██▄▂▄▅
wandb:      train/ensemble_f1 ▆▃▆▄▅▆▂▅▆▄▅▃▄▅▂▆▄█▁▅▅▄▃▄▃▃▅▅▅▂▅▂▃▆▆▂▃▂▃▄
wandb:         train/mil_loss ▃██▆▇▆▅▆▇▁█▅▃▆▇▆▆▅▅▅▆▄▅▁▄▅▃▄▄▃▅▂▄▁▄▂▄▃▃▂
wandb:      train/policy_loss ▁▄▁▁▃▅▅▃▃▆▃▂▃▃▄▂▇▂▅▂▂▃▄▅▆▄▅▂▃▅▂▄▃█▃▃▄▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▅▅▃▃▃█▆▅▂▁▅▄▄▆▃▅▇▂▃▄▄▁▃▃▃▃▆▃█▃▄▄▂▃▄▅▁▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.4276
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.19063
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.77728
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 1.09168
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x8m65svi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190714-x8m65svi/logs
wandb: Agent Starting Run: totw8qiw with config:
wandb: 	actor_learning_rate: 0.001718708240869025
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.038733944452415736
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7173201611629303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190908-totw8qiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/totw8qiw
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▄▂█▆▄▄▂▃▇▅▇▇▆▂▆▂▅▁▅▆█▂▆▇▃▆▆▅▂▇▅▁▇▅▆▅▂█
wandb:      train/ensemble_f1 ▇▄▃▇▆▄▃▅▅▇▁▄▆▇▃▄▂▅▅▄▃▄▆█▅▃▁▅▄▅▇▆▃▆▆▅▃▂▃▇
wandb:         train/mil_loss ▄▄▄▁▅▆▇▅▄▄▄▆▃▄▅▁▆▄█▄▆▆▆▆▆▄▅▅▆▇▇▅▄▃▄▄▇▄▄▄
wandb:      train/policy_loss ▃▆▆▄▂▃▅▆▄▆▃▅▅▄▅▃▅▃▃▁▅▃▅▄▅▆▄▂▅▄▄▇▃▅▅█▅▅▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▄▃▁▄▆█▃▅▅▄▅▆▂▅▂▅▂▅▄▇▅▅▄▇▇▅▂▃█▃▅▃▄▃▆▅▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.88512
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.84165
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.76289
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.50647
wandb:      train/ensemble_f1 0.50647
wandb:         train/mil_loss 0.65189
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gqzbkdkl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190737-gqzbkdkl/logs
wandb: Agent Starting Run: q16xtskg with config:
wandb: 	actor_learning_rate: 0.001236304969112542
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5180019568833404
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2081843749984076
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190937-q16xtskg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q16xtskg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▁████████████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▂▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁
wandb:      train/ensemble_f1 ▆█▅▃▁▇▅▄▄▆▄▅▃▄▄▄▃▅▅▆▆▄▃▄▂▄▄▃▅▃▂▄▄▆▂▆▄▂▃▂
wandb:         train/mil_loss ▁▄▇▇▆▄▅▄▃▅▂▆▂▆██▃▅▆▃▅▆▃▆▃▄▅▂▆▅▄▆▅▅▅▃▃▂▃▅
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▆█▅▇▆▅▃▅▅▅▆▃▄▅▇▅▅▅▃▄▅▅▁▄▅▆▄▃▅▆▅█▇▅▇▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68166
wandb: best/eval_avg_mil_loss 0.70641
wandb:  best/eval_ensemble_f1 0.68166
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99577
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.71035
wandb:      test/avg_mil_loss 0.72039
wandb:       test/ensemble_f1 0.71035
wandb:           train/avg_f1 0.32375
wandb:      train/ensemble_f1 0.32375
wandb:         train/mil_loss 0.70439
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yslr29mk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190752-yslr29mk/logs
wandb: Agent Starting Run: dmwltl6o with config:
wandb: 	actor_learning_rate: 1.117406618666379e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.457185466368528
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6746132164873446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_190946-dmwltl6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmwltl6o
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▂▄▂▅▁▇▆▄▅▃▃▃▁▅▆▅▆▆▆▄▆▆▃▄▄▄▆▅▄▅▆▅▅▃▄█▆
wandb:      train/ensemble_f1 ▂▁▇▄▄█▆▄▅▃▃▃▅▆▄█▆▄▃▅▇▅▃▇▅▂▃▄▃▄▇▆▅▄▅▄▇▂▄▇
wandb:         train/mil_loss ▇▂▂▄▂▄▅▂▃▄▅▆▆▂▃▄▅▆▃▃▄█▆▁▄▃▅▃▂▅▅▆▁▅▂▅▄▄▃▃
wandb:      train/policy_loss ▇▆▅▆▂▂▅▇▅▆▃▆▃▄▄▇▃▅▃▆▅▃▄▅▁▅▇▅▇▅▃▄█▇▅▄▅▄▄█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▁▅█▅█▅▄▂▂▇▁▂▄▇█▂▅▂▇▄▅▇▅▄▅█▅███▇█▄▅▇▂▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01042
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.00149
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12209
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3383
wandb:      train/ensemble_f1 0.3383
wandb:         train/mil_loss 0.60215
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w8xwf288
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190851-w8xwf288/logs
wandb: Agent Starting Run: kmgypt95 with config:
wandb: 	actor_learning_rate: 0.0003501436849973986
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3672970701228372
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4731519568604504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191046-kmgypt95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kmgypt95
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▁▅▁▃▂▃▃▁▅▃▃▂▃▄▄▃▄▇▃▇▅▃▃▅▄▄▂▅▅▄▅▅▆▆▃▁▆█
wandb:      train/ensemble_f1 ▃▃▅▃▂▄▃▃▅▇▅▅▄▅▅▄▃▄▃▃▆▃▆▅▃▄▅▅▂▃▁▇▆▃▅▃▃▆▆█
wandb:         train/mil_loss ▄▆█▄▇▆▇▆▅▄▆▄▆▅▇▅▅▅▅▅▃▄▇▅▅▅▆▃▅▁▂▃▄▃▆▃▆▄▅▁
wandb:      train/policy_loss █▁█▄▄▄█▁██▄██▁▄▅▁▁█▁▁██▅█▁▅▁▁▁▁█▁▁▁▅█▅▁▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▃▃▃▁▆▃▆▆▁▁▆█▃▁▁▃▁▃▃▁▆▃▁▆▃▃▆▆▁▁█▁▃▆▁▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.43836
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.26443
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.59086
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.35275
wandb:      train/ensemble_f1 0.35275
wandb:         train/mil_loss 1.15767
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/totw8qiw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190908-totw8qiw/logs
wandb: Agent Starting Run: ox6djpem with config:
wandb: 	actor_learning_rate: 0.00038042782413676
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.32165123074773405
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11534883749033288
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191103-ox6djpem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ox6djpem
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▃▄▅▅▅▆▇█
wandb: best/eval_avg_mil_loss ███▄▃▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▃▄▅▅▅▆▇█
wandb:            eval/avg_f1 ▂▁▁▂▃▄▆▇▇█▇▇▇▇▆▆▆▇███████████████▇▇█████
wandb:      eval/avg_mil_loss █▆▆▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▂▁▁▃▃▃▄▅▄▇▇▇▇▆▆▇▇████████████████▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▃▁▅▆▃▃▅▂▄▃▅▅▆▅▆▆▅▃▆▂▃▆▇▆▆▇▇▅▅█▇▅▃▆▄▅
wandb:      train/ensemble_f1 ▃▃▁▂▃▄▅▄▅▃▆▆▅▇▅▆▇▇▃▄▇▇▅▄▆▆▇▆▆██▇▆▃▅▃▇▅▄█
wandb:         train/mil_loss ▄▆▅▇▆▇▃▄▇▃▁▅▃▅▄▆▄▅▃▄▂▁▃▅▅▄█▂▃▆▅▂▂▁▅▅▃▃▅▃
wandb:      train/policy_loss ▅▂▅▅▅█▅▁▅▅█▅▅▅▅▇▅▁▅▅▇▅▅▅▅▅▅▅▅▅▇▅▅▅▅▆▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▁▅▂▂▅▅▅▅▅▅▅▅▅▅▇▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▇▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59984
wandb: best/eval_avg_mil_loss 0.61602
wandb:  best/eval_ensemble_f1 0.59984
wandb:            eval/avg_f1 0.59742
wandb:      eval/avg_mil_loss 0.5844
wandb:       eval/ensemble_f1 0.59742
wandb:            test/avg_f1 0.54598
wandb:      test/avg_mil_loss 0.68905
wandb:       test/ensemble_f1 0.54598
wandb:           train/avg_f1 0.56818
wandb:      train/ensemble_f1 0.56818
wandb:         train/mil_loss 0.62091
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmwltl6o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190946-dmwltl6o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: eu5asn91 with config:
wandb: 	actor_learning_rate: 1.918009982166434e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41497408135538105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6077183877571588
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191216-eu5asn91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eu5asn91
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▆▇▇▇███████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █████▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇██▇█▁▃▂▂▂▂▂▃▁▃▂▂▁▃▂▂▂▃▂▂▂▂▂▂▂▃▂▂▃▂▂▂▂▃▂
wandb:      train/ensemble_f1 ▇█▇█▇██▇▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▁▁▂▂▁▂▂▁▂▂▂▁▁▂▁▂▂
wandb:         train/mil_loss ▂▁▃▆▆▆▆▅▅█▇▅▇▆█▆▄▇▆▆▆▆▆▇▆▅▆▆▄▇▇▆▄▇█▅▆▆▄▇
wandb:      train/policy_loss █████▅▄▅▅▄▇▄▄▁▃▂▅▃▅▂▇▆▄▆▃▁▅▁▆▄▄▃▄▄▇▆▅▄▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▅▄▅▅▄▄▅▅▂▄▇▆▆▄▃▅▁▁▆▆▄▄▄▄▅▄▅▅▅▄▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.41654
wandb: best/eval_avg_mil_loss 0.89048
wandb:  best/eval_ensemble_f1 0.41654
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.6525
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.40659
wandb:      test/avg_mil_loss 1.17003
wandb:       test/ensemble_f1 0.40659
wandb:           train/avg_f1 0.32489
wandb:      train/ensemble_f1 0.32489
wandb:         train/mil_loss 1.65776
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ox6djpem
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191103-ox6djpem/logs
wandb: Agent Starting Run: 06uersla with config:
wandb: 	actor_learning_rate: 7.604937359862944e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8783994091245486
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19279649192178216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191257-06uersla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06uersla
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▅▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████▇▇▇▇▇▇▇▇▇▇▇▇▇▅▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▂▁▂▂▁▄▃▃▄▆▃▅▅▅▆▄▄▄▇▅▅▇▇▄▄▆▄▃█▄▇▆▄▆▅▇▅
wandb:      train/ensemble_f1 ▃▁▂▄▃▃▁▃▄▆▁▃▅▂▅▆▃▃▂▄▇▆▆▃▆▄▃▇▅▆▄▇▇▆▃▃▄▅▅█
wandb:         train/mil_loss ▇▇▄▁▆▄▄▂▃▇█▃▆▅▃▂█▂▁▆▆▅▆▄█▄▃▄▆▂▁▃█▃▂▆▃▄▂▃
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▇▆█▅▃▂▁▂▄▂▂▃▂▆▇▅▆▇███▆▇▆▇▆▆▇█▆▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47246
wandb: best/eval_avg_mil_loss 0.73991
wandb:  best/eval_ensemble_f1 0.47246
wandb:            eval/avg_f1 0.46928
wandb:      eval/avg_mil_loss 0.73167
wandb:       eval/ensemble_f1 0.46928
wandb:            test/avg_f1 0.29889
wandb:      test/avg_mil_loss 0.78013
wandb:       test/ensemble_f1 0.29889
wandb:           train/avg_f1 0.42574
wandb:      train/ensemble_f1 0.42574
wandb:         train/mil_loss 0.6661
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kmgypt95
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191046-kmgypt95/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oyxvu18u with config:
wandb: 	actor_learning_rate: 0.00770721544854592
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14923143287405538
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08812162781848343
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191321-oyxvu18u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oyxvu18u
wandb: uploading history steps 100-108, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅█▅▆▆▃▃▃▃▃▃▃▃▆▆▆▆▆▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆
wandb:      eval/avg_mil_loss █████▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇▇▇▄▄▄▄▄▄▄▄▄▄███▄▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▄▃▂▄▁▅▂▅▆▃▆▃▇▆▃▃▆█▁▂▄▄▁▂▇▃▄▄▆▅▅▄▄▄▄▅▅▇
wandb:      train/ensemble_f1 ▁▃▅▂▁▃▆▄▄▅▆▄▆▆▄▅▄▇▆▅▆▅▅▅▄▅▆▅▇▆▄▆▅▅▅▅▆▆▆█
wandb:         train/mil_loss ▇▃▇█▇▅▅▄▅▄▄▄█▂▂▇▅▆▂▆▄▆▇▄▄▅▂▄▄▃▇▃▄▂▄▄▃▃▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▄▄▄▄▄▅▅▄▄▄▄▄▄▂▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▇▅▇█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8164
wandb: best/eval_avg_mil_loss 0.4973
wandb:  best/eval_ensemble_f1 0.8164
wandb:            eval/avg_f1 0.80906
wandb:      eval/avg_mil_loss 0.41096
wandb:       eval/ensemble_f1 0.80906
wandb:            test/avg_f1 0.79947
wandb:      test/avg_mil_loss 0.57457
wandb:       test/ensemble_f1 0.79947
wandb:           train/avg_f1 0.84963
wandb:      train/ensemble_f1 0.84963
wandb:         train/mil_loss 0.51219
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eu5asn91
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191216-eu5asn91/logs
wandb: Agent Starting Run: k7dktf20 with config:
wandb: 	actor_learning_rate: 0.002411761678443894
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3390747765534431
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8346700916159702
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191416-k7dktf20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k7dktf20
wandb: uploading history steps 113-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▆█
wandb: best/eval_avg_mil_loss █▆▅▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▆█
wandb:            eval/avg_f1 ▁▆███████████████▆██▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▄▄▄▆███▆▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▁▂▄▄▂▅▆▃▄█▅▄▄▃▇▃▅▄▄▆▆▅▆▅▆▅▇▆█▅▄▄▆▆▄▅▆
wandb:      train/ensemble_f1 ▁▃▃▃▃▅▇▄▂▃▃▄█▄▄▃▄▃▃▃▅▃▃▅▆▃▅▇▆▇█▆█▅▄▅▄▆▇▅
wandb:         train/mil_loss ▆▅▅▇█▅▃▇▆▄▅▃▄▁▂█▃▃▄▆▂▄█▅▇▂▇▄▇▅▅▇▂▆▁▄▅▄▃▆
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47917
wandb: best/eval_avg_mil_loss 0.93152
wandb:  best/eval_ensemble_f1 0.47917
wandb:            eval/avg_f1 0.43574
wandb:      eval/avg_mil_loss 0.8974
wandb:       eval/ensemble_f1 0.43574
wandb:            test/avg_f1 0.40257
wandb:      test/avg_mil_loss 1.04203
wandb:       test/ensemble_f1 0.40257
wandb:           train/avg_f1 0.41781
wandb:      train/ensemble_f1 0.41781
wandb:         train/mil_loss 0.57458
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/06uersla
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191257-06uersla/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▁▁█
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▆▅▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▇█▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁█▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss █▃▃▄▂▄▆▂▁▃▂▂▄▅▄▃▄▂▂▁▃▄▄▄▄▄▄▄▂▂▄▅▅▃▃▂▂▃▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▃▃▂▁▆▂▃▂▃▂▂▅▂▃▄▃▄▁▄▂▄▄▄▄▃▃▄▃▄▃▄▄▄▅▄▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79871
wandb: best/eval_avg_mil_loss 0.97682
wandb:  best/eval_ensemble_f1 0.79871
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96382
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.83974
wandb:      test/avg_mil_loss 1.95748
wandb:       test/ensemble_f1 0.83974
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 0.82081
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oyxvu18u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191321-oyxvu18u/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: 57y9lin6 with config:
wandb: 	actor_learning_rate: 8.207959058455977e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6718145001259536
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3276713872123216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191520-57y9lin6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57y9lin6
wandb: Job received.
wandb: Agent Starting Run: xga1l6zg with config:
wandb: 	actor_learning_rate: 4.754341790374748e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5503696653260667
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19136837525883332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191523-xga1l6zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xga1l6zg
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▃▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:       eval/ensemble_f1 █▁▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▃▄▄▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:      train/ensemble_f1 █▃▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁█▂▂▅▄▃▂▄▅▄▃▃▄▃▄▄▄▄▄▃▄▃▄▂▃▃▄▃▄▃▃▃▄▃▃▃▄▃
wandb:      train/policy_loss █▁█▇████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59839
wandb: best/eval_avg_mil_loss 0.66049
wandb:  best/eval_ensemble_f1 0.59839
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97748
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.69662
wandb:      test/avg_mil_loss 0.59751
wandb:       test/ensemble_f1 0.69662
wandb:           train/avg_f1 0.33939
wandb:      train/ensemble_f1 0.33939
wandb:         train/mil_loss 0.78879
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k7dktf20
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191416-k7dktf20/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8kdhxr5r with config:
wandb: 	actor_learning_rate: 0.00022438344721743437
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7711851625996868
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11970663430610584
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191630-8kdhxr5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kdhxr5r
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▇▇▇▆▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▄▄▃▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ██▇▇▇▇▇▇▇▇▆▆▅▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇█▇█▇▇▆▇▅▅▆▅▅▄▄▃▂▂▂▂▃▂▃▃▂▂▁▂▂▁▃▂▂▂▁▂▂▃
wandb:      train/ensemble_f1 ▇▇▇█▇▇▆▆▅▆▅▃▄▄▄▄▃▄▃▄▃▂▂▃▂▂▃▁▃▃▃▃▂▂▃▂▃▂▃▃
wandb:         train/mil_loss ▃▄▅▅▇▆▄▄▅▅▆▃▅▅▄▃▆▄▇▇▆▄▅▃▅▆▃▇▆▃▅▃▇▃▂▆█▁▃▄
wandb:      train/policy_loss ▄▄▂▄▄▄▄▄▁▄▃█▄▆▆▄▄▄▄▄▄▄▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▂█████████▁█████▇█████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.59503
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.6397
wandb:      eval/avg_mil_loss 0.58033
wandb:       eval/ensemble_f1 0.6397
wandb:            test/avg_f1 0.71945
wandb:      test/avg_mil_loss 0.61079
wandb:       test/ensemble_f1 0.71945
wandb:           train/avg_f1 0.62969
wandb:      train/ensemble_f1 0.62969
wandb:         train/mil_loss 0.60401
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xga1l6zg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191523-xga1l6zg/logs
wandb: Agent Starting Run: suwomj6p with config:
wandb: 	actor_learning_rate: 0.0029749644416617502
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8060758169199188
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6574269883397478
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191716-suwomj6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/suwomj6p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▆▇█
wandb: best/eval_avg_mil_loss █▆▆▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▄▄▄▅▄▄▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▂▄▄▄▄▅▅▄▄▆▆▆▆▆▆▆▆▆▇▇▇██▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▆▇▄▆▄▆▅▄▃▇▃▄▆▂▅▅▃▃▄▁▇▂▄▄▁▆█▆▄▅▄▅▆▄▇▃▄▅
wandb:      train/ensemble_f1 ▅▆▆▅▄▃▃▆▃▆▅▆▃▅▂▇█▅▆▅▆▄▆▂▄▆▃▆▇▅▆▆▆▇▄▁▄▅▅▅
wandb:         train/mil_loss █▅▃▂▆▄▄▃▆▃▇▅▄▅▃▁▆▂▅▄▂▄▅▆▄▂▃▂▄▁▄▅▃▃▁▂▃▁▃▃
wandb:      train/policy_loss ▁▁▁▃█▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56234
wandb: best/eval_avg_mil_loss 0.6007
wandb:  best/eval_ensemble_f1 0.56234
wandb:            eval/avg_f1 0.55437
wandb:      eval/avg_mil_loss 0.57794
wandb:       eval/ensemble_f1 0.55437
wandb:            test/avg_f1 0.49942
wandb:      test/avg_mil_loss 0.60967
wandb:       test/ensemble_f1 0.49942
wandb:           train/avg_f1 0.48603
wandb:      train/ensemble_f1 0.48603
wandb:         train/mil_loss 0.72302
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q16xtskg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_190937-q16xtskg/logs
wandb: Agent Starting Run: rpwzkalj with config:
wandb: 	actor_learning_rate: 1.3573252895613476e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10631256711375248
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04762116960583096
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191723-rpwzkalj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rpwzkalj
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▁▄▁▃▄▄▅▄▅▅▇▄▇▅▅▄▅▆▇▂▆▄▅▄▂▆▆█▅▄▇▅█▅▅▅▅
wandb:      train/ensemble_f1 ▆▅▇▅▃▃▄▄▅▆▄▆▆▆▆▄▆█▅▁█▆▆▄▇▆▃▇▇▅█▇▅▅▆▄▇▅▅▇
wandb:         train/mil_loss ██▆▆▅▇▅▅▆▅▅▂▂▅█▄▇▂▄▄▅▂▃▆▂▂▁▄▇▂▄▆▂▄▄▇▃▅▂▁
wandb:      train/policy_loss ▆▄▃▂▂▃▄▁▄▄█▃▂▆▆▃▆▄▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▇▆▁▄▄▅▂█▄▃▆▄▄▅▅▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.85877
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.77263
wandb:      eval/avg_mil_loss 0.77924
wandb:       eval/ensemble_f1 0.77263
wandb:            test/avg_f1 0.78348
wandb:      test/avg_mil_loss 0.61098
wandb:       test/ensemble_f1 0.78348
wandb:           train/avg_f1 0.79681
wandb:      train/ensemble_f1 0.79681
wandb:         train/mil_loss 0.59939
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run feasible-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/57y9lin6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191520-57y9lin6/logs
wandb: Agent Starting Run: w9gwdrup with config:
wandb: 	actor_learning_rate: 0.0009418143658863252
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19276828608207297
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13527584638764323
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191816-w9gwdrup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w9gwdrup
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▂▅▅▇▆▅▂▄▅█▅▄█▆▅▇▅█▃▅▅▇▃▃▅▁▅▁▆▃▄▅▆▄▆▃▃
wandb:      train/ensemble_f1 ▄▄▅▅▃▆▆▅▇▃▃▅▃▇▅▅▃▅▆▆▅▅▄▃▂▃▅█▅▆▃▁▄▄▅▃▄▃▂▅
wandb:         train/mil_loss ▄▅█▅▃▄▇▅▄▅▅▅▅▃▃▄▆▄▅▃▆▆▆▃▆▄▂▃▄▄▄▅▅▄▆▁▄▃▂▄
wandb:      train/policy_loss ▇▂▇▅▂▃▃▁▇▃▃▆▃▂▆▂▅▃▃▆▃▆▃▁▅▃▅▃▃▁▃▁▅▁▂▃▆▂█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▁▂█▃▁▃▇▃▆▃▇▁▄▃▂▃▃▃▃▄▅▃▃▃▁▇▄▆▁▃▁▂▃▃▆▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.61753
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.47491
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.04239
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32489
wandb:      train/ensemble_f1 0.32489
wandb:         train/mil_loss 1.57473
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rpwzkalj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191723-rpwzkalj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pmmc6st2 with config:
wandb: 	actor_learning_rate: 0.003184984036764747
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7780751042441685
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4800307569450277
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_191946-pmmc6st2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pmmc6st2
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▅▇█
wandb: best/eval_avg_mil_loss ██▄▁▁
wandb:  best/eval_ensemble_f1 ▁▄▅▇█
wandb:            eval/avg_f1 ▁▄▄▄▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▆▅▅▃▅▅▅▅▅▆▆▅█
wandb:      eval/avg_mil_loss ███▇█▇▆▇▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▅▄▄▅▅▅▅▅▅▅█▅▆▆▇▅▅▅▅▅▃▅▅▅▅▅▅▅▇▆▅█▅▆▆█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▂▄▂▅▃▂▆▁▅▃▇▄▆▆▅▄▄█▄▇▇▄▆▄▇▄▄▅▆▇▆▄▇▄▇▅▃▄
wandb:      train/ensemble_f1 ▁▄▄▄▃▆▄▄▅▃▄▅▆▂▄▅▆▅▄▆▆▄▆▄▅▇▄▆▅▇▅▅▅▄▅▆█▄▆▅
wandb:         train/mil_loss ▆▅▅▁▇▂▄▃▅▆▂▅▅█▅▇▃▂▄▆▆▃▄▁▃▂▅▄▃▇▂▆▃▅▇▆▆▆▅▄
wandb:      train/policy_loss ▄▄▄▄▆▃▄▄▃▃▄▄▄▅▄▄▄▄▄▄▄▄▄▂▆▄▄▄▆▄▄▇▁▃█▆▅▄▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▃▂▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▂▄▄▄▄▄▂▄▄▄▄▇▄▄█▄▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.41099
wandb: best/eval_avg_mil_loss 0.99335
wandb:  best/eval_ensemble_f1 0.41099
wandb:            eval/avg_f1 0.41099
wandb:      eval/avg_mil_loss 0.96594
wandb:       eval/ensemble_f1 0.41099
wandb:            test/avg_f1 0.50715
wandb:      test/avg_mil_loss 0.77045
wandb:       test/ensemble_f1 0.50715
wandb:           train/avg_f1 0.48069
wandb:      train/ensemble_f1 0.48069
wandb:         train/mil_loss 0.62591
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8kdhxr5r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191630-8kdhxr5r/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂█▃▃█▂▃▄▄▄▅▆▆▃▃▄▆▃▄█▃▄▄▃▇▇▅▄▅▃▃▄▂▁▆▃▃▄▂▄
wandb:      train/ensemble_f1 ▂▂█▄▃▆▃▅▅▄▅▄▅▁▄▄▅█▄▆▂▄▄▄▄▃▃▃▅▁▄▃▂▁▃▄▄▅▇▄
wandb:         train/mil_loss ▄▇▄▅▆▆▅▄▃▅▅▇█▄▇▂▃▅▃▅▄▅▁▆▃▃▃▃▄▅▃▅▂▂▃▂▂▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.68469
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.65866
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.47917
wandb:      test/avg_mil_loss 0.60334
wandb:       test/ensemble_f1 0.47917
wandb:           train/avg_f1 0.4848
wandb:      train/ensemble_f1 0.4848
wandb:         train/mil_loss 0.71409
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w9gwdrup
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191816-w9gwdrup/logs
wandb: Agent Starting Run: o41q9zwr with config:
wandb: 	actor_learning_rate: 0.00027008945319098707
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9866768547413952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9809502554630992
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192012-o41q9zwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o41q9zwr
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tmhqu495 with config:
wandb: 	actor_learning_rate: 1.4862350920882818e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7040115116646267
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8720821807586308
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192021-tmhqu495
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmhqu495
wandb: uploading history steps 98-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▃▃▇█▅▅▃▆▇▁▅▆▅█▅▃▇▇▄▃▄▄▇▄▇▆▅▅▃▄▅▅▆▄▅▆▅
wandb:      train/ensemble_f1 ▃▅▄▁▄██▃▅▅▄▂▇▃▅▆▄▇█▃▄▄█▁▄▇█▅█▄▄▃▅▅▄▄▅▅▆▃
wandb:         train/mil_loss ▄▄▁█▃▁▅▄▃▄▅▃▆▄▆▅▂▃▅▃▆▅▄▅▇▂▅▂▃▅▄▃▅▅▅▃▄▆▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.09805
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04136
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.90145
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40313
wandb:      train/ensemble_f1 0.40313
wandb:         train/mil_loss 0.73676
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pmmc6st2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191946-pmmc6st2/logs
wandb: Agent Starting Run: a7zgmi94 with config:
wandb: 	actor_learning_rate: 0.0016611871442921246
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.007836661457842786
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09251138340004916
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192140-a7zgmi94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a7zgmi94
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆█
wandb: best/eval_avg_mil_loss █▆▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▅▅▅▅▅▅▅▅████████████
wandb:      eval/avg_mil_loss ██████████▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▃▃▃▃▃▁▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▅▅▅▅█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▂▂▅▃▃▃▂▄▃▄▅▄▆▄▄▅▆▆▅▆▃▆▇▇█▆▅▇▇▆▆█▆▇▇█▇
wandb:      train/ensemble_f1 ▁▃▂▁▁▁▂▂▂▁▃▄▂▃▃▃▅▄▅▂▄▅▂▃▄▄▅▃▅█▄▇▅▇▇▇▇▆▅▄
wandb:         train/mil_loss ▅▂██▇▄▅▄▅▇█▃▆▃▆▂▆▁▄▃▃▄▃▅▃▃▅▃▂█▄▄▆▅▆▅▆▄▃▄
wandb:      train/policy_loss ▃▃▇▄▄▂▄▄▄▄▁▃▃▂▂▅▂▃▄▅▁▃█████▃████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▃▄▃▂▅▃▄▂▂▁▃███████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.39721
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.80673
wandb:      eval/avg_mil_loss 0.39875
wandb:       eval/ensemble_f1 0.80673
wandb:            test/avg_f1 0.72863
wandb:      test/avg_mil_loss 0.49284
wandb:       test/ensemble_f1 0.72863
wandb:           train/avg_f1 0.74444
wandb:      train/ensemble_f1 0.74444
wandb:         train/mil_loss 0.54157
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/suwomj6p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_191716-suwomj6p/logs
wandb: Agent Starting Run: 46rbruc5 with config:
wandb: 	actor_learning_rate: 0.0001230639930535804
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9517866026347244
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3570856867064911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192257-46rbruc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/46rbruc5
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▇▆▇▆▆▄▁▇▅▆▆▆▇▂▅▆▅▆▅▂▅▅▄▃█▄█▄▁▅█▇▃▄▄▃▆
wandb:      train/ensemble_f1 ▄▃▄▃▅▂▂▅▅▅▃▁▅█▃▄▄▂▁▄▅▅▆▃▁▃▂▆▃▆▁▅▄▅▅▃▂▂▃▅
wandb:         train/mil_loss ▅▅▇▆▆▆▇▆▆▆▅▄▆█▅▄▆▆▃▄▄▅▁▅▅▅▆▅▆▃▄▄▅▃▄▅▅▅▆▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁█▁▁▅▅▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▁▁▁▁▁▁▁▅▁▁▁▁▁█▁▁▁▅▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.64956
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.48941
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.09205
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32261
wandb:      train/ensemble_f1 0.32261
wandb:         train/mil_loss 1.68065
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run likely-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a7zgmi94
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192140-a7zgmi94/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dt12mc7e with config:
wandb: 	actor_learning_rate: 1.3125749186921626e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3306288051177865
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0534266250224632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192345-dt12mc7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dt12mc7e
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇██▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▂▂▁████████████████████████████████████
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▅▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▂▂▁▁▂▁▁▁▁▁
wandb:      train/ensemble_f1 ██▇▇▅▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▂▁
wandb:         train/mil_loss ▅▆▄▄▄▆▇▁▂▆▃▅▃▄▅█▃▅▄▂▅▂▅▃▆▅▄▄█▆▅▅▅▅▅▇▃▃▄▆
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64194
wandb: best/eval_avg_mil_loss 0.66308
wandb:  best/eval_ensemble_f1 0.64194
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91654
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.66997
wandb:      test/avg_mil_loss 0.66483
wandb:       test/ensemble_f1 0.66997
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 0.56652
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/46rbruc5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192257-46rbruc5/logs
wandb: Agent Starting Run: xrky75qd with config:
wandb: 	actor_learning_rate: 2.2903601146943155e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2143620551384422
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34572841213018424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192451-xrky75qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xrky75qd
wandb: uploading history steps 125-129, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▁███████████████████████████████████
wandb:      eval/avg_mil_loss ███████▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▆▆▆▆▆▆▆▆▆▆▁▅▅███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▂▆▃▅▃▂▄▇▆▅▆▅▆▆▃▅▅▃▄▄▁▇▅▄▅▂▃▅█▆▄▇▅▆▅▅▆▅
wandb:      train/ensemble_f1 ▅▄▇▄▆▄▁▆▇▆▁▃▂▃▇▅▅▇▄▇▅▂▇▄▅▇▄▇█▄▄▅▄▃▇▅▆▆▃▇
wandb:         train/mil_loss ▅▇▆▅▆▆▂█▆▆█▆▅▄▇▆▅▄▅▇▇▅▄▄▁▅▄▆▆▃▅▅▅▄▄▄▅▄▇▄
wandb:      train/policy_loss ▄▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁█▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53989
wandb: best/eval_avg_mil_loss 0.67323
wandb:  best/eval_ensemble_f1 0.53989
wandb:            eval/avg_f1 0.53989
wandb:      eval/avg_mil_loss 0.60475
wandb:       eval/ensemble_f1 0.53989
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.66158
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.48841
wandb:      train/ensemble_f1 0.48841
wandb:         train/mil_loss 0.74419
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dt12mc7e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192345-dt12mc7e/logs
wandb: Agent Starting Run: iq7ucu1s with config:
wandb: 	actor_learning_rate: 0.0021982401373787314
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9810935435332058
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8896536090465871
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192610-iq7ucu1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq7ucu1s
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▅▅▄▄▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▂▂▂▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████▇▇▆▆
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████▇▆▆▆▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▄▁▅▄▃▆▄▂▇▆▄▅▆▆▄▄▄▅▆▇▆▅▆▆▇▆█▅▇▅█▆█▆▅▇▇
wandb:      train/ensemble_f1 ▄▃▄▃▄▄▁▁▅▄▄▃▃▅▅▆▄▃▃▁▂▃▂▃▄▅▂▅█▃▆▅▅▅▄▆▇▅▆▅
wandb:         train/mil_loss ▄▂▂▃▃▄▃▄▂▄▃▃▃▂▃▁▃▂█▃▂▂▂▂▂▂▄▃▂▂▃▃▂▃▄▂▁▃▃▅
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅█▁▂▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅█▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72917
wandb: best/eval_avg_mil_loss 1.47548
wandb:  best/eval_ensemble_f1 0.72917
wandb:            eval/avg_f1 0.72196
wandb:      eval/avg_mil_loss 1.4597
wandb:       eval/ensemble_f1 0.72196
wandb:            test/avg_f1 0.66731
wandb:      test/avg_mil_loss 1.8147
wandb:       test/ensemble_f1 0.66731
wandb:           train/avg_f1 0.7238
wandb:      train/ensemble_f1 0.7238
wandb:         train/mil_loss 0.51049
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run effortless-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o41q9zwr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192012-o41q9zwr/logs
wandb: Agent Starting Run: air8o88h with config:
wandb: 	actor_learning_rate: 2.211723562640477e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7284307696763644
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39084657184101057
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192722-air8o88h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/air8o88h
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇████▇▇▇▇▇▇▇▆▆▇▆▅▅▆▆▅▄▄▄▃▃▄▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▃▄▆▄▃▃▄▆▅▅▃▂▃▅▆▅▄▆▁▅▅▇▅▆▂▃▄▄▅▇▇█▄▆▃▄▃
wandb:      train/ensemble_f1 ▃▄▃▇▄▄▂▅█▃█▄▅▅▅▄▃▅▆▅▇▇▅▁▅▇▄▆▆▄▄▆▅▂█▅▅▃▅▅
wandb:         train/mil_loss ▆▆▆▄▅▄█▄▆▅▄▆▅▃▆▄▄▆▆▄▅▅▅▃▇█▅▆▃▁▅█▃▆▃▇▄▃▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 0.96638
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.96157
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.78754
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.49004
wandb:      train/ensemble_f1 0.49004
wandb:         train/mil_loss 0.58479
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq7ucu1s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192610-iq7ucu1s/logs
wandb: Agent Starting Run: rzuchnvi with config:
wandb: 	actor_learning_rate: 2.449098691842181e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.010701666688423428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9802804248018612
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_192810-rzuchnvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rzuchnvi
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ▄▄▆███▇▅▄▄▄▄▅▅▄▅▅▂▂▂▂▂▁▂
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▂▂▃▃▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇██████▇▇
wandb:      eval/avg_mil_loss ▄██▇▇▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▃▃▂▂▂▁▂▂▃▃▃▃
wandb:       eval/ensemble_f1 ▁▃▃▃▂▄▄▅▆▆▆▆▆▆▆▆▇▇▇▇▆▆▆▇▇▇▆▆▇▇█████████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▁▃▄▄▃▄▅▄▄▆▅▅▅▆▄▆▆▆▅▅▆▅▆▆▆▆▅▆▇▆▆▇▇▇█▆▇▇
wandb:      train/ensemble_f1 ▃▃▁▂▃▃▄▄▄▄▄▄▃▄▅▄▅▄▅▅▆▇▆▅▇▆▇▇▆▇▆▇▇▇▇▆▇█▇█
wandb:         train/mil_loss ▅▆▆▆█▆▆▄▄▇▅▃▄▅▂▄▄▂▄▃▂▃▃▃▃▄▃▃▃▂▃▂▂▁▂▂▂▂▄▂
wandb:      train/policy_loss ▅████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██▇███████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84998
wandb: best/eval_avg_mil_loss 0.50823
wandb:  best/eval_ensemble_f1 0.84998
wandb:            eval/avg_f1 0.82998
wandb:      eval/avg_mil_loss 0.52422
wandb:       eval/ensemble_f1 0.82998
wandb:            test/avg_f1 0.83766
wandb:      test/avg_mil_loss 0.41944
wandb:       test/ensemble_f1 0.83766
wandb:           train/avg_f1 0.81812
wandb:      train/ensemble_f1 0.81812
wandb:         train/mil_loss 0.53315
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tmhqu495
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192021-tmhqu495/logs
wandb: Agent Starting Run: 78q4bplf with config:
wandb: 	actor_learning_rate: 0.008275814439956841
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9149156251980088
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6217400538514627
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193126-78q4bplf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78q4bplf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇█
wandb: best/eval_avg_mil_loss █▆▃▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▄▅▅▅▇▇▇▇▇▇██████▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▅▅▅▇▇▇████████▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃█▄▃▄▅▅▅▆▇▃▂▃▄▆▃▁▇▅▅▆▆▄▆▄▇▄█▆▄▆▃▇▅▇▃▇▆
wandb:      train/ensemble_f1 ▄▃▆▅▇▅▃▄▄▆▄▂▇▂▅▆▄▅█▆▆▃▄▃▄▅▁▆▁▅▆▄▅▅▁▂▄▅▅▅
wandb:         train/mil_loss ▆▅█▅▇▅▅▆▆▅▄▅▄▆▆▅▄▃▅▄▃▂▃▃▄▃▄▄▃▂▂▃▂▂▃▁▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54772
wandb: best/eval_avg_mil_loss 0.63772
wandb:  best/eval_ensemble_f1 0.54772
wandb:            eval/avg_f1 0.53989
wandb:      eval/avg_mil_loss 0.5939
wandb:       eval/ensemble_f1 0.53989
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.65071
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.495
wandb:      train/ensemble_f1 0.495
wandb:         train/mil_loss 0.82948
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rzuchnvi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192810-rzuchnvi/logs
wandb: Agent Starting Run: fwrvri28 with config:
wandb: 	actor_learning_rate: 0.00026489961312880286
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8405928784438003
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0374590328754002
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193254-fwrvri28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fwrvri28
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▃▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▇▇▇███████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▂▃▃▅▅▁▂▄▅▂▆▃▇▆▅▅▇▁▃▇▂▄▇▃▅▇▄▆▃▅▄▅▂▄█▇▃
wandb:      train/ensemble_f1 ▄▂▅▃▄▂▂▆▄▁▁▃▅▃▄▅▆▂▃▄▆▄▁▃▇▁▂▅▇▄▃▆▂▅▄█▇▄▃▅
wandb:         train/mil_loss ▃▄▃▄▃▃▂▄▃▅▃▄▄▆▅▄▄▄▄█▄▅▃▄▃▅▁▄▄▃▅▅▆▅▇▅▄▅▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.92037
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.92551
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.75793
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.4192
wandb:      train/ensemble_f1 0.4192
wandb:         train/mil_loss 0.53717
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/78q4bplf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193126-78q4bplf/logs
wandb: Agent Starting Run: m1cks7t6 with config:
wandb: 	actor_learning_rate: 0.009301850718444448
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.297978476375405
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8237528745023395
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193321-m1cks7t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1cks7t6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▃▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇██
wandb: best/eval_avg_mil_loss █▅▅▄▄▄▄▄▂▂▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▃▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▃▃▄▅▅▅▅▆▆▆▅▆▆▆▆▅▅▅▆▆▆▆▆▆▇▇███████
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▁▃▄▃▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▆▅▆▆▅▆▇▇▇█████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▂▃▃▂▂▂▄▃▄▄▅▄▅▆▆▆▆▇▇▆▆▇▆▇▇▇█▆▇▇▇▆▇█▆▇
wandb:      train/ensemble_f1 ▁▁▁▂▃▃▃▅▃▄▅▆▃▅▇▇▇▇▆▇▇▆█▇▇▇▇▇▆▆▇▇▇▆███▇▆▇
wandb:         train/mil_loss ██▄▆█▇▃▇▅▆▃▄▄▄▄▃▃▃▄▃▄▄▄▄▃▃▄▃▂▄▂▃▃▃▄▁▃▁▂▂
wandb:      train/policy_loss ▆▆▆▆▆█▆▆▆▆▃▃▆▆▆▁▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60808
wandb: best/eval_avg_mil_loss 0.68415
wandb:  best/eval_ensemble_f1 0.60808
wandb:            eval/avg_f1 0.59936
wandb:      eval/avg_mil_loss 0.66255
wandb:       eval/ensemble_f1 0.59936
wandb:            test/avg_f1 0.61985
wandb:      test/avg_mil_loss 0.57469
wandb:       test/ensemble_f1 0.61985
wandb:           train/avg_f1 0.61999
wandb:      train/ensemble_f1 0.61999
wandb:         train/mil_loss 0.65091
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xrky75qd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192451-xrky75qd/logs
wandb: Agent Starting Run: sf7z6kgs with config:
wandb: 	actor_learning_rate: 0.004480580433502527
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9109237262173306
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.055903785974336984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193415-sf7z6kgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sf7z6kgs
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▆▄▄▅▇▇▁█▅▆▆▅▅▅▃▄▅▅▇▅▇▆▇▆▅▃▄▇▆▇▇▆▆▆▆▇▇█
wandb:      train/ensemble_f1 ▆▅▆▆▆▅▇▁▄▅▆▅▄▆▄▇▄▅▄█▄▆▆█▅▅▅▅▇▄▆▆▆▅▄▆▅▄▆▇
wandb:         train/mil_loss ▂▇▅▃▃▇▆▅█▄▇▃▇▆▅▅▅▅▄▆▇▁▇▆▄▄▆█▅▃▅▃▃▄▄▇▄▆▅▆
wandb:      train/policy_loss ▄▅▄▁▄▄▄▄▅▄▅▃▄▁▅▃▆▄▄▃▂▂▆▆▃▅▂▃▅▄▄▄█▃▃▄▇▇▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▇▃▇█▃▄▆▄▃▆▄▄▄▇▇▃▄▃▃▂▃▆▁▁▂▇▇▆▃▃▂█▁▇█▂▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72379
wandb: best/eval_avg_mil_loss 0.532
wandb:  best/eval_ensemble_f1 0.72379
wandb:            eval/avg_f1 0.72379
wandb:      eval/avg_mil_loss 0.53049
wandb:       eval/ensemble_f1 0.72379
wandb:            test/avg_f1 0.74189
wandb:      test/avg_mil_loss 0.58143
wandb:       test/ensemble_f1 0.74189
wandb:           train/avg_f1 0.71465
wandb:      train/ensemble_f1 0.71465
wandb:         train/mil_loss 0.57569
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run neat-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fwrvri28
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193254-fwrvri28/logs
wandb: Agent Starting Run: drqtf5k1 with config:
wandb: 	actor_learning_rate: 7.887783500681692e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9851584701141723
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5542978905778827
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193452-drqtf5k1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drqtf5k1
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▆▁▅▁▇▂▄▇▄▃▅▃▂▇▅▆▅▆▆▆▂▃█▅▅▄▃▂▃▇▅▄▆▅▆▅▇▆
wandb:      train/ensemble_f1 ▄▆▆▃▅▃▁▅▇▅▁█▄▃▄█▅▅▄▆▅▃█▇▇▄▄▆▅▄▄▂▅▃▂▄▆▂▅▅
wandb:         train/mil_loss ▄▅▃▄▃▇▇▅▅▄▄▆▄▄▃▆▄▅█▄▇▃▄▄▅▄▃▂▆▄▅▄▁▃▅▄▅▄▅▂
wandb:      train/policy_loss ▅▅▄▅█▁▄▅▄▄▁█▃▅▅▃▄▄▆▅▆▅▁█▄▅▂▂▆▂▆▅▄▁▂▄▆▄▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅▅▄▆▄▄▇▅█▃▅▃▅▅▅▅▇▆▅▆▅▄▅▃▄▅▆▂█▇▅▁▂▄▃▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76139
wandb: best/eval_avg_mil_loss 0.98147
wandb:  best/eval_ensemble_f1 0.76139
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.84961
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.77022
wandb:      test/avg_mil_loss 0.67183
wandb:       test/ensemble_f1 0.77022
wandb:           train/avg_f1 0.76221
wandb:      train/ensemble_f1 0.76221
wandb:         train/mil_loss 0.8642
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1cks7t6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193321-m1cks7t6/logs
wandb: Agent Starting Run: vslicx6j with config:
wandb: 	actor_learning_rate: 0.00016287643526990763
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.895789232764952
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38315537941606137
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193514-vslicx6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vslicx6j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████▁█▁██▁▁██▁███▁▁▁
wandb:      eval/avg_mil_loss ▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▆▆▆▆▆▆▆▆███▆▆▅▄▄
wandb:       eval/ensemble_f1 ██████████████████▁▁▁▁█████████▁████▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▇▆▆▅▅▆▃▄▁▆▄▂▂▄▇▃▄▂▂▄▂▅▅▅▃▃▃▃▁▅▄▅▄▃▆▃▂
wandb:      train/ensemble_f1 ▇▅▆█▆▇▇▆▇▅▇▇▆▆▆▆▅▆▃▅▃▆▃▅▄▃▅▅▅▃▅▆▁▅▂▃▄▆▄▃
wandb:         train/mil_loss ▅▃▃▃▄▁▂█▁▂▃▃▃▂▂▄▅▂▂▄▄▃▆▃▂▂▃▁▂▅▂▃▅▃▂▄▂▁▄▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▃▄▄▄▄▄▃▄▄▄▁▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████████████▁▇█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.59454
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.78639
wandb:      eval/avg_mil_loss 0.59387
wandb:       eval/ensemble_f1 0.78639
wandb:            test/avg_f1 0.76881
wandb:      test/avg_mil_loss 0.84852
wandb:       test/ensemble_f1 0.76881
wandb:           train/avg_f1 0.69365
wandb:      train/ensemble_f1 0.69365
wandb:         train/mil_loss 0.55537
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sf7z6kgs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193415-sf7z6kgs/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: z42qfi8v with config:
wandb: 	actor_learning_rate: 0.0009073360256278808
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6146042348404882
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4325527068503224
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193617-z42qfi8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z42qfi8v
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▂▄▄▃▂▂▂▂▃▂▂▂▂▃▃▂▃▃▃▁▂▂▃▄▄▃▂▂▁███▇▆▆▆▄▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▂▅▃█▅▂▃▃▂▄▅▄▇▇▆▃▂▅▅▁▂▅▄▆▄▄▅▇▇▅▂▄▄▆▅▆▄▃
wandb:      train/ensemble_f1 ▂▁▁▅▄▅▅▁▃▇▇▆▃▄▃▁▄▇▃██▆▄▅▃█▂▄▄▆▇▁▁▆▃▄▅▅▅▃
wandb:         train/mil_loss ▅▆█▅▆▄▄▅▄▅▅▄▄▄▂▅▃▆▃▄▄▁▆▆▄▄▁▄▅▄▄▄▂▆▆▃▃▆▃▃
wandb:      train/policy_loss ▃█▃█▆█▆▆▃████▆▆▆█▁███▆▆██▆█▆▆██████▆██▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃█▃▆▆▆█████▆▆█▆▆▁█▆██▆████▆███▆▆▆▆▆█▆██▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.88221
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.88257
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.96957
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 0.59112
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drqtf5k1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193452-drqtf5k1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ezzb1kaj with config:
wandb: 	actor_learning_rate: 0.003078153002234438
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5206774048918299
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5932323641003551
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193658-ezzb1kaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ezzb1kaj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▅▇▁▇▆▆▆▅▄▆▂▁▃▅▇▄▂█▅█▅▅▆▅█▅▇▅▄▃▇█▅▆▂▅▄▂
wandb:      train/ensemble_f1 ▅▃▅▇▆▅▄▆▇▂▆▇▁▃▂▅▄▂▄▆▅▅▅▆▆▆█▇▆▂▄▆▆▄▇▄▅▆▅▂
wandb:         train/mil_loss ▇▃▃▄█▃▅▄█▆▄▆▇▄▅▇▇▂▂▂▂▇▅▅▂▃▄▅▆▅▄▇▂▇▄▆▃▁▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.53939
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.4976
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.21904
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.37304
wandb:      train/ensemble_f1 0.37304
wandb:         train/mil_loss 0.70009
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vital-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vslicx6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193514-vslicx6j/logs
wandb: Agent Starting Run: vkokuwx6 with config:
wandb: 	actor_learning_rate: 0.002930357526880948
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9751915880210272
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3828948068930303
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193708-vkokuwx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkokuwx6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████▇▇
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▂▂▃▃▄▄▄▄▄▄▅▆▆▇▇▇▇▇▇▇▇▇▇███████▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▆▅▅▇▇▆▆▇▇▇▆▇█▇▇▇▇▇█▇▇▇▇
wandb:      train/ensemble_f1 ▁▁▂▃▃▄▃▄▃▄▅▄▄▄▄▅▅▆▅▅▆▆▇▆▆▆▆▇▇█▇█▇████▇██
wandb:         train/mil_loss ▇▆▅▅▇▆▆▅█▃▃▄▇▇▄▆▃▇▅▄▅▄▅▂▃▂▂▂▂▄▁▄▁▂▄▂▂▅▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80845
wandb: best/eval_avg_mil_loss 0.52142
wandb:  best/eval_ensemble_f1 0.80845
wandb:            eval/avg_f1 0.76887
wandb:      eval/avg_mil_loss 0.51025
wandb:       eval/ensemble_f1 0.76887
wandb:            test/avg_f1 0.86133
wandb:      test/avg_mil_loss 0.43785
wandb:       test/ensemble_f1 0.86133
wandb:           train/avg_f1 0.77495
wandb:      train/ensemble_f1 0.77495
wandb:         train/mil_loss 0.50203
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/air8o88h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_192722-air8o88h/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 066b2cho with config:
wandb: 	actor_learning_rate: 0.0006807360758671711
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28643003086434016
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3773797126789703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193808-066b2cho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/066b2cho
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▆▆▄▂▂▅▄▄▆▃▃▃▂█▅█▃▂▃▄▇▅▂▄▄▆▄▄▄▃▄▆▅▃▆▅▇▄
wandb:      train/ensemble_f1 ▆█▄▄▂▅▃▅▃▂▆▂▅▂▄▁▄▂▄▄▅▇▄▆▂▆▆▃▅▃▃▃█▅▅▃▆▅▅▁
wandb:         train/mil_loss ▃▁▁▄▄▃▁▁▁▃▁▁▁█▄▂▄▄▄▁▁▆▇█▁▁▆▄▄▁▆▃▇▁▁▃▂▁▃▅
wandb:      train/policy_loss █▅█▁█▁█▄██▅▁▄▅█▅▅▅██▁██▅█▁▅▁███▄█▁██▄██▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▅▄▅▁▄██▅▄█▄█▄▄█▁▄█▄▄██▁▁▄▄██▄██▁█▄███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 8.00446
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.93229
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.82628
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3311
wandb:      train/ensemble_f1 0.3311
wandb:         train/mil_loss 0.58335
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkokuwx6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193708-vkokuwx6/logs
wandb: Agent Starting Run: d2miihj8 with config:
wandb: 	actor_learning_rate: 0.00010274756438753256
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7996659829772963
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6830793535202692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_193902-d2miihj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d2miihj8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁█▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇█▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ██▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▂▁██▆▅▆▅▅▆▆▆▅▄▆▅▄▅▅▄▅▄▅▅▅▄▅▅▄▆▅▆▅▅▄▅▅▅▅▄
wandb:      train/policy_loss █▄▄▂▂▂▂▂▂▂▂▁▂▃▂▃▃▂▃▂▁▃▂▂▁▃▂▂▂▂▃▁▂▂▁▂▂▃▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▄▅▃▄▃▃▄▄▄▅▅▃▂▂▅▆▂▂▆▃▃▃▄▂▁▃▂▃▁▂▅▃▅▃▃▅▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68995
wandb: best/eval_avg_mil_loss 0.97849
wandb:  best/eval_ensemble_f1 0.68995
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.82053
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.66731
wandb:      test/avg_mil_loss 1.40962
wandb:       test/ensemble_f1 0.66731
wandb:           train/avg_f1 0.33278
wandb:      train/ensemble_f1 0.33278
wandb:         train/mil_loss 1.40529
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/066b2cho
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193808-066b2cho/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 15ejwydx with config:
wandb: 	actor_learning_rate: 2.2148587824575503e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03544206952814977
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5096912489351021
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194007-15ejwydx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15ejwydx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▄▇▆▅▇▆▂▁▆▅█▅▆▃▁▇▄▇▃▄▄▃▅▃▄▆▅▇▄▆▆▅▂▃▅▆█▃
wandb:      train/ensemble_f1 ▃▆▇▄▆▆▃▂▄█▅▅▃▃▁▄▃▄▅▅▂▆▄▃▅▃▇▇▄▅▅▅▄▃▅█▃▅▇▅
wandb:         train/mil_loss ▄▆▃▇▄█▇▄▅▅▄▅▄▆▇▃▄▅▃▄▇▅▂▁▆▄▃▂▅▃▄▃▃▁▃▂▂▅▃▂
wandb:      train/policy_loss ▅█▁▃▁▃▃▁▃▃▁▁▁▃▅▅▁█▃▁▅▃▅▁▃▃▅▁▁▅▁▁▁▅▁▃▃▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▁▃▁▁▃▃▃▁▃▃▃▁▃▆▃▃▆▁▆▆▆▁▃▁▁▁▆▆▁▆▃▃▁▆▃▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.96123
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.77942
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.17919
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3266
wandb:      train/ensemble_f1 0.3266
wandb:         train/mil_loss 1.61146
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/15ejwydx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194007-15ejwydx/logs
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇█
wandb: best/eval_avg_mil_loss █▅▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▃▄▄▄▆▆▆▅▅▅▅▅▅▇▇▇█████████████
wandb:      eval/avg_mil_loss ███▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▄▄▄▄▄▆▅▅▅▅▅▅▇▇▇▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅▅▄▆▇▁▆▆▅▅▄▆▇▃▆▇▇▆▄▅▇▅▄█▇▆▃▃▆▇▇▄▆█▄▅█▇
wandb:      train/ensemble_f1 ▃▄▅▁▃▄▂▃▃▂▅▂▂▄▆▇▁▆▅▃▃▄▅▄▃▂▄▃▆▆▁▄▄█▅▄▄▅▁▅
wandb:         train/mil_loss ▆▇▆▆▅▅█▄▇▄▆▆▄▆▃▅▅▆▇▄▆▅▃▄▃▃▅▅▁▅▇▂▃▄▂▃▅▂▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54772
wandb: best/eval_avg_mil_loss 0.70245
wandb:  best/eval_ensemble_f1 0.54772
wandb:            eval/avg_f1 0.54772
wandb:      eval/avg_mil_loss 0.65105
wandb:       eval/ensemble_f1 0.54772
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.65678
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.45718
wandb:      train/ensemble_f1 0.45718
wandb:         train/mil_loss 0.73117
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ezzb1kaj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193658-ezzb1kaj/logs
wandb: Agent Starting Run: 1easqgxp with config:
wandb: 	actor_learning_rate: 7.101119455985373e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6576901087392306
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5544365196490845
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194158-1easqgxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1easqgxp
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 49g7mh0n with config:
wandb: 	actor_learning_rate: 0.0003985978006838979
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9230722283933545
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5317187033068312
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194206-49g7mh0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49g7mh0n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▅▄▄▄▄▄▄▆▆▆▆▆███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▄▆▆▆████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▂▁▁▃▅▄▃▂▄▄▄▃▄▁▅▄▃▄▃▃▅▄▅▄▅▅█▄▅▄▅▅▅▅▇▅▇
wandb:      train/ensemble_f1 ▁▂▄▂▃▄▄▃▂▅▄▅▄▃▅▅▅▆▅▄▄▃▅▄▅▄▃▅▆▇▅▆▇▆▆█▇█▇▇
wandb:         train/mil_loss ▁▅▄▆▃▃▆▄▅▂▃▂█▂▆▃▃▅▃▁▃▆▂▃▅▄▃▃▅▅▃▃▃▃▃▃▆▂▃▅
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 2.02457
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 1.88507
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.62148
wandb:      test/avg_mil_loss 2.87883
wandb:       test/ensemble_f1 0.62148
wandb:           train/avg_f1 0.72405
wandb:      train/ensemble_f1 0.72405
wandb:         train/mil_loss 0.63322
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d2miihj8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193902-d2miihj8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m7zhl7gr with config:
wandb: 	actor_learning_rate: 0.002576169641815199
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6243078653540605
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7397045213270501
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194312-m7zhl7gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m7zhl7gr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▄▅▆▆▇██
wandb: best/eval_avg_mil_loss ███▆▇▆▅▄▃▃▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▄▅▆▆▇██
wandb:            eval/avg_f1 ▁▁▂▁▁▂▂▂▂▂▄▄▄▄▄▆▆▅▅▅▅▅▅▆▇▇▅▆█▆██████████
wandb:      eval/avg_mil_loss ▇▇▇███▇▇▆▆▇▇▇▇▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▁▁▁▂▃▄▄▄▄▄▄▅▅▅▆▅▅▅▇▇▇▅▆▇█▆██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▃▄▄▃▃▅▄▃▄▅▆▆▇▇▅▇▆▅▄▅▇▅▅▅▆▆▆▄▅█▆▅▇▇█▆▇▅
wandb:      train/ensemble_f1 ▁▄▂▆▄▄▆▅▆▆▇▆▆▇▄▇▇▇█▆▇▇▅▆▇▅▅▄▆▇▅▆▇█▇▆▅▅██
wandb:         train/mil_loss ▃▂█▅▄▄▄▂█▅▆▃▄▄▅▃▂▅▄▃▂▁▁▃▁▃▃▅▃▂▄▃▃▄▂▁▁▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62169
wandb: best/eval_avg_mil_loss 0.70901
wandb:  best/eval_ensemble_f1 0.62169
wandb:            eval/avg_f1 0.62169
wandb:      eval/avg_mil_loss 0.65531
wandb:       eval/ensemble_f1 0.62169
wandb:            test/avg_f1 0.51299
wandb:      test/avg_mil_loss 0.97688
wandb:       test/ensemble_f1 0.51299
wandb:           train/avg_f1 0.59946
wandb:      train/ensemble_f1 0.59946
wandb:         train/mil_loss 0.7352
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z42qfi8v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_193617-z42qfi8v/logs
wandb: Agent Starting Run: 7rz6fkrg with config:
wandb: 	actor_learning_rate: 4.066246473570649e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.18217075670716465
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6915765325040799
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194343-7rz6fkrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rz6fkrg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████▁▁▁▁▁▁▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁█▁▁▁▁▁▃
wandb:      eval/avg_mil_loss ▁▁▁▂▁▁▁▁▁▁▁▂▂▂▃▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████▇▇
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▃▃▃▃▁▃▃▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▅▆█▆▄▅▆▅▆▄▅▃▁▄▄▄▇▄▄▃▆▄▃▅▅▂▆▃▅▃▃▅▄▆▄▇▅
wandb:      train/ensemble_f1 ▅▁▆▆▇▄█▄▂▆▅▄▆▁▁▃▄▂▃▃▇▄▂▁▃▃▃▂▂▇▅▃▁▅▂▂▅▃▃▄
wandb:         train/mil_loss ▆▅▄▅▃▅▅▄▁▃▆▃▃▂▃▂▂▁█▂▄▄▄▄▃▅▆▄▃▁▄▄▆▅▂▂▂▃▄▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▃▁▄▄▄▄█▄▄▄▄▄▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3605
wandb: best/eval_avg_mil_loss 0.92546
wandb:  best/eval_ensemble_f1 0.3605
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.93116
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.38351
wandb:      test/avg_mil_loss 0.80939
wandb:       test/ensemble_f1 0.38351
wandb:           train/avg_f1 0.40825
wandb:      train/ensemble_f1 0.40825
wandb:         train/mil_loss 0.58664
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/49g7mh0n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194206-49g7mh0n/logs
wandb: Agent Starting Run: n3qy3u5f with config:
wandb: 	actor_learning_rate: 0.002667299749530211
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7030962368936461
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22164009619625713
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194400-n3qy3u5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n3qy3u5f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▇▅▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss █▁▃▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▆█▅▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▁▆▇▄▆▇▃▄▃▅▃▂▄▅▄▅▇▅▄█▅▇█▅█▃▅▃▄▂▁▆▇▅▅▇▅▅
wandb:      train/ensemble_f1 ▆▅▆▄▃▄█▄▅▄▆▅▄▅▅▃▇▆▇█▅▅▅▅█▄▃▅▁▆▃▅▆▅▅▇▅▇▅▅
wandb:         train/mil_loss ▇▆▄▃▅▅▃▄▅▃▆▆▆▃▃▅▆▁▆▃▅▃▆▄▃▄▇▅▆▄▂▆█▅▅▄▃█▇▄
wandb:      train/policy_loss ████████████████████████▁███████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68286
wandb: best/eval_avg_mil_loss 0.51949
wandb:  best/eval_ensemble_f1 0.68286
wandb:            eval/avg_f1 0.64271
wandb:      eval/avg_mil_loss 0.56679
wandb:       eval/ensemble_f1 0.64271
wandb:            test/avg_f1 0.57555
wandb:      test/avg_mil_loss 0.61148
wandb:       test/ensemble_f1 0.57555
wandb:           train/avg_f1 0.59526
wandb:      train/ensemble_f1 0.59526
wandb:         train/mil_loss 0.64609
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m7zhl7gr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194312-m7zhl7gr/logs
wandb: Agent Starting Run: tcuyzjy6 with config:
wandb: 	actor_learning_rate: 2.4173984620015966e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20505297114774113
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8707447995510395
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194508-tcuyzjy6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tcuyzjy6
wandb: uploading history steps 100-113, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▁█
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 ▁▁▁▁██▇▆▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▆▆▇▇▇▇▇▅▅▅▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▅██▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ▂▂▂▃▂██▇▁▁▂▂▂▂▂▂▂▁▂▂▃▃▃▃▄▄▄▄▄▅▇▇▇▇▇▅▅▅▅▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▃▄▃▄▂▄▃▃▃▅▄▅▆▄▇▆▄▆▇▆▄▅▆▅▆▇▇▆▇▆▆▆▆█▆▇█
wandb:      train/ensemble_f1 ▁▁▃▁▃█▅▄▄▅▄▄▃▆▃▃▄▅▅▇▄▆▅▄▅▅▆▅▅▅▅▄▅▆▆▆▅▆▅▇
wandb:         train/mil_loss ▃▄▂▄▁▃▃█▄▄▃▂▅▆▂▄▆▂▁▂▃▄▅▄▆▃▃▄▅▄▅▃▂▃▂▄▄▅▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆██▆▆▆▆▆▇▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.58464
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.73906
wandb:      eval/avg_mil_loss 0.71862
wandb:       eval/ensemble_f1 0.73906
wandb:            test/avg_f1 0.77858
wandb:      test/avg_mil_loss 0.77179
wandb:       test/ensemble_f1 0.77858
wandb:           train/avg_f1 0.79766
wandb:      train/ensemble_f1 0.79766
wandb:         train/mil_loss 0.53646
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n3qy3u5f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194400-n3qy3u5f/logs
wandb: Agent Starting Run: l69av35b with config:
wandb: 	actor_learning_rate: 0.00059613212979581
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9799044312668628
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07744089742720528
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194605-l69av35b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l69av35b
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁█▅▇▂▃▄▁▆▃▄▄▄▅▄▅▆▃▅▂▅▇▄▇▆▅▅▅▅▅▅█▇▄▆▆▄▇▆
wandb:      train/ensemble_f1 ▄▃▇▆▅▄▄▃▂▆▄▃▄▃▄▃▄▅▂▄▅▅▇▄█▄▄▄▅▄▅▅▄▅▇▁▄▅▅▅
wandb:         train/mil_loss ▇▆█▄▃▆▇▄▇▅▆▅▃▂▅▄▂▄▃▆▅▂▁▂▄▂▁▄▂▂▅▂▂▄▁▆█▄▄▃
wandb:      train/policy_loss ███▅█▅▁▅█████▅█▄▅███▄█████▄████▄█▁██▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▅██▄▄█▄██████▅████▄████▄▁▄█▅▄▁█▁▄█▄█▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.04061
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.03332
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.16438
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33555
wandb:      train/ensemble_f1 0.33555
wandb:         train/mil_loss 0.49835
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l69av35b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194605-l69av35b/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vzh93eww with config:
wandb: 	actor_learning_rate: 0.0019701129087231232
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07621735860250367
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6329745329079813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194825-vzh93eww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vzh93eww
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ██▆▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▃▃▃▃▅▅▆▆▆▆▆▆▆█████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▄▄▄▄▄▄▄▄▄▅▅▅▇▇▇▇▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▂▁▄▅▃▃▅▅▄▂▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇█▇▇███▇█
wandb:      train/ensemble_f1 ▃▂▁▁▂▃▂▄▃▄▃▁▃▃▄▄▃▅▅▄▅▅▅▄▆▆▆▇▆▅▆▆█▇▇▇▇███
wandb:         train/mil_loss ▆▆▇▇▅█▇▅▆█▅▆▅▆▅▅▅▅▆▄▆▅▆▅▃▅▃▃▄▅▅▃▄▃▂▂▃▂▂▁
wandb:      train/policy_loss ▆█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.72678
wandb: best/eval_avg_mil_loss 0.78683
wandb:  best/eval_ensemble_f1 0.72678
wandb:            eval/avg_f1 0.72678
wandb:      eval/avg_mil_loss 0.64173
wandb:       eval/ensemble_f1 0.72678
wandb:            test/avg_f1 0.72874
wandb:      test/avg_mil_loss 0.59331
wandb:       test/ensemble_f1 0.72874
wandb:           train/avg_f1 0.73814
wandb:      train/ensemble_f1 0.73814
wandb:         train/mil_loss 0.74411
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tcuyzjy6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194508-tcuyzjy6/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▃▄▅▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▆▆▆▅▅▄▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▃▄▅▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▃▃▃▃▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇███████████
wandb:      eval/avg_mil_loss ▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁████▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▃▃▂▃▄▃▂▄▆▅▅▅▆▆▆▆▆▇▆▇█▆▇▇█▇▇▇▆▇████▇█
wandb:      train/ensemble_f1 ▁▁▁▁▂▂▁▂▂▃▄▄▄▅▆▅▆▆▆▇▇▆▆▆▇▇▆█▆▆▆▇▆▇▇▇▆█▇▇
wandb:         train/mil_loss ▅▇▄▅▄▃▂▅▅▂▄▄▁▅▄▃▅▅▂▄▅█▃▅▂▃▄▃▂▅▄▃▃▃▃▅▅▅▄▄
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54814
wandb: best/eval_avg_mil_loss 0.67053
wandb:  best/eval_ensemble_f1 0.54814
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 0.7153
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 0.70687
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.59083
wandb:      train/ensemble_f1 0.59083
wandb:         train/mil_loss 0.58957
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1easqgxp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194158-1easqgxp/logs
wandb: Job received.
wandb: Agent Starting Run: m8cilriz with config:
wandb: 	actor_learning_rate: 1.4224950775340871e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6922756791852119
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25656188441466143
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194936-m8cilriz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m8cilriz
wandb: Agent Starting Run: 90oymkj0 with config:
wandb: 	actor_learning_rate: 7.807933035267583e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5065555481179047
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7906552761312312
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_194939-90oymkj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/90oymkj0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁██▅▅▄▄▆▇▃▃▄▆▄▇▇▇▅▅▆▅▆█▇█▁▂▇▇▄▃▆▆▆▄▆▃▃▅▆
wandb:      train/ensemble_f1 ▄▄█▄▆▅▃▆▂▃▄▃▄▆▄▃▄▂▅▅▃▆▁▃▇▃█▂▅▄▃▇▇▆▇▅▃▄▄▅
wandb:         train/mil_loss ▅▆▆▃█▃▅▂▃▃▄▅▃▆▄▂▄▆▆▂▃▇▄▄▂▇▄▂▂▃▆▃▁▁▂▂▃▃▄▁
wandb:      train/policy_loss █▅▅▅▁▆▆█▆▁▁▄▄▅▄▃▅▅█▅▁▅▆▂▆█▁▄▅▆▄▆▅▁▅▄▄▄▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆█▆▆▆▃▆▅▆▇▂▄▅▁▄▃▆▃▆█▃▂▆█▆█▇▂▆▆██▆▃▅▄▆▆▅▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.67364
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.55902
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.11952
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32375
wandb:      train/ensemble_f1 0.32375
wandb:         train/mil_loss 1.10644
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/90oymkj0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194939-90oymkj0/logs
wandb: Agent Starting Run: w1chra5z with config:
wandb: 	actor_learning_rate: 0.00138412058717342
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6663637645805167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3647897206177466
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195138-w1chra5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w1chra5z
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇█████
wandb: best/eval_avg_mil_loss ███▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇█████
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▂▃▃▄▅▅▆▇▇▇▇▇███████████████████
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▂▂▂▃▃▄▅▅▆▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▃▃▃▃▄▅▄▄▅▄▅▅▅▆▆█▇█▇█▇█▇▇▇████▇█▇▇▇█
wandb:      train/ensemble_f1 ▁▁▂▁▂▄▄▄▄▄▄▄▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇███▇███▇
wandb:         train/mil_loss █▇▆█▇▇▆▆▆▆▆▅▄▄▄▄▅▃▃▃▃▃▃▂▂▃▃▂▂▂▃▁▁▂▂▃▂▁▂▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▃▇▅▅▇█▅▅▅███▅█▇█▅▁▂▂▂▄▂▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82916
wandb: best/eval_avg_mil_loss 0.38544
wandb:  best/eval_ensemble_f1 0.82916
wandb:            eval/avg_f1 0.82916
wandb:      eval/avg_mil_loss 0.37629
wandb:       eval/ensemble_f1 0.82916
wandb:            test/avg_f1 0.84162
wandb:      test/avg_mil_loss 0.40033
wandb:       test/ensemble_f1 0.84162
wandb:           train/avg_f1 0.82864
wandb:      train/ensemble_f1 0.82864
wandb:         train/mil_loss 0.52656
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7rz6fkrg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194343-7rz6fkrg/logs
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▂▂▂▂▂▂▅▅▅▁▄▄▄▄▄▄███▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▇▇▇▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▂▂▂▂▂▂▂▅▅▁▁▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▄▂▅▄▅▆▄▆▇▄▇▆▇▂▄▃▃▇▁▃▆▆▄▆▃█▅▄▄█▆▅▇▄▄▇▅▄
wandb:      train/ensemble_f1 ▂▇▆▂▆▅▂▃▄▄▂▆▁▄▆▅▃▆▇▇▄▅▄▂▅▃█▆▇▆▇▇▅▇▇▇▄▇▆▂
wandb:         train/mil_loss ▇▅▄▆▅▆▃▇▄▆▁█▁▂▆█▃▃▅▅▄▆▅▁▆▅▄▃▆▂▆▃▆▆▅▂▆▆▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▅▁▆▄▇▂▂▆▆██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69914
wandb: best/eval_avg_mil_loss 0.5215
wandb:  best/eval_ensemble_f1 0.69914
wandb:            eval/avg_f1 0.6875
wandb:      eval/avg_mil_loss 0.51839
wandb:       eval/ensemble_f1 0.6875
wandb:            test/avg_f1 0.58242
wandb:      test/avg_mil_loss 0.58256
wandb:       test/ensemble_f1 0.58242
wandb:           train/avg_f1 0.64755
wandb:      train/ensemble_f1 0.64755
wandb:         train/mil_loss 0.62253
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m8cilriz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194936-m8cilriz/logs
wandb: Job received.
wandb: Agent Starting Run: n232sjni with config:
wandb: 	actor_learning_rate: 0.005978335172981062
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.963142375907335
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7971341225490792
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195232-n232sjni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n232sjni
wandb: Sweep Agent: Waiting for job.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▆▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▄▄▅▅▆▇█
wandb:            eval/avg_f1 ▁▄▄▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆███████████████
wandb:      eval/avg_mil_loss █▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▅▄▄▄▅▅▄▅▄▅▄▆▃▅▄▄█▆▆▅▇▅█▇▄▅▆▇█▆▅▆▆▅▅▆▆▇
wandb:      train/ensemble_f1 ▁▂▁▁▄▂▅▄▆▆▅▆▃▄▃▇▆▆█▇▆▇█▇▅▄▆▅▆▇█▆▆█▅▆▅▆▆▆
wandb:         train/mil_loss █▇██▆▅▅▄▄▄▅▅▃▅▄▃▄▄▄▄▄▃▃▃▂▂▃▂▂▂▂▂▂▁▂▁▂▂▁▁
wandb:      train/policy_loss ██▂███████████████▁▂▃▁▁▃▃▃▂▃▁▄▂▂▃▂▃▂▁▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████▁▂███▃▂▁▂▂▃▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45833
wandb: best/eval_avg_mil_loss 0.9221
wandb:  best/eval_ensemble_f1 0.45833
wandb:            eval/avg_f1 0.45833
wandb:      eval/avg_mil_loss 0.82694
wandb:       eval/ensemble_f1 0.45833
wandb:            test/avg_f1 0.46944
wandb:      test/avg_mil_loss 0.95676
wandb:       test/ensemble_f1 0.46944
wandb:           train/avg_f1 0.45577
wandb:      train/ensemble_f1 0.45577
wandb:         train/mil_loss 0.81625
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vzh93eww
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_194825-vzh93eww/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n461pe41 with config:
wandb: 	actor_learning_rate: 0.0026054490517298024
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1347176655980622
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11345801489144436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195248-n461pe41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n461pe41
wandb: Job received.
wandb: Agent Starting Run: e3u3ij2g with config:
wandb: 	actor_learning_rate: 0.0015807391327740145
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13304699820583454
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7595406859598877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195312-e3u3ij2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3u3ij2g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▇▃▂▃▆▆▆▂▆▃▃▅▄▆▄▄▅▃▆▅▇▃▅▄▄▄▆▆▃▄▄▄▆▁█▆▄▄
wandb:      train/ensemble_f1 ▃▄▂▂▄▁▆▅▂▆▅▄▆▁▄▂▃▂▄▄▅▃▆▄▂▃▆█▄▄▄▁▄▁▄▆▃█▃▂
wandb:         train/mil_loss ▂▁▃▂▃▆▂█▂▅▂█▄▂▅▅▇▃▄▃▅▄▄▆▄▆▄▄▁▃▅▆▄▇▂▄▃▂▆▆
wandb:      train/policy_loss ▇▇▅▇▃▂█▇▅▆▅▃▄▅▂▁▅▆▅▇▄▇▄▅▄▆▅▅▄▄▅▅▅▇▃▃▅▇▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▄▆▆▃▄▅▆▃▅▇▁▃▆▄▆▆▇▇▄▄▆▅▃▃▄▆▃▄▇▃▃▆▅█▇▇▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97707
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.94895
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.10558
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 0.72099
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w1chra5z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195138-w1chra5z/logs
wandb: Agent Starting Run: g3kmfc3v with config:
wandb: 	actor_learning_rate: 3.5727863371569975e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3299695019795451
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02624993810531784
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195337-g3kmfc3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3kmfc3v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▄▃▄▆▅▅▄▃▄▄▄▅▅▅▅▃▄▆▃▃▅▃▅▃▇▃▆▃▃█▅▄▅▁█▂▆
wandb:      train/ensemble_f1 ▄▄▄▆▄▆▄▅▃▅▆▇▄▄▄▆▄▆█▆▅▄▅▃▅▇▃▆▅▅█▃▂█▃▃▄▅▁▃
wandb:         train/mil_loss ▁▂▃▂▃▂▂▅▅▃▁▂▅▃▃▃▅▇▅▄▇█▄▂▃▄█▃▂▄▂▂▄▂▃▄▂▄▂▃
wandb:      train/policy_loss █▇█▅██▅█▅▇███▁▇▇▇▅▇▇▄▄▇█▄▇███▇██▇▇█▇█▇██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▇█▇████▇██▁█▇▇▇▇▄▇▄▄▇▇████▇██▇██▇█▂▇██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.28297
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.21218
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.88192
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32031
wandb:      train/ensemble_f1 0.32031
wandb:         train/mil_loss 0.58745
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n232sjni
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195232-n232sjni/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dup5wb9r with config:
wandb: 	actor_learning_rate: 0.0001466365867625854
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9217995381211684
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7900554818374546
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195432-dup5wb9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dup5wb9r
wandb: uploading history steps 57-70, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆█
wandb: best/eval_avg_mil_loss ██▃▁
wandb:  best/eval_ensemble_f1 ▁▂▆█
wandb:            eval/avg_f1 ▁▁▆█▆▃▃▂▂▂▂▂▂▂▂▂▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆
wandb:      eval/avg_mil_loss ███▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁█▆▆▂▂▁▁▁▁▁▁▁▁▁▁▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁█▇█▅▄▃▄▄▁▄▂▄▂▂▄▅▄▅▃▅▄▃▃▄▅▅▄▆▅▄▄▅▄▄▄▅▅▆▇
wandb:      train/ensemble_f1 ▁█▅▃▅▃▂▅▄▃▃▅▂▄▃▃▅▅▅▁▅▅▄▅▄▆▆▅▄▅▅▅▅▅▄▄▆▆▆▇
wandb:         train/mil_loss █▆▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▂▂▂▂▂▁▁▁▂▂▁▂▁▁▁
wandb:      train/policy_loss ██████████████████████████████████████▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80767
wandb: best/eval_avg_mil_loss 0.54796
wandb:  best/eval_ensemble_f1 0.80767
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.58422
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.85144
wandb:      test/avg_mil_loss 0.58013
wandb:       test/ensemble_f1 0.85144
wandb:           train/avg_f1 0.7875
wandb:      train/ensemble_f1 0.7875
wandb:         train/mil_loss 0.77152
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glamorous-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3u3ij2g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195312-e3u3ij2g/logs
wandb: uploading history steps 71-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂█▅▅▄▅▃▅█▂▅▃▆▃▇▄▇▆▆▅▇▆▃▆▂▃▅▅▁▄▆▇▅▅▃▅▄▄▃
wandb:      train/ensemble_f1 ▇▄█▄▄▆▅▅▆▇▅▆▅▆▄▃▇▆▄▄▅▆▇▆▄▅▃▄▇▅▅▅▃▅▁▅▄▅█▄
wandb:         train/mil_loss ▄▅▆▆▆▇▄▅█▃▆▆▅▆▇█▆▆▆▅▆▄▄▄▄▄▁▄▄▅▄▃▅▅▆▅▆▄▆▄
wandb:      train/policy_loss ▄▂▄▂▂▅▅▃▆▅▁▁▃▂▅▆▄▃▁▄▃▂▃▃▃▃█▄▃▂▄▄▂▃▄▄▁▂▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▁▆▃▂▂▂▂▆▆█▂▅▃▄▃▂▂█▄▂▅▃▂▃▃█▄▃▄▄▄▄▂▄▃▃▁▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.02007
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.93301
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12385
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3266
wandb:      train/ensemble_f1 0.3266
wandb:         train/mil_loss 0.81114
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n461pe41
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195248-n461pe41/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: xbs7w9nh with config:
wandb: 	actor_learning_rate: 0.0006271589270474879
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03228798538019417
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3706628480949522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195512-xbs7w9nh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xbs7w9nh
wandb: Job received.
wandb: Agent Starting Run: wvakyu8n with config:
wandb: 	actor_learning_rate: 5.692333910756081e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5437314744658538
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5021226538346205
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195516-wvakyu8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvakyu8n
wandb: uploading history steps 96-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇██▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆█▄▆▂▅▄▃▃▂▄▄▄▅▃▂▆▃▄▄▂▅▃▂▇▄▂▄▃▁▃▄▆▃▁▃▃▆
wandb:      train/ensemble_f1 ▂▅▆▆▄▂▄▃▂▄▂▄▄▅▃▄▂▃▅▃▃▄▄▄█▂▁▆▂▄▂▂▅▆▇▄▆▂▃▂
wandb:         train/mil_loss ▃▅▅██▆▆▆▇▆▂▆▅▆▃▃▄▅▅▁▇▅▄▃▆▄▁▁▃▃▇▃▆▆▃▅▅▅▃▃
wandb:      train/policy_loss ▄▄▄▅▄▄▆▄▄▄▅▅▆▅▂▄▆▅▄▄▅▄▃█▅▃▄▅▇▄▄▅▅▄▃▁▂▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▄▅▂▆▅▄▅▆▅▃▅▄▃▄█▅▄▅▄▄▇▅▅▅▄▁▃▅▅▇▄▅▅▂▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.83877
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.812
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93515
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32318
wandb:      train/ensemble_f1 0.32318
wandb:         train/mil_loss 0.69121
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3kmfc3v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195337-g3kmfc3v/logs
wandb: Agent Starting Run: wpk5e1dx with config:
wandb: 	actor_learning_rate: 0.001874545687656236
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.93450982772848
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8806806002211512
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195536-wpk5e1dx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wpk5e1dx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▁▂▂▂▂▁▁▂▃▃▂▂▄▄▄▅▄▄▅▄█▇▅▅█▅▄▃▃▇▅▃▅▅▄▅▃▆
wandb:      train/ensemble_f1 ▃▄▃▁▃▂▃▃▄▇▇▅▄▆▅▅▅█▅▆▆▅▆▅▅▄▄▆▄▇▆▆▅▆▆▇▅▆▅▇
wandb:         train/mil_loss ▃▁▄▃▃▃▂▅▃▆▃▄▄▄▂▃▅▅▇▂▅▅▂▁▆▅▄▃▅█▃▄▇▂▄▅▅▃▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.75165
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.74478
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.56573
wandb:      test/avg_mil_loss 0.71675
wandb:       test/ensemble_f1 0.56573
wandb:           train/avg_f1 0.61212
wandb:      train/ensemble_f1 0.61212
wandb:         train/mil_loss 0.58155
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dup5wb9r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195432-dup5wb9r/logs
wandb: Agent Starting Run: xr27hjye with config:
wandb: 	actor_learning_rate: 0.0002841230895533952
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9605302523127122
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21273899013387676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195626-xr27hjye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xr27hjye
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▂▆▅█▄▄▄▆▃▅▃▅▆▅▅▂▅▄▆▃▅▃▆▃▅▅▂▃▅▅▁▄▃▂▅▅▆▄
wandb:      train/ensemble_f1 ▅▆▆▃▄█▄▄▆▄▄▆▆▁▄▆▆▆▄▅▄▇▆▆▆▄▅▆▆▄▆▅▅▆▂▅▄▇▄▅
wandb:         train/mil_loss ▄▆▄▇▇▅▄▅▅▃▇▅▆█▆▂▃▄▃▆▁▅▃▃▆▂▂▂▂▄▄▁▄▃▃▄▃▄▂▂
wandb:      train/policy_loss ▁▁▃▁▁▃▃▃▁▁▁▃█▆▁▁▆▃▁▃▁▃▃▁▁▁▁▁▃▃█▁▃▆█▁▁▃▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▁▁▁▃▃▁▁▆▁█▃▁▁▃█▁▁▁▃█▁▃▃▁▁▃▃▃▁▃█▃▆▁▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.03987
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95478
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.16349
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.89269
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xbs7w9nh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195512-xbs7w9nh/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁█▅▄▃▃▃▃▇▄▅▆▃▅▃▄▅▅▅▇▆▅▄▅▅▅▃▄▃▂▅▇▃▇█▃▆█▅▅
wandb:      train/ensemble_f1 ▆█▁▆▄▄▃▄▁▂▃▅▁▃▂█▄▄▅▄▅▅█▃▅▃▃▅▄▄▄▆▇▃▃▇▃▄▄▆
wandb:         train/mil_loss █▆▆▂▄█▄▂▅▃▂▃█▆▅▆▂▇▂▄▄▃▄▂▄▄▂▅▄▄▇▂▄▂▆▃▂▂▁▃
wandb:      train/policy_loss ▃▂▄▂▃▅▄▆█▅▄▄▄▆▆▄▅▅▅▃▅▇▅▂▄▆▅▇▄▁▃▂▄▆▅▃▅▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▃▃█▅▄▆▄▇▃▆▆▆▅▇▅▃▃▇▇▃▅▃▇▂▄▃▃▄▄▃▄▆▁▆▅▅▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 0.8187
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.78736
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.6865
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.43152
wandb:      train/ensemble_f1 0.43152
wandb:         train/mil_loss 0.69354
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run graceful-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvakyu8n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195516-wvakyu8n/logs
wandb: Agent Starting Run: 4nn864kw with config:
wandb: 	actor_learning_rate: 1.8909894193558748e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4643098031796858
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6699181938333193
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195706-4nn864kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4nn864kw
wandb: Agent Starting Run: dexflclf with config:
wandb: 	actor_learning_rate: 0.0010070579689842678
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8047580845351008
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4216474084624806
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195711-dexflclf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dexflclf
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▅▅▅▅▅▆███▄▄▄▄▃▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▄█▁▂▂▆▅▅▅▂▆▃▄▄▃▃▆▃▃▆▃▄▁▃▆▃▅▄▅▂▂▆▄▇▆▂█
wandb:      train/ensemble_f1 ▅▆▅▁▄▄▆▂▅▅▄▄█▆▃▃▃▆▁▅▁▅▅▄▃▆▃█▇▄▂▅▅▆▅▄▇▅▆█
wandb:         train/mil_loss ▄▁▄▅▅▄▄▂▅▄▅▃▆▄▃▄▅▂▃▂▄▄▂▄▄▅▂▂▇▁▄▃▃▅▄▄█▄▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.85088
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.8431
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.72379
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.44224
wandb:      train/ensemble_f1 0.44224
wandb:         train/mil_loss 0.6191
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wpk5e1dx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195536-wpk5e1dx/logs
wandb: Agent Starting Run: qjria3jq with config:
wandb: 	actor_learning_rate: 1.4301714725941977e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9995092787500046
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4165251431051972
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195735-qjria3jq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjria3jq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆████▇▆▆▅▅▅▄▄▄▄▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▆▆▆▆▆▆▆▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▂▅▁▅▆▃▅▅▅▃█▄▅▄▄▅▆▆▅▇▅▄▇▅▄▆▆▅█▆▂▄█▆▅▄▅▄
wandb:      train/ensemble_f1 ▂▅▅▄█▁▅▂▅▅▂▆▃▂█▅▄▇▅▃▅▆▅▄▄▇▅▄█▅▂▇▆▃▇▃▆▂▅▄
wandb:         train/mil_loss ▄▂▃▂▃▅▅▆▇▄▄▃▅▆▄▃▄▇▅▃█▂▅▆▄▆▁▁█▃▄▆▇▆▃▃▂▂▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57033
wandb: best/eval_avg_mil_loss 0.51686
wandb:  best/eval_ensemble_f1 0.57033
wandb:            eval/avg_f1 0.57033
wandb:      eval/avg_mil_loss 0.51637
wandb:       eval/ensemble_f1 0.57033
wandb:            test/avg_f1 0.63636
wandb:      test/avg_mil_loss 0.46742
wandb:       test/ensemble_f1 0.63636
wandb:           train/avg_f1 0.60296
wandb:      train/ensemble_f1 0.60296
wandb:         train/mil_loss 0.58355
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xr27hjye
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195626-xr27hjye/logs
wandb: Agent Starting Run: 4tnsbht8 with config:
wandb: 	actor_learning_rate: 0.0002993043118465852
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5327048956117311
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22536787423717708
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195820-4tnsbht8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tnsbht8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▆▃▄▂▃▅▆▄▄▆▆▄▃▅▄▇▂▄▄▄▁▃▆▅▆▃▆█▅▅▃▆▆▆▆▆▆
wandb:      train/ensemble_f1 ▄▂▄▇▆▂▆▂▃▆█▄▆▆▄▄▄▃▅▄▇▅▂▅▄▁▅▅▂▆▅▆▁▆▆▅▆█▄▅
wandb:         train/mil_loss ▂▃▆▄▆█▄▄▆▆▄▅▃▃▅▇▆▃▃▅▃▄▅▆▅▄▅▄▆▅▃▄▆▁▂▅▄▄▅▁
wandb:      train/policy_loss ▅▃▅▃▆█▂▄▁▆▇▅▆▃▅▆▇▄▃▅▆▂▄▆▃▅▅▅▇▅▄▅▃█▃▄▅▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▅▁▄▆▂▅▆▃▄▃▆▃▆▇▃▃▄▃▃▄▃▆▇▃▅▃▃▃▄▅▄▂█▂▃▅▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.95884
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.89955
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.07959
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 0.64272
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4nn864kw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195706-4nn864kw/logs
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▂▇▃▂▇▇▅▅▂▃▂▃█▃▁▄▃▄▆▅▆▄▅▅▃▃▃▁▅▃▄▇▅█▂▅▄
wandb:      train/ensemble_f1 ▄▅▂▃▅▃▅▅▃▁▄▁▂▄▁▄▂▅▇▆█▅▆▁▅▃▄▂▅▄▂▁▄▅▃▂▅▅▄▅
wandb:         train/mil_loss ▃▄▄▅▅▂▄▄▃▁▃▄▇▁▃▇▄▆▅▄▂▆▃▃▅▂▃▁▄▅█▃▅▄▁▃▇▃█▂
wandb:      train/policy_loss ▆▃▆▇▃▅▄▇▆▄▅▇▅▅▆▅▅▅▄▆▅▄▄▅▄▆▅▅▆█▇▄▅▅▇▁▅█▇█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▂▅▅▂▁▃▅▄▄▆▄▄▇▆█▄▅▄▅▇▇▆▃▄▇█▆▅▆▄▁▄▃▆▅▆▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 4.49838
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.4166
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 5.47175
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32886
wandb:      train/ensemble_f1 0.32886
wandb:         train/mil_loss 0.91763
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dexflclf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195711-dexflclf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Agent Starting Run: r82brdyb with config:
wandb: 	actor_learning_rate: 0.001985135500184427
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.001999688660232035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09239361272866232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195904-r82brdyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r82brdyb
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/usr/lib64/python3.9/shutil.py", line 740, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/usr/lib64/python3.9/shutil.py", line 738, in rmtree
    os.rmdir(path)
OSError: [Errno 39] Directory not empty: '/scratch-local/nbraakman.12077268/pymp-382xwbq7'
wandb: Job received.
wandb: Agent Starting Run: 1gh80rzh with config:
wandb: 	actor_learning_rate: 0.0025776583294143084
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6258786781216265
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7031045533875501
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195929-1gh80rzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1gh80rzh
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▆▄██▄▃▅▅▃▄▄▇▅▄▁▄▅▅▆▂▅▃▃▃▅▃▇▂▄▇▃▂▆▄▂▃▇▃
wandb:      train/ensemble_f1 ▆▂▃▇▆▇▄▄▄▄▄▅▂▄▂▅▄▅▃▁▂▅▃▅▇▂▅▃▂▃▃▄▃▃▆▄▅▃▆█
wandb:         train/mil_loss ▅█▆▇▆▄▃▃▆▃▁▆▃▆▄▆▂▄▃▂▅▄▅▃▄▂▃▂▃▅▇▅▁▄▄▂▄▃█▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.11363
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.1271
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.91393
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.44127
wandb:      train/ensemble_f1 0.44127
wandb:         train/mil_loss 0.59263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjria3jq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195735-qjria3jq/logs
wandb: Agent Starting Run: xc4xs3ih with config:
wandb: 	actor_learning_rate: 5.091497579229059e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09330342646689538
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5182528415776766
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_195936-xc4xs3ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xc4xs3ih
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▃▅▄▄▃█▁▅▅▄▆▆▃▇▃▄▅▃▂▄▄▃▆▂▂▄█▅▇▃█▂▄▃▄▅▃
wandb:      train/ensemble_f1 ▃▃▂▅▃▃▂▃▅█▄▅▃▅▂▆▄▅▆▁▂▇▂▃▄▅▆▂▄▁▃▄▃▆▄▅▁▄▃▅
wandb:         train/mil_loss ▇▄▆▇▅▅▅▃▃▆▅▆▆█▂▅▅▇▅▅▃▆▅▆▃▅▇▄▅▃▃▂▆▄▁▃▄▄▄▅
wandb:      train/policy_loss ▁▁▁▁█▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82153
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.8039
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.91858
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3383
wandb:      train/ensemble_f1 0.3383
wandb:         train/mil_loss 0.78151
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r82brdyb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195904-r82brdyb/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.52.131.3:43694->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: 68ytzl3a with config:
wandb: 	actor_learning_rate: 0.006913382819777391
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.910978963305379
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6088068845116051
wandb: uploading history steps 99-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▁█
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▁████████████████████████████▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ▇█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂
wandb:         train/mil_loss ▂▂▁▅▆▇▄▆▆▇▃▅▆▆▄▄▄▄▅▅▄▅▄▇▅▄█▆▆▄▆▄▅▅▅▆▅▅▄▃
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▇▆▃▂▆▆▂▆▄▅▆▆▅▅▆▃▃▁▆▆▆▆▆▂▆▇▅▃█▁▅▆▆▅▆▅▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76316
wandb: best/eval_avg_mil_loss 0.5232
wandb:  best/eval_ensemble_f1 0.76316
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99094
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.85806
wandb:      test/avg_mil_loss 0.38877
wandb:       test/ensemble_f1 0.85806
wandb:           train/avg_f1 0.34694
wandb:      train/ensemble_f1 0.34694
wandb:         train/mil_loss 0.63737
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1gh80rzh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195929-1gh80rzh/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200122-68ytzl3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68ytzl3a
wandb: Agent Starting Run: 6mg83ocq with config:
wandb: 	actor_learning_rate: 0.0027076801599145855
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8774495644253766
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.39391037303146337
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200128-6mg83ocq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6mg83ocq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▆▅▄▆▃█▂▄▆▆▇▅▆▇▆▅▆▆▃▄▄▁▅▁▆▇█▃▅▄▄▂▄█▃▄▄
wandb:      train/ensemble_f1 ▄▄▄▆▆█▆▂▅▅▅▅▅█▅▆▄▅▅▆▆▆▄▃▆▅▇▃▇▁▅▄▅▅▄▄▂▃▄▃
wandb:         train/mil_loss ▅▅▃▇█▇▄▄▅▄▇▄▄▅▇▅▄▄▇▅▅▅▅▄▆▂▂▅▅▃▁▄▄▄▃▂▄▅▃▅
wandb:      train/policy_loss ▅▄▇▄▂▁▅▅▂▅█▂▄▁▄█▄▄▂▁▄▄▅▁▅▂▇▄▄▇▂▂▅▄▇▂▅█▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▄▄▇▂▁▂▂▅▄▅▂▄▂▅▅▂▂▂▁▄▇▁▅▄▅▄▄▄▇▂▄▁▂▅█▇▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.65283
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.50228
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.081
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3448
wandb:      train/ensemble_f1 0.3448
wandb:         train/mil_loss 1.55307
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xc4xs3ih
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195936-xc4xs3ih/logs
wandb: Agent Starting Run: 8daw8syu with config:
wandb: 	actor_learning_rate: 0.00045501208671639126
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2796792045657759
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7540463960233863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200134-8daw8syu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8daw8syu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▄▄▄▄▁▃▃▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆████████████
wandb:      eval/avg_mil_loss ████▇▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▁▁▄▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▁▃▃▂▃▄▅▅▆▅▃▄▃▅▅▆▄▅▂▇▃▃▄▂▄▇▄▇▇▄▅▃▂▄▃█▅
wandb:      train/ensemble_f1 ▄▄▆▃▅▅▅▂▅▃▁▅▁▄▆▆▇▄▇▄▂▆▅▆▆▇▇▆▆▆█▆▅▄▃▄▆▇▆▇
wandb:         train/mil_loss ▃▅▇▇█▃▄▆▇▆▄▆▄▅▅▅▃▇▇▇▆▅▄▄▆▇▅▇▅▇▃█▂▄▆▆▆▄▁▅
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▃▃▄▆█▄▅▇▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78
wandb: best/eval_avg_mil_loss 0.48312
wandb:  best/eval_ensemble_f1 0.78
wandb:            eval/avg_f1 0.78
wandb:      eval/avg_mil_loss 0.47312
wandb:       eval/ensemble_f1 0.78
wandb:            test/avg_f1 0.81737
wandb:      test/avg_mil_loss 0.45613
wandb:       test/ensemble_f1 0.81737
wandb:           train/avg_f1 0.76659
wandb:      train/ensemble_f1 0.76659
wandb:         train/mil_loss 0.54383
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tnsbht8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_195820-4tnsbht8/logs
wandb: Agent Starting Run: cxd6312c with config:
wandb: 	actor_learning_rate: 8.18284791814591e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8762861993540931
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04219698584961129
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200233-cxd6312c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cxd6312c
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▃▅▆▃▄▆▅▃▅█▅▄▆▅▂█▆▄█▂▁▅▂▆▃▆▁▅▂▅▆▅▁▄▅▅▅
wandb:      train/ensemble_f1 ▃▂▆▆█▄▄▃▅▅▄▆▅▄▅▃▄▃▁█▅▄▃▆▅▄▅▃▅▄▅▄▆▄▅▅▆▄▅▄
wandb:         train/mil_loss ▂▃▁█▇▅▃▄▄▃▃▃▃▁▅▂▇▇▂▃▁▂▄▃▃▅▅▂▇▃▄▅▃▂▃▁▃▂▃▄
wandb:      train/policy_loss ▅▅▆▆▁▇▃▆▅▄▇▅▄▆▅▂▂▃▇▆▅▅▆▇▃▃▅▅▆▆▇▆▆▃█▆▆▃▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▃▆▁▅▅▅▃▅▅▅▄▇▅▅▂▂▃▇▆▇▅▇▅▅▅▅▄▆▄▆▇▆█▆▅▆▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.06147
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.89609
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.63549
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33444
wandb:      train/ensemble_f1 0.33444
wandb:         train/mil_loss 0.78015
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6mg83ocq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200128-6mg83ocq/logs
wandb: Agent Starting Run: 0z4vtlx4 with config:
wandb: 	actor_learning_rate: 0.00026437331995629533
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.39212945582722913
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9104705684975856
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200322-0z4vtlx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0z4vtlx4
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▂▁▄▃█▄▁▄▃▃▂▄▅▄▃▅▃▅▃▄▃▃▅▅▄▁▇▅▅▂▃▃▆▄▆▆▃▆
wandb:      train/ensemble_f1 ▂█▆▇▃▂▅▃▆▄▅▇▄▃▃▃█▄▄▆▅▅▄▇▃▁▄▄▇▅▂▄▆▄▄▆▆▅▇█
wandb:         train/mil_loss ▇▆▅▂▅▄▅▃█▄▆▄▄▄▂▅▅▃▄▅▅▃▃▃▅▃▁▂▄▃▄▂▄▄▄▄▃▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.105
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.99613
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.90443
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.43577
wandb:      train/ensemble_f1 0.43577
wandb:         train/mil_loss 0.90543
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8daw8syu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200134-8daw8syu/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▂█
wandb:            eval/avg_f1 █████████▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▄▇▇▇▇█████████████████████████████
wandb:       eval/ensemble_f1 ████████▅▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▇▇▇▆▆█▅▅▃▃▃▂▃▂▃▁▁▂▂▃▂▂▁▂▂▂▃▂▁▁▃▂▂▂▂▁▂▂
wandb:      train/ensemble_f1 ▄▃▄▄▄▃▄▄▃█▆▃▃▃▃▂▁▂▂▁▁▂▁▂▂▁▁▂▁▂▂▂▁▂▂▂▁▂▂▂
wandb:         train/mil_loss ▅▅▆▃▇▃▄▄▅▇▅▇▆▆▄▃▁▄▅▄▅▅▄▆▅▆▄▅▆▅▅▅▅▆█▇▃▂▄▁
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.41951
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 0.77625
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.77349
wandb:      test/avg_mil_loss 0.48417
wandb:       test/ensemble_f1 0.77349
wandb:           train/avg_f1 0.46656
wandb:      train/ensemble_f1 0.46656
wandb:         train/mil_loss 0.58708
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/68ytzl3a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200122-68ytzl3a/logs
wandb: Agent Starting Run: jvhkgscd with config:
wandb: 	actor_learning_rate: 0.00032461906610660473
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8952351228619408
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9651823036201728
wandb: Agent Starting Run: lqlxuhfo with config:
wandb: 	actor_learning_rate: 0.00037251461019115954
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4623652427201669
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1363481264080425
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200343-lqlxuhfo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqlxuhfo
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200343-jvhkgscd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jvhkgscd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▃▃▂▃▁▂▅▃▄▄▄▅▄▇▂▇▄█▅▅▆▂▅▃▃▄▂▄▂▄▃▇▄▃▃▂▃▃
wandb:      train/ensemble_f1 ▄▁▄█▅▃▄▃▃▅▅▆▅▇▂▆▄▃▄▄▅▆▅▅▄▅▅▅▆▅▄▃▅▅▄▃▃▃▄▄
wandb:         train/mil_loss ▄▆▅▆▃▂▂▅▂▄▅▄▄▅▂▅▇▄▅█▄▇▄▄▃▇▆▁▂▆▃▅▂▃▄▄▇▆▄▂
wandb:      train/policy_loss ▃▄▅▅▅▄▇▃▅▇▅▇▄▁▇▅▁▃▂▁▅▂▅▄█▅▆▃▆▇▅▃▇▄▄█▄▇▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▅▃▅▆▂▅▃▃▇▃▇▇▅█▄▁▇▅▃▅▆▆▄▅▂▆█▂▄▃▇▅▂▄▇▅▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.92545
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.86967
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.04319
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.66034
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0z4vtlx4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200322-0z4vtlx4/logs
wandb: Agent Starting Run: hsnn22mt with config:
wandb: 	actor_learning_rate: 0.003391726760553613
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05008231085556192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0679382324945681
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200516-hsnn22mt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hsnn22mt
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▇▇▆▄▅▄▁▄▅▂▄▅▃▇▇█▄▂▆▄▆▅▂▆▆▄█▄█▆▆▇▄▄▇▄▆▄
wandb:      train/ensemble_f1 ▄▄▅█▄▄▆▁▆▂▄▆▃▃▄▂█▄▇▁▁▅▇▆▄▅▄▄▇▇▆▇▆▃▅▄▆▄▇▂
wandb:         train/mil_loss ▃▆▃▃▂▆▇▅▅▆▆▇▇█▆▅▄▅▄▄▆▂▄█▄▅▄▄▄▆▆▄▃▆▁▆▅▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.53148
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.35282
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.07851
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.4014
wandb:      train/ensemble_f1 0.4014
wandb:         train/mil_loss 0.92632
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lqlxuhfo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200343-lqlxuhfo/logs
wandb: Agent Starting Run: plfup8ct with config:
wandb: 	actor_learning_rate: 1.4857099772796345e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.385662173942117
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1847956690383722
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200537-plfup8ct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/plfup8ct
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▆▄▆▃▇▇▃▁▇▄▃▅▆▃▃▄▄▇▇▇▆▅█▇▇▆▆▅▆▄▅▆▇▇▆▄▄
wandb:      train/ensemble_f1 ▇▄▄▆▅▄▅▅▄▃▃▁▄▄▂▆▃▄▄▃▆▄▄▅▆▆▆▄▅▆▄█▅▄▃▅▆▆▅▄
wandb:         train/mil_loss ▄█▄▇▆▄▅▃▆▇▂▂▄▅▁▆▂▄▅▃▄▄▅▇▄▄▅▄▃▃▃▅▄▂▅▄▂▂▃▃
wandb:      train/policy_loss ▄▁▇▂▅▇█▅▂▂▅▂▇▇▁▇█▄▂▅▅▅▂▄▅▄█▄▄▇▅▅▂▇█▄▄█▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▃▇▇▄▄▆▆▆▇▇▂▃▇█▄▁▃▅▆▆▆▄▅█▅▅▅▆▇▆▅▆▄▅▆▄▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.95722
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.94473
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.04935
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 0.63861
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jvhkgscd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200343-jvhkgscd/logs
wandb: Agent Starting Run: stars2qj with config:
wandb: 	actor_learning_rate: 2.2731746498077965e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05557519178420933
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.34400786124792637
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200543-stars2qj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/stars2qj
wandb: uploading history steps 187-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:      eval/avg_mil_loss █▆▆█▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▅▃▃▃▄▃▃▃▃▃▃▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▁▃▃▁▄▂▆▃▂▅▄▅▃▂▁▃▆▃▄▃▆▆▅▃▂▅▆▂▆▄▄▄▄▆▁▃▅▅
wandb:      train/ensemble_f1 ▃▃▂▄▃▃▂▃▂▂▂▄▁▂▅▁▂▃▃▁▅▂▃▃▃▃▅▄▄▅▅█▃▄▂▅▃▅▅▆
wandb:         train/mil_loss ▄▅▇▄▃▅▅▃▅▇▇▅█▄▆▅▅█▆█▁▅▅▃▄▃▅▅▄▃▆▆▄▆▄▄▇▆▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▁▃▂▄▃▃▄▂▃▄▂▁▂▂▂▃▂████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49699
wandb: best/eval_avg_mil_loss 0.90595
wandb:  best/eval_ensemble_f1 0.49699
wandb:            eval/avg_f1 0.49699
wandb:      eval/avg_mil_loss 0.8912
wandb:       eval/ensemble_f1 0.49699
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 1.11601
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.46733
wandb:      train/ensemble_f1 0.46733
wandb:         train/mil_loss 0.62053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cxd6312c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200233-cxd6312c/logs
wandb: Agent Starting Run: miw1ome7 with config:
wandb: 	actor_learning_rate: 0.0007310290738851288
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5065915861213013
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8518523265731107
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200603-miw1ome7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/miw1ome7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▇▂▅▂▅▆▄▅▄▅▅▅▂▇▅▂▄█▅▁▃▃▃▅▇▅▃▂▄▇▃▂▆▅▄▆▆▃
wandb:      train/ensemble_f1 ▇▅▃▄▅▆▆▃▄▆▅▆▆▆▅▅▆▆▃▅▇▃▄▅▄▅▆▆▆█▅▄▁█▄▆▅▄█▄
wandb:         train/mil_loss ▄██▄▇▃▄▂█▆▆▅▅▆▅▆▄▃▅▃▄▃▃▄▇▄▆▆▄▄▂▃▃▃▃▂▅▁▄▄
wandb:      train/policy_loss ▅▁▄▄▄▁█▄▂▁▂▅▂▄▄▄▇▁▅▇▂▁▂▂▂▂▂▅▂▂▂▁▄▄▂▁▂▂▁▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▁▁▄▁▃▃▅▁▁▁▃▃▃▅▄▄▁▁▆█▁▃▁▆▁▅▃▃▁▅▁▆▃▅▁▁▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.08845
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99663
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.19758
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 0.93735
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hsnn22mt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200516-hsnn22mt/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xq6wl8hc with config:
wandb: 	actor_learning_rate: 2.3725243526038477e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.014938230096460224
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.885741867966223
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200717-xq6wl8hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xq6wl8hc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▇▄▄▇▅▆▃▅▄▆▇▄▇▆▆▇▃▅▆▇▄▁▃▆▇█▆▇▅▂▆▃▄▄▅▄▃▅
wandb:      train/ensemble_f1 ▅▁▅▇▂▄▆▁▇▄▂▃▆▅▄▇▁▄▂▂▄▃▄▃▄▃█▂▅▃▆▂▆▄▅▂▂▅▃▃
wandb:         train/mil_loss ▆▆▅▆▅▇██▅█▄▆▆▅▆▅▅█▇▄▄▄▅▅▅▃▄▄▁▄▄▇▄▅▂▆█▆▄▇
wandb:      train/policy_loss ▄▅▆▄▂▄▅▄▄▄▇▃▄▂▃▄▃▄▄▄▂▂▄▃█▄▄▅▅▁▅▄▅▂▂▂▅▄▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▃▅▄▆▇▃▄▂▃▄▅▄▂▃▄▄▆█▃▅▄▅▅▇▁▇▅▁▃▅▂▂▅▅▄▅▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.9816
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96341
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09245
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 0.83843
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/plfup8ct
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200537-plfup8ct/logs
wandb: Agent Starting Run: m0si4hrj with config:
wandb: 	actor_learning_rate: 0.0008337499611461259
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7162051918251394
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42980075704596354
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200731-m0si4hrj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m0si4hrj
wandb: uploading history steps 97-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▅▅▃▅▆▂▄▃▄▅▁▄▄▃▆▃▆█▅▄▅▂▅▃▂▆▄▄▄▄▃▆▄▆▅▅▄
wandb:      train/ensemble_f1 ▃▆█▃▃▅▃▆▇▇▄▁▅▃▃▇▆▆▅▆▅▅▆▅▅▇▇▃▄▃▄▇▆▇▆▆▆▃▅▅
wandb:         train/mil_loss ▄▆▆▅▂▆▃▄▁▂▄▅▅█▄▅▆▆▅▅▆▄▅▅▃▃▄▄▄▅▁▄▃▃▅▂▄▂▂▂
wandb:      train/policy_loss ▁▃▁▅▃██▂▂▂▂▂▂▁▁▃▁▁▃▆▃▂▄▁▁▁▆▃▁▃▂▃▂▂▁▂▆▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▅█▁▅▁▃▅▃▅▅▃▃▁▃▃▅▁▅▅▃▅▃▁▁█▅▃▃▅▆▃▅▁▄▄▆▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.67338
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.51364
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.1009
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 1.54151
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/stars2qj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200543-stars2qj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vdk0xubw with config:
wandb: 	actor_learning_rate: 0.000841914613936226
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5613951838399257
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7617865282007767
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200748-vdk0xubw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vdk0xubw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▇▇▇█▇▇▇▇▆▄▄▅▅▄▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▇▇███████▆▆▄▅▅▅▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▇▇▄▃▄▄▃▃▃▃▃▂▂▂▂▂▃▁▃▂▂▃▃▁▂▃▂▂▁▃▂▂▂▃▂▃▂
wandb:      train/ensemble_f1 ▆█▆▇▆▆▆▆▅▄▃▄▂▃▃▂▃▃▂▃▁▁▂▂▃▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂
wandb:         train/mil_loss ▇▄▅▆▅▅▃▅▆▅▆▆▂▃▄▅▃▃▆▃█▄▆▁▂▃▆▁▅▅▃▅▅▄▃▄▄▅▂▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▂▂▅▄▁█▄▄▄▄▄▄▄▄▆▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅▅▅▅▅▅▅▃▅▅▅▇▇█▇▃▅▅▁▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78829
wandb: best/eval_avg_mil_loss 0.6011
wandb:  best/eval_ensemble_f1 0.78829
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.64299
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.8205
wandb:      test/avg_mil_loss 0.63425
wandb:       test/ensemble_f1 0.8205
wandb:           train/avg_f1 0.60708
wandb:      train/ensemble_f1 0.60708
wandb:         train/mil_loss 0.59889
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/miw1ome7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200603-miw1ome7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mbe7g7a5 with config:
wandb: 	actor_learning_rate: 0.0001158318193390228
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5849979237082084
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7330840775292918
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200825-mbe7g7a5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mbe7g7a5
wandb: uploading history steps 101-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▃▃█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▄▇▅▆▄▅▁▅▅▃▅▂▅▆▇▆▅▅▅▄▆▄▆▅▇▂▇▅▅▄▆▇▅▆▇▅█
wandb:      train/ensemble_f1 ▆▅▇▃▆▃▄▃▄▄▁▅▅▅▅▅▅▄▅▆▆▆▅▅▇▄▆▄▄▃▅▅▃▇▆▇▆▂▅█
wandb:         train/mil_loss ▆▇▆▅█▅▅▅▃▅▇▄▅▄▅▃▄▅▄▅▄▄▅▆▅▄▃▃▂▂▄▃▂▄▃▂▁▃▃▂
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58767
wandb: best/eval_avg_mil_loss 0.7415
wandb:  best/eval_ensemble_f1 0.58767
wandb:            eval/avg_f1 0.57665
wandb:      eval/avg_mil_loss 0.68822
wandb:       eval/ensemble_f1 0.57665
wandb:            test/avg_f1 0.5
wandb:      test/avg_mil_loss 0.79033
wandb:       test/ensemble_f1 0.5
wandb:           train/avg_f1 0.54139
wandb:      train/ensemble_f1 0.54139
wandb:         train/mil_loss 0.69424
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xq6wl8hc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200717-xq6wl8hc/logs
wandb: Agent Starting Run: 1is8td9q with config:
wandb: 	actor_learning_rate: 0.004189246109361316
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.942017021139728
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6372192011252454
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200912-1is8td9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1is8td9q
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▇▆▅▃▂▄▂▄▂█▁▃█▅▅▄▄▅▄▅▅▅▃▂▃▇▇▁▂▄▃▂▄▂▄▆▁▂
wandb:      train/ensemble_f1 ▅▇▃▁█▆▆▄▆▄▅▅▃▅▄█▆▆▆▄▅▆▆▆▅▆▅▇▆▄▆▆▅▇█▅▇▂▅▇
wandb:         train/mil_loss ▁▂▄▂▁▂▅▄▄▅▅▅▄▅▂▂▃▃▅▄▅▃▃▅▂▃▃▃▄▆▂▅▃▄▂▃▄▃█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.81429
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.71253
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.39151
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.3866
wandb:      train/ensemble_f1 0.3866
wandb:         train/mil_loss 1.01718
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m0si4hrj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200731-m0si4hrj/logs
wandb: Agent Starting Run: 0anzyxxl with config:
wandb: 	actor_learning_rate: 0.00018995672201765757
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5124002908935528
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08245822231807343
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_200920-0anzyxxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0anzyxxl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss █▁▄
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▅▅▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▇█████████████████████████████████████
wandb:       eval/ensemble_f1 ▅▅▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃█▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁▂▁▁▁▂▁▂▂▂▂▁▁▁▁
wandb:      train/ensemble_f1 ██▄▁▁▁▂▂▁▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▂▁▁▁▂▂▂▂▂▁▂▂▂▂▁
wandb:         train/mil_loss ▄▃▄▃▄▄▃▃▄▅▇▂▄▅▃▄▂▇▃▄█▃▆▂▃▆▁█▃▄▇▅▃▅▅▂▅▄▂▂
wandb:      train/policy_loss ▁▁▇█▄▆▅▇█▇▇▆▇██▆▇▅▇▇█▇▇▆▇▆█▆█▆▆▆▆▆▆▇█▅▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63942
wandb: best/eval_avg_mil_loss 0.68158
wandb:  best/eval_ensemble_f1 0.63942
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.02105
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.69892
wandb:      test/avg_mil_loss 0.75407
wandb:       test/ensemble_f1 0.69892
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 0.53076
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1is8td9q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200912-1is8td9q/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: olhqvww2 with config:
wandb: 	actor_learning_rate: 1.632277576161568e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8774459608953683
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2917846332779265
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201120-olhqvww2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/olhqvww2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:      eval/avg_mil_loss ▇▆▆▆▅▅▅▅▂▂▂▂▂▂▂▁▁▁▁▁▅▅▅▄▃▃▃▃▇▇▇▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁█▆▆▅▅▅▆▅▃▅▆▄█▆▆▄▆▅▅▇▆▅▅▆▅▅▅▇▄▇▅▅▅▇▅▅▇▄
wandb:      train/ensemble_f1 ▅▄▅▅▃▄▅▃▃▂▆▄▂▅▆▅▅▂▃▅▃▆▂▄█▂▃▃▆▆▆▃▃▅▁▅▅▄▄▁
wandb:         train/mil_loss ▅█▇▂▁▆▃▁▅▂█▇▁▇▂▃▂▂▅▂▂▃▅▃▃▁▃▂▃▄▇▇▆█▅▃▆█▃█
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▁▆▅▃▄▃▃▃█▅▃▅▆▆▄▁▃▆▆▄▄▄▆▆▃▇▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▅▂▆▆▁▄▃▃▃▃▃▃▄▆▄▂▄▂▄▃▃▃▃▄▅▂█▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83897
wandb: best/eval_avg_mil_loss 0.49806
wandb:  best/eval_ensemble_f1 0.83897
wandb:            eval/avg_f1 0.83897
wandb:      eval/avg_mil_loss 0.50948
wandb:       eval/ensemble_f1 0.83897
wandb:            test/avg_f1 0.91732
wandb:      test/avg_mil_loss 1.03382
wandb:       test/ensemble_f1 0.91732
wandb:           train/avg_f1 0.84316
wandb:      train/ensemble_f1 0.84316
wandb:         train/mil_loss 0.66985
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0anzyxxl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200920-0anzyxxl/logs
wandb: Agent Starting Run: 4nw6ucin with config:
wandb: 	actor_learning_rate: 0.00011374766436989012
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.964769804072011
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8400983114116823
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201144-4nw6ucin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4nw6ucin
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇█
wandb: best/eval_avg_mil_loss █▅▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▄▄▄▄▄▄▄▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▂▃▃▇▁▆▅▃▃▃▅▄█▄▃▄▄▃▁▁▅▃▇▇▃▄▃▅▅▃▅▅▅█▃▅▅
wandb:      train/ensemble_f1 ▆▅▅▄▂▃▅▇▆▃▄▄▄▃▄▅▃▇▅▆▄▃▇█▅▅▄▄▄▄▃▅▄▁▅█▅▃▃▅
wandb:         train/mil_loss ▁▅▃▃█▇▇▄▇▅▅▂▃▅▃▄▃▄▅█▃▂▂▃▃▆▂▂▃▂▃▃▄▄▂▂▂▁▁▃
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▁▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▃▃▁▅▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54772
wandb: best/eval_avg_mil_loss 0.64094
wandb:  best/eval_ensemble_f1 0.54772
wandb:            eval/avg_f1 0.54772
wandb:      eval/avg_mil_loss 0.60445
wandb:       eval/ensemble_f1 0.54772
wandb:            test/avg_f1 0.51309
wandb:      test/avg_mil_loss 0.64307
wandb:       test/ensemble_f1 0.51309
wandb:           train/avg_f1 0.49215
wandb:      train/ensemble_f1 0.49215
wandb:         train/mil_loss 0.67271
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vdk0xubw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200748-vdk0xubw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uw36x7en with config:
wandb: 	actor_learning_rate: 0.0020046416958792615
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4369521763084141
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9241622202765358
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201303-uw36x7en
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw36x7en
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▅▇▅▅▆▆▇▇▅▅▁▄▅▄█▅▇▄▇▆▇▂▄▄▄▆▆█▅▆▅▆▅▅▅▃▆▄
wandb:      train/ensemble_f1 ▁▂█▅▂▇▁▇▇▅▃▄▃▂▄▃▅▇▅▄▇▁▇▇▂▂▃█▆▆▄▄▄▃▆▅▄▅▂▃
wandb:         train/mil_loss ▅▃▅▃▃▆▄▄▃▃▃▃▂▃▂▃▅▂▄▂▄▃▆▅▆▄▄█▅▂▅▃▁▁▄▃▄▂▄▄
wandb:      train/policy_loss ▅▆▇▅▅▆▅▄▆▅▆▃▂▅▅▅▄▅▄▄▆▁▅▃▂▄▅▅▅▅▅▇▇█▇▆▅▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▆▇▅▂▅▆▄▅▆▆▆▂▅▆▆▇▄▆▆▁▅▃▅█▅▇▅▅▃▇▆▅▅▆▅▆▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01705
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99026
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.13941
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 0.58301
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/olhqvww2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201120-olhqvww2/logs
wandb: Agent Starting Run: 7lh8p47j with config:
wandb: 	actor_learning_rate: 0.0033507943852674684
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3349727411256218
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6189188836863597
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201317-7lh8p47j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lh8p47j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▆▆▆▇▇▇▇▇█▇▆▇▄▄▄▅▇██▅▄▅▄▅▄▄▄▄▄▅▃▃▂▂▃▁▂▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▄▆▅▅▅▇▄▅▃▃▅▇▆▇▃▇▄▇▁▆▅▆▄▂▄▆█▄▅▂▄▆▅▃▅▄▄
wandb:      train/ensemble_f1 ▁▅▆▅▃▅▆▁▄▃▂▂▆▂▄▆▃█▆▃▃▄▆▅▃▄▄▅▇▃▅▅▅▅▄▄▄▄▄▃
wandb:         train/mil_loss ▄▅▅▅▄▃▃▃▃▃▄▄█▃▄▃▃▃▄▆▅▂▂▃▃▃▅▅▃▃▃▅▆▇▃▄▁▂▆▄
wandb:      train/policy_loss ▅▃▃▃▃▃▃▃▅▃▃▃▁▁▅▅▃▅▃▃▃▃▃▁▃▃▁▁▁█▁▅▁▁▆▃▁▃▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▆▃▃▁▁▆█▆▃▆▁▁▁▃▃█▃▆▃▁▁▃▃▁▃▁▁▆▁▁▃▁█▁▁▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.59875
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.59548
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 1.23619
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.46429
wandb:      train/ensemble_f1 0.46429
wandb:         train/mil_loss 0.64871
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4nw6ucin
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201144-4nw6ucin/logs
wandb: Agent Starting Run: bjvlaqen with config:
wandb: 	actor_learning_rate: 1.121266811930466e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5564742186132997
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06519535755537498
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201337-bjvlaqen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjvlaqen
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▄▄▃█▅▃▅▅▄▄▄▅▆▃▄▄▆▁▂▃▃▃▃▆▂▄▅▆▂▆▃▆▄▄▃▄▄▅
wandb:      train/ensemble_f1 ▆▄▃▃▁▄█▅▄▄▅▆▃▃▄▄▁▆▄▄▆▃▃▃▃▁▂▃▄▄▄▄▂▃▂▆▄▄▃▅
wandb:         train/mil_loss ▃▄▁▆█▇▅▄▇▄▄▅▄▅▃▄▄▆▄▄▂▃▂▅▄▂▂█▆▅▆▆▅▄▄▄▃▆▅▇
wandb:      train/policy_loss ▄▇▅▅▁▅▆▅▃▆▄▆▅▅▅▃▅▃▅▆▅▅▄▄▂▄▅▇▇▃▇▅█▅▅▅▄▆▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▂▂▂▅▂▂▅▄▆▅▅▅▅▅▂▅▂▆▄▃▅▄▁▄▂▄▆█▃▅▅▄▄▅▅▂▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.97926
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.76426
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.78487
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34156
wandb:      train/ensemble_f1 0.34156
wandb:         train/mil_loss 3.74398
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run serene-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bjvlaqen
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201337-bjvlaqen/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v50b7fdw with config:
wandb: 	actor_learning_rate: 0.0029961347618658552
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5278133987973085
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25296976181559216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201537-v50b7fdw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v50b7fdw
wandb: uploading history steps 473-483, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▃▄▄▅▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss █▆▅▅▅▃▃▃▃▃▂▂▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▃▄▄▅▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇████▇██████▇
wandb:      eval/avg_mil_loss █▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▅▆▆▆▆▆▆▇▇█▇████████▇▇███▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▃▃▅▅▅▆▆▆▆▆▆▆▅█▇▆▇▇▇▆▇█▆▇▇▇▇█▇▇▇█▇▇▇▇▇
wandb:      train/ensemble_f1 ▄▁▂▃▃▃▃▄▄▃▅▅▆▇▅▆▇▇▇▆▇▇▇▇▇▆▆▇▆▇▆██▇▇▇▇█▆▇
wandb:         train/mil_loss ▇▇▄▃█▆▅▅▇▄▆▄▆▅▄▃▅▆▄▂▄▁▅▄▃▅▅▃▄▃▂▂▂▂▂▂▂▃▃▄
wandb:      train/policy_loss ▃▃▃▃▄▃▄▄▃▁▃▃▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▂▃▃▂▄█▂▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▄▅▅▃▄▆▁▃▆▃▇▅▆▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃█▂▅▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67033
wandb: best/eval_avg_mil_loss 0.64562
wandb:  best/eval_ensemble_f1 0.67033
wandb:            eval/avg_f1 0.63535
wandb:      eval/avg_mil_loss 0.6249
wandb:       eval/ensemble_f1 0.63535
wandb:            test/avg_f1 0.53964
wandb:      test/avg_mil_loss 0.9073
wandb:       test/ensemble_f1 0.53964
wandb:           train/avg_f1 0.58934
wandb:      train/ensemble_f1 0.58934
wandb:         train/mil_loss 0.68877
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mbe7g7a5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_200825-mbe7g7a5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yxq0eyvc with config:
wandb: 	actor_learning_rate: 0.00012932171692670602
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8383904227938402
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5929338721385038
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201703-yxq0eyvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yxq0eyvc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▆▄▇▆▃█▅▂▅▇▆▃▇▆▆▆▃▃▅▄▇█▅▁▆▁▇▃▆▆▅▆▆▃▄▇▇▅
wandb:      train/ensemble_f1 ▄█▃▃▅▃█▆█▄▆▂▆▄▇▂▄▅▂▄▄▃▇▂▂▃▇▄▆▆▁▇▇▄▃▃▄▂▄▄
wandb:         train/mil_loss ▆▅▆▇█▄▅▆▇▄▆▆▅▇▄▅▅▆▆▆█▆▆▇▆▂▄▆▆▆▆▅▁▅▆▆▄▄▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.7046
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 0.66915
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.6281
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.50942
wandb:      train/ensemble_f1 0.50942
wandb:         train/mil_loss 0.65046
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v50b7fdw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201537-v50b7fdw/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0ps4jpyi with config:
wandb: 	actor_learning_rate: 0.004338147744297778
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.278917117015402
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.31911827394329983
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201839-0ps4jpyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ps4jpyi
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: best/eval_avg_mil_loss █▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▄▃▄▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█████▇█▇▆▆▆
wandb:      eval/avg_mil_loss ▇█▆▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▆▆▇▆▇▇▇▇▇█████████▇▇▇█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▅▅▆▇▇▇▆▇▇▇▆▇▇█▇▆▇█▅█▅▇▇▇▇▆▇▇█▇▇█▇█▇▇▇▆
wandb:      train/ensemble_f1 ▁▂▄▄▆▆▇▇▆▅▇▇▆▆▇▇█▇▇▇▆▇▅▇▆▇▇▇▇▆▇▇▇▆▇█▆▇▇▇
wandb:         train/mil_loss █▄▄▃▃▅▃▄▄▄▄▃▄▃▂▃▃▄▃▄▄▄▃▂▁▂▂▂▂▂▂▃▂▃▁▁▁▁▂▃
wandb:      train/policy_loss ▆▆▆▅█▆▆▇▆▆▆▆▆█▆▆▆▆▆▆▆▆▁▇█▇▆▄▆▆▆▆▆▆▆▄▆▆▆▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▇▅▅▆▅▅▅▅▅▅▇▅▁▅▅▅▅▅▅█▅▅▅▅▅▅▅▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69662
wandb: best/eval_avg_mil_loss 0.58373
wandb:  best/eval_ensemble_f1 0.69662
wandb:            eval/avg_f1 0.68474
wandb:      eval/avg_mil_loss 0.56335
wandb:       eval/ensemble_f1 0.68474
wandb:            test/avg_f1 0.71035
wandb:      test/avg_mil_loss 0.5967
wandb:       test/ensemble_f1 0.71035
wandb:           train/avg_f1 0.71978
wandb:      train/ensemble_f1 0.71978
wandb:         train/mil_loss 0.58637
wandb:      train/policy_loss -0.0295
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0295
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lunar-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7lh8p47j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201317-7lh8p47j/logs
wandb: Agent Starting Run: snt7ttbx with config:
wandb: 	actor_learning_rate: 0.009275176569329406
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6621827498227049
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4906317795865819
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201925-snt7ttbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/snt7ttbx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▇█
wandb: best/eval_avg_mil_loss █▆▄▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▆▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▃▃▃▄▄▄▄▄▄▆▆▅▅▇▇▇▇▇▇▇▇█████▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▅▄▅▄▄▁▅▄▇▄▂▄▃▇▃▇▆▇▂▆▃▆▄▅▅▆█▇▇█▁▇▆▂▆▅▆▃
wandb:      train/ensemble_f1 ▂█▂▁▇▃▄▆▆▄▂▂▅█▂█▂▆▄▄▆▄▅▄▄▄▃▂▃▄▇▅▆▄▅▄▂▂█▄
wandb:         train/mil_loss ██▆▅▆▆▆▅▃▁▅▃▆▅▄▅▄▅▅▅▄▄▇▄▃▄▃▄▃▄▄▄▄▄▂▁▃▃▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▇▅▇▁█▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54772
wandb: best/eval_avg_mil_loss 0.66251
wandb:  best/eval_ensemble_f1 0.54772
wandb:            eval/avg_f1 0.53989
wandb:      eval/avg_mil_loss 0.61921
wandb:       eval/ensemble_f1 0.53989
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.63389
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.49858
wandb:      train/ensemble_f1 0.49858
wandb:         train/mil_loss 0.82812
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run legendary-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uw36x7en
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201303-uw36x7en/logs
wandb: Agent Starting Run: vfl0socf with config:
wandb: 	actor_learning_rate: 0.0005716380313672454
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4912151180689288
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6031570904376122
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_201952-vfl0socf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vfl0socf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▇█
wandb: best/eval_avg_mil_loss █▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▄▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▂▂▂▂▄▄▇▇▇▇▇▇██████████████████████
wandb:      eval/avg_mil_loss █▇▇▆▆▆▅▄▄▄▄▄▄▄▄▄▃▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▂▂▂▂▄▄▄▄▇▇▇▇▇████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▅▁▄▂▄▄▃▄▅▃▃▅▅▆▆▅▅▅▆▄▅▆▅▅▅▅▅▅▆▇▄▇▇▇▇█▇
wandb:      train/ensemble_f1 ▅▅▅▃▄▁▄▆▅▅▅▂▄▆▇▅▄▄▅▆▄▅▅▆▇▅▆▇▇▆▇▅▇█▆██▇█▅
wandb:         train/mil_loss ███▆▃▇▆▅▇▃▅▄▇▅▅▁▅▇▃▅▄▄▆▅▅▄▄▂▃▃▃█▃▂▄▄▄▅▇▆
wandb:      train/policy_loss ▆▆▆▆▆▆█▆▆▆▆▆▆▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆▇██▆▅▅▅▅▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67825
wandb: best/eval_avg_mil_loss 0.71803
wandb:  best/eval_ensemble_f1 0.67825
wandb:            eval/avg_f1 0.67825
wandb:      eval/avg_mil_loss 0.71138
wandb:       eval/ensemble_f1 0.67825
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.68166
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.68638
wandb:      train/ensemble_f1 0.68638
wandb:         train/mil_loss 0.58905
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yxq0eyvc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201703-yxq0eyvc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 394i9r70 with config:
wandb: 	actor_learning_rate: 0.0005043772842723658
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7382513304486094
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.521110478683601
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202025-394i9r70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/394i9r70
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▄▅▇▆▅▁▄▃█▆▄▃▅▅▆▃▄▅▅▅█▂▅▂▄▅▅▁▄▃▃▄▂▃▅▃▆▄
wandb:      train/ensemble_f1 ▇▅▅▄▇▂▅▄▅▇▆▇█▃▅▄▆▇▂▄▆▄▁▆▅▄▇▇▃▅▆▅▆▇▄▄▃▇▃▅
wandb:         train/mil_loss ▃█▇▇▆▆▅▅█▅▇▃▄▅▄▇▄▃▇▅▄▆▆▅▆▃▁▅▃▅▆▂▄▅▅▄▃▅▂▆
wandb:      train/policy_loss ▄▆▇▆▃▅▃▅▁▄▅▄▆▆▅▆▅▄▅▂▆█▇▃▄▅▅▇▄▅▅▇▅▂▅▅▄▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▆▇▆▅▁▃▄▅▇▅▄▆▆█▇▇▇▄▆▂▆▇▃▃▄▃▄█▅▇▄▅▅▄▅▄▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 6.60559
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 6.38306
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 7.80241
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 5.45637
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0ps4jpyi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201839-0ps4jpyi/logs
wandb: Agent Starting Run: l6s2iah7 with config:
wandb: 	actor_learning_rate: 3.904474686688955e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8318673552537419
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.43910624946179433
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202032-l6s2iah7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l6s2iah7
wandb: uploading history steps 99-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████▂▂▂▂▂▁▂▂▁▁▁▂▂▂▃▃▃▃▃▃▂▂▃▃▃▃▃▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄
wandb:       eval/ensemble_f1 ██████████████▂▂▁▂▂▁▁▁▂▂▂▂▃▃▃▃▃▃▂▃▃▃▃▃▃▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▆▇▆▇▆██▇▇▇▆▄▆▃▂▄▂▃▄▃▁▃▂▃▄▅▃▅▄▄▄▅▃▄▄▃▅
wandb:      train/ensemble_f1 █▇▇▆█▆▇▅▅█▇▇▆▆▇▃▂▂▂▁▂▂▄▂▃▂▁▃▄▃▄▅▂▃▅▃▃▂▅▆
wandb:         train/mil_loss ▄▂▃▂▃▄▅▄▃▃▃▂▂▇▆▃▄▆▆▇▆▄▅▄▂▇▄▅▃▅▄▃▃▅▃▁█▆▄▆
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▁▅▅▅▁▅▅▅▅█▄▅▅▅▅▅▅▅▅▇▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅▄▅▅▅▅█▅▅▅▅▅▅▇▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.61124
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.74937
wandb:      eval/avg_mil_loss 0.71516
wandb:       eval/ensemble_f1 0.74937
wandb:            test/avg_f1 0.84
wandb:      test/avg_mil_loss 0.42689
wandb:       test/ensemble_f1 0.84
wandb:           train/avg_f1 0.76773
wandb:      train/ensemble_f1 0.76773
wandb:         train/mil_loss 0.50079
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/snt7ttbx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201925-snt7ttbx/logs
wandb: Agent Starting Run: t3vy9jik with config:
wandb: 	actor_learning_rate: 0.0001303923147747814
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.26291191571544914
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9229249091601146
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202119-t3vy9jik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t3vy9jik
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▁▅▅▅▅▆▄▆▆▅▅▇██▃▆▅▄▅▁▅▆▆▄▇▅▆▅▆▄▂▄▄▄▄▆▆▃
wandb:      train/ensemble_f1 ▅▅▆▁▃▅▅▆▅▅▅▂▃▅▄▇█▂▄▃▆▄▄▄▆▅▄▄▃▄▅▅▄▆▁▄▅▆▆▃
wandb:         train/mil_loss ▃▃▄▄▄▅▅▁▄█▆▃▄▄▅▅▄▅▄▂▄▅▆▃▅▂▆▁▃▂▄▄▅▇▅▆▃▂▂▄
wandb:      train/policy_loss ▇▆▂▅▅▅▄▆▅▅▅▄▂▅▂▇▅▆▆▇▃▇▃█▃▇▇▄▆▅▂▅▄▄▅▂▁▃▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▄▄▄▅▃▃▂▄▄█▃▅▅▅▅▂▄▅▂▅▄▅▃▃▄▃▅▄▃▃▂▁▂▄▄▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.64288
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.5324
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.08072
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32603
wandb:      train/ensemble_f1 0.32603
wandb:         train/mil_loss 1.1449
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vfl0socf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_201952-vfl0socf/logs
wandb: Agent Starting Run: srzo9t9j with config:
wandb: 	actor_learning_rate: 0.00853289131448583
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6216180408614821
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7999516438412125
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202150-srzo9t9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/srzo9t9j
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████▇▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▁▁▁▂▄▄▄▂▂▄██████████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 █████▆▅▄▄▄▄▄▃▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███▇███▆▇▄▂▂▃▂▂▁▂▁▁▂▂▂▃▁▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂
wandb:      train/ensemble_f1 ▇▇███▇▆▅▅▄▃▃▃▁▂▁▁▂▁▂▁▂▂▃▁▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂
wandb:         train/mil_loss ▃▅▁▂▄▅▆▅▆▂█▆▆▆▆▃▅▄▅▄▂▄▂█▇▄▄▆▅▆▄▇▆▆▅▅▄▅▄█
wandb:      train/policy_loss ▇▇▇▇█▇▇▅▇▆▁▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▂▇▁███████████▆████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6757
wandb: best/eval_avg_mil_loss 0.73063
wandb:  best/eval_ensemble_f1 0.6757
wandb:            eval/avg_f1 0.34094
wandb:      eval/avg_mil_loss 0.74816
wandb:       eval/ensemble_f1 0.34094
wandb:            test/avg_f1 0.62121
wandb:      test/avg_mil_loss 0.71686
wandb:       test/ensemble_f1 0.62121
wandb:           train/avg_f1 0.38777
wandb:      train/ensemble_f1 0.38777
wandb:         train/mil_loss 0.62684
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/394i9r70
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202025-394i9r70/logs
wandb: Agent Starting Run: yjhlwcn2 with config:
wandb: 	actor_learning_rate: 0.004585589863040616
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4754795157180943
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9465390098942158
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202219-yjhlwcn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjhlwcn2
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████████████████████████████▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▂▂▂▆▆▆▆▆▇▇▇▆▇▇▃▃▃▃▃▄▄▃▃▃▃▃▃▃▄████
wandb:       eval/ensemble_f1 ███████████████████████████████████▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▇▅▄▄▄▆▂▄▃▄▅▅▃▆▃▅▅▃▄▃▁▆▂▃▃▄▃▂▁▂▄█▅▁▅▅▂▆
wandb:      train/ensemble_f1 ▅▄▇█▅▅▅▆▄▂▅▃▃▁▄▇▄▅▄▄▄▃▇▃▅▆▇▆▅▄▅▅▇▆▃▆▅▄▆▁
wandb:         train/mil_loss ▃▄▅▆▄▅▃▃█▅▄▆▅▄▆▅▃▃▅▄▂▄▃▁▄▄▅▆▇▆▃▆▆▁▃▄▄▄█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78375
wandb: best/eval_avg_mil_loss 0.4962
wandb:  best/eval_ensemble_f1 0.78375
wandb:            eval/avg_f1 0.77422
wandb:      eval/avg_mil_loss 0.50486
wandb:       eval/ensemble_f1 0.77422
wandb:            test/avg_f1 0.72863
wandb:      test/avg_mil_loss 0.47808
wandb:       test/ensemble_f1 0.72863
wandb:           train/avg_f1 0.71257
wandb:      train/ensemble_f1 0.71257
wandb:         train/mil_loss 0.55799
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l6s2iah7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202032-l6s2iah7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gzydc86s with config:
wandb: 	actor_learning_rate: 4.2707573415037034e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9598856145570202
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5558338925430261
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202232-gzydc86s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2k64cqgn
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gzydc86s
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁█████████████████████████████████████
wandb:      eval/avg_mil_loss ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▆▇▇▇▇▇████▇█▇▇▇▇██████▇▇█▇▇▇▇▇█▇▇██▇
wandb:      train/ensemble_f1 ▂▁▁▇▇▇█▇▇▇▇▇██▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇█▇██▇█▇▇█
wandb:         train/mil_loss █▃▄▃▄▂▂▁▂▂▅▅▅▂▂▄▅▅▂▃▄▅▃▃▄▇▁▃▅▃▆▆▂▃▃▃▂▆▂▅
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73129
wandb: best/eval_avg_mil_loss 0.53578
wandb:  best/eval_ensemble_f1 0.73129
wandb:            eval/avg_f1 0.73129
wandb:      eval/avg_mil_loss 0.53306
wandb:       eval/ensemble_f1 0.73129
wandb:            test/avg_f1 0.72863
wandb:      test/avg_mil_loss 0.56406
wandb:       test/ensemble_f1 0.72863
wandb:           train/avg_f1 0.67515
wandb:      train/ensemble_f1 0.67515
wandb:         train/mil_loss 0.60564
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/srzo9t9j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202150-srzo9t9j/logs
wandb: Agent Starting Run: qkwsvl3i with config:
wandb: 	actor_learning_rate: 0.00014223393600038423
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2437643935824292
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.032285025957832225
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202355-qkwsvl3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkwsvl3i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▇█
wandb: best/eval_avg_mil_loss █▁▄
wandb:  best/eval_ensemble_f1 ▁▇█
wandb:            eval/avg_f1 ▄█▅▅▁▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▂▂▁▂▅███████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:       eval/ensemble_f1 ▄█▆▆▂▁▁▁▁▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▃▃▁▂▃▄▃▂▃▄▃▄▃▄▄▅▃▂▃▄▄▄▄▄▄▃▄▄▅▄▄▄▄▃▄▃▃▅
wandb:      train/ensemble_f1 ▆██▄▁▂▃▄▃▂▃▃▆▄▄▅▄▅▄▂▂▄▄▄▄▅▄▄▄▄▂▄▅▄▄▄▃▄▃▃
wandb:         train/mil_loss ▁▁▆█▇▇▅▅▇▅▅▅▃▃▆▇▆▄▆▆▄▅▂▆▄▇▄▄▇▆▅▄▆▄▃▅▅▆▅▄
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67532
wandb: best/eval_avg_mil_loss 0.67261
wandb:  best/eval_ensemble_f1 0.67532
wandb:            eval/avg_f1 0.61614
wandb:      eval/avg_mil_loss 0.81576
wandb:       eval/ensemble_f1 0.61614
wandb:            test/avg_f1 0.62907
wandb:      test/avg_mil_loss 0.86335
wandb:       test/ensemble_f1 0.62907
wandb:           train/avg_f1 0.52985
wandb:      train/ensemble_f1 0.52985
wandb:         train/mil_loss 0.77067
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yjhlwcn2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202219-yjhlwcn2/logs
wandb: Sweep Agent: Waiting for job.
wandb: uploading history steps 157-171, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▄█
wandb:            eval/avg_f1 ▆▆▆▅▁▂█▆▆████▆▅▅███▆▆▆▆▆▆▆▆▆██████▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▁▄▂▅▅▅▆▄▆▆▆█▇▇▅▅▅▅▅▅▅▅▅▅▇▇▇▇▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▃▂▄▅▅▄▅▃▅▂▃▃▂▆▂▁▄▃▆▇▂▆▆▅█▅▆▃▇▄▄▄▇▆▄▄▅▅
wandb:      train/ensemble_f1 ▃▄▄▃▅▄▂▃▄▂▂▁▅▆▅▄▅█▆▂▅▃▂▆▃▆▅▂▁▄▂▂▆▇▄▄▅▆▂▆
wandb:         train/mil_loss ██▄▇▅▆▅▆▅▅▅▆▅▇▄▅▅▄▃▅▅▄▅▄▃▅▄▃▅▃▃▁▅▄▄▄▄▃▃▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▆▁▆▄▂▄▄▅▄▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▆▅▅▅▅▃▃▁▆▅▅▅█▅▃▅▇▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▃▄▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61616
wandb: best/eval_avg_mil_loss 0.6694
wandb:  best/eval_ensemble_f1 0.61616
wandb:            eval/avg_f1 0.59596
wandb:      eval/avg_mil_loss 0.62234
wandb:       eval/ensemble_f1 0.59596
wandb:            test/avg_f1 0.5104
wandb:      test/avg_mil_loss 0.6884
wandb:       test/ensemble_f1 0.5104
wandb:           train/avg_f1 0.57884
wandb:      train/ensemble_f1 0.57884
wandb:         train/mil_loss 0.6867
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run driven-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t3vy9jik
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202119-t3vy9jik/logs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇█▇▇▇▇▇▇▇▆▇▇▅▅▅▅▅▅▅▃▃▃▃▂▁▂▂▃▃▄▄▄▄▄▃▃▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▁▆▅▆▄▅▆▄▆▇▄▆▆▆▆▆▅▇▅█▄▅▅▅▆▅▅▇▄▆▅▃▆▇▆▂▂▅
wandb:      train/ensemble_f1 ▄▄▃▄▄▃▃▂▂▆▅▃▃▅▄▄█▄▃▃▄▃▃▂▅▄▄▄▃▅▂▂▂▂█▅▂▁▄▃
wandb:         train/mil_loss ▃▄▆▂▄▁▄▅▃▂▄▃▅▆▂▄▇▂▄▄▅▄▆█▅▂▂▆▃▃▂▄▃▆▁▄▃▂▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 1.4386
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 1.43222
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 1.12236
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.53861
wandb:      train/ensemble_f1 0.53861
wandb:         train/mil_loss 0.69318
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gzydc86s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202232-gzydc86s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Job received.
wandb: Agent Starting Run: 8yfupif4 with config:
wandb: 	actor_learning_rate: 0.00011475815107076195
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14815735833731825
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05293911910596183
wandb: Job received.
wandb: Agent Starting Run: mqzbqzqw with config:
wandb: 	actor_learning_rate: 0.0006378485974491844
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6287282581482531
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30581735018705847
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202441-8yfupif4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8yfupif4
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202442-mqzbqzqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqzbqzqw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▂▆▆▁▆▆▅▄▅▄▆▆▆▄▃█▅▆▅▅▆▄▆▆▄▃▅▇▆▃▇▇▄▇█▅▂
wandb:      train/ensemble_f1 ▅▅▆▂▁▅▅▇▅▆▅▇▅▆▆▅▆▆▅▆▅▅▆▆▄▆▅▇▃▇▄█▆▅▇▆██▆▂
wandb:         train/mil_loss ▂▇▆▃▅▄▅▆▃▅▅▆▃▇▂▄▄▃▃▃▇█▅▁▃▁▆▃▅▃▄▄▄▆▁▄▅▆▅▃
wandb:      train/policy_loss ▂▄▃▄█▅▄▆▄▅▇▆▄▃▃▇▆▂▄▄▇▄▇▆▂▂▅▃▆▅▁▇▁█▄▆▄▆▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▄▃▅▄█▄▅▆▃▆▃▃▅▄▅▂▆▄▆▄▅▇▄▃█▄█▃▆▅▆▄▇▁▄▃▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.92515
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.88864
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.00535
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32031
wandb:      train/ensemble_f1 0.32031
wandb:         train/mil_loss 0.77799
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rosy-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkwsvl3i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202355-qkwsvl3i/logs
wandb: Agent Starting Run: qm0gda31 with config:
wandb: 	actor_learning_rate: 0.0007018467950768455
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5227543983762463
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.618196362090804
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202550-qm0gda31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qm0gda31
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▅▆▄▂▄▄▄▇▄█▂▅▅▂▅▁▅▄▅▃▅▆▃▂▃▃▃▃▄▃▆▃▃▃▆▃▅
wandb:      train/ensemble_f1 ▄▆▅▆▇▆▆▆▄▃▆▆▄▄▄▄▅▄▆█▅▁▅▆▆▆▄▆▄▄▃▆▅▅▆▆▆█▄▄
wandb:         train/mil_loss ▇▃█▃▄▄▄▄▃▃▇▄▃▇▆▅▂▄▁▆▃▄▆▃▅▂▆▆▃▂▅▆▇▁▅▃▄▄▂▃
wandb:      train/policy_loss ▆▄▅▆▇▄▆▆▇▆▅▇▄▇▃█▃▆▆▄▇▄▆▇▄▄▆▆▄▆▄▅▅▁▅▄▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▄▆▆▅▇▄▄▅▁▅▁▇▃▅▂▄▄▆▅█▄▂▄▂▄▂▂▃▅█▄▃▂▆▅█▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.88486
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.86366
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.96949
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32489
wandb:      train/ensemble_f1 0.32489
wandb:         train/mil_loss 0.67494
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qm0gda31
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202550-qm0gda31/logs
wandb: Agent Starting Run: 9xh5yts6 with config:
wandb: 	actor_learning_rate: 1.8267590988367175e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6789609906929198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06635895344244669
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202744-9xh5yts6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xh5yts6
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▇▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅█████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▁▅▁▅▁▃▃▃▂▆▄▂▅▃▅▄▂▂▃▄▃▅▂▄▇▄▅█▆▆▆▇▅▃▃▂▅▄
wandb:      train/ensemble_f1 ▄▂▂▂▃▁▃▄▃▆▃▃▄▆▅▄▂▃▅▂▅▆▄▅▆▄▄▃▄▄▅▆▃▅▅█▄▅▆▆
wandb:         train/mil_loss ▅▆▅▇▇█▇▇▆▆▅▆▄▄▆▅▆▅▅▆▆▅▇▂▅▅▅▅▅▅▄▄▄▄▄▄▁▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58498
wandb: best/eval_avg_mil_loss 0.6727
wandb:  best/eval_ensemble_f1 0.58498
wandb:            eval/avg_f1 0.58498
wandb:      eval/avg_mil_loss 0.63547
wandb:       eval/ensemble_f1 0.58498
wandb:            test/avg_f1 0.46375
wandb:      test/avg_mil_loss 0.66523
wandb:       test/ensemble_f1 0.46375
wandb:           train/avg_f1 0.52457
wandb:      train/ensemble_f1 0.52457
wandb:         train/mil_loss 0.66174
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8yfupif4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202441-8yfupif4/logs
wandb: Agent Starting Run: lyve3iic with config:
wandb: 	actor_learning_rate: 0.002821142253038231
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15862604426340687
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9280860901768236
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202840-lyve3iic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lyve3iic
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▆▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▅▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▁▄▃▂▃▃▄▁▃▄▃▅▄▄▄▅▅▅▂▂▄▇▆▄▆▆▆▃▅▆▄▇▅▇▇█▅▆
wandb:      train/ensemble_f1 ▁▃▁▃▄▂▃▂▃▇▅▆▃▄▇▃▄▄▃▄▅▅▃▄▄▄▂▄▄▆▄▆▅▄▂▄▆▆▆█
wandb:         train/mil_loss ▄▅▃▅▁▄█▆▂▂▂▂▄▅▅▄▁▇▃▆▃▆▂▃▂▃▁▃▆▄▅▅▂▃▃▁▄▃▃▆
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▂▃▇▁▂▂▄█▄█▂▇▃▄▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆█▄▄▃▅▂▄▃▂▃▄▄▇▃▁▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 0.53509
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.5183
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.54667
wandb:      test/avg_mil_loss 0.46916
wandb:       test/ensemble_f1 0.54667
wandb:           train/avg_f1 0.57204
wandb:      train/ensemble_f1 0.57204
wandb:         train/mil_loss 0.62092
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqzbqzqw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202442-mqzbqzqw/logs
wandb: Agent Starting Run: bedffevk with config:
wandb: 	actor_learning_rate: 0.001412752624375736
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5002276579427388
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02127187887511417
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_202901-bedffevk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bedffevk
wandb: uploading history steps 157-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅███████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅▅▅▅▅███████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▁▃▂▂▂▃▂▂▄▃▄▄▅▃▂▅▃▁▄▄▂▅▃▄▄▅▅▅▅▄▃▄▄▄▄█▇▂
wandb:      train/ensemble_f1 ▂▄▂▄▄▂▂▂▂▅▁▃▆▅▂▃▄▄▆▁▄▅▄▂▅▃▅▅▄▄▇▆▅▆▅▄▆█▄▂
wandb:         train/mil_loss ▅▅▄▆▄▆▅▅▇▃▇█▇█▇▃▆▄▃▅▇▆▄▃▄▅▇▃▄▃▅▆▁▅█▅▆▃▅▃
wandb:      train/policy_loss █▄▂▆▇▅▅▅▅▅▅▅▅▅▅▄▅▄▄▃▃▄▃▃▂▃▄▂▆▃▅▂▃▂▅▂▁▃▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.43574
wandb: best/eval_avg_mil_loss 0.72194
wandb:  best/eval_ensemble_f1 0.43574
wandb:            eval/avg_f1 0.43574
wandb:      eval/avg_mil_loss 0.7067
wandb:       eval/ensemble_f1 0.43574
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 0.78955
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.42493
wandb:      train/ensemble_f1 0.42493
wandb:         train/mil_loss 0.58983
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9xh5yts6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202744-9xh5yts6/logs
wandb: Agent Starting Run: r9kr4j6h with config:
wandb: 	actor_learning_rate: 0.00016393285134473125
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8268055546478865
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41482150479514623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203039-r9kr4j6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r9kr4j6h
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▇▇▆▅▅▄▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▂███▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▇▇▇▇▆▆▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▇▇█▆▃▃▄▃▂▁▂▁▁▂▃▂▁▁▃▁▁▁▂▂▂▁▁▂▂▄▂▃▂▂▂▁▂▂
wandb:      train/ensemble_f1 █▆▆▆▅▄▅▂▂▃▄▂▂▃▂▃▂▂▂▃▃▂▂▂▃▂▃▂▃▁▂▃▃▂▂▃▂▃▂▂
wandb:         train/mil_loss ▅▅▂▇▄▆▅▄▄▇▃▁▃▇▄▄▅▃▆▃█▄▄▅▆▄▂▃▅▁▄▂▄▄▃▇▅▃▇▂
wandb:      train/policy_loss ▇▄▄▁▃█▄▄▄▆▃▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅▅▅▁▅▆▅▇▄▅▂▅▇▅▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81935
wandb: best/eval_avg_mil_loss 0.59644
wandb:  best/eval_ensemble_f1 0.81935
wandb:            eval/avg_f1 0.65278
wandb:      eval/avg_mil_loss 0.56124
wandb:       eval/ensemble_f1 0.65278
wandb:            test/avg_f1 0.76139
wandb:      test/avg_mil_loss 0.71583
wandb:       test/ensemble_f1 0.76139
wandb:           train/avg_f1 0.63809
wandb:      train/ensemble_f1 0.63809
wandb:         train/mil_loss 0.56372
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bedffevk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202901-bedffevk/logs
wandb: Agent Starting Run: dzwo0bw3 with config:
wandb: 	actor_learning_rate: 0.00010279234804154722
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8529893767382201
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27674898332710185
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203049-dzwo0bw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dzwo0bw3
wandb: uploading history steps 132-143, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▃▇▇██
wandb: best/eval_avg_mil_loss █▄▄▃▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▃▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▂▇▁██████████████████████████
wandb:      eval/avg_mil_loss ██████▄▄▂▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▆██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▂▄▁▂▂▅▅▄▅▄▆▅▄▅▅▆▆▄▆▆▅▅▄▆▆▆▇▆▅▇▅▆▅█▆▅▇
wandb:      train/ensemble_f1 ▂▂▄▂▃▁▂▂▅▁▂▆▇▇▅▅▅▅█▅▅▅▆▆█▄▅▅█▄▆▅▆▅▅▄▆█▆▆
wandb:         train/mil_loss ▇▇▆▇█▆█▅█▇▃█▃▂▂▁▂▁▁▂▁▂▂▂▂▂▁▂▂▁▁▂▂▁▂▁▂▁▁▂
wandb:      train/policy_loss █████████▄▁██▁▃▂▄▅▃▃▂▂▂█████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▁▁▂▃▃▂▂▁▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81935
wandb: best/eval_avg_mil_loss 0.44472
wandb:  best/eval_ensemble_f1 0.81935
wandb:            eval/avg_f1 0.81935
wandb:      eval/avg_mil_loss 0.41846
wandb:       eval/ensemble_f1 0.81935
wandb:            test/avg_f1 0.81084
wandb:      test/avg_mil_loss 0.5996
wandb:       test/ensemble_f1 0.81084
wandb:           train/avg_f1 0.79939
wandb:      train/ensemble_f1 0.79939
wandb:         train/mil_loss 0.44966
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lyve3iic
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_202840-lyve3iic/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p6qvdjtj with config:
wandb: 	actor_learning_rate: 0.0001900244481823165
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.551015106573929
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9280784886699436
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203121-p6qvdjtj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p6qvdjtj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▃▃▅▅▆▄█▆▄▅▅▃▄▇▅▆▃▄▁▃▄▃▄▅▄▂▄▅▅▃▃▁▅▆▄▄▅
wandb:      train/ensemble_f1 ▄▂▅▆▃▃▃▄▅▂▆▄▄▃▄▃▆▃▇▃▂▃█▄▃▄▄▁▄▄▅▅▃▂▄▃▂▅▁▂
wandb:         train/mil_loss ▁█▃▃▄▂▆▆▃▂▁▂▄▃▂▁▅▃▃▆▂▇▅▄▂▂▃▄▂▃▂▃▄▄▂▆▂▂▁▃
wandb:      train/policy_loss ▄▁█▃▄▅▂▂▄▃▄█▆▃▃▂▃▅▇▂▂▄▆▅▂▃▆▅▂▄▄▄▃▅▂▃▅▇▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▂▂▄▃▅▄▄▄▄▂▂▅▄▅▄▂▃▄▅▄▂▂▄▄▄▂▅▅▃▃▂▂▄▄▄▄█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.91294
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.87023
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.77408
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.50345
wandb:      train/ensemble_f1 0.50345
wandb:         train/mil_loss 0.66478
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devoted-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r9kr4j6h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203039-r9kr4j6h/logs
wandb: Agent Starting Run: tv30n9bd with config:
wandb: 	actor_learning_rate: 3.7008251988353085e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5564143674293095
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.825995015075514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203233-tv30n9bd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tv30n9bd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▅▃▅▇▆▅▃▁▆▄▄▅▂▂▄▂▇▄▄▄▆▃▁▃█▅▆▅▅▇▅▅▇▆▂▅▅
wandb:      train/ensemble_f1 ▂▃▃▂▆▄▃▃▆▅▅█▅▄▄▁▄▅▆▃▅▄▄▅▁▆▄▁█▃▇▆▅▃█▂▅▃▄▆
wandb:         train/mil_loss ▆▁▄▇▆▃▂▅▅▅▂▄▅▄▆▃▃▂▄▂▄▃▆▂▇▃▄██▂▅▅▄▄▁▄▆▅▃▄
wandb:      train/policy_loss ▇▁▅▂▁▁▄▂▁▂▁▄▂█▅▄▅▁▄▄▄▁▅▄▇▄▂▂▂▁▇█▅▂▄▅▂▁▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▃▆▄▃▇▂▆▄▄▄▄▇▄█▁▄▄▆▆▇▃▆▅▅▁▄▄▅▆▃▄▃█▂▆▇▂▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50715
wandb: best/eval_avg_mil_loss 1.20397
wandb:  best/eval_ensemble_f1 0.50715
wandb:            eval/avg_f1 0.50715
wandb:      eval/avg_mil_loss 1.11061
wandb:       eval/ensemble_f1 0.50715
wandb:            test/avg_f1 0.50375
wandb:      test/avg_mil_loss 1.6168
wandb:       test/ensemble_f1 0.50375
wandb:           train/avg_f1 0.55238
wandb:      train/ensemble_f1 0.55238
wandb:         train/mil_loss 0.68741
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run snowy-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dzwo0bw3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203049-dzwo0bw3/logs
wandb: Agent Starting Run: z95nztxg with config:
wandb: 	actor_learning_rate: 0.002729377080440371
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9947853294736052
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08031001346992228
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203238-z95nztxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z95nztxg
wandb: uploading history steps 117-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄▆▇█
wandb: best/eval_avg_mil_loss █▄▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▃▄▄▆▇█
wandb:            eval/avg_f1 ▂▂▁▃▅▆████▇▅▅▅▄▄▄▄▄▄▄▄▄▄▃▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ███▅▅▄▃▃▂▂▂▂▂▁▁▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▃▃▁▂▄▅▅▆▇████▆▅▅▅▅▅▅▅▅▅▅▄▂▂▂▃▃▃▃▄▃▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▂▇▆█▇▄▆▄▂▄▆▃▅▃▂▇▄▄▃▃▆▁▃▁▄▁▃▃▃▁▄▄▅▅▃▄▅▁
wandb:      train/ensemble_f1 ▂▆▄▃▁▄▄▄▇▄▆▆█▇▆▄▅▅▅▄▃▇▅▅▄▂▄▃▄▂▂▄▂▆▆▂▅▅▂▂
wandb:         train/mil_loss ▅▇█▅▄▅▅▄▅▄▅▁▁▅▇▁▄▄▂▄▇▃▃▃▃▄▂▃▄▃▂▃▁▃▁▃▃▂▅▃
wandb:      train/policy_loss ▆▄█▅▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▂▆▇▆▆▆▆▆▆▆▆▄▁▆▁▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇█▇▇█▇▇▅▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁█▇▇▄▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45545
wandb: best/eval_avg_mil_loss 1.02268
wandb:  best/eval_ensemble_f1 0.45545
wandb:            eval/avg_f1 0.37611
wandb:      eval/avg_mil_loss 0.963
wandb:       eval/ensemble_f1 0.37611
wandb:            test/avg_f1 0.45437
wandb:      test/avg_mil_loss 0.8553
wandb:       test/ensemble_f1 0.45437
wandb:           train/avg_f1 0.44631
wandb:      train/ensemble_f1 0.44631
wandb:         train/mil_loss 0.72656
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p6qvdjtj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203121-p6qvdjtj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d7yr6sil with config:
wandb: 	actor_learning_rate: 7.773593991206148e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4672454155893568
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8998082952082699
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203341-d7yr6sil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7yr6sil
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▇▇▅▅▅▅▇▇▇▇▇▇▇▇▇▇██▇██████▇▇▇▇▇▅▅▄▄▂▂▂▁
wandb:      eval/avg_mil_loss ▂▂▂▂▃▅▅▄▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▃▄▅▅▅▇▇▇█
wandb:       eval/ensemble_f1 ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████▇▇▇▇▇▅▅▄▂▂▂▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆██▅▅▄▃▁▂▆▅▇▅▅▅█▆█▇▅▅▅▅▄▆▆▆▅▇▆▅▆▆▄▃▆▄▂▁▄
wandb:      train/ensemble_f1 ▅▅▇▇▄▃▄▃▃▄▇▃▄▇▅▇▅▅▅▃▅▅▇▆▅▄█▅▆▅▃▄▅▃▁▃▁▃▄▁
wandb:         train/mil_loss ▂▆▂▅▃▅█▄▆▄▅▃▁▅▆▅▅▂▄▆▂▂▃▅▃▄▄▅▃▇▅▃▅▆▃▄▁▅▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.5894
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.62765
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.57156
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.49174
wandb:      train/ensemble_f1 0.49174
wandb:         train/mil_loss 0.6287
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tv30n9bd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203233-tv30n9bd/logs
wandb: Agent Starting Run: z2y71o3i with config:
wandb: 	actor_learning_rate: 8.371646255690074e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8963616616971448
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5732527944445198
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203427-z2y71o3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2y71o3i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄██
wandb: best/eval_avg_mil_loss █▄▁▃
wandb:  best/eval_ensemble_f1 ▁▄██
wandb:            eval/avg_f1 ▆▆▇▇██▇▇▇▇█▇████████▇▇▇▅▄▄▄▂▂▃▃▂▂▂▃▂▂▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▆▆▇▇▇▇▇███
wandb:       eval/ensemble_f1 ▆▆▇▇▇███▇▇▇▇▇█▇▇▇██████▇▇▄▂▂▃▃▃▂▂▃▁▂▂▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆██▇▇▇██▇▅██▇▇█▇▆▇▅▄▅▆▄▇▄▁▄▅█▄▃▅▄▃▃▄▁▃▃▂
wandb:      train/ensemble_f1 ▆▅▆▇▆▅▅▇▅▆▆█▇▇▅▇▇▇▇▅▆▄▄▄▅▄▃▆▆▅▅▇▃▄▄▃▃▃▂▁
wandb:         train/mil_loss ▇▆▅▄▂▄▄▄▄▅▄▄▆▃▆▇▄▄▆▆▃▅▁▆▄▇▆█▂▃▅▃▃▃▄▁▅▅▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64912
wandb: best/eval_avg_mil_loss 0.58997
wandb:  best/eval_ensemble_f1 0.64912
wandb:            eval/avg_f1 0.56897
wandb:      eval/avg_mil_loss 0.74302
wandb:       eval/ensemble_f1 0.56897
wandb:            test/avg_f1 0.65946
wandb:      test/avg_mil_loss 0.62664
wandb:       test/ensemble_f1 0.65946
wandb:           train/avg_f1 0.55803
wandb:      train/ensemble_f1 0.55803
wandb:         train/mil_loss 0.56376
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z95nztxg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203238-z95nztxg/logs
wandb: Agent Starting Run: 8ld5gbop with config:
wandb: 	actor_learning_rate: 2.611487574224415e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.950894099598325
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5868714829274758
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203504-8ld5gbop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ld5gbop
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▄▆▃▁▅▆▇▅▇▂▂▆▇▁▆▅▂▄█▄▇▂▄█▄▅▇▃▄▂▆▇▄▄▄▅▆▃
wandb:      train/ensemble_f1 ▁▂▆▃▄▇▄▂▆▅▇▄▆▇▄▄▆▅▆▆▅▅▆▆▄█▅▆▆▄▄▆▅▃▆▄▄▄▄▄
wandb:         train/mil_loss ▃▅▄▄▄▁▃▄▂▅▁▂▂█▃▁▃▆▅▄▅▃▂▅▃▂▂▂▁▃▅▄▅▂▅▆▃▅▁▄
wandb:      train/policy_loss ▂▇█▇▇▃▄▆▁▅▆▄▇▁▇▆▆▄▅▇▇██▂▇▃▇▆▄▄██▇▄▆█▄▇▇▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▂▆▅▇█▃▅█▅▄▆▅▃▅▆▇▁▆▅▆▅▃█▃▇▅▆▇▂▅▃▅▃▆▇▅▁▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.58067
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.53413
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.01754
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 0.71395
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z2y71o3i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203427-z2y71o3i/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a9j2u1o2 with config:
wandb: 	actor_learning_rate: 0.0023436664901625784
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5270429636995163
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18014637535240607
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203632-a9j2u1o2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a9j2u1o2
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▆▃▃▃▃▃▁▃▅▃▃▃▃▃▃▁▄▄▂▄▄▂▂▂▄▂▂▄▆▆▄▂▄▂▂▂▂
wandb:      eval/avg_mil_loss ▂▁▁▁▁▇▇▇▇▇███████████▇▇▇▇▇▇▇▇▇█████▇▇▇█▇
wandb:       eval/ensemble_f1 █████▆▆▃▃▁▃▃▃▅▅▅▃▃▃▃▃▃▄▄▄▂▂▄▂▂▄▄▂▆▄▄▄▄▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▇▁▆▃▂▆▃▄▄▁▄▄▂▄▃▂▄▆▆▇▄▄▁▂▆▂▇▄▇▄▂▃▄▅█▅▂
wandb:      train/ensemble_f1 ▆▇▃▇▅▅▅█▆▃▆▂▄█▅▄▄▆▅▆▄▄▃▆▂▄▅▅▂▆▃▂▄█▁▅▅▃▇▃
wandb:         train/mil_loss ▇▂▅▅▆▄▅▄▂▆▁▆▄▇▄▄▃▇█▆▄▄▁▅▃▇▃▆▃▇▃▄▃▂▁▆▄▁▄▄
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄█▄▄▄▅▄▄▄▄▄▂▄▄▄▄▄▄▁▅▄▅▄▄▄▄▆▄▄▆▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄▃▅▄▄▄▄▄▃▄█▄▂▄▁█▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66018
wandb: best/eval_avg_mil_loss 0.66761
wandb:  best/eval_ensemble_f1 0.66018
wandb:            eval/avg_f1 0.62169
wandb:      eval/avg_mil_loss 0.67029
wandb:       eval/ensemble_f1 0.62169
wandb:            test/avg_f1 0.648
wandb:      test/avg_mil_loss 0.66333
wandb:       test/ensemble_f1 0.648
wandb:           train/avg_f1 0.65335
wandb:      train/ensemble_f1 0.65335
wandb:         train/mil_loss 0.54945
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8ld5gbop
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203504-8ld5gbop/logs
wandb: Agent Starting Run: mqmq7vzw with config:
wandb: 	actor_learning_rate: 0.0011336381612860082
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9410412702459844
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5400903182167474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203653-mqmq7vzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqmq7vzw
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁██████████████████████████████████████
wandb:      eval/avg_mil_loss ▇█▇▆▇▇▆▆▆▆▆▆▅▆▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁
wandb:       eval/ensemble_f1 ██▁█████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▄▃▄▃▁▇▂▆▅█▄▅▂▇▇██▂▆▅▄▇█▆▅▂▄▆▅▃▆▅▆▃█▇▅
wandb:      train/ensemble_f1 ▃▃▃▃▅▆▅▅▅▂▄▄▅▃▂▆▅▂▅▄▆▆▅▇▂▇▂▆█▆▆▃▅▁▆▅▆▃█▃
wandb:         train/mil_loss ▄▆▅▇▂▇▆▁▂▄▅▁▄▄▅▇▆▄▃▄▄▇▅▅▅▃▆▇▇▄█▄▆▅▅█▇▂▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58996
wandb: best/eval_avg_mil_loss 0.64861
wandb:  best/eval_ensemble_f1 0.58996
wandb:            eval/avg_f1 0.58996
wandb:      eval/avg_mil_loss 0.64794
wandb:       eval/ensemble_f1 0.58996
wandb:            test/avg_f1 0.5104
wandb:      test/avg_mil_loss 0.689
wandb:       test/ensemble_f1 0.5104
wandb:           train/avg_f1 0.56467
wandb:      train/ensemble_f1 0.56467
wandb:         train/mil_loss 0.55319
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqmq7vzw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203653-mqmq7vzw/logs
wandb: Sweep Agent: Waiting for job.
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ███████████████████▄▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▂▄▅▅▆▆▇▇▇████████████████████
wandb:       eval/ensemble_f1 ███████████████▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆▇█▆▇▇▇█▇█▆▇▅▃▃▃▂▂▁▁▃▂▂▁▂▁▁▂▁▁▂▂▁▁▁▂▁▂
wandb:      train/ensemble_f1 ████▇▇█▇▇█▇▇▄▅▄▂▂▃▃▂▂▂▁▂▁▂▃▁▂▂▂▂▁▁▂▁▂▂▂▁
wandb:         train/mil_loss ▃▂▃▂▂▄▃▂▂▃▄▃▂▁▅▅▆▆▃▇▅▃▆▄▄▄▇▇▅▅▆▄▆█▆▆▆▆▄▅
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▂▃▃▃▃▃▃▁▃▃▃▃▃▄▄▁▂▁▃▁▁▃▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▃▂▃▃▃▃▃▃▃▃▄▂▄▂▁▂▃▁▃▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74064
wandb: best/eval_avg_mil_loss 0.53196
wandb:  best/eval_ensemble_f1 0.74064
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.67766
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.70129
wandb:      test/avg_mil_loss 0.54561
wandb:       test/ensemble_f1 0.70129
wandb:           train/avg_f1 0.46183
wandb:      train/ensemble_f1 0.46183
wandb:         train/mil_loss 0.62796
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a9j2u1o2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203632-a9j2u1o2/logs
wandb: Agent Starting Run: h2q2rdk2 with config:
wandb: 	actor_learning_rate: 0.0006338318678296933
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.35944492699304276
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9659812853487336
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203918-h2q2rdk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2q2rdk2
wandb: Job received.
wandb: Agent Starting Run: s0awxytz with config:
wandb: 	actor_learning_rate: 0.0007634759030389833
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27837027989203
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9327832038587104
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_203921-s0awxytz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s0awxytz
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▄▅▅▆▆▇▇▇█
wandb: best/eval_avg_mil_loss ▄▅▇▇██▅▄▄▃▃▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▄▅▅▆▆▇▇▇█
wandb:            eval/avg_f1 ▂▃▂▂▁▂▂▁▂▂▂▃▃▃▃▃▃▅▅▅▅▆▅▅▇▂▁▅▇▅▆▅▇▇████▇█
wandb:      eval/avg_mil_loss ▆████▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▄▅▄▄▄▅▄▄▄▄▄▄▄▅▆▅▅▆▆▇▇▆▄▇▇▆▇█▇▆▇███▇█▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▅▇▆▇▆▆▆▅▇▆▆█▆▇▇▇▇▇▆███▇▆▇▇▇▇▇▇▆▆▆█▇▇▆
wandb:      train/ensemble_f1 ▁▂▃▄▆▆▆▇▅▇▇▆▇▇▇▇▇███▇▇█▇▆█▇█▇▇██▇█▅█▇▇█▆
wandb:         train/mil_loss ▆▅▅▆▇▃▅▁█▇▇▃▅▆▅▆▇▃▃▆▅▄▂▆▃▅▃▁▂▅▃▅▁▃▄▆▇▅▄▅
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▅▁▄█▆▆▆▇▄▆▇▆▆▆█▆▇▆▆▄▇▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▇▇▄▄▄▄▄▄▄▄▇▄▄▄▄▇▄▃▄▄▄▁▆▄▄▅▆▄▃▄▄▄▁█▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 0.59957
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.6568
wandb:      eval/avg_mil_loss 0.58413
wandb:       eval/ensemble_f1 0.6568
wandb:            test/avg_f1 0.70515
wandb:      test/avg_mil_loss 0.58657
wandb:       test/ensemble_f1 0.70515
wandb:           train/avg_f1 0.6403
wandb:      train/ensemble_f1 0.6403
wandb:         train/mil_loss 0.60208
wandb:      train/policy_loss 0.20776
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.20776
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d7yr6sil
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203341-d7yr6sil/logs
wandb: Agent Starting Run: n28852lk with config:
wandb: 	actor_learning_rate: 0.001744180028781081
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6914473835245429
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.118899992160571
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204023-n28852lk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n28852lk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▃▆▆▄▅▃▄▆▃▆▁▅▂▇▇▇▄▆▄▄▃▄▇▄▄▂▇▇▁▃▅▄▄▄▅▁█▄
wandb:      train/ensemble_f1 ▁▇▇▅▃▄▅▅▅▇▆▆▇▃▆▅▇▆▆▄▃▄▆▇▃▂▇▄▃▃▂▅▅█▁▃▂▇▂▄
wandb:         train/mil_loss ▃▄▄▃▅█▅▄▄▃▄▃▅▃▆▃▇▂▃▄▄▃▄▁▃▅▃▄▃▄▄▃▄▃▅▃▄▃▅▂
wandb:      train/policy_loss █▅▅▄▅▄▃▄▅▅▄▇▅▅▄▅▄▆▆▆▄▄▅▅▄▃▄▅▃▄▂▄▄▅▁▂▂▃▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▃▃▄▄▅▅▅▄▅▄▂▂▆▄▂▆▅▄▅▃▄█▃▃▄▄▄▃▄▄▄▃▁▃▅▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.61263
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.49646
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.03763
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.335
wandb:      train/ensemble_f1 0.335
wandb:         train/mil_loss 1.19955
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h2q2rdk2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203918-h2q2rdk2/logs
wandb: Agent Starting Run: 43yebr6j with config:
wandb: 	actor_learning_rate: 0.00013199227514736344
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9198695849684628
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8609494569477645
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204112-43yebr6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/jl8tu6rw
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/43yebr6j
wandb: uploading history steps 118-125, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▆▇█
wandb: best/eval_avg_mil_loss █▅▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▆▇█
wandb:            eval/avg_f1 ▁▁▁▅████▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ██▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▇█▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅█▇▅▇▄▃▃▁▁▅▆▃▄▆▂▂▄▅▆▅▅▅▅▃▄▇▄▅▂▃▅▅▃▄▆▄▄
wandb:      train/ensemble_f1 ▆▅▆▄▆▆█▅▆▅▄▂▅▅▅▃▆▄▄▆▅▄▅▃▅▄▅▆▄▆▁▅▅▄▄▄▇▃▄▄
wandb:         train/mil_loss ▇█▆▄█▇▅█▄█▆▃▅▄█▇▃▁▁▅▇▆▅▅▄▃▃▆▇▅▃▄▆▅▃▅▅▃▄▄
wandb:      train/policy_loss ███▅█▄▂▁▆███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▅██▅▂▃▄▂▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77778
wandb: best/eval_avg_mil_loss 0.61946
wandb:  best/eval_ensemble_f1 0.77778
wandb:            eval/avg_f1 0.7457
wandb:      eval/avg_mil_loss 0.61143
wandb:       eval/ensemble_f1 0.7457
wandb:            test/avg_f1 0.67825
wandb:      test/avg_mil_loss 0.64504
wandb:       test/ensemble_f1 0.67825
wandb:           train/avg_f1 0.70804
wandb:      train/ensemble_f1 0.70804
wandb:         train/mil_loss 0.58888
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s0awxytz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_203921-s0awxytz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qcxxa24t with config:
wandb: 	actor_learning_rate: 0.0006461342965524799
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23911306760566953
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7457164303038997
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204142-qcxxa24t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qcxxa24t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁████████████████████████████▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ██▇▆▆▆▅▅▅▅▄▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▇▄▁▇▄▄▄▄▄▆▇▆▃█▅▅▇█▅▆▅▅▃▃▅▄▆▄▃▆█▄█▆▅▇▇▅
wandb:      train/ensemble_f1 ▁▂▄▄▄▄▁▅▆▂▃▃▅▅▄▃▃▆▄▃▆▂▆▄▃▆▃▇▆▄▃█▇▃▅▅▅▅▃▄
wandb:         train/mil_loss ▄▆▅▇▆▄▅▄▂▆▇▁▄▄▆▃▄▅▅▄▄▄▃▅▅▅▇█▄█▂▄▅▇▇▅▅▂▃▄
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82708
wandb: best/eval_avg_mil_loss 0.47041
wandb:  best/eval_ensemble_f1 0.82708
wandb:            eval/avg_f1 0.81737
wandb:      eval/avg_mil_loss 0.45829
wandb:       eval/ensemble_f1 0.81737
wandb:            test/avg_f1 0.86133
wandb:      test/avg_mil_loss 0.37644
wandb:       test/ensemble_f1 0.86133
wandb:           train/avg_f1 0.82006
wandb:      train/ensemble_f1 0.82006
wandb:         train/mil_loss 0.48945
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweepy-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/n28852lk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204023-n28852lk/logs
wandb: Agent Starting Run: khqhlxv2 with config:
wandb: 	actor_learning_rate: 0.00014833721655452647
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02391786770323512
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7442777339648989
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204218-khqhlxv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/khqhlxv2
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▄▄▁▄▄▁▆▂▄▅▃▁▇▄▄▂█▃▇▅▅▅▇▄▃▁▅▂▃▄▃▁▄▃▇▄▄▂
wandb:      train/ensemble_f1 ▄▇▇▅▅▅▇▅▄▇▆▄▄▆█▃▇▆▇▆▆▄██▃▆▄▁▆▅▅▄▁▇▂▇▄▅▄▃
wandb:         train/mil_loss ▁▃▃▄▅▃▃▁▆▃▃▄▂▅▅▃▃▅▄▂▂▆▂▆▃█▄▂▄▅▂▄▄▅▃▆▃▁▂▃
wandb:      train/policy_loss ▂▂▁▃▃▂▃▃▂▂▁▃▃▃▂▃▂▄▁▅▂▅▂▃▅▅▄▁▄▄▂▄▃▄▃█▃▁▁▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▇▄▅▄▂▅▅▅▄▄▄▂▄▁▂▄▁▅▁█▄▇▂▂▅▂▄▂█▁▇▁▇▄▅▂▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.83825
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.8158
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.76348
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.47147
wandb:      train/ensemble_f1 0.47147
wandb:         train/mil_loss 0.64003
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/43yebr6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204112-43yebr6j/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: uploading history steps 106-118, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆▆▇█
wandb: best/eval_avg_mil_loss █▁▂▃▆
wandb:  best/eval_ensemble_f1 ▁▆▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▇█▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▁▁▁▂██████████████████████████████
wandb:       eval/ensemble_f1 ▁▁▁▁██▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▂██▃▂▂▃▂▃▄▂▃▁▃▃▂▂▁▂▃▄▃▃▂▂▂▁▂▃▃▃▃▃▂▂▁▃▁
wandb:      train/ensemble_f1 ▂▂▂▁▂▆▆█▂▂▁▂▃▃▂▃▃▂▂▃▂▁▃▂▁▁▃▂▂▂▂▂▁▂▂▁▃▂▂▁
wandb:         train/mil_loss ▂▁▁▂▂▁▇█▇▆▆▇▅█▇▅▇▅▅▇█▄▄▆▄▅▄▆▆▅▆▆▇▅▆▆█▄▆▅
wandb:      train/policy_loss ███▂██████████████▁████▅████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.74977
wandb: best/eval_avg_mil_loss 0.52712
wandb:  best/eval_ensemble_f1 0.74977
wandb:            eval/avg_f1 0.58822
wandb:      eval/avg_mil_loss 0.8066
wandb:       eval/ensemble_f1 0.58822
wandb:            test/avg_f1 0.83022
wandb:      test/avg_mil_loss 0.52376
wandb:       test/ensemble_f1 0.83022
wandb:           train/avg_f1 0.53297
wandb:      train/ensemble_f1 0.53297
wandb:         train/mil_loss 0.72706
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qcxxa24t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204142-qcxxa24t/logs
wandb: Agent Starting Run: 5lhasjtb with config:
wandb: 	actor_learning_rate: 0.0011523897916234944
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0009360965235994944
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1856740161107825
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204346-5lhasjtb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5lhasjtb
wandb: uploading history steps 121-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▆█
wandb: best/eval_avg_mil_loss █▇▇▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▆█
wandb:            eval/avg_f1 ▁▂▅▅▅▅▆▆▅▇▇▇▇█▇▇▇▇█▇▇▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▃▄▅▅▇▇▇▇█▇▇▇▇▇▇██▇▇▇▇▇▅▅▅▅▅▅▆▅▅▅▅▅▆▅▅▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▇▄▄▆▅█▇▆▇█▅▇▅▆▆▅▅█▅▆▆▅▆▆▇▆▅▆▄▇█▇▄▄▆▆▃▅
wandb:      train/ensemble_f1 ▁▂▄▃▅▅▅▃▅▆▃▆▆▆▄▆█▇▅▄▄▄▄▃▅▄▃▅▆▇▅█▇▅▆▂▇▆▂▆
wandb:         train/mil_loss ▇▅█▆▅▆▅▅▅▄▅▄▆▃▄▅▄▃▅▄▅▄▇▃▄▅▃▃▃▃▅▂▃▃▁▂▁▂▄▂
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▅▃▅▃▃▃▃▃▃▃▃▁▁▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃█▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▃▅▅▅▅▅▅▅▅▆▅▁▂▅▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.44317
wandb: best/eval_avg_mil_loss 0.89602
wandb:  best/eval_ensemble_f1 0.44317
wandb:            eval/avg_f1 0.42555
wandb:      eval/avg_mil_loss 0.83123
wandb:       eval/ensemble_f1 0.42555
wandb:            test/avg_f1 0.50249
wandb:      test/avg_mil_loss 0.77291
wandb:       test/ensemble_f1 0.50249
wandb:           train/avg_f1 0.49354
wandb:      train/ensemble_f1 0.49354
wandb:         train/mil_loss 0.81029
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cosmic-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/khqhlxv2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204218-khqhlxv2/logs
wandb: Agent Starting Run: wzk4g139 with config:
wandb: 	actor_learning_rate: 0.0003313472570765726
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2776122289352181
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21078018404058177
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204427-wzk4g139
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzk4g139
wandb: uploading history steps 183-191, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▆▇██
wandb: best/eval_avg_mil_loss ▂▁▇▇██▇▇▇▅
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▆▇██
wandb:            eval/avg_f1 ▁▁▁▂▄▆▇▇▇▆▇▆▆▇▇▇▇▆▆▆▆▆▇▆▇▆▇▇▆▆▇▇▇▇▆▇▇▇▇█
wandb:      eval/avg_mil_loss ▁████▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▄▅▆▇▅▇▆▇▆▆▇▇▆▇▆▆▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇█▇▆▆█▇█
wandb:      train/ensemble_f1 ▁▁▂▆▇▇▆▇▆▆▆▇▇▇▆▆▆▆▇▇▇▇█▇▇▇▆▇▆▇▇▇▆▇█▇█▇▇▇
wandb:         train/mil_loss ▇▇▆▄▅▆▅▇▇▇▅▅▅▂▄▆▅▄▅▃▅█▆▆▂▄▅▆▁▃▃▄▂▂▄▃▃▆▁▂
wandb:      train/policy_loss ▅▅▁▅▅▅▅▅▁▅▅▆▅▅▅▅▅▅▄▅▅▅▅▅▃▅▅▅▅▄▅▅▅▅▅▅▄▅▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▁▄▄█▄█▄▄▅▄▄▄▄▄▄▃▅▄▄▄▆▄▁▄▄▁▄▄▄▄▄▄▆▄▃▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64271
wandb: best/eval_avg_mil_loss 0.62321
wandb:  best/eval_ensemble_f1 0.64271
wandb:            eval/avg_f1 0.63922
wandb:      eval/avg_mil_loss 0.59728
wandb:       eval/ensemble_f1 0.63922
wandb:            test/avg_f1 0.69231
wandb:      test/avg_mil_loss 0.58935
wandb:       test/ensemble_f1 0.69231
wandb:           train/avg_f1 0.70634
wandb:      train/ensemble_f1 0.70634
wandb:         train/mil_loss 0.61557
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wzk4g139
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204427-wzk4g139/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 27wek0ot with config:
wandb: 	actor_learning_rate: 0.0008221164761281859
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2944983695471677
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3759500497463054
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204748-27wek0ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/knxlgt95
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/27wek0ot
wandb: uploading history steps 334-335, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss ▁█▄▃▂▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▄▅▅▅▇▇███▇▇▇▇▇▇
wandb:      eval/avg_mil_loss █▇▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▅▅▇▇▇▇█▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▅▂▄▃▆▂▆▄▅▃▃▄▄▄▃▅▄▄▇▅▇▆▅▄▄▄▇▆█▆▆▃▇▇▆▄█
wandb:      train/ensemble_f1 ▅▅▂▃▁▃▅▄▃▁▄▅▅▁▇▅▆▂▃▇▄▅▆▄▇▆▇▄▃▆▄▇▆▃█▆▆▆▅▇
wandb:         train/mil_loss █▇▅▅▆▄▅▄▃▄▄▄▄▄▃▃▅▂▃▄▄▃▂▃▂▄▁▂▄▂▂▂▁▂▂▄▂▂▂▁
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁▁▁▁▁▁▁▁▁▁▁██████████▁▁▂▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.8591
wandb: best/eval_avg_mil_loss 0.39576
wandb:  best/eval_ensemble_f1 0.8591
wandb:            eval/avg_f1 0.84926
wandb:      eval/avg_mil_loss 0.37166
wandb:       eval/ensemble_f1 0.84926
wandb:            test/avg_f1 0.85288
wandb:      test/avg_mil_loss 0.37864
wandb:       test/ensemble_f1 0.85288
wandb:           train/avg_f1 0.86557
wandb:      train/ensemble_f1 0.86557
wandb:         train/mil_loss 0.4303
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5lhasjtb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204346-5lhasjtb/logs
wandb: Agent Starting Run: e7g6ka72 with config:
wandb: 	actor_learning_rate: 1.8824710167530967e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.491889025464139
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6535938857510424
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_204907-e7g6ka72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e7g6ka72
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▆▆▆▆▆▅▄▄▄▃▃▃▂▁▁▁▆▆▆▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▅▄▅▅▄▄▄▆▄▆▄▅▄▄▆▄▆▅▅▃▃▁▅▆▄▂▄█▅▅█▅▄▇▇▄▅
wandb:      train/ensemble_f1 ▃▃▆▅▇▆▂▄█▄▆▇▆▅▁▅▆▇▄▅▅▆▃▅▄▄▆▅▁▃▂▆▅▄▇▆▄▆▄▆
wandb:         train/mil_loss ▄▅▇▆▇▃▇▄▅▅▄▅▄▄▅▅▄▃▃▅▄▄▁▄▂▃▇█▄▁▄▄▃▄▆▃▂▃▁▆
wandb:      train/policy_loss ▅▆█▆▅▇▃▅▃▂▇▆▇▄▇▄▅▄▇▃▄▅▂▅▇▄▆▅▃▅▂▁▅▅▆▄▆▅▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▇▅▅▂▆▆▅▇▅▆▄▅▄▆▃▄▅▅▂▆▅▅▇▆▆▆▂▁▅▇▅█▇▁▅█▅▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.36518
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.25951
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.95469
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3372
wandb:      train/ensemble_f1 0.3372
wandb:         train/mil_loss 1.73056
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e7g6ka72
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204907-e7g6ka72/logs
wandb: Agent Starting Run: s2gihxbe with config:
wandb: 	actor_learning_rate: 1.2377150408238909e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03831573958520029
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.103530327563216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_205050-s2gihxbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s2gihxbe
wandb: uploading history steps 287-291, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▆▆▅▅▅▅▄▄▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▃▅▅▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇███▇▇▇██▇▇▇▇▇▇▇█▇▆
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▃▄▅▆▆▇▆▆▇▇▇▇▇▇███▇▇███▇▇▇▇▇▇█▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▂▃▃▃▄▄▄▄▄▅▅▅▅▆▅▆▅▇▆▅▆▇▇▇▆▇██▇█▇██▇██▇
wandb:      train/ensemble_f1 ▁▃▃▃▄▅▅▄▅▅▆▅▅▅▅▆▆▇▆▆▇▇█▆▇▇▇▆▆▆▇█▆▇▆▆▇██▇
wandb:         train/mil_loss █▆▆▇▇▄▇▆▆▃▄▇▄▄▃▃▄▄▂▂▃▃▃▄▃▃▂▁▄▂▂▂▂▄▃▂▁▂▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▁▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73317
wandb: best/eval_avg_mil_loss 1.2514
wandb:  best/eval_ensemble_f1 0.73317
wandb:            eval/avg_f1 0.68747
wandb:      eval/avg_mil_loss 1.13227
wandb:       eval/ensemble_f1 0.68747
wandb:            test/avg_f1 0.72867
wandb:      test/avg_mil_loss 1.79803
wandb:       test/ensemble_f1 0.72867
wandb:           train/avg_f1 0.73896
wandb:      train/ensemble_f1 0.73896
wandb:         train/mil_loss 0.76272
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run giddy-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/27wek0ot
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_204748-27wek0ot/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▆▇▇▇█
wandb: best/eval_avg_mil_loss █▇▆▅▄▃▃▁▁▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▆▇▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▆▆▆▆▆▆▆▇▇▇▇███████▆▆
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████████████▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▁▂▄▃▂▃▃▃▂▂▃▄▄▄▅▄▆▄▆▅▃▃▆▅▅▆▄▄▇▅█▅█▇▅▅▇▆
wandb:      train/ensemble_f1 ▁▁▃▁▂▂▄▃▅▅▂▃▅▃▄▃▃▄▂▄▂▁▁▄▆▆▅▅▆▇▆▇▇█▅▅▆▇▆▄
wandb:         train/mil_loss ▆▆█▂▅▅▆█▅▇▃▃▄▅▅▄▂▄▄▅▃▃▆▅▄▆▆▄▂▄▆▁▃▃▃▃▃▃▃▁
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████▁█████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66596
wandb: best/eval_avg_mil_loss 0.59494
wandb:  best/eval_ensemble_f1 0.66596
wandb:            eval/avg_f1 0.63474
wandb:      eval/avg_mil_loss 0.58028
wandb:       eval/ensemble_f1 0.63474
wandb:            test/avg_f1 0.71591
wandb:      test/avg_mil_loss 0.54835
wandb:       test/ensemble_f1 0.71591
wandb:           train/avg_f1 0.70087
wandb:      train/ensemble_f1 0.70087
wandb:         train/mil_loss 0.59616
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s2gihxbe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_205050-s2gihxbe/logs
wandb: Agent Starting Run: 8safpmug with config:
wandb: 	actor_learning_rate: 0.005756286874893501
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5352776995060059
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9922019835998854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_205718-8safpmug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8safpmug
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁██
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁██
wandb:            eval/avg_f1 ▁█▇▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▂▂▁▃▅▅▅▅▅▅▅▅█████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▁██▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▆▅▆▂▃▃▄▃▁▃▃▃▁▄▄▄▄▄▆▂▅▂▃▃▅▃▆▅▄▄▅▄▆▄▃▅▄▅
wandb:      train/ensemble_f1 ▁█▆█▆▆▅▅▅▅▄▅▆▄▄▅▅▅▅▅▅▆▅▅▆▆▄▅▆▆▆▅▆▇▆▅▆▆▆▆
wandb:         train/mil_loss ▅█▂▁▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▂▁
wandb:      train/policy_loss ▃▅▅▅▅▅▅▅▃▄▅█▃▂▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61556
wandb: best/eval_avg_mil_loss 0.66356
wandb:  best/eval_ensemble_f1 0.61556
wandb:            eval/avg_f1 0.53119
wandb:      eval/avg_mil_loss 0.72818
wandb:       eval/ensemble_f1 0.53119
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 0.73504
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.50746
wandb:      train/ensemble_f1 0.50746
wandb:         train/mil_loss 0.58151
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8safpmug
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_205718-8safpmug/logs
wandb: Agent Starting Run: mpbk95p6 with config:
wandb: 	actor_learning_rate: 0.0032208851820751615
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.561964784154083
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8389029020655167
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_205901-mpbk95p6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mpbk95p6
wandb: uploading history steps 102-114, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████▇▇▇███▆▆▆▅▅▅▅▄▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▄▄▆▇▆▆▆██████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 █████▇▇█▆▆▅▄▄▄▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▆▇█▇▆▇▅▅▇▆▅▇▅▆▄▄▃▄▃▃▁▄▃▃▂▃▄▃▅▃▄▅▅▆▁▄▁▄
wandb:      train/ensemble_f1 ▇█▇▆▅█▆█▅▆▅▆▆▇▆▇▅▅▃▃▄▃▆▃▃▄▅▃▃▁▃▂▅▃▄▁▅▆▄▁
wandb:         train/mil_loss █▄▃▅▇▂▇▆▅▆▃▃▁▄▄▄█▆▄▄▄▅▇▂▄▅▂▄▄▃▇▇▄▅▆▃▅█▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▇▄▄▄█▄▇▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7552
wandb: best/eval_avg_mil_loss 0.57196
wandb:  best/eval_ensemble_f1 0.7552
wandb:            eval/avg_f1 0.65278
wandb:      eval/avg_mil_loss 0.57261
wandb:       eval/ensemble_f1 0.65278
wandb:            test/avg_f1 0.63492
wandb:      test/avg_mil_loss 0.59945
wandb:       test/ensemble_f1 0.63492
wandb:           train/avg_f1 0.63569
wandb:      train/ensemble_f1 0.63569
wandb:         train/mil_loss 0.57845
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mpbk95p6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_205901-mpbk95p6/logs
wandb: Agent Starting Run: iobzrhrm with config:
wandb: 	actor_learning_rate: 1.8439362396643843e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8590581018848968
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4448993386791207
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_210050-iobzrhrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iobzrhrm
wandb: uploading history steps 100-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅▅▃▁▃▅▆▃▆▄▆▅█▂▁▅▅▃▄▅▆▆▆▅▃▄▂▅▂▃▄▃▃▂▄▃▄▄
wandb:      train/ensemble_f1 ▇▇▃▆▅▆▂▆▅▃▅▇▆█▅▄▅▁▄▆▆▇▃▃▆▄▃▆▅▆▇▄▃▄▄▅▇▃▆▁
wandb:         train/mil_loss ▃▄▃▅▇▅▇▅▆▄▆▄█▆▂▆▅▁▄▅▁▅▅▅▄▁▁▃▂▅▂▁▃▆▄▅▂▃▅▃
wandb:      train/policy_loss ▅▂▁▇▃▇▅▆▂▃▂▅▂▆▅▄▂▂█▅▆▆▆▇▄▆▄▆▆▇▃▄▆▆▇▅▅▆▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▇▅▆▆▁▆▄▅▇▅▅▄▅▄▇▄▆▇▃▆▇▇▇▆▂▅▄▇▇▅▄▇▆▆▇█▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.8108
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.79839
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.98136
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31034
wandb:      train/ensemble_f1 0.31034
wandb:         train/mil_loss 0.57675
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run devout-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iobzrhrm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_210050-iobzrhrm/logs
wandb: Agent Starting Run: giu7dbv3 with config:
wandb: 	actor_learning_rate: 8.441677565626928e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.007073263632552895
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01869573150489634
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_210230-giu7dbv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/6zuemt8r
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/giu7dbv3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: best/eval_avg_mil_loss ██▇▇▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:            eval/avg_f1 ▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▇▇█████████████
wandb:      eval/avg_mil_loss █▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▁▂▂▂▃▃▃▃▄▄▆▅▅▅▆▅▆▆▆▇▆▇█▇▇▇▇▇▇▇▇█▇██
wandb:      train/ensemble_f1 ▁▁▂▂▁▂▂▃▂▃▃▃▄▄▄▅▅▅▆▆▅▆▅▅▆▆▇▆▇▆▇▇▇▆█▇▇▇▆█
wandb:         train/mil_loss █▇▇█▅▆▇▆▆▅▅▅▄▄▄▃▄▄▃▄▃▃▂▃▂▁▂▁▂▂▂▁▂▂▁▂▂▁▁▂
wandb:      train/policy_loss ██████████████████████████▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75196
wandb: best/eval_avg_mil_loss 0.52265
wandb:  best/eval_ensemble_f1 0.75196
wandb:            eval/avg_f1 0.74425
wandb:      eval/avg_mil_loss 0.45623
wandb:       eval/ensemble_f1 0.74425
wandb:            test/avg_f1 0.67884
wandb:      test/avg_mil_loss 0.6966
wandb:       test/ensemble_f1 0.67884
wandb:           train/avg_f1 0.71137
wandb:      train/ensemble_f1 0.71137
wandb:         train/mil_loss 0.72667
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run royal-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/giu7dbv3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_210230-giu7dbv3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
