wandb: Agent Starting Run: xf6k4u7q with config:
wandb: 	actor_learning_rate: 9.32718262271915e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.031332263723463094
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14227307576061243
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145209-xf6k4u7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xf6k4u7q
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 221-226, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▆▆▆███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▆▆█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▂▄▆▅▃▄▃▅▅▆▄▅▃▁▇▃▄▇▃▆▆▄▅▆▄▃▆▇▄█▇█▆▇▇▆▆
wandb:      train/ensemble_f1 ▃▄▄▁▁▅▁▆▅▄▁▂▄▆▄▅▃▄▇▅▄▅▃▄▅▄▇▅▄▂▄▇▇▅▅▆█▆▇█
wandb:         train/mil_loss ▅▄▇▆▃▆▄▃▇▆▆▇▆▄▂▅▃▆▄▂▃▄▃▄▅▅▄▂▄▂▃▅▇▂▃█▆▄▁▆
wandb:      train/policy_loss ████████████████████▁███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████▁███████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58242
wandb: best/eval_avg_mil_loss 0.78495
wandb:  best/eval_ensemble_f1 0.58242
wandb:            eval/avg_f1 0.58242
wandb:      eval/avg_mil_loss 0.76448
wandb:       eval/ensemble_f1 0.58242
wandb:            test/avg_f1 0.54338
wandb:      test/avg_mil_loss 0.76641
wandb:       test/ensemble_f1 0.54338
wandb:           train/avg_f1 0.56212
wandb:      train/ensemble_f1 0.56212
wandb:         train/mil_loss 0.8019
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xf6k4u7q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145209-xf6k4u7q/logs
wandb: Agent Starting Run: 4chcmp2v with config:
wandb: 	actor_learning_rate: 0.00012951262804464003
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4193063456692142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13199157711313958
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145449-4chcmp2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4chcmp2v
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▆▃▄▅▆▄▃▇▄▇▄▄▁▃▅▄▆█▆▂▆▅▆▃▄▄▇▅▇▆▅▃▆▇▄▄▆
wandb:      train/ensemble_f1 ▄▇▅▄▆▅▄▆▄▇▆▇▄▄▅▁█▃▃▅▆▆▄▆▃▅▆▇▆▂▆▆▆▅▇▆█▆▄▇
wandb:         train/mil_loss ▁▅▆▆▅▆▆▇▂▅▆▆▄▃▄▅▅▄▅▇▅▆▃▆▇▆▂▃█▅▇▃▆▇█▄▇▅▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 5.47866
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.42034
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 7.14852
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33555
wandb:      train/ensemble_f1 0.33555
wandb:         train/mil_loss 4.24174
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4chcmp2v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145449-4chcmp2v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p8e3r1zk with config:
wandb: 	actor_learning_rate: 4.369588223554294e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14655469158102907
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03758076408916233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145608-p8e3r1zk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p8e3r1zk
wandb: uploading history steps 95-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅█
wandb:      eval/avg_mil_loss ▅▅▅█▇██████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▁
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▅▂█▃▇▄▃▅▄▅▁▃▄▄▇▆█▃▃▂▇▃▇▅▅▆▆▄▃▄█▁▄▄▄▆▇▄
wandb:      train/ensemble_f1 ▅▆▅▂▄▃▅▅▅▅▄▁▄▇▇▇▂▆▃▁▇▃▅▃▆▄▅▅▄▄▄▆▁█▄▅▅▃▆█
wandb:         train/mil_loss ▃▇▄█▇▃▃▂▂▁▄▆▇▄▆▂▇▆█▃▃█▃▂▆▄▄▅▃▄▂▆▂▃▄▆▆▇▄▄
wandb:      train/policy_loss ▄▂█▇▅▇▄█▇████▄▇▅▇▅▇▇██▇▅▇▅██▅█▄▄▄▄▄▄▄▄▄▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████▁███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.77257
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 0.75089
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.56573
wandb:      test/avg_mil_loss 0.70275
wandb:       test/ensemble_f1 0.56573
wandb:           train/avg_f1 0.54828
wandb:      train/ensemble_f1 0.54828
wandb:         train/mil_loss 0.75733
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/p8e3r1zk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145608-p8e3r1zk/logs
wandb: Agent Starting Run: 80rql2i0 with config:
wandb: 	actor_learning_rate: 4.936555020227304e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04349020563645778
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.020850011287933738
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145720-80rql2i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80rql2i0
wandb: uploading history steps 165-180, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▅▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▄▄█▆▅▃▅▆▅▄▁▂▂▇▅▆▅▇▄▄▂▅▃▄▃▅▅▅▃▃▆█▃▂▇▃▃▇
wandb:      train/ensemble_f1 ▂▄▂▅▇█▆▄▅▆▆▆▃▃▂▇▆▂▇▅▇▅▃▄▁▅▇▅▁▃▅▄▄▅▆▇▃▄▃█
wandb:         train/mil_loss ▇▅▄▆▃▅▁▂▄▄▄▄▄▅▃▅▃▅▃▃█▆▄▅▃▄▁▃▅▂▅▅▃▅▄▃▄▄▂▁
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▃▁▁▃▁▁▃▁▁▁▁▁▁▁▁▁▃▁▁▁▁▅▃▁▁▁▁▁▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.74695
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.72344
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.62774
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.51488
wandb:      train/ensemble_f1 0.51488
wandb:         train/mil_loss 0.64696
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80rql2i0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145720-80rql2i0/logs
wandb: Agent Starting Run: kcrpyb00 with config:
wandb: 	actor_learning_rate: 2.04979193332363e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04164084917463007
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15724242953326673
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_145919-kcrpyb00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kcrpyb00
wandb: uploading history steps 305-312, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▄▅▇█
wandb: best/eval_avg_mil_loss █▇▇▅▃▁
wandb:  best/eval_ensemble_f1 ▁▂▄▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▅▅▅▇▇▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▄▄▄▄▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▅▅▅▅▁▃▆▅▄▅▃▅▃▆▅▄▅▅█▄▅▅▆▇▆▆▆▇▅▅▅▆▄▅▆▆▇
wandb:      train/ensemble_f1 ▅▄▂▃▄▄▄▂▂▄▃▄▄▅▁▂▄▄▂▃▅▄▄▅▅▄▅▅▆▅▅▅█▅▃▄▆▅▅▆
wandb:         train/mil_loss ▅▆▆▆▇█▆▆█▇▄▅▄▆▃▅▄▅▂▂▄▄▃▄▅▃▃▃▄▂▁▅▂▂▅▃▃▄▂▃
wandb:      train/policy_loss ████████████▁███████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅██▇▇█▅▅▅▅▅▅▅▅▅▂▁▁▂▂▁▂▁▁▂▂▁▁▁▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.86597
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 0.83485
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.74563
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.5704
wandb:      train/ensemble_f1 0.5704
wandb:         train/mil_loss 0.73156
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kcrpyb00
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_145919-kcrpyb00/logs
wandb: Agent Starting Run: szpcbyx9 with config:
wandb: 	actor_learning_rate: 1.2868660864207657e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.006942993086555216
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5294754424168165
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150245-szpcbyx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/szpcbyx9
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▇▅▂▄▃▂▅▁▃▃▄▄▃▁▄█▇▅▄▄▄▆▅▆▄▃▂▅▃▃▃▄▆▆▃▅▆
wandb:      train/ensemble_f1 ▅▅▅▄▃▅▆▅▁▃▅▆▂▄▄▅▆▅▅▅▄▄▅▆▇▅▆▂▆▅▄█▄▅▇▇▆▇▆▄
wandb:         train/mil_loss ▄▄▅▁▇▃▃▅▄▄▃▆▁▅▄▆▅▃▇▃▄▃▄█▆▄▄▅▃▃▅▇▂▅▇▇██▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62248
wandb: best/eval_avg_mil_loss 0.65354
wandb:  best/eval_ensemble_f1 0.62248
wandb:            eval/avg_f1 0.62248
wandb:      eval/avg_mil_loss 0.6432
wandb:       eval/ensemble_f1 0.62248
wandb:            test/avg_f1 0.5864
wandb:      test/avg_mil_loss 0.67801
wandb:       test/ensemble_f1 0.5864
wandb:           train/avg_f1 0.592
wandb:      train/ensemble_f1 0.592
wandb:         train/mil_loss 0.76469
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/szpcbyx9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150245-szpcbyx9/logs
wandb: Agent Starting Run: r08e4po1 with config:
wandb: 	actor_learning_rate: 2.889841002181666e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03017642837487211
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7272572364099554
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150357-r08e4po1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r08e4po1
wandb: uploading history steps 394-414, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▆▇▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▅▄▅▅▄▁▅▅▃▄▂▄▄▅▇▆▆▅▇▇▇▆▇▇▇▅▆▆▇▇▆▇▇▅▇▇██
wandb:      train/ensemble_f1 ▃▁▃▅▂▂▄▄▄▄▄▃▄▅▅▆▅▄▄▅▃▆▆▆▅▅▆▇▆▆▆▆▆█▇▇▆███
wandb:         train/mil_loss █▇▇▃███▆▆▅▆▆▅▇▇▄▇▅▂▅▄▆▄▆▆▅▃▄▃▃▃▄▁▁▂▃▃▂▃▂
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▁▂▂███▇█▇▁▁▁▁████▇████▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁████████████████▃████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76139
wandb: best/eval_avg_mil_loss 0.82958
wandb:  best/eval_ensemble_f1 0.76139
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.77435
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.78348
wandb:      test/avg_mil_loss 0.5678
wandb:       test/ensemble_f1 0.78348
wandb:           train/avg_f1 0.7468
wandb:      train/ensemble_f1 0.7468
wandb:         train/mil_loss 0.73756
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run mild-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r08e4po1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150357-r08e4po1/logs
wandb: Agent Starting Run: rakodp6h with config:
wandb: 	actor_learning_rate: 1.193336058537619e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1330795230211389
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.954049233746042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150831-rakodp6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rakodp6h
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▃▅▃▄▄▇▅▃▄▂▃▃▂▁▆▂▇▃▄▃▄▄▁▄▂█▃▆▂▁▅▃▃▆▄▂▁▄
wandb:      train/ensemble_f1 ▅▅▄▅▆▄▆█▄█▅▅▁▃▄▂▅▄▅▄▄▆▆▁▄▅▅▅▄▅▅▅▃▆▁▄▄▅▃▄
wandb:         train/mil_loss ▆▃▃▄▅▃▃▄▄▃▅▅▅▄▂▅▄▃▁▁▄▇▇▅▆▇▅▆▇▃▅▄▅▃▅▄█▃▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.91844
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91217
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.05965
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3266
wandb:      train/ensemble_f1 0.3266
wandb:         train/mil_loss 0.79745
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rakodp6h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150831-rakodp6h/logs
wandb: Agent Starting Run: j31s4pxo with config:
wandb: 	actor_learning_rate: 0.00023289254337027768
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.037431876859478574
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9390810954191574
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_150943-j31s4pxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j31s4pxo
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▄▄▆▄▄▃▅▅▄▄▂▃▃▄▄▅▃▅▄▃▇▆▁▂▅▆▅▄▅▄▅█▃▄▃▃▄▅
wandb:      train/ensemble_f1 ▅▅▃▅▆▃▆▅▃▅▄▅▅▃▅▆▅▄▅▅▆▁▄▃▄▇▇▆▅▄▄▆▃▅▅▄▄█▄▃
wandb:         train/mil_loss ▆▆▇▁▁▄▄▇▇▇▂▄▇▇█▄▆▆▂▆▅▂▆▄▃▅▆▆▂▃▁▃▆▅▂▆▁▃▅▃
wandb:      train/policy_loss █████▁██████▁█▁▆██▁████████████▆██████▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██▁█████▁█▁████████████████████▆██▆██▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38558
wandb: best/eval_avg_mil_loss 1.2918
wandb:  best/eval_ensemble_f1 0.38558
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 1.2596
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.90828
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.42878
wandb:      train/ensemble_f1 0.42878
wandb:         train/mil_loss 0.99319
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run upbeat-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j31s4pxo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_150943-j31s4pxo/logs
wandb: Agent Starting Run: mck7dezk with config:
wandb: 	actor_learning_rate: 1.307209381001262e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2261671103094021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6946030367572169
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151056-mck7dezk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mck7dezk
wandb: uploading history steps 348-350, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▆▆▆███████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▆▆▆▆▆▆▆██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▆▆▂▆▇▅▂▆▃▃▃▆▁▄▃▂█▁▁▄▃▇▄▃▂▃▂▁▅▂▃▇▅▇▂▇▁▅
wandb:      train/ensemble_f1 ▃▂▄▅▇▃▅▅▂▅▃▅▃▄▄▁▂▆▅▃▄▆▂▃▂▃▅▂▄▁▄▅▄▄▄█▆▄▆▁
wandb:         train/mil_loss ▆▂▄▆▅▅▆█▃▄▆▁▇▅▇▅▃▅▆▃▇█▇▄█▅▁▅▇▄▄▄▆▅▃▆▃▄▄▆
wandb:      train/policy_loss ▇▇█▇▆▆█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▃▁▁▂▂▄▂▂▁▁▂▂▁▂▃▁▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▇▇▆▇█▅▅▅▅▅▅▅▅▅▅▅▅▅▂▃▁▂▂▁▂▂▂▃▂▁▁▂▂▂▂▂▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.72538
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.65625
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 1.35867
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.47186
wandb:      train/ensemble_f1 0.47186
wandb:         train/mil_loss 1.32456
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mck7dezk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151056-mck7dezk/logs
wandb: Agent Starting Run: u18313u0 with config:
wandb: 	actor_learning_rate: 7.736378284719078e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.010283043958280724
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4699714993548356
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151447-u18313u0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u18313u0
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▄▂▄▄▆▅▄▃▇▄▄▆▂▄▄▅▅▃▁▄▄▅▄▅▆▆▅▃▁▅▆▄▆▄▅▄▃█
wandb:      train/ensemble_f1 ▇▅▂▅▁▆▅▅▅▄▄▄▄▄▃▄▄▃▅▆▇▇▅▄▅▄▄▅▄▅▅▂▆▄▇▄▆▅▃█
wandb:         train/mil_loss ▄▆█▄▄▅▅▄▆▄▅▃▆▃▆▆▅▆▁▅▅▅▄▅▆▆▅▅▆▃▆▆▂▅▅▇▅▅▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.89814
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.89233
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.04013
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34959
wandb:      train/ensemble_f1 0.34959
wandb:         train/mil_loss 0.94653
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u18313u0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151447-u18313u0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qlf1w1it with config:
wandb: 	actor_learning_rate: 0.007374485971276195
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9965325264699656
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9291842409117456
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151616-qlf1w1it
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qlf1w1it
wandb: uploading history steps 161-179, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ▇█▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▅▄▄▄███████████████████████████
wandb:      eval/avg_mil_loss ▇▇▇█████████▄▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅▅▅▅▅▄▄█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▂▆▅▅▃▆▁▄▅▅▅▅▃▆▁▄▆▂▆▁▅▅▄▅▅▆▄█▅▇▅▅▅▃▃▄▅▆
wandb:      train/ensemble_f1 ▄▅▆▄▄▄▅▁▄▃▂▅▂▃▅▃▃▄▆▆▄▂▄▃▅▄▄█▇▅▅▅▆▆▃▅▆▆█▆
wandb:         train/mil_loss █▃▃▃▄▇▇▃▃▅▅▆▆▇▃▁▄▇▇▅▄▅▅▄▃▃▁▁▄▅▆▂▁▆▃▄▅▄▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6875
wandb: best/eval_avg_mil_loss 0.57432
wandb:  best/eval_ensemble_f1 0.6875
wandb:            eval/avg_f1 0.6875
wandb:      eval/avg_mil_loss 0.58293
wandb:       eval/ensemble_f1 0.6875
wandb:            test/avg_f1 0.58242
wandb:      test/avg_mil_loss 0.67198
wandb:       test/ensemble_f1 0.58242
wandb:           train/avg_f1 0.66588
wandb:      train/ensemble_f1 0.66588
wandb:         train/mil_loss 0.55561
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run iconic-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qlf1w1it
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151616-qlf1w1it/logs
wandb: Agent Starting Run: 80ysanw4 with config:
wandb: 	actor_learning_rate: 0.004522212610308275
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7874783363691352
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9614777719669344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_151821-80ysanw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80ysanw4
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▄▆▅▅▇▆▅▅▆▄▆▆▅▆▅▁█▆▄▅▄▅▅▃▆▅▄▆▅▅▆▇▅▅▆▇▅▆
wandb:      train/ensemble_f1 ▅▄▄▇▃▂▄▄▅▂▅▄▅▅▃█▅▅▄▄▅▃▆▄▇▆▇▂▂▄▂▅▅▆▅▆▄▁▆▆
wandb:         train/mil_loss ▆▃▃▃▆▅█▄▆▄▃▃▆▃▂▃▃▁▆▆▁▄▅▆▃▃▄▂▃▄▁▁▃▂▁▁█▃▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57033
wandb: best/eval_avg_mil_loss 1.64254
wandb:  best/eval_ensemble_f1 0.57033
wandb:            eval/avg_f1 0.57033
wandb:      eval/avg_mil_loss 1.59859
wandb:       eval/ensemble_f1 0.57033
wandb:            test/avg_f1 0.56573
wandb:      test/avg_mil_loss 1.24624
wandb:       test/ensemble_f1 0.56573
wandb:           train/avg_f1 0.57165
wandb:      train/ensemble_f1 0.57165
wandb:         train/mil_loss 0.62678
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/80ysanw4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_151821-80ysanw4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dw2tdm6x with config:
wandb: 	actor_learning_rate: 0.006546907271623926
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9798586484484184
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6064514960016066
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152000-dw2tdm6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2tdm6x
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▆▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃
wandb:      eval/avg_mil_loss ▃▅▅▁▂▂▂▂▂▂▂▂▂▂▂▅▇▇▇▇██████████▆▄▄▄▃▃▃▃▃▃
wandb:       eval/ensemble_f1 █▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▆▅█▇▆▆▅▅▇▇▄▇▁▇▄▇▆▅▂▆▄▆▆▇▅▃▄▄▃▄▄▁▅▃▃▃▂▅
wandb:      train/ensemble_f1 █▅▇▅▅▆▅▇▇▆▄▆▅▄▂▄▇▇▃▇▄▇▆▄▅▄▆▄▇▅▅▂▄▄▄▅▃▃▁▅
wandb:         train/mil_loss ▂▃▂▂▂▃▅▂▄▃▂▃▃▃▄▄█▁▂▄▄▃▂▅▃▁▅▃▅▄▂▂▃▃▄▃▃▃▃▇
wandb:      train/policy_loss █████▅▇████████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56261
wandb: best/eval_avg_mil_loss 0.7987
wandb:  best/eval_ensemble_f1 0.56261
wandb:            eval/avg_f1 0.53661
wandb:      eval/avg_mil_loss 0.79884
wandb:       eval/ensemble_f1 0.53661
wandb:            test/avg_f1 0.58
wandb:      test/avg_mil_loss 0.7554
wandb:       test/ensemble_f1 0.58
wandb:           train/avg_f1 0.58767
wandb:      train/ensemble_f1 0.58767
wandb:         train/mil_loss 0.53539
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dw2tdm6x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152000-dw2tdm6x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2e6pm0ed with config:
wandb: 	actor_learning_rate: 0.003202070935787142
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9985758638261436
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7996795289290353
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152121-2e6pm0ed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2e6pm0ed
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████████▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▅▅▆▆▆▅▆▆▆▅▆▆▇▇▇▆▆▆███▇▇▇▇
wandb:       eval/ensemble_f1 █████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▄▇▄▇▄▅▅▆▆▅▇▅▆▇▅█▄▅▃▇▃▄▅▇▆▅▅▆▄▃▇▆▅▅▅▄▅▁
wandb:      train/ensemble_f1 ▅▃█▆▆▇▄▃▆▅█▆▇█▇▆▆▅▅▅▅▇▃▄▅▅█▇▆▆▄▆▅▆▄▅█▅▅▁
wandb:         train/mil_loss ▃▄▂▄▁▅▂▄▄▆▃▄▂▅▂▆▆▃▁▃▇▂▄▂▂▇▃▃▂█▅▃▃▄▃▂▁▂▄▇
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████████████▁███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.648
wandb: best/eval_avg_mil_loss 0.64415
wandb:  best/eval_ensemble_f1 0.648
wandb:            eval/avg_f1 0.63535
wandb:      eval/avg_mil_loss 0.66248
wandb:       eval/ensemble_f1 0.63535
wandb:            test/avg_f1 0.59524
wandb:      test/avg_mil_loss 0.65238
wandb:       test/ensemble_f1 0.59524
wandb:           train/avg_f1 0.62813
wandb:      train/ensemble_f1 0.62813
wandb:         train/mil_loss 0.62317
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run different-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2e6pm0ed
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152121-2e6pm0ed/logs
wandb: Agent Starting Run: rsgcog5g with config:
wandb: 	actor_learning_rate: 0.00022198216581008123
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9921025107023568
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.954259004249014
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152233-rsgcog5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rsgcog5g
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████████████▅▅▅▅▅▅▅▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▇▇▇▇▇▇█████████
wandb:       eval/ensemble_f1 ████████████████████████▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆█▅▆▂▆▅▇▅▆▇▇▄▄▄▆▇▆▆▄▅▅▄▁▅▃▆▄▄▂▃▃█▃▅▄▂▄▂
wandb:      train/ensemble_f1 ▆▆▅▄█▇▄▆▆▇▄▄▇▆▇▅▆▇▆▇▆▇▄▅▃▄▁▄▅▅▄▆▅▇▄▅▄▅▁▅
wandb:         train/mil_loss ▄▆▇▇▆▆▆▄▅▅▅▇▄▂▃▇▅▄▄▅▆▄▆▅█▃▇▆▄▅▃▃▇▆▅▆▆▃▁▇
wandb:      train/policy_loss ███████████████████████████████████▁████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████████▁████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 0.63721
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.63922
wandb:      eval/avg_mil_loss 0.65666
wandb:       eval/ensemble_f1 0.63922
wandb:            test/avg_f1 0.56363
wandb:      test/avg_mil_loss 0.63827
wandb:       test/ensemble_f1 0.56363
wandb:           train/avg_f1 0.62407
wandb:      train/ensemble_f1 0.62407
wandb:         train/mil_loss 0.58112
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rsgcog5g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152233-rsgcog5g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c1zgfxcw with config:
wandb: 	actor_learning_rate: 4.064536212284563e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9399166146844976
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9233302207162084
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152403-c1zgfxcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1zgfxcw
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▃▃▃▅▅▅▅▇▇▇████████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▂▅▃▆▆▅▅▇▄▆▄▆▇▃▅▄▅▂▇▇▄▃▇█▂▆█▆▆▆▅▇▅▄▁▇▆
wandb:      train/ensemble_f1 ▆▄▂▅▄▄▁▅▅▄▆▄▅▅▆█▅▃▄▆▃▄▄▆▄▄▃▃█▇▅▄▅▅▆▇▄▇▄▅
wandb:         train/mil_loss █▁▅▄▅▃▆▅▂▅▆▃▆▄▆▄▃▇▆▅▅▆▅▄▃▆▂▇▄▄▄▇▅▄▃▄▅▃▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6568
wandb: best/eval_avg_mil_loss 0.69367
wandb:  best/eval_ensemble_f1 0.6568
wandb:            eval/avg_f1 0.6568
wandb:      eval/avg_mil_loss 0.69898
wandb:       eval/ensemble_f1 0.6568
wandb:            test/avg_f1 0.63636
wandb:      test/avg_mil_loss 0.55349
wandb:       test/ensemble_f1 0.63636
wandb:           train/avg_f1 0.64973
wandb:      train/ensemble_f1 0.64973
wandb:         train/mil_loss 0.59161
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worthy-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c1zgfxcw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152403-c1zgfxcw/logs
wandb: Agent Starting Run: jtblsiic with config:
wandb: 	actor_learning_rate: 0.0002141701746590349
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9930766218025004
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6700498135979998
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152515-jtblsiic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jtblsiic
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▃▄▄▄▅▅▄▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇██████
wandb:       eval/ensemble_f1 █████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▄▄▄▆▄▄▄▄▃▂▅█▃▃▃▆▅█▄▄▅▆▅▃▅▇▁▄▄▃▆▄▆▃▄▄▃
wandb:      train/ensemble_f1 ▄▆▄▄▅▆▇█▄▅▄▂▃▇▆▃▆▄▄▅▇▃▅▄▅▆▅▁▅▃▅█▃▆▄▂▂▅▄▆
wandb:         train/mil_loss ▄▁▆▁▂▂▄▃▃▃▄▃▂▄▂▃▄▅▄▃▂▂▂▃▂█▂▅▃▂▂▂▃▁▂▂▃█▆▃
wandb:      train/policy_loss █████████████▁██████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66562
wandb: best/eval_avg_mil_loss 1.14014
wandb:  best/eval_ensemble_f1 0.66562
wandb:            eval/avg_f1 0.65278
wandb:      eval/avg_mil_loss 1.16995
wandb:       eval/ensemble_f1 0.65278
wandb:            test/avg_f1 0.65278
wandb:      test/avg_mil_loss 0.74821
wandb:       test/ensemble_f1 0.65278
wandb:           train/avg_f1 0.645
wandb:      train/ensemble_f1 0.645
wandb:         train/mil_loss 0.57127
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jtblsiic
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152515-jtblsiic/logs
wandb: Agent Starting Run: ca7g24zp with config:
wandb: 	actor_learning_rate: 1.19529648335825e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9823493607856822
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9927791291700344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152628-ca7g24zp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ca7g24zp
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▄▂▅▆▄▄▅▅▄▄▃▆█▆▃▆▅▄▅▅▅▅▆▃▅▅▄▅▅▅▃▁▅▅▅▅
wandb:      train/ensemble_f1 ▆▄▆▅▄▄▆▅▅█▅▇▇▃█▅▅▇▇▁▆▆▆▅▅█▅▄▆▅▇▅▅▁▅█▆▆▅▄
wandb:         train/mil_loss ▂▂▆▄▂▃▂▄▃▃▆▃▅▂▆▃▆▃▄▃▁▂▂▃▄▂▃▃▂▄▃█▃▅▇▄▆▅▃▃
wandb:      train/policy_loss ████████▁█████▁██▁█████████▆██▁██▁██▁█▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████▁▁███▁███████▁████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.09284
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.10295
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.88162
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.38316
wandb:      train/ensemble_f1 0.38316
wandb:         train/mil_loss 0.56599
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ca7g24zp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152628-ca7g24zp/logs
wandb: Agent Starting Run: hcvhi7vm with config:
wandb: 	actor_learning_rate: 7.263499695605022e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7616589556608282
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9484551142490784
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152740-hcvhi7vm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcvhi7vm
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▅▆▆▇▂▇▅█▄▅▄▇▅▄▄▆▁▄▃▄▆▃▃▅▂▅█▃▃▇▆▂▆▆▃▆▃▄
wandb:      train/ensemble_f1 ▄▁▄▄▄▆▃▃▄▆▄▅▆▃▄▆▆▅█▄▄▂▄▁▄▂▅▆▂▅▅▅▄▄▃▆▂▃▂▅
wandb:         train/mil_loss ▄▁▂▆▁▂▄█▂▄▃▅▃▃▅▄▂▃▄▆▄▄▁▆▄▂▆▅▅▅▄▃▆▃▂▇▃▄▇▂
wandb:      train/policy_loss ▆▇▇▇█▇▆▅▇▇▇▇▇▄▇▇▇▅▇▅█▅▄▇▅▆█▄▅▇▅▁▇▄▇▇▂▇▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆█▄▆▆▅▆▆▆▆▆▃▆▆▆▄▆▆▅▆▅▅▆▆█▆▆▃▆▅▄▆▃▅▄▅▄▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.44153
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.42432
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.03381
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40439
wandb:      train/ensemble_f1 0.40439
wandb:         train/mil_loss 0.68021
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcvhi7vm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152740-hcvhi7vm/logs
wandb: Agent Starting Run: g6b3gk0g with config:
wandb: 	actor_learning_rate: 0.009741463197460424
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9820157349062528
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.779002767798722
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_152853-g6b3gk0g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g6b3gk0g
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▃▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▁▁▁▁█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:       eval/ensemble_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▆▇▆▅▂▄▆▆▄▁▇▆▇▃▃▆▂▆▆▆▆▂▆▅▆▇▄▁▆▅▇▆▇▂▄▆██
wandb:      train/ensemble_f1 ▄▆▆▄▅▃▅▃▆▃▆▅▅▂▄▃▃▅▅▅▅▆▅█▁▆▆▅▄▅▄▁▃▄█▄▄▂▆▂
wandb:         train/mil_loss ▅▅██▄▄▃▆▇▃▆▅▆▆▆▁▅▅▆▆▇▄▄▁▄▄▄▄▆▅▆▄▆▅▅▅▇▃▇▅
wandb:      train/policy_loss ████████▁███████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62248
wandb: best/eval_avg_mil_loss 0.67475
wandb:  best/eval_ensemble_f1 0.62248
wandb:            eval/avg_f1 0.57665
wandb:      eval/avg_mil_loss 0.7227
wandb:       eval/ensemble_f1 0.57665
wandb:            test/avg_f1 0.63439
wandb:      test/avg_mil_loss 0.64826
wandb:       test/ensemble_f1 0.63439
wandb:           train/avg_f1 0.56319
wandb:      train/ensemble_f1 0.56319
wandb:         train/mil_loss 0.57097
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silvery-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g6b3gk0g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_152853-g6b3gk0g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kuow4tec with config:
wandb: 	actor_learning_rate: 0.006977655221369493
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.005111457259147967
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7407470735271645
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153015-kuow4tec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuow4tec
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▄▆▃▆▂▄▄▆▇▃▄▄▃▇▃▂▁█▅▇▄▃▆▅▂▆▃▄▆▂▄▇█▂▆▄▄▄
wandb:      train/ensemble_f1 ▅▃▄▁▃▄█▅▂▃▃▅▄▃▁▄▅▂▃▂▁▇▂▃▄▅▃▄▄▃▁▅▇▃▆▁▄▄▄▃
wandb:         train/mil_loss ▅▃▆▅▅▅▄▅▂▇▅▄▅▄▅▂█▄▃▃▅▆▁▃▅▇▁▅▃▆▃▅▆▆▂▆▂▅▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.88436
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.87855
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.01769
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 0.89234
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuow4tec
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153015-kuow4tec/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8malewhf with config:
wandb: 	actor_learning_rate: 0.009232845321516508
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.006447528584778595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33330680622804765
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153138-8malewhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8malewhf
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁█▁▃▄▃▄▅▇█▅▂▅▅▆▆▁▇▇▆▂▆▄▅▂▅▄▅▆▆▅▇▆▄█▆▅▄▄
wandb:      train/ensemble_f1 ▂▂▇▁▃█▃▂▂▂▂▅▅▄▂▄▃▄▃▄▆▅▅▅▇▃▄▅▇▆▄▇▆▆▇▄▆▅▃▆
wandb:         train/mil_loss ▆█▄▇█▅▆▅▇▇▅▄▅▆█▅▆▆▆▅▄▅▆▆▄▆▅▇▁▃▄▅▆▅▆█▅▅▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 1.42905
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 1.36838
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.61948
wandb:      test/avg_mil_loss 0.9994
wandb:       test/ensemble_f1 0.61948
wandb:           train/avg_f1 0.61216
wandb:      train/ensemble_f1 0.61216
wandb:         train/mil_loss 1.44891
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8malewhf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153138-8malewhf/logs
wandb: Agent Starting Run: qkb5pm5d with config:
wandb: 	actor_learning_rate: 0.000901870080885328
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9793417001723862
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9602652419547908
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153251-qkb5pm5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkb5pm5d
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▄▃▆▅▃▆▆▆▅▂▅▆▂▃▂▅▅▅▅▅▅▇▅▃▂▅▅▁▄▆▄▇▄▄▄█▂▅
wandb:      train/ensemble_f1 ▅▄▅▆▅▅▄▆▅▆▇▆▇▆▇▇▄▇▃▅▅▇▆▇▄▄▅▂▁▆▄▆█▄▇▅▆▆▅▆
wandb:         train/mil_loss ▃▄▃▂▁▆▂▃▃▃▃█▃▃▃▄▃▂▂▄▄▃▃▄▂▅▃▄▂▆█▅▃▃▂▃▂▆▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.17321
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.17039
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.39813
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.335
wandb:      train/ensemble_f1 0.335
wandb:         train/mil_loss 0.5263
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkb5pm5d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153251-qkb5pm5d/logs
wandb: Agent Starting Run: uuhjsr08 with config:
wandb: 	actor_learning_rate: 0.00881716968961693
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11955247016489869
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9735100331584624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153403-uuhjsr08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uuhjsr08
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▇██
wandb: best/eval_avg_mil_loss █▄▂▁▁
wandb:  best/eval_ensemble_f1 ▁▄▇██
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▄▆▆▆▆▇█████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▇▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▄▇▆▇████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▂▃▃▁▂▃▁▃▅▅▆▇▇▆▇▇█▆▅▆▄▇▅▅▇▆▃▅▇█▆▆▅▇▇▆▅▆
wandb:      train/ensemble_f1 ▂▂▁▃▃▃▄▂▃▂▄▃▄▄▅▇▆▇▇█▄▇▆▅█▇▆█▇▆▇▅█▆▅▇██▆█
wandb:         train/mil_loss ██▇▇▇▅▆▅▇▇▅▂▁▅▂▄▅▄▄▃▄▃▅▁▂▂▂▄▂▂▃▃▂▄▃▂▃▄▂▅
wandb:      train/policy_loss █████████▁██████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅███▂▁▅▅▂▁▂▁▃▂▂▂▁▁▁▄▁▁▃▁▃▁▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83897
wandb: best/eval_avg_mil_loss 0.72162
wandb:  best/eval_ensemble_f1 0.83897
wandb:            eval/avg_f1 0.83897
wandb:      eval/avg_mil_loss 0.71254
wandb:       eval/ensemble_f1 0.83897
wandb:            test/avg_f1 0.8284
wandb:      test/avg_mil_loss 0.53164
wandb:       test/ensemble_f1 0.8284
wandb:           train/avg_f1 0.81798
wandb:      train/ensemble_f1 0.81798
wandb:         train/mil_loss 0.64177
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uuhjsr08
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153403-uuhjsr08/logs
wandb: Agent Starting Run: cwnfzbmt with config:
wandb: 	actor_learning_rate: 8.20938499445882e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9741436867519444
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9793235355775912
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153552-cwnfzbmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cwnfzbmt
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▃▇▄▃▄█▆▃▅▄▇▇▅▃▅▅▆▅▅▃▃▃▂▄▇█▅▃▄▃▄▄▁▅▆▆▂
wandb:      train/ensemble_f1 ▂▇▅▃▄▇▅▄▃▃▅▄▇▇▅▃█▄▅▆▅▅▄▆▇▅▇▃▃▆▆█▄▁▄▅▆▅▅▄
wandb:         train/mil_loss ▆▅▃▃▄▄▂▆▄▄▇▅▄▄▄▃▄▃▃▆▄▅▃▄▄▃█▃▅▅▃▄▅▇▂▃▄▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.84826
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.84674
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.9667
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 0.53434
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cwnfzbmt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153552-cwnfzbmt/logs
wandb: Agent Starting Run: khl1etep with config:
wandb: 	actor_learning_rate: 0.008390413342327445
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.990513796015446
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1915220821711352
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153704-khl1etep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/khl1etep
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▂▅▃▆▆▆▇▅▇▃▆▄▆▄▄▇▂▇▇▄▆▅▅▄▄▄▆▅▄█▁▇▇▇▂▇▆▇
wandb:      train/ensemble_f1 ▆▃▅▃▅▅▄▆▅▅▆▆▃▆▇▆▇▂▆▇▇▄▅▆▅▄▄▅▅▄▆▄▁▇▇▂█▄█▅
wandb:         train/mil_loss ▃▃▃▅▄▁▂▃▃▂▄█▅▂▃▃▃▃▅▁▃▄▆▃▄▇█▃▃▃▂▂▇▃▃▅▂▂▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.0371
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.03504
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.26991
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3448
wandb:      train/ensemble_f1 0.3448
wandb:         train/mil_loss 0.53872
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/khl1etep
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153704-khl1etep/logs
wandb: Agent Starting Run: ui3cdons with config:
wandb: 	actor_learning_rate: 1.0258542495309438e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9609701028386226
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6277955936402254
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153816-ui3cdons
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ui3cdons
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▃▃▄▄▄▄▅▅▆▅▅▆▇▇▇▆▆▆▆▆▇▇▆▆▇▇▇▆▆▇▇▇▇█████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▃▂▄▅▃▅▆▁▃▄█▆▆▄▆▄▄▄▄▄▅▇▅▄▂▄▄▆▄▅▄▅▄▂▄▄▆
wandb:      train/ensemble_f1 ▄▄▃▃▂▃▅▄▇▆▄▃█▆▆▆▄▅▄▄▇▆▆▄▂▁▄▄▄▅▆▃▆▅▅▃▄▅▃▆
wandb:         train/mil_loss ▄▂▂▄▂▃▄▅▁▁▂▅▄▅▄▃▄▃▄▃▄▂▄▅▇▃█▃▄▂▇▁▃▂▆▄▇▂▃▇
wandb:      train/policy_loss ███████▂████▂██▁█████████▂█▂██▁▂████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▂██▂▂████▁██████▂▂█▇███▂▇▁█▂████▂█▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.86666
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.87199
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.7379
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.51808
wandb:      train/ensemble_f1 0.51808
wandb:         train/mil_loss 0.5603
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run expert-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ui3cdons
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153816-ui3cdons/logs
wandb: Agent Starting Run: y4kp7fqr with config:
wandb: 	actor_learning_rate: 2.2213956935861374e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9944041381833228
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7833067928330886
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_153928-y4kp7fqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4kp7fqr
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆▃▇▆▃▃▅▃▃▃▅▄▅▄▄▄▃▆▄▄▇▄▅▅▃▄█▆▅▅▂▇▅▁▅▅▅▄
wandb:      train/ensemble_f1 ▃▄█▂▇▆▃▅▅▃▆▄▄▄▇▄▄▃▆▄▇▇▁▅▄▇▅▃▄▃▅▂▆▅▆▁▂▅▅▄
wandb:         train/mil_loss ▄▄▇▂▃▂▅█▄▃▆▇▅▃▄▄▂▄▅▅▃▂▃▃▄▃▄▄▃▄▃▄▃▄▃▄▂▄▁▄
wandb:      train/policy_loss ███▁████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆█▅▄▅▇▄▄▅▅▄▅▄▆▆▇▅▅▄▄▃▃▂▄▄▅▆▇▅▆▆▅▁▅▄▅▄▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.09953
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.11322
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.85327
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.41925
wandb:      train/ensemble_f1 0.41925
wandb:         train/mil_loss 0.55331
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4kp7fqr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_153928-y4kp7fqr/logs
wandb: Agent Starting Run: aiie1mic with config:
wandb: 	actor_learning_rate: 0.0035266564399164604
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0373589973140388
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9771337523928968
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154041-aiie1mic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aiie1mic
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▇▄▆▁▂▂▅▄▅█▂▅▅▆▃▂▇▃▃▂▆▆▆▆▇▅▁▅▄▄▂▄▇▂▅▂▇
wandb:      train/ensemble_f1 ▅▃▃▅▁▄▅▄▅▃▄▄▂▂▅▁▂▆▃▅▆▂▅▆▅▆▃▅▂█▅▄▄▄▄▅▇▃▂▂
wandb:         train/mil_loss ▃▆▂▅▄█▅▅▃▄▂▅▇▅▆▂▅▂▁▂▇▃▃▅▅▆▂▇▄▃▆▂▄▃▄▄▃▄▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.8979
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.89216
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.03983
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34694
wandb:      train/ensemble_f1 0.34694
wandb:         train/mil_loss 0.92996
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aiie1mic
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154041-aiie1mic/logs
wandb: Agent Starting Run: cg1div2e with config:
wandb: 	actor_learning_rate: 1.045312979954627e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.003702438159804755
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.379436753160344
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154154-cg1div2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cg1div2e
wandb: uploading history steps 117-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss ▅▂█▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▅▄▄▄▅▅▅▅▅▇▇██▇▇▇▇▇▇▄▄▄▁▁▂▂▂▂▂▄▄▄▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▄▃▅▁▁▅▂▁█▇▃▂▂▂▄▃▃▃▂▂▃▃▃▃▃▅▄▄▃▃▄▄▂▂▂▂▁▁▂▂
wandb:       eval/ensemble_f1 ▅▃▅▆▆▅▅▆██▆▆▆▆▆▆▆▆▆▅▃▃▁▁▁▁▁▁▁▁▁▃▃▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▅▄▆▅▂▆▃▄▄▄█▅▆▂▃▅▃▄▅▄▅▂▄▄▄▅▅▅▃█▅▃▄█▆▅▆▄
wandb:      train/ensemble_f1 ▄▄▆▃▆▄▆▅▇▅▄▅▄▅▆▃▃▄▇▁▅▅▆▅▆▇▅▇▃▃▇▅▆▅█▇▅▆▆▇
wandb:         train/mil_loss ▆▅▆█▃▇▅▅▃▆▄▄▄▄▄▃█▄▄▇▅▆▄▅▁▅▆▄▂▅▃▄▄▄▄▅▅▂▄▃
wandb:      train/policy_loss ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇█▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▂▇▇▇▇▇▇▇▂▇▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75962
wandb: best/eval_avg_mil_loss 0.5533
wandb:  best/eval_ensemble_f1 0.75962
wandb:            eval/avg_f1 0.73906
wandb:      eval/avg_mil_loss 0.55217
wandb:       eval/ensemble_f1 0.73906
wandb:            test/avg_f1 0.66928
wandb:      test/avg_mil_loss 0.6997
wandb:       test/ensemble_f1 0.66928
wandb:           train/avg_f1 0.67503
wandb:      train/ensemble_f1 0.67503
wandb:         train/mil_loss 0.62381
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cg1div2e
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154154-cg1div2e/logs
wandb: Agent Starting Run: 5ul6p0zg with config:
wandb: 	actor_learning_rate: 0.00825672402445798
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.25889219533532615
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7809551281382843
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154326-5ul6p0zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5ul6p0zg
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▇▄▇▃▄▄▄▄▄▅▇▆▅▃█▃▃▄▆▂▅▄▅██▇▆▆▅▇▃▇▅▂▃▄▁
wandb:      train/ensemble_f1 ▅█▆▆▅▇▄▅▅▅▇▆▇▅▅▅▆▅▅▆▆▄▄▆▆▃▃▅▄▅▆▁▆▇▄▆▄▅▆▄
wandb:         train/mil_loss ▃▇▄▇▂▅▄▆▅▆▆▅▅▇▅▂█▄▆▁▄▇▃▂▅▇▆▃▄▁▄▄▇▆▄▆▄▆▄▃
wandb:      train/policy_loss ▅▆▁▄▃▃▆▆▄█▅▃▄▃▃▃▁▄▆▁▃▃▁▄▄▁▅▆▄▃▄▆▃▃▅▃▆▁▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▃▃▆▁█▅▃▃▁▁▁▃▃▃▄█▄▁▄▃▄▁▃█▄▅▁▅▆█▅▄▃▃▆▃▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.86228
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.8075
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.44765
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.39224
wandb:      train/ensemble_f1 0.39224
wandb:         train/mil_loss 1.15862
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5ul6p0zg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154326-5ul6p0zg/logs
wandb: Agent Starting Run: ll7dy694 with config:
wandb: 	actor_learning_rate: 1.009973465924049e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05464151371295933
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.024191173918328368
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154439-ll7dy694
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll7dy694
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▇▆▅▄▅▄▂▆▆▅▅█▁▅▆▄▄▄▅▅▄▄▄▃▄▇▆▆▂▆▅▄▂▆▄▁▅▄
wandb:      train/ensemble_f1 ▃▆▃█▇▃▆▃▅▂▅▅▅▇▆▅▅▄▂▆▆▄▄▄▄▄▇▅▆█▅▃▇▁▆▄▁▅▅▄
wandb:         train/mil_loss ▇▇█▅▇▆▇█▇█▅▆▇▇▆▆▃▇▅▅▄▅▅▇▇█▆▇█▁▇▆▇▅▇▆▆▆▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.36333
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.27968
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.40505
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32717
wandb:      train/ensemble_f1 0.32717
wandb:         train/mil_loss 7.20105
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ll7dy694
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154439-ll7dy694/logs
wandb: Agent Starting Run: 4a91f47q with config:
wandb: 	actor_learning_rate: 8.52413830755115e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6014509464691148
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4816452681670418
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154552-4a91f47q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4a91f47q
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▃▅▂▃▅▅▃▃▄▃▃▆▅▃▅▃▁▄█▅▅▅▃▄▂▃▅▆▄▅▆▂▃▂▅▅▂
wandb:      train/ensemble_f1 ▆▃▂▅▃▃▅▄▆▃▅▅▅▄▄▄▆▄▆▄▅█▄▅▅▂▄▆▅▂▃▂▄▁▅▂▂▃▂▃
wandb:         train/mil_loss ▅▅▅▁▄▆▃▇▃▇▄▅▅▅▂▄▅▅▅▄▇▅▃▄▇▄▄▄▄▃▇▆█▅▇▃▆▄▇▂
wandb:      train/policy_loss ▅▄▄▄▇▅▅▄▄▇▅▂▂▂█▅▄▄▇▄▅▇▅▄▅▁▄▅▄▅▇▁▂▂▅▄▂▂▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▅▅▄▄▄▅▇▂▁▃█▇█▇▅▄▅▅▅▆▅▁▄▅▅▅▆▅▂▄▃▂▅▆▄▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.08342
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.067
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.88637
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.37984
wandb:      train/ensemble_f1 0.37984
wandb:         train/mil_loss 0.59362
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4a91f47q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154552-4a91f47q/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w0cu93lb with config:
wandb: 	actor_learning_rate: 0.0006394553732878626
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8861534475391497
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7362917674637889
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154714-w0cu93lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w0cu93lb
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇█████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▂▂▁▂▂▁▁▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▃▂▄▆▅▄▇▇▂▆▄▄▂▃▆▅▆▃▇▆▆▆▇▃█▄▅▂▄▃▆▃▃▁▂▄▂
wandb:      train/ensemble_f1 ▄▅▆▂▄▄▃▄▄▅▄▃▂▅▅▂▅▂▅▅▅▄▃▃▆▄▄▅▃▆▂█▂▄▅▃▁▂▃▂
wandb:         train/mil_loss ▅▅▁▃▂▁▃▂▃▄▃▃█▇▅▄▃▃▅▂▁▂▂▂▂▃▁▃▄▅▃▁▅▃▆▃▃▂▅▁
wandb:      train/policy_loss ▅▁▁▇█▅█▅▄█▇██▅▅▅███▅█▅▅████▄█▁▅▄▅█▅█▅▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▂█▅▇███▅▅█▇▅▅▅███▁█▂██▅███▇▂▅▅▄▅▅█▂▅▇█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 1.8307
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.82112
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 1.41097
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.41874
wandb:      train/ensemble_f1 0.41874
wandb:         train/mil_loss 0.74035
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w0cu93lb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154714-w0cu93lb/logs
wandb: Agent Starting Run: 5iysmu5l with config:
wandb: 	actor_learning_rate: 0.008508510822513901
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12326601657705782
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05085093602634094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_154827-5iysmu5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5iysmu5l
wandb: uploading history steps 233-240, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▅▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▆▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▅▅▅████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▂▂▂▂▂▅▅▅▅▅▅▅▅▅▅▆▆▇████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▅▁▅▃▅▄▅▅▃▁▄▄▃▄▄▄▄▅▅▅▂▅▅▆▅▅▅▅█▇▅▄█▆▇▆▇
wandb:      train/ensemble_f1 ▂▃▄▂▃▁▃▅▄▃▁▅▂▆▄▄▄▅▃▄▅▅▄▂▆▄▄▅▆▄▃▇▅▅▅▇▆▇▇█
wandb:         train/mil_loss ▆▅▆▅▆█▆▆█▁▅▇▆▅▅▄▅▃▃▄▇▆▄▂▄▁▃▂▄▃▂▅▃▃▄▅▃▆▅▄
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▃▇▆▆██▅▆▅▅▃▃▃▁▃▃▁▁▁▄▆▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66562
wandb: best/eval_avg_mil_loss 0.72859
wandb:  best/eval_ensemble_f1 0.66562
wandb:            eval/avg_f1 0.66562
wandb:      eval/avg_mil_loss 0.69415
wandb:       eval/ensemble_f1 0.66562
wandb:            test/avg_f1 0.63636
wandb:      test/avg_mil_loss 0.59556
wandb:       test/ensemble_f1 0.63636
wandb:           train/avg_f1 0.67355
wandb:      train/ensemble_f1 0.67355
wandb:         train/mil_loss 0.64501
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5iysmu5l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_154827-5iysmu5l/logs
wandb: Agent Starting Run: 8vp4bnsj with config:
wandb: 	actor_learning_rate: 0.0001993435931012317
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4834345595262439
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47723357239273534
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155106-8vp4bnsj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8vp4bnsj
wandb: uploading history steps 184-203, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▃▄▃▂█▁▂▅▄▃▁▂▄▃▄▃▃▄▂▃▄▅▇▅▇▃▄▂▄▅▅▂▅▂▄▆▅
wandb:      train/ensemble_f1 ▁▃▄▂▃▂▄▃▂▁▃▆▂▃▅▄▆▃▃▅▄█▅▄▅▄▁▆█▇▅▄▁▄▃▃▄▆▅▇
wandb:         train/mil_loss ▆▆▆▇▇▇▇▆▆▄▆█▅▅▇▆██▇▅▃▇▃██▃▇▅▅▇▃▁▄▄▆█▃▅▆▃
wandb:      train/policy_loss ▆▂▂▃▅▅▁▄█▆█▄▄▇▆▁▅▁▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 0.76732
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.7438
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.61129
wandb:      test/avg_mil_loss 0.66942
wandb:       test/ensemble_f1 0.61129
wandb:           train/avg_f1 0.63035
wandb:      train/ensemble_f1 0.63035
wandb:         train/mil_loss 0.6127
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run blooming-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8vp4bnsj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155106-8vp4bnsj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oturex9y with config:
wandb: 	actor_learning_rate: 6.712456782384204e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.014968441741647465
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6524573208494296
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155352-oturex9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oturex9y
wandb: uploading history steps 116-138, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▅▃▆▄▇▅▅▄▃▄▃▄▆▅▃▅▅█▅▅▅▆▃▂▂▃▁▇▅▃▄▃▇▃▂▇▆▇
wandb:      train/ensemble_f1 ▃▅▃▄▃▄▄▇▄▃▅▅▅▆▅▇▅▂▂▄█▃▅█▃▂▁▂▃▂▄▃▇▇▃█▅▆▅▅
wandb:         train/mil_loss ▃▆▇▅▃▄▄▁▄▄▅▆▃▅▃▅▆▆▆▅▅▄▆▆▄▆▃▄█▂▃▁▅▂▅▃▅▅▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 2.11244
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 2.02679
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.61622
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.42756
wandb:      train/ensemble_f1 0.42756
wandb:         train/mil_loss 1.89467
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oturex9y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155352-oturex9y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gsng3nn1 with config:
wandb: 	actor_learning_rate: 4.416333173112144e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8985456114232796
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7492626474865381
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155535-gsng3nn1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gsng3nn1
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▇▄▄▆▆▆▄▅▇▇▅▃▅▃▅▃█▄█▂▅▆▂▇▄▅▁▇█▅▂█▆▂▇▅▂▂
wandb:      train/ensemble_f1 ▄█▄▅█▄▄▄▇█▆▆▆▄▄▄▅▇▃█▂▄▄▁▃▄▅▄▅▁▅▆▅▂▆▂▇▇▂▅
wandb:         train/mil_loss ▂▂▅▄▆▄▄▃▆▂▄▄▃▂█▄▃▆▄▄▂▆▅▂▃▂▃▁▃▂▇▄▅▂▅▃▄█▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.77554
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.77419
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.94448
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33555
wandb:      train/ensemble_f1 0.33555
wandb:         train/mil_loss 0.6202
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gsng3nn1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155535-gsng3nn1/logs
wandb: Agent Starting Run: jlwexlpf with config:
wandb: 	actor_learning_rate: 0.00022447777321857172
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.788142440136682
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9900060231102324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155649-jlwexlpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jlwexlpf
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▇▆▆▆▅▅▅▅▅▅▃▂▂▂▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁██▅▅▅▅▄▅▅▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▃▃▄▄▃▆▆▄▆▅▅█▆▅█▃▆▃▁▆▅▄▆▄▇▂▆▆▇▇▅▅▄▃▁▆▆▆
wandb:      train/ensemble_f1 ▄▃▃▄▂▆▆▄▆▃▆▃▅▅▆█▅▃▆▅▃▄▆▃▆▄▆▆▆▄▄▅▅▅▂▃▁▃▆▆
wandb:         train/mil_loss ▄▆▃▅▃▆▁▅▆▂▅▄▂▄▄▄▄▃▂▂▅▅▄▄▂▄▄▄▃▂█▇▄▂▃▃▃▄▄▇
wandb:      train/policy_loss ▆▄▄▆▆█▂█▆█▃▂▄▄█▃▃▆▆▄▆██▄▆▆█▄▆▄▆▆▁█▆▆▃▆▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅█▃▆██▇█▇▅▃██▇▅█▅▇▇▇█▆▅▅██▇▅▅▁▆▆▆█▇▅▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60091
wandb: best/eval_avg_mil_loss 0.69401
wandb:  best/eval_ensemble_f1 0.60091
wandb:            eval/avg_f1 0.60091
wandb:      eval/avg_mil_loss 0.69337
wandb:       eval/ensemble_f1 0.60091
wandb:            test/avg_f1 0.59524
wandb:      test/avg_mil_loss 0.71612
wandb:       test/ensemble_f1 0.59524
wandb:           train/avg_f1 0.59481
wandb:      train/ensemble_f1 0.59481
wandb:         train/mil_loss 0.71943
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jlwexlpf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155649-jlwexlpf/logs
wandb: Agent Starting Run: t7b01mmk with config:
wandb: 	actor_learning_rate: 0.0010401209912405693
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11347400275313768
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.949600406999218
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155802-t7b01mmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t7b01mmk
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▃▄▃▅▁▃▇▆▁▄▅▄▆▂▂▆▄▅▃▃▆▄▂█▅▇▄▄▄▅▆▄▅▇▄▃▁▂
wandb:      train/ensemble_f1 ▇▄▅▃▁▇▄▃▁▃▄▄▇▅▅▅▄▂▅▄▆▄▄▃▂█▅▂▄▅█▄▅▅▄▁▆▃▅▃
wandb:         train/mil_loss ▅▂▂▃█▅▃▃▆▅▅▅▇▂▆▆▆▄▄▃█▁▁▅▄▅▅▂▆▁▅▅▆█▇▂▄▆▇▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.77772
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.77345
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.88181
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3283
wandb:      train/ensemble_f1 0.3283
wandb:         train/mil_loss 0.79302
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t7b01mmk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155802-t7b01mmk/logs
wandb: Agent Starting Run: 0kree2r6 with config:
wandb: 	actor_learning_rate: 0.0002371831664890643
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04104894007044613
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9038051697958542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_155913-0kree2r6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0kree2r6
wandb: uploading history steps 187-195, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▂▂▂▂▂▂▂▂▂▂▂▂█████▂▂▂▂▂▂▂▂▂▂▂███▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇█▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂██▂▂▂▂▂▂▂▂▂████▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▃▂▇▅▇▅▃▄█▄▁▆█▄▃▅▅▅▄▇▅▂▅▅▅▃▅▆▆▃▃▃▅▅▆▅▄
wandb:      train/ensemble_f1 ▆▄▃▃▂▃▁▆█▄▄▇▅▅▅▂▆▃▄▅▄▃▇▄▄▅▃▆▇▆▁▅▃▃▇▁▅▄▅▃
wandb:         train/mil_loss ▇▃▄▃▅▁▆▄▃█▃▅▅▃▃▅▄▆▅▅▃▁▁▅▅▃▂▂▅▅▂▁▃▄▃▅▇▂▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆█▄██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▄████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71717
wandb: best/eval_avg_mil_loss 0.60768
wandb:  best/eval_ensemble_f1 0.71717
wandb:            eval/avg_f1 0.70645
wandb:      eval/avg_mil_loss 0.6017
wandb:       eval/ensemble_f1 0.70645
wandb:            test/avg_f1 0.57464
wandb:      test/avg_mil_loss 0.90379
wandb:       test/ensemble_f1 0.57464
wandb:           train/avg_f1 0.66389
wandb:      train/ensemble_f1 0.66389
wandb:         train/mil_loss 0.73126
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0kree2r6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_155913-0kree2r6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iz1wfk99 with config:
wandb: 	actor_learning_rate: 1.0515768742671588e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07664713685646862
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47155882365911894
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160132-iz1wfk99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iz1wfk99
wandb: uploading wandb-summary.json
wandb: uploading history steps 186-202, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅██████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▄▃▄▃▄█▄▅▇█▃▄▅▇▄▅▄▁▃▇▄▇▃█▅▆▂▅▅█▆▆▅▆▇▃▅
wandb:      train/ensemble_f1 ▂▇▇▅▃▅▂▃▇▄▂█▅█▆▃▄█▆▆▄▁█▄▅▆▂▄▅▇▇▇▆▆▅▆▇▇▅▇
wandb:         train/mil_loss █▅▆▄▄▄▅▄▇▆▅▃▄▃▆▆▄▅▅▂▃▆▃▆▄▃▃▃▃▅▃▁▃▅▅▄▅▄▄▃
wandb:      train/policy_loss █▆▆▆█▆▆█▆▁▁▁▁█▆█▇▄▆█▆█▆█▃█▄▆██▄▇██▆███▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▆█▆▆█████▄██▆▆▁▁▁▁▁▁▄███▇▆█▆█▆▃▆█▄████▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 0.87987
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 0.8529
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78778
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.55675
wandb:      train/ensemble_f1 0.55675
wandb:         train/mil_loss 0.79633
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iz1wfk99
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160132-iz1wfk99/logs
wandb: Agent Starting Run: e7ew4m6f with config:
wandb: 	actor_learning_rate: 0.0004949593355605621
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7703540019847674
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44728170858135863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160350-e7ew4m6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e7ew4m6f
wandb: uploading history steps 90-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▅▃▄▆▃▅▄▂▅▃▂▅▂▄▅▅▅▅▅▄▇▄▃▄▄▅▄▄▃▅▄▄▄▄▃█▅▄
wandb:      train/ensemble_f1 ▅▅▄▄▅▃▆▆▆▇▃▁▄▅▁▇▇█▂▅▄▄▄▆█▄▆▇▁▅▅▅▇▇▇▄▃▅▁▄
wandb:         train/mil_loss ▃▃▂▆▄▅▃▂▁▄▅▅▂▄▃▅█▃▁▄▄▅▆▂▄▅▄▅▂▇▄▄▂▂▂▄▃▅▅▃
wandb:      train/policy_loss ▄▂▃▁▁▁▁▁▄▂▄▂▄▂▄▄▁▁▆▂▆▅▂▄▅▂▆▄▄▄▂▄▄▁▂█▄▂▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▃▃▁▄▁▅▃▆▁▅▁▄▅▄▅▅▃▅▃▃▁▆▇█▁▁▅▅▃▅▃▁▃▃▅▁▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 0.86813
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.86289
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.78348
wandb:      test/avg_mil_loss 0.50659
wandb:       test/ensemble_f1 0.78348
wandb:           train/avg_f1 0.68361
wandb:      train/ensemble_f1 0.68361
wandb:         train/mil_loss 0.57672
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e7ew4m6f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160350-e7ew4m6f/logs
wandb: Agent Starting Run: t2jwjhao with config:
wandb: 	actor_learning_rate: 0.009642240391040837
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.041658007256770935
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7218122463438721
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160503-t2jwjhao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t2jwjhao
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▄▃▁▅▄▃▄▄▆▅▄▆▂▅▅▄▅▅▅▃▂▂▃▅▂▃▂▃▅▃▄▄▆▆▂▃▆▅
wandb:      train/ensemble_f1 █▃▂▅▅▃▄▆▃▆▂▁▄▄▅▅▃▃▄▄▁▅▅▄▂▁▃▂▃▄▁▃▃▂▆▄▆▄▄▄
wandb:         train/mil_loss ▇▁▆▆▆▆▅█▆▅▇▇▅▇▆▆▆▆▆▃▅▆▆▄▄▇▄▆▆▇▇██▇▄▆▆▆▇▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.89814
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.89243
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.04013
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.94262
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t2jwjhao
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160503-t2jwjhao/logs
wandb: Agent Starting Run: zy00iz6q with config:
wandb: 	actor_learning_rate: 3.345694387856236e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29199318648034345
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01719016335037238
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160616-zy00iz6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zy00iz6q
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▇▄▁▃▃▄▆▆▆▅▅▄▅▂▆█▃▆▅▇▆▅█▄▇▅▇▂▅▅▆▆▃▅▅▆▅▅
wandb:      train/ensemble_f1 ▇▅▃▆▃▆▆▆▅▅▃▇▆▇▆▃▇▇▇██▃▅▁▄▂█▅▅▇▆▆▆▄▇█▇██▆
wandb:         train/mil_loss ▆▅▅▅▆▅▆▅▆▃▆▄▅█▄▂▅▂▂▃▅▁▄▁▃▂▇▄▆▂▁▄▃▅▅█▂▆▅▅
wandb:      train/policy_loss ▅▄▄▄▄▄▅▁▂▅▂▄▄▄▄▂▆▅▃▄▂▄▄▅▄█▄▂▄▁▆▂▅▅▅▂▆▁▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▁▄▁▄▅▃▂▂▅▁▂▄▄▄▁▄▂▆▅▃▃▇▅▅▇█▇▂▅▅▃▃▅▆▂▄▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62637
wandb: best/eval_avg_mil_loss 0.72421
wandb:  best/eval_ensemble_f1 0.62637
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.70353
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.56875
wandb:      test/avg_mil_loss 0.73175
wandb:       test/ensemble_f1 0.56875
wandb:           train/avg_f1 0.5516
wandb:      train/ensemble_f1 0.5516
wandb:         train/mil_loss 0.76495
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zy00iz6q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160616-zy00iz6q/logs
wandb: Agent Starting Run: xlrsld6z with config:
wandb: 	actor_learning_rate: 0.0005215085010634572
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0014373191331377155
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05953932617457802
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160728-xlrsld6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlrsld6z
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▇▄▁▄▇▂▂▁▃▂▆█▆▃▄▄▅▄▄▃▃▄▅▅▃▂█▄▂▂▅▂▃▄▃▄▁▅▂
wandb:      train/ensemble_f1 ▃▁▄▂▃▄▂▂▃▁▄▂▆█▃▃▃▄▄▇▄▂▅▄▃▅▅█▃▅▂▃▄▅▃▄▁▅▄▃
wandb:         train/mil_loss ▄▆▄▆▄▃▅▂▅▅▅▅▅▅▅▆▆▆▅▂▂▄▃▆▄▄▃▃▆▅▅▃█▃▅▆▃▆▁▂
wandb:      train/policy_loss █████████████████████▁██████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▃▃▃▃▃▃▅▁▅▅▅▅▄▃▂▃▄▃▄▃▃▅▄▂▃▄▄▅▃▆▄▃█▂▄▂▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63108
wandb: best/eval_avg_mil_loss 1.09982
wandb:  best/eval_ensemble_f1 0.63108
wandb:            eval/avg_f1 0.63108
wandb:      eval/avg_mil_loss 1.05999
wandb:       eval/ensemble_f1 0.63108
wandb:            test/avg_f1 0.70515
wandb:      test/avg_mil_loss 0.5964
wandb:       test/ensemble_f1 0.70515
wandb:           train/avg_f1 0.66905
wandb:      train/ensemble_f1 0.66905
wandb:         train/mil_loss 0.78743
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xlrsld6z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160728-xlrsld6z/logs
wandb: Agent Starting Run: yn06ecu0 with config:
wandb: 	actor_learning_rate: 3.245228793171099e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11180886401691648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0354818843763286
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160840-yn06ecu0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yn06ecu0
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▆▅▃▅▇▃▂▃▅▇▇▂█▂▃▁▄▄▁▃▁▄▅▄▆▂█▃▂▄▃▂▃▆▅▃▃▄
wandb:      train/ensemble_f1 ▅▆▄█▄▃▃▅▃▃▄▆▇▃▃▇▃▆▅▁▃▄▂▅▆▃▄▅▄▅▆▇▆▂▃▆▄▅▅▆
wandb:         train/mil_loss ▂▁▇▄▅▅▄▆▃▃▃▅▄█▃▅▇▅▆▂▃▅▆▅▇▆▃▂▃▁▄▃▅▂▅▅▆▃▃▃
wandb:      train/policy_loss ▆▃█▃▃▁▃▃▃▁▁▆▃▁▄▃▃▁▁▆▃▁▁▄▃▆▆▆▂▃▃▁▁▁▆▁▁▁▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▆▆▁▃▃▁▃▃▁▆▃▁▁▆▁▁▃▃▁▃▃▁▁▁▆█▃▃▁▁▆▁▁▁▃▃▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.10043
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.06605
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.89507
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.41159
wandb:      train/ensemble_f1 0.41159
wandb:         train/mil_loss 0.8765
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yn06ecu0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160840-yn06ecu0/logs
wandb: Agent Starting Run: jjypi8q6 with config:
wandb: 	actor_learning_rate: 0.0002616390874861137
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7351621680083273
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7173439501826101
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_160953-jjypi8q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jjypi8q6
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇██▇▇▆▆▆▆▆▆▅▅▆▄▅▅▅▅▄▅▅▅▅▄▄▄▄▃▄▄▄▄▃▂▁▁▁▁
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▃▆▄▇▇▂▆▃▁▄▃▄▆▅██▃▆▃▇▄▆▄▅▄▅▆█▆▇▆▅▁▃▃▃▄█
wandb:      train/ensemble_f1 ▆▅█▅▂▁▄▄▄▁▃▃▂▇▄▆▄▅▆▆▇▅▃▆▇▆▄▆▃▆▆▅█▆▁▂▂▄▄█
wandb:         train/mil_loss ▄▂▁▄▇▆▂▄▄▇▅▆█▃▄▂▅▅▅▆▁▄▄▃▁▁▅▅▂▄▂▃▆▆▅▄▆▅▄▆
wandb:      train/policy_loss ▆▃▁▄▃▄▆▃▅▆▁▃▄▄▃█▃▄▄▄▆▁▄▃▃▆▁▄▁▄▃▃▃▁▃▄▄▄▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▁▃▄▄▄▄▃▁▁▁▃▄▃█▃▄▁▁▄▆▄▄▃▃▃▆▃▅▆▆▅▄▄▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 0.89547
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.8984
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.75686
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.5137
wandb:      train/ensemble_f1 0.5137
wandb:         train/mil_loss 0.5759
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jjypi8q6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_160953-jjypi8q6/logs
wandb: Agent Starting Run: 7n8jmb2j with config:
wandb: 	actor_learning_rate: 0.00031200091210099206
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0876204520875844
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6069371979239722
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161106-7n8jmb2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ciwdkp3z
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7n8jmb2j
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▄▁▃▅▆▆▃▁▄▅▄▄▃▁▄▇▄▂█▂▄▁▆▃▃▃▂▂▆▄▅▂▁▇▆▁▆
wandb:      train/ensemble_f1 ▄▄▃▄▄▄▆▅▄▄▃▄▇▄▃▄▄█▃▄▆▇▁▃▄▃▂▆▂▁▃▄▃▆▄▅▂▃▁▂
wandb:         train/mil_loss ▆▄▄▂▃▄▇▂▅▁▇▆▇▆▇▂▆▆▆█▄█▄▂█▅█▅▇▆█▆▄▇▂▅▅▅▇▄
wandb:      train/policy_loss ▄▅▅▁▅▄▁▁▁█▁▅▄█▄▅▁▁▁▁▁▁▅▅▄█▅▁▁▁▁▁█▅▁▁▄▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▅█▁▁▅▅█▅▅█▁▁▁▁▁▁▁▁▁▁▄▁▁▅▁▁▁▅▁▁▁█▅▄▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.0682
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.04091
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.85447
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.3866
wandb:      train/ensemble_f1 0.3866
wandb:         train/mil_loss 0.91113
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run azure-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7n8jmb2j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161106-7n8jmb2j/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: my68hjhl with config:
wandb: 	actor_learning_rate: 0.0003948117109367525
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4305814329207299
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5583463052467716
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161243-my68hjhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/my68hjhl
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 83-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▃▂▅▆▄▆▆▃▄▆▆█▅▆▄▁▄▅▄▄▃▅▃▁▆▄▅▇█▂▅▂▆▂▁▁▁▅
wandb:      train/ensemble_f1 ▇▄▁▂▂▆▅▆▆▃▄▆▅▅▃▇▅▇▄▆▇▃▃▁▇█▆▆▇▂█▃▁▄▁▆▄▄▅▅
wandb:         train/mil_loss ▅▇▆▁▃▇▃▃▂▁▄▆▅▄▄▅▆▅▄▅▄▅▇▇█▃▇▅▆▅▅▅▁▆▄▃▆▄▅█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.15108
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.10979
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.97352
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.335
wandb:      train/ensemble_f1 0.335
wandb:         train/mil_loss 0.97814
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/my68hjhl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161243-my68hjhl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jjpjguc5 with config:
wandb: 	actor_learning_rate: 0.0005871972787221958
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6727887138629842
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11443273541306263
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161411-jjpjguc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jjpjguc5
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄█▅▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▃▄▄▅███████████████████████████▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 █▅▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▅▂▂▁▂▂▁▂▁▂▂▁▂▂▂▁▂▁▂▁▂▂▂▃▂▂▂▃▂▁▂▂▂▃▂▂▁▂
wandb:      train/ensemble_f1 █▄▂▂▂▁▂▁▂▁▂▁▂▂▃▁▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▂
wandb:         train/mil_loss ▄▃▃▄▃▆▄▄▇▅▅▃▄▃▄▅▃▄▇▁▅▄▄▁▂█▁▄▃▃▂▇▂▄▄▄▄▅▇▄
wandb:      train/policy_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▇▁▂▄▂▄▄▅▇▄▁▅▄▂▂▄▁▁▅▁▄▄▂█▅▇▃▆▃▂▂▆▄▄▅▅▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64349
wandb: best/eval_avg_mil_loss 0.60684
wandb:  best/eval_ensemble_f1 0.64349
wandb:            eval/avg_f1 0.36
wandb:      eval/avg_mil_loss 0.81874
wandb:       eval/ensemble_f1 0.36
wandb:            test/avg_f1 0.65107
wandb:      test/avg_mil_loss 0.66197
wandb:       test/ensemble_f1 0.65107
wandb:           train/avg_f1 0.41345
wandb:      train/ensemble_f1 0.41345
wandb:         train/mil_loss 0.58964
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jjpjguc5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161411-jjpjguc5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k4q17yvu with config:
wandb: 	actor_learning_rate: 0.000665024864309551
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6326789314666375
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.14333221490903203
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161559-k4q17yvu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k4q17yvu
wandb: uploading history steps 110-119, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▄▄▄▄▄▄▄▄▄██▆▆▃▃▆▆▆▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▁▁▃▃▃▁▁
wandb:      eval/avg_mil_loss █████▁▁▂▁█▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ▄▄▄▄▄████▆▃▆▆▃▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▁▃▃▃▃▃▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▃█▆▆▆▅▇▂▇▃▁▄▅▄▄▃▄▃▁▃▅▂▅▅▃▂▄▄▇▂▂▅▂▄▃▂▃▂
wandb:      train/ensemble_f1 ▆▆▇▃▇▇▅█▆▆▆▆▃▄▆▃▄▃▄▄▄▂▃▁▄▄▂▃▆▂▄▅▄▃▄▃▅▃▅▃
wandb:         train/mil_loss ███▃▂▂▃▁▂▅▄▆▄▅▃▄▆▅▅▆▄▄▂▄▃█▆▅▄▁▅▆▄█▂▄▄▁▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▅▁▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77965
wandb: best/eval_avg_mil_loss 0.60396
wandb:  best/eval_ensemble_f1 0.77965
wandb:            eval/avg_f1 0.74796
wandb:      eval/avg_mil_loss 0.60706
wandb:       eval/ensemble_f1 0.74796
wandb:            test/avg_f1 0.65503
wandb:      test/avg_mil_loss 0.8163
wandb:       test/ensemble_f1 0.65503
wandb:           train/avg_f1 0.65946
wandb:      train/ensemble_f1 0.65946
wandb:         train/mil_loss 0.60832
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k4q17yvu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161559-k4q17yvu/logs
wandb: Agent Starting Run: mme99ksz with config:
wandb: 	actor_learning_rate: 0.0013633445706615504
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5353129529683516
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.040661424251219214
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161727-mme99ksz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mme99ksz
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▅▃▅▇▅▅▅▄▅▃▅▄▂▅▄█▄▃▂▅▃▄▄▃▇▅▃▁▄▄▁▆▄▂▆▄▄
wandb:      train/ensemble_f1 ▇▅▄▃▆▅▅▁▇▅▅▃▅▄▁▂▄▂▂▂▁█▅▅▃▄▅▂▄▂█▄▃▃▇▆▅▂▃▄
wandb:         train/mil_loss ▇▅▃▄▃▃▆▄▃▅▂▃▄▄▄▅▅▃▄▅▃▄▃█▃▅▅▄▁▃▃▁▄▃▃▃▁▆▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01846
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99064
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.19522
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34048
wandb:      train/ensemble_f1 0.34048
wandb:         train/mil_loss 0.82922
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glorious-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mme99ksz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161727-mme99ksz/logs
wandb: Agent Starting Run: 70y6zvi8 with config:
wandb: 	actor_learning_rate: 0.002610804884978825
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7670678238205656
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15430091005342506
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_161845-70y6zvi8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/70y6zvi8
wandb: uploading history steps 131-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅█████████████████████████████
wandb:      eval/avg_mil_loss ████████▇▅▅▆▆▆▆▆▅▅▅▅▅▅▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▅▅▅██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▂▄▃▅▃▄▂▆▅▄▇▅▃▄▆▃▄▄▆▃▅▅▅▂▂▃█▁▅▄▃▃▅▄▅▄▅
wandb:      train/ensemble_f1 ▆▃▃▁▃▅▇█▆▄▃▅▇▅▄▇▅▅▆▆█▄▄▅▅▅▃▇▆▄▃▄▃▅▆▅▅█▄▅
wandb:         train/mil_loss █▆▅▆▇▅▄▄█▄▆▆▃▆█▄▅▄▇▆▆█▄▃▇▁▁▄▆▇▆▄▅▅▇▅▄▇▄▆
wandb:      train/policy_loss ▇▇▇▇▇▃█▇▅▁▄▅▄▇▃▇▅▃▅▁▁▃▃▁▃▃▃▄▃▂▅▁▇▃▃▃▃▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▇▇▇▄▃▃█▁▄▅▃▃▇▁▅▃▅▃▅▄▁▃▃▃▄▂▅▁▅▃▅▅▃▁▁▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79475
wandb: best/eval_avg_mil_loss 0.47273
wandb:  best/eval_ensemble_f1 0.79475
wandb:            eval/avg_f1 0.79475
wandb:      eval/avg_mil_loss 0.4628
wandb:       eval/ensemble_f1 0.79475
wandb:            test/avg_f1 0.83405
wandb:      test/avg_mil_loss 0.39842
wandb:       test/ensemble_f1 0.83405
wandb:           train/avg_f1 0.75745
wandb:      train/ensemble_f1 0.75745
wandb:         train/mil_loss 0.54617
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/70y6zvi8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_161845-70y6zvi8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 03smy794 with config:
wandb: 	actor_learning_rate: 0.008642958557404774
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8144858497239406
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.24161398088413932
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162101-03smy794
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03smy794
wandb: uploading wandb-summary.json
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▂▂▂▂▂▂▁▁▁▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 █████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▃▆▃█▄▇▄▆▁▃▅▂▂▂▆▇▅▆▂▆▅▂▄█▆▃▆▄▅▄▁▅▃▃▄▅▆▄
wandb:      train/ensemble_f1 ▅▄▃▃▃▃▆▅▃▅▅▃▂▂▇▄▄▂▆▃▅▁▅▅▅▄▄▄▃▅▂▄▃█▃▆▅▄▄▆
wandb:         train/mil_loss ▅▆▃▁█▂▆▁▂▁▇▅▁▂▂▆▆▄▄▄▁▄▂▃▅▅▇▁▁▆▄▁▃▆▅▅▆▃▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50249
wandb: best/eval_avg_mil_loss 1.20942
wandb:  best/eval_ensemble_f1 0.50249
wandb:            eval/avg_f1 0.49501
wandb:      eval/avg_mil_loss 1.17868
wandb:       eval/ensemble_f1 0.49501
wandb:            test/avg_f1 0.4294
wandb:      test/avg_mil_loss 1.60261
wandb:       test/ensemble_f1 0.4294
wandb:           train/avg_f1 0.4958
wandb:      train/ensemble_f1 0.4958
wandb:         train/mil_loss 0.82041
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03smy794
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162101-03smy794/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3rt06g0s with config:
wandb: 	actor_learning_rate: 0.0017651174030763844
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7032528608247701
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19012825395561272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162229-3rt06g0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3rt06g0s
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇█▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▆▁▄▆▄▃▄█▂▄▄▃▆▆▃▃▆▅█▄▅▇▄▄▂▇▂▃▆▃▄▇▅▄▃▇▅▅
wandb:      train/ensemble_f1 ▃▅▁▄▆▆▆▁▂▄▄▄█▃▆▄▆▅▅▅▅▅▂▅▂▃█▃▄▅▅▅▃▆▅▇▅▃▂▇
wandb:         train/mil_loss ▇▄▄▄▇▄▁▃▃▃▄▄█▃▄▂▂▃▃▄▄▂▄▁▆▂▃▆▂▂▆▄▂▄▄▄▃▅▄▅
wandb:      train/policy_loss ▅▄▅▄▇▂▂▂▄▂▅▂▆▅▂▅▅▅▂▄▂▂▅▄▅▂▆▁▇▄▄▅▃▁▃▆▅▂█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▃▃▄▃▁▃▆▆▃▁▃▁█▆▃▃▅▁▄▆▆▆▅▁▅▄▁▄█▃▁▁▃▃▄▃▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 0.60589
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 0.5918
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.56573
wandb:      test/avg_mil_loss 0.51241
wandb:       test/ensemble_f1 0.56573
wandb:           train/avg_f1 0.62321
wandb:      train/ensemble_f1 0.62321
wandb:         train/mil_loss 0.52162
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run decent-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3rt06g0s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162229-3rt06g0s/logs
wandb: Agent Starting Run: 1zo2teyc with config:
wandb: 	actor_learning_rate: 0.0020129056154069925
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8836012493376142
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1314021466996349
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162347-1zo2teyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zo2teyc
wandb: uploading history steps 218-225, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:      eval/avg_mil_loss █████▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆█████▆▆▆▆▆▆▆▆▆▆▆▆▆▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▄▇▄▅▄▇▅▅▄▇▆██▆▆▅▆▃▆▅▂▃▃▅▅▁▇█▆▇▅▆▆▄▄▄▅▆
wandb:      train/ensemble_f1 ▅▃▅▅▇▆▂▅▆▄▇▆▇▄▅▄▅▅█▆█▅▄▄▆▅▅▁▆▅▇▃▄▄▆▅▄▃▅▃
wandb:         train/mil_loss ▇▃▆▃▂▅▂▆▄▁▄▂▆▂█▅█▄▂▅▃▅▃▃▅▆▄▁▅▃▅▄▇▄▄▆▂▄▆▇
wandb:      train/policy_loss ███████████████████████████▁████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.39117
wandb: best/eval_avg_mil_loss 0.8889
wandb:  best/eval_ensemble_f1 0.39117
wandb:            eval/avg_f1 0.37996
wandb:      eval/avg_mil_loss 0.87692
wandb:       eval/ensemble_f1 0.37996
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 1.00374
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.4263
wandb:      train/ensemble_f1 0.4263
wandb:         train/mil_loss 0.66076
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1zo2teyc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162347-1zo2teyc/logs
wandb: Agent Starting Run: g0p7akei with config:
wandb: 	actor_learning_rate: 0.004361891930065568
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7657976750394248
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.003643952225923952
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162626-g0p7akei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0p7akei
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▄▃▃▃▃▁▁▆▆▆▅▅▄▄▄▄▄▄▄███▇▇▇▆▆▆▆▆▆▆▅▆▅▄▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▅▇▂▅█▅▇▄▃▄▅▄▁▁▄▄▅▄▄▄▃▇▄▄▅▇▆▃▄▄▅▆▃▅▅▆▅▅
wandb:      train/ensemble_f1 ▄▅▄▄▅▂▂▅▄█▆▄▄▃▁▁▄▃▄▆▅▃▅▃▃▄█▄▅▇▃▄▄▅▅▁▇▅▅▄
wandb:         train/mil_loss ▃▄▃█▁▄▅▆▄▄▅▃▃▂▄▄▃▄▄▇▂▅▂▅▂▃▆▇▄▅▄▃▄▃▆▃▂▆▃▅
wandb:      train/policy_loss ▃▆▆▇▆█▁▅▃▁▁▃▃▃█▆▆█▆▃▁▅▁▆▃▃██▆█▆▆██▃█▃▆▆█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▆▇▄▄▇██▅▄▆▂▂▄▄▃▁▂▂▂▂▃▄▆█▄██▆▆▂█▆▂▃█▄██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83942
wandb: best/eval_avg_mil_loss 0.40326
wandb:  best/eval_ensemble_f1 0.83942
wandb:            eval/avg_f1 0.83942
wandb:      eval/avg_mil_loss 0.40319
wandb:       eval/ensemble_f1 0.83942
wandb:            test/avg_f1 0.89583
wandb:      test/avg_mil_loss 0.42084
wandb:       test/ensemble_f1 0.89583
wandb:           train/avg_f1 0.8221
wandb:      train/ensemble_f1 0.8221
wandb:         train/mil_loss 0.55067
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sandy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g0p7akei
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162626-g0p7akei/logs
wandb: Agent Starting Run: 5igehypk with config:
wandb: 	actor_learning_rate: 0.008679198970272212
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6716784121336477
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05212794416319033
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162744-5igehypk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5igehypk
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▇▁▆▆▆▅▃▅▃▄▇▂▇▄▆▄▅▁▄▅▇▆▅█▃▅▄▇▂▄█▅▆▃▆▁▂▇
wandb:      train/ensemble_f1 █▄▃▂▅█▄▅▃▄▅▅▃▄▂▇▄▆▁▅▅▇█▇▄▄▇▅▂▅█▅▅▆▇▂▃▇▅▃
wandb:         train/mil_loss ▅▄▅▃▄▄▃▂▄▄▄▄▄▄▁▅▂▄▄▄▅▆▅▂▁▁▄▅▁▇▄█▃▄▃▂▇▄▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.11817
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.08146
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.98029
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32886
wandb:      train/ensemble_f1 0.32886
wandb:         train/mil_loss 0.55165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run playful-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5igehypk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162744-5igehypk/logs
wandb: Agent Starting Run: g3f1vrq3 with config:
wandb: 	actor_learning_rate: 0.001616318062774078
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7607615098855914
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.011991726278319017
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_162901-g3f1vrq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3f1vrq3
wandb: uploading wandb-summary.json
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▂▅▃▆▅▃▄▄▁▄▂▆▄▄▄▅▄▂▂▂▃▁▂▅▂▄▄▄▂▃█▅▃▃▇▂▇▄
wandb:      train/ensemble_f1 ▃▅▃▅▇▄▁▅▅▂▁▄▃█▂▃▂▄▅▅▆▁▅▂▃▄▂▄▅▅▄▃▃▅▄▇▃▂▇▅
wandb:         train/mil_loss ▁▃▅▃█▆▄▃▄▇▅▄▄▇▅▅▅▆▄▃▇▃▄█▂▃▄▆▅▃▃▄▃▃▄▃▃█▄▃
wandb:      train/policy_loss ▁▅▅▄▁▅▅▇▄██▁▇▄▄▁▄▄▄▇▇▇▇▄▁▇▂▄▄▄█▄▄▄▁▇█▄▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▃▃██▁▆▃█▁▄▆▃▃▃▃▄▃▃▆▆▆▆▆▃▆▃▆▁▃▆▃▆▃▄▁▂▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56363
wandb: best/eval_avg_mil_loss 0.85343
wandb:  best/eval_ensemble_f1 0.56363
wandb:            eval/avg_f1 0.56363
wandb:      eval/avg_mil_loss 0.84786
wandb:       eval/ensemble_f1 0.56363
wandb:            test/avg_f1 0.54955
wandb:      test/avg_mil_loss 0.98905
wandb:       test/ensemble_f1 0.54955
wandb:           train/avg_f1 0.57699
wandb:      train/ensemble_f1 0.57699
wandb:         train/mil_loss 0.62293
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g3f1vrq3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_162901-g3f1vrq3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zgf63ut6 with config:
wandb: 	actor_learning_rate: 0.0040867879199355
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8359436097289522
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.041148105376642374
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163045-zgf63ut6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zgf63ut6
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▄▃▇▃▆▄▂▅▂▄▄▄▅██▄▃▃▁▆▅▄▅▃▅▆▇▄▆▆▅▆▆█▇▅▄
wandb:      train/ensemble_f1 █▂▃▂▇▄▆▂▃▃▃▃▄▄▄▃▃▃▄▁▂▃▆▄▂▄█▁▃▅█▅▅▂▂▆▂▅▄▃
wandb:         train/mil_loss ▄▂▃▆▂█▄▆▄▂▆▅▂▂▄▄▇▃▅▃▃▃▅▂▃▂▃▁▃▂▁▇▃▄▅▅▅▃▄▂
wandb:      train/policy_loss ▁▃▁▁█▁▆▁▆▃▁▁▆▁█▃▁▃▃▆▁▆▃▃▃▃▁▂▁▃▃█▃▃▃▃▁▆▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃█▆▃▃▆▁▃▆▆▆▁█▃▁▁▃▁▆▁▆▃▃▃▁▂▁▂▃▁▂█▃▆▄▆▆▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40476
wandb: best/eval_avg_mil_loss 0.75618
wandb:  best/eval_ensemble_f1 0.40476
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.74435
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.44086
wandb:      test/avg_mil_loss 0.61726
wandb:       test/ensemble_f1 0.44086
wandb:           train/avg_f1 0.47656
wandb:      train/ensemble_f1 0.47656
wandb:         train/mil_loss 0.5923
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zgf63ut6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163045-zgf63ut6/logs
wandb: Agent Starting Run: 52ajfagi with config:
wandb: 	actor_learning_rate: 0.0009395541929329724
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7812409166704829
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2944580964196346
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163159-52ajfagi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/52ajfagi
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████▅▅▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆█▆▆▆▇█▇▇▇▇▇▆▆▆▆▄▄▄▄▁
wandb:       eval/ensemble_f1 ███████████████████▆▅▅▅▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▅▅▁▄▃▄▃▅▂▄▄▃▄▅▅▅▄▅▄▃▄▄▃▃▁▅▃▄▂▂▆▆▄▃▅▂▂▃▅
wandb:      train/ensemble_f1 ▆▄▅▇▇▆▆▄▅▄▂▄▅▂▆▅▅▅▅▂▅▇▅▃▂▁▆▃▂█▇▅▂▃▃▇▂▂▃▃
wandb:         train/mil_loss ▁▄▂▄▄▃▇▃▂▄▃▄▅▂▄▂▄▂▄▅▆▁▄▃▃▄▁▃▆▆▆▁▅▄█▄▃▄▄▁
wandb:      train/policy_loss ▇▅██▆▅█▃▇█▆▅▇▅▇▄▇▇▄▄▇█▄▁▄▅▄▄▂▄▁▄▂▅▇▇▇▇▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▅█▅▅█▃█▇█▆▅▆▆▆▄▃▇▄▇▇█▄▁▄▃▃▃▂▄▂▇▄▇▇▄█▅▂▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.44853
wandb: best/eval_avg_mil_loss 0.76292
wandb:  best/eval_ensemble_f1 0.44853
wandb:            eval/avg_f1 0.43464
wandb:      eval/avg_mil_loss 0.75475
wandb:       eval/ensemble_f1 0.43464
wandb:            test/avg_f1 0.51433
wandb:      test/avg_mil_loss 0.63075
wandb:       test/ensemble_f1 0.51433
wandb:           train/avg_f1 0.51551
wandb:      train/ensemble_f1 0.51551
wandb:         train/mil_loss 0.59281
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/52ajfagi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163159-52ajfagi/logs
wandb: Agent Starting Run: 9mqo78r7 with config:
wandb: 	actor_learning_rate: 0.0023758793276647035
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9455555751522547
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42650183420115406
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163317-9mqo78r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mqo78r7
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▅▄▆▄▇▅▃▃▄▃▁▄▄▅▅▂▄▅▄▄▆▇▅▂▄▆▄▃▃▅▅▃▅▁▆▆█
wandb:      train/ensemble_f1 ▃▇▅▄▄▆▃▇▅▃▄▃▆▄▂▄▃▃▅▂▂█▅▄▂▅▅▄▄▄▆▇▃▅▅▃▄▄▆▁
wandb:         train/mil_loss ▂▃▃▂▆▂▂▁▃▅▁▂▃▂▂▅█▂▄▂▂▄▄▃▂▄▆▃▄▂▃▂▄▆▃▃▃▃▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.83006
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.81874
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.4423
wandb:      test/avg_mil_loss 1.22272
wandb:       test/ensemble_f1 0.4423
wandb:           train/avg_f1 0.49091
wandb:      train/ensemble_f1 0.49091
wandb:         train/mil_loss 0.62571
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9mqo78r7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163317-9mqo78r7/logs
wandb: Agent Starting Run: dxwdfmyx with config:
wandb: 	actor_learning_rate: 0.00039083529723102985
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9867411553733788
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3871913068878705
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163434-dxwdfmyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxwdfmyx
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▆▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▂▆█▅▄▅▃▃▆▅▅▇▄▅▃▇▆▅▄▅▆▆▅▂▃▄▇█▅▃▄▃▁▆▄▄▅
wandb:      train/ensemble_f1 ▂▆▄▅▄▅▃▄▅▄▂▃▅█▆▆▅▇▃▅▁▇▅▇▅▃▄█▃▅▆▆▆▃▃▂▇▅▅▃
wandb:         train/mil_loss ▂▁▄▂▂▂▂▅▃▂▃▄▂█▂▂▃▂▃▄▃▃▃▄▃▃▄▁▂▅▃▂▄▂▃▃▂▃▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████▆████████▆███▆██████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████▆███▆███████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.35031
wandb: best/eval_avg_mil_loss 0.82468
wandb:  best/eval_ensemble_f1 0.35031
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.8149
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.28571
wandb:      test/avg_mil_loss 1.20037
wandb:       test/ensemble_f1 0.28571
wandb:           train/avg_f1 0.39224
wandb:      train/ensemble_f1 0.39224
wandb:         train/mil_loss 0.56533
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dxwdfmyx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163434-dxwdfmyx/logs
wandb: Agent Starting Run: 176ds62w with config:
wandb: 	actor_learning_rate: 0.00025146863278475317
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09745571699885758
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9085858170631184
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163552-176ds62w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/176ds62w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▆▇▆▆▂▆▅▅▆▁▂▅▂▆▂▃▇▄▆▇▂▅▆▅█▅▇▆▆▅▅▃▅▅▄▅▂▄
wandb:      train/ensemble_f1 ▆▇▂▄▆▅▃▅▃▅█▆▄▁▄▆▆▆▄▄▇▆▅▄▅▇▅▃▆▅▄▅▆▇▄▅▄▅▁▄
wandb:         train/mil_loss ▁▅▃▇▃▇▇▅▅▅▇▃▇▆▅▅▆██▅▅▆▇▆▆▇▄▅▅▄▇▇▅▅▂▅▅▂▁▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.52916
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.46512
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.25055
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 2.79334
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run confused-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/176ds62w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163552-176ds62w/logs
wandb: Agent Starting Run: 0cf9hftv with config:
wandb: 	actor_learning_rate: 0.001014666690731854
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9956907049469792
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6798957851264033
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_163710-0cf9hftv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0cf9hftv
wandb: uploading history steps 259-269, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████████
wandb:      eval/avg_mil_loss ██▅▅▅▅▅▅▅▃▃▃▃▄▃▃▄▃▃▃▃▃▃▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▅▅▇▅▃▆▅▆█▅▆▆▃▅▃▅▅▄▅▄▄▄▁▇▇▆▇▄▅▆▄▄▆▄▆▄▆
wandb:      train/ensemble_f1 ▄▅▅▂▄▃▆▃▅▄▄▃█▆▅▆▅▇▃▅▅▅▅▅▆▄▃▁▆▅▄▃▂▃▄▆▆▄▆▆
wandb:         train/mil_loss ▃▅▄▃▆▃▃▄▄▃▅▆▃▂▃▄▃▄▄▄▂▅█▁▃▃▅▆▃▂▃▄▃▅▁▅▂▄▃▄
wandb:      train/policy_loss ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.67052
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.67065
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.66875
wandb:      test/avg_mil_loss 0.48749
wandb:       test/ensemble_f1 0.66875
wandb:           train/avg_f1 0.64155
wandb:      train/ensemble_f1 0.64155
wandb:         train/mil_loss 0.56985
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0cf9hftv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_163710-0cf9hftv/logs
wandb: Agent Starting Run: orwl71ta with config:
wandb: 	actor_learning_rate: 0.005243449305480859
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9430793043178216
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7504485489869671
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164021-orwl71ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orwl71ta
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇███▇█▇▅▅▅▅▄▄▄▄▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▄▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▃▄▄▅▆▅▁▆▄▅▃▇▃▄▅▅▄▄▇▇▄▅▄▅▄▇▃▅█▅▄▃▅▇▄▅▅▇
wandb:      train/ensemble_f1 ▆▂▃▄▅▄▄▄▅▄▁▂▅█▃▃▃▆▄▅▇▆▆▅▆▂▄▄▇▄▃▃▃▅▆▄▆▄▃▄
wandb:         train/mil_loss ▄▆▅▇█▁▇▅▆▅▄▄▅█▆█▆▄▅▄▄▄▅▄▅▄▆▅▆▆▅▅▃▅▅▅▄▆▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 0.65352
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.65313
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.58718
wandb:      test/avg_mil_loss 0.64355
wandb:       test/ensemble_f1 0.58718
wandb:           train/avg_f1 0.59292
wandb:      train/ensemble_f1 0.59292
wandb:         train/mil_loss 0.5316
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/orwl71ta
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164021-orwl71ta/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d6d35rx4 with config:
wandb: 	actor_learning_rate: 0.001270906026231369
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9444770321828522
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8539864654964833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164149-d6d35rx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6d35rx4
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▃▃▂▂▂▂▁▁▁▇▇▆▆▆▆▆█████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▂▃▃▆▅▅▃█▃▄▆▂▃▃▂▂▁▅▂▄▄▃▄▃▄▅▂▅▂▃▃▅▄▆▁▄▄
wandb:      train/ensemble_f1 ▂▆▅▄▇▃▆▄▆▆▃▄▃▂▄▁▂▃█▇▅▃▆▂▄▃▅▄▄▅▄▆▂▅▄▅▇▅▆▄
wandb:         train/mil_loss █▂▃▅▆▃▂▆▁▃▇▃▆▂▁▄▃▁▄▂▅▃▅█▄▂▁▃▇▅▆▅▂▆▂▅▅▂▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.86873
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.87279
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.47147
wandb:      test/avg_mil_loss 1.10567
wandb:       test/ensemble_f1 0.47147
wandb:           train/avg_f1 0.44241
wandb:      train/ensemble_f1 0.44241
wandb:         train/mil_loss 0.52872
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d6d35rx4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164149-d6d35rx4/logs
wandb: Agent Starting Run: 9a5uv45r with config:
wandb: 	actor_learning_rate: 0.00934768892296332
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9847271632765208
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.934878861169201
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164307-9a5uv45r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9a5uv45r
wandb: uploading history steps 109-123, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▁▁█
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▇▇▇███████▄▄▃▁▁▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▇█████████████████████████████▇
wandb:       eval/ensemble_f1 ▄▅▅▅▅▅▅▅█▁▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▂▃▄▃▆▃▆▇▅▇▅▆▆▆▅▆▅▄▅▆▅▄▅▆▄▇▆▆▄▆▇▃█▅▄▆▅
wandb:      train/ensemble_f1 ▅▄▃▁▁▄▃▇▃▃▄▅▅▅▆▇▅█▅▇▄▆▇▅▅█▄▆▆▅▇▇▂▄▅▃▄▇▆▇
wandb:         train/mil_loss ▂▃▃▂▃▂▃▃▃▄▂▂▂▃▂▃▂▁▄▁▂▂▄▃▃▂▁▃▂▂▂▄▁▄▃▂█▂▃▃
wandb:      train/policy_loss ▁▁▁██████████▁▁█████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68077
wandb: best/eval_avg_mil_loss 0.98161
wandb:  best/eval_ensemble_f1 0.68077
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 1.02039
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.61939
wandb:      test/avg_mil_loss 1.31852
wandb:       test/ensemble_f1 0.61939
wandb:           train/avg_f1 0.60586
wandb:      train/ensemble_f1 0.60586
wandb:         train/mil_loss 0.52832
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9a5uv45r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164307-9a5uv45r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q0wnprxm with config:
wandb: 	actor_learning_rate: 0.007803554715336179
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9978972007209518
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5348160646136256
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164445-q0wnprxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q0wnprxm
wandb: uploading history steps 130-133, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▇█
wandb: best/eval_avg_mil_loss ██▅▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▃▅▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▃▅▅█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▂▁▂▂▂▃▆▇▆▆▇▆▇▇▇▆▆▇▇▇▅▆▇▇█▇█▇▇▆█▇▇▇█▇▆
wandb:      train/ensemble_f1 ▁▂▂▁▄▆▄▄▆▆▆▇▆▇▇▇▇▆▇▇▆█▇█▇▆▆▇▇▇█▆▇▆▆▇▇▇▇█
wandb:         train/mil_loss ▃█▅▇▃▄▃▄▆▄▃▃▄▅▃▂▄▄▅▄▁▂▆▅▃▃▃▄▂▃▃▂▅▅▂▂▅▄▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▁▅▅██▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78829
wandb: best/eval_avg_mil_loss 0.58075
wandb:  best/eval_ensemble_f1 0.78829
wandb:            eval/avg_f1 0.77778
wandb:      eval/avg_mil_loss 0.58757
wandb:       eval/ensemble_f1 0.77778
wandb:            test/avg_f1 0.71062
wandb:      test/avg_mil_loss 0.88098
wandb:       test/ensemble_f1 0.71062
wandb:           train/avg_f1 0.70763
wandb:      train/ensemble_f1 0.70763
wandb:         train/mil_loss 0.50985
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q0wnprxm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164445-q0wnprxm/logs
wandb: Agent Starting Run: 4th79lqr with config:
wandb: 	actor_learning_rate: 0.009541706020708618
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8317938335207997
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6232238027582233
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164623-4th79lqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4th79lqr
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████████████████████████████▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▂▂▂▂▁
wandb:       eval/ensemble_f1 █████████████████████████████████████▂▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▂▄▄▅▄▃▆▃▅▄▅▄▅▄▆▆▂▄▅▆▃▇▆▆▇▆▇▄▆▇▇▄▅▄▁▇▃█
wandb:      train/ensemble_f1 ▇▁▄▅▁▃▃▅▂▆▄▃▅█▅▂▃▅▄▇▇▅▅▃▃█▃▆▃▇▅▄▅▂▃▄▄▂▄█
wandb:         train/mil_loss ▄▄▄▆▂▃▅▂▄█▅▄▄▆▄▅▆▃▁▂▅▁▂▂▅▆▁█▂▃▅▃▆▄▃▄▆▃▁▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▁▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▁▂▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38667
wandb: best/eval_avg_mil_loss 1.3254
wandb:  best/eval_ensemble_f1 0.38667
wandb:            eval/avg_f1 0.36
wandb:      eval/avg_mil_loss 1.29421
wandb:       eval/ensemble_f1 0.36
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.76616
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.39595
wandb:      train/ensemble_f1 0.39595
wandb:         train/mil_loss 0.58354
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4th79lqr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164623-4th79lqr/logs
wandb: Agent Starting Run: a7mybdni with config:
wandb: 	actor_learning_rate: 0.00013769912854981768
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9869262366406056
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8479811761153574
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164741-a7mybdni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a7mybdni
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁█████████████████████████████████████
wandb:      eval/avg_mil_loss ▁▁▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████████
wandb:       eval/ensemble_f1 ▁▁██████████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▁▃▇▂▃▃▆█▅▃▄▅▄▅▅▆▅▃▇▄▄▆▅▅▄▅▇▅▃█▆▇▃▅▃▄▄▅
wandb:      train/ensemble_f1 ▁▁▃▁▅▅▃█▅▂▆▅▅▆▄▆▆▆▆▄▄▅▅▇▆▄▅▇▇▄▅▄▅▅▃▅▅▃▆█
wandb:         train/mil_loss ▄▅▁█▄▄▄▃▃▄▃▇▃▆▆▃▄▄▂▅▄▄▇▃▁▆▅▆▄█▃▄▃▆▅▄▅▆▅▆
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁██████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.75
wandb: best/eval_avg_mil_loss 0.67436
wandb:  best/eval_ensemble_f1 0.75
wandb:            eval/avg_f1 0.75
wandb:      eval/avg_mil_loss 0.6823
wandb:       eval/ensemble_f1 0.75
wandb:            test/avg_f1 0.74724
wandb:      test/avg_mil_loss 0.65629
wandb:       test/ensemble_f1 0.74724
wandb:           train/avg_f1 0.75469
wandb:      train/ensemble_f1 0.75469
wandb:         train/mil_loss 0.54417
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fallen-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a7mybdni
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164741-a7mybdni/logs
wandb: Sweep Agent: Waiting for job.
wandb: ERROR Error while calling W&B API: Post "http://anaconda2.default.svc.cluster.local/search": read tcp 10.53.231.4:42486->10.55.247.53:80: read: connection reset by peer (<Response [500]>)
wandb: Job received.
wandb: Agent Starting Run: ospg1ond with config:
wandb: 	actor_learning_rate: 0.0030827234223712204
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9874723136028234
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6723580559429355
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_164917-ospg1ond
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ospg1ond
wandb: uploading history steps 151-164, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▅▅▅▅▅▅████▅▅▅▅██████▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆▇▇▇▇▇▇▇█▇▅▅▅▂▂▂▂▂▂▂▂▁▃▃▃▃▃▂▇▇▇▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██▅▅▅▅▅█████▅▅▅▅▅▅▅▅▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▇▆▄█▅▇▇▃▄▂█▃▅▄▁▇▅▂▃▄▅▇▆▂▅▆▂▃█▄▃▄▃▃▅▇▅
wandb:      train/ensemble_f1 ▂▇▅█▅▅▄█▆▄▄▅▃▃▆▆█▆▆▅▄▆▅▄█▇▄▆▂▃▃▄█▄▃▁▅▄▄▅
wandb:         train/mil_loss ▁▃▃▃▁▅▂▅▃▃▆▄▅▅▂▄▄▅▁▂▇▅▄▄▂▂█▄▅▄▆▄▃▃▄▄▆▂▅▄
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▆▆▆█▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃█▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58897
wandb: best/eval_avg_mil_loss 0.69574
wandb:  best/eval_ensemble_f1 0.58897
wandb:            eval/avg_f1 0.56892
wandb:      eval/avg_mil_loss 0.69565
wandb:       eval/ensemble_f1 0.56892
wandb:            test/avg_f1 0.63689
wandb:      test/avg_mil_loss 0.67356
wandb:       test/ensemble_f1 0.63689
wandb:           train/avg_f1 0.57584
wandb:      train/ensemble_f1 0.57584
wandb:         train/mil_loss 0.54449
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ospg1ond
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_164917-ospg1ond/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cdvcnz8t with config:
wandb: 	actor_learning_rate: 0.00023721532537680616
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9784892270958552
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6519264987117795
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165124-cdvcnz8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdvcnz8t
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▅▄▃▃█▅▃▅▄█▃▄▄▅▁▄▃▄▅▅▄▅▂▅▄▆▂▃▂▁▃▄▂▇▃▆▄▅
wandb:      train/ensemble_f1 ▃▄▆▄▅▆▂▄▅▄▃▆▃▄▄▅▅▂▅▅▅█▅▅▃▃▅▃▅▃▇▃▆▄▆▆▃▄▅▁
wandb:         train/mil_loss ▃▅▄▁▄▃▅▇▇▄▃▄▆▂▄▅▄▅▃▆▂▅▅▁▅▄▂▃▄▃▁▄█▄▅▆▅▃▄▃
wandb:      train/policy_loss ████████▁███████▁██▁███▁█████▁█████▁████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁██████▆█████████▁████████▁████████▁█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.45907
wandb: best/eval_avg_mil_loss 0.80037
wandb:  best/eval_ensemble_f1 0.45907
wandb:            eval/avg_f1 0.45907
wandb:      eval/avg_mil_loss 0.79222
wandb:       eval/ensemble_f1 0.45907
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.66213
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.46492
wandb:      train/ensemble_f1 0.46492
wandb:         train/mil_loss 0.569
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cdvcnz8t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165124-cdvcnz8t/logs
wandb: Agent Starting Run: d34pkypm with config:
wandb: 	actor_learning_rate: 2.663913642280942e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.940134519549422
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8288812926335759
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165242-d34pkypm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d34pkypm
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇
wandb:      eval/avg_mil_loss ▁▃▃▃▄▃▃▃▄▄▅▅▅▅▆▇▇▇▇▇▇▇▇▇▆██▇▇▇▇▇▇▆▆▆▇▆▆▇
wandb:       eval/ensemble_f1 ██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▇▅▄▃▆▄▃▄▇▆▅▅▅▆▆▂▂▂▂█▄▁▄▆▃▆▇▄▆▆▄▆▅▇▆▄▄▄
wandb:      train/ensemble_f1 ▅▃▂▅▄▂▆▃█▃▅▆▄▄▂▄▄▆▆▃▃▇▅▅▂▁▆▆▄▇▆▅▃▃▇▆▇▅▆▄
wandb:         train/mil_loss ▇▃▄▄▁▅▆▃▅▅▃▂▃▃▆▅▄▅▅▃▃▄▅▃▄▃▃▆▂▃▂▄▃▆▅█▄▄▄▃
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77858
wandb: best/eval_avg_mil_loss 0.64682
wandb:  best/eval_ensemble_f1 0.77858
wandb:            eval/avg_f1 0.77778
wandb:      eval/avg_mil_loss 0.64703
wandb:       eval/ensemble_f1 0.77778
wandb:            test/avg_f1 0.72536
wandb:      test/avg_mil_loss 0.75012
wandb:       test/ensemble_f1 0.72536
wandb:           train/avg_f1 0.71151
wandb:      train/ensemble_f1 0.71151
wandb:         train/mil_loss 0.54573
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misty-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d34pkypm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165242-d34pkypm/logs
wandb: Agent Starting Run: 4cg0wdaz with config:
wandb: 	actor_learning_rate: 3.859071100911346e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9955803408202508
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6133872418172267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165359-4cg0wdaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cg0wdaz
wandb: uploading history steps 173-194, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▂▄▃▄▅▇▆▂▄▆▃▆▆▃▇▅▇▄▅▆▅▄▄▄▃▆▆▃▇▃▆▅▃▅█▇▁█
wandb:      train/ensemble_f1 ▂▄▃▄▃▃▇▃▆▃█▄▁▄▅▄▅▅▅▄▆▄▇▅▃▇▃▅▂▁▄▁▂▅▅▁▆█▂▂
wandb:         train/mil_loss ▃▄▂▇▂▄▂▃▃▂▃▃▃▂▁▂▂▂▂▂▁▁▃▂▂▃▂▂▁▃▂▂▄▂█▂▂▂▁▃
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42827
wandb: best/eval_avg_mil_loss 1.44584
wandb:  best/eval_ensemble_f1 0.42827
wandb:            eval/avg_f1 0.42827
wandb:      eval/avg_mil_loss 1.43074
wandb:       eval/ensemble_f1 0.42827
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 1.9668
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.37271
wandb:      train/ensemble_f1 0.37271
wandb:         train/mil_loss 0.55142
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4cg0wdaz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165359-4cg0wdaz/logs
wandb: Agent Starting Run: he6c0e6j with config:
wandb: 	actor_learning_rate: 4.4916989411668685e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.955864851129828
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9946058625551438
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165619-he6c0e6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/he6c0e6j
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅█▇▃▅▆▇▇▇▇█▄▆▆▄▇▆▇▁▆▆▆▆▇▆▆▇▄▆▄▇▄▄█▆▆▆▅▄
wandb:      train/ensemble_f1 ▅▅█▇▄█▇▇▇▅▄▆▆▆▇▆█▆▇▁▇▆▆▆▆▅▇▇█▅▆▄▅▇▇▇▆▆▅▅
wandb:         train/mil_loss ▅█▃▂▂▂▂▁▂▃▇▂▅▂▇▂▁▆▅▇▁▂▂▂▂▁▂▂▅▂▂▇▆▂▂▂▂▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.19873
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.17926
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.74048
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32203
wandb:      train/ensemble_f1 0.32203
wandb:         train/mil_loss 0.52812
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/he6c0e6j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165619-he6c0e6j/logs
wandb: Agent Starting Run: yp9vhilc with config:
wandb: 	actor_learning_rate: 1.5509170286157872e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.34619286983340747
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.05712646965797896
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_165736-yp9vhilc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yp9vhilc
wandb: uploading history steps 196-201, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████
wandb:       eval/ensemble_f1 ▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▄▄▄▆▂▅▆▆▃▃▇▄▅▄▄▆▆▅▇▂▆▁▆▄█▆█▃▅▆▅▃▇▄▄▃▄▄
wandb:      train/ensemble_f1 ▆▄▃▃▃▅▅▃▃▃▃▂▆▂▁▂▄▅▄▄▇▄▃▆▃▁▄▃▄█▂▇▂▄▅▃▂▅▂▁
wandb:         train/mil_loss ▃▅▃▁▃▆▇█▆▃▄▄▆▄▃▂▅▅▂▃▆▅▃▄▆▆▄▅▆▅▅▇▅▅▆▇█▄▆▆
wandb:      train/policy_loss ▅▅▅▆▅▅▆▅▅▇▅█▅▅▅▅▄▅▆▇▁▂▂▃▅▄▃▂▅▅▄▁▃▂▆▂▄▄▄▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▇▅▆▇▆▇▇▆▇▆▇▇█▇▇██▅▂▆▂▁▃▄▅▃▂▆▁▁▄▄▂▄▁▁▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.84
wandb: best/eval_avg_mil_loss 0.4267
wandb:  best/eval_ensemble_f1 0.84
wandb:            eval/avg_f1 0.82
wandb:      eval/avg_mil_loss 0.46008
wandb:       eval/ensemble_f1 0.82
wandb:            test/avg_f1 0.81884
wandb:      test/avg_mil_loss 0.38236
wandb:       test/ensemble_f1 0.81884
wandb:           train/avg_f1 0.77283
wandb:      train/ensemble_f1 0.77283
wandb:         train/mil_loss 0.54252
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stellar-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yp9vhilc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_165736-yp9vhilc/logs
wandb: Agent Starting Run: 9snk347a with config:
wandb: 	actor_learning_rate: 0.0002826151186264575
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.48382078499605485
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.964954086172934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170001-9snk347a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9snk347a
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▅▆▃▆▆▅▁▃▆▅▇█▄▆▇▃▅▇▆▇▇▆▆▅▅▇▅▆▄▅▇▆▆▃█▆▃
wandb:      train/ensemble_f1 ▂▁▅▇▇▇▅█▄▆▄▅▇▆▆▆█▇█▁▅▃▇▅▇▅▂▄▆▇▃▃▃▅▇▅▆▃▃▂
wandb:         train/mil_loss ▄▅▅▃▅▄▄▄▅▄▆▆▂▃▃▄▆▅▆▅▄▄▂▄▅▃▃▄▃█▅▄▆▅▄▃▆▅▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.26251
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.21529
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.10306
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33054
wandb:      train/ensemble_f1 0.33054
wandb:         train/mil_loss 1.48088
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run robust-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9snk347a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170001-9snk347a/logs
wandb: Agent Starting Run: 21hf1el6 with config:
wandb: 	actor_learning_rate: 1.3106651595506145e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.44667754265593695
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.022253795910624596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170118-21hf1el6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/21hf1el6
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅▅▃▁▃▃▆▃▂▅▅▂▃▄▁▄▇▃▅▆▄▄▄▆▄▆▄▆▅▄▅▄▄█▅▄▃
wandb:      train/ensemble_f1 ▆▇▆▆▅▅▆█▇▆▆▁▅▆▆▆▄▅▆▄▆▇▆▆▅▇▆▅▄▇▇▅▅▅▆█▇▆▅▃
wandb:         train/mil_loss ▅▃▄▂▇▆▁▄▇▆▃▇▆▄▄▆▃▄█▆▅▄▇▃▇▇▅▅▁▄▇▂▅▅▅▆▄▆▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98703
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.98103
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.1525
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31448
wandb:      train/ensemble_f1 0.31448
wandb:         train/mil_loss 0.82081
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/21hf1el6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170118-21hf1el6/logs
wandb: Agent Starting Run: u7mbh70r with config:
wandb: 	actor_learning_rate: 1.4404602956520134e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.21144857913269732
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06989313427677724
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170236-u7mbh70r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7mbh70r
wandb: uploading history steps 176-182, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ████▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▆▄▆▄▄▅▅▆▄▃▄▅▄▃▅▅▅▄▃▄▃▅▅▅▄▅▄▄▃▅▅▃█▃▅▁▆▆
wandb:      train/ensemble_f1 ▂▂▁▂▂▇▄▂▅▃▅▆▆▅▄█▂▃▄▇▄▄▅▄▆▃▃▃▃▃▇▄▁█▆▄▄▆▅▂
wandb:         train/mil_loss ▄▆█▅▆▃▄▁▇▇▄▅▃▇▅▆▄▇▅▃▆▃▅▂▅▃▄▃▆▃▃▄▁▅▅▁▅▃▁▃
wandb:      train/policy_loss █▁▄▂▁▄▁▄▃▁▃▁▂▁▁▂▅▃▄▄▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46928
wandb: best/eval_avg_mil_loss 0.85391
wandb:  best/eval_ensemble_f1 0.46928
wandb:            eval/avg_f1 0.46237
wandb:      eval/avg_mil_loss 0.80736
wandb:       eval/ensemble_f1 0.46237
wandb:            test/avg_f1 0.37795
wandb:      test/avg_mil_loss 1.12475
wandb:       test/ensemble_f1 0.37795
wandb:           train/avg_f1 0.45129
wandb:      train/ensemble_f1 0.45129
wandb:         train/mil_loss 0.97345
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u7mbh70r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170236-u7mbh70r/logs
wandb: Agent Starting Run: wevd0a0x with config:
wandb: 	actor_learning_rate: 2.1525044466591367e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3582714122888423
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15538707308338529
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170445-wevd0a0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wevd0a0x
wandb: uploading history steps 348-350, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▄▅▆▆▆▇█
wandb: best/eval_avg_mil_loss ▂▁▁▄▆▄▃▆███
wandb:  best/eval_ensemble_f1 ▁▂▃▃▄▅▆▆▆▇█
wandb:            eval/avg_f1 ▁▁▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▇█▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:      eval/avg_mil_loss ▁▁▁▁▁▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▆▆▆▅██▇████▇▇███▇▇▇▇
wandb:       eval/ensemble_f1 ▁▂▃▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▇▆▆▆▆▅▆▆▆▆▆▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▃▂▄▁▂▃▃▄▃▅▄▂▃▂▄▄▃▃▄▄▅▄▄▃▅▇▅▅▆▅▆▃▆▇▅█▆▇
wandb:      train/ensemble_f1 ▄▃▃▄▅▄▃▄▅▁▃▄▃▄▅▅▆▆▆▆▅▅▅▅▃▅▆▅▅▆▅▅▆▇▆▆▆▆▅█
wandb:         train/mil_loss ▇▅▃▃▄█▁▃▂▄▇▁▃▃▃▇▅▃▇▇▆▄▄▃▅▄▇▄▄▄▃▃▄▅▆▇▄▆▅▄
wandb:      train/policy_loss ▅▅▅▅▅▁▇█▆▇▆▃▆▆▇▇▇▆██▄▂▆▃▅▅▅▅▅▄▂▂▄▅▃▆▂▂▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▂▄▄▇▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▆▄█▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6387
wandb: best/eval_avg_mil_loss 0.64408
wandb:  best/eval_ensemble_f1 0.6387
wandb:            eval/avg_f1 0.62907
wandb:      eval/avg_mil_loss 0.64271
wandb:       eval/ensemble_f1 0.62907
wandb:            test/avg_f1 0.44551
wandb:      test/avg_mil_loss 0.82246
wandb:       test/ensemble_f1 0.44551
wandb:           train/avg_f1 0.6169
wandb:      train/ensemble_f1 0.6169
wandb:         train/mil_loss 0.59972
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wevd0a0x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170445-wevd0a0x/logs
wandb: Agent Starting Run: ut4to111 with config:
wandb: 	actor_learning_rate: 6.727873300680577e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.34423102848007325
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03715947180598034
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_170853-ut4to111
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ut4to111
wandb: uploading history steps 153-155, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss ██▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁▅▄▅▆▃▃▄▂▄▃▄▅▄▄▅▄▇▄▅▃▄▆▅▆▆▄▅▇▆██▆▆▅▇█▆█
wandb:      train/ensemble_f1 ▂▂▁▄▃▃▃▅▂▄▅▂▃▂▇▅▃▄▅▇▄▃▅▄▂▂▅▅▃▅▄▆▇▇█▅▇▃▆▇
wandb:         train/mil_loss ▃▄▅▅▄▆▂▄▃█▆▄▂▆▄▃▃▇▃▃▅▂▅▇▂▄▄▄▁▂▂▂▄▆▂▅▂▅▁▁
wandb:      train/policy_loss ▄▄▃▂▃▅▃▄▄▄▁▃▃▄▃▆▆▇█▅▅▆▄▄▆▆▆█▆▇▄▆▆▆█▇▆▅▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▁▃▅▅▁▂▄▄▂▃▁▃▃▃█▆▇▇█▅▃▃▆▆▆█▆▄▆▇▇▅▅▇▇█▇▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 0.71016
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 0.6774
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.69048
wandb:      test/avg_mil_loss 0.55657
wandb:       test/ensemble_f1 0.69048
wandb:           train/avg_f1 0.62994
wandb:      train/ensemble_f1 0.62994
wandb:         train/mil_loss 0.69357
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ut4to111
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_170853-ut4to111/logs
wandb: Agent Starting Run: iz9oui10 with config:
wandb: 	actor_learning_rate: 3.0098316588154644e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3260958211674395
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0035706770333396864
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171047-iz9oui10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iz9oui10
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████████▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ██████████████▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▁▄▇▅▂▇▄▂▇▄▅▃▃▄▄██▃▃▄▆▅▅▃▃▄█▅▇█▆▅▃▅▇▇▆▁▇
wandb:      train/ensemble_f1 ▄▁▄▅▃▅▃▃▆▁▄▃▂▂▂▄▄▅▃▄▁▂▆▆▆▅▄▆▅█▄▂▅▄▆▆▆▅▄▅
wandb:         train/mil_loss ▂▆▄▃▃▄█▅▆█▆▅▅▆▂▃▄▅▃▆▆▂▃▇▃▁▃▄▅▄▁▅▆▅▂▄▅▅▇▅
wandb:      train/policy_loss ▆▄▅▇▅▆▇█▆▇▇▇▅▆▄▃▂▂▂▅▆▂▄▁▃▄▅▂▅▄▂▂▃▂▃▃▄▂▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▅▅▇▆█▅▅▃▆▆▇▅▇▆▄▅▅▃▆▄▃▄▁▂▄▃▆▄▄▂▃▂▄▂▃▂▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40476
wandb: best/eval_avg_mil_loss 0.89286
wandb:  best/eval_ensemble_f1 0.40476
wandb:            eval/avg_f1 0.39291
wandb:      eval/avg_mil_loss 0.84026
wandb:       eval/ensemble_f1 0.39291
wandb:            test/avg_f1 0.41365
wandb:      test/avg_mil_loss 1.2091
wandb:       test/ensemble_f1 0.41365
wandb:           train/avg_f1 0.41867
wandb:      train/ensemble_f1 0.41867
wandb:         train/mil_loss 0.92315
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iz9oui10
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171047-iz9oui10/logs
wandb: Agent Starting Run: j47684dk with config:
wandb: 	actor_learning_rate: 1.0034150638213111e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9180060801112926
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7667850046289701
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171204-j47684dk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j47684dk
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▅▆▅▅▅▄▄▄▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▇▆▄▇▄█▃▆▆▃▅█▅▅▂▅▅▇█▇▇▃▄▅▄▂▁▃▄▅▇▃▅▆▇▂▃▆
wandb:      train/ensemble_f1 ▆▄▅▅▇▆▆▄▅▇▇▄█▂▄▅▅▂▇▅▆▃█▇▄▄▅▄▅▂▄▃▆▅▂▄▅▃▆▁
wandb:         train/mil_loss ▁▂▃▄▂▆▂▁▁▆▃▂▃▂▃▃▁▃▂▄▁▂▂▂▂▃▂▂▃▂▂▁▄▂▅▂▆▃▄█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.99356
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9832
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.16268
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31624
wandb:      train/ensemble_f1 0.31624
wandb:         train/mil_loss 0.54046
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run distinctive-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j47684dk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171204-j47684dk/logs
wandb: Agent Starting Run: 8e1p0enw with config:
wandb: 	actor_learning_rate: 0.0001838847424109656
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42187904536656007
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03186293606002644
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171322-8e1p0enw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8e1p0enw
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▂▄▅▄▇▅▅▆▆▅▃▄▄▁▅▄▅▇▄▇▆▃▃▂▇▆▆▂▅▅█▃▅▆▆▅▆▆
wandb:      train/ensemble_f1 ▅▄▄▅▁▄▄▅▄▅▂▂▃▃▃▃▃▆▅▃▅▁▂▁▅▃▁▄▅▂▄▃▄▄▅▇▅█▄▂
wandb:         train/mil_loss ▄▂▅▄▂▄▅▃▅▃█▅▅▄▁▄▆▅▇▄▅▁▃▂▅█▃▃▂▆▃▆▃▅▁▃▂▄▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98502
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97904
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.13705
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32432
wandb:      train/ensemble_f1 0.32432
wandb:         train/mil_loss 0.81057
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run youthful-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8e1p0enw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171322-8e1p0enw/logs
wandb: Agent Starting Run: kk1b5u41 with config:
wandb: 	actor_learning_rate: 1.0804972137186284e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29599975071288653
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30002822002637175
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171440-kk1b5u41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk1b5u41
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▄▅▄▄▂▁▄▄▄█▅▄▃▃▃▅▅▆▅▃▁▃▆▃▄▂▂▃▅▄▃▆▃▅▅▄▃
wandb:      train/ensemble_f1 ▄▆▄▂▃▃▄▅▃▆▆▅▄█▆▅▄▆▅▅▆▃▃▄█▄▃▅▄▃▄▃▁▂▄▄▂▅▄▂
wandb:         train/mil_loss ▆▁▇▃▆▆▅▂▅▄▃▃▅█▃▂▄▄▄▅▆▃▃▃▄▃▆▄▂▅▅▄▂▁▅▃▃▃▇▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.64365
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.5677
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.40928
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32717
wandb:      train/ensemble_f1 0.32717
wandb:         train/mil_loss 1.57897
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run generous-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kk1b5u41
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171440-kk1b5u41/logs
wandb: Agent Starting Run: bnquy7hu with config:
wandb: 	actor_learning_rate: 9.793814232018133e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11203636875265333
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.012083119917271843
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171557-bnquy7hu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bnquy7hu
wandb: uploading history steps 176-188, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▅▅▅▅▅█
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▆▃▄▂▅▂▃▃▆▇▆█▆▆▂▇▇▃█▃▃▃▄▆▆▄▅▃▁▂▆▃▅▃▂▃▂
wandb:      train/ensemble_f1 ▄▃▅▆▆▆▂▃▆▆▃▃▇▆▃▆▅▂▇▃▄▃▃█▃▃▄▅▄▅▆▃▄▁▄▅▂▂▅▂
wandb:         train/mil_loss ▇█▁▅▂▇▄▄▄▆▃▃▅▅▇▄▅▅▅▃▅▃▅▆▅▆▅▄▆▆▄▅▇▇█▄▆▅▅▄
wandb:      train/policy_loss ▁▂▁▂▁▂▂▂▁▂▁▂▁▂▁▄▂▁▁▁███▆████▇▇█▇█▇█▇█▂▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▂▁▂▁▂▁▂▁▂▂▂▂▁█▇█▆█▆██▇▇█▆███▇█▇▂▁▁▁▂▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78829
wandb: best/eval_avg_mil_loss 0.52326
wandb:  best/eval_ensemble_f1 0.78829
wandb:            eval/avg_f1 0.77858
wandb:      eval/avg_mil_loss 0.54282
wandb:       eval/ensemble_f1 0.77858
wandb:            test/avg_f1 0.8164
wandb:      test/avg_mil_loss 0.49987
wandb:       test/ensemble_f1 0.8164
wandb:           train/avg_f1 0.72221
wandb:      train/ensemble_f1 0.72221
wandb:         train/mil_loss 0.53149
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bnquy7hu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171557-bnquy7hu/logs
wandb: Agent Starting Run: klxyhtoh with config:
wandb: 	actor_learning_rate: 0.00023118109458377005
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.02486414579232865
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.11373081099644822
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171812-klxyhtoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/klxyhtoh
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▆▃▄▄▃▃▅▄▂▁▄▇▇▂▃▃▃▃▄▇▃▃▂▄█▃▃▃▃▂▃▃▁▃▁▆▅
wandb:      train/ensemble_f1 ▅▅▅▃▅▆█▇▃▃▆▁█▄▄▄▆▃▃▅▃▇▄▇▁▄▇▄▄▆▅▄▃▄█▄▇▆▆▇
wandb:         train/mil_loss ▅▅▃▆▄▅▆▄▃█▄▇▆▅▂▃▄▄▄▄▅▄▅▄▃▅▄▅▁▂▂▅▃▇▅▅▃▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.70859
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.61749
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.29571
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 1.96706
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/klxyhtoh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171812-klxyhtoh/logs
wandb: Agent Starting Run: rwbo5h66 with config:
wandb: 	actor_learning_rate: 6.290951887929504e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.22416837206659124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.008826200566677045
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_171929-rwbo5h66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rwbo5h66
wandb: uploading history steps 131-137, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▅▅▅▅▅███████████████████████████
wandb:      eval/avg_mil_loss █████▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▃▃▃▃▂▁▁▁▂▂
wandb:       eval/ensemble_f1 ▁▁▁▅▅▅▅▅▅███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▃▂▂▁▃▂▂▃▂▄▃▃▁▃▅▆▃▄▃▂▆▅▃▅▄▅█▅▆▆▅▇▄▂▅▅▄
wandb:      train/ensemble_f1 ▂▂▃▄▂▃▂▆▅▃▆▁▁▄▅▂▃▂▅▆▆▂▇▆▂▃▄▄▆▆▅▅▇▅█▅▂▂▇▄
wandb:         train/mil_loss ▃▅▆▃▄▁▆▄▅▆▄▃▅▆▇█▃▄▇█▆▄▄▄▃▆▅▄▆▅▄▅▅▃▄▅▄▃▃▃
wandb:      train/policy_loss ▁▅▅▇█▃▃▁▄▃▆▃▃▄▁▃▄▅▃▃▆▅▅▃▅▁▃▅▅▃▃▇▃▃▄▄▅▅▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▇▇▇▁▄█▄▁▄▁▁▅▇▄▁█▄▅▂▁█▄▇▄▄▅▄▄▄▅▅▁▅▇▄▅▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.46728
wandb: best/eval_avg_mil_loss 1.22171
wandb:  best/eval_ensemble_f1 0.46728
wandb:            eval/avg_f1 0.46728
wandb:      eval/avg_mil_loss 1.17893
wandb:       eval/ensemble_f1 0.46728
wandb:            test/avg_f1 0.33333
wandb:      test/avg_mil_loss 1.72571
wandb:       test/ensemble_f1 0.33333
wandb:           train/avg_f1 0.39823
wandb:      train/ensemble_f1 0.39823
wandb:         train/mil_loss 1.10587
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run restful-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rwbo5h66
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_171929-rwbo5h66/logs
wandb: Agent Starting Run: jdz1ng6w with config:
wandb: 	actor_learning_rate: 0.0005784649531038943
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13724223773528454
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.03749330977941623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172108-jdz1ng6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdz1ng6w
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▆▆▆▆▅▄▇▃▆▄▃▇▅▇▆▅▅▃▅▇▅▇▄▄▅▂▅▆▅▄▂█▅▃▄▃▁
wandb:      train/ensemble_f1 ▅▄▇▅▅▅▄▇▃▄▅▇▆▄▅▄▇▃▅▇▆▆▆▆▄█▆▆▆▁▆▄▂▇▄▄▄▄▆▂
wandb:         train/mil_loss ▆▄▅▃▆▂▅▂▅▄▃▄▆▂▃▅▄▆▁▃▂▅▇▅▂█▇▂▆▂▁▅▄▅▆▆▅▃█▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.77592
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.72713
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.05463
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3133
wandb:      train/ensemble_f1 0.3133
wandb:         train/mil_loss 1.46591
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdz1ng6w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172108-jdz1ng6w/logs
wandb: Agent Starting Run: j6334frb with config:
wandb: 	actor_learning_rate: 0.0007492785486472665
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6854542943312709
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33857085032044
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172225-j6334frb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6334frb
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▂▂▂▁▁██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▇▇▆▆▆▆▅▄▄▄▃▃▃▃▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▇▆█▄▄▄▆▄▅█▅▄▆▆▄▅▆▇▄▄▂▆▇▇▅▄▄▄█▁▆█▆▅▄▇▄
wandb:      train/ensemble_f1 ▅▅▇▅▄▄▅▄▇▄▆▆▇▅▇▇▇█▆▅▆▅▄█▄▆██▅▂█▅█▃▁▅▆▄▃█
wandb:         train/mil_loss ▄▄▃▅▂▄▄▃▆▆▃▄▃▃▅▅▄▄▃▄▄▅█▃▄▃▅▃▅▄▄▂▄▁▆▄▃▆▃█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.72647
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.72581
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.81322
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32432
wandb:      train/ensemble_f1 0.32432
wandb:         train/mil_loss 0.68901
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j6334frb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172225-j6334frb/logs
wandb: Agent Starting Run: fgeah0ti with config:
wandb: 	actor_learning_rate: 0.002292511015216209
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7594680092037354
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1573120594168671
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172343-fgeah0ti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fgeah0ti
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▄▄▃▄▅▄█▅█▃▇▇▆▅▁▄▁▁▂▄▅▆▄▃▄▅▁▅▁▃▆▄▇▄▁▆▅▃
wandb:      train/ensemble_f1 ▃▂▆▃▄▂▄▅▁▄▅▅▃▅▁▃▂▄█▅▃▂▂▅▂▅▇▃▃▅▅▄▂▃▅▇▄▄▂▅
wandb:         train/mil_loss ▅▄▄▄▂▂▁▁▄▃▄▄▂▇▅▁▅▁▄█▂▆▃▂▃▆▄▆▃▂▄▃▁▅▃▄▃▄▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.85575
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.8486
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02313
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3283
wandb:      train/ensemble_f1 0.3283
wandb:         train/mil_loss 0.75043
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run summer-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/fgeah0ti
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172343-fgeah0ti/logs
wandb: Agent Starting Run: xii08u7s with config:
wandb: 	actor_learning_rate: 2.072625290379093e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8504509493142272
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.32535992934112623
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172500-xii08u7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xii08u7s
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▃▆▇▄▃▃█▅▃▅▇▇▃▃▅▄▃▄▄▅▅▇▄▅▃▄▄▅▃▅▄▁▄█▂▇▅▅
wandb:      train/ensemble_f1 ▇▄▅▃█▃▄▅▃▅▅▅▇▆▃▅▅▃▄▇▆▄▆▆▅▄▅▆▆▃▄▄▅▄▁▅▂██▇
wandb:         train/mil_loss ▃▄▄▁▃▃▂▂▁▅▄▂▅▃▅▇▁▅▁▄▇▅▄█▃▅▃▄▄▄▂▇▂▂▂▆▂▃▃▃
wandb:      train/policy_loss ▃▃▆▃▂▁▃▁▁▆▁▁▃▃▃▃█▄▃▃▄▃▃▁▃▆▃▃▁▄▆▁▃▁▃█▃▃▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▄▆▁▁▂▄▃▆▁▆▁▁▁█▁▁█▃▂▃▁▃▃▃▃▄▆▁▃▃█▄▃█▁▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.36
wandb: best/eval_avg_mil_loss 0.90229
wandb:  best/eval_ensemble_f1 0.36
wandb:            eval/avg_f1 0.36
wandb:      eval/avg_mil_loss 0.8872
wandb:       eval/ensemble_f1 0.36
wandb:            test/avg_f1 0.38593
wandb:      test/avg_mil_loss 1.06842
wandb:       test/ensemble_f1 0.38593
wandb:           train/avg_f1 0.39973
wandb:      train/ensemble_f1 0.39973
wandb:         train/mil_loss 0.55931
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xii08u7s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172500-xii08u7s/logs
wandb: Agent Starting Run: yr63lzcw with config:
wandb: 	actor_learning_rate: 0.0001808731674759777
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.47042282200878105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4490155435104955
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172618-yr63lzcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yr63lzcw
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▁▁▁▃▄▄▄▄▄▄▄▄▄▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆
wandb:      eval/avg_mil_loss ▂▂▂▄▇████▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▃▄▄▄▄▄▄▄██████████████████████████▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▂▃▃▃▄▃▄▂▃▃▃▅▅▃▄▅▅▃▅▅▅▅▄▁▅▄▄▄▃▂▇▅▅▄▄▂▃▆
wandb:      train/ensemble_f1 ▇▆▇▆▂▃▃▁▄▃▄▄▂▃▄▆▃▅▄▅▃▄▄▃▅▅▅▅▅▃▄▄█▃▄▄▁▄▃▆
wandb:         train/mil_loss █▃▄▇▃▆▆▁▅▄▄▅▅▆▄▅▃▂▄▂▇▅▁▅▅▅▅▂▆▂▆█▄▇▂▅█▄▄▅
wandb:      train/policy_loss ██▁█████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███▁████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.44148
wandb: best/eval_avg_mil_loss 0.85975
wandb:  best/eval_ensemble_f1 0.44148
wandb:            eval/avg_f1 0.42956
wandb:      eval/avg_mil_loss 0.85256
wandb:       eval/ensemble_f1 0.42956
wandb:            test/avg_f1 0.41365
wandb:      test/avg_mil_loss 1.17068
wandb:       test/ensemble_f1 0.41365
wandb:           train/avg_f1 0.42956
wandb:      train/ensemble_f1 0.42956
wandb:         train/mil_loss 0.8573
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yr63lzcw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172618-yr63lzcw/logs
wandb: Agent Starting Run: rqkqjy1u with config:
wandb: 	actor_learning_rate: 0.002025446293557672
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6436137694432675
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8452479332364652
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172736-rqkqjy1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rqkqjy1u
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▄▄▄▄▄▄▄▄▄▃▃▃▃▃▆█▆▅▃▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 █████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▇▄█▇▇▆▅▆▇█▆▇▇▇▅▇▄▄▅▅▃▃▃▄▃▅▄▅▃▂▄▃▅▄▃▁▄▂
wandb:      train/ensemble_f1 ▇▇▃▆▃█▆▄▅█▇▅▄▅▅▇▅▆▃▃▅▂▃▂▂▃▂▄▄▁▃▃▁▃▂▁▁▁▂▂
wandb:         train/mil_loss ▂▄▄▂▂▄▅▂▃▄▆▄▃▄▄▅▆▂▂▃▄▆▅▄▃▃▃▁▅▄▂▅▄▂█▂▅▃▅▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▇▄▄▆▆▄█▆▇▇▁▄▄█▅▂▄▆▄▇▁▄▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████████████▁██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40229
wandb: best/eval_avg_mil_loss 1.18696
wandb:  best/eval_ensemble_f1 0.40229
wandb:            eval/avg_f1 0.3763
wandb:      eval/avg_mil_loss 1.14559
wandb:       eval/ensemble_f1 0.3763
wandb:            test/avg_f1 0.32211
wandb:      test/avg_mil_loss 1.53142
wandb:       test/ensemble_f1 0.32211
wandb:           train/avg_f1 0.32781
wandb:      train/ensemble_f1 0.32781
wandb:         train/mil_loss 0.88389
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run apricot-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rqkqjy1u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172736-rqkqjy1u/logs
wandb: Agent Starting Run: i75v7tmc with config:
wandb: 	actor_learning_rate: 0.0005047677460630419
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8188307798194208
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.38677637273289545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_172854-i75v7tmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i75v7tmc
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇█▇▇▇▆▆▆▆▆▆▆▄▄▄▄▃▂▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▁▃▄▁▅▄▅▅▇▅▇▂▅█▃▂▆▅▄▄▅▃▃▂▂▅▄▄▄▂▂▄▃▆▅▆▅▅
wandb:      train/ensemble_f1 ▄▅▄▁▅▅▅▅▅▅▇▄▂█▂▃▃▅▄▄▄▅▇▃▂▅▇▆▄▇▅▄▅▄▄▂▃▅▅▅
wandb:         train/mil_loss ▄▄▄▃▂▃▃▆▁▃▂▅▃▄▄▆▁▃▃▇▃▅▃▃▃▅▂▃▃▁▇▄▅█▄▂▁▅▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 0.7417
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.73268
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.67991
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.4908
wandb:      train/ensemble_f1 0.4908
wandb:         train/mil_loss 0.57827
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i75v7tmc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_172854-i75v7tmc/logs
wandb: Agent Starting Run: 72srpe64 with config:
wandb: 	actor_learning_rate: 0.0032976820985055615
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3430983338187643
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9826030636644536
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173011-72srpe64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/72srpe64
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▆▇▄▃▅▆▂▇▄▆▅▅▅▃▆▃▄▆▄▆▅▄▃▃▅▅▅█▆▅▁▄▃▄▅▄▃▆
wandb:      train/ensemble_f1 ▄▆▆▄▃▆▅▅▅▆▃▅▄▅▄▃▆█▆▄▆▅█▃▅▇▆▄▆▆▆▅▅▄▁▄▄▃▇▇
wandb:         train/mil_loss ▆▅▆▆▄▄▇▅▄▇▆▆█▅▁▅▅▆▅▄▆▄▆▇▄▄▅▄▆▅▅▅▇▁▅▅▅▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.00825
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9847
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.28889
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34372
wandb:      train/ensemble_f1 0.34372
wandb:         train/mil_loss 0.94712
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lucky-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/72srpe64
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173011-72srpe64/logs
wandb: Agent Starting Run: 9e2c0c43 with config:
wandb: 	actor_learning_rate: 7.581700579955242e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9432445462920456
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6977724420805872
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173129-9e2c0c43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/965x6drt
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9e2c0c43
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▇▆▄▁▆▄▅▆▆▆▅▃▇▅▆▇▆▃▇▃▃▄▄▅▄▅▆▂▃▅▆▂▁▃▅█▃
wandb:      train/ensemble_f1 ▅▂▅▇▆▇█▅▆▆▆▆▆▆▆▅▆▅▇▆▅▇▁▅▅▆▅▆▄▃▃▄▆▆▆▇▂▄▄▆
wandb:         train/mil_loss ▂▄▅▂▄▂▄▅▂▂▂▄▂▂▄▅▄▂▁▁▁▁▄█▅▁▂▄▁▁▅▆▃▄▂▂▂▁▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.59955
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.59228
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.82525
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32375
wandb:      train/ensemble_f1 0.32375
wandb:         train/mil_loss 0.53038
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9e2c0c43
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173129-9e2c0c43/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: c85ydwl3 with config:
wandb: 	actor_learning_rate: 0.0002008743260087668
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.010329967686191432
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13346008773394136
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173326-c85ydwl3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c85ydwl3
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 83-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▂▅▇▅▄▅▅▁▄▅▅▂▁▃▃▃▅▄▂▃▃▁▃▄▃▃▄▂▃▄█▅▂▂▂▅▇▄
wandb:      train/ensemble_f1 ▆▃▄▅▅▄▅▅▅▂▆▄▂▃▅▂▁▄▅▄▃▂▃▄▃▅▅▄▅█▄▄▅▄▅▅▄▆▄▆
wandb:         train/mil_loss ▅▅▄▆▄▃▃▃▅▃▆▃▄▅▄▄▂▃▃▅▆▂█▃▅▁▃▄▃▅▆▄▂▂▂▂▃▂▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.9615
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.90989
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.91113
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.46615
wandb:      train/ensemble_f1 0.46615
wandb:         train/mil_loss 0.95485
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c85ydwl3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173326-c85ydwl3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u4mmzv55 with config:
wandb: 	actor_learning_rate: 2.0035657077178245e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8625233355782834
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29677516700726636
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173455-u4mmzv55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u4mmzv55
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▂▂▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▇▆▅▃▃▃▆▁▇▅▅▆▆▄▃▅▃▅▄▇▁▅▃▄▇▃▇▄▅█▅▆▅▇▄▅▅
wandb:      train/ensemble_f1 ▅▄▄▄▅▄▂▆▆▅▆▅█▆▅▄▇▄▅▄▅▄▃▅▃▇▁▅▅▃█▄▆▅▇▄▆▄▃▆
wandb:         train/mil_loss ▇▄▆▆▅▅▄▃▅▄▆▄▅▅▅▃▅▆▂▅▄▅▄█▆▅▄▅▃▂▃▆▄▃▅▄▃▄▁█
wandb:      train/policy_loss ▃▁▅▃▃▁▁▁▅▃▂▇▁▃▃▃▃▃▁▁▇▇█▅▃▁▃▂▃▁▃▄▁▅▁▅▁▁▁▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▂▆▃▁▆▂▂▁▁▁▃▃▁▃▁▃▁▆▃▁█▃▁▄▂▃▃▂▃▁▂▆▂▁▃▃▂▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38558
wandb: best/eval_avg_mil_loss 0.77608
wandb:  best/eval_ensemble_f1 0.38558
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.77417
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.68732
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.46594
wandb:      train/ensemble_f1 0.46594
wandb:         train/mil_loss 0.62125
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u4mmzv55
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173455-u4mmzv55/logs
wandb: Agent Starting Run: 26rtsays with config:
wandb: 	actor_learning_rate: 0.00013707444123584397
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2944405001948497
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9781663184194518
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173612-26rtsays
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26rtsays
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▇▄▃▄▇▅▆█▄▅▃▆▇▂▇▇▇▅▇▆▅▆▆▅▁▇█▅▆▃▅▇▇█▅▃▄▄
wandb:      train/ensemble_f1 ▄▄▇▅▄▇▄▇▄▇▄▅▇▂▄▂▇▅▂▆▅▂▄▆▄█▅▅▁▅▄▄▅▆▃▄▅▁▂▃
wandb:         train/mil_loss ▄▄▇▆▄▇▃▃▅▂▁▆▂▄▄▇▆█▅▃▄▄▄▇▅▄▂▄▄▅▄▃▇▃▄▃▃▃▄▇
wandb:      train/policy_loss ▃▇█▃▆▆▃▅▇▇▇▇▃▆▆▅█▅▄▆▃▃▃▃▆▃▄▇▃▃▁▆▇▁▆▁▇▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▇▃▄▃█▇▆██▃▆▅▃▃▄▄▆▇▃▇▆▃▃▃▇▁▅▆▄▇▄▁▅▆▆▄▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.0481
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.00957
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.95232
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.46641
wandb:      train/ensemble_f1 0.46641
wandb:         train/mil_loss 1.09782
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26rtsays
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173612-26rtsays/logs
wandb: Agent Starting Run: f8ohet8n with config:
wandb: 	actor_learning_rate: 0.0003759893416284333
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9418168573384176
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6299182631108455
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173730-f8ohet8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8ohet8n
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▅▅▆▄▄▄▅█▃▄▁▃▄▆▅▃▃▄▁▂▁▄▂▂▂▆▆▃▅▂▃▄▅▆▅▂▄
wandb:      train/ensemble_f1 ▄▄▅▅▁▆▃▅▄▆▄▂▅▄▄▄▄▄▄▅▅▆▂▆▆▂▅█▃▃▄▄▇▄▄▃▅▃▅▅
wandb:         train/mil_loss ▅▂▃▅▃▁▁▅▃▂▁▄▁▅█▂▂▂▆▂▁▁▄▂▂▁▅▄▂▂▁█▆▂▃▄▃▆▄▄
wandb:      train/policy_loss ▇██▆▁▆█▇▆██████▃██▆██▆██▆█▆▆██▆▅█▇█▆▆█▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▁▆▆███▆█████▃█▆███▆█▆▆▆▇████▅██▇█▃██▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 1.26954
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 1.25982
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.99926
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.43148
wandb:      train/ensemble_f1 0.43148
wandb:         train/mil_loss 0.67109
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f8ohet8n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173730-f8ohet8n/logs
wandb: Agent Starting Run: t1f9it03 with config:
wandb: 	actor_learning_rate: 0.0008102898315800696
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.778004399251452
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3335715960396418
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_173847-t1f9it03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t1f9it03
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▇▄▄▄▅▃▄▇▂▁▄▅▆▆▇▄▆▇▂▃▆▄▃▆▆▇▅▅▆▇█▂▅▆▆▆
wandb:      train/ensemble_f1 ▁▆▄▅▆▄▄▃▅▆▆▆██▆▅▆▅▇▆▆▃█▃▄▅▅▄█▅▆▄█▅▃▆▅▆▆▃
wandb:         train/mil_loss ▃▄▅▁▄▄▂▂▁▄▂▅▃▃▄▁▂▁▂▁▅▃▃▃▃▁▃▁▂▃▇▃▂▁▂▄▆▃█▅
wandb:      train/policy_loss █▆▆▅▃▆▆▅▄▆▅▅▆▆▃██▆▆█▃▆▆█▅▆██▆▆▁▆▆▆▃▅▅▆▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▂▂▇▆▆▆▄▆▂█▄▂███▁▅▄▄▆▄▃█▆▄▆█▄█▆▄█▂▂▄▇▆▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.3083
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.28638
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.08511
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.42033
wandb:      train/ensemble_f1 0.42033
wandb:         train/mil_loss 0.83263
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t1f9it03
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_173847-t1f9it03/logs
wandb: Agent Starting Run: lfult04h with config:
wandb: 	actor_learning_rate: 1.0408905039869914e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8306496214898635
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.295916881341841
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174005-lfult04h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lfult04h
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▅▅▆▄▄▁▄▇▆▆▂▇▆▇▃▄▂▄▄▆▄▆▁▅▆▂█▆▄▄▃▇▃▅▆▅
wandb:      train/ensemble_f1 ▅▄▄█▇▆▇▇▂▄▆▆█▇█▅▃▄▄▄▇▇▄▁▄▆▅▅▄▃▁▄▃▇▄▇▇▇▆▄
wandb:         train/mil_loss ▇▃▁▄▇▅▂▅▁▆▄▄▂▇▅▇▆▇▅▃▇▅▇▅█▅▅▆▇▅▄▂▅▆▄▆▅▆▃█
wandb:      train/policy_loss ▁▁▃▃▃▁▃▃▅▃▁▁▁▅▃▅▃▄▃▃▃█▃▃▄▆▄▁▃▁▃▃▅▄▃▅▆▃▃▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▃▃▁▃▁▁▁▅▂▁▂▄▁▃▁▁▁▃▇▃▁▂▃▅▃▇▅▃▂▅▃▅▃▃▃▅▅█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63108
wandb: best/eval_avg_mil_loss 0.59497
wandb:  best/eval_ensemble_f1 0.63108
wandb:            eval/avg_f1 0.63108
wandb:      eval/avg_mil_loss 0.59367
wandb:       eval/ensemble_f1 0.63108
wandb:            test/avg_f1 0.55864
wandb:      test/avg_mil_loss 0.6195
wandb:       test/ensemble_f1 0.55864
wandb:           train/avg_f1 0.58422
wandb:      train/ensemble_f1 0.58422
wandb:         train/mil_loss 0.60617
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lfult04h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174005-lfult04h/logs
wandb: Agent Starting Run: rv1njnwi with config:
wandb: 	actor_learning_rate: 1.0942867765627412e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7677661644963776
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16797670872282755
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174123-rv1njnwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rv1njnwi
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▆▆▅▄▆▃▃▅▅▆▄▆█▆▅▄▅▆▅▄▂▃▁▄▅▅▆▅▆▆▅▆▇▄▅█▃▅
wandb:      train/ensemble_f1 ██▃▆▃▆▆▂▄▃▅▅▃▃▅▄▅▃▄▅▄▄▄▂▆▄▁▃▃▃▄▅▃▄▅▂▄▁▃▄
wandb:         train/mil_loss ▆▃█▁▁▅▅▁▃▄▁▃▅▅▅▁▃▂▃▃▆▄▃▁▅▇▁▁▂▆▆▁▄▄▃▂▃▄▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.60734
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.5844
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.1048
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34747
wandb:      train/ensemble_f1 0.34747
wandb:         train/mil_loss 0.792
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pleasant-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rv1njnwi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174123-rv1njnwi/logs
wandb: Agent Starting Run: ahzu81oc with config:
wandb: 	actor_learning_rate: 0.00010386573797007843
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0538131712404869
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12111275095472718
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174241-ahzu81oc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahzu81oc
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▄▄▆▄▃▄▁▂▆▂▄▇▂▅▄▆▃▄▄▆▆▄▇▅▅▃▃▃▅█▅▃▆▆▄▅▅
wandb:      train/ensemble_f1 ▄▄▂▁▄▂▃▅▃▅▃▃▁▂▅▂▂▃▂▃▅▃▃▄▆▅▄▃▃▁▄▅█▃▂▅▆▅▅▆
wandb:         train/mil_loss ▂▄▅█▅▃▅▄▂▆▆▄▅▆▅▅▃▃▆▂▂▄▄▄▇▂▅▆▆▃▅▄▁▁▃▂█▅▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.75582
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.73927
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.8667
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33716
wandb:      train/ensemble_f1 0.33716
wandb:         train/mil_loss 0.7705
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahzu81oc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174241-ahzu81oc/logs
wandb: Agent Starting Run: 40lluvgh with config:
wandb: 	actor_learning_rate: 0.0009402840244221728
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2308265028708194
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6765454873774283
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174358-40lluvgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40lluvgh
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▄▄▄▄▂█▅▅▄▅▅▃▁▃▅▃▅▂▄▄▆▄▁▄▂▂▆▆▇▇▃▄▃▃▂▄▆▄
wandb:      train/ensemble_f1 ▂▇▅▅▄▄▃█▅▄▁█▃▄▅▄▆▄▆▇▅▃▆▄▆▆▆▆▅▂▂▄▅▄█▂▄▂▄▄
wandb:         train/mil_loss ▁▆▇▇▇▅▂▄▃▇▄▆▄▄▄▅▅▄▄▃▅█▅▆▄▃▅▇█▆▄▅▆▅▄▇▂▇▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.78898
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.78157
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.88275
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 0.68205
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hearty-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/40lluvgh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174358-40lluvgh/logs
wandb: Agent Starting Run: ybl2vh8x with config:
wandb: 	actor_learning_rate: 0.00016697754739198852
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9094729596245636
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.241726562120687
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174515-ybl2vh8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ybl2vh8x
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███████▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▇▇▁▃▃▅█▂▅▃▃▄▂▃▄▃▄▄▃▃▅▁▇▆▄▄▄▄▃▄▅▃▄▃▄▄▄▅
wandb:      train/ensemble_f1 ▅▂▃▄▇▇▂▄▇▃▄▃▃▅▅▄▆▃▄▃▅▄▄▅▁█▅▇▅▅▁▃▅▃▅▄▄▄▆▆
wandb:         train/mil_loss ▅▃▂▄▄▂▅▂▃▄▃▅▂▂▃▅█▅▂▄▁▅▄▃▃▃▃▄▂▅▅▂▃▃▃▃▄▄▂▂
wandb:      train/policy_loss ▄▄█▄▅█▄▁█▅█▅▁█▄█▇██▅▄▄▇▇█▅▄██████▄▄▄▅▅██
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇█▅██▅▄█▅█▅█▅▅▅▇█▅▇▇█▅██▄█▂▂████▅▅█▁███
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.94226
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.92875
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.88023
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.52575
wandb:      train/ensemble_f1 0.52575
wandb:         train/mil_loss 0.56196
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sunny-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ybl2vh8x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174515-ybl2vh8x/logs
wandb: Agent Starting Run: thi5wvms with config:
wandb: 	actor_learning_rate: 5.5548681211003666e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3479435942792559
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2658587742281988
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174633-thi5wvms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/thi5wvms
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▆▆▆▆▆▆▆▅▄▄▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▄▆▄▅▂▅▄▆▅▁▅▇▄▇▃▄█▄▅▆▅▇▇▄▁▅▄▆▅▆▇▅▆▇▆▃▆
wandb:      train/ensemble_f1 ▅▁▆▅▅▆▅▇▆█▇▆▆▄█▄▅▄▁▅▃▄▄▃▇▅▅▄▇▆▆▆█▆▇▅█▇▄▅
wandb:         train/mil_loss ▆▃▁▂▆▇▆▅▃▅▃▇▅▄▅▅▆▂▅▅▅▇▅▄▆▄▃▆▆▆▆▅▇▅█▆▇▅▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.71192
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.70531
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.78639
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.65718
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/thi5wvms
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174633-thi5wvms/logs
wandb: Agent Starting Run: e3379pbl with config:
wandb: 	actor_learning_rate: 1.7380380871979446e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09448497765707252
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4879942453610624
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174751-e3379pbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3379pbl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▇▃▄▂▃▃▅▁▄█▂▆▄▅▅▆▄▅▂▅▃▄▆▇▄▄▄▇▃▇▂▃▆▆▆▃▇▃
wandb:      train/ensemble_f1 ▂▄█▅▂▂▁▃▁▃▅▂▄▆▄▄▁▄▅▂▆▇▄▄▃▇▃▃▆▃▄▃▆▇▇▇▆▃▆▃
wandb:         train/mil_loss ▅▃▅▇▃▄▆▃▆▄▄▃▃▄▅▅▆▅▃▆▁▁▆▄▇▂▇▂▁▂█▆▂▆▆▄▅▂▆▆
wandb:      train/policy_loss ▃▂▁▁▃▃▁▁▁▆▂▁▁▁▃▄▁▁▁▆▃█▁▃▁▃▁▁▁▃▁▃▁▃▁▁▃▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▅▁▁▁▅▁▁█▅▁▁▁▁▁▁▁▁█▅▁▅▁▅▁▁▁▁▅▁▅▁▁▄▄█▁▁▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.28238
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.23648
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.0605
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40414
wandb:      train/ensemble_f1 0.40414
wandb:         train/mil_loss 1.02528
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e3379pbl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174751-e3379pbl/logs
wandb: Agent Starting Run: upo3i3vg with config:
wandb: 	actor_learning_rate: 0.0034260652247615027
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8451717102192603
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7955606792652474
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_174909-upo3i3vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upo3i3vg
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▃▃▆▃▃▃▄▅▃▆▁▃▇▁▄▃█▄▃▄▂▄▅▃▂▅▃▅▂▄▃▂▄▄▆▄▄
wandb:      train/ensemble_f1 ▆▂▆▇▅▅▄▁▇█▅▃▅▆▆▆▆▇▃▄▅▄▇▅▄▅▆▇▆▇▆▆▄▅▅▆▃█▅▆
wandb:         train/mil_loss ▂▁█▃▂▄▄▄▄▂▃▃▂▁▄▁▄▃▄▄▂▄▄▂▂▂▁▃▅▃▃▃▂▃▂▅▂▅▆▅
wandb:      train/policy_loss ██▁▆█▆█▆▄█▆███▆█▅▆▆█▆▆▅▆▆▆▆▅█▆███▆█▆▅▆▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆███▆▅█▅██▆██▆▅███▅██▆▆▆███▆▅█▆██▅▅▅██▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.96262
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.94596
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.88987
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.49554
wandb:      train/ensemble_f1 0.49554
wandb:         train/mil_loss 0.73332
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/upo3i3vg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_174909-upo3i3vg/logs
wandb: Agent Starting Run: utgtg11n with config:
wandb: 	actor_learning_rate: 0.00015273248471241922
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5521237553868533
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5990253644664219
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175026-utgtg11n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utgtg11n
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▄▂▁▃▃▃▄▃▃▆▂▃█▂▃▅▃▄▂▄▃▄▄▃▅▁▄▃▅▄▂▅▂▄▅▄▃
wandb:      train/ensemble_f1 ▁▅▃▅▄▆▄▁▄▅▂▄▄▅▁▅▃▆▄▅▆▅▇▅▄▂▄▆██▆▇█▃▄▅▃▃▄▇
wandb:         train/mil_loss ▄▅█▄▂██▅▃▁▄▂▆▂▃▃▄▅▇▂▃▆▂▇▄█▅▅▃▃▃▅▄▇█▂▇▅▄▇
wandb:      train/policy_loss ▄▁▇▄▁▅▁█▃▄▅▆▅▅▇▄▅▄▂▅▄▃▆▄▂▄▇▄▄▅▅▇▇▅▅▅▇▄▂▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▁▄▂▁▅▅▁▅█▄▇▅▅▅▆▅▅▅▅▇▃▄▃▃▄▂▄▄▂▄▄▄▇▄▇▅▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.29635
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.26669
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.07912
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.41157
wandb:      train/ensemble_f1 0.41157
wandb:         train/mil_loss 0.70661
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/utgtg11n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175026-utgtg11n/logs
wandb: Agent Starting Run: j9su3jr5 with config:
wandb: 	actor_learning_rate: 0.00024445549175733107
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4567968690276005
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9512371936936124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175144-j9su3jr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j9su3jr5
wandb: uploading history steps 84-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▆▅▇▄▆▅▅▅▁▄█▇▅▄▆▆▆▇▄▆▆▅▅▄▅▄▄▅▄▅▅▆▅▅▆▆▇
wandb:      train/ensemble_f1 ▇▇▆▄▂█▆▅▂▁▅▇▅▇▃▇▃▇▃▇▃▃▄▇▅▃▅▃▁▄▄▅█▃▃▅▇▅▄▅
wandb:         train/mil_loss ▄█▃▅▆█▅▇▅▇▃▇▄▄▃▂▆▇▂▄▄█▄▅▂▅▅▅▅▄▄▃▅▄▄▂▅▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.81322
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.8074
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.92436
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34747
wandb:      train/ensemble_f1 0.34747
wandb:         train/mil_loss 0.7013
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run still-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j9su3jr5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175144-j9su3jr5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: adfgrkez with config:
wandb: 	actor_learning_rate: 0.006293979230751348
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4618845028217361
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.925896929207118
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175312-adfgrkez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/adfgrkez
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▆▆▇▅▅▅▅▄▅▇▄▄▅▆▁█▆▃▅▅▂▆▃▃▄▇▆▆▇▅▇▃▆▄▂▆▇▅
wandb:      train/ensemble_f1 ▄▄▅▄▄▃▃▃▇▄▄▅▆▂▄▇▅▂▅▆▄▅▃▆▂▂▁▃▅▅█▄▂▄▃▁▃▆▃▆
wandb:         train/mil_loss ▂▅▆▅▂▁▃▃▅▄▄▄▃▂▄█▄▄▅▂▃▇▃▁▂█▃█▃▁▄▄▆▃▄▆▅▄▃▅
wandb:      train/policy_loss █▂▅▁▃▅▅▆▅▅▂▅▅▅▅▆▄▅▆▅▄▆▅██▅▄█▁▅▅█▄▅▃▆▄▄█▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▄▆▃▅▇▇▃▆▆▅▅▆▇▇▅▇▅▄▇▅▇▂██▁▅▇▄▁▆▂▅▄▅▇▃▄▇▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.3098
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.27673
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.08663
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.42404
wandb:      train/ensemble_f1 0.42404
wandb:         train/mil_loss 1.11795
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/adfgrkez
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175312-adfgrkez/logs
wandb: Agent Starting Run: 2scqzjhy with config:
wandb: 	actor_learning_rate: 1.2841193608851578e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.417565400321628
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4033587653716232
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175430-2scqzjhy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2scqzjhy
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅▅▅▆▁▂▅▄▆▄▄▄▄▅▆▃▃▅▅▅▅▂▄▆▅▄▃▃▁█▇▆▆▆▇▃▇
wandb:      train/ensemble_f1 ▄▁▆▅▄▇▁▄▅▃▃▃▃██▅▅▃▂▂▄▅▃▃▆▂▆▃▂▁█▅▃▅▆▆▁▆▄▅
wandb:         train/mil_loss ▃▄▄▅▅▄▅▅▆▆▇▄▃▇▅▇▆▄▆▅▇▅▇█▃▃▅▆▅▇▁▄▃▇▃▃▆▄▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.85154
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.84327
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.9749
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33665
wandb:      train/ensemble_f1 0.33665
wandb:         train/mil_loss 0.78769
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2scqzjhy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175430-2scqzjhy/logs
wandb: Agent Starting Run: 1j9abdic with config:
wandb: 	actor_learning_rate: 6.292141268847208e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3348978471405579
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3117398870081257
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175548-1j9abdic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1j9abdic
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▂▂▅▅▆▂▃▅▅▄▆▄▃▄▆▃▂▄▆▅▃▄▄▅▃▁▁▅▄▄▅▆▃▃▁█▃
wandb:      train/ensemble_f1 ▇▅▇▇▅▄▁▇▂▆▃▅▅▁▄▇▆█▅▆▄▅▄▇▅█▆▆▆▅▃▅█▆▇▆▅▅▅▄
wandb:         train/mil_loss ▁▄▄▆▄▂▄▃▃▅▅▆▃▆▅▆▄▆▃▃▆▃█▄▅▁█▃▂▃▄▄▅▃▃▄▄▅▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.59837
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.5596
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.09575
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3266
wandb:      train/ensemble_f1 0.3266
wandb:         train/mil_loss 1.22088
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1j9abdic
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175548-1j9abdic/logs
wandb: Agent Starting Run: kuzfmkpt with config:
wandb: 	actor_learning_rate: 0.0002294320199904296
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29437724789243147
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7901156539901272
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175705-kuzfmkpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuzfmkpt
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▅▃▇▄▃▆▄▅▅▅▆▅▄▇▆▆▆▃█▅▄▄█▄█▂▄▂▁█▆▅▂█▆▅▆
wandb:      train/ensemble_f1 ▇▃▄▆▄█▇▄▇▆▃▅▇▄▅▅▅▆▆▅▆▆▅▆▃▇▆▄▇▅▂▇▇▆▁▆▃▅▆▅
wandb:         train/mil_loss ▅▄▁▄▆▅▅█▃▇▄▄▅▂▄▅▇▄▂▅▅▂▄▅▆▁▆▇▃▅▅▃▂▂▄▆▂▃▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.99362
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97486
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12784
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33444
wandb:      train/ensemble_f1 0.33444
wandb:         train/mil_loss 0.87508
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dandy-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kuzfmkpt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175705-kuzfmkpt/logs
wandb: Agent Starting Run: jx7gqg07 with config:
wandb: 	actor_learning_rate: 3.221479815964409e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3606697723537928
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9392635565130756
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175823-jx7gqg07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jx7gqg07
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▁▆▅▄▁▆▃▄▅▄▄▃▆▄▅▃▂▂▄▆▄▆▃▆█▂▂▅▅▄▂▆▆▆▇▃▃▅
wandb:      train/ensemble_f1 ▃▁▃▃▂▂▄▂▁▅▂▂▃▄▄▅▂█▃▄▂▅▅▂▃▃▆▂▄▂▃▃▃▅▃▅▃▅▄▄
wandb:         train/mil_loss ▆▅▆▅▄▅▆▃▅▅▆▁▇▄▄▄▃▄▅▆▆▄▃▅█▃▂▄▅▁▅▃▅▇▃▆▄▄▆▅
wandb:      train/policy_loss ▄▄▄▇▂▃▅▄▄▇▁▄▄▄█▆▄▁▂▅▄▅▁▂▅▄▇▅▅▂▅▂█▄▇▅▅▂▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▇▃▄▅▃▅▄▄▇█▂▁▄▄▄▆█▅▁▂▄▄▁▅▅▁▂▄▅▁▂▄▄▂▂▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.94878
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.90451
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.90178
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.48865
wandb:      train/ensemble_f1 0.48865
wandb:         train/mil_loss 0.88726
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run laced-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jx7gqg07
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175823-jx7gqg07/logs
wandb: Agent Starting Run: kqpsqr81 with config:
wandb: 	actor_learning_rate: 0.000643428135786238
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4449720163008394
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9231013348586148
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_175940-kqpsqr81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kqpsqr81
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▇█▆▅█▅▁█▅▅▃▄▆█▃▆▄▆▆▇▅▇▆▅▆▄▇▇▆▇▅▇▄▃▅▅▅▅
wandb:      train/ensemble_f1 ▆█▆█▆▅▃▃▅▅▅██▁▄▅▅▅▇▄▅▅▃▅▄▃▇▅▇█▇▇▄▇▆▇▅▅▄▅
wandb:         train/mil_loss ▂▂▆▇▅▆▂▃▇▆▃▄▆▂▆▃▄▄▅▅▆▃▅▅▅▇█▅▆▃▃▂▄▄▂▅▄▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82044
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81464
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93359
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32886
wandb:      train/ensemble_f1 0.32886
wandb:         train/mil_loss 0.64632
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kqpsqr81
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_175940-kqpsqr81/logs
wandb: Agent Starting Run: manw2007 with config:
wandb: 	actor_learning_rate: 0.005201655833234283
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9256100310562771
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.058390049521255816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180058-manw2007
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/manw2007
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▅▆▃▃▃█▂▅▅▇▂▅▂▅▅█▅▆▃▇▅▃▆▂▆▅▃█▅▄▇▂▄▄▅▄▂▄
wandb:      train/ensemble_f1 ▆▆▆▅▄▅▆▃▁▆█▂▇▆▆▆▂▆▃▆▆▆▂▆▄▆▇▅▄▅█▇▅█▅▅▅▂▃▅
wandb:         train/mil_loss ▆▁▂▂▂▁▂▅▅▂▇▄▁▅▂▂▂▂▂█▄▄▂▅▄▁▅▅▂▁▅▁▁▅▁█▂▂▁▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.61358
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.59925
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.11474
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.56675
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fragrant-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/manw2007
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180058-manw2007/logs
wandb: Agent Starting Run: 8vaxvnyz with config:
wandb: 	actor_learning_rate: 0.0002872251601755037
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09887315957142984
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5063335506669383
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180216-8vaxvnyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8vaxvnyz
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅▄█▅▅▅▅▃▅▇▅▃▃▅▃▂█▅▆▆▅▄▅█▁▄▆▃▆█▄█▅▃▅▃▃▄
wandb:      train/ensemble_f1 ▆▇▃█▆▅▃▅▅▇█▅▄▄▂▃█▆▆▃▆▁█▅▄▂▄▆▆▃▆▄█▃▄▆▄▅▄▄
wandb:         train/mil_loss ▄▅▅▅▄▁▂▄▄▄▅▇█▄▅▅▅▅▄▅▄▃▇▆▅▃▃▂▅▆▃▆▁▃▄▆█▁▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.75908
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.75229
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.83743
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32717
wandb:      train/ensemble_f1 0.32717
wandb:         train/mil_loss 0.7321
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8vaxvnyz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180216-8vaxvnyz/logs
wandb: Agent Starting Run: oxwoppub with config:
wandb: 	actor_learning_rate: 1.245416473596536e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0016599513380601838
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5559794674098665
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180333-oxwoppub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oxwoppub
wandb: uploading history steps 88-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▇▅▅▅▅▆▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▂▂▂▃▂▂▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▃▃█████████
wandb:       eval/ensemble_f1 ████▇▅▅▅▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▆▆▅▆█▇▅▆▇▇▄▆▆▅▇▇▇▆▇▇▆▆█▅▆▆▇▄▆▆▄▅▁▃▅▄▄
wandb:      train/ensemble_f1 ▆▆▆▇▇▆▆██▇▇▇▆█▇▆▆▆▇▇▇▇▇▆█▆██▅▇▇▅▄▆▃▄▆▅▁▄
wandb:         train/mil_loss ▃▅█▄▅▃▅▆▄▇▃▄▅▄▄▄▃▆▅▆▁▃▆▄▃▃▅▇▄▆▇▅▇▆▆▄█▅▇▇
wandb:      train/policy_loss ████▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████████▁▁▁▁████▁▁▁▁▁▁▁▁▁▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61786
wandb: best/eval_avg_mil_loss 0.5965
wandb:  best/eval_ensemble_f1 0.61786
wandb:            eval/avg_f1 0.54004
wandb:      eval/avg_mil_loss 0.61417
wandb:       eval/ensemble_f1 0.54004
wandb:            test/avg_f1 0.55864
wandb:      test/avg_mil_loss 0.61946
wandb:       test/ensemble_f1 0.55864
wandb:           train/avg_f1 0.52571
wandb:      train/ensemble_f1 0.52571
wandb:         train/mil_loss 0.61741
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/oxwoppub
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180333-oxwoppub/logs
wandb: Agent Starting Run: 3cgy4mip with config:
wandb: 	actor_learning_rate: 0.0055940788344519396
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.35162895971750097
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41520786237070384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180451-3cgy4mip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3cgy4mip
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▃▁▂▁▂▅▄▃▂▅▂▁▄▃▄▃▄▅▂▂▃▂▅▂▄▃█▁▄▄▃▃▄▂▁▅▃
wandb:      train/ensemble_f1 ▄▄▆▂▂▅▂▂▄▃▄▃▅▄▄▂▄▅▄▅▄▂▃▁▁▄▄█▂▁▃▅▄▃▃▂▄▂▄▅
wandb:         train/mil_loss ▆▆▃▇▂▃█▅▃▄▆▄▆▄▁▅▅▃▄▆▂▂▃▄▅▂▄▂▃▄▅▄▄▂▄▂▃▅▄▅
wandb:      train/policy_loss ▃▆▆▆▆▆▅▄▄▁▆██▁▄▅▄▁▃▆█▆▄▄▆▃▄▄▁█▆▃▄▆▃█▅▆▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▇▃▂▆█▅▄▄▁▁▅▂▃▄▇▆▄▄▃▄▃▂▄▅▄▂▄▄▁▂▅▅▄▅▄▃▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 0.98597
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 0.93177
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.89551
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.46893
wandb:      train/ensemble_f1 0.46893
wandb:         train/mil_loss 0.93194
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3cgy4mip
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180451-3cgy4mip/logs
wandb: Agent Starting Run: 0o1xxrli with config:
wandb: 	actor_learning_rate: 0.0008313825518835475
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2233963204293986
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10459694774194216
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180608-0o1xxrli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o1xxrli
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅█▆▃▅▆▇█▄▃▅▅▄▅▆▆▅▅█▅▄▅▄█▃▃▇▅▅▅▃▆▅▆▄▆▁▇▆
wandb:      train/ensemble_f1 ▂▄▃▃▇▆▄▆█▁▆▄▄▆▅▆▅▄▄█▅▆▄▄▃▅▂▆▄▇▅▄▁▄▃▅▃▃▅▇
wandb:         train/mil_loss ▅█▃▅▆▇█▇▇▇▄▄▄▁▄▆▇▃▆▃▇▄▂▄▃▇▃▄▅▁▅▇▃▅▆▇▇▅▇█
wandb:      train/policy_loss ▂▃▅▃▅▂▁▃▃▃▃▃▆▁▅▁▃▃▃▃▅▃▁▃█▅▅▅▅▁▇▅▁▅▁▃▃▆▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▄▄▃▃▃▃▆▆▁█▄▄▁▃▃▃▄▃▁█▃▆▃▃▆▄▆▁▆▄▃▃▁▆▁▃▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.15213
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.11131
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.99574
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.48818
wandb:      train/ensemble_f1 0.48818
wandb:         train/mil_loss 0.87963
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0o1xxrli
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180608-0o1xxrli/logs
wandb: Agent Starting Run: ktrbwf43 with config:
wandb: 	actor_learning_rate: 0.005800726195739167
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12397082541360328
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19033223624598872
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180726-ktrbwf43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ktrbwf43
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▄▆▄▆▆▅▇▆▄▆▄▆▅█▇▄▄▅▄▅▃▅▆▆▃▅▇▅▄▁▆▄▂▂▅▄▆▆
wandb:      train/ensemble_f1 ▇▄▆▆▄▅▄▇▆▅▆▃▇▇▄▅▇▄▅▆▃▆▆▄▆▅▅█▆▄▄▃▁▄▃▃▄▅▄▆
wandb:         train/mil_loss ▂▆▅▆▄█▂▆▆▅▄▂▅█▄▆▆▆▄▆▄▆▅▆▃▄▇▅▆▅▆▂▄▁▆▄▇▅▇▅
wandb:      train/policy_loss ▅▁▁▃▁▂▅▃▃▅▃▁▁▃▃▅▁▃▁▄▃▁▃▁▁▅▃▃▁▁▃▆█▁▃▅▁▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▁▁▂▆▁▁▃▃▃▃▂▃▃▃▆▃▁▁▁▁▆▃▁▁▁▁▃▃▁▃▃▃▁▁▃█▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.53989
wandb: best/eval_avg_mil_loss 0.83334
wandb:  best/eval_ensemble_f1 0.53989
wandb:            eval/avg_f1 0.53989
wandb:      eval/avg_mil_loss 0.79756
wandb:       eval/ensemble_f1 0.53989
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.82511
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.50893
wandb:      train/ensemble_f1 0.50893
wandb:         train/mil_loss 0.88019
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ktrbwf43
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180726-ktrbwf43/logs
wandb: Agent Starting Run: 2x1mrc06 with config:
wandb: 	actor_learning_rate: 0.00033990853654093114
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28716615606155105
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7301238923048079
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_180844-2x1mrc06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2x1mrc06
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▄▃▆▄▄▁▂▄▃▆▃▄▅▄▃▄▃▄▃▅▅█▇▅▄▂▂▄▅▃▂▃▄▃▅▃▅▄
wandb:      train/ensemble_f1 ▄▇▃▁▁▃▃▆▆▆▃▄▄▃▄▅▅▇▄▂▅▂▄▅▄▅▅▄▃█▃▅▅▃▆▄█▅▅▆
wandb:         train/mil_loss ▅▄▄▅█▅▅▆▄▅▄▂▄▄▁▅▄▄▇▄▅▅▃▅▇▆▆▅▃▇▂▅▁▂▃▅▆▃▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 1.23987
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 1.20101
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 1.03644
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.48094
wandb:      train/ensemble_f1 0.48094
wandb:         train/mil_loss 1.19168
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2x1mrc06
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_180844-2x1mrc06/logs
wandb: Agent Starting Run: qjqbfimg with config:
wandb: 	actor_learning_rate: 0.00011810750935495893
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9543278071199076
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.344074812785529
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181002-qjqbfimg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjqbfimg
wandb: uploading history steps 84-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████████▇▇▇▇▆▆▆▆▅▅▅▄▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▆▆▇▅▅▆▇▄▄▅▅▇▅▃▃█▁▅▄▆▄▃▅▃▆▆▆▆▇▅█▇▄▇▅▆▄
wandb:      train/ensemble_f1 ▃▃▄█▃▅▅█▅▄▃▄▂▄▂▄▆▆▁▆▇▂▅▃▃▄▇▅▄▃▅▆▂▆▄▆▁▄▃▁
wandb:         train/mil_loss ▆▃▁█▇▅▄▄▅▇▅▅▇▇▅▅▄▄▃▂▂▄▄█▄▄▂▅▅▃▇▅▇▅▅▂▆▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.78698
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.78575
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.8825
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32375
wandb:      train/ensemble_f1 0.32375
wandb:         train/mil_loss 0.59485
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run leafy-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qjqbfimg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181002-qjqbfimg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3z37ey10 with config:
wandb: 	actor_learning_rate: 0.0014952396608686094
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2734518347925826
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3894349092360443
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181129-3z37ey10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3z37ey10
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▇▁▇▄▅▇█▂▄▅▂▄▃▁▃▁▃▃▂▅▂▂▄▂▃▆▇▁▆▂▄▃▁▁▄▄▄
wandb:      train/ensemble_f1 ▃▄▂▃▂▄▄▇▃▃▄▃▄▂▆▅▃▅▄▃▂▂▅▄▃▄▅▄▁▅▆▂▆▃▂▃▄█▄▄
wandb:         train/mil_loss ▆▆▄▄▃▅▅▆▆▅▄▃▆▅▆▇▅▆▅▄▃▃▅▅▃▆▅▃▅█▅▃▄▁▄▇▁▃▅▄
wandb:      train/policy_loss ▁▁▃▃▆▄▆▅▅▅▃▃▅▃▆▅▁▃▄▆▃▆▃▇▅▅▁▃█▃▁▂▅▃▆▄▇▁▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▂▄▃▄▄▃▄▄▂▂▂▄▁▂▄▅▂▆▆▄▂▄▅▄▇▂▂▄▄▁▁▄▄▂▁█▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.11847
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.05594
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.96562
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.48599
wandb:      train/ensemble_f1 0.48599
wandb:         train/mil_loss 0.93798
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3z37ey10
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181129-3z37ey10/logs
wandb: Agent Starting Run: 24518qln with config:
wandb: 	actor_learning_rate: 0.001699882966586217
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5621585631500441
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.374204814109191
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181247-24518qln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24518qln
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▁▄▆▆▆▅▄▆▅▆▄▄▆▅▅▆▆▅▄▅▅▃▇▆▆▅▄▆▄█▅▆▆▄▇▆▅▅
wandb:      train/ensemble_f1 ▃▅▄▄▄▇▅▄█▃▅▃▅▃▆▂▂▃▇▅▅▇▆█▇▅▇█▅▅▄▇▂▂▆▄▆▁▆▄
wandb:         train/mil_loss ▅▄▅▅▂▆▄▅▅▅▂▃▁▃▂▂▅▄▅▄▃▁▃▃▄▃▂▁▅▂▄▁▃▆▆█▄▂▃▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.86666
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.85969
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.99914
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.348
wandb:      train/ensemble_f1 0.348
wandb:         train/mil_loss 0.69195
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24518qln
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181247-24518qln/logs
wandb: Agent Starting Run: 6dx7shg6 with config:
wandb: 	actor_learning_rate: 0.0008726197692826219
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7417128089561758
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8397082796428113
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181404-6dx7shg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6dx7shg6
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▃▄▃▄▃▅▂▂▄▆▄▄▆▃▄█▂▃▁▄▅█▃▂█▃▄▃▅▄▂▂▃▅▅▅▅▄
wandb:      train/ensemble_f1 ▄▆▄▄▄▅▅▆▅▁▆▅▆▄▄▅▃▄▄▄▅▂▇█▄▄▃▆▅▅▅▅▃▇▅▅▅▇▆▆
wandb:         train/mil_loss ▂▃▂▄▄▃▃▂▁▆▄▂▆▅▄▃▂▆▁▄▄▂▃▄▂▁▅▂▃▄█▂▄▂▅▄▂▄▃▅
wandb:      train/policy_loss ▅▇▄▇▆█▄▅█▅█▇▄▇▅▇▄▇▃▄▄▇▅▅▆▆▄▇▄▆▅▁▇▅▄▅█▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▇█▆▅▄▅▇▇▇▄▅▇▄▅▅▁█▃▅▄▇▇▄▇▄▅▁▇▄▇▅▄▇▅▇█▄▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.23993
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.2142
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.02537
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.40178
wandb:      train/ensemble_f1 0.40178
wandb:         train/mil_loss 0.69898
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6dx7shg6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181404-6dx7shg6/logs
wandb: Agent Starting Run: rlk1r74x with config:
wandb: 	actor_learning_rate: 0.0002721900035128667
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8583908548639889
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8522003302347703
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181522-rlk1r74x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rlk1r74x
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▅▄▂▃▆█▄▅▄▃▃▃▆▄▂▃▃▃▃▂▅▇▃▁▄▁▇▅▆▆▃▂▂▆▅▃▆
wandb:      train/ensemble_f1 ▂▆▇▅▇▅▄▃▅█▄▆▅▅▅▄▆▅▇▅▆▄▅▄▅▅▁▅▄▇▆▅▃▆▇▅▅▇▇▄
wandb:         train/mil_loss ▂▄▂▃▇▃▅▁▃▆▁▅▁▃▅▁▄▇▁▆▃▁▄▁▃▂▁▃▅▃▁█▆▄▄▃▅▄▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.59734
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.5784
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.09959
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 0.58064
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rlk1r74x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181522-rlk1r74x/logs
wandb: Agent Starting Run: 819nrz66 with config:
wandb: 	actor_learning_rate: 0.00019631993653328715
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14604506252309768
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5375838066295555
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181639-819nrz66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/819nrz66
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▅▃▂▃▄▅█▄▃▅▄▅▄▆▆▄▅▆▃▄▆▄▆▄▄▄▄▁▄▄▇▄▄▇▄▂▄
wandb:      train/ensemble_f1 ▄▆▂▄▁▄▃▆▇▇▆▅▆▇▅█▄▆▄▇▇▅▆▆▇▅▃▄▅▅▄▄▅▇▄█▅▅▆▅
wandb:         train/mil_loss ▅▅▅▃▃▇▆▇▅▇▆▅▂█▆▆▅▃▅▁▅▅▅▄▄▃▇▄▄▇▇▇▄▄▄▂▇▄▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.42569
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.38327
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.91187
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 1.57959
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/819nrz66
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181639-819nrz66/logs
wandb: Agent Starting Run: gbr1szl4 with config:
wandb: 	actor_learning_rate: 1.7469862921681235e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7850206488581133
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22226538848741983
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181758-gbr1szl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbr1szl4
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▄▅▆▃▃▄▄▅▃▂▅█▄▅▅▅▂▃▅▂▅▆▇▇▃▆▅▅▂▄▃▄▅▅▃▅▁▆
wandb:      train/ensemble_f1 ▃▁▅▄▇▃▅▁▁▃▁▆▅▃█▂▃▅▂▂▂▅▇▄▆▆▅▄▄▄▄▅▅▄▄▆▃▅▄▄
wandb:         train/mil_loss ▃▄▃▄▄▄▃▄▅▄▃▄▃▅▂▄▃▆▁█▆▃▆▁▁▅▂▂▅▁▁▃▄▃▅▂▁▄▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82106
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81756
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93296
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34265
wandb:      train/ensemble_f1 0.34265
wandb:         train/mil_loss 0.64489
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gbr1szl4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181758-gbr1szl4/logs
wandb: Agent Starting Run: lng1p7wd with config:
wandb: 	actor_learning_rate: 0.006634048692288524
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4855088464434578
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9340359756585384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_181916-lng1p7wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lng1p7wd
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▁▅▂█▂▇▁▄▃▄▁▆▄▂▆▄▄▂▃▄▃▆▃▆▂▄▂▆▃▇▆▄▂▃▂▄▇
wandb:      train/ensemble_f1 ▅▅▁█▁▄▃▃▂▄▅▆▂▃▃▆▃▃▆▆▆▃▄▄▃▄▃▅▄▃▃▃▆▂▆▂▃▂▄▂
wandb:         train/mil_loss ▇▄▅▆▅▃▄▅▃▃▂▃▅▅▆▅▇▄▅▅▅▅▆▇▁▄▄▄█▄▇▄▄▃▅▂▂▄▁▄
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▃▃▅▁▃▅█▁▃▆▁▆▆▅▆▁▅▃▁██▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▆█▃▃▃▃▃▅█▆▇█▇▃▆▁▆▄▁▅▆▁▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38667
wandb: best/eval_avg_mil_loss 0.74725
wandb:  best/eval_ensemble_f1 0.38667
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 0.74176
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.31482
wandb:      test/avg_mil_loss 0.8384
wandb:       test/ensemble_f1 0.31482
wandb:           train/avg_f1 0.35058
wandb:      train/ensemble_f1 0.35058
wandb:         train/mil_loss 0.74548
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lng1p7wd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_181916-lng1p7wd/logs
wandb: Agent Starting Run: wepe3uoe with config:
wandb: 	actor_learning_rate: 4.329151247293938e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8823377280920369
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7696100250170144
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182033-wepe3uoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wepe3uoe
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▄▄▄▃▂▂▃▃▅▄▂▄▂▆▂▅▆▄▁▃▂▅█▄▅▄▄▂▄▃▂▃▂▅▅▅▂▃
wandb:      train/ensemble_f1 ▅▂▅▄▂▄▃▄▄▂▃▄▂▅▄▄▅▂▅▂▃▆▂▂▄▁▅▁▂█▄▅▆▅▄▄▂▂▆▅
wandb:         train/mil_loss █▄▄█▅▂▃▄▂▂▂▁▂▄▂▂▂▁▅▆█▂▇▂▅▂█▇▇▄▂▁▅▂▂▁▂▂▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.56251
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.54796
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.0702
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3383
wandb:      train/ensemble_f1 0.3383
wandb:         train/mil_loss 0.76732
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wepe3uoe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182033-wepe3uoe/logs
wandb: Agent Starting Run: 5w4mlx2v with config:
wandb: 	actor_learning_rate: 0.0007351938673543281
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9952897188317802
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.22925588679604347
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182151-5w4mlx2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5w4mlx2v
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▅▅▅▅▅▅▄▄▅▅▂▂▂▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▆▆▅▄▅▅▆▄▅▅▅▅▃▅▅▃▃▅▃▃▃▃▄▂▄▃▄▅▃█▂▄▅▆▅▄▄▃
wandb:      train/ensemble_f1 ▁█▇▆▆▅▆▆▇▇▇▄▇▆▆█▄▆▅▅▃▅▇▃▇▇▂▅▇▅▆▅▆▃▅▄▄▅▇▆
wandb:         train/mil_loss ▆▄▃▂▃▃▂▄▅▂▅▁▃▃▄▅▅▂▃▃▅▂▅▄▅▆▁▄▃▇▃▄▃█▁▄▃▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.86847
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.86776
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.9744
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32432
wandb:      train/ensemble_f1 0.32432
wandb:         train/mil_loss 0.59396
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vibrant-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5w4mlx2v
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182151-5w4mlx2v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b9cvdcl4 with config:
wandb: 	actor_learning_rate: 0.00024321698546438757
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5396189967819841
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7740135804811029
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182318-b9cvdcl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b9cvdcl4
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▂█▅▃▁▁▃▇▅▂▂▂▃▂▃▃▅▅▆▂▂▆▄▁▆▂▅▃▃▄▃▃▂▆▇▇▅
wandb:      train/ensemble_f1 ▃▃▃▂██▅▅▃▄▄▁▃▃▅▂▃▄▆▃▇▅▂▆▂▄▅▅▄█▄▃▃▄▅▆▅▆▄▅
wandb:         train/mil_loss ▇▃▅▁█▄▄▆█▄▁▅▄▂▄▇▃▄▃▂▁▅▄▄▆▅▄▁▄▆▂▅█▆▅▄▂▅▁▅
wandb:      train/policy_loss ▂▃▂▃█▁▄▇▃▅▄▄▅▅▂▅▄▅▅▁▄▃▄▄▃▁▄▆█▂█▄▁▃▃▂▄▄▇▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▆▇▅▅▃▅█▄▁▅▃▃▅▄▄▅▁▂▅▅▅▅▄▄▄▄▄▄▇▄▄▄▁▃▅▂▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47619
wandb: best/eval_avg_mil_loss 1.12282
wandb:  best/eval_ensemble_f1 0.47619
wandb:            eval/avg_f1 0.47619
wandb:      eval/avg_mil_loss 1.08507
wandb:       eval/ensemble_f1 0.47619
wandb:            test/avg_f1 0.52
wandb:      test/avg_mil_loss 0.96607
wandb:       test/ensemble_f1 0.52
wandb:           train/avg_f1 0.50593
wandb:      train/ensemble_f1 0.50593
wandb:         train/mil_loss 0.90461
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run splendid-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b9cvdcl4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182318-b9cvdcl4/logs
wandb: Agent Starting Run: su5b9p9g with config:
wandb: 	actor_learning_rate: 0.0005604726172137786
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15786517889186558
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9869161110849692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182435-su5b9p9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/su5b9p9g
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▄▃▂▄▃▅▄▃▇▃▂▆▇█▅▃▅▃▃▁▅▆▃█▄▅▂▂▅▂▃▂▅▄▄▅▄
wandb:      train/ensemble_f1 ▄▅▅▅▆▇▆▃▇▆▄▁▃▄▃▅▄██▂▅▃▄▂▇▃▆▃▆▆▄▄▄▄▄▆▇▅▆▃
wandb:         train/mil_loss ▄▄▅▆▄▅▄▅▃▇▆▅▅▆▂▆▁▅▆█▆▄▅▅▅▇▆▃▅▆▃▆▆▄▅▁▅▅▂▆
wandb:      train/policy_loss ▃▃▃▃▃▃▆▂▃██▁▁▃▆▆▁▁▁▃▃▁▁▃▆▃▃▁▄▁▆█▃▃▃▃▁▁▃▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▂█▁▁▆▃▃▄█▆▆▁▁▆▁▄▁▃▁▃▆▃▃▃▃▃▆█▃▆▁▃▁▄▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.31073
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.26779
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.0865
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40521
wandb:      train/ensemble_f1 0.40521
wandb:         train/mil_loss 1.26725
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/su5b9p9g
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182435-su5b9p9g/logs
wandb: Agent Starting Run: m5spjn65 with config:
wandb: 	actor_learning_rate: 0.002607464264632812
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3722056398458823
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10258792919276016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182553-m5spjn65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5spjn65
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▅▂▃▄▂▅█▆▄▆▃▂▃▃▃▃▂▅▃▅▇▃▅▃▅▃▃▅▁▄▄▄▄▂▅▄▁▃
wandb:      train/ensemble_f1 ▄▅▄▄▄▅▆▁▆▂▃▆▅█▆▂▄▂▄▄▃▃▂▃▇▆▄▆▄▆▂▄▃▄▅▆▆▆▄▅
wandb:         train/mil_loss ▆▅▂▃▇█▅▄▅▄▅▄▅▄▅▃▅▄▄▅▃▆▅▅▆▃▅▅▆▄▄▃▅▅▆▃▆▁▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.47256
wandb: best/eval_avg_mil_loss 0.73299
wandb:  best/eval_ensemble_f1 0.47256
wandb:            eval/avg_f1 0.47256
wandb:      eval/avg_mil_loss 0.72882
wandb:       eval/ensemble_f1 0.47256
wandb:            test/avg_f1 0.51097
wandb:      test/avg_mil_loss 0.71506
wandb:       test/ensemble_f1 0.51097
wandb:           train/avg_f1 0.47713
wandb:      train/ensemble_f1 0.47713
wandb:         train/mil_loss 0.64054
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m5spjn65
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182553-m5spjn65/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: js75c40n with config:
wandb: 	actor_learning_rate: 1.9128419878058223e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7689720972092663
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.04436075018481911
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182719-js75c40n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/js75c40n
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▆▃▃▃▆▆▅▆▆▄▅▇█▅▆▅▆█▄▅▄▅▇▅█▁▄▇▆▇▄█▄▅▃▅▆▆
wandb:      train/ensemble_f1 ▁▄▄▆▄█▂▅▅▆▅▅▆▆▅▇▆▅▄▃▄▆▄▆▅▃▃▅▄▃▄▆▇▄▅▅▄▃▄▅
wandb:         train/mil_loss ▁▅▃▃▅▇▃▂▂▂▁▆▂▂▆▂▅▁▁▂▄▁▅▅▆▆▂▄▄▁▆▄▆█▄▄▂▃▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82116
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.8174
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93434
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33444
wandb:      train/ensemble_f1 0.33444
wandb:         train/mil_loss 0.61844
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/js75c40n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182719-js75c40n/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4g71wick with config:
wandb: 	actor_learning_rate: 0.007709304921336786
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2134950858734251
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15214727209402668
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_182915-4g71wick
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g71wick
wandb: uploading wandb-summary.json
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▆▅▄▄▅▄▄▇▇▆▅▂▅▅▇▆▄▂▂▅▇▅▆█▆▃▃▂▁▆▅▄▃▄▅▄▁
wandb:      train/ensemble_f1 ▅▃▃▆▇▇▆▅▆▅▆▃▅▄▃▅█▄█▇▃▇▃▆▆▇▄▆▅▅▄▆▆▇▆▁▆▅▃█
wandb:         train/mil_loss ▇▅▅▇▇▄▅▇▆▇▅█▅▅▆▇▇▆▅▆▇▆▅▆▅▆▆▇▆▆▅▆█▆▄▁▄▆▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.61184
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.56972
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.11554
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34694
wandb:      train/ensemble_f1 0.34694
wandb:         train/mil_loss 1.35545
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swift-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4g71wick
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_182915-4g71wick/logs
wandb: Agent Starting Run: uin9tvty with config:
wandb: 	actor_learning_rate: 0.0001436458349000464
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5026276296040906
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15439952335861007
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183033-uin9tvty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uin9tvty
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃▂▄▃▇▄▅▂▅▅▆█▅▄▅▃▇▇▆▆▃▆▄▅▁▄▅▆▆▄▄▅▄▆▇▃▃▅▅
wandb:      train/ensemble_f1 ▂▄▆▄▄▁▂▄▂█▃▅▇▆▅▇▆▄▁▁▁▃▄▇▂▃▆▄▅▁▆▄▃▃▇▁▄▆▇▂
wandb:         train/mil_loss ▇▅▄▄▄▅▂▄▂▅▄▄▂▄▆▄▄▆▄▂▄▄▃▆▂█▁▃▅▂▅▄▂▆▂▄▄▄▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.42337
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.39037
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.91342
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 0.73473
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uin9tvty
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183033-uin9tvty/logs
wandb: Agent Starting Run: syrpo8ll with config:
wandb: 	actor_learning_rate: 1.1049001050707168e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5704758510044974
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37593390937526583
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183151-syrpo8ll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/syrpo8ll
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▄▄▄▅▅▆▇█▇████████▇▇▇▇▇
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▅▇▃▂▆▇█▅▁▅▃▄▃▃▁▅▁▃▇▃▅█▅▁▃▂▄▆▃▂▅▃▃▂▂▅▄▄
wandb:      train/ensemble_f1 ▅▆▅▇▄▇▄▆▃▆▄▇▄▃▅▅▄▅▄▅▂▃▆▄▄█▅▇▄▅▅▄▄▆▁▅▆▄▄▅
wandb:         train/mil_loss ▇▃▃▅▄▄▄▆▅▆▁▂▄▄▄▄▄▆▃▇▂▆▄▂▃▄▄▆▄▆▃▅▅▄▁▆▅▇▁█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.78711
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.79935
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.8925
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33278
wandb:      train/ensemble_f1 0.33278
wandb:         train/mil_loss 0.79406
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/syrpo8ll
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183151-syrpo8ll/logs
wandb: Agent Starting Run: b40gy6n3 with config:
wandb: 	actor_learning_rate: 0.0004773584110662852
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.36244807292465986
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9739094351604072
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183308-b40gy6n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b40gy6n3
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▆▆▃▆▆▄▅▄█▃▄▆▃▄▃▅▅▅▇▄▅▃▄▃▁▅▆▅▇▆▆▆▄▅▆▅▆▄
wandb:      train/ensemble_f1 ▆▃▃▆▆▃▃▄▆▅█▅▄▂▄▂▇▃▂▄▄▃▄▄▂▄▂▃▂▅▆▆▅▇▁▅▆▇▅▇
wandb:         train/mil_loss ▃▆█▆▇▆▂▄▇▆▅▄▆▃▃▃▅▇▁▆▄▅▅▃▃▄▄▆▄▃▅▇▇▄▇▅▃▇▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.56593
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.53197
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.07328
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3283
wandb:      train/ensemble_f1 0.3283
wandb:         train/mil_loss 1.43671
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b40gy6n3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183308-b40gy6n3/logs
wandb: Agent Starting Run: qvo4fn39 with config:
wandb: 	actor_learning_rate: 0.0002730253925106008
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2639869429509806
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4830208986057499
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183426-qvo4fn39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qvo4fn39
wandb: uploading history steps 86-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▃▅▂▅▆▇▆▁▅▅▅▃▅▆▄▆▆█▅▅▇▃▅▄▇▅▇▄▃▄▂▅▆▅▄▄▅
wandb:      train/ensemble_f1 ▆▇▇▅▆▄▁▆▅▁▇█▂▃▆▇▅▄▂▅▅▆▆▆██▅▃▇▄▇▆▄▄▄▅▅▆▅▅
wandb:         train/mil_loss ▃▅▆▅▄▇▃▂▄▃▄▆▃▂▅▃▅▁▃▄▄▃▇█▃▇▄▅▇▃▄▅▃▄▃▅▄▆▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.61062
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.56991
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 2.11032
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 1.48553
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run olive-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qvo4fn39
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183426-qvo4fn39/logs
wandb: Agent Starting Run: hcctjf5b with config:
wandb: 	actor_learning_rate: 0.002040285587483125
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9171783787666892
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3123673597359016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183544-hcctjf5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcctjf5b
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▅▅▅▅▅▅▅▄▇▇▅▃▃▃▂▂▂▂▁▁▅▅▄▄▄▃▂▂▂▂▁▅▄▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▆▆▇▂█▂▅▂▂▄▄█▅▄▅▄▄▄▄▂▅▅▁▅▆▄▆▇▇▄▇▅▃▆▇▄▇▄
wandb:      train/ensemble_f1 ▅▅▃▂▄▃▅▅▄▄▅▂▄▃▅▄▃▃▄▆█▄▁▅▅▂▅▅▃▅▅▂▄▄▅▄▅▄▅▆
wandb:         train/mil_loss ▂▄▅▇█▆▃▄▂▂▄▅█▃▆▄█▁▃▄▆▃▃▂▅██▄▄▂▅▂▆▇▅▅▂▃▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.81329
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81271
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.92377
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31682
wandb:      train/ensemble_f1 0.31682
wandb:         train/mil_loss 0.57021
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run curious-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hcctjf5b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183544-hcctjf5b/logs
wandb: Agent Starting Run: eax35qao with config:
wandb: 	actor_learning_rate: 0.004297119707895877
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5453716666774204
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6620863671148206
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183701-eax35qao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eax35qao
wandb: uploading history steps 85-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▂▆▅▁▃▆▄▄▅▃▃▃▆▅▅▆▅█▃▃▅▄▂▄▁▃▃▇▅▆▇▆▃▄▅▃▁▄
wandb:      train/ensemble_f1 ▄▄▄▃▂▄▁▄▂▃▃▃▃▆▅▆▅▆▃█▃▃▆▂▅▃▄▂▃▂▇▃▅▃▆▅▄▅▁▃
wandb:         train/mil_loss ▅▅▇▄▃▄▂▇▆▄▅▂▃▄▄▅▇▄▃▄█▅▄▂▅▃▁▆▇▆▅▄▆▇▇▃▄▄▄▅
wandb:      train/policy_loss ▄▇▅▇▆▆▁▅▇▂▅▃▅▇▅▄▁▄▅▂▅▅▅▅▄█▄▄▄▄▂▂▂▄▅▄▅▂▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▇▇▆▇▁▇▄▂▅▃▅▇▆▅▅▅▂▄▃▆█▆█▄▅▃▄▂▃▃▇▄▆▃▅▇▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.91723
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.90673
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.803
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39511
wandb:      train/ensemble_f1 0.39511
wandb:         train/mil_loss 0.72145
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eax35qao
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183701-eax35qao/logs
wandb: Agent Starting Run: xiyhe3k6 with config:
wandb: 	actor_learning_rate: 0.0019303328753484351
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7291830037655357
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44589364820851585
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183821-xiyhe3k6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/zwm4xct2
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xiyhe3k6
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▄▃▅▆▆▄▅▅▅▄▃▆▄▅▄▃▆▅▄▄▅▃▄▃▂▄▇▄▆▅▅▄▁▅▆█▅
wandb:      train/ensemble_f1 ▂▆▅▅▄▄▆▄▃▅▆▄▆▄▄▅▆▃▅▆▄▅▁▅▃▄▄▄▄▃▅▅▇▂▅▅▆█▄▁
wandb:         train/mil_loss ▆▄▆▃▂▄▃▃▆▆▆▂▇▄▂▂▆▂▇▄▅▃█▅▁▄▆▃▇▂▆▅▆▆▅▁▃▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82372
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.81994
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93681
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 0.67785
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xiyhe3k6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183821-xiyhe3k6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: js0rkcqz with config:
wandb: 	actor_learning_rate: 6.748076710167246e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4301154447972224
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9709874499097532
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_183956-js0rkcqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/js0rkcqz
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading history steps 84-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆█▄▃▄▇▇▂▅▅▄▄▅▁▆▅▃▆▂▄▄▅▄▅▂▃▅▅▆▄▄▂▃▃▁▄▇▄▆
wandb:      train/ensemble_f1 ▅▆▆█▆▄▆▂▄▆▂▃▄▁▆▃▆▂▄▄▃▅█▂▂▃▆▃▅▆▇▁▄▆▆▆▅▇▇▅
wandb:         train/mil_loss ▅▆▅▆▄▇▅▆▅▁█▅▄▆▄▃▂▃▂▃▇▃▃▇▂▄▄▂▄▇▃▅▂█▂▆▆▄█▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97243
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95494
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.13742
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3361
wandb:      train/ensemble_f1 0.3361
wandb:         train/mil_loss 0.70507
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/js0rkcqz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_183956-js0rkcqz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cvyi2s0j with config:
wandb: 	actor_learning_rate: 1.2407748893206336e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9805377289819124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8932712113985862
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184124-cvyi2s0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvyi2s0j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃█
wandb: best/eval_avg_mil_loss ▁▆█
wandb:  best/eval_ensemble_f1 ▁▃█
wandb:            eval/avg_f1 ▁▁▁▁▁███▅▆▆▆█▄▃▇▇▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ▁▁▁▂▂▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██
wandb:       eval/ensemble_f1 ▁▁██▅▆▆██▄▇▇▃▃▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▄▂█▅▅█▇▃▅▇▅▇▄▅▅▆▃▆▄▇▆▄▅▇▅▅▃▅▅█▆▅▇▄█▄▅▆
wandb:      train/ensemble_f1 ▄▅▁▁▅▃▄▅▅▅▅▆▅▅▅▆▆▅▆▅▃▆▇▃▇▅▄▆▃▅▅▄▅▅█▆▅▄▄▃
wandb:         train/mil_loss ▄▃▁▄▃▆▂▄▅▆▄▂█▂█▃▄▄▄▁▄▃▅▁▄▅▂▅▃▃▂▄▅▂▃▁▂▃█▃
wandb:      train/policy_loss ▂▂▂▆█▂▂▂▂▂▇▂▂▁▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄█▄▄▄▆▅▄▄▄▇▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57966
wandb: best/eval_avg_mil_loss 1.01452
wandb:  best/eval_ensemble_f1 0.57966
wandb:            eval/avg_f1 0.56044
wandb:      eval/avg_mil_loss 1.04807
wandb:       eval/ensemble_f1 0.56044
wandb:            test/avg_f1 0.55587
wandb:      test/avg_mil_loss 0.85179
wandb:       test/ensemble_f1 0.55587
wandb:           train/avg_f1 0.57138
wandb:      train/ensemble_f1 0.57138
wandb:         train/mil_loss 0.54919
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peachy-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cvyi2s0j
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184124-cvyi2s0j/logs
wandb: Agent Starting Run: nh91j3gf with config:
wandb: 	actor_learning_rate: 7.600759793775904e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4306824467283198
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9722547235921324
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184247-nh91j3gf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nh91j3gf
wandb: uploading history steps 89-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▄▄▄▄▄▄▄▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▃
wandb:      eval/avg_mil_loss ▇▇▆▆▆▅▅▆▆▆▅▅▄▄▄██▇▇▇▆▆▆▆▆▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 █████▄▄▄▄▄▄▄▄▄▄▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▃▁▁▁▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▃▂▆▅▁▃▄▄▃▄▂▇▄▅█▄█▄▅▅▅▃▇▂▄▇▄▅▄▆▃▆▄▆▄▄▆
wandb:      train/ensemble_f1 ▃▁▄▃▄▅▁▆▃▂▃▂▇▄█▅▂▅▃▃▅▄▆▄▃▅▄▁▅▅▆▆▅▃▅▄▄▅▄▅
wandb:         train/mil_loss ▃▄▄▄▄▅▆▄█▅▂▅▁▅▂▄▅▃▄▆▄▃▄▂▄▁▆▄▄▂▃▂▅▆▃▅▄▇▂▂
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▁▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56897
wandb: best/eval_avg_mil_loss 0.85355
wandb:  best/eval_ensemble_f1 0.56897
wandb:            eval/avg_f1 0.54449
wandb:      eval/avg_mil_loss 0.83333
wandb:       eval/ensemble_f1 0.54449
wandb:            test/avg_f1 0.46944
wandb:      test/avg_mil_loss 0.79909
wandb:       test/ensemble_f1 0.46944
wandb:           train/avg_f1 0.5436
wandb:      train/ensemble_f1 0.5436
wandb:         train/mil_loss 0.65692
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run light-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nh91j3gf
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184247-nh91j3gf/logs
wandb: Agent Starting Run: ggaqf4hm with config:
wandb: 	actor_learning_rate: 0.0017746198297034091
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3903620841488152
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20902219398685384
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184405-ggaqf4hm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ggaqf4hm
wandb: uploading history steps 88-107, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃█▁▁▁▁▁▁▂▁▁▁▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▂▃▃▃█▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▂▁▂▁▂▂▁▂▁
wandb:         train/mil_loss ▇█▆▅▁▃▃▄▂▂▁▂▃▄▄▃▃▄▃▅▃▃▄▄▃▂▂▃▂▄▃▄▄▃▃▂▃▂▃▂
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁███████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71989
wandb: best/eval_avg_mil_loss 0.65328
wandb:  best/eval_ensemble_f1 0.71989
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.93256
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.74796
wandb:      test/avg_mil_loss 0.54086
wandb:       test/ensemble_f1 0.74796
wandb:           train/avg_f1 0.31973
wandb:      train/ensemble_f1 0.31973
wandb:         train/mil_loss 0.86729
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ggaqf4hm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184405-ggaqf4hm/logs
wandb: Agent Starting Run: sfd3dz1b with config:
wandb: 	actor_learning_rate: 0.0005369366384944862
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9769055987948988
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9716249585995046
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184522-sfd3dz1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfd3dz1b
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▇▇███████
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▆▇▄█▄▂▄▃▄▆▇▄▅▃▃▅▂▄▄▁▄█▇█▃▅▄▃▃▂▆▆▄▂▅▄▅▁
wandb:      train/ensemble_f1 ▄▄▆▅▆▇▁█▂▇▄▆▇▅▃▃▃▅▄▄█▄▆▆▂▆▆▃▃▃▇▆▅▅▅▇▃▄▁▆
wandb:         train/mil_loss ▅▄▆▃▃▃▅▄▃▅█▆▃▆▅▇▃▅▇▃▃▅▅▃▄▅▃▃▁▃▄▄▃▄▅▄▆▆▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁██▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁█▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁█▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 0.72851
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.73648
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.79647
wandb:      test/avg_mil_loss 0.47359
wandb:       test/ensemble_f1 0.79647
wandb:           train/avg_f1 0.70701
wandb:      train/ensemble_f1 0.70701
wandb:         train/mil_loss 0.57332
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sfd3dz1b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184522-sfd3dz1b/logs
wandb: Agent Starting Run: gydk2sst with config:
wandb: 	actor_learning_rate: 2.732971756972318e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8389506212617166
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3260099913801844
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184640-gydk2sst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gydk2sst
wandb: uploading history steps 87-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▅█▄▅▂▂▄▂▃▅▅▅▃▅▆▅▃▆▆▃▇▁▄▃▆▃▆▅▁█▃▁▅▄▅▂▅
wandb:      train/ensemble_f1 ▆▄▄▇▄▃▄▃▄▁▃▁▆▄▅▃▃▂▆▅▄▆▁▅▃▅▃▅▆▃█▇▄▃▂▄▄▅▄▅
wandb:         train/mil_loss ▆▃▃▁▁▁▇▃▃▃▃▁▁▁▅█▃▃▃▁▃▃▅▅▁▆▃▁▃▃▄▃▁▃▃▁█▁▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.99319
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.94796
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.83246
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.335
wandb:      train/ensemble_f1 0.335
wandb:         train/mil_loss 0.99455
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gydk2sst
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184640-gydk2sst/logs
wandb: Agent Starting Run: zl4ws3l7 with config:
wandb: 	actor_learning_rate: 0.00019090020054133317
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5186435398162069
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9488484167755904
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184758-zl4ws3l7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl4ws3l7
wandb: uploading config.yaml
wandb: uploading history steps 109-122, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▆▆▁▁▁▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▆█▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▆▁▁▁▁▅▅██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▄█▄▄▅▄▅▃▄▄▆▂▃▅▄▅▄▆▂▁▆▄▅▆▄▄▃▇▇▆▆▆▃█▇▄▃
wandb:      train/ensemble_f1 ▄▅▅▂▄▃▃▃▃█▄▃▄▆▆▅▄▆▅▄▅▁▆▄▆▅▄▄▃▇▆▆▄█▄▅▄▄▄▄
wandb:         train/mil_loss ▆█▇▂█▇▃▅▄▃▁▄▄▄▃▄▅▄▅▅▅▆▆▆▂▂▅▇▅▄▅▄▅▅▃▅▆▃▅▄
wandb:      train/policy_loss ▁███████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▁█████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.56261
wandb: best/eval_avg_mil_loss 0.83843
wandb:  best/eval_ensemble_f1 0.56261
wandb:            eval/avg_f1 0.55357
wandb:      eval/avg_mil_loss 0.81837
wandb:       eval/ensemble_f1 0.55357
wandb:            test/avg_f1 0.46375
wandb:      test/avg_mil_loss 0.76512
wandb:       test/ensemble_f1 0.46375
wandb:           train/avg_f1 0.49636
wandb:      train/ensemble_f1 0.49636
wandb:         train/mil_loss 0.63297
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zl4ws3l7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250601_184758-zl4ws3l7/logs
wandb: Agent Starting Run: 3qud5z05 with config:
wandb: 	actor_learning_rate: 0.000164782422777095
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2644663814566961
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9086094453982854
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250601_184930-3qud5z05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/2u82r01o
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3qud5z05
slurmstepd: error: *** JOB 12116333 ON gcn144 CANCELLED AT 2025-06-01T18:51:50 DUE TO TIME LIMIT ***
